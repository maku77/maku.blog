---
title: "機械学習 (ML) 用語のまとめ"
url: "p/ouzjm6o/"
date: "2023-12-30"
tags: ["ml"]
draft: true
---

特徴量エンジニアリング
: 読み込んだデータを機械学習用アルゴリズムが使える形に加工すること。あるいは、既存のデータの組み合わせや加工により、新しい特徴量を作成すること。

標準化
: 各特徴量の平均を 0、標準偏差を 1 になるように揃えること。
scikit-learn であれば、`sklearn.preprocessing.StandardScaler()` を使用して標準化を行えます。
伝統的な機械学習アルゴリズムでは特徴量の標準化を行わないと学習がうまくいかないことがありますが、「ランダムフォレスト」や「LightGBM」などの標準化が必要ないアルゴリズムもあります。

カテゴリ変数／カテゴリカル変数／質的変数
: カテゴリ変数は、数値ではなく特定のカテゴリや群を表す変数です。
例えば、血液型（A型、B型、O型、AB型）、色（赤、青、緑）、商品のカテゴリ（服、食品、家電）などがカテゴリ変数の例です。
一般的には文字列で表現されるもので、数値にマッピングすることは可能ですが、それらの数値の大小関係に意味はありません。

正解ラベル
: モデルが予測しようとする対象の出力または目的変数を表します。
通常、教師あり学習（Supervised Learning）の文脈で使われます。
正解ラベルは、トレーニングデータセットにおいて各入力データに対して対応する出力や目的となる値です。
例えば、画像が犬か猫かを分類するモデルを考えると、各画像データ（入力）に対してその画像が犬か猫かのラベル（出力）が正解ラベルとなります。

決定境界
: 分類アルゴリウムがデータを各クラスに分類するときの境界。

OVR (One Vs Rest)
: 2 値のロジスティック回帰の予測モデルを、3 クラス以上の分類に使用する手法。
例えば、クラス A/B/C の 3 値に分類する問題があるとします。
それぞれのクラスで 2 値の予測 (y=0 or y=1) を行うことで、クラス A である確率、クラス B である確率、クラス C である確率が求められます。
これらのうち、一番確率の高いものを 3 値分類の結果とするという手法です。

