<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>音声認識 on まくろぐ</title><link>https://maku.blog/tags/%E9%9F%B3%E5%A3%B0%E8%AA%8D%E8%AD%98/</link><description>Recent content in 音声認識 on まくろぐ</description><generator>Hugo -- gohugo.io</generator><language>ja-jp</language><lastBuildDate>Wed, 31 Jul 2024 00:00:00 +0900</lastBuildDate><atom:link href="https://maku.blog/tags/%E9%9F%B3%E5%A3%B0%E8%AA%8D%E8%AD%98/index.xml" rel="self" type="application/rss+xml"/><item><title>Svelte 実装例: Web ブラウザで音声認識する (SpeechRecognition)</title><link>https://maku.blog/p/bf4cpjx/</link><pubDate>Wed, 31 Jul 2024 00:00:00 +0900</pubDate><guid>https://maku.blog/p/bf4cpjx/</guid><description>何をするか？ Web ブラウザーの SpeechRecognition API を使って、音声認識をしてみます。 ここでは Svelte アプリケーションとして作成しますが、単純な HTML + JavaScript の組み合わせでもほぼ同様のコードになると思います（参考: Svelte 関連メモ）。
デモ: https://p-bf4cpjx-svelte-speech-recognition.vercel.app/ ソースコード: https://github.com/maku77/p-bf4cpjx-svelte-speech-recognition/ プロジェクトの準備 Svelte (SvelteKit) のプロジェクトがない場合は最初に作成しておきます。
プロジェクトの作成 $ npm create svelte@latest myapp (選択肢が表示されたら TypeScript を選択しておく） $ cd myapp $ npm install SpeechRecognition はブラウザ標準の API として策定されているものですが、TypeScript の型情報が認識されなかったので DefinitelyTyped で提供されている型情報 @types/dom-speech-recognition をインストールしておきます。
型情報のインストール $ npm install --save-dev @types/dom-speech-recognition これで、window.SpeechRecognition コンストラクタや、SpeechRecognitionResult などの各型情報を参照できるようになります。
SpeechRecognition の使い方 SpeechRecognition による音声認識の基本的な流れは次のようになります。
SpeechRecognition インスタンスを生成して、各種パラメーターを設定する。 SpeechRecognition.onresult プロパティに、認識結果を受け取るためのコールバック関数を設定する。 SpeechRecognition.start() でマイクからの音声キャプチャと音声認識を開始する。 SpeechRecognition インスタンスの生成 まず、SpeechRecognition インスタンスを生成して、各種パラメータを設定していきます。 次のような感じで関数化しておくと分かりやすいです。</description></item><item><title>Azure Speech Service を使って音声をテキストに変換する (STT)</title><link>https://maku.blog/p/5zx3ozz/</link><pubDate>Wed, 24 Jul 2019 00:00:00 +0900</pubDate><guid>https://maku.blog/p/5zx3ozz/</guid><description>Microsoft の Cognitive Services のひとつとして提供されている Speech Service を使用すると、音声をテキストに変換したり、逆にテキストを音声に変換したりすることができます。
ここでは、Python から Speech Service の機能を利用してみます（Windows 10 で動作確認済）。 実行するにはマイクのついた PC が必要です マイクのついていない PC で実行すると SPXERR_MIC_NOT_AVAILABLE エラーが発生します。
準備 Speech Service の準備 Azure Portal から Speech のリソースを作成し、Subscription Key を取得しておいてください。
Speech SDK のインストール Python の azure-cognitiveservices-speech パッケージをインストールします。
$ pip install azure-cognitiveservices-speech Visual Studio C++ Redistributable のインストール 必要があれば、Visual Studio C++ の再頒布可能パッケージをインストールします。
Visual C++ 再頒布可能パッケージ (vc_redist.x64.exe) Python コード 一回だけ変換して終わるバージョン stt.py import azure.cognitiveservices.speech as speechsdk # この設定は適宜変更してください subscription = &amp;#34;e1b5f0964ab743133b7de4f892741c7a&amp;#34; region = &amp;#34;japaneast&amp;#34; language = &amp;#34;ja-JP&amp;#34; # proxy = (&amp;#34;proxy.</description></item></channel></rss>