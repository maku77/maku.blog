var data = [
{
url: "/p/ujqinda/",
title: "プログラミング",
date: "2022-06-22T00:00:00Z",
body: "プログラミング"
},
{
url: "/p/cenio8m/",
title: "AWS 一般／環境／設定など",
date: "2022-04-11T00:00:00Z",
body: "AWS 一般／環境／設定など"
},
{
url: "/p/vrhjtds/",
title: "Azure のメモ",
date: "2021-06-12T00:00:00Z",
body: "Azure のメモ"
},
{
url: "/p/pufs8kx/",
title: "Amazon Cognito (1) サインイン可能な Web サイトを作る (Cognito User Pool)",
date: "2021-05-28T00:00:00Z",
body: "Amazon Cognito (1) サインイン可能な Web サイトを作る (Cognito User Pool) Cognito とは？ Amazon Cognito は、各種アプリケーションにユーザーの概念を取り入れて、サインアップやサインインなどを行えるようにするサービスです（OpenID Connect 準拠の Identity Provider (IdP) のひとつです）。 Cognito は大きく下記の 2 つの機能から成ります。 ユーザープール: ユーザーを管理する。任意のアプリに、ユーザー登録（サインアップ）や、認証（サインイン）の機能を付けることができる。 ID プール: 上記の仕組みでサインインしたユーザーに対して、AWS サービスへのアクセス権限を付加する。 単純にユーザー管理だけをしたいのであれば、前者の「ユーザープール」の機能だけを使うことができます。 実際には、認証後に AWS のリソースにアクセスさせることが多いと思いますので、後者の「ID プール」の仕組みを使って IAM の権限割り当てを行うことになります。 認証の仕組みに関しては、5 万 MAU（月間アクティブユーザー）まで無料で使えるので、個人で作成しているアプリでも使いやすいと思います。 ただし、無料枠を超えると 1 ユーザーあたり 1 円くらいかかり、多要素認証などを使おうとするともう少しお金がかかります。 詳しくは、Cognito の料金）のページを参照してください。 通常、Web サイトに認証機能を付けたいと思うと、ユーザー管理の仕組みや、サインイン画面などの UI を作成する必要がありますが、Cognito はこれらをまとめて提供してくれます。 ここでは、Cognito のユーザープールの作成から、React アプリでの認証までを説明します。 Cognito にユーザープールを作成する 準備として、Cognito のユーザープールを作成しておきます。 Cognito のマネージメントコンソールにアクセス ユーザープールの管理 → ユーザープールを作成する を選択します ユーザー作成時の条件 (Attribute) などを設定して作成ボタンを押します プール名は、適当に myapp-test とでも付けておけば大丈夫です。 本番環境用のユーザープールと、開発／テスト用のユーザープールは分けて作っておくのがよいので、ここではサフィックスとして -test を付けておきました。 デフォルト設定でサクッと作成してしまうこともできるし、いろいろな条件（メールアドレス必須とかパスワード強度とか）を指定することもできます。 ここでは、とりあえずデフォルト設定で適当に作成してしまいましょう。 ユーザー名でなく、メールアドレスでもログインできるようにしたいときは、属性 (Attribte) のタブで、ユーザー名 - 検証済みの E メールアドレスでのサインインも許可 にチェックをいれておきます。 デフォルト設定は次のような感じになってます。 ユーザーは自由にサインアップできる（Eメールアドレスが必須） ユーザー名の大文字・小文字は区別しない (Maku = maku = mAkU） パスワードは 8 文字以上（大文字 + 小文字 + 特殊文字 + 数字） ユーザープールを作成すると、Cognito のマネージメントコンソール上から、ユーザーの追加や削除ができるようになります。 次に、「アプリクライアントの登録」という作業を行います。 これは、Web アプリやモバイルアプリなど、独自のアプリから Cognito のユーザープール（および ID プール）を利用するための設定です。 （参考）OAuth 2.0 の認可コードフロー ここは読み飛ばしても構いませんが、OAuth 2.0 の認可コード・グラントタイプ・フロー (RFC 6749 4.1) を大まかにでも理解していると、Cognito での各種設定の意味がよく分かるようになります。 OAuth では認可サーバーを用いて、Web API の呼び出しに必要なアクセストークンを取得するまでの仕組みを定義しており、Cognito の認証＆認可もこの仕組みを利用しています。 正確には、OAuth はアプリにアクセス権限を与える「認可」の仕組みであって、サインインなどの「ユーザー認証」に関しては定義していませんが、ここではわかりやすさのために記載しています。 下記は、OAuth の 認可コードフロー (Authorization code grant) で定義されているアクセストークン取得の流れです。 Cognito の設定項目の中にも、まさに、OAuth の認可コードフロー (Authorization code grant) を有効にする、というチェックボックスがあります、 アプリが認可サーバー（認可エンドポイント）に認可リクエスト (with クライアント ID）を投げると、リソース参照の同意を求める画面が表示される。通常は、そのリソースを提供するサービスへのサインイン（認証）を伴うことになる（他のユーザーのリソースを勝手にアクセス許可できないので当たり前と言えば当たり前）。 ユーザーがサインインしてリソースアクセスを了承すると、認可サーバー（認可エンドポイント）から 認可コード (Authorization code) が返される。このとき、あらかじめクライアント ID に紐づけられている URL にリダイレクトされて、認可コード付きアドレスで Web アプリ側の画面に戻ってくる。 Web アプリは認可サーバー（トークンエンドポイント）に認可コードを送って アクセストークン (Access token) を受け取る。 アクセストークンを取得したアプリは Web API を呼び出して、リソースサーバーから情報を取得できるようになります。 リソースサーバーは送られてきたアクセストークンが正しいものか判断した上で、問題なければ情報を返します（例えば、認可サーバーのイントロスペクションエンドポイントにアクセストークンを送ることで有効性を判断します）。 リソースサーバーと認可サーバーは同一であることがよくあります。 アクセストークンというのは、限られたリソースのみ（スコープといいます）にアクセスを許可するためのキーのようなものです。 このアクセストークンの定義と取得の流れが OAuth 認可フレームワークの要です。 ユーザープールにアプリクライアント情報を登録する クライアント ID の発行 任意のクライアントから Cognite のユーザープールにアクセスするには、あらかじめクライアント情報を登録して、接続用の クライアント ID を発行しておく必要があります。 複数のクライアントタイプ（Web アプリやモバイルアプリ）からのアクセスを想定しているのであれば、それぞれを別のクライアント情報として登録することが推奨されています。 これは、アクセストークン取得のフローなどが異なるからです（参考: OAuth 2.0 - 2.1 クライアントタイプ）。 Cognito のマネージメントコンソールで対象のユーザープールを選択します アプリクライアント → アプリクライアントの追加 を選択します 適当な「アプリクライアント名」を入力します（myapp-test-browser) など クライアントシークレットを作成 のチェックを外します（これはサーバーサイドにキーを埋め込んだりして、AWS の API 呼び出し時に直接指定したいときのもの） アプリクライアントの作成 ボタンを押します 図: 発行されたクライアント ID 上記のようにアプリクライアントの ID が発行されるので、これをメモしておきます。 サインイン画面用のドメイン名を設定 Cognito はサインアップやサインインのための Web ページを提供してくれるのですが、そのための一意なアドレスを設定しておく必要があります。 ユーザープールのサイドバーから、アプリの統合／ドメイン名 を選択します 適当なドメイン名を設定して 変更の保存 をクリックします コールバックアドレスの登録 次に、Web ブラウザ上のアプリから認証＆認可を行うために、作成しようとしている Web サイトの URL をコールバックアドレスとして登録します。 ☝️ なぜコールバックアドレスの登録が必要か？ Cognito でのサインインはあくまで AWS 上のサイト（https://\u0026lt;任意\u0026gt;.auth.ap-northeast-1.amazoncognito.com など）で行われるため、一時的に Web ブラウザの URL は、自分のサイトから離脱することになります。 サインインが終了したあとに、もとの Web サイトに戻ってくるために、このコールバックアドレスに対してリダイレクトしてもらう必要があります。 ユーザープールのサイドバーから、アプリの統合／アプリクライアントの設定 を選択します。 ID プロバイダ (IdP) として、今回作成した Cognito User Pool を選択します（Cognito は他にも Google や Facebook のアカウントを使えるよう設定できます）。 サインイン後のリダイレクト先 URL を指定します（例: https://myapp.example.com/)。基本的に https:// で始まるアドレスが必要ですが、テスト用クライアントであれば、http://localhost:3000/ のようなローカルアドレスを指定できます。 OAuth 2.0 の設定では、認証フローとして Authorization code grant （前述の認可コードフロー）を選択し、必要なスコープ（アクセストークンで扱える権限）を選択します。スコープは迷ったらとりあえず全部選択しておきます。 最後に 変更の保存 を押して設定完了です。 ☝️ Authorization code grant と Implicit grant 昔は Web ブラウザだけでのトークン取得には、暗黙的フロー (Implicit grant) が使われることがありましたが、これは認可時に認可コードを経由してトークンを取得するというステップを踏まず、直接トークンをリダイレクト URL のフラグメントに付加してしまう方法です。 このフローはセキュリティホールになりやすく、現在では Web ブラウザでのトークン取得においても 認可コードフロー (Authorization code grant) を使うのが主流になっています。 サインイン画面を表示してユーザー登録してみる 上記の設定が完了すると、「アプリクライアントの設定」の下の方の ホストされた UI を起動 というリンクが有効になります。 このリンクをクリックすると、Cognito が提供してくれるサインイン（サインアップ）画面が表示されます。 デフォルトのサインイン画面はこのようにシンプルですが、もちろんカスタマイズできます。 今回はまだユーザーを登録していないと思いますので、ここの Sign up リンクから、新しいユーザーをユーザープールに登録してみましょう。 登録時に指定したメールに送られてくる確認コード (verification code) を入力すれば、ユーザーの登録が完了するはずです。 確認コード入力後に、先ほど設定したリダイレクト先アドレス（例: http://localhost:3000/?code=3bc09fe0-ba9e-4b88-98c2-58eacdc99006）に飛ぶので、Web ブラウザではページが見つからないというエラーになりますが、この段階では無視して大丈夫です。 Cognito サービス側のユーザーの登録処理と、Eメールアドレスの検証処理自体は正しく完了しています。 Cognito のコンソールで「ユーザーとグループ」タブを選択すれば、そのユーザーが登録されていることを確認できるはずです。 Node.js アプリからサインインしてみる いよいよ、独自アプリから Cognito による認証を使用してみます。 React アプリ内からサインイン画面を表示したりする前に、まずは単純な Node.js のコンソールアプリで Cognito 認証を試してみます。 aws-amplify という npm パッケージを使うと簡単です。 AWS Amplify サービス自体を使うわけではないのですが、Cognito 関連の SDK もここに含まれているのでこれを使います。 $ npm install aws-amplify （あるいは yarn add） 次のコードを実行してユーザー認証に成功すると、標準出力にアクセストークンなどの情報が出力されます。 もちろんユーザー情報は、前述の作業で登録したユーザーのものを指定してください。 signin.ts import { Amplify, Auth } from \u0026#39;aws-amplify\u0026#39;; // 使用するユーザープール、クライアントの ID を指定 Amplify.configure({ Auth: { region: \u0026#39;ap-northeast-1\u0026#39;, userPoolId: \u0026#39;ap-northeast-1_w4Lb7OMrk\u0026#39;, userPoolWebClientId: \u0026#39;7egbq6mnk61udtpa0v7qr5u96o\u0026#39;, } }); async function signIn() { const username = \u0026#39;User-1\u0026#39;; const password = \u0026#39;Password-1\u0026#39;; try { const user = await Auth.signIn(username, password); console.log(user); // console.log(user.attributes.email); } catch (error) { console.error(error); } } signIn(); Amplify.configure() で指定する ID 情報は、Cognito マネージメントコンソールの、ユーザープール管理画面で確認できます。 userPoolId: 全般設定 タブの プール ID userPoolWebClientId: アプリクライアント タブの アプリクライアント ID React アプリでサインインが必要な画面を作る @aws-amplify/ui-react パッケージは、Cognito を利用するための React コンポーネントを提供します。 aws-amplify パッケージに加えて、このパッケージをインストールします。 $ npm install aws-amplify @aws-amplify/ui-react このパッケージが提供する AmplifyAuthenticator コンポーネントを使用すると、Cognito で サインイン済みでないと表示できないページ を作成することができます。 下記は Next.js アプリのカスタム App (pages/_app.tsx) 実装例ですが、このように全体を AmplifyAuthenticator で囲むと、ページ全体がサインイン済みのときのみ表示されるようになります。 Web ブラウザ上で動作する React アプリにおいても、Cognito ユーザープールにアクセスする前に、Amplify.configure 関数 で接続情報をセットしておかなければいけないのは同様です。 pages/_app.tsx import type { AppProps } from \u0026#39;next/app\u0026#39;; import { Amplify } from \u0026#39;aws-amplify\u0026#39;; import { AmplifyAuthenticator, AmplifySignOut } from \u0026#39;@aws-amplify/ui-react\u0026#39;; // Cognito ユーザープールとクライアントの ID 設定 Amplify.configure({ Auth: { region: \u0026#39;ap-northeast-1\u0026#39;, userPoolId: \u0026#39;ap-northeast-1_w4Lb7OMrk\u0026#39;, userPoolWebClientId: \u0026#39;7egbq6mnk61udtpa0v7qr5u96o\u0026#39;, } }); function MyApp({ Component, pageProps }: AppProps): JSX.Element { return ( \u0026lt;AmplifyAuthenticator\u0026gt; \u0026lt;AmplifySignOut /\u0026gt; \u0026lt;Component {...pageProps} /\u0026gt; \u0026lt;/AmplifyAuthenticator\u0026gt; ); } export default MyApp; サインインしていない状態では、AmplifyAuthenticator コンポーネントは、次のようにサインイン画面を表示してくれます。 サインインすると、次のように通常のページが表示されます。 今回は、先頭に AmplifySingOut コンポーネントを配置しているので、サインアウト用のボタンが表示されています。 上記のコードで何となくサインインが必要な Web サイトができた感じがしますが、実際には @aws-amplify/ui-components モジュールが提供する AuthState の状態を見て、サインイン済みかどうかを判断して表示処理を分岐させた方がよいようです（おそらく、AmplifyAuthenticator コンポーネントのレンダリングが常に走ってしまうのを防ぐため）。 このあたりは、Amplify SDK の公式サイト にも recommended way として記載されています。 例えば、次のような感じで表示部分の場合分けをすればよさそうです。 pages/_app.tsx import React from \u0026#39;react\u0026#39; import Head from \u0026#39;next/head\u0026#39; import type { AppProps } from \u0026#39;next/app\u0026#39; import { Amplify } from \u0026#39;aws-amplify\u0026#39; import { AmplifyAuthenticator } from \u0026#39;@aws-amplify/ui-react\u0026#39; import config from \u0026#39;../libs/config\u0026#39; import { useAuthState } from \u0026#39;../libs/useAuthState\u0026#39; // Cognito ユーザープールとクライアントの ID 設定 Amplify.configure(config.amplify) export default function MyApp({ Component, pageProps }: AppProps): JSX.Element { const { isSignedIn } = useAuthState() return isSignedIn ? ( \u0026lt;\u0026gt; \u0026lt;Head\u0026gt; \u0026lt;title\u0026gt;My App\u0026lt;/title\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;minimum-scale=1, initial-scale=1, width=device-width\u0026#34; /\u0026gt; \u0026lt;/Head\u0026gt; \u0026lt;Component {...pageProps} /\u0026gt; \u0026lt;/\u0026gt; ) : ( \u0026lt;AmplifyAuthenticator /\u0026gt; ) } 上記の例では、useAuthState() というカスタムフックを作成して、現在のサインイン状態やユーザー情報 (CognitoUserInteface) を簡単に取得できるようにしています。 下記はこのカスタムフックの実装例ですが、もう少し綺麗に書けるうまいやり方があるといいなぁ。。。 副作用フック (useEffect) の中の非同期 API 呼び出しで、状態セットしているのも若干問題ありですがとりあえずは動作します。 できれば公式 SDK でこういうフックサポートして欲しい。 libs/useAuthState.ts import { useEffect, useState } from \u0026#39;react\u0026#39; import { Auth } from \u0026#39;aws-amplify\u0026#39; import { AuthState, CognitoUserInterface, onAuthUIStateChange } from \u0026#39;@aws-amplify/ui-components\u0026#39; export type UseAuthStateOutput = { isSignedIn: boolean user: CognitoUserInterface | undefined } export const useAuthState = (): UseAuthStateOutput =\u0026gt; { // Cognito によるサインイン状態やユーザー情報を保持するステート const [authState, setAuthState] = useState\u0026lt;AuthState\u0026gt;() const [user, setUser] = useState\u0026lt;CognitoUserInterface | undefined\u0026gt;() // サインイン状態やユーザー情報の変化をハンドル useEffect(() =\u0026gt; { // 画面遷移時に onAuthUIStateChange が呼ばれないことへの対応 // https://github.com/aws-amplify/docs/issues/2895 if (authState === undefined) { Auth.currentAuthenticatedUser() .then((authData) =\u0026gt; { setAuthState(AuthState.SignedIn) setUser(authData) }) .catch(() =\u0026gt; { /* Nothing to do */ }) } // 公式にはこの呼び出しだけでよいような記述がありますが。。。 return onAuthUIStateChange((nextAuthState, authData) =\u0026gt; { setAuthState(nextAuthState) setUser(authData as CognitoUserInterface) }) }, [authState]) return { isSignedIn: authState === AuthState.SingedIn, user } } （おまけ）サインイン状態とユーザー名の取得 次の UserInfo コンポーネントは、Cognito でサインインが完了して、そのユーザー情報が取得できているときは、Hello, \u0026lt;ユーザー名\u0026gt; と表示し、それ以外の場合は Not signed in と表示します。 もっとも、サインイン後にしか描画しないページコンポーネントの中でこのコンポーネントを使うのであれば、Not signed in の文字を見ることはありません。 components/UserInfo.tsx import React from \u0026#39;react\u0026#39; import { useAuthState } from \u0026#39;../libs/useAuthState\u0026#39; export const UserInfo: React.FC = () =\u0026gt; { const { user } = useAuthState() // サインイン状態によって表示内容を分ける return user ? ( \u0026lt;h1\u0026gt;Hello, {user.username}\u0026lt;/h1\u0026gt; ) : ( \u0026lt;h1\u0026gt;Not signed in\u0026lt;/h1\u0026gt; ) } （おまけ）Sign-In 画面や Sign-Up 画面をカスタマイズする Amplify ライブラリが提供するデフォルトの ユーザー作成画面 (Sign Up) には、「電話番号 (Phone Number)」の入力欄などが表示されます。 この画面の表示項目をカスタマイズするには、AmplifyAuthenticator コンポーネントの下に AmplifySignUp コンポーネントを配置して、その属性で表示内容を指定します。 次の例では、「サインアップ画面 (AmplifySignUp)」と「サインイン画面 (AmplifySignIn)」をカスタマイズしています。 // import { // AmplifyAuthenticator, AmplifySignIn, AmplifySignUp // } from \u0026#39;@aws-amplify/ui-react\u0026#39; \u0026lt;AmplifyAuthenticator\u0026gt; \u0026lt;AmplifySignUp slot=\u0026#34;sign-up\u0026#34; headerText=\u0026#34;ユーザーの新規登録\u0026#34; formFields={[ { type: \u0026#39;username\u0026#39;, label: \u0026#39;ユーザー名 *\u0026#39; }, { type: \u0026#39;email\u0026#39;, label: \u0026#39;メールアドレス *\u0026#39; }, { type: \u0026#39;password\u0026#39;, label: \u0026#39;パスワード *\u0026#39; }, ]} /\u0026gt; \u0026lt;AmplifySignIn slot=\u0026#34;sign-in\u0026#34; headerText=\u0026#34;MyApp サインイン\u0026#34; submitButtonText=\u0026#34;サインイン\u0026#34; formFields={[ { type: \u0026#39;username\u0026#39;, label: \u0026#39;ユーザー名\u0026#39; }, { type: \u0026#39;email\u0026#39;, label: \u0026#39;メールアドレス\u0026#39; }, ]} /\u0026gt; \u0026lt;/AmplifyAuthenticator\u0026gt; サインイン画面から、「Create account」のリンクを消すには、AmplifySignIn コンポーネントの hideSignUp 属性を true に設定します（= 以降は省略可）。 \u0026lt;AmplifyAuthenticator\u0026gt; \u0026lt;AmplifySignIn slot=\u0026#34;sign-in\u0026#34; hideSignUp /\u0026gt; \u0026lt;/AmplifyAuthenticator\u0026gt; 参考 Amazon Cognito (2) サインイン後に AWS リソースへのアクセス権限を与える (Cognito Identity Pool)"
},
{
url: "/p/s9iry9g/",
title: "Next.js ですべてのページにグローバルな CSS を適用する (pages/_app.ts)",
date: "2021-05-06T00:00:00Z",
body: "Next.js ですべてのページにグローバルな CSS を適用する (pages/_app.ts) Next.js で、すべてのページコンポーネント (pages/*.tsx) に共通のスタイルシート（いわゆるグローバル CSS）を適用したい場合は、pages/_app.tsx(js) というファイルを作成して、そこで CSS ファイルをインポートします。 例えば、グローバル CSS として次のようなファイルを用意したとします。 styles/global.css * { box-sizing: border-box; } html { margin: 0; padding: 0; } body { font-family: -apple-system, BlinkMacSystemFont, Segoe UI, Roboto, Oxygen, Ubuntu, Cantarell, Fira Sans, Droid Sans, Helvetica Neue, sans-serif; max-width: 50rem; padding: 0.5rem; margin: 0 auto; font-size: 100%; } a { color: inherit; text-decoration: none; } この CSS ファイルを pages/_app.tsx からインポートすれば、すべてのコンポーネントにスタイルが反映されます。 このファイルが存在しない場合は作成してください。 pages/_app.tsx import type { AppProps } from \u0026#39;next/app\u0026#39; import \u0026#39;../styles/global.css\u0026#39; export default function MyApp({ Component, pageProps }: AppProps) { return \u0026lt;Component {...pageProps} /\u0026gt; } ☝️ pages/_app.tsx って何者？ Next.js は pages/_app.tsx を特殊なファイルとして扱い、ここで default export しているコンポーネントを、すべてのページコンポーネントの親コンポーネントとして扱います。 具体的には、上記コード中の Component 部分が各ページのコンポーネントに置き換えられた形で動作します。 結果的に、ここでインポートした CSS が、全ページから参照できることになります。 ちなみに、ここで複数の CSS ファイルをインポートしている場合は、Next.js が Web サイトのビルド時に 1 つの CSS ファイルにマージしてくれます。 Bootstrap や Tailwind CSS などの CSS フレームワークを使いたい場合も、この pages/_app.tsx ファイルでインポートすれば OK です。 参考リンク Next.js で Bootstrap (React Bootstrap) を使う"
},
{
url: "/p/qcp2coz/",
title: "Next.js の API Routes 機能で Web API を作成する",
date: "2021-05-05T00:00:00Z",
body: "Next.js の API Routes 機能で Web API を作成する Next.js の Web API 機能 Next.js では、pages/api ディレクトリ以下に TypeScript (JavaScript) コードを配置するだけで、クライアントサイド JavaScript から呼び出せる API を定義することができます。 例えば、次のようなファイルを作成します。 pages/api/hello.ts import type { NextApiRequest, NextApiResponse } from \u0026#39;next\u0026#39; type Response = { name: string } export default (req: NextApiRequest, res: NextApiResponse\u0026lt;Response\u0026gt;) =\u0026gt; { res.status(200).json({ name: \u0026#39;John Doe\u0026#39; }) // チェーン呼び出しせずに次のように記述しても OK // res.statusCode = 200 // res.json({ name: \u0026#39;John Doe\u0026#39;}) } あとは、Next.js サーバーを起動した状態で、/api/hello というエンドポイントにアクセスすると、次のような JSON データを取得できます。 {\u0026#34;name\u0026#34;:\u0026#34;John Doe\u0026#34;} API 機能は次のような用途に使用することができます。 フォームに入力された値が POST されたときにサーバーサイドで DB に保存する 3rd パーティ製の Web API の呼び出しを中継する このような機能を実装するには、データベースのパスワードや、3rd パーティ製 Web API のアクセスキーなどが必要になりますが、そういった情報は Next.js サーバ側の環境変数などに保存しておくことができます。 そうすれば、API の実装コードから process.env.XXX_ACCESS_KEY のように参照できます。 pages/api ディレクトリ以下の実装内容が、クライアントに見られてしまうことはありません。 参考: Next.js で環境変数を扱う (.env, NEXT_PUBLIC, NODE_ENV) API のコードは Next.js サーバー上で実行されるため、この API 機能を使用するには、Web サイトのホスティング時に Next.js サーバー (next start) が必要です。 必然的に、Vercel のサービス などを使ってホスティングすることになるため、静的サーバー用の HTML ファイル群を生成する next exports コマンドは実行できなくなります（pages/api 以下にファイルを作成すると、next build までしか成功しなくなります）。 クエリパラメーターに対応する 例えば、ゲームの情報を取得する API として /api/games というエンドポイントを定義するとします。 パラメーターとして 1 などのゲーム ID を指定する場合、次のような 2 通りの指定方法が考えられます。 /api/games/1 （REST 形式の URL にする） /api/games?id=1 （クエリ文字列を付加する） 以下、それぞれの実装方法を説明します。 REST 形式 /api/games/1 という REST API 風の URL でアクセスしたいときは、通常のページコンポーネントと同様のダイナミックルーティングの機能を使って API を実装します。 例えば、/api/games/1 や /api/games/2 のような URL をハンドルするには、pages/api/games/[id].ts というファイルを作成します。 id 部分に指定されたパラメーターの値は、ハンドラー関数に渡される NextApiRequest オブジェクトを使って、req.query.id のように参照することができます。 pages/api/games/[id].ts import type { NextApiRequest, NextApiResponse } from \u0026#39;next\u0026#39; export type Game = { id: string title: string genre: string } // API のレスポンス型 export type GamesApiResponse = { game?: Game debugMessage?: string } // API のエントリポイント export default function gamesApi( req: NextApiRequest, res: NextApiResponse\u0026lt;GamesApiResponse\u0026gt; ): void { const id = req.query.id as string const game = fetchGameData(id) if (game) { res.status(200).json({ game }) } else { res.status(400).json({ debugMessage: `Game [id=${id}] not found` }) } } // 擬似的なデータフェッチ関数 function fetchGameData(id: string): Game | undefined { const games: Game[] = [ { id: \u0026#39;1\u0026#39;, title: \u0026#39;ドンキーコング\u0026#39;, genre: \u0026#39;アクション\u0026#39; }, { id: \u0026#39;2\u0026#39;, title: \u0026#39;ゼビウス\u0026#39;, genre: \u0026#39;シューティング\u0026#39; }, { id: \u0026#39;3\u0026#39;, title: \u0026#39;ロードランナー\u0026#39;, genre: \u0026#39;パズル\u0026#39; }, ] return games.find((game) =\u0026gt; game.id === id) } 例えば、/api/games/3 というアドレスでアクセスすると、次のような JSON データが返されます。 {\u0026#34;game\u0026#34;:{\u0026#34;id\u0026#34;:\u0026#34;3\u0026#34;,\u0026#34;title\u0026#34;:\u0026#34;ロードランナー\u0026#34;,\u0026#34;genre\u0026#34;:\u0026#34;パズル\u0026#34;}} 参考リンク ページコンポーネントにおけるダイナミックルーティング クエリ文字列形式 /api/games?id=1 といったクエリ文字列の形で指定されたパラメータ (?id=1) を取得するには、API を実装するファイルを、pages/api/games.ts あるいは pages/api/games/index.ts という名前で作成します。 パラメーターの参照方法は前述の方法と同じで、req.query.id のように参照できます。 games/api/games.ts // ...実装方法はまったく同じ... export default function gamesApi( req: NextApiRequest, res: NextApiResponse\u0026lt;GamesApiResponse\u0026gt; ): void { const id = req.query.id as string const game = fetchGameData(id) if (game) { res.status(200).json({ game }) } else { res.status(400).json({ debugMessage: `Game [id=${id}] not found` }) } } 例えば、/api/games?id=2 というアドレスでアクセスすると、次のような JSON データが返されます。 {\u0026#34;game\u0026#34;:{\u0026#34;id\u0026#34;:\u0026#34;2\u0026#34;,\u0026#34;title\u0026#34;:\u0026#34;ゼビウス\u0026#34;,\u0026#34;genre\u0026#34;:\u0026#34;シューティング\u0026#34;}} どちらの形式を使うべきか？ どちらでもよいですが、パラメーターが 1 つの場合は REST 形式 (pages/api/games/[id].ts) で定義するとシンプルです。 API を呼び出すときに、いちいち id のようなパラメーター名を指定する必要がありません（呼び出し例: /api/games/1）。 逆にパラメーターを複数指定する可能性があって、その指定順序に制約がない場合は、クエリ文字列を使った形式 (pages/api/games.tsx) で定義するのがよいと思います。 呼び出し時にキー＆バリューの形でパラメーターを指定するので、間違った値を指定してしまうミスが減ります（呼び出し例: /api/games?genre=ACT\u0026amp;year=1990）。 React コンポーネントから API を呼び出す 上記のように定義した API を React コンポーネントの実装から呼び出すには、useSWR フックを使用するのが簡単です。 このフックは Vercel が swr パッケージとして提供しています。 swr パッケージのインストール ### yarn の場合 $ yarn add swr ### npm の場合 $ npm install swr 先に、Game インタフェースを共有できるように、ライブラリファイルとして抽出しておきます。 libs/types.ts export type Game = { id: string title: string genre: string } 次のコンポーネントでは、クライアントサイド JavaScript で /api/games/1 というエンドポイントの API を呼び出しています。 useSWR フックの型パラメーターとして Game を指定することで、戻り値の data 変数の型が Game | undefined になります（データ取得が完了するまで undefined になる）。 pages/home.tsx import { NextPage } from \u0026#39;next\u0026#39; import useSWR from \u0026#39;swr\u0026#39; import type { GamesApiResponse } from \u0026#39;../api/games/[id]\u0026#39; const HomePage: NextPage = () =\u0026gt; { const { data, error } = useSWR\u0026lt;GamesApiResponse, Error\u0026gt;(\u0026#39;/api/games/1\u0026#39;, fetcher) if (error) return \u0026lt;p\u0026gt;Error: {error.message}\u0026lt;/p\u0026gt; if (!data) return \u0026lt;p\u0026gt;Loading...\u0026lt;/p\u0026gt; return ( \u0026lt;\u0026gt; {data.game \u0026amp;\u0026amp; \u0026lt;b\u0026gt;{data.game.title}\u0026lt;/b\u0026gt;} {data.debugMessage} \u0026lt;/\u0026gt; ) } export default HomePage const fetcher = (url: string) =\u0026gt; fetch(url).then((r) =\u0026gt; r.json())"
},
{
url: "/p/rdr4fq2/",
title: "Next.js で各ページの head 要素をカスタマイズする (next/head)",
date: "2021-05-04T00:00:00Z",
body: "Next.js で各ページの head 要素をカスタマイズする (next/head) Next.js で各ページの head 要素をカスタマイズしたいときは、Next.js の Head コンポーネント を使用して、必要な値のみを設定していきます。 典型的なのは、次のような title 要素の設定です。 // import Head from \u0026#39;next/head\u0026#39; \u0026lt;Head\u0026gt; \u0026lt;title\u0026gt;Page Title\u0026lt;/title\u0026gt; \u0026lt;/Head\u0026gt; ちなみに、head 要素ではなく、html 要素の属性値などを設定したいときは、pages/_document.tsx ファイルを作成します。"
},
{
url: "/p/iv4agnt/",
title: "Next.js のプリレンダリング機能を使用する (getStaticProps)",
date: "2021-05-04T00:00:00Z",
body: "Next.js のプリレンダリング機能を使用する (getStaticProps) Pre-rendering とは ブログの記事一覧ページなどを生成する場合、なんらかの API で取得した値をもとにページのコンテンツを生成する必要があります。 例えば、次のように取得した値を使ってページを生成することになります。 Web API で取得した値 データベースのクエリ結果 ローカルファイルの内容や、ファイルの一覧情報 Next.js には、Web サイトのビルド時や、Web サーバーへのアクセス時にこういった API を呼び出して、HTML コンテンツを生成する Pre-rendering 機能が備わっています。 Pre-rendering 機能は次の 2 種類があり、どちらか一方を使うこともできますし、両方を組み合わせて使うこともできます。 SSG: Static Generation（静的サイトジェネレーション） Web サイトのビルド時に HTML ファイルを生成します。Web サーバーは静的な HTML ファイルを返すだけでよいので、パフォーマンスが非常に高くなります。すべてのページを事前に列挙できるのであれば、できるだけこの SSG を使って静的に HTML 生成してしまうことが推奨されています。静的な HTML ファイルをホスト可能なサーバー（GitHub Pages など）があれば、Web サイトを公開できます。 SSR: Server-side Rendering（サーバーサイドレンダリング） クライアントが Web サーバーにアクセスしたときに、サーバーサイドで動的に HTML を生成します。この仕組みを使うと、日々増減するデータを扱いやすくなりますが、Web サーバーとして Next.js サーバーを稼働させておく必要があります。感覚的には、PHP サーバーなどが動作しているイメージに近いです。 ちなみに、純粋に React.js のみを使用した場合とはどう違うのでしょうか？ React.js 自体には Pre-rendering 機能は備わっておらず、主に SPA (Single Page Application) を作成するライブラリとして使用されています。 React.js のみを使って上記の例のような記事一覧ページを生成する場合、Web ブラウザ上で JavaScript を実行してコンテンツを動的に生成する必要があります。 これを SSG や SSR と区別するために、CSR: Client-side rendering（クライアントサイドレンダリング） と呼びます。 CSR \u0026hellip; Web ブラウザ上の JavaScript API のみ呼び出せる（React.js のみを使った場合） SSG/SSR \u0026hellip; Node.js 環境の JavaScript API を呼び出せる（Next.js を使った場合） つまり、Next.js を使うと、より柔軟な方法でコンテンツを事前生成することが可能になります。 ☝️ 静的サイトジェネレーターとの違いは？ Hugo などの Static Site Generator（静的サイトジェネレーター）は、そのビルドコマンド自体が、上記の SSG (Static Generation) に対応する Pre-rendering 機能を提供しています。 Next.js を使うと、Hugo に組み込まれている Static Generation 部分（.md から .html への変換部分）を自由に実装できるのだと考えるとわかりやすいかもしれません。 Pre-rendering 機能を使用する Pre-rendering 用の関数 Next.js が提供する Pre-rendering 機能のひとつである静的サイトジェネレーション (SSG: Static Generation) を使用すると、Web サイトのビルド時（next build 実行時）に、外部 API などを利用して HTML を事前生成することができます。 SSG 機能を利用するには、各ページコンポーネントの実装ファイルで、次のような名前の async 関数を実装して export します。 getStaticProps 関数 (SSG) Web サイトのビルド時にこの関数が呼び出されるので、そのページのレンダリングに使用するデータを返すように実装します。戻り値として返したオブジェクトの props プロパティの値が、ページコンポーネントの引数（通称 props）として渡されます。 getStaticPaths 関数 (SSG) ダイナミックルーティングを使用するとき、事前生成するページのリストを返すよう実装します。詳しくは、ダイナミックルーティングの記事 で説明します。 一方、完全にサーバーサイドで HTML を生成するサーバーサイドレンダリング (SSR: Server-side Rendering) の仕組みを使いたい場合は、上記の代わりに getServerSideProps 関数を実装します。 getServerSideProps 関数 (SSR) Web サイトへのアクセス時にこの関数が呼び出されるので、そのページのレンダリングに使用するデータを返すように実装します。詳しくは、ダイナミックルーティングの記事 で説明します。 ちょっとややこしいですが、Next.js では、SSG も SSR も Pre-rendering の一種として分類されています。 Pre-rendering というのは、あくまでサーバーサイド（ビルド時含む）でページの内容を構築することを示しています。 Pre-rendering じゃないのは、CSR: Client-side Rendering のみです。 Pre-rendering の実装例 例として、ローカルファイルや、データベースなどに格納された「本の一覧」を表示する books インデックスページを考えてみます。 こういった インデックスページ を Web サイトのビルド時に生成するには、getStaticProps 関数を実装して、戻り値の props プロパティで一覧情報を返すように実装します。 props プロパティの値はページコンポーネントの引数として渡されるため、その値を参照して「本の一覧」を表示することができます。 下記のサンプルコードでは、props プロパティの型を Props として定義しています。 pages/books/index.tsx import Link from \u0026#39;next/link\u0026#39; import React from \u0026#39;react\u0026#39; import { GetStaticProps } from \u0026#39;next\u0026#39; type Book = { id: string; title: string; } // ページコンポーネントに渡されるデータ type Props = { books: Book[]; } // この関数がビルド時に呼び出され、戻り値の props の値がページコンポーネントに渡される export const getStaticProps: GetStaticProps\u0026lt;Props\u0026gt; = async context =\u0026gt; { // 本来は、ここで外部 API などを呼び出してデータを取得する const books = [ { id: \u0026#39;001\u0026#39;, title: \u0026#39;Title-1\u0026#39; }, { id: \u0026#39;002\u0026#39;, title: \u0026#39;Title-2\u0026#39; }, { id: \u0026#39;003\u0026#39;, title: \u0026#39;Title-3\u0026#39; } ] // この props プロパティの値がページコンポーネントに渡される return { props: { books } } } // ページコンポーネントの実装 const BooksPage: React.FC\u0026lt;Props\u0026gt; = ({ books }) =\u0026gt; ( \u0026lt;\u0026gt; \u0026lt;h2\u0026gt;Book list\u0026lt;/h2\u0026gt; \u0026lt;ul\u0026gt; {books.map(book =\u0026gt; ( \u0026lt;li key={book.id}\u0026gt; \u0026lt;Link href={`/books/${book.id}`}\u0026gt;\u0026lt;a\u0026gt;{book.title}\u0026lt;/a\u0026gt;\u0026lt;/Link\u0026gt; \u0026lt;/li\u0026gt; ))} \u0026lt;/ul\u0026gt; \u0026lt;/\u0026gt; ) export default BooksPage getStaticProps 関数は Node.js 環境で実行されるため、ローカルファイルへのアクセスや、外部 API の呼び出しなどを自由に行うことができます。 つまり、データソースとして、ローカルの YAML ファイルや CSV ファイル、Web API で取得したデータなど、どのようなデータでも扱うことができます。 getStaticProps は、ページコンポーネントの実装ファイル (pages/**.tsx) の中でしか定義できないことに注意してください。 個別ページの Pre-rendering 上記の実装例では、「本の一覧」を表示するインデックスページを Pre-rendering する方法を示しました。 そこに表示された各アイテムには次のような URL のリンクが張られており、個々の本の詳細情報にジャンプできるようになっています。 /books/001 /books/002 /books/003 これらのページを、pages/books/001.tsx や pages/books/002.tsx のようなファイルで、ひとつずつページコンポーネントとして実装していくのは大変です。 Next.js は、上記のような URL によるアクセスを 1 つのページコンポーネント (pages/books/[id].tsx) でハンドルする ダイナミックルーティング という仕組みを提供しています。 参考リンク Next.js のダイナミックルーティング機能を利用する (getStaticPaths, getStaticProps, getServerSideProps)"
},
{
url: "/p/h7arpdj/",
title: "AWS CloudFormation 入門 (Hello World)",
date: "2021-04-01T00:00:00Z",
body: "AWS CloudFormation 入門 (Hello World) CloudFormation とは AWS CloudFormation を使用すると、テンプレートファイル (YAML or JSON) で定義した AWS リソース群をまとめて生成（更新）することができます。 いわゆる IaC (Infrastructure as Code) 環境を提供するものであり、Ansible や Chef を使ったことがあれば、それの AWS リソース構築用だと考えると分かりやすいです。 テンプレートから生成されるインフラ（AWS リソース群）は スタック と呼ばれ、テンプレートがあればスタックは何度でも生成することができます。 これはオブジェクト指向プログラミングにおける、クラスとインスタンスの関係に似ています。 必要のなくなったリソース群は、スタック単位でまとめて削除することができます。 CloudFormation の主な特徴は次の通りです。 何度でも同じ構成でリソースをセットアップできる（他のリージョンに複製したり、一時的に使うインフラを自動生成できる） テンプレートはテキストファイル (YAML/JSON) なので、GitHub などでバージョン管理することができ、PullRequest ベースのコードレビューを行える 冪等性が考慮されており、テンプレートには最終的な結果だけを定義しておけばよい（構成のアップデート時に差分を意識する必要はない） 例えば、次のようなテンプレートを使用すると、S3 サービスのバケットリソースを自動で作成することができます。 template.yml AWSTemplateFormatVersion:\u0026#34;2010-09-09\u0026#34;Resources:HelloBucket:Type:AWS::S3::Bucket 必須のルートプロパティは Resources だけですが、テンプレートフォーマットのバージョンを示す AWSTemplateFormatVersion は最低限指定しておくのがよいでしょう（2021年時点で、2010-09-09 が最新バージョンです）。 CloudFormation コンソールからスタックを生成する CloudFormation マネージメントコンソール を使うと、Web サイト上でスタックを生成することができます。 CloudFormation マネージメントコンソールを使ったスタックの生成手順は以下の通りです。 サイドバーから Stacks（スタック）を選択する CloudFormation で管理されているスタックの一覧が表示されます。 （スタックの作成）ボタンを押す テンプレートを指定する S3 上に置いたファイルを指定することもできますが、ここではローカルに作成した YAML ファイルをアップロードします。そのためには、Template is ready（テンプレートの準備完了） → Upload a template file（テンプレートファイルのアップロード）を選択し、YAML ファイルを選択します。 任意のスタック名（mystack など）を入力します テンプレートファイル内にパラメータ (Parameters) を定義している場合は、ここで具体的な値を入力できます。 あとはそのまま進めていって、Create stack（スタックの作成）を押せば、スタックの生成処理が始まります。 スタックの一覧画面に戻ると、作成中のスタックのステータスが CREATE_IN_PROGRESS となって表示されます。 しばらくしてスタックの生成処理が完了すると、ステータスが CREATE_COMPLETE に変わります。 これで、テンプレートで定義した AWS リソース群が使用できる状態になります。 ちなみに、スタック内に作成される S3 バケットには、一意な物理 ID (Physical ID) が自動的に割り当てられるため、テンプレート内での論理 ID (Logical ID) はシンプルに保つことができます（この例では HelloBucket）。 Logical ID: HelloBucket（テンプレートファイル内で付けた名前） Physical ID: mystack-hellobucket-npd68k1m8ut8a（CloudFormation が自動生成した ID） AWS CLI を使ってスタックを生成する AWS CLI のセットアップ が完了していれば、Web ブラウザを使わず、コマンドラインから CloudFormation のスタックを生成することができます。 例えば、カレントディレクトリにある template.yml を使ってスタック mystack を生成するには次のようにします。 $ aws cloudformation create-stack \\ --stack-name mystack --template-body file://template.yml 作成されたスタックの情報は次のように確認できます。 $ aws cloudformation describe-stacks --stack-name mystack 必要のないスタックは次のように削除します。 $ aws cloudformation delete-stack --stack-name mystack 参考リンク AWS CloudFormation をコマンドライン (CLI) で操作する"
},
{
url: "/p/4ju5eow/",
title: "AWS S3 をコマンドライン (CLI) で操作する",
date: "2021-02-16T00:00:00Z",
body: "AWS S3 をコマンドライン (CLI) で操作する AWS CLI で S3 バケットの操作を行う場合、大きく分けて以下の 2 種類のコマンドがあります。 aws s3 \u0026hellip; 高レベルコマンド aws s3api \u0026hellip; API レベルコマンド 基本的には、aws s3 コマンドでカバーできない操作が出てきたときに aws s3api コマンドの方を調べてみるというやり方でいいと思います。 aws s3 コマンドの方は、OS のコマンドラインシェルのファイル操作コマンドのような体系になっています（aws s3 ls とか aws s3 rm とか）。 S3 バケットの操作を行うには、IAM ユーザーに適切な権限が割り当てられている必要がありますが、AmazonS3FulAccess 管理ポリシーがあればほとんどの操作が可能です。 S3 バケットを作成する (s3 mb) $ aws s3 mb s3://\u0026lt;バケット名\u0026gt; 実行例 $ aws s3 mb s3://makutemp-123456789012-bucket-1 make_bucket: makutemp-123456789012-bucket-1 ☝️ 同名バケットの再生成でエラー バケットの削除後に、同名のバケットを再生成しようとすると、次のような conflicting conditional operation のエラーになることがあります。 この場合は、バケットの削除処理が完了するまでしばらく待つ必要があります。 make_bucket failed: s3://makutemp-123456789012-bucket-1 An error occurred (OperationAborted) when calling the CreateBucket operation: A conflicting conditional operation is currently in progress against this resource. Please try again. このような待ち時間を防ぐためには、s3 rb でバケットを削除した後で再生成するのではなく、s3 rm --recursive でバケット内のオブジェクトだけをすべて削除します。 S3 バケットの作成先リージョンを明示するには、--region オプションを使用します。 例: 日本のリージョンを指定 $ aws s3 mb s3://makutemp-123456789012-bucket-1 --region ap-northeast-1 参考: S3 バケットのリージョンを確認する S3 バケットの一覧、オブジェクトの一覧を表示する (s3 ls) S3 バケットの一覧を取得 $ aws s3 ls 実行例 $ aws s3 ls 2021-02-18 04:43:42 makutemp-123456789012-bucket-1 2021-02-19 05:14:48 makutemp-123456789012-bucket-2 2021-02-20 19:32:05 makutemp-123456789012-bucket-3 バケットに含まれるオブジェクトの一覧を取得 $ aws s3 ls s3://\u0026lt;バケット名\u0026gt; 例: バケット内のファイルを取得 $ aws s3 ls s3://makutemp-123456789012-bucket-1 2021-03-03 21:13:55 213 sample1.txt 2021-03-03 21:14:30 593 sample2.txt 2021-03-03 21:15:13 477 sample3.txt 例: 指定したディレクトリ内のファイルを取得 $ aws s3 ls s3://makutemp-123456789012-bucket-1/dir/ 2021-03-03 19:13:55 53 hoge1.txt 2021-03-03 19:14:30 37 hoge2.txt ディレクトリ名まで指定する場合は、dir/ のように最後のスラッシュが必要です。 これを付けないと、dir というファイルを探してしまいます。 例: 深いディレクトリのファイルまですべて取得 $ aws s3 ls s3://makutemp-123456789012-bucket-1 --recursive 2021-03-03 19:13:55 53 dir/hoge1.txt 2021-03-03 19:14:30 37 dir/hoge2.txt 2021-03-03 21:13:55 213 sample1.txt 2021-03-03 21:14:30 593 sample2.txt 2021-03-03 21:15:13 477 sample3.txt オブジェクトをコピーする (s3 copy) $ aws s3 cp \u0026lt;source\u0026gt; \u0026lt;target\u0026gt; [--options] s3 copy (cp) コマンドでは、ローカルファイルのバケットへの転送、バケットからのダウンロード、バケット内でのコピーなどを行うことができます。 ローカル → S3 バケット 例: ローカルの sample.txt を my-bucket バケットにアップロード $ aws s3 cp sample.txt s3://my-bucket 例: ローカルの data ディレクトリ内のファイルを my-bucket バケットにアップロード $ aws s3 cp data s3://my-bucket --recursive S3 バケットの方にも data ディレクトリを作りたければ、ターゲットを明示的に s3://my-bucket/data とする必要があります。 更新されたファイルだけを効率的にアップロードしたいときは、s3 sync コマンドを使ってください。 S3 バケット → ローカル 例: my-bucket バケット内のファイルをローカルの out ディレクトリにダウンロード $ aws s3 cp s3://my-bucket/sample.txt out 例: my-bucket バケット内の全てのファイルを再帰的にローカルの out ディレクトリにダウンロード $ aws s3 cp s3://my-bucket out --recursive S3 バケット → S3 バケット 例: bucket-1 バケット内のファイルを bucket-2 バケットにコピー $ aws s3 cp s3://bucket-1/sample.txt s3://bucket-2 例: bucket-1 バケット内のファイルを bucket-2 バケットの dir/ 以下にコピー $ aws s3 cp s3://bucket-1/sample.txt s3://bucket-2/dir/ 例: bucket-1 バケット内のすべてのファイルを bucket-2 バケットにコピー $ aws s3 cp s3://bucket-1 s3://bucket-2 --recursive ディレクトリの内容を同期する (s3 sync) $ aws s3 sync \u0026lt;LocalDir\u0026gt; \u0026lt;S3Uri\u0026gt; $ aws s3 sync \u0026lt;S3Uri\u0026gt; \u0026lt;LocalDir\u0026gt; $ aws s3 sync \u0026lt;S3Uri\u0026gt; \u0026lt;S3Uri\u0026gt; s3 sync コマンドは、2 回目以降の実行では更新されたファイルのみを転送します。 似たようなコマンドに s3 cp --recursive がありますが、すでに存在するファイルもすべて転送してしまうので効率が悪いです。 例: ローカルディレクトリ → S3 バケット $ aws s3 sync photos s3://mybucket/photos $ aws s3 sync photos s3://mybucket/photos --delete --delete オプションを付けると、同期元に存在しないファイルを同期先から削除します。 例: S3 バケット → ローカルディレクトリ $ aws s3 sync s3://mybucket/photos photos $ aws s3 sync s3://mybucket/photos photos --delete 例: 同期対象外にするファイルのパターンを指定 $ aws s3 sync . s3://mybucket/myapp --exclude \u0026#34;*.zip\u0026#34; $ aws s3 sync . s3://mybucket/myapp --exclude \u0026#34;*node_modules/*\u0026#34; --exclude \u0026#34;*test/*\u0026#34; 注意点としては、深い階層にあるファイルにマッチさせるためには、*hello.txt のように先頭に * を付ける必要があるというところです。 つまり、ほとんどのケースでは * プレフィックスを付ける必要があります。 あと、*/hello.txt のようなスラッシュ付きのプレフィックスを付けてしまうと、最上位にあるファイルにマッチしなくなってしまうようです。 ちょっと使いにくいコマンド仕様ですね。。。 オブジェクトを削除する (s3 rm) $ aws s3 rm s3://\u0026lt;バケット名\u0026gt;/\u0026lt;オブジェクト名\u0026gt; 例: バケット内のファイルを 1 つ削除 $ aws s3 rm s3://my-bucket/sample1.txt 例: ディレクトリ以下をすべて削除 $ aws s3 rm s3://my-bucket/dir/ --recursive 例: バケット内のファイルをすべて削除（バケットを空にする） $ aws s3 rm s3://my-bucket --recursive バケットのバージョニングが有効になっている場合は、バケットの中身を空にすることはできません。 バケットを削除する バージョニング設定が無効であれば、下記のコマンドでバケットを削除することができます。 $ aws s3 rb s3://\u0026lt;バケット名\u0026gt; ただし、空ではないバケット（オブジェクトを含むバケット）を削除しようとすると、BucketNotEmpty というエラーが発生します。 例: バケット削除エラー $ aws s3 rb s3://my-bucket remove_bucket failed: s3://my-bucket An error occurred (BucketNotEmpty) when calling the DeleteBucket operation: The bucket you tried to delete is not empty 含まれているオブジェクトもすべて削除してしまってよい場合は、バケット削除時に --force オプションを使用します。 S3 Glacier ストレージクラスに移行済みのオブジェクトも含めて、オブジェクトがすべて削除されます。 例: 中のオブジェクトを含めてバケットを削除 $ aws s3 rb s3://my-bucket --force バケットのタグ関連の操作 バケットのタグを取得する (s3api get-bucket-tagging) $ aws s3api get-bucket-tagging --bucket \u0026lt;バケット名\u0026gt; 実行例 $ aws s3api get-bucket-tagging --bucket bucket-123456789012-hello TagSet: - Key: DeploySlot Value: prod - Key: Department Value: Marketing - Key: CostCenter Value: 1234ABCD バケットにタグを設定する (s3api put-bucket-tagging) $ aws s3api put-bucket-tagging --bucket \u0026lt;バケット名\u0026gt; --tagging=\u0026lt;タグセット\u0026gt; 次の例では、2 つのタグを S3 バケットにセットしています。 既存のタグは上書きされてしまうことに注意してください。 実行例 $ aws s3api put-bucket-tagging --bucket bucket-123456789012-hello --tagging \u0026#34;TagSet=[{Key=key1,Value=val1},{Key=key2,Value=val2}]\u0026#34; JSON ファイルでタグの内容を記述しておいて、それを --tagging オプションで渡すこともできます。 実行例 $ aws s3api put-bucket-tagging --bucket bucket-123456789012-hello \\ --tagging file://tagging.json tagging.json { \u0026#34;TagSet\u0026#34;: [ {\u0026#34;Key\u0026#34;: \u0026#34;key1\u0026#34;, \u0026#34;Value\u0026#34;: \u0026#34;val1\u0026#34;}, {\u0026#34;Key\u0026#34;: \u0026#34;key2\u0026#34;, \u0026#34;Value\u0026#34;: \u0026#34;val2\u0026#34;}, {\u0026#34;Key\u0026#34;: \u0026#34;key3\u0026#34;, \u0026#34;Value\u0026#34;: \u0026#34;val3\u0026#34;} ] } バケットのバージョニング (s3api put-bucket-versioning) バケットのバージョニングを有効にすると、S3 バケットに同名のキーでファイルをアップロードしたときに、過去のバージョンが残るようになります。 具体的には、バージョニング有効時にファイルをアップロードすると、そのオブジェクトに一意の バージョン ID が割り当てられて、過去のファイルと区別できるようになります。 バージョニング無効時にアップロードされたファイルのバージョン ID は null になります。 キー バージョン ID 説明 hello.txt 8PqtjVIxmjtn_aJ3aVxAJHVxOWNdWlXk 3 回目のアップロード（バージョニング有効時） hello.txt 2vE4HOEHRPPd5hSqAazAHQczmQnmmlQ7 2 回目のアップロード（バージョニング有効時） hello.txt null 1 回目のアップロード（バージョニング無効時） 例: バージョニングを有効にする $ aws s3api put-bucket-versioning --bucket mybucket \\ --versioning-configuration Status=Enabled 例: バージョニングを無効にする $ aws s3api put-bucket-versioning --bucket mybucket \\ --versioning-configuration Status=Suspended バージョニングを無効に切り替えても、バージョニング有効時にアップロードしたファイル群が消えることはありません。 新しくアップロードされるファイルのバージョン ID が null になるだけです。 このとき、バージョン ID が null のオブジェクトが既に存在する場合は上書きされます（過去にバージョニング無効時にアップロードしたものがある場合）。 各バージョンのファイルは、S3 のマネージメントコンソールから個別に削除することができます。 バケットのリージョンを確認する (s3api get-bucket-location) S3 バケットがどのリージョンに作成されているかを調べるには以下のようにします。 $ aws s3api get-bucket-location --bucket \u0026lt;バケット名\u0026gt; 実行例 $ aws s3api get-bucket-location --bucket makutemp-123456789012-bucket-1 LocationConstraint: ap-northeast-1 このコマンドでは、バケット名に s3:// プレフィックスは付けてはいけないことに注意してください。 バケット名やバケットの ARN を指定します。 出力のフォーマットは、設定によって JSON 形式だったり YAML 形式だったりします。 上記の例は、YAML 形式です。"
},
{
url: "/p/j5iu7it/",
title: "AWS の初期設定: AWS CLI と認証情報の設定",
date: "2021-02-07T00:00:00Z",
body: "AWS の初期設定: AWS CLI と認証情報の設定 AWS CLI とは？ AWS CLI (Command Line Interface) を使うと、AWS の各種サービスをコマンドラインから操作することができます。 例えば、次のように様々な処理を実行できます。 S3 にファイルをコピーする $ aws s3 cp ローカルファイル s3://バケット名/ディレクトリ名 IAM ユーザーのアクセスキーを表示する $ aws iam list-access-keys --user-name=ユーザー名 DynamoDB にテーブルを作成する $ aws dynamodb create-table --table-name テーブル名 ... AWS の各種サービスの設定は、それぞれのマネージメントコンソール（Web サイト）上で設定することができますが、AWS CLI を使うことで、Web ブラウザを開かずに設定を済ませられます。 頻繁に行う処理などは、シェルスクリプトなどにして自動化することができます。 AWS CLI を使用するには、下記のような IAM ユーザーのアクセスキー（及びシークレットアクセスキー）が必要です。 以降の説明では、これらの情報が取得できていることを前提とします。 API 用アクセスキー（例）: INMCAKIAQX77PNSXQAGP API 用シークレットアクセスキー（例）: 2ufOA3Q2KAmpNTo2GHPDXFJK7Jiv9yfZGegIdbCW 参考リンク IAM ユーザーのアクセスキーを作成するには - AWS CLI AWS CLI のインストール インストール方法 macOS の場合 \u0026hellip; AWSCLIV2.pkg をダウンロードしてインストールできます。 Windows の場合 \u0026hellip; AWSCLIV2.msi をダウンロードしてインストールできます。 Linux の場合 \u0026hellip; curl コマンドでインストール用スクリプトをダウンロードしてインストールできます。 インストール後の確認 何らかの aws コマンドが実行できるようになっていれば成功です。 $ aws --version aws-cli/2.1.24 Python/3.7.4 Darwin/19.5.0 exe/x86_64 prompt/off AWS CLI の設定 (aws configure) 設定ファイルを作成する AWS CLI を使用して AWS の各種操作を行うには、credentials ファイルにアカウントキー情報を設定しておく必要があります。 aws congigure コマンドで設定を行えます。 $ aws configure AWS Access Key ID [None]: INMCAKIAQX77PNSXQAGP AWS Secret Access Key [None]: 2ufOA3Q2KAmpNTo2GHPDXFJK7Jiv9yfZGegIdbCW Default region name [None]: ap-northeast-1 Default output format [None]: yaml デフォルトリージョンは、AWS CLI でコマンド実行したときに、どのリージョンのサーバーにリクエストが送信されるかの設定です。 通常は、最寄りのリージョン（東京であれば ap-northeast-1）を指定しておけば大丈夫です（リージョンの一覧はこちら）。 リージョンの指定は、aws コマンドを実行する際に --region オプションで指定することも可能です。 AWS CLI の出力フォーマットは、yaml や json、table、text などを指定できます。 人間にも機械にもやさしい yaml 形式がおすすめです（yaml 形式は CLI バージョン 2 から選択できます）。 設定が完了すると、~/.aws ディレクトリ以下に次のようなファイルとして保存されます。 ~/.aws/config [default] region = ap-northeast-1 output = yaml ~/.aws/credentials [default] aws_access_key_id = INMCAKIAQX77PNSXQAGP aws_secret_access_key = 2ufOA3Q2KAmpNTo2GHPDXFJK7Jiv9yfZGegIdbCW 設定を変更したいときは、上記のファイルを直接変更してもいいですし、もう一度 aws configure コマンドを実行しても OK です。 設定の一部を変更する $ aws configure AWS Access Key ID [****************QAGP]: AWS Secret Access Key [****************dbCW]: Default region name [ap-northeast-1]: Default output format [yaml]: json 現在の設定を確認する aws configure list コマンドで AWS CLI の現在の設定を確認することができます。 $ aws configure list Name Value Type Location ---- ----- ---- -------- profile \u0026lt;not set\u0026gt; None None access_key ****************QAGP shared-credentials-file secret_key ****************dbCW shared-credentials-file region ap-northeast-1 config-file ~/.aws/config 個々の値を取得したいときは aws configure get コマンドを使用します。 $ aws configure get region ap-northeast-1 $ aws configure get aws_access_key_id AKIXXXXXXXXXXXXXQAGP $ aws configure get aws_secret_access_key 8kR6XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXdbCW （応用）別のプロファイルを作成する 別の IAM ユーザーのアクセスキーを使用したい場合などは、別のプロファイル設定を追加することで対応できます。 次の例では、power という名前のプロファイルを作成しています。 $ aws configure --profile=power AWS Access Key ID [None]: XXXXXXXXXXXXXXXXXXXX AWS Secret Access Key [None]: XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX Default region name [None]: ap-northeast-1 Default output format [None]: yaml これにより、設定ファイル内にそのプロファイル用の設定が追加されます。 ~/.aws/config [default] region = ap-northeast-1 output = yaml [profile power] region = ap-northeast-1 output = yaml ~/.aws/credentials [default] aws_access_key_id = INMCAKIAQX77PNSXQAGP aws_secret_access_key = 2ufOA3Q2KAmpNTo2GHPDXFJK7Jiv9yfZGegIdbCW [power] aws_access_key_id = XXXXXXXXXXXXXXXXXXXX aws_secret_access_key = XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX AWS CLI コマンドを使用するときにプロファイルを切り替えたいときは、aws コマンドの --profile オプションか、AWS_DEFAULT_PROFILE 環境変数でプロファイル名を指定します。 プロファイルを切り替えて AWS CLI を実行 （方法1） $ aws --profile=power configure list （方法2） $ export AWS_DEFAULT_PROFILE=power $ aws configure list"
},
{
url: "/p/sk3rykz/",
title: "GitHub の GraphQL API Explorer の使い方",
date: "2020-09-14T00:00:00Z",
body: "GitHub の GraphQL API Explorer の使い方 GraphQL API Expolorer とは GitHub の GraphQL API (API ver.4) を使用すると、GitHub で管理されているリポジトリの情報やユーザーの情報などを、柔軟な GraphQL クエリを使って取得することができます。 しかし、いろいろなクエリ方法が用意されていて、実際にどのような情報が取得できるのかが分かりにくかったりします。 そんなとき便利なのが、GitHub が Web サイトとして用意してくれている、GraphQL API Explorer です。 GraphQL API Explorer | GitHub Developer Guide GraphQL API Explorer を使用すると、GraphQL API を使ってどのような情報を取得できるのか、実際にクエリを実行して確かめることができます。 GitHub アカウントでサインインした状態であれば、プライベートリポジトリの情報も取得することができます。 GitHub GraphQL API を利用するアプリケーションを作成するときは、このサイトでどのようなクエリを発行すればよいのかを調べながら作っていくことになると思います。 クエリエディタでは、下記のようなショートカットキーを使用することができます。 Ctrl + Space \u0026hellip; 入力補完 Ctrl + Enter \u0026hellip; 実行 History 機能と Explorer 機能 History ボタンを押すと、過去に実行したクエリをロードすることができます。 クエリに次のように名前を付けておくと、History にその名前が表示されるので、後ほど再利用する予定があれば、わかりやすい名前を付けておくとよいでしょう。 queryGetApolloRepo{repository(owner:\u0026#34;apollographql\u0026#34;,name:\u0026#34;apollo-client\u0026#34;){owner{loginurl}nameurl}} Explorer ボタンを押すと、スキーマ定義に基づいて、入力可能なフィールドをツリー形式で参照することができます（これを使うより、Ctrl + Space による補完の方が便利ですが）。 クエリのパラメータ化 (QUERY VARIABLES) クエリ文字列の中で、実行のたびに変化させたい部分は変数にしておくと便利です。 次の例では、クエリ実行時に $owner と $name パラメーターを受け取るように定義しています。 String! は、省略できない文字列型パラメーターであることを示しています。 queryGetRepo($owner:String!,$name:String!){repository(owner:$owner,name:$name){owner{loginurl}nameurl}} このようなパラメーター付きのクエリを実行するときは、QUERY VARIABLES の入力欄で、次のように JSON 形式で変数の値をセットします。 { \u0026#34;owner\u0026#34;: \u0026#34;apollographql\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;apollo-client\u0026#34; } 呼び出し回数制限に注意 (rateLimit) GraphQL Explorer では無制限に API を実行できるわけではありません。 現状は GitHub ユーザーごとに、1 時間あたり 5000 ポイントまでの呼び出しを行えるようになっています。 あるクエリで消費したポイントと残りのポイントは、次のように rateLimit フィールドを指定することで調べることができます。 query{rateLimit{costremaining}...残りはいつも通り記述...} 実行結果 { \u0026#34;data\u0026#34;: { \u0026#34;rateLimit\u0026#34;: { \u0026#34;cost\u0026#34;: 1, \u0026#34;remaining\u0026#34;: 4989 }, ... } } 上記の結果は、今回のクエリ実行に 1 ポイント消費し、残り 4989 ポイント残っていることを示しています。 参考: GitHub GraphQL API の呼び出し回数制限 (rate limit) の情報を取得する"
},
{
url: "/p/3veuap5/",
title: "textlint のインストールと基本的な使い方",
date: "2020-05-20T00:00:00Z",
body: "textlint のインストールと基本的な使い方 textlint とは textlint は、テキストファイルや Markdown ファイル用の記述内容をチェックするための校正ツールです。 textlint · The pluggable linting tool for text and markdown たとえば、「である・ですます調の不一致」、「単語の表記揺れ」、「句読点の使いすぎ」など、様々なルールを定義して文章をチェックすることができます。 多人数で管理する社内ドキュメントはもちろんのこと、個人のブログなどで使用すれば、すべての文章で一定の品質を保つことができるようになります。 textlint のインストール textlint は Node.js のパッケージとして配布されているので、まだインストールされていない場合は先に Node.js をインストールしておく必要があります。 カレントプロジェクト用にインストールする カレントプロジェクト用に textlint をインストールするには、プロジェクト（テキストファイルが入ったディレクトリ）のルートディレクトリに移動し、次のように npm コマンドを実行します。 textlint をインストール $ npm init -y # なければ package.json を作成 $ npm install --save-dev textlint ☝️ ワンポイント この方法でインストールすると、カレントディレクトリの node_modules ディレクトリ以下に、ローカルモジュールとして textlint がインストールされます。 --save-dev (-D) オプションを付けることで、依存パッケージの情報が package.json および pacakge-lock.json ファイルに記録され、他のユーザーが npm install で同じ環境を構築できるようになります。 次のように textlint コマンドを実行できれば成功です。 $ npx textlint -v v11.6.3 ☝️ npx コマンドについて npx コマンドはローカルパッケージを起動するためのユーティリティで、npx textlint は、./node_modules/.bin/textlint のショートカットとして使用できます。 npx コマンドは npm コマンドに付属しているので、別途インストールする必要はありません。 システム全体にインストールする 次のようにして、textlint コマンドをシステム全体にインストールすることもできます。 システム全体にインストール $ npm install --global textlint このようにインストールした場合は、npx プレフィックスなしで直接実行できるようになります。 $ textlint -v v11.6.3 どちらの方法でインストールするか迷ったら、前者の方法でインストールしておきましょう。他の人とファイルを共有したときに環境を合わせやすくなります。 textlint のルール設定 textlint はデフォルトでは何のチェックも有効になっておらず、.textlintrc という設定ファイルでルールを有効化していく必要があります。 使用できるルールは、下記のサイトにまとめられています。 Collection of textlint rule 例として、ここでは、次のようなルールを有効化してみます。 textlint-rule-no-dropping-the-ra \u0026hellip; 「ら抜き言葉」が使われていないかをチェック textlint-rule-no-mix-dearu-desumasu \u0026hellip; 「ですます」調と「である」調の混在をチェック textlint のルールは、本体とは別に Node パッケージとして提供されているので、次のようにインストールします。 textlint のルールをインストール $ npm install --save-dev textlint-rule-no-dropping-the-ra $ npm install --save-dev textlint-rule-no-mix-dearu-desumasu ☝️ ワンポイント グルーバルにインストールした textlint コマンドを使用する場合は、ルールをインストールするときも --global オプションを使ってインストールする必要があります。 あとは、プロジェクトルートに置いた設定ファイルで次のように有効化します（設定ファイルの書き方の詳細はこちら）。 .textlintrc {\u0026#34;rules\u0026#34;: {\u0026#34;no-dropping-the-ra\u0026#34;: true,\u0026#34;no-mix-dearu-desumasu\u0026#34;: true}} 設定ファイル内で指定するルール名には、textlint-rule- というプレフィックスを除いた名前を指定します。 ☝️ ワンポイント インストール済みのルールをすべて有効にした .textlintrc を新しく作成する場合は、 textlint --init コマンドを使用できます。 textlint を実行する ここでは、サンプル文章として次のようなテキストファイルを用意します。 sample.txt 吾輩は猫である。名前はまだないです。 猫は食べれません。 カレントディレクトリ以下のすべての .txt ファイルに対して textlint をかけるには次のようにします。 $ npx textlint \u0026#34;**/*.txt\u0026#34; 実行結果 /Users/maku/sample.txt 1:5 error 本文: \u0026#34;である\u0026#34;調 と \u0026#34;ですます\u0026#34;調 が混在 =\u0026gt; \u0026#34;ですます\u0026#34;調 の文体に、次の \u0026#34;である\u0026#34;調 の箇所があります: \u0026#34;である。\u0026#34; Total: である : 1 ですます: 1 no-mix-dearu-desumasu 2:5 error ら抜き言葉を使用しています。 no-dropping-the-ra ✖ 2 problems (2 errors, 0 warnings) 1 行目に「である」調と「ですます」調が混在しているというエラーと、2 行目に「ら抜き言葉」があるというエラーが出ています。 以上が textlint の基本的な使い方になります。 ここではごく簡単なルールだけを紹介しましたが、他にも WEB+DB PRESS用語統一ルール や、ルール設定をまとめた 技術文書向けのtextlintルールプリセット など、複雑なルールも用意されています。 ただ、既存の文書に複雑なルールをまとめて適用すると、大量にエラーが出て悲しくなるので、少しずつ自分に合ったチェックだけ有効にしていくという使い方がよいかもしれません。 npm のスクリプトとして textlint を実行できるようにする textlint コマンドを頻繁に実行する場合は、次のように package.json ファイルに lint スクリプトとして定義しておくとよいでしょう。 package.json { \u0026#34;name\u0026#34;: \u0026#34;my-site\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;0.0.1\u0026#34;, \u0026#34;scripts\u0026#34;: { \u0026#34;lint\u0026#34;: \u0026#34;textlint \\\u0026#34;content/**/*.md\\\u0026#34;\u0026#34; }, \u0026#34;devDependencies\u0026#34;: { \u0026#34;textlint\u0026#34;: \u0026#34;^11.6.3\u0026#34; } } これで、下記のように textlint を実行できるようになります。 $ npm run lint textlint でキャッシュを有効にする textlint の実行はものすごく遅い（数百ファイルを対象にすると何十秒もかかったりする）ので、 --cache オプションを使いましょう。 $ textlint --cache \u0026#34;content/**/*.md\u0026#34; このように実行すると、カレントディレクトリに .textlintcache というキャッシュファイルが作成されて、次回の実行からは変更されたファイルのみがチェック対象になります（それでも何秒もかかりますけど\u0026hellip;）。 このファイルにはローカル PC 内のファイル情報が含まれることになるので、Git でファイル管理している場合は、 .gitignore に .textlintcache を登録しておきましょう。"
},
{
url: "/p/2uds9o4/",
title: "TypeScriptの型: 基本型（プリミティブタイプ）の一覧",
date: "2020-04-28T00:00:00Z",
body: "TypeScriptの型: 基本型（プリミティブタイプ）の一覧 プリミティブ型 (primitive types) 下記のプリミティブ型は、JavaScript が内部的な型情報として扱うものであり、TypeScript のタイプアノテーションでも同様に使用することができます。 型名がすべて小文字になっているのが特徴的です。 boolean（真偽値） let isDone: boolean = false; （true または false） number（数値） let decimal: number = 6; （10進数リテラル） let hex: number = 0xf00d; （16進数リテラル） let octal: number = 0o744; （8進数リテラル） let binary: number = 0b1010; （2進数リテラル） string（文字列） let name: string = 'Maku'; （シングルクォートとダブルクォートは同様） let msg: string = `Hello, ${name}`;（変数展開する場合はバッククォート） function（関数） function foo(): number { return 100; } let bar: () =\u0026gt; number = foo bigint（巨大整数） let x: bigint = 1n; （ES2020 移行） symbol（ユニークなシンボル） let sym: symbol = Symbol('key'); （ES2015 移行） undefined（変数が初期化されていないことを示す） オブジェクト型 (object) 上記の型以外は、JavaScript の世界ではすべて object 型とみなされます。 TypeScript のタイプアノテーションでは、変数に格納できる値の型をより明確に示すことができます。 Array（配列） let arr: number[] = [1, 2, 3]; （数値の配列） let arr: Array\u0026lt;number\u0026gt; = [1, 2, 3]; （〃） let arr: string[] = ['AAA', 'BBB']; （文字列の配列） let arr: Array\u0026lt;string\u0026gt; = ['AAA', 'BBB']; （〃） 参考: 配列を定義する (Array) Tuple（タプル）扱いは配列とほぼ同じだが、各位置の要素の型が決まっているもの let x: [string, number] = ['Hello', 100]; 参考: タプルを定義する (Tuple types) Null（値がない） let x: string | null = null; その他 Enum enum Color {Red, Green, Blue} let c: Color = Color.Red; 列挙型の値（上記の例では Color.Red など）は、内部的にはただの数値 (number) 扱いです。 Void / Never void や never は、関数の戻り値の性質を表すもので、通常は変数の型情報としては使われません。 // 戻り値 void 型は、return 時に値を返さないことを示す function foo(name: string): void { console.log(`Hello, ${name}`); } // 戻り値 never 型は、return することがない関数を示す function throwError(msg: string): never { throw new Error(msg); } 参考リンク typeof で型情報を調べる"
},
{
url: "/p/7axgzfu/",
title: "Azure のストレージアカウントを作成する",
date: "2020-03-17T00:00:00Z",
body: "Azure のストレージアカウントを作成する Table Storage などのストレージ系サービスを使用するには、Azure ポータル から ストレージアカウント を作成しておく必要があります。 このトレージアカウントは Table Storage 専用ではなく、様々なストレージサービス（BLOB、ファイル、キュー、テーブル）をまとめて扱うものです。 ストレージアカウント → 作成 のような感じで進めば作成用の画面が開くので、ストレージアカウント名などを入力します。 ストレージアカウント名は、Azure 内で一意（要するに世界中で一意）な名前を付ける必要があります。 選択項目によっては、料金が変わってくるものがあるので、情報アイコンの説明を見ながら、安いプランを選択していきます。 例えば、Table Storage のレプリケーションの種類別価格は次のようになっています（こちらから抜粋）。 図: Table Storage の月額 入力が終わったら、作成 のボタンを押して、しばらく待てばストレージアカウントが作成されます（1分くらいかかります）。"
},
{
url: "/p/qt5qyzu/",
title: "Azure DevOps で無料のプライベート Git リポジトリ (Repos) を使用する",
date: "2019-09-30T00:00:00Z",
body: "Azure DevOps で無料のプライベート Git リポジトリ (Repos) を使用する Azure DevOps について GitHub は Microsoft によって買収されましたが、Azure ブランドの DevOps サービスでも Git リポジトリを扱う Repos という機能が提供されています。 GitHub は 2019 年から無制限に Private リポジトリを作成できるようになりましたが、Azure DevOps の方も無制限に Private リポジトリを作成することができ、5 ユーザーまでのコラボレーションが無料です（GitHub は 3 ユーザーまで）。 DevOps の Repos でも、GitHub のようにプルリクエストを使ったレビューを行えます。 さらに、DevOps には Pipelines という、継続的インテグレーション/継続的デリバリー (CI/CD) の機能も含まれており、こちらも毎月 1,800 分の実行まで無料で使用できます。 GitHub Actions なども同じような機能を提供する予定であり、これから Azure DevOps とどのような関係で進化していくのかわかりませんが、現状では Azure DevOps は魅力的な選択肢と言えそうです。 Azure DevOps の Git リポジトリ (Repos) を使用する DevOps で Git リポジトリを作成する場合、まずは DevOps のプロジェクトを作成し、その中に Git リポジトリを作成していくという構成になります。 1 つの DevOps プロジェクトには、いくつでも Git リポジトリを作成できます。 DevOps プロジェクトと Git リポジトリの作成 Azure Repos | Microsoft Azure Azure Repos の 無料で始める ボタンを押して、DevOps プロジェクトを作成します。 Azure DevOps のプロジェクト作成画面に飛ぶので、プロジェクト名を入力して Create project を押せば完成です。 ここでは、HelloWorld という名前のプロジェクトを作成しています。 作成したプロジェクトのダッシュボードが開いたら、左側のタブから Repos という項目を選択すると、プロジェクト内の Git リポジトリの一覧を確認することができます。 デフォルトでは、DevOps プロジェクトの名前と同じ名前の Git リポジトリ（ここでは HelloWorld）が 1 つだけ作成された状態になっています。 上部のヘッダーのプルダウンメニュー（リポジトリアイコンが付いた部分）を開くと、New repository という項目があり、ここからいくつでも Git リポジトリを追加できます。 git clone できるようにする ローカルの PC から、この Git リポジトリをクローンできるようにするには、アクセス用の Git credentials（要するにユーザー名とパスワード）を設定しておく必要があります。 左側のメニューから Repos / Files を選択し、Generate Git credentials ボタンを押すことでユーザー名とパスワードを登録するフォームが開きます。 アクセストークンを生成してそちらを使う方法もありますが、ここでは単純にユーザー名＋パスワードのペアでアクセスすることにします。 Alias の欄にユーザー名、Password の欄にパスワードをそれぞれ入力し、Save Git Credentials ボタンを押せば設定完了です。 あとは、表示されている URL を使って、git clone コマンドを実行すれば、リポジトリをクローンすることができます。 この際、URL の @ の前の部分だけ、設定したユーザー名 (Alias) に置き換えて実行してください。 $ git clone https://\u0026lt;ユーザー名\u0026gt;@dev.azure.com/makkuma/HelloWorld/_git/HelloWorld Cloning into \u0026#39;HelloWorld\u0026#39;... Password for \u0026#39;https://\u0026lt;ユーザー名\u0026gt;@dev.azure.com\u0026#39;: ******** remote: Azure Repos remote: Found 4 objects to send. (43 ms) Unpacking objects: 100% (4/4), done. Checking connectivity... done. これで、ローカル PC 上に HelloWorld ディレクトリが生成されます。 ちなみに、このユーザー名とパスワードは、DevOps プロジェクト内のすべての Git リポジトリに共通の設定となります（新しく Git リポジトリを作成するごとに登録する必要はありません）。"
},
{
url: "/p/tdouo5p/",
title: "TypeScript とは",
date: "2019-09-24T00:00:00Z",
body: "TypeScript とは TypeScript は、JavaScript に静的な型付けを行えるようにしたプログラミング言語です。 トランスパイラ (tsc コマンド）を使って、TypeScript で記述したコードを JavaScript のコードに変換するのが主な使い方になります。 大規模な JavaScript アプリケーションを開発するときに TypeScript を導入すると、品質の高いコードを効率よく作成できるようになります。 TypeScript はマイクロソフトによって開発が進められており、同じくマイクロソフトによって開発されている Visual Studio Code でコーディングを行うのがよいとされています。 数年前に CoffeeScript と呼ばれる同様の言語が一時的にブームになりましたが、現在は TypeScript が主流です。 TypeScript には下記のような特徴があり、しばらくは JavaScript alternative として主流であり続けるでしょう。 Microsoft により強力にサポートされており、Visual Studio Code が最新の TypeScript バージョンに迅速に対応します。 静的な型付けにより、実行前（トランスパイル時）にコーディングのミスを発見しやすくなります。型の推論がしやすくなるため、IDE（VS Code など）のプロパティ名の自動補完が効くようになります。これがほんとに便利で、特にサードパーティ製のライブラリを使っているときにありがたみが分かります。 JavaScript (ECMAScript) の新しい仕様を使ってコーディングできます。TypeScript が新しい構文で書かれたコードを過去バージョンの JavaScript コードに変換してくれるため、各ブラウザベンダーが新しい仕様に対応するのを待つ必要がありません。 JavaScript のコードは有効な TypeScript のコードとして動作します（構文に互換性があります。専門用語では JavaScript の「スーパーセット」であると言う）。そのため、既存の JavaScript プロジェクトに TypeScript を導入しようとするとき、既存の JavaScript コードを修正する必要がありません。また、これまでに身に着けた JavaScript のノウハウをそのまま活かし続けることができます。"
},
{
url: "/p/xzc5z98/",
title: "MongoDB の特徴",
date: "2019-05-20T00:00:00Z",
body: "MongoDB の特徴 MongoDB はオープンソースの NoSQL データベースで、MongoDB Inc.（旧 10gen）によって開発とサポートが行われています。 https://www.mongodb.org/ MongoDB は次のような特徴を持っています。 ドキュメント指向型のデータベースで、BSON 形式でオブジェクトを格納する。 スキーマ定義が必要なく、データ構造が柔軟。 マスタ・スレーブ型のアーキテクチャを取り、書き込みはマスタノードに対してのみ、読み出しは複製されたスレーブノードからのみ行われる。非同期に複製が行われ、一時的に複数のデータバージョンが混在する可能性があるため、完璧な整合性が求められる用途には向かない。 バージョン 1.6 以降はレプリカ・セットという方式を採用し、プライマリ＆セカンダリの役割に基づいて複製制御が行われる。 MapReduce を使ったバッチ処理を利用できる。 セカンダリ・インデックスという機能により、複数の索引を使ってデータを検索できる。 RDB と比較して大量のデータを扱える。Mongo という名前は、英語の humongous（巨大な）から来ている。 JavaScript コードをストアド・プロシージャとして使用できる。"
},
{
url: "/p/opxhnho/",
title: "PlantUML の基本（インストール〜画像ファイルへの保存）",
date: "2018-10-12T00:00:00Z",
body: "PlantUML の基本（インストール〜画像ファイルへの保存） Graphviz のインストール PlantUML は図の生成のために内部で Graphviz の dot コマンドを使用するので、先に Graphviz をインストールしましょう。 Graphviz - Graph Visualization Software ここでは、上記のサイトから ZIP ファイル graphviz-2.38.zip をダウンロードし、展開してできた release ディレクトリ内のファイル群を C:\\app\\graphviz-2.38 というディレクトリ内に配置するとします。 Graphviz に含まれる dot コマンドのパスを環境変数 GRAPHVIZ_DOT に設定すれば Graphviz のインストールは完了です（この環境変数を PlantUML が参照します）。 環境変数 GRAPHVIZ_DOT の設定 GRAPHVIZ_DOT=C:\\app\\graphviz-2.38\\bin\\dot.exe PlantUML のインストール 下記から plantuml.jar をダウンロードして、適当なディレクトリに配置します。 PlantUML - plantuml.jar のダウンロード ここでは、C:\\app\\plantuml\\plantuml.jar というパスで配置することにします。 コマンドプロンプトから、下記のように実行して、特にエラーが発生しなければ OK です。 実行テスト C:\\\u0026gt; java -jar C:\\app\\plantuml\\plantuml.jar -testdot The environment variable GRAPHVIZ_DOT has been set to C:\\app\\graphviz-2.38\\bin\\dot.exe Dot executable is C:\\app\\graphviz-2.38\\bin\\dot.exe Dot version: dot - graphviz version 2.38.0 (20140413.2041) Installation seems OK. File generation OK plantuml コマンドを簡単に使えるようにする PlantUML を使って図を生成するために、毎回 java -jar plantuml.jar xxx と入力するのは面倒なので、plantuml というコマンドで一発で実行できるようにします。 plantuml.jar と同じディレクトリに、下記のようなバッチファイルを作成してください。 C:\\app\\plantuml\\plantuml.cmd @java -jar %~dp0\\plantuml.jar -charset UTF-8 %* ついでに、UML ダイアグラムの中で日本語が文字化けしないように、-charset の指定も行っています。 最後に、上記のバッチファイルをどこからでも実行できるように、上記のパスを環境変数 PATH に追加しておきます。 環境変数 PATH の設定 PATH=%PATH%;C:\\app\\plantuml これで、次のようにどこのディレクトリからでも plantuml コマンドを実行できるようになります。 実行テスト（ヘルプの表示） C:\\\u0026gt; plantuml -h 画像ファイルとして出力する 最後に plantuml コマンドを使って、UML ダイアグラムを画像ファイルとして出力するテストをしてみます。 まず、下記のようなシーケンス図のためのサンプルファイルを作成してください。 sequence.txt @startuml Alice -\u0026gt; Bob: Authentication Request Bob --\u0026gt; Alice: Authentication Response Alice -\u0026gt; Bob: Another authentication Request Alice \u0026lt;-- Bob: another authentication Response @enduml コマンドラインから下記のように実行すれば、sequence.png という名前の PNG ファイルが生成されます。 $ plantuml sequence.txt SVG ファイルとして出力する デフォルトでは PNG ファイルとして図が出力されますが、-tsvg オプションを付けることで SVG ファイルとして出力することができます。 下記のように実行すると、sequence.svg ファイルが生成されます。 $ plantuml -tsvg sequence.txt 図: 出力結果 (sequence.svg)"
},
{
url: "/p/pwx5kf7/",
title: "mongo シェルの基本的な使い方",
date: "2015-04-13T00:00:00Z",
body: "mongo シェルの基本的な使い方 MongoDB サーバーへの接続 mongo シェルで MongoDB サーバーへ接続するには次の用に実行します。 先に MongoDB サーバーを起動 しておく必要があります）。 $ mongo # 単純に接続する場合 $ mongo mydb # 使用するデータベース名を指定する場合 ポート番号（デフォルトは 27017）や接続先の IP アドレスを指定することもできます。 下記はすべて正しい接続方法です。 $ mongo --port 40001 $ mongo --port 40001 mydb $ mongo localhost:40001 $ mongo localhost:40001/mydb $ mongo 192.168.0.100 $ mongo 192.168.0.100/mydb $ mongo 192.168.0.100:40001/mydb ヘルプの表示 (help) mongo シェルを起動したあとに、help コマンドを実行するとヘルプを表示することができます。 \u0026gt; help 実行結果 db.help() help on db methods db.mycoll.help() help on collection methods sh.help() sharding helpers rs.help() replica set helpers help admin administrative help help connect connecting to a db help help keys key shortcuts help misc misc things to know help mr mapreduce show dbs show database names show collections show collections in current database show users show users in current database show profile show most recent system.profile entries with time \u0026gt;= 1ms show logs show the accessible logger names show log [name] prints out the last segment of log in memory, \u0026#39;global\u0026#39; is default use \u0026lt;db_name\u0026gt; set current database db.mycoll.find() list objects in collection mycoll db.mycoll.find( { a : 1 } ) list objects in mycoll where a == 1 it result of the last line evaluated; use to further iterate DBQuery.shellBatchSize = x set default number of items to display on shell exit quit the mongo shell コレクションにドキュメントを追加する (db.coll.insert) まず、データベース名を指定して MongoDB サーバーに接続してください。 ここでは、mydb という名前のデータベースを使うことにします（実体は必要に応じて自動的に作成されます）。 $ mongo mydb データベース名を指定せずに接続した場合は、use \u0026lt;DB名\u0026gt; で切り替えられます。 現在操作対象としているデータベースは db と入力することで確認できます。 \u0026gt; use mydb switched to db mydb \u0026gt; db mydb データベースの「コレクションにドキュメントを追加する」には、次のようなコマンドを実行します。 これは、RDB でいうところの「テーブルにレコードを追加する」ことに相当します。 js db.\u0026lt;コレクション名\u0026gt;.insert(\u0026lt;ドキュメント\u0026gt;) コレクションはあらかじめ生成しておく必要はなく、必要に応じて自動的に生成されます（データベースと同様）。 追加するデータ（ドキュメント）は、JavaScript のオブジェクト形式で指定します。 次の例では、books コレクションに、3 つのドキュメントを追加しています。 \u0026gt; db.books.insert({title: \u0026#39;Title 1\u0026#39;}) \u0026gt; db.books.insert({title: \u0026#39;Title 2\u0026#39;}) \u0026gt; db.books.insert({title: \u0026#39;Title 3\u0026#39;}) コレクション内のドキュメントを取得する (db.coll.find) コレクションに格納されているドキュメントを取得（検索）するには、find を使用します。 引数なしで実行すると、すべてのドキュメントを取得します。 books コレクション内の全ドキュメントを取得 \u0026gt; db.books.find() { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;6096b7e313fb77617c8a6a6c\u0026#34;), \u0026#34;title\u0026#34; : \u0026#34;Title 1\u0026#34; } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;6096b7ea13fb77617c8a6a6d\u0026#34;), \u0026#34;title\u0026#34; : \u0026#34;Title 2\u0026#34; } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;6096b7eb13fb77617c8a6a6e\u0026#34;), \u0026#34;title\u0026#34; : \u0026#34;Title 3\u0026#34; } 特定のドキュメントを検索したいときは、次のような感じで引数で検索条件を指定します。 \u0026gt; db.books.find({title: \u0026#39;Title 1\u0026#39;}) { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;6096b7e313fb77617c8a6a6c\u0026#34;), \u0026#34;title\u0026#34; : \u0026#34;Title 1\u0026#34; } books コレクションに対して、他にどのようなコマンドを実行できるかは、次のようにして確認できます。 コレクションの操作に関するヘルプ \u0026gt; db.books.help() コレクション内のドキュメントを削除する (db.coll.drop, db.coll.remove) 全てのドキュメントを削除する \u0026gt; db.books.drop() 条件に一致するドキュメントを削除する \u0026gt; db.books.remove({title: \u0026#39;Title 1\u0026#39;}) remove の引数に空オブジェクト ({}) を渡すことでも全てのドキュメントを削除することができますが、drop を使った方が効率的です。"
},
{
url: "/p/3ucs8n3/",
title: "MongoDB サーバー (mongod) を起動する",
date: "2015-04-13T00:00:00Z",
body: "MongoDB サーバー (mongod) を起動する MongoDB クライアント（mongo コマンドや Web アプリケーション）から MongoDB のデータベースにアクセスするには、あらかじめ MongoDB サーバー（mongod）を起動しておく必要があります。 MongoDB サーバーを起動する (mongod) MongoDB サーバーは、単純にコマンドラインから mongod と実行するだけで起動できます（Windows のサービスとして起動 しておくことも可能です）。 mongod コマンドを実行するときに、--dbpath オプションを使ってデータの格納先ディレクトリを指定することができます（デフォルトは /data/db）。 下記の例では、mydata ディレクトリをデータ格納先に指定しています。 MongoDB サーバーの起動 $ mkdir mydata $ mongod --dbpath mydata ログファイル名を指定する (\u0026ndash;logpath, \u0026ndash;logappped) MongoDB サーバーのログはデフォルトで標準出力に出力されますが、--logpath オプションを使って、出力先のログファイル名を指定することもできます。 さらに、--logappend オプションを指定すると、これまでのログに追記される形で書き込まれます（このオプションを付けないと、ログファイルが上書きされてしまいます）。 ログを log.txt に保存する $ mongod --dbpath mydata --logpath log.txt --logappend --dbpath にはディレクトリ名を指定しますが、--logpath にはファイル名を指定することに注意してください。 ポート番号を指定する (\u0026ndash;port) mongod が使用するデフォルトのポート番号は 27017 ですが、--port オプションを使用して、任意のポート番号で起動することができます。 ポート番号を変更しておけば、1 台のホスト上で複数の mongod を立ち上げることができます。 ポート番号 40001 で起動する $ mongod --dbpath mydata --port 40001 サーバー側のポート番号を変更した場合は、mongo クライアントを起動するときにも mongo localhost:40001/dbname や --port 40001 のようにポート番号の指定が必要になることに注意してください。 MongoDB サーバー用の設定ファイル 設定を YAML ファイルに記述する MongoDB サーバー用の起動オプションは、YAML 形式の設定ファイルに記述しておくことができます（YAML 形式は ver 2.6 から対応）。 mongod.yml（mongod 用の設定ファイル） storage:dbPath:data/dbsystemLog:destination:filepath:data/log/mongod.loglogAppend:truenet:port:40001 設定ファイルを指定して起動する $ mongod --config mongod.yml 設定ファイルの詳細については下記の公式ドキュメントを参照してください。 参考リンク Configuration File Options — MongoDB Manual 起動用のスクリプトを作成する いずれにしても、データ格納先のディレクトリ（上記の例では data）はあらかじめ作成しておく必要があるので、簡単な設定だけであれば、シェルスクリプトやバッチファイルで起動するようにしておいた方が楽かもしれません。 mongod-start.sh（Linux 用） #!/bin/bash PORT=40001 mkdir -p data/db mkdir -p data/log echo Start mongod on port $PORT ... mongod --dbpath data/db --logpath data/log/mongod.log --logappend --port $PORT \u0026amp; mongod-stop.sh（Linux 用） #!/bin/bash killall mongod mongod-start.bat（Windows 用） @echo off md data\\db \u0026gt; NUL 2\u0026gt;\u0026amp;1 md data\\log \u0026gt; NUL 2\u0026gt;\u0026amp;1 echo Start mongod ... mongod --dbpath data\\db --logpath data\\log\\mongod.log --logappend --port 40001"
},
{
url: "/p/7gmjvza/",
title: "１時間で分かる GoF デザインパターン",
date: "2008-05-13T00:00:00Z",
body: "１時間で分かる GoF デザインパターン オブジェクト指向における再利用のためのデザインパターン エリック ガンマ, ラルフ ジョンソン, リチャード ヘルム, ジョン ブリシディース ソフトバンククリエイティブ 増補改訂版Java言語で学ぶデザインパターン入門 結城 浩 ソフトバンククリエイティブ デザインパターンの輪講をしたときのメモ。 生成に関するパターン (Creational Patterns) (1) Abstract Factory パターン 同種の複数のオブジェクト生成を concrete factory クラスとして種類ごとにまとめ、実際の生成は abstract factory クラスの抽象化されたインタフェース経由で行う。一貫した種類のインスタンスを作ることができる。 実装イメージ TvFactory tvFactory = new SonyTvFactory(); // Sony 製の TV を作るための TvFactory ... tvFactory.CreatePanel(); // SonyPanel を生成 tvFactory.CreateTuner(); // SonyTuner を生成 ... どのような手順で factory method を呼び出すかを定義すると、それは Builder パターンになる。 (2) Builder パターン オブジェクトの生成手順を共通化して使いまわし、異なるオブジェクトを作成。 実装イメージ Product* Director::CreateProduct(Builder *builder) { builder-\u0026gt;CreateStep1(); builder-\u0026gt;CreateStep2(); builder-\u0026gt;CreateStep3(); return builder-\u0026gt;GetProduct(); } 上記のメソッドに異なる Builder オブジェクトを渡せば、異なる Product が生成される。ただし、作成手順は共通化されている。 (3) Factory Method パターン インスタンス生成メソッドを抽象化し、サブクラスに具体的なインスタンス生成を任せる。インスタンス生成メソッド (factory method) を呼び出す部分がすべて抽象化されるのがポイント。 実装イメージ Component component = new TextComponent(); // 具象クラスが出るのはこの１回のみ Renderer renderer = component.CreateRenderer(); // その後のインスタンス生成は抽象化される // factory method の実装 Renderer TextComponent::CreateRenderer() { return new TextRenderer(); // このクラスに適したインスタンスを生成 } Factory Method と Abstract Factory の違いは下記のような感じ（個人的解釈あり）。 同系統のクラスをインスタンス化するための factory method を複数持つように実装すると、それは、Abstract Factory パターンになる。 Abstract Factory の場合、一貫性を保持して同種のオブジェクトを factory method で作成するようにしているのがポイント。 Factory Method パターンの場合、抽象化する対象は単一のメソッドなので、クラス名にそのパターンを使っていることを暗示するような名前をわざわざ付けるようなことはしない。 一方、Abstract Factory パターンの場合、どのような種類のインスタンスを生成するためクラスなのかを示す名前を付けるべき。というか付けないと相当分かりにくくなる。 (4) Prototype パターン プロトタイプ・オブジェクトをコピーして似たようなインスタンスを作る。コンストラクタでなく、オブジェクト (prototype) を元にインスタンスを生成するため、作成されるオブジェクトをカスタマイズできる。 AbstractFactory オブジェクトに Prototype オブジェクトをセットできるようにすれば、生成するオブジェクトの種類を制御できる。 実装イメージ PrototypeHoge hoge = prototypeHoge.Clone(); (5) Singleton パターン 省略。 構造に関するパターン (Structual Patterns) (6) Adapter パターン 既存クラスのインタフェース (Adaptee) を、クライアントが使用したいインタフェース (Target) に合うように変換する。 実装イメージ（object adapter の場合） class Adapter : public Target { private: Adaptee *m_pAdaptee; // インタフェースの合わない既存のクラス public: // object adapter の一般的な作り方 Adapter(Adaptee *adaptee) : m_adaptee(adaptee) {} // クライアントは Target::DoSomething() の形で呼び出したい vitual void DoSomething() { m_adaptee-\u0026gt;ProprietaryMethod(); ... } } 上記のように委譲させる実装方法 (delegation) の他に、Adapter クラスが Adaptee を private 継承するようにする class adapter という実装形態もある。 (7) Bridge パターン 機能の階層（アプリドメインにおける機能など (Abstraction)）と、実装の階層（プラットフォームごとの実装や、データクラスの内部表現など (Implementor)）をごっちゃにするなということ。抽象化された実装のインタフェースを使って機能部分を実装することで、プラットフォームごとの実装にとらわれずにアプリの本質的な処理を実装できる。つまり、Abstraction レイヤーをいじれば（アプリなどの）機能が変わり、Implemetor レイヤーをいじっても表面的な機能は変わらないということ。 性質上、Implementor のインタフェースは Abstraction のインタフェースよりもプリミティブなものになる。機能部分と実装部分は別々の継承関係を持つので、別々にサブクラス化して拡張していける。 実装イメージ // 機能の階層 (Abstraction \u0026amp; RefinedAbstraction) class Frame { void Draw() { Graphics *p = GetGraphics(); p-\u0026gt;DrawLine() で枠を描く } } class BeautifulFrame : public Frame { void Draw() { Graphics *p = GetGraphics(); p-\u0026gt;DrawLine() で綺麗な枠を描く } } // 内部実装の階層 (Implementor \u0026amp; ConcreteImplementor) class Graphics { void DrawLine(Point, Point); } class BresenhamGraphics : public Graphics { void DrawLine(Point a, Point b) { Bresenham アルゴリズムによる線の描画 } } class EccentricGraphics : public Graphics { void DrawLine(Point a, Point b) { 変わったアルゴリズムによる線の描画 } } 階層を分けるというと複雑に感じるけど、Abstraction と Implementor 階層のクラス関係を見ると、それは単なる Strategy パターンだと気づく。だから、Bridge パターンって、役割の違うクラスを同じ階層に入れるなという単なる教訓みたいなもの。 (8) Composite パターン あるオブジェクトと、それを含む composite のインタフェースを統一する。 実装イメージ // File と Directory の共通の親クラス class Entry { public: virtual int GetSize(); }; class File : public Entry { public: virtual int GetSize() { return 自分自身のサイズ; } } class Directory : public Entry { public: virtual int GetSize() { return ディレクトリ内の合計サイズ; } void AddEntry(Entry *entry) { ディレクトリに追加; } }; // Directory には File を格納できる Directory *dir = new Directory(); dir-\u0026gt;AddEntry(new File()); dir-\u0026gt;AddEntry(new File()); // Directory に Directory を格納することもできる Directory *dir2 = new Directory(); dir2-\u0026gt;AddEntry(dir); // Directory 内のファイルサイズ合計を取得 Print(dir2-\u0026gt;GetSize()); (9) Decorator パターン 継承せずにオブジェクトを拡張する。 拡張対象のオブジェクト (Component) を delegate として持ち、メソッド呼び出しをラッピングする形で拡張する。インタフェースは変わらないので、再帰的に拡張することができる。継承ではなく、オブジェクトコンポジションによる拡張なので、動的 (at run-time) に拡張することができる。 実装イメージ // 拡張される側 (Component) class Greeter { public: virtual void Greet() = 0; }; class OrdinaryGreeter : public Greeter { public: virtual void Greet() { cout \u0026lt;\u0026lt; \u0026#34;Hello. \u0026#34;; } }; // 拡張する側 (Decorator) class Decorator : public Greeter { private: Greeter *m_greeter; public: Decorator(Greeter *greeter) : m_greeter(greeter) {} virtual void Greet() { m_greeter-\u0026gt;Greet(); } ... }; class YahooDecorator : public Decorator { // ConcreteDecorator public: YahooDecorator(Greeter *greeter) : Decorator(greeter) {}; virtual void Greet() { cout \u0026lt;\u0026lt; \u0026#34;Yahoo! \u0026#34;; Decorator::Greet(); cout \u0026lt;\u0026lt; \u0026#34;WYYYRYYY!\u0026#34; } }; // main Greeter *greeter = new YahooDecorator( new YahooDecorator( new OrdinaryGreeter())); greeter-\u0026gt;Greet(); // \u0026#34;Yahoo! Hello. WYYYRYYY!\u0026#34; 上記の例では、ConcreteDecorator は 1 種類しか存在しないので、実は Decorator 部分が ConcreteDecorator（ここでは YahooDecorator）であってもよい。 (10) Facade パターン 複数のオブジェクトを使用して行わなければならない処理をまとめ、シンプルなインタフェースで実行できるようにする。 実装イメージ class Facade { private: static void DoEverything() { // 複数オブジェクトを駆使した処理をまとめる ClassA a; a.DoSomething(); ClassB b; b.DoSomething(a); ClassC c; c.DoSomething(a, b); } }; // main Facade::DoEverything(); // クライアントはシンプルなインタフェースで呼び出すだけ (11) Flyweight パターン 多数のオブジェクトを作る必要があるとき、使いまわせるデータを複数のオブジェクトが共有することで効率よく内部データを表現する。共有できるデータを intrinsic state といい、これを保持するオブジェクトをテーブルに保持するなどして使いまわす。逆に、コンテキストによって変化する共有できないデータを extrinsic state といい、メソッド実行時にパラメータで渡す。どちらのアプローチもメモリ節約に貢献する。 実装イメージ class Character { private: char m_ch; // 共有できる部分 (intrinsic state) public: Character(char ch) : m_ch(ch) {} Draw(Position pos) { ... } // 各々の Position は共有できない (extrinsic state) }; class CharacterFactory { private: Character m_char[MAX_CHAR]; // intrinsic state を持つオブジェクトはテーブルに入れて共有 public: static *Character CreateCharacter(char c) { if (m_characters[c]) { m_characters[c] = new Character(c); } return m_characters[c]; } }; // main Character *pCh1 = CharacterFactory::GetCharacter(\u0026#39;a\u0026#39;); Character *pCh2 = CharacterFactory::GetCharacter(\u0026#39;a\u0026#39;); // 同じオブジェクトを参照する pCh1-\u0026gt;Draw(Position(0, 10)); // それぞれの描画位置は共有できないので引数で渡す pCh2-\u0026gt;Draw(Position(0, 20)); intrinsic なデータを持つオブジェクトも extrinsic なデータを扱ってよい。ただし、extrinsic なデータは毎回パラメータとして渡す必要がある。上の例では Character オブジェクトをテーブルに保持して共有しているが、実際に共有されているデータは Character オブジェクトの intrinsic state である m_ch のみ。 (12) Proxy パターン あるオブジェクト (RealSubject) へのアクセス方法を制御する。クライアントは RealSubject へ直接アクセスするときと同じインタフェースで Proxy にアクセスできる。 「遅延ロード (on demand)」「キャッシュ」「インスタンス共有」「アクセス先の隠蔽」「スマートポインタの実装」などの用途に適用できる。 実装イメージ（遅延ロードを実現する場合） // (Subject) クライアントが使用するインタフェース class Data { virtual void PrintData() = 0; }; // (RealSubject) インスタンス化にコストがかかると仮定 class LargeData : public Data { public: virtual void PrintData() { ... } ... }; // (Proxy) RealSubject へのアクセスを制御（必要になってから RealSubject をインスタンス化） class DataProxy : public Data { private: LargeData *m_pData; public: DataProxy() : m_pData(0) {} virtual void PrintData() { if (m_pData == 0) { m_pData = new LargeData(); } m_pData-\u0026gt;PrintData(); } ... } // main Data *pData = new DataProxy(); // この段階では LargeData はインスタンス化されない pData-\u0026gt;PrintData(); // この段階で Proxy 内部で LargeData が生成される 振る舞いに関するパターン (Behavioral Patterns) (13) Chain of Responsibility パターン リクエストを伝播させ、適切なオブジェクトで処理させる。Linked list か何かでメソッド呼び出しを伝播させるように実装する。 実装イメージ class Handler { private: Handler *m_pSuccessor; // 次のリクエスト転送先 public: Handler(Handler *pSuccessor = 0) : m_pSuccessor(pSuccessor) {} virtual void HandleRequest(const Request *pRequest) { if (m_pHandler) { m_pHandler-\u0026gt;HandleRequest(); } } }; class ConcreteHandler1 : public Handler { public: ConcreteHandler1(Handler *pSuccessor) : Handler(pSuccessor) {} virtual void HandleRequest(const Request *pRequest) { if (pRequest-\u0026gt;GetType() == Request::SOME_KIND_OF_REQUEST) { // 自分の興味のあるリクエストだったら処理して終了 cout \u0026lt;\u0026lt; \u0026#34;Yahoooo!\u0026#34; \u0026lt;\u0026lt; endl; return; } // 次の Handler へリクエストを転送 Handler::HandleRequest(); } }; class ConcreteHandler2 : public Handler { ... 同様 ... }; // main Handler *pHandler = new ConcreteHandler1(new ConcreteHandler2(new CocreteHandler3()); pHandler-\u0026gt;HandleRequest(someKindOfRequest); メモ ツリー構造が既に構成されているなら、親ノードへのポインタを successor ポインタの代わりに利用できる。 チェーンがループしないように注意しなきゃね。 リクエストの転送部分以外の実際の処理部分だけを子クラスで実装するようにしてもよい。その場合は、リクエストを処理したかどうかを示す真偽値をハンドラメソッドの戻り値で返すようにして転送させる必要があるかどうかを親クラス側で判断する。いくつかの Windows API がこの方法を採用している。 Q. すでに何らかのクラスを継承済みのクラスに Handler の役割を持たせたい場合は？ A. 既存のクラスに Handler を継承させるのではなく、チェーンを構成するための ConcreteHandler クラス群を別に作り、それに既存のクラスの処理を委譲させればよい。 (14) Command パターン 要求の処理方法を Command オブジェクトにカプセル化し、好きなタイミングで要求を処理できるようにする。処理を発火させるオブジェクト (Invoker) は、処理方法を知らなくてもよいので、簡単に要求の種類 (Command) を増やすことができる。 処理内容は Command オブジェクト内に直接実装してもよいし、Command オブジェクトに保持させた他のオブジェクト (Receiver) に委譲してもよい。 実装イメージ class Command { public: virtual ~Command(); virtual void Execute() = 0; }; class HelloCommand : public Command { private: string m_name; public: HelloCommand(string name) : m_name(name) {} virtual void Execute() { cout \u0026lt;\u0026lt; \u0026#34;Hello \u0026#34; \u0026lt;\u0026lt; name; } }; class GoodByeCommand : public Command { public: virtual void Execute() { cout \u0026lt;\u0026lt; \u0026#34;Good bye\u0026#34;; } }; // main buttonA.SetCommand(new HelloCommand(\u0026#34;Mike\u0026#34;)); // ボタン A が押された時の処理を設定 buttonB.SetCommand(new GoodByeCommand()); // ボタン B が押された時の処理を設定 timer.SetCommand(new GoodByeCommand(), 10); // 10 分のタイマーが切れた時の処理を設定 Command::Execute() を実行する前の状態を Command オブジェクトが保持するようにしておけば、Command::Undo()、Command::Redo() などを実装することができる。 (15) Interpreter パターン ある言語ルールに従った表現 (Expression) をオブジェクトの構造（構文木など）で表現し、そのオブジェクト構造をもとに言語を解釈（式の評価など）できるようにする。 実装イメージ class Expression { public: virtual int Evaluate() = 0; }; class Number : public Expression { private: int m_num; public: Number(int num) : m_num(num) {} virtual int Evaluate() { return m_num; } }; class PlusExpression : public Expression { public: PlusExpression(Expression *exp1, Expression *exp2) : m_exp1(exp1), m_exp2(exp2) {} // 足し算の解釈方法を定義（解釈方法は実装言語に依存した形で実装する） virtual int Evaluate() { return m_exp1.Evaluate() + m_exp2.Evaluate(); } }; // main // \u0026#34;(100 + 200) + 300\u0026#34; を表現し、解釈する Expression *pExp = new PlusExpression( new Expression(new Number(100), new Number(200)), new Number(300)); cout \u0026lt;\u0026lt; pExp-\u0026gt;Evaluate() \u0026lt;\u0026lt; endl; // 600 生成したオブジェクト構造それ自身に意味を解釈する (interpret) 能力を持たせるところがポイント。オブジェクト構造を構成する要素 (Expression) それぞれに自分自身を解釈する機能を持たせているため、新しい表現を追加する場合は Expression を追加するだけで、自動的に言語の解釈方法が拡張されることになる（当然、パースしてこういったオブジェクト構造を作成する部分は変更しなければならないが）。 (16) Iterator パターン 様々な集約構造 (aggregate) 内の要素を、統一されたインタフェースで順にアクセスする。 実装イメージ template\u0026lt;Item\u0026gt; class ListIterator : public Iterator { // List の要素を走査する Iterator public: ListIterator(const List\u0026lt;Item\u0026gt; *pList) : m_pList(pList), m_index(0) {} virtual void First() { m_index = 0; } virtual void Next() { ++m_index; } virtual void bool IsDone() const { return m_index \u0026gt;= m_pList.Size(); } virtual Item CurrentItem() const { return m_pList.Item(m_index); } private: const List\u0026lt;Item\u0026gt; *m_pList; int m_index; }; // main List\u0026lt;int\u0026gt; *pList = new List\u0026lt;int\u0026gt;; pList-\u0026gt;Add(100); pList-\u0026gt;Add(200); ListIterator it(pList); for (it-\u0026gt;First(); !it-\u0026gt;IsDone(); it-\u0026gt;Next()) { cout \u0026lt;\u0026lt; pList-\u0026gt;CurrentItem() \u0026lt;\u0026lt; endl; } 特定の条件を満たす要素だけを抽出するフィルタ用途の iterator を作ったり、走査の順序を変えた iterator を作ったりすることができる。 aggregate がインタフェースにより抽象化されているのなら、ひとつの iterator を様々な aggregate に対して適用できる。 (17) Mediator パターン 複数のオブジェクト間のやり取りを、ひとつのオブジェクトに集約する。 オブジェクト間の連携方法は Mediator オブジェクトに隠蔽される。 実装例 （ListBox、TextBox への入力を互いに反映させる Mediator） class QuickEntryMediator : public ListBoxListener, public TextBoxListener { public: QuickEntryMediator(ListBox *pListBox, TextBox *pTextBox) { : m_pListBox(pListBox), m_pTextBox(pTextBox) { m_pListBox.addListener(this); m_pTextBox.addListener(this); } virtual ~QuickEntryMediator() { m_pListBox.deleteListener(this); m_pTextBox.deleteListener(this); } // ListBox の選択が変更されたら、TextBox に内容を表示 virtual void OnListBoxChanged(const Event\u0026amp; e) { m_pTextBox-\u0026gt;SetText(m_pListBox-\u0026gt;GetSelectedText()); } // TextBox の内容が変更されたら、対応する ListBox の項目を選択 virtual void OnTextBoxChanged(const Event\u0026amp; e) { int i = GetCorrespondingIndex(m_pTextBox.GetText()); if (i \u0026gt; 0) { m_pListBox-\u0026gt;Select(i); } else { m_pListBox-\u0026gt;Unselect(); } } int GetCorrespondingIndex(const string\u0026amp; text) { ... } }; 言い換えれば、汎用性のない部分が Mediator に集約される。 (18) Memento パターン あるオブジェクト (Originator) の状態をオブジェクト (Memento) に保存し、後からその状態を復元できるようにする。Memento オブジェクトの内容は Originator のみが設定／参照できる。 // Originator のある時点の状態（スナップショット）を保存 class Memento { public: virtual ~Memento(); private: // Memento の内容は対象の Originator だけが設定／参照する friend class Originator; Memento(); void GetState(State \u0026amp;state) { state = m_state; } void SetState(const State \u0026amp;state) { m_state = state; } State m_state; // Originator の状態 }; class Originator { public: Originator() { m_state.ChangeState(); } Mement CreateMemento(); // 現在のスナップショットを Memento オブジェクトに保存 void SetMemento(const Memento\u0026amp; memento); // 状態を Memento オブジェクトから復帰 void ChangeState() { ... } private: State m_state; }; // main Originator org; org.ChangeState(); Mement mement = org.CreateMemento(); // 現在の状態を Memento オブジェクトに保存 org.ChangeState(); org.SetMemento(memento); // 状態を復帰 (19) Observer パターン オブジェクト (Subject) に変化があったときに、関連する他のオブジェクト (Observers) に自動で通知されるようにする。Subject は Observer が何を行うかを知らないでよい。 実装イメージ class Subject { // Subject interface public: virtual ~Subject(); virtual void *Attach(Observer *observer) { m_observers.Add(observer); } virtual void *Detach(Observer *observer) { m_observers.Remove(observer); } void Notify() { ListIterator it(m_observers); for (it.First(); !it.IsDone(); it.Next()) { it.CurrentItem()-\u0026gt;Update(this); } } protected: Subject(); List m_observers; } class Observer { // Observer interface public: virtual ~Object(); virtual void Update(Subject *changedSubject) = 0; protected: Observer(); }; 自動で通知といっても、どこかで Subject#Notify() を呼ばなきゃならないのだけど。 (20) State パターン オブジェクトの状態を State オブジェクトとして表現し、それぞれの状態における振る舞いを定義する。State クラスのサブクラスを定義することによって、新たな状態の追加を柔軟に行える。 実装イメージ class Context { public: Context() : m_pState(new ConcreteState1()) {} virtual Context() { delete m_pState; } void Request() { // 現在の状態に応じた処理を行う。中で状態が変化することもある。 m_pState-\u0026gt;Handle(this); } private: friend class State; // State オブジェクトにだけ ChangeState() を許可 void ChangeState(State *pState) { delete m_pState; m_pState = pState; } State *m_pState; }; class State { public: virtual Handle(Context *pContext) = 0; }; class ConcreteState1 : public State { public: virtual Handle(Context *pContext) { cout \u0026lt;\u0026lt; \u0026#34;state1\u0026#34; \u0026lt;\u0026lt; endl; pContext-\u0026gt;ChangeState(new ConcreteState2()); } }; class ConcreteState2 : public State { public: virtual Handle(Context *pContext) { cout \u0026lt;\u0026lt; \u0026#34;state2\u0026#34; \u0026lt;\u0026lt; endl; pContext-\u0026gt;ChangeState(new ConcreteState1()); } } (21) Strategy パターン アルゴリズムをオブジェクトにカプセル化し、自由に取り替えられるようにする。多態性の基本的な考え方。委譲によりアルゴリズムを切り替える。 実装イメージ class TextBox { // Strategy を利用するクラス public: bool IsValid() { // このテキストボックスに入力された値が正しいかをチェック。 // チェックの仕組み (Strategy) は自由に入れ換えられる。 return m_pValidator-\u0026gt;IsValid(GetText()); } ... private: Strategy *m_pValidator; }; class Validator { // テキストのフォーマットが正しいかを検証する Strategy public: virtual bool IsValid(string text) = 0; }; class PostalCodeValidator : public Validator { public: virtual bool IsValid(string text) { ... text が郵便番号として正しいなら true を返す } }; (22) Template Method パターン メソッドの呼び出し方法（アルゴリズムの大枠）を template method として定義し、各メソッド (primitive operations) の実装をサブクラスで行えるようにする。 アルゴリズムの不変な部分、変化する部分を明確に分けることができる。 実装イメージ class AbstractClass { public: // TemplateMethod 内でメソッドの呼び出し順序（アルゴリズム）が固定される void TemplateMethod() { PrimitiveOperation1(); PrimitiveOperation2(); ... } protected: virtual void PrimitiveOperation1() = 0; virtual void PrimitiveOperation2() = 0; }; class ConcreteClass : public AbstractClass { protected: // TemplateMethod の中で呼ばれる各ステップの実装はサブクラスで定義できる virtual void PrimitiveOperation1() { ... } virtual void PrimitiveOperation2() { ... } }; abstract メソッドを定義した時点で、ほぼこのパターンになる。 Strategy パターンが委譲によってアルゴリズムの一部を変更するのに対し、Template Method パターンは継承によってアルゴリズムの一部を変更する。 (23) Visitor パターン ある構文をあらわしたオブジェクト構造（ツリーなど）を意味解釈するために、意味解釈するためのオブジェクト (Visitor) を各オブジェクト (Element) に巡回させ、その過程で意味を解釈していく。オブジェクト構造を解釈するためのオペレーションを、各 Element に散らばらせることなく、ひとつの Visitor オブジェクトにまとめられる。 オブジェクト構造を構成する各 Element は、巡回してきた Visitor を Accept() メソッドで処理する。ここでは単純に自分自身を Visitor に渡し、意味解釈を Visitor オブジェクトに委譲すればよい。 void ElementA::Accept(Visitor\u0026amp; visitor) { visitor.VisitElementA(this); // 意味解釈は Visitor に任せる } オブジェクト構造を別の方法で意味解釈したい場合は、Visitor のサブクラスを新たに作成し、上記の例における VisitElementA() などを適切に実装するだけでよい。この時、各 Element の実装を変更する必要はない。 Interpreter パターンでは、オブジェクト構造自体に意味解釈する機能を持たせるが、さらに Visitor パターンを適用することで、いろんな方法で意味解釈できるようになる。 ConcreteVisitor を実装するのは、XML の SAX Parser を実装するのに似てるかな。"
},
{
url: "/p/xp8o5k2/",
title: "Next.js から AWS DynamoDB にアクセスする",
date: "2021-11-02T00:00:00Z",
body: "Next.js から AWS DynamoDB にアクセスする 何をするか？ Next.js アプリの API routes (pages/*.ts) や、getServerSideProps などのサーバーサイドで実行される関数では、通常の Node.js モジュールを使うことができるため、AWS の DynamoDB からデータを取得する、といったことも自由に行えます。 ここでは、Next.js の API routes 機能を使って、DynamoDB から情報を取得する Web API を作ってみます。 具体的には次のようなことをします。 テスト用の DynamoDB テーブル (Books) を作成する Books テーブルを参照するためのアクセスキー（IAM ユーザー）を作成する Next.js の API routes の実装 (pages/api/books.ts) を行う AWS SDK を使って DynamoDB から情報を取得する /api/books/001 のような URL にアクセスすると JSON データを返す アクセスキーは環境変数で設定する ☝️ アクセスキーを使った AWS リソースのアクセスについて AWS のアクセスキーは、IAM ユーザーに設定されるものであり、このアクセスキーが漏洩すると、そのユーザーの権限で何でもできる ということになります。 そのため、アクセスキーを使用するときは、IAM ユーザーの権限を適切に絞ることが大切で、そもそも本当に必要なケースでのみアクセスキーを使うようにすべきです。 アクセスキーが必要になるのは、AWS の外から AWS リソースに直接アクセスするケースです。 例えば、AWS CLI のコマンドで AWS の制御を行う場合や、今回の例のように AWS 外のサーバーから AWS へアクセスするようなケースです。 逆に、AWS 内の世界でのやりとりは、IAM ロールを使ってアクセス権を付けるのが常套手段です。 例えば、AWS App Runner 上で Next.js アプリを動かすのであれば、そこに IAM ロールを割り当てれれば、適切な AWS リソースに自由にアクセスできます（もちろん、サーバーサイドで実行される関数コードに限りますが）。 API Gateway (REST API) や AppSync (GraphQL API) に IAM ロールを割り当てれば、バックエンドの Lambda 関数に自由にアクセスできます。 DynamoDB のテーブルを作成する ここでは、テスト用の DynamoDB テーブルとして Books テーブルを作成します。 プライマリキーとして BookId というパーティションキーだけを持つシンプルなテーブルです。 既存のテーブルがあればそちらを使っても構いません。 ここでは、AWS CLI を使ってサクッと作ってしまいますが、本格的なプロダクト用に作成するときは、CDK や Terraform などを使ってリソースの生成を自動化しましょう。 手作業でやるなら CLI よりも DynamoDB の マネージドコンソール を使った方が楽かもしれません。 Books テーブルの作成 $ aws dynamodb create-table --table-name Books \\ --attribute-definitions AttributeName=BookId,AttributeType=S \\ --key-schema AttributeName=BookId,KeyType=HASH \\ --billing-mode PAY_PER_REQUEST テーブルができたら、適当にアイテムを追加しておきます。 Books テーブルにアイテムを追加 $ aws dynamodb put-item --table-name Books --item \u0026#39;{\u0026#34;BookId\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;001\u0026#34;}, \u0026#34;Title\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;Title-1\u0026#34;}}\u0026#39; $ aws dynamodb put-item --table-name Books --item \u0026#39;{\u0026#34;BookId\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;002\u0026#34;}, \u0026#34;Title\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;Title-2\u0026#34;}}\u0026#39; $ aws dynamodb put-item --table-name Books --item \u0026#39;{\u0026#34;BookId\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;003\u0026#34;}, \u0026#34;Title\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;Title-3\u0026#34;}}\u0026#39; 最後に、アイテムが追加されているか確認しておきます。 $ aws dynamodb scan --table-name Books --output yaml 実行結果 ConsumedCapacity: null Count: 3 Items: - BookId: S: \u0026#39;001\u0026#39; Title: S: Title-1 - BookId: S: \u0026#39;003\u0026#39; Title: S: Title-3 - BookId: S: \u0026#39;002\u0026#39; Title: S: Title-2 ScannedCount: 3 参考: DynamoDB をコマンドライン (CLI) で操作する IAM ユーザーとアクセスキーを作成する AWS の各種サービスにアクセスするためのアクセスキーが欲しいときは、まず IAM ユーザーを作成して、その IAM ユーザー用にアクセスキーを生成する、という手順を踏みます。 このあたりは、サービス側でアクセスキーを作ることのできる Azure とは違って、ややとっつきにくいかもしれません。 そして、そのアクセスキーの権限は、IAM ユーザーに設定された権限と等しいものになります。 ここでは、AWS CLI を使って、IAM ユーザーの作成、アクセスキーの作成、権限の設定を行います（もちろん AWS コンソールを使っても OK です）。 DynamoDB の Books テーブルにアクセスするための IAM ユーザーなので、ユーザー名は user-for-books としておきます。 このユーザーには、AWS コンソールにサインインするためのパスワードは設定せず、本当にアクセスキーを提供するためだけのユーザーという扱いにします。 IAM ユーザーとアクセスキーの作成 $ aws iam create-user --user-name user-for-books $ aws iam create-access-key --user-name user-for-books このとき、次のようなアクセスキー ID とシークレットアクセスキーが表示されるのでメモしておきます。 AccessKeyId: AKIAQXINMCQAELHU2GXY SecretAccessKey: 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 DynamoDB の Books テーブルの読み取りアクセスを許可するためのインラインポリシーを IAM ユーザーに追加します。 IAM ユーザーにインラインポリシーを追加 $ aws iam put-user-policy --user-name user-for-books \\ --policy-name dynamo-books-read --policy-document file://policy.json policy.json（入力ファイル） { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;ReadOnBooks\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;dynamodb:GetItem\u0026#34;, \u0026#34;dynamodb:BatchGetItem\u0026#34;, \u0026#34;dynamodb:DescribeTable\u0026#34;, \u0026#34;dynamodb:Query\u0026#34;, \u0026#34;dynamodb:Scan\u0026#34;, \u0026#34;dynamodb:ConditionCheckItem\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:dynamodb:ap-northeast-1:123456789012:table/Books\u0026#34; } ] } Resource のところで指定するテーブル ARN は、下記のコマンドで確認できます。 $ aws dynamodb describe-table --table-name Books --query Table.TableArn インラインポリシーがちゃんと設定されているかは、次のようなコマンドで確認できます。 $ aws iam list-user-policies --user-name user-for-books $ aws iam get-user-policy --user-name user-for-books \\ --policy-name dynamo-books-read 参考: AWS IAM の設定をコマンドライン (CLI) で行う 参考: DynamoDB 用のポリシー設定例 Next.js に Web API を実装する まず、Web API の実装コードから AWS のアクセスキーを参照できるように、環境変数を設定しておきます。 ここでは、プロジェクトのルートに次のような .env.local ファイルを作成して環境変数を設定することにします。 このファイルは Git にはコミットしないように注意 してください。 Vercel などの環境にデプロイする場合は、Vercel サービス側の環境変数として設定してください。 .env.local BOOKS_ACCESS_KEY_ID=AKIAQXINMCQAELHU2GXY BOOKS_SECRET_ACCESS_KEY=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 DynamoDB のアクセスのために、AWS SDK ver.3 の DynamoDBClient クラスを使うので、次のようにインストールしておきます。 # npm を使う場合 $ npm install @aws-sdk/client-dynamodb # yarn を使う場合 $ yarn add @aws-sdk/client-dynamodb 下記は、DynamoDB の Books テーブルからアイテムを 1 つ取得する fetchBook 関数の実装例です。 AWS のアクセスキーは環境変数から取得しています。 src/libs/booksUtil.ts import { DynamoDBClient, GetItemCommand } from \u0026#39;@aws-sdk/client-dynamodb\u0026#39; const dbClient = new DynamoDBClient({ credentials: { accessKeyId: process.env.BOOKS_ACCESS_KEY_ID as string, secretAccessKey: process.env.BOOKS_SECRET_ACCESS_KEY as string, }, }) export type Book = { id: string title: string } // アイテムを取得する export async function fetchBook(bookId: string): Promise\u0026lt;Book | undefined\u0026gt; { const command = new GetItemCommand({ TableName: \u0026#39;Books\u0026#39;, Key: { BookId: { S: bookId } }, }) const output = await dbClient.send(command) const item = output.Item if (item == undefined) return undefined return { id: item[\u0026#39;BookId\u0026#39;][\u0026#39;S\u0026#39;], title: item[\u0026#39;Title\u0026#39;][\u0026#39;S\u0026#39;], } as Book } あとは、Web API 用のコードを、上記の関数を使って実装します。 src/pages/api/books/[bookId].ts import type { NextApiRequest, NextApiResponse } from \u0026#39;next\u0026#39; import { Book, fetchBook } from \u0026#39;../../../libs/booksUtil\u0026#39; // API のレスポンス型 export type BooksApiResponse = { book?: Book debugMessage?: string } export default async function booksApi( req: NextApiRequest, res: NextApiResponse\u0026lt;BooksApiResponse\u0026gt; ): Promise\u0026lt;void\u0026gt; { const id = req.query.bookId as string const book = await fetchBook(id) if (book) { res.status(200).json({ book }) } else { res.status(400).json({ debugMessage: `Book [id=${id}] not found` }) } } これで、http://localhost:3000/api/books/001 などにアクセスすると、次のような JSON データが返ってくるようになります。 {\u0026#34;book\u0026#34;:{\u0026#34;id\u0026#34;:\u0026#34;001\u0026#34;,\u0026#34;title\u0026#34;:\u0026#34;Title-1\u0026#34;}} React コンポーネントの中から、この Web API を呼び出す部分は省略しますが、useSWR フックを使うとお手軽に実装できます。 参考: Next.js で環境変数を扱う (.env, NEXT_PUBLIC, NODE_ENV) 参考: Next.js の API Routes 機能で Web API を作成する 参考: DynamoDB を Node.js で操作する（SDK ver.3 の場合） 参考: React フック: useSWR でデータフェッチ 後始末 上記で使ったひととおりの AWS リソースを削除しておきます。 IAM ユーザーの削除 アクセスキー用に作成した IAM ユーザー (user-for-books) を削除します。 IAM ユーザーを削除するときは、先にそれに付随する情報（インラインポリシーやアクセスキーなど）を削除する必要があります。 IAM ユーザーのインラインポリシーを削除 $ aws iam delete-user-policy --user-name user-for-books \\ --policy-name dynamo-books-read IAM ユーザーのアクセスキーを削除 # 下記でアクセスキー ID を確認して $ aws iam list-access-keys --user-name user-for-books # 次のように削除 $ aws iam delete-access-key --user-name user-for-books \\ --access-key-id AKIAQXINMCQAELHU2GXY IAM ユーザー自体を削除 $ aws iam delete-user --user-name user-for-books DynamoDB テーブルの削除 DynamoDB の Books テーブルを削除します。 こちらは、テーブルにアイテムが格納されていても問答無用で削除されてしまうので、気をつけて実行しないといけません。 DynamoDB テーブル自体を削除 $ aws dynamodb delete-table --table-name Books これで、スッキリ、サッパリ！"
},
{
url: "/p/3mx8hr2/",
title: "Amazon Cognito (2) サインイン後に AWS リソースへのアクセス権限を与える (Cognito Identity Pool)",
date: "2021-05-31T00:00:00Z",
body: "Amazon Cognito (2) サインイン後に AWS リソースへのアクセス権限を与える (Cognito Identity Pool) 何をやるか？ 参考: Amazon Cognito (1) サインイン可能な Web サイトを作る (with React) 上記記事では、Cognito のユーザープール機能を使って、Web サイトにサインイン（サインアップ）機能を付けるところまでを説明しています。 ここでは、さらに Cognito の ID プール機能を使い、認証後のユーザーに AWS リソースへのアクセス権限を割り当てる方法を説明します。 Amazon Cognito サービスは、大きくわけて下記の 2 つの機能を提供しています。 User Pool \u0026hellip; 認証 (Authentication) Identity Pool \u0026hellip; 認証後のユーザーに対する 認可 (Authorization) 「認証」の方は、Cognito の User Pool を使う方法以外にも、Amazon、Facebook、Google など、様々な認証サービス（これらを 認証プロバイダー (IdP) と呼びます）を使用することができますが、ここでは Cognito の User Pool でユーザー認証することを前提とします。 ここから先の説明は、「認可」に関しての説明になります。 Cognito Identity Pool は、何らかの認証プロバイダーによる認証済みユーザーに対して、IAM ロールを割り当てることによって、任意の AWS リソースへのアクセスを許可します。 また、認証していないユーザー（いわゆるゲストユーザー）に対して、リードオンリーな IAM ロールを割り当てたり、User Pool の方でユーザーをグループに登録しておいて、そのグループの IAM ロールをアクセス権限として割り当てるといったことも可能です。 ID プール（フェデレーティッドアイデンティティ） Cognito の ID プールを使うと、各種認証プロバイダーサービス（Cognito の場合は「ユーザープール」）でサインインしたユーザーに対して、AWS リソース（API Gateway や DynamoDB など）へのアクセス権限を割り当てることができます。 ざっくり言うと、ID プールは、ユーザーに対して IAM ロールを割り当てる仕組み です。 ID プールは次のように作成します。 Cognito のマネージメントコンソールにアクセス ID プールの管理 → 新しいIDプールの作成 を選択します ユーザー作成時の条件 (Attribute) などを設定して作成ボタンを押します ID プール名は自由に入力してください。 認証されていない ID というところを有効にすると、認証していないユーザー（ゲストユーザー）に何らかの AWS リソースアクセス権限（IAM ロール）を与えることができます。 今回は、サインイン済みのユーザーにだけアクセス権限を与えたいので、認証プロバイダー のところで、作成した Cognito ユーザープールの ID（例: ap-northeast-1_w4Lb7OMrk）と、アプリクライアント ID（例: 7egbq6mnk61udtpa0v7qr5u96o）を設定して、プールの作成 ボタンを押して先へ進みます。 すると、具体的にどのような IAM ロールを与えるかを設定する画面が表示されるので、適切なポリシードキュメント（アクセス権限）を記述して 許可 ボタンを押します（後から IAM のマネージメントコンソールから修正可能です）。 ちなみに、デフォルトで作成される IAM ロールのポリシー設定は次のような感じになっています。 S3 や DynamoDB などのリソースにアクセスできるようにするには、ここにポリシーステートメントを追加していく必要があります。 認証済みユーザーのポリシードキュメント { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;mobileanalytics:PutEvents\u0026#34;, \u0026#34;cognito-sync:*\u0026#34;, \u0026#34;cognito-identity:*\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;*\u0026#34; ] } ] } 認証していないユーザーのポリシードキュメント { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;mobileanalytics:PutEvents\u0026#34;, \u0026#34;cognito-sync:*\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;*\u0026#34; ] } ] } 例えば、ある S3 バケットの内容を読み取れるようにしたい場合は、Statement プロパティの配列に、次のようなステートメントを追加します。 { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:ListBucket\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::temp-123456789012-bucket-1\u0026#34;, \u0026#34;arn:aws:s3:::temp-123456789012-bucket-1/*\u0026#34; ] } 無事 ID プールの作成に成功すると、下記のように ID プールの ID を確認することができます。 この ID は、プログラム内で指定する必要があるので控えておきます。 認可処理の実装 Cognito ID プールによる認可処理は、Amplify SDK (aws-amplify) を使って認証を済ませると自動的に行われます。 React アプリなどで認証処理を行う方法は、こちらの記事 で説明していますが、ID プールによる認可処理まで自動実行するには、Amplify.configure() で渡すコンフィグ情報に、identityPoolId を指定しておく必要があります。 ここに指定する値は、上記で作成した ID プールの ID（例: ap-northeast-1:12e74c09-fe09-e845-f48e-929364272fb）です。 src/pages/_app.tsx（抜粋） import { Amplify } from \u0026#39;aws-amplify\u0026#39; const amplifyConfig = { Auth: { region: \u0026#39;ap-northeast-1\u0026#39;, userPoolId: \u0026#39;ap-northeast-1_w4Lb7OMrk\u0026#39;, userPoolWebClientId: \u0026#39;7egbq6mnk61udtpa0v7qr5u96o\u0026#39;, // AWS 認可処理にはこの ID プールの指定が必要↓ identityPoolId: \u0026#39;ap-northeast-1:12e74c09-fe09-e845-f48e-929364272fb\u0026#39;, }, } Amplify.configure(amplifyConfig) React 上での認証処理は、@aws-amplify/ui-react モジュールが提供する AmplifyAuthenticator コンポーネントなどで行うと簡単です。 認証後に表示するページで、次のようなコードを実行すると、アクセストークンの情報を取得できていることが分かります。 src/pages/index.tsx import React from \u0026#39;react\u0026#39; import { Auth } from \u0026#39;aws-amplify\u0026#39; const getAuth: () =\u0026gt; void = async () =\u0026gt; { try { const cred = await Auth.currentCredentials(); console.log(cred.authenticated) // true console.log(cred.accessKeyId) // P4TAUTOAEOY5ASIAVTXA console.log(cred.secretAccessKey) // b3jXGfXXfI7toiiH6WAVXqRyeFdfnvFC58Lo+6iD console.log(cred.sessionToken) // ...長大... } catch (e) { console.error(e) } } const IndexPage: React.FC = () =\u0026gt; { getAuth() return \u0026lt;div\u0026gt;Hello\u0026lt;/div\u0026gt; } あとは任意の AWS SDK（@aws-sdk/client-s3 など）を使って AWS リソースへアクセスすることができます。 例えば、次のサンプルコードでは、S3 バケット内のオブジェクト名（キー）の一覧を取得しています。 ちなみに、React (Next.js) アプリからデータフェッチを行うときは、この例のように useSWR フックを使う方法 が常套手段です。 import useSWR from \u0026#39;swr\u0026#39; import { Auth } from \u0026#39;aws-amplify\u0026#39; import { S3Client, ListObjectsV2Command } from \u0026#39;@aws-sdk/client-s3\u0026#39; type BucketData = { keys: string[] } // S3 バケット内のオブジェクトの一覧を取得する async function fetchS3Objects(bucket: string): Promise\u0026lt;BucketData\u0026gt; { try { const s3 = new S3Client({ region: \u0026#39;ap-northeast-1\u0026#39;, credentials: await Auth.currentCredentials(), }) const output = await s3.send( new ListObjectsV2Command({ Bucket: bucket, MaxKeys: 10, // 最大10件まで取得 }) ) if (!output.Contents) return [] return { keys: output.Contents.map((c) =\u0026gt; c.Key!) } } catch (err) { throw err } } export const ObjectList: React.FC = () =\u0026gt; { const { data, error } = useSWR\u0026lt;BucketData, Error\u0026gt;( \u0026#39;temp-123456789012-bucket-1\u0026#39;, fetchS3Objects, ) if (error) return \u0026lt;div\u0026gt;Error: {error.message}\u0026lt;/div\u0026gt; if (!data) return \u0026lt;div\u0026gt;Loading...\u0026lt;/div\u0026gt; return ( \u0026lt;ul\u0026gt; {data.keys.map((k) =\u0026gt; \u0026lt;li key={k}\u0026gt;{k}\u0026lt;/li\u0026gt;)} \u0026lt;/ul\u0026gt; ) } Web ブラウザ上の JavaScript で S3 バケットにアクセスしようとすると、デフォルトではクロスドメインアクセスのため CORS policy エラーになります。 S3 バケットの CORS 設定をしておく必要があります。 S3 アクセス時の CORS policy エラー Access to fetch at \u0026#39;https://temp-123456789012-bucket-1.s3.ap-northeast-1.amazonaws.com/?list-type=2\u0026amp;max-keys=10\u0026#39; from origin \u0026#39;http://localhost:3000\u0026#39; has been blocked by CORS policy: ... Amazon S3 のマネージメントコンソール で対象のバケットを選択し、アクセス許可 のタブの下の方に、Cross-Origin Resource Sharing (CORS) という項目があるので、そこに次のような感じで入力すれば、クロスドメインアクセスができるようになります。 S3 バケットの CORS 設定 [ { \u0026#34;AllowedHeaders\u0026#34;: [ \u0026#34;*\u0026#34; ], \u0026#34;AllowedMethods\u0026#34;: [ \u0026#34;HEAD\u0026#34;, \u0026#34;GET\u0026#34;, \u0026#34;PUT\u0026#34;, \u0026#34;POST\u0026#34;, \u0026#34;DELETE\u0026#34; ], \u0026#34;AllowedOrigins\u0026#34;: [ \u0026#34;*\u0026#34; ], \u0026#34;ExposeHeaders\u0026#34;: [ \u0026#34;ETag\u0026#34; ] } ] ここでは、まずはアクセスできることを確認するために、すべてのドメインからの CORS アクセス許可をしていますが、実際には AllowdOrigins のところでドメイン名を絞り込んでください。 ドメイン名の指定では、一箇所でワイルドカード (*) を使えますが、http や https などのスキーム指定は必須です（ポート番号 80 以外の場合はポート番号も必須です）。 { // ... \u0026#34;AllowedOrigins\u0026#34;: [ \u0026#34;http://localhost:*\u0026#34;, \u0026#34;https://example.com\u0026#34;, \u0026#34;https://*.example.com\u0026#34;, ], // ... } これでアクセスして 403 Forbidden (Access Denied) エラーが出るようでしたら、おそらく IAM Role のポリシーで S3 アクセスが許可できていません。 Role のポリシー設定を確認してください。 ユーザーが所属するグループに応じてアクセス権限を割り当てる ユーザーの種類によって AWS リソースへのアクセス権限を細かく制御したいということはよくあります。 例えば、管理者ユーザーと一般ユーザーを分けたり、チームごとに参照可能なリソースを制御したいという場合です。 これを実現するには、Cognito ユーザープールの グループ 機能を使用します。 グループは、Cognito ユーザープールのコンソール から簡単に作成できます。 ユーザーは複数のグループに所属することができるため、その場合にどの IAM Role を優先的に適用するかを、優先順位 の欄で設定しておくことができます（0 が最優先）。 グループを作成したら、任意のユーザーをグループに追加してください。 次に、Cognito ID プール（フェデレーテッドアイデンティティ）のコンソール から、認可に使用する ID プールを選択し、認証後に上記グループの IAM Role を適用するように設定します。 ID プールの編集画面を開き、認証プロバイダ の 認証されたロールの選択 の項目で、トークンからロールを選択する を選択して、変更の保存 ボタンを押します。 これで、Cognito ユーザープールによって認証されたユーザーに対して、グループに設定した IAM Role が割り当てられるようになります。 トークンからロールを選択する とか、分かりにくい表現ですが、Cognito では内部的に JSON Web Token を使った処理が行われていて、その過程でグループ側の IAM Role を割り当てる、といった感じのことを示しているようです。 なお、IAM Role の優先順位が解決できない場合や、どのグループにも属していないユーザーに対しては、これまで通り、「認証されたロール」で設定した IAM Role が割り当てられます。 参考 Amazon Cognito (1) サインイン可能な Web サイトを作る (Cognito User Pool)"
},
{
url: "/p/seq2cmw/",
title: "Next.js でコンポーネント単位の CSS を作成する (CSS Modules)",
date: "2021-05-06T00:00:00Z",
body: "Next.js でコンポーネント単位の CSS を作成する (CSS Modules) CSS Modules とは CSS Modules は、コンポーネント（ファイル）単位で CSS ファイルを分けて管理する仕組みです（これ自体は Next.js の仕組みではありません）。 CSS の名前空間がコンポーネントごとに分離されるため、シンプルな CSS クラス名を付けても名前がコンフリクトする心配がありません。 Next.js は標準で CSS Modules の仕組みをサポートしており、CSS ファイルの拡張子を .module.css にするだけで、各コンポーネントの実装ファイルから簡単にインポートすることができます。 Next.js で CSS Modules 機能を使う Next.js で特定のコンポーネント用に CSS ファイルを用意するときは、そのコンポーネントと同じディレクトリに .module.css という拡張子を持つファイルを作成します。 この拡張子は、Next.js で CSS Modules の仕組みを使うときのルールです。 ここでは、警告メッセージを表示する Alert コンポーネント用の Alert.module.css を作成してみます。 といっても、普通に CSS ファイルを記述するだけです。 グローバルに適用する CSS ファイルと異なるのは、Alert コンポーネント用のスタイル定義しか含まれていないことです。 components/Alert.module.css .box { margin: 1em; padding: 0.5em; background: red; color: white; font-weight: bolder; border-radius: 0.5em; } この CSS ファイルを Alert コンポーネントから使用するには、次のようにインポートします。 components/Alert.tsx import React from \u0026#39;react\u0026#39; import styles from \u0026#39;./Alert.module.css\u0026#39; type Props = { message: string; } export const Alert: React.FC\u0026lt;Props\u0026gt; = ({ message }) =\u0026gt; { return ( \u0026lt;div className={styles.box}\u0026gt;{message}\u0026lt;/div\u0026gt; ) } 上記の例では .css ファイルを使いましたが、Next.js は Sass を標準サポート しているので、.scss ファイルも同様にインポートすることができます。 TypeScript を使っているときに警告が出る場合 TypeScript を使ってコンポーネントを実装している場合、css ファイルをインポートしている部分で次のような警告が出ることがあります。 Cannot find module \u0026#39;./Alert.module.css\u0026#39; or its corresponding type declarations. これは、.css ファイルの内容を styles オブジェクト経由で参照するときに、型情報が存在しないよという警告です。 この警告を抑制するには、プロジェクトのルートにある型情報ファイル (next-env.d.ts) に次のように追記します。 next-env.d.ts /// \u0026lt;reference types=\u0026#34;next\u0026#34; /\u0026gt; /// \u0026lt;reference types=\u0026#34;next/types/global\u0026#34; /\u0026gt; declare module \u0026#39;*.css\u0026#39; { const styles: { [className: string]: string }; export default styles; } declare module \u0026#39;*.scss\u0026#39; { const styles: { [className: string]: string }; export default styles; } この記述により、TypeScript コンパイラに対して、「styles オブジェクトは文字列型のパラメーターを持っているよ」ということを知らせることができます。 ここでは、将来的に Sass を導入 したときのために、.scss ファイルにも同様の型情報を追加しています。 参考リンク 既存の JavaScript ライブラリに型情報を追加する（.d.ts ファイル）"
},
{
url: "/p/rdq3ep2/",
title: "Next.js のダイナミックルーティング機能を利用する (getStaticPaths, getStaticProps, getServerSideProps)",
date: "2021-05-05T00:00:00Z",
body: "Next.js のダイナミックルーティング機能を利用する (getStaticPaths, getStaticProps, getServerSideProps) ダイナミックルーティングとは Next.js では、pages/books/[id].tsx のようなファイル名でページを作成すると、1 つのファイルで、 /books/001 /books/002 /books/003 のようなパス (URL) によるアクセスをハンドルできます。 これを ダイナミックルーティング (Dynamic Routes) 機能と呼びます。 Next.js のページコンポーネント (/pages/xxx.tsx) は、そのページのエントリポイント（ルートコンポーネント）となるため、通常の React コンポーネントとは違って、上位のコンポーネントから props 情報を渡すことができません。 そこで Next.js では、ページコンポーネントの実装ファイル内で getStaticProps という関数を定義することで、ページコンポーネントに渡す props 情報を生成できるようにしています。 getStaticProps 内では、上記のような URL パラメータ情報（/books/[id] の id の部分の値）を取り出して、それを元に props 情報を生成できます。 この仕組みによって、Next.js のページコンポーネントは、1 つの .tsx ファイルで、複数のページ (.html) を生成できるようになっています。 ダイナミックルーティングの実装（SSG の場合） 静的ジェネレーション (SSG: Static Generation)、つまり Web サイトのビルド時にすべての HTML ファイルを生成してしまうには、あらかじめどのようなパラメーター（上記の例では id）でのアクセスが行われるかを把握した上で、各ページの内容を生成する必要があります。 これを実現するには、ページコンポーネントの実装ファイル (pages/*.tsx) で、次のような async 関数を実装して export します。 getStaticPaths 関数 URL のパラメーター部分（上記の例では id）で指定可能な値を返すように実装します。言い換えると、プリビルドすべきページの一覧情報を Next.js に教えてあげるための実装です。この関数は通常、Web サイトのビルド時にだけ実行されますが、開発サーバー (next dev) 使用時はアクセス毎に呼び出されることに注意してください。 getStaticProps 関数 指定されたパラメーターに対応するデータを返すように実装します。この値がページコンポーネントに引数として渡されます。この関数は通常、Web サイトのビルド時にだけ実行されますが、getStaticPath の戻り値のプロパティ fallback を true、あるいは 'blocking' に設定した場合は、アクセス時に呼び出される可能性があります（後述のフォールバックの説明を参照）。 次の例では、/books/001、/books/002、/books/003 といった URL でアクセス可能な books/[id] ページを定義しています。 pages/books/[id].tsx import Head from \u0026#39;next/head\u0026#39; import React from \u0026#39;react\u0026#39; import { GetStaticPaths, GetStaticProps } from \u0026#39;next\u0026#39; // パスの構成要素を表す型 (/books/[id].tsx の id 部分など) // (Note) Params という名前にすると曖昧なので、アクセス時のパスから抽出する // 情報だということを示すために PathParams という名前にしています。 type PathParams = { id: string; } // ページコンポーネントに渡される props の型 // (Note) ページコンポーネント用の props であることを意識するために、 // 一般的な Props ではなく、PageProps という名前にしています。 type PageProps = { title: string; author: string; } // 事前生成するページのパス（URL のパラメータ部分）のリストを返します。 // eslint-disable-next-line @typescript-eslint/require-await export const getStaticPaths: GetStaticPaths\u0026lt;PathParams\u0026gt; = async () =\u0026gt; { // /books/001、/books/002、/books/003 のページを事前生成するには、 // 次のように paths プロパティの値を設定して返します。 // 本来は id のリストを外部 API（getBookList など）で取得します。 return { paths: [ { params: { id: \u0026#39;001\u0026#39; } }, { params: { id: \u0026#39;002\u0026#39; } }, { params: { id: \u0026#39;003\u0026#39; } } ], fallback: false // 上記以外のパスでアクセスした場合は 404 ページにする } } // URL のパラメータ情報（プレースホルダー部分に指定された値）をもとに、 // ページコンポーネントに渡す props データを生成します。 // context.params プロパティでこれらのパラメータを参照できるので、 // その値に応じて props データを生成して返すように実装します。 // eslint-disable-next-line @typescript-eslint/require-await export const getStaticProps: GetStaticProps\u0026lt;PageProps\u0026gt; = async context =\u0026gt; { // ファイル名が [id].tsx なので id パラメーターを取り出すことができる const { id } = context.params as PathParams // 本来はここで getBook(id) のように API を呼び出してデータを取得する const props: PageProps = { title: `Title-${id}`, author: `Author-${id}` } // ページコンポーネントに渡す PageProps オブジェクトを // props プロパティに設定したオブジェクトを返す return { props } } // ページコンポーネントの実装 const BookPage: React.FC\u0026lt;PageProps\u0026gt; = ({ title, author }: PageProps) =\u0026gt; { return \u0026lt;\u0026gt; \u0026lt;Head\u0026gt; \u0026lt;title\u0026gt;{title} の詳細ページ\u0026lt;/title\u0026gt; \u0026lt;/Head\u0026gt; \u0026lt;ul\u0026gt; \u0026lt;li\u0026gt;タイトル: {title}\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;著者: {author}\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/\u0026gt; } export default BookPage フォールバック制御 fallback プロパティ 上記の例では、getStaticPaths 関数の戻り値の fallback プロパティに false をセットしていますが、この値は、想定外のパラメーターを指定された場合のフォールバック方法 を設定するために使用します。 fallback: false paths プロパティで指定したパラメーター以外でのアクセス時に、404 ページ (pages/404.tsx) を返します。 fallback: true paths プロパティで指定したパラメーター以外でのアクセス時に、サーバーサイドで getStaticProps を呼び出して動的にページを生成します。それ以降のアクセスは、そのページを返します。この機能を利用する場合は、Next.js サーバーで Web サイトをホスティングしている必要があります（next export で HTML エクスポートした場合は動作しません）。サーバーサイドでのページ生成中は、Web ブラウザ側には瞬間的に「フォールバックページ」が表示されることになります。フォールバック表示中かどうかを判断するには、useRouter フックを利用して isFallback 情報を参照します（後述）。 fallback: 'blocking' true を指定した場合とほぼ同じですが、サーバーサイドでの HTML 生成が終わってから初めて Web ブラウザにレスポンスが返されるところが異なります（なのでブロッキングという名前になっています）。true を指定した場合は、フォールバック表示（Loading 表示など）を行うことができますが、'blocking' を指定した場合は、フォールバック表示は行えません（実装は楽ですがユーザーへのレスポンスが遅くなります）。 getStaticProps でデータを生成できないときの処理 このフォールバック機能を有効にしているとき（fallback: true あるいは fallback: 'blocking' のとき）、getStaticProps は Web サイトへのアクセス時に、未知のパラメーター（上記の例の場合は id の値）を伴って呼び出される可能性があります。 それに対応する props オブジェクト (PageProps) を生成できない場合は、次のいずれかの対応を行う必要があります。 データが空であることを示すオブジェクト（空オブジェクトとか）を返して、ページコンポーネント内で適切にハンドルする 404 コード（と 404 ページ）を返す（{ notFound: true } を返す） 別のパスにリダイレクトする（{ redirect: ... } を返す） 例えば、次の例では、対応する props オブジェクトを生成できない場合に、空のオブジェクト {} を返すように実装しています。 export const getStaticProps: GetStaticProps\u0026lt;PageProps | {}\u0026gt; = async context =\u0026gt; { // ... context.params.id に対応する props を提供できない場合 return { props: {} } } const BookPage: React.FC\u0026lt;PageProps\u0026gt; = ({ title, author }: PageProps) =\u0026gt; { if (title == undefined) { return \u0026lt;div\u0026gt;NOT FOUND\u0026lt;/div\u0026gt; } // ... } 潔く、404 ページを表示するのであれば、getStaticProps 関数の戻り値として { notFound: true } を返すだけで OK です。 export const getStaticProps: GetStaticProps\u0026lt;PageProps\u0026gt; = async context =\u0026gt; { // ... props を提供できない場合 return { notFound: true } } ☝️ ワンポイント getStaticPaths の戻り値で fallback: false と設定している場合は、上記のような分岐処理は必要ありません。 パラメーターとして未知の値が指定された場合に、自動的に 404 が返されます（getStaticProps が呼び出されることがありません）。 不正なパラメーターを指定された時に別の URL へリダイレクトしてしまいたい場合は、戻り値で redirect プロパティを指定します。 return { redirect: { destination: \u0026#39;/\u0026#39;, permanent: false } } フォールバック時のキャッシュの有効時間 フォールバックを有効にしているとき (fallback: true)、未知のパラメーターでページアクセスがあると、Next.js サーバー側で getStaticProps 関数が呼び出されて、動的にページ生成が行われます。 このとき、次回以降のアクセスのために、生成されたページはキャッシュされるわけですが、このキャッシュの有効期間は getStaticProps の戻り値の revalidate プロパティで秒単位で設定することができます。 export async function getStaticProps() { const res = await fetch(\u0026#39;https://.../posts\u0026#39;) const posts = await res.json() return { props: { posts }, revalidate: 60 * 10 // 10 分間キャッシュ } } 指定された秒数を経過後に、同じ URL にアクセスがあったときは、再度 getStaticProps が呼び出されて、最新データでページが再構築されます。 逆に、revalidate プロパティを設定しなかった場合は、最初に生成されたページがずーっと使われることになります。 revalidate プロパティを指定してサーバーサイドで定期的にページを再構築することを、Next.js では ISR: Incremental Static Regeneration と呼んでいます。 フォールバック時の一時表示（フォールバックページ） フォールバック有効時（fallback: true のとき）、サーバーサイドで動的なページ生成が行われている最中（getStaticProps 実行中）は、クライアント側には「フォールバックページ」が表示されることになります。 フォールバックページでは、パラメーターとして渡される props は空っぽになるので、代わりに適切な Loading 表示などを行う必要があります。 現在のページがフォールバック中であるかどうかを調べるには、useRouter フックを使って、isFallback の値をチェックします。 import { useRouter } from \u0026#39;next/router\u0026#39; // ページコンポーネントの実装 const BooksPage: React.FC\u0026lt;PageProps\u0026gt; = ({ title, author }: PageProps) =\u0026gt; { const router = useRouter() if (router.isFallback) { return \u0026lt;div\u0026gt;Loading...\u0026lt;/div\u0026gt; } // ... } 参考: Fallback pages - Next.js ダイナミックルーティングの実装（SSR の場合） すべてのページを Web サーバーへのアクセス時に動的に生成することを、サーバーサイドレンダリング (SSR: Server-side Rendering) と呼びます。 ダイナミックルーティング機能を SSR で使用するには、getStaticPaths 関数や getStaticProps 関数の代わりに次の関数を実装します。 getServerSideProps 関数 Web サーバー（Next.js サーバー）へのアクセス時に呼び出されます。context.params を参照すると URL で指定されたパラメーター (id) を取得できるので、それに対応するデータを返すように実装します。このデータはページコンポーネントの引数として渡されます。 実装方法は getStaticProps と同様です。 pages/books/[id].tsx（抜粋） export const getServerSideProps: GetServerSideProps\u0026lt;PageProps\u0026gt; = async context =\u0026gt; { const { id } = context.params as PathParams // 本来はここで getBook(id) のように API を呼び出してデータを取得する const props: PageProps = { title: `Title-${id}`, author: `Author-${id}` } return { props } } この関数は Web サーバーへのアクセス時に呼び出されるため、必ず Web サイトを Next.js サーバーでホスティングする必要があります（next export で静的な HTML ファイルとしてエクスポートした場合は動作しません）。 Next.js アプリのホスティングサービスとしては、Vercel が有名です。 SSR の仕組み (getServerSideProps) を使うと、Web ページへのアクセス時に毎回ページ生成が行われるため、クライアントへのレスポンスはどうしても遅くなります。 常に最新の情報を使ってページ生成を行う必要がないのであれば、できるだけ SSG: Static Generation によるレンダリングを行うべきです（getServerSideProps ではなく getStaticProps を実装する）。 getStaticProps でも、戻り値の revalidate プロパティを設定すれば、定期的にページを再構築できます (ISR)。"
},
{
url: "/p/dxamw8i/",
title: "Next.js で全ページ共通のレイアウトを定義する（Layout コンポーネント）",
date: "2021-05-04T00:00:00Z",
body: "Next.js で全ページ共通のレイアウトを定義する（Layout コンポーネント） Next.js で Web サイトに見た目の統一感を持たせるには、Layout コンポーネントを作成して、全てのページのベースレイアウトとして使用するようにします。 Next.js の仕組みというより、React コンポーネントを作成するときの慣例のようなもので、コンポーネントに Layout という名前を付けるのも多くの人がその名前を使っているだけです。 Layout コンポーネントを定義する Layout コンポーネントを定義するために、次のようなファイルをプロジェクト内に作成します。 {children} の部分には、Layout 要素以下に配置した子要素が展開されることになります。 components/Layout.tsx import { ReactNode } from \u0026#39;react\u0026#39; type Props = { children: ReactNode; } export function Layout({ children, ...props }: Props) { return \u0026lt;div {...props}\u0026gt;{children}\u0026lt;/div\u0026gt; } この Layout コンポーネントを使用するには、各ページのコンポーネント実装において、ルート要素として配置します。 pages/about.tsx import Head from \u0026#39;next/head\u0026#39; import Link from \u0026#39;next/link\u0026#39; import { Layout } from \u0026#39;../components/Layout\u0026#39; export default () =\u0026gt; ( \u0026lt;Layout\u0026gt; \u0026lt;Head\u0026gt; \u0026lt;title\u0026gt;About me\u0026lt;/title\u0026gt; \u0026lt;/Head\u0026gt; \u0026lt;h1\u0026gt;About me\u0026lt;/h1\u0026gt; \u0026lt;Link href=\u0026#34;/\u0026#34;\u0026gt; \u0026lt;a\u0026gt;Back to home\u0026lt;/a\u0026gt; \u0026lt;/Link\u0026gt; \u0026lt;/Layout\u0026gt; ) Layout コンポーネントに CSS を適用する styled-jsx で直接スタイルを埋め込む方法 styled-jsx の仕組み を使って、コンポーネントの定義内に直接 CSS を埋め込んでしまう方法です。 components/Layout.tsx import { ReactNode } from \u0026#39;react\u0026#39; type Props = { children: ReactNode; } export function Layout({ children, ...props }: Props) { return \u0026lt;\u0026gt; \u0026lt;style jsx\u0026gt;{` .container { max-width: 36rem; padding: 0 1rem; margin: 3rem auto 6rem; background: #eee; } `}\u0026lt;/style\u0026gt; \u0026lt;div className=\u0026#34;container\u0026#34; {...props}\u0026gt; {children} \u0026lt;/div\u0026gt; \u0026lt;/\u0026gt; } CSS Modules の仕組みで別ファイルにスタイル定義する方法 CSS Modules の仕組み で、Layout コンポーネント用の CSS ファイルを作成してインポートする方法です。 components/Layout.module.css .container { max-width: 36rem; padding: 0 1rem; margin: 3rem auto 6rem; background: #eee; } components/Layout.tsx import { ReactNode } from \u0026#39;react\u0026#39; import styles from \u0026#39;./Layout.module.css\u0026#39; type Props = { children: ReactNode; } export function Layout({ children, ...props }: Props) { return ( \u0026lt;div className={styles.container} {...props}\u0026gt; {children} \u0026lt;/div\u0026gt; ) } グローバルな CSS でスタイル定義する方法 サイト全体に CSS ファイルを適用して、その中で定義した CSS クラスを Layout コンポーネント内で参照するという方法もあります。 参考: すべてのページにグローバルな CSS を適用する (pages/_app.ts)"
},
{
url: "/p/2td9ouj/",
title: "AWS CLI: Windows で HOME 環境変数を設定したときに credentials が見つからなくなる場合の対処",
date: "2021-03-29T00:00:00Z",
body: "AWS CLI: Windows で HOME 環境変数を設定したときに credentials が見つからなくなる場合の対処 AWS CLI や AWS SDK が参照する共有認証ファイル（credentials および config）は、デフォルトでは下記のようなディレクトリになっています。 Linux の場合: ~/.aws/credentials Windows の場合: ~/%USERPROFILE%/.aws/credentials ところが、Windows を使用している場合に、環境変数 %HOME% を設定していると、CLI や SDK が %HOME%/.aws/credentials を見に行ったりして、credentials が見つからない系のエラーが出ることがあります。 一貫して %USERPROFILE% の方を見に行ってくれれればよいのですが、このあたりの振る舞いは結構ルーズなようです。 そこで、Windows のジャンクション機能 で、両方の .aws ディレクトリが同じディレクトリを指すようにしてみました。 ジャンクション生成のコマンドは、mklink /j \u0026lt;fromDir\u0026gt; \u0026lt;toDir\u0026gt; です。 ジャンクションで 2 つの .aws を同一にする C:\\\u0026gt; mklink /j %HOME%\\.aws %USERPROFILE%\\.aws C:\\home\\.aws \u0026lt;\u0026lt;===\u0026gt;\u0026gt; C:\\Users\\maku\\.aws のジャンクションが作成されました これで、%HOME%\\.aws ディレクトリを参照したときの実体として、%USERPROFILE%\\.aws ディレクトリが使われるようになります。 今のところ快適に動作しています。 ちなみに、ジャンクションを削除したいときは、ジャンクション元の %HOME%\\.aws ディレクトリを削除するだけです。 実体の方の %USERPROFILET%\\.aws は削除されないので安全です。"
},
{
url: "/p/m8kv8it/",
title: "Node.js で Amazon S3 を操作する (AWS SDK)",
date: "2021-03-21T00:00:00Z",
body: "Node.js で Amazon S3 を操作する (AWS SDK) ここでは、Node.js 用の AWS SDK を使って Amazon S3 を操作する方法を説明します。 TypeScript の基本的な環境構築 は終わっているものとします。 S3 用の Node.js SDK をインストールする AWS SDK version 3 の S3 用パッケージをインストールするには次のようにします。 ### npm の場合 $ npm install @aws-sdk/client-s3 ### yarn の場合 $ yarn add @aws-sdk/client-s3 これで、TypeScript コードから次のようにパッケージ内のクラスをインポートできるようになります。 main.ts import { S3Client, ListBucketsCommand } from \u0026#39;@aws-sdk/client-s3\u0026#39;; S3Client インスタンスの生成 AWS SDK で S3 の操作を行うには、S3Client オブジェクトを使って各種コマンドを送ります。 new S3Client(configuration: S3ClientConfig): S3Client S3Client コンストラクタには S3ClientConfig オブジェクトを渡すようになっており、接続情報などを指定できます。 空オブジェクト ({}) を渡すと、現在の環境の default プロファイルの設定が使用されます（~/.aws/config と ~/.aws/credentials に設定されたもの）。 // default プロファイルで接続する場合 const s3 = new S3Client({}); // 接続情報をカスタマイズする場合 const s3 = new S3Client({ region: \u0026#39;ap-northeast-1\u0026#39;, credentials: { accessKeyId: \u0026#39;QABCSCRHWJAKIAQXINMC\u0026#39;, secretAccessKey: \u0026#39;TTey3DVmbrILhTforDDa8kR6+SL+47htmoJ+Vimv\u0026#39;, }, }); 一時的にプロファイルを切り替えて実行したいときは、環境変数 AWS_PROFILE でプロファイル名を指定します。 例: プロファイルを admin に切り替えて実行 $ export AWS_PROFILE=admin $ npm start --silent 設定情報を確認する 次のようにすれば、S3Client のコンフィギュレーション情報として、どのような設定が使用されるかを確認できます。 main.ts import { S3Client } from \u0026#39;@aws-sdk/client-s3\u0026#39;; const s3 = new S3Client({}); (async () =\u0026gt; { console.log(await s3.config.credentials()); console.log(await s3.config.endpoint()); })(); 実行結果 { accessKeyId: \u0026#39;QAGPX77PNSAKIAQXINMC\u0026#39;, secretAccessKey: \u0026#39;FegIdbCW2JK7Jiv9yfZGGH3Q2KAmp2ufOANToPDX\u0026#39;, sessionToken: undefined } { hostname: \u0026#39;s3.ap-northeast-1.amazonaws.com\u0026#39;, port: undefined, protocol: \u0026#39;https:\u0026#39;, path: \u0026#39;/\u0026#39;, query: undefined } S3 バケットを作成する (CreateBucketCommand) 新しい S3 バケットを作成するには、S3Client#send() メソッドで CreateBucketCommand コマンドを送ります。 create-bucket.ts import { S3Client, CreateBucketCommand, } from \u0026#39;@aws-sdk/client-s3\u0026#39;; const s3 = new S3Client({}); // S3 バケットを作成する async function createBucket() { try { const output = await s3.send( new CreateBucketCommand({ Bucket: \u0026#39;s3-123456789012-sample-bucket-1\u0026#39; }) ); console.log(\u0026#39;SUCCESS - Bucket created:\u0026#39;, output); } catch (err) { console.error(\u0026#39;ERROR:\u0026#39;, err); } } createBucket(); 実行結果 SUCCESS - Bucket created: { \u0026#39;$metadata\u0026#39;: { httpStatusCode: 200, requestId: undefined, extendedRequestId: \u0026#39;X8LD9DYz4+UB8MbbwdfuH2nifmfLC0qJt0LcGhpRAZUDOBAYtrk/qsVqc/WLtYQj7qbIPmIk3gj=\u0026#39;, cfId: undefined, attempts: 1, totalRetryDelay: 0 }, Location: \u0026#39;http://s3-123456789012-sample-bucket-1.s3.amazonaws.com/\u0026#39; } S3 バケットを削除する (DeleteBucketCommand) S3 バケットを削除するには、S3Client#send() メソッドで DeleteBucketCommand コマンドを送ります。 バケットを削除するには、先にバケット内のオブジェクトをすべて削除しておく必要があります。 delete-bucket.ts import { S3Client, DeleteBucketCommand, } from \u0026#39;@aws-sdk/client-s3\u0026#39;; const s3 = new S3Client({}); // S3 バケットを削除する（先にすべてのオブジェクトを削除しておく必要あり） async function deleteBucket() { try { const output = await s3.send( new DeleteBucketCommand({ Bucket: \u0026#39;s3-123456789012-sample-bucket-1\u0026#39; }) ); console.log(\u0026#39;SUCCESS - Bucket deleted:\u0026#39;, output); } catch (err) { console.error(\u0026#39;ERROR:\u0026#39;, err); } } deleteBucket(); 実行結果 SUCCESS - Bucket deleted: { \u0026#39;$metadata\u0026#39;: { httpStatusCode: 204, requestId: undefined, extendedRequestId: \u0026#39;Ha4qd+x3FHsbi8WsdRu9GTXz5LhLl3s/m/yavxT6Nc9LOgjKNCG2Plk19V86hdeTyfKws6jfFF/=\u0026#39;, cfId: undefined, attempts: 1, totalRetryDelay: 0 } } S3 バケットにオブジェクトを追加する (PutObjectCommand) SDK V3 の場合 既存の S3 バケットにオブジェクトを追加するには、S3Client#send() メソッドで PutObjectCommand コマンドを送ります。 put-object.ts import { S3Client, PutObjectCommand } from \u0026#39;@aws-sdk/client-s3\u0026#39;; const s3 = new S3Client({}); // S3 バケットにオブジェクトを追加する async function putObject() { try { const output = await s3.send( new PutObjectCommand({ Bucket: \u0026#39;s3-123456789012-sample-bucket-1\u0026#39;, Key: \u0026#39;object-key-1\u0026#39;, Body: \u0026#39;object-body-1\u0026#39; }) ); console.log(\u0026#39;SUCCESS - Object added:\u0026#39;, output); } catch (err) { console.error(\u0026#39;ERROR:\u0026#39;, err); } } putObject(); 実行結果 SUCCESS - Object added: { \u0026#39;$metadata\u0026#39;: { httpStatusCode: 200, requestId: undefined, extendedRequestId: \u0026#39;M0oachGF8zXfHPrFA97PO2LNz/9dkinNBeCUz4vhaQLeorIdGkmLFqMAkhdhuEb1s9iu4JIC947=\u0026#39;, cfId: undefined, attempts: 1, totalRetryDelay: 0 }, BucketKeyEnabled: undefined, ETag: \u0026#39;\u0026#34;f0d3e2d98146efec4959d6bf45924b7e\u0026#34;\u0026#39;, Expiration: undefined, RequestCharged: undefined, SSECustomerAlgorithm: undefined, SSECustomerKeyMD5: undefined, SSEKMSEncryptionContext: undefined, SSEKMSKeyId: undefined, ServerSideEncryption: undefined, VersionId: undefined } SDK V2 の場合 put-object-v2.ts import * as AWS from \u0026#39;aws-sdk\u0026#39;; const s3 = new AWS.S3({ region: \u0026#39;ap-northeast-1\u0026#39; }); async function putObjectV2() { try { const output = await s3.putObject({ Bucket: \u0026#39;s3-123456789012-sample-bucket-1\u0026#39;, Key: \u0026#39;object-key-1\u0026#39;, Body: \u0026#39;object-body-1\u0026#39; }).promise(); console.log(\u0026#39;SUCCESS - Object added:\u0026#39;, output); } catch (err) { console.error(\u0026#39;ERROR:\u0026#39;, err); } } putObjectV2(); 実行結果 (SDK V2) SUCCESS - Object added: { ETag: \u0026#39;\u0026#34;90ad571f0ce74c38c7eca7a806a7ce68\u0026#34;\u0026#39; } S3 バケット内のオブジェクトの一覧を取得する (ListObjectV2Command) S3 バケット内のオブジェクトのリスト（最大1000件）を取得するには、S3Client#send() メソッドで ListObjectsV2Command コマンドを送ります。 list-objects.ts import { S3Client, ListObjectsV2Command } from \u0026#39;@aws-sdk/client-s3\u0026#39;; const s3 = new S3Client({}); // S3 バケット内のオブジェクトの一覧を取得する async function listObjects() { try { const output = await s3.send( new ListObjectsV2Command({ Bucket: \u0026#39;s3-123456789012-sample-bucket-1\u0026#39;, MaxKeys: 10, // 最大10件まで取得 }) ); for (const obj of output.Contents || []) { console.log(obj); } } catch (err) { console.error(\u0026#39;ERROR:\u0026#39;, err); } } listObjects(); 実行結果 { Key: \u0026#39;object-key-1\u0026#39;, LastModified: 2021-03-21T07:51:13.000Z, ETag: \u0026#39;\u0026#34;59d6bf45924b7ef0d3e2d98146efec49\u0026#34;\u0026#39;, Size: 13, StorageClass: \u0026#39;STANDARD\u0026#39;, Owner: undefined } { Key: \u0026#39;object-key-2\u0026#39;, LastModified: 2021-03-21T08:12:11.000Z, ETag: \u0026#39;\u0026#34;3f895677e156d30464cb71606a3f0f46\u0026#34;\u0026#39;, Size: 13, StorageClass: \u0026#39;STANDARD\u0026#39;, Owner: undefined } { Key: \u0026#39;object-key-3\u0026#39;, LastModified: 2021-03-21T08:12:18.000Z, ETag: \u0026#39;\u0026#34;a4d8c2240f532047c257f1208dd710c2\u0026#34;\u0026#39;, Size: 13, StorageClass: \u0026#39;STANDARD\u0026#39;, Owner: undefined } オブジェクトの内容を取得する (GetObjectCommand) SDK V3 の場合 特定のオブジェクトの内容を取得するには、S3Client#send() メソッドで GetObjectCommand コマンドを送ります。 戻り値の GetObjectCommandOutput の Body プロパティを参照すると、バケットオブジェクトの内容を取得できるのですが、これはオブジェクトの内容そのものではなく、ReadableStream オブジェクト になっているため、次のような感じで少しずつデータを取り出して結合する必要があります。 ここでは、オブジェクトの内容は UTF-8 形式のテキストであると想定しています。 get-object.ts import { S3Client, GetObjectCommand } from \u0026#39;@aws-sdk/client-s3\u0026#39; import config from \u0026#39;./config\u0026#39; // ReadableStream からバイトデータを少しずつ読み出します。 async function* yieldUint8Chunks(stream: ReadableStream\u0026lt;Uint8Array\u0026gt;) { const reader = stream.getReader() try { while (true) { const { done, value } = await reader.read() if (done) return yield value } } finally { reader.releaseLock() } } // ReadableStream からバイトデータを読み出して utf-8 文字列に結合して返します。 async function streamToString( stream: ReadableStream\u0026lt;Uint8Array\u0026gt; ): Promise\u0026lt;string\u0026gt; { const buf: Buffer[] = [] for await (const chunk of yieldUint8Chunks(stream)) { buf.push(Buffer.from(chunk as Uint8Array)) } return Buffer.concat(buf).toString(\u0026#39;utf-8\u0026#39;) } /** 指定した S3 バケットのオブジェクトの内容を取得します。 */ export async function getS3Object( bucketName: string, objectKey: string ): Promise\u0026lt;string\u0026gt; { try { const s3 = new S3Client({ region: config.region, credentials: config.credentials, }) const output = await s3.send( new GetObjectCommand({ Bucket: bucketName, Key: objectKey, }) ) const stream = output.Body as ReadableStream\u0026lt;Uint8Array\u0026gt; return streamToString(stream) } catch (err) { throw err } } // 使用例 const text = await getS3Object(\u0026#39;s3-123456789012-sample-bucket-1\u0026#39;, \u0026#39;object-key-1\u0026#39;) 実行結果 object-body-1 S3 のドキュメントでは別の方法として、SDK が提供する [getSignedUrl 関数を使って署名付き URL を作成] (https://docs.aws.amazon.com/ja_jp/sdk-for-javascript/v3/developer-guide/s3-example-creating-buckets.html#s3-create-presigendurl) し、そのアドレスに対して fetch することでオブジェクトの内容を取得するサンプルが示されています。 確かにこれを使うとコードがめっちゃシンプルです。 署名付き URL ってこういった用途に使ってよいの？という疑問はありますが、下記のように有効期限を 60 秒くらいに設定しておけばおそらく問題ないかと思います。 import { S3Client, GetObjectCommand } from \u0026#39;@aws-sdk/client-s3\u0026#39; import { getSignedUrl } from \u0026#39;@aws-sdk/s3-request-presigner\u0026#39; import config from \u0026#39;./config\u0026#39; // 指定したオブジェクトの内容を取得する export async function getS3Object( bucketName: string, objectKey: string ): Promise\u0026lt;string\u0026gt; { try { const s3 = new S3Client({ region: config.region, credentials: config.credentials, }) const command = new GetObjectCommand({ Bucket: bucketName, Key: objectKey, }) // Create the presigned URL and fetch the object const signedUrl = await getSignedUrl(s3, command, { expiresIn: 60 }) return (await fetch(signedUrl)).text() } catch (err) { throw new Error(err) } } // 使用例 const text = await getS3Object(\u0026#39;s3-123456789012-sample-bucket-1\u0026#39;, \u0026#39;object-key-1\u0026#39;) SDK V2 の場合 get-object-v2.ts import { S3 } from \u0026#39;aws-sdk\u0026#39;; const s3 = new S3(); async function getS3Object(): Promise\u0026lt;string | undefined\u0026gt; { const output: S3.GetObjectOutput = await s3.getObject({ Bucket: \u0026#39;s3-123456789012-sample-bucket-1\u0026#39;, Key: \u0026#39;object-key-1\u0026#39;, }).promise(); return output.Body?.toString(); } (async function main() { const body = await getS3Object(); console.log(body); })(); 実行結果 (SDK V2) object-body-1"
},
{
url: "/p/d3fs5gs/",
title: "VSCode の textlint プラグインで文章を校正する (vscode-textlint)",
date: "2020-05-20T00:00:00Z",
body: "VSCode の textlint プラグインで文章を校正する (vscode-textlint) 事前準備（textlint のインストール） vscode-textlint は、Visual Studio Code でテキスト校正ツールの textlint を実行するためのプラグインです。 プレーンテキスト (.txt) や、Markdown ファイル (.md) の校正を VSCode 上で実行できるようになります。 textlint の本体の方は、Node.js の npm コマンドを使ってあらかじめインストールしておく必要があります。 参考: textlint のインストールと基本的な使い方 こんな感じでインストールできます。 textlint 本体のインストール $ cd myproject # テキストファイルのあるディレクトリへ移動 $ npm init -y # package.json がない場合は作成 $ npm install -D textlint # textlint のインストール もし、既存のプロジェクトで、package.json や .textlintrc などがすでに存在しているのであれば、次のように実行すれば一発で textlint の実行環境が整います。 package.json に従って環境構築する場合 $ npm install vscode-textlint プラグインをインストールする vscode-textlint プラグインは、VS Code の Extensions タブから、textlint で検索してインストールすることができます。 vscode-textlint プラグインによる校正を実行する vscode-textlint プラグインは、VS Code で開いたディレクトリ内に設定ファイル .textlintrc が存在すると自動的に校正を実行します（ファイルではなく、ディレクトリを開かないと動作しません）。 たとえば次の設定ファイルでは、「ら抜き言葉」を検出するルール設定 を行なっています。 .textlintrc {\u0026#34;rules\u0026#34;: {\u0026#34;no-dropping-the-ra\u0026#34;: true}} このとき、事前にこのルールを実行するためのモジュールがインストールされていないと、 Failed to load textlint\u0026#39;s rule module: \u0026#34;no-dropping-the-ra\u0026#34; is not found. といったエラーが Output ウィンドウに表示されます。 次のように、対応する textlint ルールをインストールすれば正しく実行されるようになります（次回からは npm install でまとめてインストールできるようなります）。 $ npm install -D textlint-rule-no-dropping-the-ra textlint のルールによりエラーが検出されると、次のようにエディタ上に下線が引かれ、Problems ウィンドウにエラーの一覧が表示されます。 図: 「ら抜き言葉」の検出 ☝️ Quick Fix による自動修正 textlint --fix コマンドで自動修正可能なエラーであれば、エラーのある行にカーソルがある状態で Alt + Enter あるいは Cmd + . と入力すれば、自動的に正しい表現に修正してくれます。 自動修正に対応しているかどうかは、各ルールの NPM モジュールの説明ページを参照してください。 例えば、textlint-rule-ja-hiragana-fukushi は自動修正に対応しています（例: 且つ → かつ）。 あとは、同様にして いろいろな設定 を追加していくことができます。 文字を入力するたびに textlint を実行する textlint の実行タイミングは、デフォルトではテキストファイルの保存時 (onSave) になっています。 文字を入力するたびに校正を実行したい場合は、設定メニュー (Settings) から、Extensions → textlint と辿り、設定を onType に変更します。 図: textlint.run 設定"
},
{
url: "/p/avssq37/",
title: "TypeScript のコーディング規約（ルール／ガイドライン）",
date: "2020-02-27T00:00:00Z",
body: "TypeScript のコーディング規約（ルール／ガイドライン） 有名な JavaScript/TypeScript スタイル TypeScript のコーディングスタイルは下記のサイトが参考になります。 スタイルガイド（コーディング規約） - TypeScript Deep Dive 日本語版 TypeScript Deep Dive のスタイルガイドは、重要なポイントが簡潔にまとまっていてわかりやすいです。 standard/standard: JavaScript Standard Style セミコロンの省略を推奨していますが、2021 年時点ではまだセミコロン有り派の方が多いようです。モダンなプログラミング言語では行末にセミコロンを付けないものが多いので、セミコロン省略派が増えてきているというのも何となく頷けます。 関数定義の際に、カッコの前にスペースを強制するところがちょっと気持ち悪いです。 Node.js、npm、GitHub、Electron など有名どころが採用しています。 ドキュメントサイト airbnb/javascript: JavaScript Style Guide Airbnb は JS スタイルを細かく定義しています。ただ、長大すぎるので、重要なポイントをかいつまんで読むのには向いてません。ESLint などのツールを使ってスタイル強制する 場合にもよく使われますが、TypeScript 対応が不完全で、モジュールインポート時の拡張子省略がエラーになったりします（2021-05 時点）。 Coding guidelines · microsoft/TypeScript Wiki TypeScript 自体のコントリビューター用のコーディングガイドラインです。ユーザーレベルの開発プロジェクトに強制するものではないと注記がありますが、多くのルールはそのまま採用できると思います。インデントサイズは 4 とされていますが、多くの TypeScript プロジェクトではインデントサイズは 2 が採用されているので、ここだけ例外的です。 google/styleguide: Google Style Guides JavaScript/TypeScript 以外にもいろいろな言語の Google スタイルが説明されています。 JavaScript/TypeScript の世界では、上記の JavaScript Standard か Airbnb のスタイルの方が人気があるようです。 ESLint 用の設定ファイルはこちら まとめると、多くのスタイルガイドでは次のようなルールが採用されています。 インデントは 2 文字（4 文字を採用しているのはごく一部のプロジェクトのみ） ドキュメンテーションコメントには JSDoc の記法を使う 命名規則 型名（クラス名、列挙型、エイリアスなど）は PascalCase 変数名や関数名は camelCase プライベートプロパティ名を _ で始めない 文字列リテラル は 'シングルクォーテーション' で囲む シングルクォーテーションを含む文字列はダブルクォーテーションで囲んで OK 比較には == ではなく === を使用する。ただし、下記は例外。 obj == undefined \u0026hellip; null あるいは undefined であることのチェック obj != undefined \u0026hellip; null でも undefined でもないことのチェック 値の設定には null も undefined も使用せず、代わりに { valid: boolean, value?: Foo} のようなオブジェクトを返すことを検討する どうしても明示しなければいけないケースでは undefined に統一（undefined と null は同じものとして使って通常は問題ない） null は API で指定されている場合のみ使う（コールバック関数の error 引数として null を渡すとか） 開き括弧 ({) は同じ行の末尾に記述する 結局どのスタイルがよい？ 多くのケースでは、JavaScript Standard か Airbnb スタイルのどちらかを採用しているようですが、一応 GitHub リポジトリのスター数比較（2021-05時点）を載せておきます。 スター数だけでいうと、圧倒的に Airbnb スタイルが人気がありますが、とりあえずシンプルなスタイルだけでも適用したいということであれば、Standard スタイルがよいかもしれません。 Github Compare airbnb/javascript: 109,050 stars standard/starndard: 25,509 stars google/eslint-config-google: 1,510 stars 下記のサイトでは、ESLint の設定でどのスタイルがよく使われているかをもう少し詳しく比較しています。 Comparing eslint-config-airbnb vs. eslint-config-google vs. standard"
},
{
url: "/p/ugyw5ee/",
title: "TypeScriptの型: 変数の型指定（タイプアノテーション）の基本",
date: "2019-09-26T00:00:00Z",
body: "TypeScriptの型: 変数の型指定（タイプアノテーション）の基本 TypeScript の特徴は、変数の型を明示的に指定できることです。 この型指定のことを タイプアノテーション (Type annotation) と呼びます。 単純な変数のタイプアノテーション 下記は、文字列、数値、真偽値、配列のタイプアノテーションの例です。 let user: string = \u0026#39;まく\u0026#39;; let age: number = 14; let isActive: boolean = true; let titles: string[] = [\u0026#39;名前1\u0026#39;, \u0026#39;名前2\u0026#39;, \u0026#39;名前3\u0026#39;]; 指定した型と異なる型の値を代入しようとするとエラーになります。 let age: number = 14; age = \u0026#39;100歳\u0026#39;; エラーメッセージ Cannot assign to \u0026#39;age\u0026#39; because it is a constant. 配列や辞書、クラスなどの使い方は下記のページを参考にしてください。 参考リンク 配列を定義する (Array) 辞書型を定義する (Dictionary) クラス定義の基本 (class) 関数のタイプアノテーション 関数の型もアノテーションで示すことができます。 // 文字列を受け取り、何も返さない関数 let logger: (name: string) =\u0026gt; void; // 2つの数値を受け取り、真偽値を返す関数 let equal: (a: number, b: number) =\u0026gt; boolean; これらの変数には、パラメータと戻り値の型が等しく定義された関数のみ代入することができます。 function func1(name: string) { console.log(\u0026#34;Hello, \u0026#34; + name); } function func2(a: number, b: number): boolean { return a == b; } logger = func1; equal = func2; logger(\u0026#39;Maku\u0026#39;); // Hello, Maku console.log(hikaku(10, 20)); // false"
},
{
url: "/p/tn6y85z/",
title: "PlantUML でクラス図を作成する",
date: "2019-03-07T00:00:00Z",
body: "PlantUML でクラス図を作成する クラスの箱を描く 基本 クラスの箱を描くには、class キーワードを使用します。 他にも、interface でインタフェース、abstract で抽象クラス、enum で列挙型を定義することができます。 @startuml class クラス interface インタフェース abstract 抽象クラス enum 列挙型 @enduml クラス名にスペースや記号を含んでいる場合 クラス名やインタフェース名にスペースや記号を含めたい場合は、その文字列全体をダブルクォート \u0026quot;\u0026quot; で囲みます。 さらに、as で別名を付けておくと、あとから参照しやすくなります。 @startuml class \u0026#34;This is a class A\u0026#34; as A class \u0026#34;This is a class B\u0026#34; as B A -\u0026gt; B @enduml ステレオタイプ クラス名の後ろに \u0026lt;\u0026lt;ステレオタイプ\u0026gt;\u0026gt; と記述することで、クラス名の上部に任意のステレオタイプを表示することができます。 独自のステレオタイプを表示することができますし、複数のステレオタイプを表示することもできます。 @startuml interface インタフェース \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; abstract 抽象クラス \u0026lt;\u0026lt;abstract\u0026gt;\u0026gt; class ほげほげ \u0026lt;\u0026lt;独自ステレオタイプ\u0026gt;\u0026gt; class へむへむ \u0026lt;\u0026lt;Serializable\u0026gt;\u0026gt; \u0026lt;\u0026lt;Model\u0026gt;\u0026gt; @enduml クラス名の横の記号を非表示にする クラス名の左側に表示される C の記号などを非表示するには、hide circle コマンドを使用します。 下記のようにすると、クラスやインタフェースの記号がすべて非表示になります。 インタフェースに \u0026lt;\u0026lt;inteface\u0026gt;\u0026gt; というステレオタイプを表示するのであれば、記号は冗長なので消しておいた方がよいかもしれません。 @startuml hide circle class MyClass interface MyInterface \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; abstract MyAbstract enum MyEnum @enduml 記号を非表示にするクラスの種類を絞り込むこともできます。 下記の例では、通常のクラス (class) の記号と、ステレオタイプ \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; のついたクラスの記号を非表示にしています。 他にも、抽象クラス (abstract)、列挙型 (enum)、任意のクラス名の記号を非表示にすることもできます。 @startuml hide class circle hide \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; circle class MyClass interface MyInterface \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; abstract MyAbstract enum MyEnum @enduml クラス名の横に独自の記号を表示する クラスを表す C 記号や、インタフェースを表す I 記号はデフォルトで表示されますが、任意の記号を任意の色で表示することもできます。 独自の印を表示するには、クラスを定義するときに \u0026lt;\u0026lt; (記号, 色) \u0026gt;\u0026gt; というフォーマットでステレオタイプを付加します。 @startuml class DeprecatedClass \u0026lt;\u0026lt; (D, red) \u0026gt;\u0026gt; class PlayerView \u0026lt;\u0026lt; (V, #00FF00) View \u0026gt;\u0026gt; @enduml 関係を示す線を引く シンプルな関連の線 2 つのクラス名をハイフンで繋ぐことで、関連 (association) があることを示すことができます。 ハイフン 1 つなら縦に、ハイフン 2 つなら横に並べて配置されます。 -: 横方向に並べる --: 縦方向に並べる @startuml ClassA - ClassB ClassC -- ClassD @enduml ハイフン 2 つ以上は縦方向にクラスが並びますが、ハイフンが増えるごとに線の長さが伸びtていきます。 @startuml relation2 ClassA -- ClassB ClassC --- ClassD ClassE ---- ClassF ClassG ----- ClassH @enduml ただし、基本はハイフン 2 つを使っておいて、配置は PlantUML の最適化にまかせることが推奨されています。 依存の方向を示す矢印を表示する方法は下記で説明しますが、上記のように単純な線でクラスを結んだ場合は、誘導可能性が未知、あるいは双方向の依存があるということを意味します。 簡単に言えば、とりあえずなんらかの関連がある、ということを示すということですね。 矢印の種類 下記のように依存の方向を表す矢印（誘導可能性矢印: navigability arrows）を表示することができます。 両端に同様の記号を配置すれば、双方向の矢印として表示することができます。 ハイフンやドットの数を 1 つにすれば、クラスを横方向に並べることができますが、ここでの紹介例ではすべて縦方向に並べています。 --\u0026gt;: 関連 (Association) ※長期的な依存 ..\u0026gt;: 依存 (Dependency) ※短期的な依存 o--: 集約 (Aggregation) *--: 合成、コンポジション (Composition) \u0026lt;|--: 汎化 (Extension) \u0026lt;|..: 実現 (Realization) @startuml A --\u0026gt; B C ..\u0026gt; D E o-- F G *-- H @enduml @startuml abstract Parent interface MyInterface Parent \u0026lt;|-- ChildA Parent \u0026lt;|-- ChildB MyInterface \u0026lt;|.. ImplA MyInterface \u0026lt;|.. ImplB @enduml 多重度と関連のラベル（制約） 次のようにして、線の両端に多重度を表示したり、関連の意味や制約を示すラベルを表示したりすることができます。 @startuml BookShelf \u0026#34;1\u0026#34; o-- \u0026#34;*\u0026#34; Book : contains @enduml ラベルの先頭か末尾に \u0026lt; や \u0026gt; を付けることでラベルに方向を表示することができます。 @startuml Driver - Car : drives \u0026gt; @enduml 下記の例では、Customer が順序のある Purchase を保持していることを示しています。 @startuml Customer --\u0026gt; \u0026#34;1..* {ordered}\u0026#34; Purchase @enduml 関連間の制約 関連の線の間に { xor } 制約などを表示することは PlantUML ではまだできないっぽいです。 コメントなどで対応するしかなさそうです。 属性を定義する メソッドやフィールド（属性）を追加する クラスにメソッドやフィールドを追加していくには、クラス名の後ろに {} で囲んだブロックを作成します。 @startuml class MyClass { property1 : Int property2 : String func1() : String func2(p1, p2) : Int } @enduml メソッドやフィールドの可視性 (Visibility) メソッドやフィールドの先頭に、+、#、-、~ を付加することで、可視性を示すアイコンが表示されるようになります。 @startuml class MyClass { +publicField #protectedField -privateField ~packagePrivateField +publicMethod() #protectedMethod() -privateMethod() ~packagePrivateMethod() } @enduml 可視性を示すアイコンが分かりにくい場合は、最初に skinparam classAttributeIconSize 0 というコマンドを実行しておけば、+ や - 記号がそのまま表示されるようになります。 @startuml skinparam classAttributeIconSize 0 class MyClass { +publicField #protectedField -privateField ~packagePrivateField +publicMethod() #protectedMethod() -privateMethod() ~packagePrivateMethod() } @enduml Static メソッドと Abstract メソッド メソッドの前に、{static} モディファイアを付けることで静的メソッド (static method)、{abstract} モディファイアを付けることで抽象メソッド (abstract method) であることを示すことができます。 @startuml static-and-abstract class MyClass { {static} staticField: String {abstract} abstractField: String {static} staticMethod(): void {abstract} abstractMethod(): void } @enduml セパレータで自由に区切る デフォルトでは、括弧の有無によってメソッドとフィールドがグルーピングされて表示されます。 下記のようなセパレータを使用することで、自由な位置に区切り線を入れて表示をグルーピングすることができます。 セパレータ 線の種類 .. 破線 -- ノーマル __ 太線 == 二重線 @startuml class ClassA { property1 .. property2 -- property3 __ property4 == property5 } @enduml セパレータの線の上にテキストを表示することもできます。 @startuml class ClassB { property1 .. dashed line .. property2 -- normal line -- property3 __ heavy line __ property4 == double line == property5 } @enduml フィールドとメソッドのどちらに割り振るかを制御する デフォルトの振る舞いでは、末尾に () の付いた属性はメソッドだと認識され、それ以外はフィールドだと認識されます。 この振る舞いを強制的に変更するには、先頭に {field} や {method} モディファイアを付けます。 @startuml field-and-method-modifier class MyClass { これは括弧がないのでフィールド {field} これは括弧があるけどフィールド() これは括弧があるのでメソッド() {method} これは括弧がないけどメソッド } @enduml セパレータを入れることでも同様の表現が可能なので、こちらの方がシンプルでよいかもしれません。 @startuml field-and-method-modifier2 class MyClass { これは括弧がないのでフィールド これは括弧があるけどフィールド() __ これは括弧があるのでメソッド() これは括弧がないけどメソッド } @enduml メソッドがない場合にメソッドの領域を非表示にする フィールドやメソッドが存在しない場合、その表示領域を非表示にするには、hide empty fields コマンドや、hide empty methods コマンドを使用します。 @startuml hide empty fields hide empty methods class ClassA class ClassB { field } class ClassC { method() } class classD { field method() } @enduml パッケージ クラスをパッケージ囲む クラスを package ブロックで囲むことで、パッケージ内にクラスを表示することができます。 パッケージ名の後ろには背景色を指定することもできます。 @startuml package1 package util { class UtilClass1 class UtilClass2 } package main #acf { class MainClass1 class MainClass2 } UtilClass1 \u0026lt;-- MainClass1 UtilClass2 \u0026lt;-- MainClass2 @enduml パッケージ間の矢印 パッケージも、クラスと同様に関連の矢印を引くことができます。 @startuml package main { class Main1 } package feature { class Feature1 class Feature2 } main --\u0026gt; feature @enduml パッケージのスタイル パッケージ名の後ろに特定のステレオタイプを指定することで、パッケージのスタイル（形状）を変更することができます。 デフォルトは \u0026lt;\u0026lt;Folder\u0026gt;\u0026gt; を指定したものと同じ形状で表示されます。 @startuml package node \u0026lt;\u0026lt;Node\u0026gt;\u0026gt; { class Class1 } package rectangle \u0026lt;\u0026lt;Rectangle\u0026gt;\u0026gt; { class Class2 } package folder \u0026lt;\u0026lt;Folder\u0026gt;\u0026gt; { class Class3 } @startuml package frame \u0026lt;\u0026lt;Frame\u0026gt;\u0026gt; { class Class4 } package cloud \u0026lt;\u0026lt;Cloud\u0026gt;\u0026gt; { class Class5 } package database \u0026lt;\u0026lt;Database\u0026gt;\u0026gt; { class Class6 } @enduml 個々のパッケージのスタイルを指定する代わりに、先頭で skinparam packageStyle コマンドを実行することで、すべてのパッケージのスタイルを変更することができます。 @startuml package5 skinparam packageStyle rectangle package package1 { class Class1 } package package2 { Class1 -\u0026gt; Class2 } package package3 { Class2 --\u0026gt; Class3 } package package4 { Class3 .\u0026gt; Class4 } @enduml ちなみに、上記のサンプルコードからも分かるように、すべてのクラスを package ブロック内で class キーワードを使って定義する必要はなく、package ブロック内で初めて登場したクラスは、自動的にそのパッケージ内に所属するものとみなされます。 名前空間 名前空間にクラスを配置する 名前空間 (namespace) の機能によりクラス名を修飾すると、同じ名前のクラスを 1 つのダイアグラム内に登場させることができます。 下記の例では、名前空間 ns1 と ns2 に、同じ名前のクラス MyClass を定義しています。 @startuml namespace ns1 { class MyClass } namespace ns2 { class MyClass } ns1.MyClass -\u0026gt; ns2.MyClass @enduml namespace キーワードを使った名前空間の定義は必須ではなく、aaa.bbb.MyName のように、ドットで区切られたクラス名を使用することで、自動的にその名前空間に所属するクラスとして定義されます。 @startuml class ns1.MyClass ns1.MyClass -\u0026gt; ns2.MyClass ns2.MyClass -\u0026gt; ns3.MyClass @enduml 名前空間の機能を無効にする 上記の例のように、デフォルトではクラス名にドット (.) を含めることで自動的にそのクラスは名前空間に配置されてしまいます。 この機能を無効にして、クラス名にドットを含められるようにするには、set namespaceSeparator none コマンドを実行します。 @startuml namespace-none set namespaceSeparator none class aaa.MyClass aaa.MyClass -\u0026gt; bbb.MyClass bbb.MyClass -\u0026gt; ccc.MyClass @enduml 名前空間のセパレータ文字を変更する 名前空間 (namespace) のセパレータ文字は、デフォルトではドット (.) になっていますが、set namespaceSeparator コマンドを使用して任意の文字列に変更することができます。 下記の例では、セパレータ文字列として :: を設定しています。 @startuml set namespaceSeparator :: class X::Y::Foo { func() } X::Y::Foo -\u0026gt; X::Y::Z::Bar @enduml 注釈（コメント）を表示する クラスに直接注釈 (note) を付ける note コマンドを使用すると、クラスの箱の上下左右の位置に注釈を表示することができます。 @startuml class MyClass note left of MyClass : 左に表示される注釈 note right of MyClass : 右に表示される注釈 note top of MyClass : 上に表示される注釈 note bottom of MyClass : 下に表示される注釈1 note bottom of MyClass : 下に表示される注釈2 @enduml of MyClass などのターゲット指定を省略すると、直前に登場したオブジェクトに対しての注釈だとみなされます。 @startuml class Foo note left : \u0026#34;注釈1\u0026#34; Foo \u0026lt;-- Bar note left : \u0026#34;注釈2\u0026#34; note left : \u0026#34;注釈3\u0026#34; @enduml 次のようにして複数行に渡る注釈を記述することもできます。 改行位置はそのまま表示に反映されます。 @startuml class Foo note bottom of Foo これは複数行にわたる 注釈です。改行の位置も そのまま反映されます。 endnote @enduml 注釈 (note) 定義しておいて後からクラスに付加する note テキスト as 注釈名 という形で注釈 (note) に名前を付けて定義しておくと、後から クラス名 .. 注釈名 のような感じでクラスに割り当てることもできます。 この方法を使うと、同じ注釈を複数のクラスに適用することができます。 注釈の表示位置は次のような感じで、ある程度制御することができます。 記述 注釈の表示位置 注釈名 .. クラス名 クラスの上 クラス名 .. 注釈名 クラスの下 注釈名 . クラス名 クラスの左 クラス名 . 注釈名 クラスの右 @startuml class Foo class Bar note \u0026#34;注釈1です\u0026#34; as note1 note \u0026#34;注釈2です\u0026#34; as note2 note \u0026#34;注釈3です\u0026#34; as note3 note1 . Foo Foo .. note2 Bar .. note2 Bar . note3 @enduml 複数行に渡る注釈を定義しておくこともできます（直接クラスに付加してしまう場合と同様です）。 改行位置はそのまま表示に反映されます。 @startuml class Foo note as note1 これは複数行にわたる 注釈です。改行の位置も そのまま反映されます。 endnote Foo .. note1 @enduml フィールドやメソッドに注釈を付ける 注釈を付けるターゲットとして、クラス名::フィールド名 のように指定すると、フィールドやメソッドに対して注釈を付けることができます。 @startuml class Foo { field1 method1() } note left of Foo::field1 フィールドの注釈 endnote note right of Foo::method1 メソッドの注釈 endnote @enduml ポジションの指定は left あるいは right のみで、複数行コメントの形 (note~endnote) で指定しないとうまくいかないようです。 関連（リンク）に対して注釈をつける 関連の線に注釈 (note) を付加したいときは、リンクの定義の直後に note on link コマンドを使用します。 @startuml Foo --\u0026gt; Bar note on link : これは関連に対する注釈です Foo -\u0026gt; Hoge note on link #pink : \u0026lt;b\u0026gt;背景色\u0026lt;/b\u0026gt;を変更できます Hoge --\u0026gt; Hemu note right on link \u0026lt;b\u0026gt;複数行に渡る\u0026lt;/b\u0026gt;注釈を 記述できます。 endnote @enduml 注釈テキストを HTML タグで装飾する 注釈内のテキストは、下記のような HTML 風タグで装飾することができます。 ダイアログの目的は設計情報を伝えることなので、あまり装飾にこだわりすぎないように、\u0026lt;b\u0026gt; による強調くらいにしておくのがよいでしょう。 タグ 意味 \u0026lt;b\u0026gt; 太字 \u0026lt;u\u0026gt; 下線 \u0026lt;i\u0026gt; イタリック \u0026lt;s\u0026gt;, \u0026lt;del\u0026gt;, \u0026lt;strike\u0026gt; 打ち消し線 \u0026lt;color:#AAAAAA\u0026gt;, \u0026lt;font color=\u0026quot;#AAAAAA\u0026quot;\u0026gt; フォント色 \u0026lt;size:nn\u0026gt; フォントサイズ \u0026lt;img:file\u0026gt;, \u0026lt;img src=\u0026quot;file\u0026quot;\u0026gt; 画像表示 @startuml class Foo note bottom of Foo 注釈テキストは\u0026lt;b\u0026gt;HTMLタグ\u0026lt;/b\u0026gt;で装飾できます。 \u0026lt;color:red\u0026gt;色の変更\u0026lt;/color\u0026gt;などもできますが、 \u0026lt;size:20\u0026gt;必要最小限\u0026lt;/size\u0026gt;にしましょう。 endnote @enduml レイアウト（配置）を調整する クラスの配置はできるだけ PlantUML の自動レイアウトにまかせるべきですが、どうしてもよい配置にならないときがあります。 そのような場合は、下記のようなテクニックを使ってある程度は配置の調整を行うことができます。 クラスの箱の配置順 クラスの箱は、基本的に登場した順に左上から配置されていきます。 クラス間の関連を表す矢印のハイフンが 1 つだと横方向、2 つ以上だと縦方向に配置されます。 依存関係によって PlantUML は最適な位置にクラスを配置していきますが、矢印とクラス配置の関係はおおよそ次のようになります。 矢印 クラスの配置 -\u0026gt; 左から右 \u0026lt;- 右から左 --\u0026gt; 上から下 \u0026lt;-- 下から上 思った位置と逆に表示されてしまったら、クラスが登場する順序を逆にして、それに合わせて矢印の向きを逆転させるとうまくいくことが多いです。 @startuml A --|\u0026gt; B B -\u0026gt; C @enduml @startuml B \u0026lt;|-- A C \u0026lt;- B @enduml 矢印の方向 矢印の内側に left、right、up、down と記述することで、その方向に矢印が向かうように配置を調整することができます。 @startuml Center -up-\u0026gt; Up Center -left-\u0026gt; Left Center -right-\u0026gt; Right Center -down-\u0026gt; Down @enduml 見えない関連の線を引いて配置 次の例では、6 つのクラスを自動レイアウトで配置していますが、無駄に横長に配置されてしまっています。 @startuml hidden-line1 class A A -\u0026gt; B C -\u0026gt; D E --\u0026gt; F @enduml クラス A と B の下に、C と D を配置できればもっとコンパクトに表示できるはずです。 このようなケースでは、[hidden] キーワードを使って、A と C の間に見えない関連の線（縦方向の線）を引いてやることで、うまく A と C が縦に並ぶようになります。 @startuml hidden-line2 class A A -\u0026gt; B A -[hidden]- C C -\u0026gt; D E --\u0026gt; F @enduml 関連クラス クラスをある 2 つのクラス A, B の関連クラスとして表示するには、(クラスA, クラスB) .. 関連クラス名 という記述を使います。 クラス間の接続では クラス .. クラス と記述していましたが、この片方を (クラス, クラス) というペアの記述に変えたものだと考えると分かりやすいです。 @startuml Student \u0026#34;1\u0026#34; - \u0026#34;1\u0026#34; Course (Student, Course) .. Enrollment @enduml 関連クラスの表示位置も、クラスの表示位置と同様にある程度制御することができます。 @startuml Student \u0026#34;1\u0026#34; - \u0026#34;1\u0026#34; Course Enrollment .. (Student, Course) @enduml 全体のカラー（配色）を変更する skinparam コマンドを使って、クラス図全体の配色をまとめて変更することができます。 @startuml skinparam classBackgroundColor #FFFFFF skinparam classBorderColor #black skinparam classArrowColor #black skinparam classFontColor #blue skinparam classFontSize 20 skinparam classFontName Helvetica \u0026#39; 可視性をアイコンではなく文字で表示 skinparam classAttributeIconSize 0 \u0026#39; 影をなくす skinparam shadowing false Foo \u0026lt;|-- Bar @enduml skinparam コマンドはブロック化することで、プレフィックス部分を省略して記述することができます。 skinparam class { BackgroundColor #FFFFFF BorderColor #black ArrowColor #black FontColor #blue FontSize 20 FontName Helvetica AttributeIconSize 0 } skinparam shadowing false シンプルにグレースケール表示にしたい場合は、skinparam monochrome true とするのが手っ取り早いです。 @startuml skinparam monochrome true \u0026#39; 可視性をアイコンではなく文字で表示 skinparam classAttributeIconSize 0 \u0026#39; 影をなくす skinparam shadowing false Foo \u0026lt;|-- Bar @enduml 一連の skinparam の定義は別ファイル (.iuml) に保存してしまい、プロジェクト全体でインクルード (!include) して使用するのがよいでしょう。 ネット上のファイルをインクルード (!includeurl) することもできます。 skinparams.iuml skinparam class { BackgroundColor #white BorderColor #black ArrowColor #black FontColor #black FontSize 20 FontName Helvetica \u0026#39; 可視性をアイコンではなく文字で表示 AttributeIconSize 0 } \u0026#39; 影をなくす skinparam shadowing false 使用例 @startuml !include skinparams.iuml class Foo class Bar @enduml 参考: PlantUML \u0026ndash; Changing colors and fonts"
},
{
url: "/p/2thipwb/",
title: "mongo シェルで JavaScript ファイル（スクリプト）を実行する",
date: "2014-03-31T00:00:00Z",
body: "mongo シェルで JavaScript ファイル（スクリプト）を実行する 例えば、input.js というスクリプトを mongo シェルで実行するには以下のようにします。 ここでは、mydb という名前のデータベースの books コレクションに、テスト用のドキュメントを追加しています。 $ mongo mydb input.js input.js db.books.insert({title: \u0026#39;Title 1\u0026#39;}); db.books.insert({title: \u0026#39;Title 2\u0026#39;}); db.books.insert({title: \u0026#39;Title 3\u0026#39;}); ドキュメントには書いてありませんが、標準入力から読み込ませることもできるようです。 この方法を使うと、mongo コマンドのオプションのフォーマット的に、データベース名を省略してスクリプトファイル名を指定できるようになるので、スクリプトの中でデータベースを切り替えることができます。 $ mongo \u0026lt; input2.js $ mongo --port 40001 \u0026lt; input2.js $ mongo localhost:40001 \u0026lt; input2.js input2.js use testdb; db.books.insert({title: \u0026#39;Title 1\u0026#39;, tags: [\u0026#39;AAA\u0026#39;, \u0026#39;BBB\u0026#39;]}); db.books.insert({title: \u0026#39;Title 2\u0026#39;, tags: [\u0026#39;BBB\u0026#39;, \u0026#39;CCC\u0026#39;]}); db.books.insert({title: \u0026#39;Title 3\u0026#39;, tags: [\u0026#39;CCC\u0026#39;, \u0026#39;AAA\u0026#39;]}); 参考: http://docs.mongodb.org/manual/tutorial/write-scripts-for-the-mongo-shell/#execute-a-javascript-file"
},
{
url: "/p/tm4jzet/",
title: "MongoDB サーバー (mongod) を Windows サービスとして登録する",
date: "2014-01-17T00:00:00Z",
body: "MongoDB サーバー (mongod) を Windows サービスとして登録する Windows サービスとして MongoDB サービスを登録する MongoDB サーバー (mongod) を Windows サービスとして登録しておくと、バックグラウンドで MongoDB サーバーが動作するようになるため、いちいちコマンドラインで mongod を起動する必要がなくなります。 MongoDB サーバーを Windows サービスとして登録するには、コマンドプロンプトを管理者権限で起動し、次のように入力します。 Windows サービスとして MongoDB サービスを登録 C:\\\u0026gt; mongod --install --dbpath \u0026lt;DBディレクトリ\u0026gt; --logpath \u0026lt;ログファイル名\u0026gt; コンソール上でログを確認することができなくなってしまうので、ログがファイルに保存されるように、ログファイル名を指定しておく必要があります。 下記は実行例です。 ここでは、データベースディレクトリとして D:\\mongo_data、ログファイル名 D:\\mongo_log\\log.txt を指定しています。 ディレクトリはあらかじめ作成しておく必要があります。 C:\\\u0026gt; mkdir D:\\mongo_data C:\\\u0026gt; mkdir D:\\mongo_log C:\\\u0026gt; mongod --install --dbpath D:\\mongo_data --logpath D:\\mongo_log\\log.txt Fri Jan 17 12:11:49.699 Trying to install Windows service \u0026#39;MongoDB\u0026#39; Fri Jan 17 12:11:49.711 Service \u0026#39;MongoDB\u0026#39; (Mongo DB) installed with command line \u0026#39;C:\\app\\mongodb\\mongod.exe --dbpath D:\\mongo_data --logpath D:\\mongo_log\\log.txt --service\u0026#39; Fri Jan 17 12:11:49.712 Service can be started from the command line with \u0026#39;net start MongoDB\u0026#39; これで、MongoDB という名前の Windows サービスとして認識されるようになります。 sc コマンドで、実際に登録されているか確認しておきましょう。 MongoDB サービスが登録されているか確認 C:\\\u0026gt; sc query MongoDB SERVICE_NAME: MongoDB TYPE : 10 WIN32_OWN_PROCESS STATE : 1 STOPPED WIN32_EXIT_CODE : 1077 (0x435) SERVICE_EXIT_CODE : 0 (0x0) CHECKPOINT : 0x0 WAIT_HINT : 0x0 サービス登録直後は、上記のように MongoDB サービスは停止状態 (STOPPED) になっています。 MongoDB サービスを起動する Windows サービスとして登録された MongoDB サービスは下記のようにして起動します。 MongoDB サービスの開始 C:\\\u0026gt; net start MongoDB MongoDB サービスを開始します... MongoDB サービスは正常に開始されました。 次のようなエラーが発生する場合は、データベースファイルやログファイルを格納するためのディレクトリが存在しているかを確認してください。 C:\\\u0026gt; net start MongoDB The service is not responding to the control function. More help is available by typing NET HELPMSG 2186. デフォルトポート (27017) で起動した MongoDB サービスには、下記のようにパラメータなしで MongoDB シェル (mongo) を実行すれば接続できます。 mongo シェルで接続 C:\\\u0026gt; mongo MongoDB shell version v4.0.9 ... Windows サービスから MongoDB サービスを削除する MongoDB サービスを Windows サービスから登録解除したいときは下記のように実行します。 この場合も、コマンドプロンプトは管理者権限で実行しなければいけないことに注意してください。 Windows サービスから MongoDB サービスを削除 C:\\\u0026gt; mongod --remove 実行例 C:\\Windows\\system32\u0026gt; mongod --remove 2019-05-21T23:47:37.500+0900 I CONTROL [main] Automatically disabling TLS 1.0, to force-enable TLS 1.0 specify --sslDisabledProtocols \u0026#39;none\u0026#39; 2019-05-21T23:47:37.502+0900 I CONTROL [main] Trying to remove Windows service \u0026#39;MongoDB\u0026#39; 2019-05-21T23:47:37.504+0900 I CONTROL [main] Service \u0026#39;MongoDB\u0026#39; removed もちろん、sc コマンドを使ってサービスを削除することもできます。 C:\\\u0026gt; sc stop MongoDB C:\\\u0026gt; sc delete MongoDB"
},
{
url: "/p/gbs79ua/",
title: "MongoDB と RDB の用語比較",
date: "2013-10-22T00:00:00Z",
body: "MongoDB と RDB の用語比較 MongoDB で使用する Database や Collection などの用語は、RDB の用語と以下のような関係にあります。 MongoDB の用語 RDB の用語 Database Database（同じ） Collection（コレクション） Table（テーブル） Document（ドキュメント） Record（行） Field（フィールド） Column（列） ある Database の Collection に Document を追加するときは、mongo クライアントでは以下のように実行します。 \u0026gt; use \u0026lt;Database名\u0026gt; \u0026gt; db.\u0026lt;Collection名\u0026gt;.insert(\u0026lt;Document の Field セット\u0026gt;)"
},
{
url: "/p/24p8jjx/",
title: "Amazon Cognito: Amplify SDK による認証まわりの UI 表示あれこれ",
date: "2021-06-09T00:00:00Z",
body: "Amazon Cognito: Amplify SDK による認証まわりの UI 表示あれこれ 認証済みユーザーが admin グループに属しているか調べて UI を切り替える Cognito ユーザープールの「グループ」機能を使うと、既存のユーザーをグループ単位でまとめて、特別な IAM ロールを割り当てたりすることができます。 例えば、admin グループを作っておいて、そのグループに所属するユーザーに、DynamoDB の書き込み権限 (IAM role) を与える、といったことができます。 React アプリのレイヤでは、このような IAM ロールの権限うんぬんの前に、カレントユーザーがどのようなグループに所属しているかに応じて UI の表示分けをしたいことがあります。 例えば、admin グループのユーザーが Web ページを表示しているときは、管理者向けのメニュー表示をする、といったケースです。 幸い、aws-amplify モジュールの Auth オブジェクトが提供する認証情報を参照することで、認証済みのユーザーがどの Cognito グループに属しているかを調べることができます。 具体的には、Auth.currentAuthenticatedUser() などが返すユーザー情報のアクセストークンのペイロードに cognito:groups というプロパティがあり、そこに Cognito グループ名のリストが格納されています。 参考: Using the Access Token - Amazon Cognito 次のようなカスタムフック useAuthState を定義しておくと、戻り値の isAdmin プロパティを見るだけで、現在のユーザーが admin グループに属しているかを確認できます。 src/hooks/useAuthState.tsx import { useEffect, useState } from \u0026#39;react\u0026#39; import { Auth } from \u0026#39;aws-amplify\u0026#39; import { AuthState, CognitoUserInterface, onAuthUIStateChange, } from \u0026#39;@aws-amplify/ui-components\u0026#39; // ユーザーがこのグループ名の Cognito グループに所属しているときに、 // useAuthState フックが返す isAdmin プロパティを true にします。 const ADMIN_GROUP_NAME = \u0026#39;admin\u0026#39; /** useAuthState フックの戻り値の型 */ export type UseAuthStateOutput = { isSignedIn: boolean isAdmin: boolean user: CognitoUserInterface | undefined } /** 現在の認証状態を取得するためのフック関数です。 */ export const useAuthState = (): UseAuthStateOutput =\u0026gt; { // Cognito によるサインイン状態やユーザー情報を保持するステート const [authState, setAuthState] = useState\u0026lt;AuthState | undefined\u0026gt;() const [user, setUser] = useState\u0026lt;CognitoUserInterface | undefined\u0026gt;() useEffect(() =\u0026gt; { // 画面遷移時に onAuthUIStateChange が呼ばれないことへの対応 // https://github.com/aws-amplify/docs/issues/2895 if (authState === undefined) { Auth.currentAuthenticatedUser() .then((authData) =\u0026gt; { setAuthState(AuthState.SignedIn) setUser(authData) }) .catch(() =\u0026gt; { /* Nothing to do */ }) } return onAuthUIStateChange((nextAuthState, authData) =\u0026gt; { setAuthState(nextAuthState) setUser(authData as CognitoUserInterface) }) }, [authState]) return { isSignedIn: authState === AuthState.SignedIn, isAdmin: isAdmin(user), user, } } // アクセストークン内のグループ名リストに \u0026#34;admin\u0026#34; があるかを調べます。 function isAdmin(user: CognitoUserInterface | undefined): boolean { // eslint-disable-next-line @typescript-eslint/no-unsafe-member-access const groups = user?.signInUserSession?.accessToken?.payload[ \u0026#39;cognito:groups\u0026#39; ] as Array\u0026lt;string\u0026gt; return groups?.includes(ADMIN_GROUP_NAME) ?? false } 上記のフック実装では、戻り値の user プロパティで CognitoUserInterface 情報を返すようにしていますが、Cognito に依存する情報はできるだけフック内に隠蔽してしまった方がいいですね。 下記は、このフック関数の使用例です。 useAuthState() が返す isAdmin の値が true のときに、管理者用のメニューを表示するという処理を想定しています。 src/components/Sample.tsx（使用例） // ... export const Sample: FC = () =\u0026gt; { const { isAdmin } = useAuthState() return ( \u0026lt;\u0026gt; \u0026lt;p\u0026gt;If you are in admin group, you can see the following menu\u0026lt;/p\u0026gt; {isAdmin \u0026amp;\u0026amp; \u0026lt;p\u0026gt;Secret menu\u0026lt;/p\u0026gt;} \u0026lt;/\u0026gt; ) } Sign in、Sign out 処理を Next.js ページとして実装する 次のように、pages/signin.tsx、pages/signout.tsx といった Next.js ページを作っておくと、そのアドレスへルーティング (Router.push('/signout')) するだけで、サインイン／アウト処理を起動することができます。 src/pages/signin.tsx import { FC } from \u0026#39;react\u0026#39; import { AmplifyAuthenticator, AmplifySignIn } from \u0026#39;@aws-amplify/ui-react\u0026#39; import Router from \u0026#39;next/router\u0026#39; // サインイン済みかどうかを調べるフックを用意しておきます import { useAuthState } from \u0026#39;@/hooks/useAuthState\u0026#39; const SignInPage: FC = () =\u0026gt; { // サインイン状態ならトップページなどへ飛ばす const { isSignedIn } = useAuthState() if (isSignedIn) void Router.replace(\u0026#39;/\u0026#39;) // サインインの画面を表示する return ( \u0026lt;AmplifyAuthenticator\u0026gt; \u0026lt;AmplifySignIn slot=\u0026#34;sign-in\u0026#34; hideSignUp /\u0026gt; \u0026lt;/AmplifyAuthenticator\u0026gt; ) } export default SignInPage src/pages/signout.tsx import { FC, useEffect } from \u0026#39;react\u0026#39; import Router from \u0026#39;next/router\u0026#39; import { Auth } from \u0026#39;aws-amplify\u0026#39; const SignOutPage: FC = () =\u0026gt; { useEffect(() =\u0026gt; { void Auth.signOut() void Router.replace(\u0026#39;/\u0026#39;) }, []) return null } export default SignOutPage 上記のようなページを Next.js アプリ内に設置すれば、ブラウザの URL 欄に直接 /signin と入力してサインイン画面を表示したり、/signout と入力してサインアウトすることができます。 また、プログラムから Router.push('/signin') とすることでも同じ振る舞いを再現できます。 次のコンポーネントは、現在のサインイン状態に応じて「Sign out」あるいは「Sign in」のボタンを表示しています。 src/components/SignInOrOutButton.tsx import { FC } from \u0026#39;react\u0026#39; import Router from \u0026#39;next/router\u0026#39; import Button from \u0026#39;@mui/material/Button\u0026#39; import { useAuthState } from \u0026#39;@/hooks/useAuthState\u0026#39; /** * Shows a sign-in or sign-out button, depending on the current * authentication status. */ export const SignInOrOutButton: FC = () =\u0026gt; { const { isSignedIn } = useAuthState() return isSignedIn ? ( \u0026lt;Button onClick={() =\u0026gt; Router.push(\u0026#39;/signout\u0026#39;)}\u0026gt;Sign out\u0026lt;/Button\u0026gt; ) : ( \u0026lt;Button onClick={() =\u0026gt; Router.push(\u0026#39;/signin\u0026#39;)}\u0026gt;Sign in\u0026lt;/Button\u0026gt; ) } Sign out ボタンの表示方法 React コンポーネント (AmplifySignOut) を配置する方法 import { AmplifySignOut } from \u0026#39;@aws-amplify/ui-react\u0026#39; export const MyComponent: React.FC = () =\u0026gt; { // ... return ( \u0026lt;AmplifySignOut /\u0026gt; ) } サインアウト関数 (Auth.signOut()) を呼び出す方法 import { Auth } from \u0026#39;aws-amplify\u0026#39; import Button from \u0026#39;@mui/material/Button\u0026#39; export const MyComponent: React.FC = () =\u0026gt; { // ... return ( \u0026lt;Button onClick={() =\u0026gt; Auth.signOut()}\u0026gt;Sign out\u0026lt;/Button\u0026gt; ) }"
},
{
url: "/p/2n2doyb/",
title: "Next.js で Sass (scss/sass) を有効にする",
date: "2021-05-06T00:00:00Z",
body: "Next.js で Sass (scss/sass) を有効にする Next.js は Sass を使ったスタイルシート記述 (.scss / .sass ファイル）をサポートしています。 ほぼゼロコンフィグ（設定なし）で使用できますが、NPM の sass モジュールだけはマニュアルでインストールする必要があります。 sass のインストール ### yarn の場合 $ yarn add sass --dev ### npm の場合 $ npm install sass --save-dev 今まで .css 拡張子で作成していたファイルを、.scss に変更すれば、SCSS フォーマットでスタイル記述できます。 置換前: styles/global.css 置換後: styles/global.scss あとは、.css ファイルをインポートしている部分を、.scss に置換すれば導入完了です。 pages/_app.tsx import type { AppProps } from \u0026#39;next/app\u0026#39; import \u0026#39;../styles/global.scss\u0026#39; export default function MyApp({ Component, pageProps }: AppProps) { return \u0026lt;Component {...pageProps} /\u0026gt; } もちろん、CSS Modules の仕組み を使っている場合にも Sass を使うことができます。 その場合は、.module.css という拡張子を .module.scss に置き換えます。"
},
{
url: "/p/ods6iv8/",
title: "TypeScriptの型: 値の型を typeof で調べる",
date: "2020-04-28T00:00:00Z",
body: "TypeScriptの型: 値の型を typeof で調べる 次のサンプルコードでは、それぞれの変数値の型情報を、JavaScript の typeof で調べています（ついでに、Object.prototype.toString.call でもう少し詳しい情報も表示）。 // ヘルパ関数 function printType(x: any) { console.log(`${typeof(x)}${Object.prototype.toString.call(x)}`); } let booleanValue: boolean = true; printType(booleanValue); //=\u0026gt; boolean [object Boolean] let numberValue: number = 100; printType(numberValue); //=\u0026gt; number [object Number] let stringValue: string = \u0026#39;Hello\u0026#39;; printType(stringValue); //=\u0026gt; string [object String] function func(): number { return 100; } printType(func); //=\u0026gt; function [object Function] let undefinedValue: undefined = undefined; printType(undefinedValue); //=\u0026gt; undefined [object Undefined] let tupleValue: [string, number] = [\u0026#39;Hello\u0026#39;, 100]; printType(tupleValue); //=\u0026gt; object [object Array] let arrayValue: number[] = [1, 2, 3]; printType(arrayValue); //=\u0026gt; object [object Array] let nullValue: null = null; printType(nullValue); //=\u0026gt; object [object Null] let general: any = { name: \u0026#39;Mofu\u0026#39; }; printType(general); //=\u0026gt; object [object Object] let sym: symbol = Symbol(\u0026#39;key\u0026#39;); // ES2015 printType(sym); //=\u0026gt; symbol [object Symbol] let x: bigint = 1n; // ES2020 printType(x); //=\u0026gt; bigint [object BigInt] enum Color { Red, Green, Yellow }; // これは数値と同じ扱い printType(Color.Red); // number [object Number] 注意しなければいけないのは、JavaScript の typeof は、TypeScript のタイプアノテーションで指定した型を返してくれるわけではないということです。 typeof が返す型情報は、JavaScript コードとして実行したときに、実際にその値がどのような型で扱われているかを示すものです。 なので、TypeScript 独自のタイプアノテーション情報（Tuple 型など）が調べられるわけではありません。 TypeScript のタイプアノテーションは、JavaScript へのトランスパイル時に使われる参考情報でしかありません。 これは、次のように「何でも型」の any で変数を定義し、具体的な値として数値、文字列、オブジェクトを格納してみるとよくわかります。 let x: any = 100; printType(x); //=\u0026gt; number [object Number] x = \u0026#39;Hello\u0026#39;; printType(x); //=\u0026gt; string [object String] x = {\u0026#39;a\u0026#39;: 100}; printType(x); //=\u0026gt; object [object Object] 共用体 (Union) 型を使った場合も同様。 let x: string | null; x = \u0026#39;Hello\u0026#39;; printType(x); //=\u0026gt; string [object String] x = null; printType(x); //=\u0026gt; object [object Null] typeof は、あくまで 実行時の値 の型を調べるものだということですね。"
},
{
url: "/p/n8p7qmw/",
title: "PlantUML でシーケンス図を作成する",
date: "2018-10-12T00:00:00Z",
body: "PlantUML でシーケンス図を作成する シーケンス図は相互作用図 (interaction diagram) の代表的なダイアグラムです。 シーケンス図は、特定のユースケースに関するオブジェクトの典型例と、オブジェクト間のメッセージを示します。 要素の並び順の制御 (participant) 必須の定義ではないですが、participant であらかじめ要素を列挙しておくと、その後のメッセージ定義の順序に関係なく、participant に並べた順に左から要素が配置されます。 @startuml participant Class1 participant Class2 participant Class3 Class3 -\u0026gt; Class1 Class2 -\u0026gt; Class3 Class1 -\u0026gt; Class2 @enduml participant の代わりに actor というキーワードを使用すると、アクターのシンボルを表示することができます。 @startuml actor Class1 participant Class2 participant Class3 Class3 -\u0026gt; Class1 Class2 -\u0026gt; Class3 Class1 -\u0026gt; Class2 @enduml 同期メッセージと非同期メッセージ、リターン オブジェクト間のメッセージは、下記のように描き分けることができます。 -\u0026gt;: 同期メッセージ --\u0026gt;: 戻り値（リターン） -\u0026raquo;`: 非同期メッセージ 同期メッセージには戻り値（リターン）(--\u0026gt;) がありますが、UML の仕様としては省略することができます。 @startuml A -\u0026gt; B : 同期メッセージ A \u0026lt;-- B : リターン A -\u0026gt;\u0026gt; C : 非同期メッセージ @enduml ライフラインの活性区間 (activation) と終了 ライフラインの上に描かれる長方形は「活性区間 (activation)」で、その区間の間はオブジェクトがアクティブな状態になっていることを表します。 活性区間は、activate と deactivate で示します。 ライフラインの終了（生存期間の終わり）を示すには、deactivate の代わりに destory で示します（×が表示されます）。 @startuml A -\u0026gt; B : DoWork activate B B -\u0026gt; C : DoWork activate C C --\u0026gt; B : Done deactivate C B --\u0026gt; A : Done destroy B @enduml 参加者 (participant) の生成と削除 参加者 (participant) の生成と削除には、create と destroy を使用します。 create \u0026lt;participant\u0026gt;: オブジェクトを生成する destroy \u0026lt;participant\u0026gt;: オブジェクトを削除する @startuml participant Alice participant Bob participant Carol create Bob Alice -\u0026gt; Bob: new note left: 生成 activate Bob create Carol Bob -\u0026gt; Carol: new Bob -\u0026gt; Carol: close destroy Carol note right: 他のオブジェクト\\nによる削除 deactivate Bob Alice \u0026lt;-- Bob: results destroy Bob note right: 自己削除 @enduml コンストラクタなどの処理を示すには、参加者 (participant) のボックスの下に接する形でアクティベーションボックスを描きます。 ×マークに向かってメッセージの矢印が伸びているときは、他のオブジェクトによって削除されることを示します。 ライフライン（生存性）の最後に×マークがあるときは、そのオブジェクトが GC などで自動的に削除されることを示します。 インとアウトのメッセージ (incoming and outgoing messeage) メッセージの両端に何も表示したくない場合は、左側の要素の代わりに [、右側の要素の代わりに ] を指定します（何も指定せずに矢印だけ記述するとエラーになります）。 @startuml [-\u0026gt; A: DoWork activate A A -\u0026gt; A: Internal call activate A A -\u0026gt;] : \u0026lt;\u0026lt; createRequest \u0026gt;\u0026gt; A \u0026lt;--] : RequestCreated deactivate A [\u0026lt;- A: Done deactivate A @enduml 最初のメッセージのように、ソースが不確定なメッセージを found message（見出されたメッセージ） と呼びます（『UMLモデリングのエッセンス』 より）。 メッセージのテキストに改行を入れる（複数行のメッセージ） メッセージのテキスト内で改行したいときは \\n を使用します。 @startuml Alice -\u0026gt; Alice: メッセージの\\nテキスト内で\\n\\\\n を使用すると\\n改行できます @enduml ループと条件分岐 シーケンス図は制御ロジックのモデル化には適していませんが、下記のような相互作用フレームを使用することで、ループ処理や条件分岐を表現することができます。 alt ~ else ~ end: ガード条件に一致した部分だけを実行する。 opt ~ end: ガード条件に一致した場合のだけ実行する（上記の特殊バージョン）。 loop ~ end: ガード条件に一致する限り繰り返し実行する。 @startuml hide footbox alt successful case Alice -\u0026gt; Bob: message else some kind of failure Alice -\u0026gt; Bob: message else Another type of failure Alice -\u0026gt; Bob: message end opt value \u0026gt; $10000 Alice -\u0026gt; Bob: message end loop for each line item Alice -\u0026gt; Bob: message end @enduml インデントは自由にできるので、上記のように各ブロックの中をインデントして記述するとわかりやすくなります。 フレームは入れ子で使用することもできます。 ノート (note) を付ける メッセージのノート メッセージの定義の次の行で、note left や note right を使用すると、そのメッセージに対してのノート（注釈）を表示することができます。 @startuml A -\u0026gt; B: message1 note left: メッセージの\\n左側のノート A \u0026lt;- B: message2 note right: メッセージの\\n右側のノート A -\u0026gt; B: message3 note right 複数行に渡る 記述も可能！ end note @enduml ライフライン（生存線）のノート note left of、note right of、note over を使用すると、参加者（participant) に対するノートを表示することができます。 note left of \u0026lt;participant\u0026gt; [色]: テキスト: ライフラインの左側にノートを表示 note right of \u0026lt;participant\u0026gt; [色]: テキスト: ライフラインの右側にノートを表示 note over \u0026lt;participant\u0026gt; [色]: テキスト: ライフラインに重ねる形でノートを表示 @startuml participant Alice participant Bob Alice -\u0026gt; Bob: Long long long dummy message note left of Alice このノートは Alice の ライフラインの左側に 表示されます。 end note note right of Bob このノートは Bob の ライフラインの右側に 表示されます。 end note note right of Alice: これは Alice の右側に\\n表示されます。 note left of Bob: これは Bob の左側に\\n表示されます。 note over Alice: これは Alice の上に\\n重ねて表示されます。 note over Alice, Bob: これは Alice と Bob の上に\\n重ねて表示されます。 @endumls ノート (note) の背景色を変更する ノートの色を設定することもできます。 @startuml A -\u0026gt; B: message1 note left #LightGreen: LightGreen な色のノート A \u0026lt;- B: message2 note right #LightPink: LightPink な色のノート A -\u0026gt; B: message3 note left #CEF RGB 表記でもノート の色は設定できるよ end note @enduml スタイル設定 下の参加者 (participant) ボックスを非表示にする hide footbox を記述することで、下側のオブジェクトのボックスを非表示にすることができます。 @startuml hide footbox Alice -\u0026gt; Bob: message Bob -\u0026gt; Carol: message @enduml"
},
{
url: "/p/jyn7v9y/",
title: "MongoDB (mongo, mongod) をインストールする",
date: "2013-12-28T00:00:00Z",
body: "MongoDB (mongo, mongod) をインストールする 各種 OS 用のパッケージでインストールする MongoDB のクライアント (mongo) やサーバー (mongod)、その他の各種コマンド（mongoexport や mongostat など） は、下記のサイトから各種 OS 用のバイナリをダウンロードしてインストールすることができます。 MongoDB Download Center | MongoDB Windows 用のインストーラを使うと、簡単に mongod を Windows サービスとして登録したりすることができます（手動でサービス登録することもできます）。 インストールして、bin ディレクトリへのパスが通ったら、mongo コマンドを実行できるか確認しておきましょう。 mongo コマンドを実行できるか確認 $ mongo --version MongoDB shell version v4.0.9 git version: fc525e2d9b0e4bceff5c2201457e564362909765 allocator: tcmalloc modules: none build environment: distmod: 2008plus-ssl distarch: x86_64 target_arch: x86_64 macOS なら Homebrew でのインストールが楽 macOS の場合、Homebrew を使うと簡単に MongoDB のコマンド群（mongo や mongod）をインストールできます。 mongodb-community パッケージのインストール $ brew tap mongodb/brew # MongoDB 用のリポジトリ情報を追加 $ brew install mongodb-community # MongoDB 関連コマンドをインストール $ brew upgrade mongodb-community # （バージョンアップしたいとき） これで、/usr/local/bin に以下のようなコマンド群がインストールされます（正確にはこれらはシンボリックリンクであり、実体は /usr/local/Cellar/mongodb-* 以下にインストールされています）。 /usr/local/bin/mongo /usr/local/bin/mongod /usr/local/bin/mongodump /usr/local/bin/mongoexport /usr/local/bin/mongofiles /usr/local/bin/mongoimport /usr/local/bin/mongorestore /usr/local/bin/mongos /usr/local/bin/mongostat /usr/local/bin/mongotop ☝️ 古い mongodb パッケージを使用している場合 2019 年に Homebrew の Core リポジトリから mongodb パッケージが削除されました。 代わりに 3rd party リポジトリ (mongodb/brew) から、mongodb-community パッケージが配信されています。 以前の mongodb パッケージがインストールされている場合は、brew uninstall mongodb でアンインストールして、mongodb-community の方を使うようにしてください。 動作確認 $ mongo --version MongoDB shell version v4.4.5 ... $ mongod --version db version v4.4.5 ..."
},
{
url: "/p/pbp2dpy/",
title: "Next.js でコンポーネント内に直接 CSS を記述する (styled-jsx)",
date: "2021-05-04T00:00:00Z",
body: "Next.js でコンポーネント内に直接 CSS を記述する (styled-jsx) Next.js は CSS-in-JS ライブラリの一種である styled-jsx をデフォルトでサポートしています（styled-jsx も Next.js と同様に Vercel がメンテナンスしています）。 React コンポーネントの定義の中に、次のように CSS を直接記述することができます。 \u0026lt;style jsx\u0026gt;{` ... `}\u0026lt;/style\u0026gt; 下記は実際に styled-jsx を使って p 要素をスタイル設定した例です。 pages/sample.tsx export default () =\u0026gt; \u0026lt;\u0026gt; \u0026lt;p\u0026gt;only this paragraph will get the style\u0026lt;/p\u0026gt; \u0026lt;style jsx\u0026gt;{` p { color: red; } `}\u0026lt;/style\u0026gt; \u0026lt;/\u0026gt; ここで設定したスタイルのスコープは、この React コンポーネントに閉じたものになるため、他の React コンポーネントに影響を与えてしまう心配がありません。 そのため、シンプルなタグ名やクラス名でスタイル設定を行うことができます。 Next.js は、外部ファイルとして作成した .css や scss ファイルを読み込む CSS Modules の機能 もデフォルトでサポートしています（その場合は *.module.css というファイル名にするというルールがあります）。"
},
{
url: "/p/t7cfj92/",
title: "PlantUML でオブジェクト図を作成する",
date: "2018-10-15T00:00:00Z",
body: "PlantUML でオブジェクト図を作成する オブジェクト図はクラス図と同様の文法で記述することができます。 下記のページも参考にしてください。 PlantUML でクラス図を作成する オブジェクト図の基本 オブジェクト図 (object diagram) は、システム内のオブジェクト群のある時点のスナップショットを表現します。 具体的なオブジェクト同士の関係を表現することができるため、複雑な依存関係を持つオブジェクト インスタンス名は下線付きで「インスタンス名：クラス名」という形式で記述します。 インスタンス名とクラス名はどちらか一方を省略して記述することもできますが、クラス名だけを記述する場合は、「：クラス名」のようにコロン部分だけは残して記述します。 オブジェクト図は、メッセージなしのコミュニケーション図と考えることもできます。 ─『UMLモデリングのエッセンス第3版』マーチン・ファウラー PlantUML で登場させるオブジェクト群は、object キーワードを使って定義します。 as を使って別名を付けておくことができます。 @startuml object object1 object \u0026#34;My second object\u0026#34; as o2 @enduml 関連の線を引く オブジェクト同士の依存関係を示すには、-- でオブジェクト名（あるいは別名）を繋ぎます。 代わりに .. を使用すると、破線 (dashed line) で繋ぐことができます。 @startuml object object1 object \u0026#34;Second object\u0026#34; as o2 object \u0026#34;Third object\u0026#34; as o3 object \u0026#34;Fourth object\u0026#34; as o4 object1 -- o2 object1 -- o3 object1 -- o4 o2 .. o3 o3 .. o4 @enduml ハイフンやドットの数を 1 つに減らすことで、オブジェクトを横方向に配置することができます。 @startuml object-lines2 object object1 object \u0026#34;Second object\u0026#34; as o2 object \u0026#34;Third object\u0026#34; as o3 object \u0026#34;Fourth object\u0026#34; as o4 object1 -- o2 object1 -- o3 object1 -- o4 o2 . o3 o3 . o4 @enduml オブジェクト名に下線を引く オブジェクト図らしく、オブジェクト名に下線を引くには下記のようなマークアップを使用します。 @startuml rectangle \u0026#34;\u0026lt;u\u0026gt;tools: Organization\u0026lt;/u\u0026gt;\u0026#34; as tools rectangle \u0026#34;\u0026lt;u\u0026gt;John : Person\u0026lt;/u\u0026gt;\u0026#34; as john rectangle \u0026#34;\u0026lt;u\u0026gt;Don : Person\u0026lt;/u\u0026gt;\u0026#34; as don tools -- john tools -- don @enduml 上記では、object キーワードの代わりに rectangle キーワードを使ってオブジェクトを定義しているため、属性部分が表示されず、単純な矩形としてオブジェクトが表示されています。 関連を示すテキストを追加する 関連の線に沿う形でテキストを表示するには下記のようにします。 それぞれのオブジェクトに近い位置、あるいは中央に配置できます。 @startuml object Parent object Child1 object Child2 object Child3 Parent \u0026#34;parent\u0026#34; -- Child1 Parent -- \u0026#34;child\u0026#34; Child2 Parent -- Child3 : family @enduml 属性を表示する オブジェクトの属性（フィールド）を表示するには、下記のように、オブジェクトを定義した後で、オブジェクト名 : フィールド というフォーマットで記述していきます。 @startuml object \u0026#34;\u0026lt;u\u0026gt;tools: Organization\u0026lt;/u\u0026gt;\u0026#34; as tools object \u0026#34;\u0026lt;u\u0026gt;apps: Organization\u0026lt;/u\u0026gt;\u0026#34; as apps tools : location = \u0026#34;Chicago\u0026#34; apps : location = \u0026#34;Saba\u0026#34; @enduml 複数の属性を表示したいときは、次のように属性定義の行を追加していくか、 @startuml object \u0026#34;\u0026lt;u\u0026gt;tools: Organization\u0026lt;/u\u0026gt;\u0026#34; as tools object \u0026#34;\u0026lt;u\u0026gt;apps: Organization\u0026lt;/u\u0026gt;\u0026#34; as apps tools : location = \u0026#34;Chicago\u0026#34; tools : id = 100 apps : location = \u0026#34;Saba\u0026#34; apps : id = 200 @enduml あるいは、object 定義時にブロックを付加して属性を列挙します。 属性が 1 つだけの場合も、このようにブロックを使って記述しちゃった方がまとまりがあって分かりやすいかもしません。 @startuml object \u0026#34;\u0026lt;u\u0026gt;tools: Organization\u0026lt;/u\u0026gt;\u0026#34; as tools { location = \u0026#34;Chicago\u0026#34; id = 100 } object \u0026#34;\u0026lt;u\u0026gt;apps: Organization\u0026lt;/u\u0026gt;\u0026#34; as apps { location = \u0026#34;Saba\u0026#34; id = 200 } @enduml オブジェクト図のサンプル 最後に複雑なオブジェクト図のサンプルを載せておきます。 @startuml object \u0026#34;\u0026lt;u\u0026gt;engineering : Organization\u0026lt;/u\u0026gt;\u0026#34; as engineering { location = \u0026#34;Boston\u0026#34; } object \u0026#34;\u0026lt;u\u0026gt;tools : Organization\u0026lt;/u\u0026gt;\u0026#34; as tools { location = \u0026#34;Chicago\u0026#34; } object \u0026#34;\u0026lt;u\u0026gt;apps : Organization\u0026lt;/u\u0026gt;\u0026#34; as apps { location = \u0026#34;Saba\u0026#34; } object \u0026#34;\u0026lt;u\u0026gt;Don : Person\u0026lt;/u\u0026gt;\u0026#34; as don { location = \u0026#34;Champaign\u0026#34; } object \u0026#34;\u0026lt;u\u0026gt;John : Person\u0026lt;/u\u0026gt;\u0026#34; as john { location = \u0026#34;Champaign } engineering \u0026#34;parent\u0026#34; -- tools engineering -- apps tools \u0026#34;parent\u0026#34; -- don tools \u0026#34;parent\u0026#34; -- john @enduml 出典：『UMLモデリングのエッセンス第3版』マーチン・ファウラー著"
},
{
url: "/p/x3ocp9a/",
title: "TypeScriptの型: 辞書型を定義する (Dictionary)",
date: "2020-02-04T00:00:00Z",
body: "TypeScriptの型: 辞書型を定義する (Dictionary) 辞書オブジェクトを作成する JavaScript の配列は、もともと「キー＆値」を扱う連想配列として使用することができますが、TypeScript のタイプアノテーションを使うと、キーの型と値の型 を明示した辞書 (Dictionary) オブジェクトを作成することができます。 次の例では、文字列のキーと、数値の値を持つ辞書オブジェクトを作成しています。 // 辞書オブジェクトを作成する const userAges: { [name: string]: number } = {}; // 辞書オブジェクトを使用する userAges[\u0026#39;maku\u0026#39;] = 14; userAges[\u0026#39;hemu\u0026#39;] = 6; console.log(userAges[\u0026#39;maku\u0026#39;]); //=\u0026gt; 14 console.log(userAges[\u0026#39;hemu\u0026#39;]); //=\u0026gt; 6 間違った型のキーや値を格納しようとするとエラーになります。 userAges[14] = \u0026#39;maku\u0026#39;; // Error!! 辞書型のインタフェースを定義する 単純な辞書 上記の例では、辞書オブジェクトを生成するときに同時にその型を指定していましたが、あらかじめ辞書型を表すインタフェースだけを定義しておくこともできます。 次の UserAges インタフェースは、文字列型のキーと数値型の値を持つ、よくある辞書の定義例です。 // 辞書オブジェクトを作成する interface UserAges { [name: string]: number; } // 使用例 const userAges: UserAges = {}; userAges[\u0026#39;maku\u0026#39;] = 14; console.log(userAges[\u0026#39;maku\u0026#39;]); //=\u0026gt; 14 任意のオブジェクトを値にする辞書 次の UserDictionary インタフェースは、文字列型のキーと User 型の値を持つ辞書型を表しています。 UserDictionary インタフェースの定義 interface User { name: string; age: number; } interface UserDictionary { [id: string]: User; } UserDictionary インタフェースは次のように使用します。 UserDictionary インタフェースの使用例 // 辞書オブジェクトの作成 const dic: UserDictionary = {}; dic[\u0026#39;maku\u0026#39;] = { name: \u0026#39;Makkuma\u0026#39;, age: 14 }; dic[\u0026#39;hemu\u0026#39;] = { name: \u0026#39;Hemumu\u0026#39;, age: 6 }; // 辞書の参照 const maku = dic[\u0026#39;maku\u0026#39;]; console.log(maku.name); //=\u0026gt; Makkuma console.log(maku.age); //=\u0026gt; 14 辞書からキーを削除する 辞書のキー（とその値）を削除するには、delete キーワードを使用します。 delete dic[\u0026#39;maku\u0026#39;]; // 辞書から maku のエントリを削除 console.log(Object.keys(dic).length); //=\u0026gt; 1（キーのサイズが減ってる） 辞書をループ処理する 辞書内の要素をループ処理するには、例えば次のようにキーをループ処理します。 Object.keys(dic).forEach(key =\u0026gt; { const value = dic[key]; console.log(value.name); console.log(value.age); }); ES 2017 以降であれば、Object.entries() 関数を使って、キーと値のペアを取り出しながらループ処理できます。 ES 2017 以降の辞書ループ Object.entries(dic).forEach(([key, value]) =\u0026gt; { console.log(key); console.log(value); }); ちなみに、tsc コマンドなどで TypeScript コードをトランスパイルしている場合、ES 2017 の機能を使うには、compilerOptions.target の項目で ES2017 以上を指定しておく必要があります。 tsconfig.json { \u0026#34;compilerOptions\u0026#34;: { \u0026#34;outDir\u0026#34;: \u0026#34;./build\u0026#34;, \u0026#34;allowJs\u0026#34;: true, \u0026#34;target\u0026#34;: \u0026#34;ES2017\u0026#34;, \u0026#34;module\u0026#34;: \u0026#34;commonjs\u0026#34;, \u0026#34;strict\u0026#34;: true }, \u0026#34;include\u0026#34;: [ \u0026#34;./src/**/*\u0026#34; ] } なぜ辞書オブジェクトの型定義は分かりにくいのか？ { [name: string]: number } という辞書オブジェクトの型定義は、「次のように簡潔に記述できないの？」と思うかもしれません。 { string: number } しかし、後者の定義は辞書型を示すものではなく、string という名前のプロパティを持つオブジェクト型を定義するものになってしまいます。 使い方も、次のようにまったく異なります。 // これは複数の「key＆value」を格納できる辞書オブジェクト const dic: { [name: string]: number } = {}; dic[\u0026#39;Maku\u0026#39;] = 5; dic[\u0026#39;Hemu\u0026#39;] = 10; dic[\u0026#39;Puni\u0026#39;] = 15; // これは単一のオブジェクトを格納する変数 let data: { string: number }; data = { string: 100 }; TypeScript の辞書オブジェクトの型定義は、最初は面食らうかもしれませんが、 型定義の中に [] が出てきたら、それは辞書オブジェクトのキーの型 なのだということが分かっていれば、コードもスラスラと読めるようになります。"
},
{
url: "/p/ttwoetd/",
title: "TypeScriptの型: 配列を定義する (Array)",
date: "2020-01-22T00:00:00Z",
body: "TypeScriptの型: 配列を定義する (Array) TypeScript で配列を定義するには、次のいずれかの方法を使います。 文字列配列を作成する const strArr: string[] = []; const strArr: Array\u0026lt;string\u0026gt; = []; ここでは初期値として空の配列 [] を代入しています。 const で変数を作成していますが、JavaScript の const は変数自体への代入を制限するだけなので、配列の内容を変更することは可能です。 const nums: number[] = []; nums.push(100); nums.push(200); nums.push(300); for (const x of nums) { console.log(x); } 実行結果 100 200 300 参考リンク TypeScript: タプルを定義する (Tuple types)"
},
{
url: "/p/6uzqf4q/",
title: "TypeScriptの型: タプルを定義する (Tuple types)",
date: "0001-01-01T00:00:00Z",
body: "TypeScriptの型: タプルを定義する (Tuple types) タプルの基本 TypeScript のタプル型は、複数の値を保持することのできる型です。 [] 記号を使うところも配列によく似ていますが、それぞれの位置の要素の型を明示しておくことができます。 文字列と数値のタプルを定義する例 let vote: [string, number] vote = [\u0026#39;red\u0026#39;, 100]; // OK vote = [\u0026#39;green\u0026#39;, 200]; // OK vote = [\u0026#39;yellow\u0026#39;, 300]; // OK vote = [\u0026#39;AAA\u0026#39;, \u0026#39;BBB\u0026#39;]; // Error 上記の例では、2 つの値を保持するタプル型変数を定義していますが、3 つ以上の値を保持するタプルを定義することもできます。 配列と同様、タプルの各要素にはインデックスでアクセスできます。 let data: [string, number, number] data = [\u0026#39;maku\u0026#39;, 100, 5]; // インデックスで各要素を参照 console.log(data[0]); //=\u0026gt; maku console.log(data[1]); //=\u0026gt; 100 console.log(data[2]); //=\u0026gt; 5 // ループで各要素を取り出す for (const x of data) { console.log(x); } タプルによる多値関数 タプルを関数の戻り値として使用すると、複数の値を返す「多値関数」として扱うことができます。 function getResult(): [number, string] { return [404, \u0026#39;Not Found\u0026#39;]; } const result = getResult(); console.log(result); //=\u0026gt; [404, \u0026#39;Not Found\u0026#39;] 次のようにすると、返されたタプルを複数の変数に分解して受け取ることができます。 const [code, message] = getResult(); console.log(code); //=\u0026gt; 404 console.log(message); //=\u0026gt; Not Found ただ、タプル型は各位置の値が何を示しているかが不明瞭になってしまうので、できればインタフェースを使って、明確にプロパティを定義した方がよいでしょう。 interface HttpStatus { code: number; message: string; } function getResult(): HttpStatus { return { code: 404, message: \u0026#39;Not Found\u0026#39; }; } const result: HttpStatus = getResult(); console.log(result.code); //=\u0026gt; 404 console.log(result.message); //=\u0026gt; Not Found 参考リンク TypeScript: 配列を定義する (Array)"
},
{
url: "/p/s6djqw3/",
title: "Next.js で Material-UI を使う",
date: "2021-06-02T00:00:00Z",
body: "Next.js で Material-UI を使う Material-UI は、マテリアルデザインを提供する React コンポーネントライブラリです。 Material-UI のインストール Material-UI のコアパッケージ (@material-ui/core) は、npm コマンドで簡単にインストールできます。 マテリアルデザイン系のアイコン を使いたい場合は、@material-ui/icons パッケージもインストールしておきます。 ### yarn の場合 $ yarn add @material-ui/core $ yarn add @material-ui/icons ### npm の場合 $ npm install @material-ui/core $ npm install @material-ui/icons Next.js の create-next-app コマンドでプロジェクトを作成済みであれば、これだけで Material-UI コンポーネントを使う準備は完了です。 Material-UI のデフォルトテーマは Roboto フォントを使用する ので、次のようなコードを head 要素内に記述する必要がありますが、これは後述の _document.tsx で設定します。 \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;https://fonts.googleapis.com/css?family=Roboto:300,400,500,700\u0026amp;display=swap\u0026#34; /\u0026gt; Material-UI は font weight に 300/400/500/700 のいずれかを使用するので、上記のように読み込むデータを制限することで、ロード時間を削減できます。 Material-UI のコンポーネントを使ってみる Material-UI のインストールができたら、あとは、各コンポーネントの実装ファイルから import するだけで使用できます。 次の例では、Button コンポーネントと、ButtonGroup コンポーネントを使っています。 pages/index.tsx import { Button, ButtonGroup } from \u0026#39;@material-ui/core\u0026#39; export default function Home() { return ( \u0026lt;\u0026gt; \u0026lt;div style={{ margin: \u0026#39;0.5em\u0026#39; }}\u0026gt; \u0026lt;Button variant=\u0026#34;contained\u0026#34;\u0026gt;Default\u0026lt;/Button\u0026gt;{\u0026#39; \u0026#39;} \u0026lt;Button variant=\u0026#34;contained\u0026#34; color=\u0026#34;primary\u0026#34;\u0026gt;Primary\u0026lt;/Button\u0026gt;{\u0026#39; \u0026#39;} \u0026lt;Button variant=\u0026#34;contained\u0026#34; color=\u0026#34;secondary\u0026#34;\u0026gt;Secondary\u0026lt;/Button\u0026gt;{\u0026#39; \u0026#39;} \u0026lt;Button variant=\u0026#34;contained\u0026#34; disabled\u0026gt;Disabled\u0026lt;/Button\u0026gt;{\u0026#39; \u0026#39;} \u0026lt;Button variant=\u0026#34;contained\u0026#34; color=\u0026#34;primary\u0026#34; href=\u0026#34;https://google.com/\u0026#34;\u0026gt;LINK\u0026lt;/Button\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div style={{ margin: \u0026#39;0.5em\u0026#39; }}\u0026gt; \u0026lt;ButtonGroup variant=\u0026#34;contained\u0026#34; color=\u0026#34;primary\u0026#34; aria-label=\u0026#34;contained primary button group\u0026#34;\u0026gt; \u0026lt;Button\u0026gt;One\u0026lt;/Button\u0026gt; \u0026lt;Button\u0026gt;Two\u0026lt;/Button\u0026gt; \u0026lt;Button\u0026gt;Three\u0026lt;/Button\u0026gt; \u0026lt;/ButtonGroup\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/\u0026gt; ) } Next.js 用の App / Document コンポーネント設定 Material-UI を Next.js アプリから使用する場合は、サーバーサイドレンダリングとの兼ね合いで、pages/_app.tsx と pages/_document.tsx を作成して、スタイル定義の処理順序を制御しておく必要があります。 これを入れておかないと、makeStyle などを使ったスタイル設定 がうまく反映されず、次のようなエラーになったりします。 Warning: Prop `className` did not match. Server: \u0026#34;MuiTypography-root makeStyles-customText-5 ...\u0026#34; Client: \u0026#34;MuiTypography-root makeStyles-customText-1 ...\u0026#34; これは、サーバーサイド側で生成された CSS クラス名が、クライアント側で参照しようとしているクラス名と食い違ってしまった場合に発生します（クラス名を自動生成する仕組みのため、タイミングによって発生します）。 具体的な対応方法に関しては、Material-UI のドキュメントには下記のコードを参照、と書かれていますが、こちらは残念ながら TypeScript に対応していないので、ここでは TypeScript 化したコードを載せておきます。 material-ui/examples/nextjs pages/_app.tsx import React from \u0026#39;react\u0026#39; import { AppProps } from \u0026#39;next/app\u0026#39; import Head from \u0026#39;next/head\u0026#39; import { CssBaseline } from \u0026#39;@material-ui/core\u0026#39; import { ThemeProvider } from \u0026#39;@material-ui/core/styles\u0026#39; import theme from \u0026#39;./theme\u0026#39; export default function MyApp({ Component, pageProps }: AppProps): JSX.Element { React.useEffect(() =\u0026gt; { // Remove the server-side injected CSS. const jssStyles = document.querySelector(\u0026#39;#jss-server-side\u0026#39;) jssStyles?.parentElement?.removeChild(jssStyles) }, []) return ( \u0026lt;\u0026gt; \u0026lt;Head\u0026gt; \u0026lt;title\u0026gt;MyApp\u0026lt;/title\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;minimum-scale=1, initial-scale=1, width=device-width\u0026#34; /\u0026gt; \u0026lt;/Head\u0026gt; \u0026lt;ThemeProvider theme={theme}\u0026gt; \u0026lt;CssBaseline /\u0026gt; \u0026lt;Component {...pageProps} /\u0026gt; \u0026lt;/ThemeProvider\u0026gt; \u0026lt;/\u0026gt; ) } pages/_document.tsx では、Roboto フォントの読み込みも行っています。 pages/_document.tsx import React from \u0026#39;react\u0026#39; import Document, { DocumentContext, DocumentInitialProps, Html, Head, Main, NextScript, } from \u0026#39;next/document\u0026#39; import { ServerStyleSheets } from \u0026#39;@material-ui/core/styles\u0026#39; import theme from \u0026#39;./theme\u0026#39; export default class MyDocument extends Document { render(): JSX.Element { return ( \u0026lt;Html lang=\u0026#34;ja\u0026#34;\u0026gt; \u0026lt;Head\u0026gt; {/* PWA primary color */} \u0026lt;meta name=\u0026#34;theme-color\u0026#34; content={theme.palette.primary.main} /\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;https://fonts.googleapis.com/css?family=Roboto:300,400,500,700\u0026amp;display=swap\u0026#34; /\u0026gt; \u0026lt;/Head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;Main /\u0026gt; \u0026lt;NextScript /\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/Html\u0026gt; ) } // `getInitialProps` belongs to `_document` (instead of `_app`), // it\u0026#39;s compatible with server-side generation (SSG). static async getInitialProps( ctx: DocumentContext ): Promise\u0026lt;DocumentInitialProps\u0026gt; { // Render app and page and get the context of the page with collected side effects. const sheets = new ServerStyleSheets() const originalRenderPage = ctx.renderPage ctx.renderPage = () =\u0026gt; originalRenderPage({ enhanceApp: (App) =\u0026gt; (props) =\u0026gt; sheets.collect(\u0026lt;App {...props} /\u0026gt;), }) const initialProps = await Document.getInitialProps(ctx) return { ...initialProps, // Styles fragment is rendered after the app and page rendering finish. styles: [ ...React.Children.toArray(initialProps.styles), sheets.getStyleElement(), ], } } } 上記のファイルからテーマ設定ファイル theme.ts を参照しているので、これも作成しておきます。 サイト全体のプライマリカラーや、セカンダリカラーをここで設定できます。 pages/theme.ts import { createMuiTheme } from \u0026#39;@material-ui/core/styles\u0026#39; import { red } from \u0026#39;@material-ui/core/colors\u0026#39; const theme = createMuiTheme({ palette: { //primary: { // main: \u0026#39;#556cd6\u0026#39;, //}, //secondary: { // main: \u0026#39;#19857b\u0026#39;, //}, error: { main: red.A400, }, background: { default: \u0026#39;#fff\u0026#39;, }, }, }) export default theme"
},
{
url: "/p/cw9ju6f/",
title: "Material-UI のコンポーネントに独自の CSS スタイルを設定する (makeStyle)",
date: "2021-06-06T00:00:00Z",
body: "Material-UI のコンポーネントに独自の CSS スタイルを設定する (makeStyle) Material-UI コンポーネントのスタイル設定 Material-UI が提供する各種コンポーネントには、表示スタイルを切り替えるためのプロパティが用意されています。 例えば、Button コンポーネント は variant や color プロパティで見た目を切り替えることができます。 \u0026lt;Button\u0026gt;Default\u0026lt;/Button\u0026gt; \u0026lt;Button variant=\u0026#34;contained\u0026#34; color=\u0026#34;primary\u0026#34;\u0026gt;Primary\u0026lt;/Button\u0026gt; \u0026lt;Button variant=\u0026#34;contained\u0026#34; color=\u0026#34;secondary\u0026#34;\u0026gt;Secondary\u0026lt;/Button\u0026gt; \u0026lt;Button variant=\u0026#34;outlined\u0026#34; disabled\u0026gt;Disabled\u0026lt;/Button\u0026gt; 多くのケースでは、この仕組みで十分にスタイル設定できるのですが、デフォルトのスタイルから外れた表示をしたり、div 要素など Material-UI 以外のコンポーネントに対して独自の CSS を適用したいことがあります。 このような場合、コンポーネントの実装ファイル内に直接 CSS コードを記述してスタイルをカスタマイズできます（JavaScript 内に記述するので CSS-in-JS と呼びます）。 React の世界では色々な CSS 参照方法がありますが、Material-UI は次のような理由で CSS-in-JS な記述方法を採用しています。 現在のテーマ設定に基づいたスタイル設定を行える（例: 基準スペースの2倍のマージンを設定する） コンポーネントの props の値を使って動的にスタイル設定できる（例: \u0026lt;MyButton color=\u0026quot;vivid\u0026quot;\u0026gt; で派手な色のスタイルを設定する） フックによるスタイル設定 (makeStyle) Material-UI で、コンポーネントに独自スタイルを設定する方法としては、主に次の 3 種類の方法が用意されています。 Hook API makeStyle 関数で生成したフック関数をコンポーネント内で呼び出す方法。一番よく使われてる。 Styled components API 既存のコンポーネント (Button など）をラップする形で、スタイルを適用したコンポーネント（MyButton など）を作成する方法。 Higher-order component API Styled components に似てるけど、HoC の仕組みでスタイル設定したコンポーネントを作成する方法。ちょっとわかりにくい。 ここでは、一番メジャーで分かりやすい、フックを利用したスタイル設定方法を紹介します。 次の例では、Material-UI の Button コンポーネントに、独自の CSS スタイル（customButton クラス）を適用しています。 components/MyButton.tsx import { Button } from \u0026#39;@material-ui/core\u0026#39; import { makeStyles } from \u0026#39;@material-ui/core/styles\u0026#39; const useStyles = makeStyles({ customButton: { color: \u0026#39;white\u0026#39;, background: \u0026#39;#229966\u0026#39;, padding: \u0026#39;1em 3em\u0026#39;, }, }) const MyButton: React.FC = () =\u0026gt; { const classes = useStyles() return \u0026lt;Button className={classes.customButton}\u0026gt;Button\u0026lt;/Button\u0026gt; } export default MyButton ポイントは、makeStyles 関数 で作成したフック関数を呼び出して、その戻り値のオブジェクトを使って各コンポーネントの className プロパティを指定するところです。 基本はこれだけなので、このやり方に慣れてしまえば OK です。 Props によるスタイル設定の分岐 CSS-in-JS なスタイル記述方法の利点の一つとして、次のような動的なスタイル設定があります。 この例では、スタイル設定用のフック関数 (useStyles) に、StyleProps 型の引数を渡すことでテキストの色を切り替えています。 components/MyLabel.tsx import { Typography } from \u0026#39;@material-ui/core\u0026#39; import { makeStyles, Theme } from \u0026#39;@material-ui/core/styles\u0026#39; // スタイル定義用のフック関数が受け取るプロパティの型 type StyleProps = { textStyle: \u0026#39;normal\u0026#39; | \u0026#39;vivid\u0026#39; } const useStyles = makeStyles\u0026lt;Theme, StyleProps\u0026gt;({ customText: { // 引数で渡されたオブジェクトの値で分岐処理できる color: (props) =\u0026gt; (props.textStyle === \u0026#39;normal\u0026#39; ? \u0026#39;black\u0026#39; : \u0026#39;#ff6633\u0026#39;), }, }) const MyLabel: React.FC = () =\u0026gt; { const classes = useStyles({ textStyle: \u0026#39;vivid\u0026#39; }) return \u0026lt;Typography className={classes.customText}\u0026gt;Hello\u0026lt;/Typography\u0026gt; } export default MyLabel 上記の例では、コンポーネントの実装内で StyleProps オブジェクトを作成して useStyles に渡していますが、コンポーネント自身の Props オブジェクトをそのまま渡してしまう方が一般的かもしれません。 components/MyLabel.tsx import { Typography } from \u0026#39;@material-ui/core\u0026#39; import { makeStyles, Theme } from \u0026#39;@material-ui/core/styles\u0026#39; type Props = { textStyle?: \u0026#39;normal\u0026#39; | \u0026#39;vivid\u0026#39; children: React.ReactNode } const useStyles = makeStyles\u0026lt;Theme, Props\u0026gt;({ customText: { color: (props) =\u0026gt; (props.textStyle === \u0026#39;normal\u0026#39; ? \u0026#39;black\u0026#39; : \u0026#39;#ff6633\u0026#39;), }, }) const MyLabel: React.FC\u0026lt;Props\u0026gt; = (props: Props) =\u0026gt; { const classes = useStyles(props) return ( \u0026lt;Typography className={classes.customText}\u0026gt;{props.children}\u0026lt;/Typography\u0026gt; ) } MyLabel.defaultProps = { textStyle: \u0026#39;normal\u0026#39;, } export default MyLabel こうすると、そのコンポーネントを使う側でスタイルを制御できるようになります。 pages/index.tsx import MyLabel from \u0026#39;../components/MyLabel\u0026#39; const IndexPage: React.FC = () =\u0026gt; { return ( \u0026lt;div\u0026gt; \u0026lt;MyLabel\u0026gt;Default Label\u0026lt;/MyLabel\u0026gt; \u0026lt;MyLabel textStyle=\u0026#34;normal\u0026#34;\u0026gt;Normal Label\u0026lt;/MyLabel\u0026gt; \u0026lt;MyLabel textStyle=\u0026#34;vivid\u0026#34;\u0026gt;Vivid Label\u0026lt;/MyLabel\u0026gt; \u0026lt;/div\u0026gt; ) } export default IndexPage オブジェクト間のマージン用にスタイル設定する makeStyle で作成したスタイル設定は、Material-UI のコンポーネント以外にも適用できます。 次の例では、div 要素に独自スタイルを適用し、子要素のマージンを現在のテーマのスペース 1 つ分 (theme.spacing(1)) に設定しています。 スタイルオブジェクトを入れ子の形で定義すると、プロパティ名の部分で \u0026amp; を使ってカレント要素を参照できます。 import { Button } from \u0026#39;@material-ui/core\u0026#39; import { makeStyles, Theme } from \u0026#39;@material-ui/core/styles\u0026#39; const useStyles = makeStyles((theme: Theme) =\u0026gt; ({ root: { \u0026#39;\u0026amp; \u0026gt; *\u0026#39;: { margin: theme.spacing(1), }, }, })) const IndexPage: React.FC = () =\u0026gt; { const classes = useStyles() return ( \u0026lt;div className={classes.root}\u0026gt; \u0026lt;Button variant=\u0026#34;contained\u0026#34;\u0026gt;Button 1\u0026lt;/Button\u0026gt; \u0026lt;Button variant=\u0026#34;contained\u0026#34;\u0026gt;Button 2\u0026lt;/Button\u0026gt; \u0026lt;Button variant=\u0026#34;contained\u0026#34;\u0026gt;Button 3\u0026lt;/Button\u0026gt; \u0026lt;/div\u0026gt; ) } export default IndexPage"
},
{
url: "/p/5e4cikn/",
title: "MUI (Material-UI) でカスタムコンポーネントに sx プロパティを渡せるようにする",
date: "2021-12-15T00:00:00Z",
body: "MUI (Material-UI) でカスタムコンポーネントに sx プロパティを渡せるようにする 何をするか？ MUI (Material-UI) ver.5 以降では、各コンポーネントのスタイル設定に便利な sx props を使うことができます。 The sx prop - MUI MUI コンポーネントをラップするようなカスタムコンポーネントを作成するときは、カスタムコンポーネント経由で sx props を渡せるようにしておくと、利用するときにマージン設定などを簡単に行えて便利です。 実装例 下記は、sx props を渡せるようにした CustomButton コンポーネントの実装例です。 sx props の値は、MUI の Button コンポーネントにそのまま渡しています。 型情報として SxProps\u0026lt;Theme\u0026gt; を使うところがポイントです。 src/components/CustomButton.tsx import { FC, ReactNode } from \u0026#39;react\u0026#39; import Button from \u0026#39;@mui/material/Button\u0026#39; import { SxProps, Theme } from \u0026#39;@mui/material/styles\u0026#39; type Props = { children: ReactNode sx?: SxProps\u0026lt;Theme\u0026gt; } export const CustomButton: FC\u0026lt;Props\u0026gt; = ({ children, sx }) =\u0026gt; { return ( \u0026lt;Button variant=\u0026#34;contained\u0026#34; sx={sx}\u0026gt; {children} \u0026lt;/Button\u0026gt; ) } これで、次のように sx prop 流のマージン設定などを行えるようになります。 src/pages/index.tsx（抜粋） \u0026lt;CustomButton sx={{ m: 2 }}\u0026gt;Hello\u0026lt;/CustomButton\u0026gt; 上記のカスタムコンポーネントの実装例では、sx props の値を Button コンポーネントに渡していますが、複数要素から構成されるカスタムコンポーネントの場合は、次のように最上のコンテナ系コンポーネント（Box や Stack など）の sx props に渡した方がよいでしょう。 src/components/CustomButton.tsx import { FC, ReactNode } from \u0026#39;react\u0026#39; import Button from \u0026#39;@mui/material/Button\u0026#39; import Stack from \u0026#39;@mui/material/Stack\u0026#39; import Typography from \u0026#39;@mui/material/Typography\u0026#39; import { SxProps, Theme } from \u0026#39;@mui/material/styles\u0026#39; type Props = { children: ReactNode sx?: SxProps\u0026lt;Theme\u0026gt; } export const CustomButton: FC\u0026lt;Props\u0026gt; = ({ children, sx }) =\u0026gt; { return ( \u0026lt;Stack direction=\u0026#34;row\u0026#34; spacing={1} alignItems=\u0026#34;center\u0026#34; sx={sx}\u0026gt; \u0026lt;Button variant=\u0026#34;contained\u0026#34;\u0026gt;{children}\u0026lt;/Button\u0026gt; \u0026lt;Typography variant=\u0026#34;subtitle2\u0026#34;\u0026gt;Amazing!\u0026lt;/Typography\u0026gt; \u0026lt;/Stack\u0026gt; ) }"
},
{
url: "/p/tiwamzb/",
title: "TypeScriptの型: 関数を定義する (function)",
date: "2020-06-22T00:00:00Z",
body: "TypeScriptの型: 関数を定義する (function) TypeScript の関数定義は JavaScript とほぼ同じですが、各パラメータと戻り値に型アノテーション付けることができます。 簡単な関数 次の indent 関数は、指定したレベルのインデント文字列（レベル数x2 の半角スペース）を返します。 TypeScript の型アノテーションで、number 型のパラメータと、string 型の戻り値を持つことを示しています。 function indent(level: number): string { return \u0026#39; \u0026#39;.repeat(level); } console.log(indent(0) + \u0026#39;AAA\u0026#39;); //=\u0026gt; \u0026#39;AAA\u0026#39; console.log(indent(1) + \u0026#39;BBB\u0026#39;); //=\u0026gt; \u0026#39; BBB\u0026#39; console.log(indent(2) + \u0026#39;CCC\u0026#39;); //=\u0026gt; \u0026#39; CCC\u0026#39; 関数オブジェクト 名前なしの関数オブジェクトやアロー関数を使用するときも同様に、パラメータや戻り値の型をアノテートできます。 const add = function(a: number, b: number) { return a + b; }; const sub = (a: number, b: number) =\u0026gt; { return a - b; }; console.log(add(1, 2)); //=\u0026gt; 3 console.log(sub(1, 2)); //=\u0026gt; -1 関数の実装から戻り値の型を推測できる場合は、上記のように戻り値の型アノテーションを省略できます（この場合は : number が省略されています）。 戻り値を返さないを示す void 関数を抜ける時に、何も値を返さない場合は、戻り値の型を void にします。 function greet(name: string): void { console.log(`Hello, ${name}`); } greet(\u0026#39;Maku\u0026#39;); //=\u0026gt; \u0026#39;Hello, Maku\u0026#39; 戻り値を持たない関数はよくあるので、void 型のアノテーションは 省略してもよい ことになっています。 function greet(name: string) { console.log(`Hello, ${name}`); } 関数が終わらないことを示す never 戻り値の型として never を指定すると、その関数は終了することがないことを示します。 無限ループはその典型的な例です。 function neverEnding(): never { while (true) { console.log(\u0026#39;Hello\u0026#39;); } } neverEnding(); 必ず例外をスローする関数も never でアノテートできます。 function error(msg: string): never { throw Error(`My error - ${msg}`); } error(\u0026#39;Hoge\u0026#39;); オプショナルパラメータとデフォルト引数 オプショナルパラメータ パラメータ名の末尾に ? を付けると、そのパラメータはオプショナル扱いとなり、関数の呼び出し時に引数を省略することができるようになります。 function greet(name?: string) { if (name) { console.log(`Hello, ${name}`); } else { console.log(\u0026#39;名を名乗れっ！\u0026#39;); } } greet(\u0026#39;まく\u0026#39;); //=\u0026gt; \u0026#39;Hello, まく\u0026#39; greet(); //=\u0026gt; \u0026#39;名を名乗れっ！\u0026#39; greet(undefined); //=\u0026gt; （同上） greet(\u0026#39;\u0026#39;); //=\u0026gt; （同上） 引数を省略された場合、関数内でその値を参照すると undefined になります。 JavaScript では、undefined を真偽値として評価すると false 扱いとなるので、上記のように if 文で条件分岐させることができます。 ただし、空文字列 ('') も false として評価されることに注意してください。 変数の値が undefined であることを確実にチェックしたいときは、次のように typeof を使って判定してください。 function greet(name?: string) { if (typeof name === \u0026#39;undefined\u0026#39;) { console.log(\u0026#39;名を名乗れっ！\u0026#39;); } else { console.log(`Hello, ${name}`); } } greet(\u0026#39;まく\u0026#39;); //=\u0026gt; \u0026#39;Hello, まく\u0026#39; greet(); //=\u0026gt; \u0026#39;名を名乗れっ！\u0026#39; greet(undefined); //=\u0026gt; （同上） greet(\u0026#39;\u0026#39;); //=\u0026gt; \u0026#39;Hello, \u0026#39; デフォルト引数 引数が省略された場合のデフォルト値を指定したい場合は、次のように デフォルト引数 の仕組みを使用すると簡単です。 function greet(name: string = \u0026#39;名無しさん\u0026#39;) { console.log(`Hello, ${name}`); } greet(\u0026#39;まく\u0026#39;); //=\u0026gt; \u0026#39;Hello, まく\u0026#39; greet(); //=\u0026gt; \u0026#39;Hello, 名無しさん\u0026#39;"
},
{
url: "/p/5q5gs4f/",
title: "TypeScriptの型: インタフェースを定義する (interface)",
date: "2020-06-22T00:00:00Z",
body: "TypeScriptの型: インタフェースを定義する (interface) プロパティを定義する 次の例では、2 つのプロパティ x、y を持つインタフェース Point を定義しています。 // Point インタフェースの定義 interface Point { x: number; y: number; } このインタフェースを使って、次のようにオブジェクトを生成することができます。 オブジェクトを生成するときには、インタフェースで定義されているすべてのプロパティに値を設定してやる必要があります。 // Point 型のオブジェクトを生成 const p: Point = { x: 10, y: 20 }; // 内容を出力してみる console.log(`x=${p.x}, y=${p.y}`); //=\u0026gt; x=10, y=20 Java などと異なり、TypeScript ではインタフェース定義さえあれば、上記のようにその型のオブジェクトを生成することができます（Java では厳密にはクラス定義がないとオブジェクトを生成できません）。 そのため、TypeScript では、interface キーワードを使ったインタフェース定義の頻度が高くなります。 TypeScript のインタフェースは、拡張に対してオープンであり、次のように後付けでプロパティを追加することができます。 interface Point { x: number; y: number; } // Point インタフェースにプロパティを追加 interface Point { z: number; } const p: Point = { x: 1, y: 2, z: 3 }; メソッドを定義する インタフェースでは、オブジェクトが持つべきメソッドを定義することができます。 次の Product インタフェースは、2 つのプロパティ name、price の他に、1 つのメソッド calcTotal() を持つ型を示しています。 // Product インタフェースを定義 interface Product { name: string; price: number; calcTotal(quantity: number): number; } この Product 型のオブジェクトを生成するには次のようにします。 プロパティの値だけではなく、メソッドの実装もこのタイミングで渡す必要があります。 // Product 型のオブジェクトを生成 const prod: Product = { name: \u0026#39;Brown Shelf\u0026#39;, price: 250, calcTotal(quantity: number): number { return this.price * quantity; } }; console.log(prod.calcTotal(4)); //=\u0026gt; 1000 もっとも、オブジェクト生成時に上記のように毎回メソッドの実装を渡していては大変なので、このような場合は、通常はクラス定義を使用します。 参考: クラス定義の基本 (class)"
},
{
url: "/p/rpfr5fr/",
title: "TypeScriptの型: インタフェースのプロパティをオプショナルにする",
date: "2020-04-28T00:00:00Z",
body: "TypeScriptの型: インタフェースのプロパティをオプショナルにする オプショナルプロパティの定義 TypeScript でインタフェースを定義するとき、プロパティ名の末尾に ? を付けると、そのプロパティをオプショナルプロパティとすることができます（関数のオプショナルパラメータと同様です）。 例えば、次の User インタフェースの age プロパティはオプショナルになっているため、User オブジェクトを生成するときに age プロパティの値を省略することができます。 interface User { name: string; age?: number; // age プロパティはオプショナル } const u1: User = { name: \u0026#39;Maku\u0026#39;, age: 5 }; // OK const u2: User = { name: \u0026#39;Maku\u0026#39; }; // OK console.log(u1.age); //=\u0026gt; 5 console.log(u2.age); //=\u0026gt; undefined インタフェースを定義せずに、変数の定義時に型情報を指定する場合も同様です。 let user: { name: string, age?: number }; user = { name: \u0026#39;Maku\u0026#39;, age: 5 }; // OK user = { name: \u0026#39;Maku\u0026#39; }; // OK user = { age: 5 }; // Error オプショナルなプロパティを定義する代わりに、特定の値（例えば -1）を、値がないことを示すために使用するという方法もありますが、プロパティ自体格納せずに undefined としておく方が分かりやすいでしょう。 オプショナルプロパティが指定されたか調べる オブジェクトが、あるプロパティを保持しているかどうかを調べるには、次のように in や typeof を使って確認します。 if (\u0026#39;age\u0026#39; in user) { // age プロパティが存在する } if (typeof user.age === \u0026#39;undefined\u0026#39;) { // age プロパティが存在しない } 使用例 次の getUser 関数は、name プロパティと age プロパティを持つ User オブジェクトを返す関数ですが、場合によっては age プロパティを持たないオブジェクトを返すことを示しています。 interface User { name: string; age?: number; // age プロパティはオプショナル } function getUser(withAge: boolean): User { return withAge ? {name: \u0026#39;Maku\u0026#39;, age: 5} : {name: \u0026#39;Maku\u0026#39;}; } // main const user = getUser(true); console.log(`name = ${user.name}`); if (\u0026#39;age\u0026#39; in user) { console.log(`age = ${user.age}`) }"
},
{
url: "/p/p8ir2ai/",
title: "TypeScriptの型: インタフェースのプロパティを読み取り専用にする (readonly)",
date: "2020-06-22T00:00:00Z",
body: "TypeScriptの型: インタフェースのプロパティを読み取り専用にする (readonly) インタフェースのプロパティの前に、 readonly キーワードを付けると、そのプロパティは読み取り専用になり、オブジェクト生成時に格納した値を変更できなくなります。 次の Book インタフェースは 3 つのプロパティを持ちますが、そのうち id プロパティだけがリードオンリーとして定義されています。 interface Book { readonly id: string; // id プロパティはリードオンリー title: string; price: number; } 次の例では Book オブジェクトを作成した後で各プロパティの値を変更しようとしていますが、id プロパティを変更しようとしている部分でトランスパイルエラーになります。 const book: Book = { id: \u0026#39;001\u0026#39;, title: \u0026#39;TypeScript is Awesome\u0026#39;, price: 2300 }; book.id = \u0026#39;002\u0026#39;; // Error: リードオンリープロパティ book.title = \u0026#39;TypeScript is Horrible\u0026#39;; book.price = 800;"
},
{
url: "/p/b4i46ah/",
title: "TypeScriptの型: インタフェースを結合する (交差型: Intersection types)",
date: "2020-02-04T00:00:00Z",
body: "TypeScriptの型: インタフェースを結合する (交差型: Intersection types) 2 つのインタフェースを \u0026amp; で結ぶと、両方のインタフェースを備えていることを示す新しい型 (交差型: Intersection type) を定義することができます。 interface Foo { foo(): void; } interface Bar { bar(): void; } // インタフェースの結合 type FooAndBar = Foo \u0026amp; Bar; 上記のように定義された FooAndBar インタフェースを実装するクラスは、Foo インタフェースと Bar インタフェースの両方を実装しなければいけません。 class Hoge implements FooAndBar { foo(): void { console.log(\u0026#39;foo!!\u0026#39;); } bar(): void { console.log(\u0026#39;bar!!\u0026#39;); } } const h = new Hoge(); h.foo(); h.bar(); ☝️ 共用体は OR、交差型は AND どちらかの型になることができること示す共用体 (union) が | （OR記号）で定義されるのに対し、両方の性質を持つ交差型 (intersection type) は \u0026amp;（AND記号）を使って定義されます。 意味が直感的に分かりやすいですね。"
},
{
url: "/p/yzjj4c7/",
title: "Amazon Cognito をコマンドライン (CLI) から操作する",
date: "2022-04-06T00:00:00Z",
body: "Amazon Cognito をコマンドライン (CLI) から操作する AWS CLI による Cognito 操作用のコマンドには、cognito-idp と cognito-identity があります。 aws cognito-idp \u0026hellip; Cognito User Pools の操作（ユーザープール／ID プロバイダー） ユーザープール自体の作成や、ユーザーの追加・削除などを行えます。ユーザープールでの認証に成功すると、ユーザー情報を参照するためのトークンが発行されます。一般的にいうところの ID プロバイダー (IdP) です。 aws cognito-identity \u0026hellip; Cognito Federated Identities の操作（フェデレーテッドアイデンティティー／ID プール） 何らかの ID プロバイダー (IdP) で認証されたユーザーに対して、AWS サービスにアクセスするための一時的なアクセストークンを発行します。ID プロバイダーは上記の Cognito ユーザープールでもよいし、Google や Facebook などのサードパーティ ID プロバイダーでもかまいません。 ユーザープールの操作 (cognito-idp) aws cognito-idp のサブコマンドには、admin- プレフィックスが付くものと付かないバージョンがあったりしますが、プレフィックスがない方は、ユーザー認証後に取得できるトークンの指定 (--access-token) が必要です。 ユーザープールを作成する (cognito-idp create-user-pool) $ aws cognito-idp create-user-pool --pool-name \u0026#34;Test user pool\u0026#34; ユーザープールの作成に成功すると、初期設定の内容（パスワードのルールなど）が出力されます。 ユーザープールを削除する (cognito-idp delete-user-pool) $ aws cognito-idp delete-user-pool --user-pool-id ap-northeast-1_5O6lfqrqN --user-pool-id オプションには、ユーザープール名ではなく、ユーザープール ID を指定することに注意してください。 ユーザープール ID は、cognito-idp list-user-pools コマンドで確認できます。 ユーザープールの一覧を取得する (cognito-idp list-user-pools) $ aws cognito-idp list-user-pools --max-results 10 実行例 UserPools:- CreationDate:\u0026#39;2020-10-20T16:56:45.201000+09:00\u0026#39;Id:ap-northeast-1_vi4PeCz78LambdaConfig:{}LastModifiedDate:\u0026#39;2022-03-18T13:37:64.768000+09:00\u0026#39;Name:Test users 1- CreationDate:\u0026#39;2021-05-17T19:41:04.870000+09:00\u0026#39;Id:ap-northeast-1_nFafZcqMhLambdaConfig:{}LastModifiedDate:\u0026#39;2021-10-27T18:31:07.327000+09:00\u0026#39;Name:Test users 2 ユーザープールの情報を取得する (cognito-idp describe-user-pool) $ aws cognito-idp describe-user-pool --user-pool-id ap-northeast-1_5O6lfqrqN 実行例 UserPool:AdminCreateUserConfig:AllowAdminCreateUserOnly:falseUnusedAccountValidityDays:7Arn:arn:aws:cognito-idp:ap-northeast-1:123456789012:userpool/ap-northeast-1_5O6lfqrqNCreationDate:\u0026#39;2022-04-07T01:56:38.960000+09:00\u0026#39;EmailConfiguration:EmailSendingAccount:COGNITO_DEFAULTEstimatedNumberOfUsers:0Id:ap-northeast-1_5O6lfqrqNLambdaConfig:{}LastModifiedDate:\u0026#39;2022-04-07T01:56:38.960000+09:00\u0026#39;MfaConfiguration:OFFName:Test user poolPolicies:PasswordPolicy:MinimumLength:8RequireLowercase:trueRequireNumbers:trueRequireSymbols:trueRequireUppercase:trueTemporaryPasswordValidityDays:7SchemaAttributes:- AttributeDataType:StringDeveloperOnlyAttribute:falseMutable:falseName:subRequired:trueStringAttributeConstraints:MaxLength:\u0026#39;2048\u0026#39;MinLength:\u0026#39;1\u0026#39;- AttributeDataType:StringDeveloperOnlyAttribute:falseMutable:trueName:nameRequired:falseStringAttributeConstraints:MaxLength:\u0026#39;2048\u0026#39;MinLength:\u0026#39;0\u0026#39;- AttributeDataType:StringDeveloperOnlyAttribute:falseMutable:trueName:given_nameRequired:falseStringAttributeConstraints:MaxLength:\u0026#39;2048\u0026#39;MinLength:\u0026#39;0\u0026#39;- AttributeDataType:StringDeveloperOnlyAttribute:falseMutable:trueName:family_nameRequired:falseStringAttributeConstraints:MaxLength:\u0026#39;2048\u0026#39;MinLength:\u0026#39;0\u0026#39;- AttributeDataType:StringDeveloperOnlyAttribute:falseMutable:trueName:middle_nameRequired:falseStringAttributeConstraints:MaxLength:\u0026#39;2048\u0026#39;MinLength:\u0026#39;0\u0026#39;- AttributeDataType:StringDeveloperOnlyAttribute:falseMutable:trueName:nicknameRequired:falseStringAttributeConstraints:MaxLength:\u0026#39;2048\u0026#39;MinLength:\u0026#39;0\u0026#39;- AttributeDataType:StringDeveloperOnlyAttribute:falseMutable:trueName:preferred_usernameRequired:falseStringAttributeConstraints:MaxLength:\u0026#39;2048\u0026#39;MinLength:\u0026#39;0\u0026#39;- AttributeDataType:StringDeveloperOnlyAttribute:falseMutable:trueName:profileRequired:falseStringAttributeConstraints:MaxLength:\u0026#39;2048\u0026#39;MinLength:\u0026#39;0\u0026#39;- AttributeDataType:StringDeveloperOnlyAttribute:falseMutable:trueName:pictureRequired:falseStringAttributeConstraints:MaxLength:\u0026#39;2048\u0026#39;MinLength:\u0026#39;0\u0026#39;- AttributeDataType:StringDeveloperOnlyAttribute:falseMutable:trueName:websiteRequired:falseStringAttributeConstraints:MaxLength:\u0026#39;2048\u0026#39;MinLength:\u0026#39;0\u0026#39;- AttributeDataType:StringDeveloperOnlyAttribute:falseMutable:trueName:emailRequired:falseStringAttributeConstraints:MaxLength:\u0026#39;2048\u0026#39;MinLength:\u0026#39;0\u0026#39;- AttributeDataType:BooleanDeveloperOnlyAttribute:falseMutable:trueName:email_verifiedRequired:false- AttributeDataType:StringDeveloperOnlyAttribute:falseMutable:trueName:genderRequired:falseStringAttributeConstraints:MaxLength:\u0026#39;2048\u0026#39;MinLength:\u0026#39;0\u0026#39;- AttributeDataType:StringDeveloperOnlyAttribute:falseMutable:trueName:birthdateRequired:falseStringAttributeConstraints:MaxLength:\u0026#39;10\u0026#39;MinLength:\u0026#39;10\u0026#39;- AttributeDataType:StringDeveloperOnlyAttribute:falseMutable:trueName:zoneinfoRequired:falseStringAttributeConstraints:MaxLength:\u0026#39;2048\u0026#39;MinLength:\u0026#39;0\u0026#39;- AttributeDataType:StringDeveloperOnlyAttribute:falseMutable:trueName:localeRequired:falseStringAttributeConstraints:MaxLength:\u0026#39;2048\u0026#39;MinLength:\u0026#39;0\u0026#39;- AttributeDataType:StringDeveloperOnlyAttribute:falseMutable:trueName:phone_numberRequired:falseStringAttributeConstraints:MaxLength:\u0026#39;2048\u0026#39;MinLength:\u0026#39;0\u0026#39;- AttributeDataType:BooleanDeveloperOnlyAttribute:falseMutable:trueName:phone_number_verifiedRequired:false- AttributeDataType:StringDeveloperOnlyAttribute:falseMutable:trueName:addressRequired:falseStringAttributeConstraints:MaxLength:\u0026#39;2048\u0026#39;MinLength:\u0026#39;0\u0026#39;- AttributeDataType:NumberDeveloperOnlyAttribute:falseMutable:trueName:updated_atNumberAttributeConstraints:MinValue:\u0026#39;0\u0026#39;Required:falseUserPoolTags:{}VerificationMessageTemplate:DefaultEmailOption:CONFIRM_WITH_CODE ユーザーを作成する (cognito-idp admin-create-user) $ aws cognito-idp admin-create-user \\ --user-pool-id ユーザープールID \\ --username ユーザー名 \\ --temporary-password 初期パスワード（省略可） \\ --message-action SUPPRESS（確認メールを送信しない場合） 実行例 $ aws cognito-idp admin-create-user --user-pool-id ap-northeast-1_sf1nSZ2Oj --username user1 User: Attributes: - Name: sub Value: c5d45c78-74d0-4c14-b089-3c01cfa2cea9 Enabled: true UserCreateDate: \u0026#39;2022-04-06T16:04:22.543000+09:00\u0026#39; UserLastModifiedDate: \u0026#39;2022-04-06T16:04:22.543000+09:00\u0026#39; UserStatus: FORCE_CHANGE_PASSWORD Username: user1 ユーザーを削除する (cognito-idp admin-delete-user) $ aws cognito-idp admin-delete-user \\ --user-pool-id ユーザープールID \\ --username ユーザー名 ユーザーの一覧を取得する (cognito-idp list-users) $ aws cognito-idp list-users --user-pool-id ユーザープールID 実行例 $ aws cognito-idp list-users --user-pool-id ap-northeast-1_sf1nSZ2Oj Users: - Attributes: - Name: sub Value: 11f2d50e-5138-4aa8-967e-d0cc1267dc63 Enabled: true UserCreateDate: \u0026#39;2022-04-06T16:09:19.621000+09:00\u0026#39; UserLastModifiedDate: \u0026#39;2022-04-06T16:09:19.621000+09:00\u0026#39; UserStatus: FORCE_CHANGE_PASSWORD Username: user1 指定したユーザーの情報を取得する (cognito-idp admin-get-user) $ aws cognito-idp admin-get-user \\ --user-pool-id ユーザープールID \\ --username ユーザー名 実行例 $ aws cognito-idp admin-get-user --user-pool-id ap-northeast-1_sf1nSZ2Oj --username user1 Enabled: true UserAttributes: - Name: sub Value: 11f2d50e-5138-4aa8-967e-d0cc1267dc63 UserCreateDate: \u0026#39;2022-04-06T16:09:19.621000+09:00\u0026#39; UserLastModifiedDate: \u0026#39;2022-04-06T16:09:19.621000+09:00\u0026#39; UserStatus: FORCE_CHANGE_PASSWORD Username: user1 ユーザープールにクライアントを追加する (create-user-pool-client) $ aws cognito-idp create-user-pool-client \\ --user-pool-id ユーザープールID --client-name クライアント名 クライアントアプリや AWS CLI で認証を行うには、ユーザープールに「クライアント」を追加しておく必要があります。 実行例 $ aws cognito-idp create-user-pool-client \\ --user-pool-id ap-northeast-1_sf1nSZ2Oj \\ --client-name client1 UserPoolClient: AllowedOAuthFlowsUserPoolClient: false ClientId: 5sf3ad654tid5qt4r1768stto ClientName: client1 CreationDate: \u0026#39;2022-04-06T16:34:56.112000+09:00\u0026#39; EnableTokenRevocation: true LastModifiedDate: \u0026#39;2022-04-06T16:34:56.112000+09:00\u0026#39; RefreshTokenValidity: 30 TokenValidityUnits: {} UserPoolId: ap-northeast-1_sf1nSZ2Oj ユーザープールのクライアントの一覧を取得する (list-user-pool-clients) $ aws cognito-idp list-user-pool-clients --user-pool-id ユーザープールID 実行例 $ aws cognito-idp list-user-pool-clients --user-pool-id ap-northeast-1_sf1nSZ2Oj UserPoolClients: - ClientId: 1me8va44u5ec9ttirfmo8abro1 ClientName: myapp-browser UserPoolId: ap-northeast-1_sf1nSZ2Oj - ClientId: 5sf3ad654tid5qt4r1768stto ClientName: client1 UserPoolId: ap-northeast-1_sf1nSZ2Oj ユーザープールのクライアントの情報を取得する (describe-user-pool-client) $ aws cognito-idp describe-user-pool-client \\ --user-pool-id ユーザープールID \\ --client-id クライアントID クライアント名ではなく、クライアント ID を指定する必要があることに注意してください。 クライアント ID は、list-user-pool-clients コマンドで確認できます。 実行例 $ aws cognito-idp describe-user-pool-client --user-pool-id ap-northeast-1_sf1nSZ2Oj --client-id 5sf3ad654tid5qt4r1768stto UserPoolClient: AllowedOAuthFlowsUserPoolClient: false ClientId: 5sf3ad654tid5qt4r1768stto ClientName: client1 CreationDate: \u0026#39;2022-04-06T16:34:56.112000+09:00\u0026#39; EnableTokenRevocation: true LastModifiedDate: \u0026#39;2022-04-06T16:34:56.112000+09:00\u0026#39; RefreshTokenValidity: 30 TokenValidityUnits: {} UserPoolId: ap-northeast-1_sf1nSZ2Oj ユーザープールのクライアントの設定を変更する (update-user-pool-client) $ aws cognito-idp update-user-pool-client \\ --user-pool-id ユーザープールID \\ --client-id クライアントID \\ ...(設定変更のオプション)... 実行例（Auth flow の設定） $ aws cognito-idp update-user-pool-client \\ --user-pool-id ap-northeast-1_m43jEsA8r \\ --client-id 2dkct9bm65e9oj3q3bsg40u5g5 \\ --explicit-auth-flows ALLOW_REFRESH_TOKEN_AUTH \\ ALLOW_ADMIN_USER_PASSWORD_AUTH UserPoolClient: AllowedOAuthFlowsUserPoolClient: false ClientId: 2dkct9bm65e9oj3q3bsg40u5g5 ClientName: client1 CreationDate: \u0026#39;2022-04-07T02:29:09.818000+09:00\u0026#39; EnableTokenRevocation: true ExplicitAuthFlows: - ALLOW_ADMIN_USER_PASSWORD_AUTH - ALLOW_REFRESH_TOKEN_AUTH LastModifiedDate: \u0026#39;2022-04-07T03:21:50.683000+09:00\u0026#39; RefreshTokenValidity: 30 TokenValidityUnits: {} UserPoolId: ap-northeast-1_m43jEsA8r ユーザーのパスワードを設定する (admin-set-user-password) $ aws cognito-idp admin-set-user-password \\ --user-pool-id ユーザープールID \\ --username 既存のユーザー名 \\ --password 新しいパスワード 実行例 $ aws cognito-idp admin-set-user-password \\ --user-pool-id ap-northeast-1_sf1nSZ2Oj \\ --username user1 --password Password!123 ユーザー認証する (admin-initiate-auth) $ aws cognito-idp admin-initiate-auth \\ --user-pool-id ユーザープールID \\ --client-id クライアントID \\ --auth-flow ADMIN_USER_PASSWORD_AUTH --auth-parameters USERNAME=ユーザー名,PASSWORD=パスワード ユーザープールに登録されたユーザーの名前とパスワードで認証し、トークンを取得します。 この管理 API でユーザー認証を行うには、Cognito ユーザープールの設定で対象のクライアントを選択し、ALLOW_ADMIN_USER_PASSWORD_AUTH にチェックを入れておく必要があります。 これを有効にしておかないと、管理者用の Cognito API（admin-initiate-auth コマンドなど）で認証できません。 実行例（パスワード変更が必要な場合） $ aws cognito-idp admin-initiate-auth --user-pool-id ap-northeast-1_sf1nSZ2Oj --client-id 5sf3ad654tid5qt4r1768stto --auth-flow ADMIN_USER_PASSWORD_AUTH --auth-parameters USERNAME=user1,PASSWORD=Password!123 ChallengeName: NEW_PASSWORD_REQUIRED ChallengeParameters: USER_ID_FOR_SRP: user1 requiredAttributes: \u0026#39;[\u0026#34;userAttributes.email\u0026#34;]\u0026#39; userAttributes: \u0026#39;{\u0026#34;email\u0026#34;:\u0026#34;\u0026#34;}\u0026#39; Session: AYABeBBlOn...（長いので省略）...Q_FXfCoWCsI-w レスポンスとして、ChallengeName: NEW_PASSWORD_REQUIRED が返ってきた場合は、新しいパスワード設定する必要があります。 新しいパスワードの設定も CLI から行えます（admin-initiate-auth のレスポンスに含まれているセッショントークン Session の値が必要です）。 $ aws cognito-idp admin-respond-to-auth-challenge \\ --user-pool-id ap-northeast-1_sf1nSZ2Oj \\ --client-id 5sf3ad654tid5qt4r1768stto \\ --challenge-name NEW_PASSWORD_REQUIRED \\ --challenge-responses USERNAME=user1,NEW_PASSWORD=\u0026#34;passWORD#123\u0026#34;,userAttributes.email=\u0026#34;user1@example.com\u0026#34; \\ --session \u0026#34;AYABeBBlOnhrpnx82...（省略）...L7uMc6Q_FXfCoWCsI-w\u0026#34;"
},
{
url: "/p/ofuan2e/",
title: "React の基本と環境構築",
date: "2021-07-18T00:00:00Z",
body: "React の基本と環境構築"
},
{
url: "/p/tfq2cnw/",
title: "VS Code の設定ファイルの場所 (settings.json)",
date: "2021-07-11T00:00:00Z",
body: "VS Code の設定ファイルの場所 (settings.json) ユーザー設定とワークスペース設定 VS Code の設定画面は Ctrl(Cmd) + , で起動できますが、ここで行った設定は、settings.json というユーザー設定ファイル（あるいはワークスペース設定ファイル）に保存されます。 このファイルの内容と設定画面の内容は連動しているので、設定はどちらで行ってもいいのですが、慣れてくると setttings.json を直接編集した方がすばやく設定を行えます。 ユーザー設定ファイル VS Code のユーザー設定ファイル (settings.json) は、OS ごとに下記のディレクトリに保存され、全ての VS Code インスタンス（ワークスペース）に共通の設定として使用されます。 OS ユーザー設定ファイルのパス Windows %APPDATA%\\Code\\User\\settings.json macOS $HOME/Library/Application Support/Code/User/settings.json Linux $HOME/.config/Code/User/settings.json ワークスペース設定ファイル ワークスペースごとの設定は、プロジェクトのルートディレクトリの .vscode ディレクトリに保存されます。 \u0026lt;プロジェクトルート\u0026gt;/.vscode/settings.json ワークスペース設定は、前述のユーザー設定よりも優先されます（同じ設定項目の値が上書きされます）。 .vscode ディレクトリを Git にコミットしておけば、チーム内で VS Code の設定を共有できます。 .vscode ディレクトリには、プロジェクトのタスク設定ファイル (tasks.json) なども格納されます。 設定ファイルのサンプル settings.json ファイルの拡張子は .json ですが、JavaScript 形式のコメントを記述できるようになっています (JSON with Comments)。 settings.json の例 // Place your settings in this file to overwrite the default settings { \u0026#34;breadcrumbs.enabled\u0026#34;: false, \u0026#34;editor.fontSize\u0026#34;: 14, \u0026#34;editor.minimap.enabled\u0026#34;: false, \u0026#34;editor.renderControlCharacters\u0026#34;: true, \u0026#34;editor.tabSize\u0026#34;: 2, \u0026#34;files.trimTrailingWhitespace\u0026#34;: true, \u0026#34;terminal.integrated.tabs.enabled\u0026#34;: true, \u0026#34;typescript.updateImportsOnFileMove.enabled\u0026#34;: \u0026#34;always\u0026#34;, \u0026#34;vim.useSystemClipboard\u0026#34;: true, \u0026#34;workbench.startupEditor\u0026#34;: \u0026#34;newUntitledFile\u0026#34; } settings.json を素早く開く コマンドパレットから開く コマンドパレット (Ctrl/Cmd + Shift + P) から、Open Settings (JSON) という項目を選択することで、settings.json ファイルを直接開くことができます。 コマンドパレットに settings json と入力すると、この項目を素早く見つけられます。 Open Settings (JSON) が「ユーザー設定ファイル」で、Open Workspace Settings (JSON) が「ワークスペース設定ファイル」です。 もう一つの、Open Default Settings (JSON) はデフォルトの設定値一覧が記述されたファイルであり、ユーザーが変更するものではありません（後述）。 GUI の設定画面から開く VS Code の GUI 版の設定画面 (Ctrl/Cmd + ,) の右上の アイコンをクリックすることでも、settings.json ファイルを開くことができます。 設定画面のタブで「ユーザー設定」と「ワークスペース設定」を切り替えられるようになっているので、開きたい設定のタブを選択してからアイコンをクリックしてください。 デフォルトの設定 (defaultSettings.json) settings.json でユーザー設定（or ワークスペース設定）を行わない場合は、VS Code はデフォルトの設定を使用します。 デフォルトの設定は、defaultSettings.json に記述されており、次のようにして開いて確認することができます。 コマンドパレット (Ctrl/Cmd + Shift + P) → Preferences: Open Default Settings (JSON) このファイルは 5000 行近くありますが、次のようにコメント付きで表示されるので、ざっと眺めてみると何か発見があるかもしれません。 defaultSettings.json（抜粋） { // Controls whether the editor shows CodeLens. \u0026#34;diffEditor.codeLens\u0026#34;: false, // When enabled, the diff editor ignores changes in leading or trailing whitespace. \u0026#34;diffEditor.ignoreTrimWhitespace\u0026#34;: true, // ... } このデフォルト設定値は、下記の公式ドキュメントでも参照できます。 Visual Studio Code - Default settings プログラミング言語別の設定 (per-language configuration) ある言語タイプのファイルを開いているときのみ有効にしたい設定は、setting.json の中で、[ファイルタイプ] というプロパティに設定を記述します。 下記の例では、TypeScript ファイル (.ts) と Markdown ファイル (.md) に対する設定を行っています。 settings.json { // ... \u0026#34;[typescript]\u0026#34;: { \u0026#34;editor.formatOnSave\u0026#34;: true, \u0026#34;editor.formatOnPaste\u0026#34;: true }, \u0026#34;[markdown]\u0026#34;: { \u0026#34;editor.formatOnSave\u0026#34;: true, \u0026#34;editor.wordWrap\u0026#34;: \u0026#34;on\u0026#34;, \u0026#34;editor.renderWhitespace\u0026#34;: \u0026#34;all\u0026#34;, \u0026#34;editor.acceptSuggestionOnEnter\u0026#34;: \u0026#34;off\u0026#34; } } 言語別の設定は、指定できるプロパティが限られていますが、IntelliSense による入力補完機能 (Ctrl + Space) を使うと、どのようなプロパティを指定できるかがすぐにわかります。 複数の言語タイプをまとめて指定したいときは、プロパティ名の部分で \u0026quot;[typescript][typescriptreact]\u0026quot; のように記述します。 複数の言語タイプをまとめて [typescript, typescriptreact] のように指定することは まだできない ようです（2021年7月時点）。 → （2022年1月）できるようになってました！今井さん情報提供ありがとうございます。 マニュアル追加する項目は settings.json の上の方に書く settings.json の書き方のちょっとしたコツですが、直接このファイルに設定項目やコメントを記述する場合は、末尾よりは先頭あたりに追記していくのがよいです。 VS Code の設定 UI で新しく設定した項目（デフォルト設定じゃなくなった項目）は、settings.json の末尾に自動追加されていくので、これと混ざらないようにするためです。 例えば、次のようにカテゴライズしておくと、設定 UI で変更した内容は、末尾の「その他の設定」のところに追加されていくので管理しやすくなります。 settings.json { // エクスプローラーに表示しないディレクトリ \u0026#34;files.exclude\u0026#34;: { \u0026#34;**/.next\u0026#34;: true, \u0026#34;**/node_modules\u0026#34;: true }, // 自動フォーマット（Prettier関連）設定 \u0026#34;typescript.format.enable\u0026#34;: false, \u0026#34;editor.defaultFormatter\u0026#34;: \u0026#34;esbenp.prettier-vscode\u0026#34;, \u0026#34;editor.formatOnSave\u0026#34;: true, \u0026#34;editor.formatOnType\u0026#34;: true, \u0026#34;editor.formatOnPaste\u0026#34;: true, // その他の設定 // ... } （おまけ）プラグイン (extensions) が保存されている場所 ちなみに、VS Code の拡張 (extensions) は、ホームディレクトリの .vscode ディレクトリ以下に保存されています。 OS 拡張関連のファイルが格納されているディレクトリ Windows %USERPROFILE%\\.vscode\\extensions macOS ~/.vscode/extensions Linux ~/.vscode/extensions"
},
{
url: "/p/3o2ep2c/",
title: "Next.js アプリの環境構築",
date: "2021-05-04T00:00:00Z",
body: "Next.js アプリの環境構築"
},
{
url: "/p/vigdnzf/",
title: "AWS CLI 関連記事",
date: "2021-03-29T00:00:00Z",
body: "AWS CLI 関連記事"
},
{
url: "/p/vgt5g7f/",
title: "Azure Functions で簡単な関数を作ってみる",
date: "2020-08-16T00:00:00Z",
body: "Azure Functions で簡単な関数を作ってみる Azure Functions を使うと、Web API 的なものを、サーバーの存在を意識せずに作成することができます。 ここでは、最初のステップとして、HTTP リクエストで送ったメッセージをオウム返しするだけの簡単な関数を作ってみます。 Functions アプリを新規作成する 新しい Functions アプリを作成するには、Azure ポータルのリソースの作成画面 から、Functions App（関数アプリ） を選択します。 Azure のアカウントがない場合は先に作成する必要があります。 画面に従って入力していけば作成できますが、いくつかポイントがあるので説明しておきます。 基本タブ 関数アプリ名 \u0026hellip; 任意のアプリ名を付けることができますが、\u0026lt;アプリ名\u0026gt;.azurewebsites.net というアドレスが割り当てられるので、世界で一意な名前を指定する必要があります。 ランタイムスタック \u0026hellip; 関数の実装に使用する言語を選択します。JavaScript で記述するなら Node.js、C# で実装するなら .NET Core を選択しておきます。 ホスティングタブ プランの種類 \u0026hellip; 今回のテストのように、ときどき実行するだけなら 消費量（サーバーレス） を選択しておきます。App Service プラン は常時起動型の VM でホスティングするもので、ほとんど関数呼び出ししなくても月額数千円はかかってしまうので、最初は避けておくのが無難です。ただし、すでに他の Web サーバに App Service リソースを使用しているのであれば、そちらに相乗りしてホスティングすることが可能です。 最後に 作成 ボタンを押せば、数分で Functions のリソース作成が完了します。 Functions アプリに関数を追加する Functions リソースに新しい関数を追加するには、関数 → 追加 と選択します。 ここでは HTTP リクエストにより関数を実行するので、HTTP trigger を選択します。 関数名はデフォルトのままで HttpTrigger1、Authorization level はキーなしでリクエストできるように Anonymous を選択しておきます。 最後に 作成 ボタンを押すと、数秒で新しい関数が登録されます。 関数の実装を確認する 作成された関数を選択すると、次のようにデフォルトの実装を確認することができます。 実は、最初からオウム返しする Hello World 実装が入っているので、今回はこれをそのまま使うことにします。 関数の振る舞いを変更したければ、ここで直接コードを変更して 保存 ボタンを押すだけで一瞬で反映されます。 右上の 関数の URL の取得 というボタンを押して、関数を呼び出すための URL を取得してください。 関数を呼び出す Web ブラウザから URL を開いて実行する HTTP trigger タイプの関数は HTTP の GET リクエストで呼び出せるので、Web ブラウザのアドレスバーに次のようなアドレスを入力するだけでレスポンスを確認できます。 https://\u0026lt;アプリ名\u0026gt;.azurewebsites.net/api/HttpTrigger1?name=Maku ブラウザに次のようなメッセージが表示されれば成功です！ Hello, Maku. This HTTP triggered function executed successfully. curl コマンドで実行する コマンドラインからサクッと動作確認したいときは、curl コマンドを使うと便利です。 $ curl https://\u0026lt;アプリ名\u0026gt;.azurewebsites.net/api/HttpTrigger1?name=Maku Hello, Maku. This HTTP triggered function executed successfully. ヘッダ情報などの詳細を確認したいときは、-v オプションを付けます。 Web ブラウザの JavaScript から実行する Web ブラウザ上で実行する JavaScript から Azure Functions を呼び出す場合は、クロスオリジン通信になるので、そのままだと以下のような CORS ポリシーエラーが発生してうまくいきません。 Access to fetch at \u0026lsquo;https://XXX.azurewebsites.net/api/HttpTrigger1?name=Maku' from origin \u0026lsquo;http://localhost:1234\u0026rsquo; has been blocked by CORS policy: No \u0026lsquo;Access-Control-Allow-Origin\u0026rsquo; header is present on the requested resource. If an opaque response serves your needs, set the request\u0026rsquo;s mode to \u0026lsquo;no-cors\u0026rsquo; to fetch the resource with CORS disabled. クロスオリジン通信を許可するには、Azure Functions の CORS の項目から次のように設定します。 アクセスを許可するドメインの指定部分には、http://localhost:1234 のようにひとつずつドメインを指定することもできますが、今回はワイルドカード * ですべてのドメインからのアクセスを許可しています。 ワイルドカードを使用する場合は、他のエントリはすべて削除しないとうまく動作しないので注意してください（このあたり何も警告が出ないのは意地悪ですね\u0026hellip;）。 最後に忘れずに 保存 ボタンを押せば設定が反映されます。 JavaScript からは、次のように fetch 関数を使って HTTP リクエストを発行できます。 const API = \u0026#39;https://\u0026lt;アプリ名\u0026gt;.azurewebsites.net/api/HttpTrigger1\u0026#39;; const url = API + \u0026#39;?name=\u0026#39; + encodeURIComponent(\u0026#39;まく\u0026#39;); fetch(url) .then(res =\u0026gt; { if (!res.ok) { throw new Error(`${res.status}${res.statusText}`); } return res.text(); }) .then(text =\u0026gt; { // これがレスポンス本文のテキスト alert(text); }) .catch(error =\u0026gt; { throw new Error(JSON.stringify(error)) });"
},
{
url: "/p/m4dmt3a/",
title: "React + TypeScript の環境を整える (1) 自力で webpack 設定する方法",
date: "2020-07-02T00:00:00Z",
body: "React + TypeScript の環境を整える (1) 自力で webpack 設定する方法 React とは Web サイトを作成するときに React を採用すると、HTML をフラットな形でゴリゴリ記述していくのではなく、独自コンポーネント（例: \u0026lt;MyButton\u0026gt; コンポーネント）を定義してまとまりのある単位でサイトを構築していくことができます。 Web Components という同様な技術の標準化が進んでいますが、しばらくは React のようなコンポーネントライブラリが使われるでしょう。 React – ユーザインターフェース構築のための JavaScript ライブラリ ここでは React を使った Web サイト開発用に、下記のようなツールを組み合わた環境を構築します。 React \u0026hellip; コンポーネントベースで Web サイト構築するためのライブラリ TypeScript \u0026hellip; JavaScript を型付けできるようにした言語 webpack \u0026hellip; Web サイトのリソースをバンドルするためのツール この環境構築方法を理解すれば、React を利用した Web サイトをどんどん作ることができます。 ちなみに、上記のすべてのツールは Node.js 上で動作するため、Node.js がインストールされていない場合は先にインストールしてください。 TypeScript、React、webpack のインストール チュートリアルなどでは、create-react-app を使って React アプリの雛形を生成する方法がよく載っていますが、よくわからないモジュールが勝手にインストールされるのは気持ち悪いので、ここでは自力で各モジュールをインストールしてきます。 ☝️ create-react-app は使わない方がいい TypeScript ベースの React アプリの雛形を生成するには、create-react-app myapp --template typescript のように実行します。 このコマンドによって作成された雛形をリファレンスにするのがよいかなと思ったのですが、少なくともバージョン 3.4.1 時点で生成される雛形はかなり怪しいです。 例えば、TypeScript の処理系や型定義ファイルが devDependencies ではなく、dependencies でインストールされるようになっていたりします。 最終的に Web サーバーにデプロイするファイル群は webpack で生成（バンドル）することを想定しているので、npm (or yarn) でインストールするモジュールは、 すべて devDependencies（開発用モジュール）としてインストール していきます（Web サーバー側で npm install を実行することはないということです）。 プロジェクトの作成 プロジェクト用のディレクトリがなければ作成し、package.json ファイルを作成しておきます。 $ mkdir myapp \u0026amp;\u0026amp; cd myapp $ npm init -y 各モジュールのインストール TypeScript をインストールします。 $ npm install --save-dev typescript React 関連のモジュール（react、react-dom）と、その型定義をインストールします。 本体の方は実行時にも使用するので、--save オプションでインストールする必要があります。 $ npm install --save react react-dom $ npm install --save-dev @types/react @types/react-dom webpack 関連のモジュールをインストールします。 コマンドラインツールの webpack-cli、TypeScript コードを認識させるための ts-loader、HTML ファイルを生成するための html-webpack-plugin も一緒にインストールします。 $ npm install --save-dev webpack webpack-cli ts-loader html-webpack-plugin 確認 ここまでで、package.json 内の依存定義 (devDependencies) は次のようになっています。 package.json { // ... \u0026#34;dependencies\u0026#34;: { \u0026#34;react\u0026#34;: \u0026#34;^16.13.1\u0026#34;, \u0026#34;react-dom\u0026#34;: \u0026#34;^16.13.1\u0026#34; }, \u0026#34;devDependencies\u0026#34;: { \u0026#34;@types/react\u0026#34;: \u0026#34;^16.9.41\u0026#34;, \u0026#34;@types/react-dom\u0026#34;: \u0026#34;^16.9.8\u0026#34;, \u0026#34;html-webpack-plugin\u0026#34;: \u0026#34;^4.3.0\u0026#34;, \u0026#34;ts-loader\u0026#34;: \u0026#34;^7.0.5\u0026#34;, \u0026#34;typescript\u0026#34;: \u0026#34;^3.9.6\u0026#34;, \u0026#34;webpack\u0026#34;: \u0026#34;^4.43.0\u0026#34;, \u0026#34;webpack-cli\u0026#34;: \u0026#34;^3.3.12\u0026#34; } } 設定ファイル ディレクトリ構成 下記のようなディレクトリ構成を想定して、各種ツールの設定を行っていきます。 myapp/ +-- package.json # Node プロジェクトの設定 +-- tsconfig.json # TypeScript の設定 +-- webpack.config.js # webpack の設定 +-- dist/ # webpack の出力先 +-- src/ # ソースコード +-- index.html +-- index.tsx +-- ... ソースコードや各種リソースファイルは src ディレクトリ以下に作成し、webpack によるバンドル結果を dist ディレクトリに出力します。 最終的に dist ディレクトリの中身を Web サーバーにデプロイすることになります。 ルートディレクトリには、設定ファイル以外のファイルをなるべく置かないようにするとスッキリします。 webpack の設定 Web サイト用のコンテンツは webpack コマンドにより生成するため、webpack の設定は重要です。 webpack は、ここで指定されたエントリーポイント（.js あるいは .ts ファイル）を起点にファイルの依存関係を認識し、それらのファイルをバンドルします。 webpack.config.js const path = require(\u0026#39;path\u0026#39;); const HtmlWebpackPlugin = require(\u0026#39;html-webpack-plugin\u0026#39;); module.exports = { // 開発用の設定 mode: \u0026#39;development\u0026#39;, // エントリポイントとなるコード entry: \u0026#39;./src/index.tsx\u0026#39;, // バンドル後の js ファイルの出力先 output: { path: path.resolve(__dirname, \u0026#39;dist\u0026#39;), filename: \u0026#39;index.js\u0026#39; }, // import 時に読み込むファイルの拡張子 resolve: { extensions: [\u0026#39;.js\u0026#39;, \u0026#39;.json\u0026#39;, \u0026#39;.ts\u0026#39;, \u0026#39;.tsx\u0026#39;] }, // ソースマップファイルの出力設定 devtool: \u0026#39;source-map\u0026#39;, module: { rules: [ // TypeScript ファイル (.ts/.tsx) を変換できるようにする { test: /\\.tsx?$/, use: \u0026#34;ts-loader\u0026#34;, include: path.resolve(__dirname, \u0026#39;src\u0026#39;), exclude: /node_modules/ } ] }, plugins: [ // HTML ファイルの出力設定 new HtmlWebpackPlugin({ template: \u0026#39;./src/index.html\u0026#39; }) ] }; Web サイト用のクライアントスクリプトを TypeScript で作成する場合は、.ts ファイルおよび、.tsx ファイルを ts-loader で処理するように指定しておく必要があります。 webpack はあくまでバンドルツールなので、HTML ファイルの出力などはオプショナルな振る舞いになります。 上記の例では、html-webpack-plugin の機能を使って、src/index.html から dist/index.html を生成するように設定しています。 TypeScript の設定 webpack によりデプロイ用のファイル群を生成する場合、TypeScript のトランスパイルも webpack 経由で実行することになります（tsc コマンドは直接実行しない）。 TypeScript の設定ファイルでは、基本的な変換ルールだけ定義しておきます。 ほとんど空っぽでも動くはずですが、.tsx ファイル内の JSX コードを認識させるための設定は必須です。 tsconfig.json { \u0026#34;compilerOptions\u0026#34;: { \u0026#34;target\u0026#34;: \u0026#34;ES2015\u0026#34;, \u0026#34;module\u0026#34;: \u0026#34;commonjs\u0026#34;, \u0026#34;lib\u0026#34;: [\u0026#34;esnext\u0026#34;, \u0026#34;dom\u0026#34;], \u0026#34;jsx\u0026#34;: \u0026#34;react\u0026#34;, // .tsx ファイル内の JSX 記述を認識 \u0026#34;strict\u0026#34;: true, \u0026#34;esModuleInterop\u0026#34;: true, \u0026#34;skipLibCheck\u0026#34;: true, \u0026#34;forceConsistentCasingInFileNames\u0026#34;: true, // 出力先などは webpack 側で指定するので本質的には必要なし \u0026#34;sourceMap\u0026#34;: true, \u0026#34;outDir\u0026#34;: \u0026#34;./dist\u0026#34;, \u0026#34;sourceRoot\u0026#34;: \u0026#34;./src\u0026#34;, } } Hello World の実装 基本的な設定が終わったので、React を使って独自の \u0026lt;Hello\u0026gt; コンポーネントを作る実装を行います。 src/index.html トップページとなる index.html ファイルを作成します。 script 要素は webpack が勝手に挿入してくれるので、最小限の要素だけ記述しておけば OK です。 src/index.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;MyApp\u0026lt;/title\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1\u0026#34;\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div id=\u0026#34;root\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; src/index.tsx Web アプリのエントリポイントとして設定したスクリプトを作成します。 ここでは、React コンポーネントとして Hello コンポーネントを作成し、HTML のルートに配置した div 要素の内容として表示します。 src/index.tsx import * as React from \u0026#39;react\u0026#39;; import * as ReactDom from \u0026#39;react-dom\u0026#39;; // Hello コンポーネントの属性（プロパティ）を定義 interface HelloProps { name?: string; // オプショナルな name 属性 } // Hello コンポーネントを定義 class Hello extends React.Component\u0026lt;HelloProps\u0026gt; { public render(): React.ReactNode { const name = this.props.name ?? \u0026#39;Unknown\u0026#39;; return ( \u0026lt;b\u0026gt;Hello, {name}!\u0026lt;/b\u0026gt; ); } } // Hello コンポーネントを \u0026lt;div id=\u0026#34;root\u0026#34;\u0026gt; に表示 ReactDom.render( \u0026lt;Hello name=\u0026#34;React\u0026#34; /\u0026gt;, document.getElementById(\u0026#39;root\u0026#39;) ); ビルド 次のように webpack コマンドを実行すると、dist ディレクトリ以下に Web サイト用コンテンツが出力されます。 $ npx webpack Web ブラウザで dist/index.html を開いて、Hello, React! と表示されれば成功です。 あとは必要に応じて、npm run build でビルドを実行できるようにスクリプトを定義しておきます。 package.json { \u0026#34;name\u0026#34;: \u0026#34;myapp\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;0.0.1\u0026#34;, \u0026#34;scripts\u0026#34;: { \u0026#34;build\u0026#34;: \u0026#34;webpack\u0026#34; }, \u0026#34;devDependencies\u0026#34;: { // ... } }"
},
{
url: "/p/k6hs3cm/",
title: "VS Code の操作方法メモ",
date: "2020-06-10T00:00:00Z",
body: "VS Code の操作方法メモ"
},
{
url: "/p/f5iv9kx/",
title: "VS Code を code コマンドで起動できるようにする",
date: "2020-06-10T00:00:00Z",
body: "VS Code を code コマンドで起動できるようにする Windows のコマンドプロンプトや、macOS のターミナルから Visual Studio Code を開くには、code コマンドを使用します。 $ code . # ディレクトリを開く（通常はこれを使う） $ code sample.txt # ファイルを開く code コマンドが見つからない (command not found) と言われる場合は、VS Code から次のように実行することで実行できるようになります。 Cmd + Shift + P (Ctrl + Shift + P) でコマンドパレットを開く shell と入力し、Shell Command: install 'code' command in PATH を選択する macOS の場合は、下記のコマンドへのシンボリックリンクとして、/usr/local/bin/code というファイルが作成されるようです。 /Applications/Visual Studio Code.app/Contents/Resources/app/bin/code"
},
{
url: "/p/qhxet9n/",
title: "TypeScriptの型: クラス定義の基本 (class)",
date: "2020-03-31T00:00:00Z",
body: "TypeScriptの型: クラス定義の基本 (class) TypeScript のクラスは、Java や Kotlin に似た文法で定義します。 インタフェースの定義に似ていますが、コンストラクタやメソッドを持つことができるという大きな違いがあります。 簡単なクラス 次の Greeter クラスは、1 つのプロパティ、1 つのコンストラクタ、1 つのメソッドを持っています。 class Greeter { // プロパティの定義（デフォルトで public） private name: string; // コンストラクタの定義 constructor(name: string) { this.name = name; } // メソッドの定義（デフォルトで public） greet() { console.log(`Hello, ${this.name}`); } } コンストラクタやメソッドの前に function というキーワードは必要ないことに注意してください。 プロパティやメソッドの可視性は デフォルトで public になるため、外部からアクセスできないようにするには、明示的に private と指定する必要があります。 クラスのインスタンスを生成するには、次のように new キーワードを使用します。 const greeter = new Greeter(\u0026#39;Maku\u0026#39;); greeter.greet(); //=\u0026gt; \u0026#39;Hello, Maku\u0026#39; プロパティ定義の省略 コンストラクタ (constructor()) のパラメータ名の前に、private や public といった可視性を指定すると、プロパティ定義とその値を設定するコードを省略することができます。 次のようなコードは、 class Book { private name: string; constructor(name: string) { this.name = name; } } 次のように省略して記述することができます。 class Book { constructor(private name: string) {} } public でリードオンリーなプロパティとして定義する場合は、こんな感じ。 class Book { constructor(public readonly name: string) {} } コンストラクタのデフォルト引数 関数のパラメータと同様に、コンストラクタのパラメータでもデフォルト引数の仕組みを使用できます。 class Indentor { constructor(private indentStr: string = \u0026#39; \u0026#39;) {} indent(level: number): string { return this.indentStr.repeat(level); } } // コンストラクタのパラメータは省略可能 const indentor = new Indentor(); console.log(indentor.indent(0) + \u0026#39;AAA\u0026#39;); //=\u0026gt; \u0026#39;AAA\u0026#39; console.log(indentor.indent(1) + \u0026#39;BBB\u0026#39;); //=\u0026gt; \u0026#39; BBB\u0026#39; console.log(indentor.indent(2) + \u0026#39;CCC\u0026#39;); //=\u0026gt; \u0026#39; CCC\u0026#39; プロパティの setter/getter を定義する メソッド名の前に set キーワード、 get キーワードを付けて定義することで、プロパティの setter/getter を定義することができます。 setter はプロパティへの代入時 (obj.prop = value) に呼び出され、getter はプロパティの参照時 (value = obj.prop) に呼び出されます。 setter/getter には可視性を指定することはできず、必ず public として扱われます。 次の例では、title という名前の setter/getter を定義しています。 実際の値は、_title というプライベートプロパティに保存しています。 class Book { private _title: string = \u0026#39;\u0026#39;; set title(value: string) { console.log(\u0026#39;setter が呼ばれたよ\u0026#39;); this._title = value; } get title(): string { console.log(\u0026#39;getter が呼ばれたよ\u0026#39;); return this._title; } } const b = new Book(); b.title = \u0026#39;タイトル\u0026#39;; // setter が呼ばれたよ console.log(b.title); // getter が呼ばれたよ → タイトル 次のように getter だけを定義しておけば、外からは値を変更できないリードオンリーなプロパティを定義することができます。 下記の Counter クラスの count プロパティは参照専用で、外から値を代入できないようになっています。 class Counter { constructor(private _count: number = 0) {} tick() { this._count += 1; } get count(): number { return this._count; } } const counter = new Counter(); counter.tick(); counter.tick(); counter.tick(); console.log(counter.count); //=\u0026gt; 3 上記のように getter のみを提供することは、プロパティ自体に readonly キーワードを付けるのとは異なることに注意してください。 プロパティに readonly を付けると、クラスの中からもその値を変更できなくなります。 次のようにクラス定数を定義するときに使えます。 class TaxCalculator { private static readonly RATE = 0.10; static calc(price: number) : number { return Math.floor(price * (1 + TaxCalculator.RATE)); } } console.log(TaxCalculator.calc(100)); //=\u0026gt; 110 （応用）プライベートコンストラクタ コンストラクタ (constructor) を private 定義することで、外部からの new 呼び出しを禁止することができます。 代わりに、static なファクトリメソッドを用意してインスタンス生成できるようにします。 export class MyData { static of(value: string): MyData { return new this(value) } // 外部からのコンストラクタ (new) の直接呼出しは禁止 private constructor(public readonly value: string) {} } static メソッドから、this() でコンストラクタを呼び出せるところがポイントです。"
},
{
url: "/p/dwsog4p/",
title: "逆引き Azure CLI: Azure CLI（az コマンド）をインストールする",
date: "2020-03-17T00:00:00Z",
body: "逆引き Azure CLI: Azure CLI（az コマンド）をインストールする Azure CLI をインストールすると、az コマンドを使用して、Azure の様々な機能を呼び出すことができるようになります。 Azure ポータル 上で実行できることは、ほとんど az コマンドでも実行できるようになっています。 Azure CLI は下記のサイトに従ってインストールします（インストーラを実行するだけです）。 Azure コマンドラインインターフェイス (CLI) 実際には、Azure ポータル上で実行してしまった方が手軽なことが多いのですが、スクリプトなどで処理を自動化したい場合は Azure CLI を使うことになります。"
},
{
url: "/p/ornz2yx/",
title: "VS Code で Markdown ファイルのプレビューを表示する",
date: "2020-03-16T00:00:00Z",
body: "VS Code で Markdown ファイルのプレビューを表示する 図: VSCode の Markdown プレビュー表示 Visual Studio Code で Markdown ファイルのプレビュー表示を行うには、F1 キー（あるいは Ctrl + Shift + P) でコマンドパレットを開き、Markdown メニューから Open Preview を選択します。 次のように、新しいタブで開くか、左右に分割して表示するかを選択できます。 プレビューを新しいタブで表示: Markdown: Open Preview プレビューを左右分割して表示: Markdown: Open Preview to the Side Markdown ファイルを編集中に右上に表示される「プレビューボタン」を押すことでも、プレビューを表示することができます（こっちのが早いかも）。 図: VSCode の分割プレビューボタン 1 文字入力するごとにリアルタイムにプレビュー更新してくれるので気持ちよく作業できます。 フロントマターを解析してプレビュー表示してくれないなどの欠点はありますが、きっと近いうちに拡張されて表示できるようになると思います。"
},
{
url: "/p/p4bipw4/",
title: "MongoDB の基礎知識",
date: "2019-05-20T00:00:00Z",
body: "MongoDB の基礎知識"
},
{
url: "/p/o2nq2qa/",
title: "よいチャットボットとは？ボットを作成するときのベストプラクティス",
date: "2019-02-08T00:00:00Z",
body: "よいチャットボットとは？ボットを作成するときのベストプラクティス とある事情によりチャットボットを作ろうという話になっています。 まずは、チャットボットってどんなことに気を付けて作ればよいかを調べたので、ポイントになりそうなことをまとめておきます。 下記の Microsoft が提供している Bot Framework のドキュメントがとても参考になりました。 参考: Principles of bot design - Bot Service | Microsoft Docs チャットボットの知識は、今流行りのスマートスピーカー（Amazon Alexa や Google Home）などのスキルを作成する際にも応用がききそうです。 音声入力による会話は、チャットの特殊形態（キーボードやモニタがないときの手段）と考えることができるので、チャットボットの基本原則を押さえておくことはきっと参考になります。 チャットボットが目指すべきこと こだわるべき事 少ないステップで簡単に問題を解決できること 他の手段よりもチャットボットを使ったほうが速く、簡単で、よりよい結果を得られること ユーザが**使いたい環境（クライアント）**で動作すること ユーザがボットの存在に気付けること。それを使って何をすればよいのか気付けること 何より大切なのはユーザーエクスペリエンスです。 めっちゃ賢い AI を使っているかどうかではなく、ユーザがやりたいことを素早く、簡単に行えるかが重要です。 こだわらなくてよい事 機械学習は必須ではない。めっちゃ賢いボットは必須ではない。 完璧に自然言語を理解して会話できる必要はない。 ボイス対応により必ず UX が改善されるわけではない。ボイスを嫌うユーザはいるし、ノイズの多い環境では使えない。 大切なのは技術力とかクールさとかではなく、ユーザのやりたいことができることです。 最初の挨拶は「自然言語」か「メニュー選択」か？ どんな話しかけにも反応できるボットは存在しません（少なくとも現在は）。 ユーザは、ボットが何をできるのか知らないので、できることの選択肢を表示してあげるとよいです。 選択肢が少なければボタンを並べて、それを押すだけで会話を進められるようにすると、ユーザの入力の手間を大幅に削減することができます。 できることがたくさんあるのであれば、選択肢として「ヘルプ」ボタンを配置して、より詳しい使い方を提示してあげましょう。 図: 最初のメッセージの例 一般的に、自由回答形式の質問 (open-ended question) はユーザーの返答を予測できないので、選択回答形式の質問 (closed-ended question) を使用した方がボットの設計者にとっても望ましいといえます。 見栄を張ってどんな会話でもできる賢いボットを作ろうとするのではなく、できることを明確に示して上げたほうがユーザにとっても使いやすいボットができるでしょう。 プライバシーポリシーの表示 ユーザが「個人情報保護に関する方針と利用規約」(Privacy policy and terms of use) にアクセスできるようにしておくのが望ましいです。 特に、チャットボットサービスを介して個人情報を収集するのであれば、このような表示は必須になります。 会話 (Dialog) のスタック構造という罠 チャットボットのフレームワーク内部では、会話の流れは Dialog（会話）といった単位で管理されます。 一般的に、ユーザとの会話は、GUI アプリケーションのウィンドウと同様に、Dialog（会話）のスタック構造で管理されます。 つまり、ウィンドウを開いたり閉じたりするのと同様に、次の会話内容へ進んだり、前の会話内容へ戻ったりします。 ただし、、、ユーザにはこのようなスタック構造で会話しているという意識はありません。 ユーザは本当に気まぐれなので、こんなきれいに会話が進むことはありません。 チャットボットのアンチパターン (1) 頑固なボット (The stubborn bot) ユーザが別のことをしたいのに、ボットが現在のシナリオが完了するまで強引に会話を進めようとしてしまう。 ボット「どちらまで行きますか？」 ユーザ「やっぱりやめます」 ボット「分かりませんでした。どちらまで行きますか？」 ユーザ「キャンセル」 ボット「分かりませんでした。どちらまで行きますか？」 ユーザ「終了」 ボット「分かりませんでした。どちらまで行きますか？」 ユーザ「キャンセルしてください。会話を終了してください。もういいです。何もしないでください。」 教訓 ユーザがやりたいことを途中で変えられるようにしよう。 ユーザの発言を無視して、同じ質問を繰り返すのはやめよう。少なくともリトライ回数の上限を設定しよう。 (2) 無知なボット (The clueless bot) ユーザが別の意図で入力したキーワードを、現在の質問への回答だと判断して処理を進めてしまう。 ボット「好きな映画のジャンルを入力してください」 ユーザ「help」 ボット「好きなジャンルとして help を登録しました。それではお楽しみください」 ユーザ「ちょっと待って」 教訓 help（ヘルプ）、cancel（キャンセル）、start over（やり直し）といった入力に対して、割り込んで応答するミドルウェアを導入しよう。 各々の会話 (dialog) ごとに、認識しなければならないキーワードをリスト管理するのやめよう。いつでも使えるマジックワードは、共通のミドルウェアで処理すると楽。 (3) 謎めいたボット (The mysterious bot) 会話中に急にボットからの反応がなくなってしまう。 ボット「こんにちは。ご用件をどうぞ」 ユーザ「今週はどんな映画をやっていますか？」 ユーザ「こんにちは」 ユーザ「今週上映される映画は何がありますか？」 ユーザ「ボットさん、いますか？」 教訓 ボット側で時間がかかるかもしれない処理を開始する前には、ユーザに何らかの反応を返しておこう。 ボットフレームワークの提供する typing メッセージ機能 (typing indicator) を利用しよう。このメッセージ返すことで、ユーザのチャット UI 上に「入力中です」と表示される。 (4) わざわざ言うボット (The captain obvious bot) Captain obvious というのは、分かり切ったことをわざわざ言う人のことです。 ボット「また1万円も課金しちゃいましたね」 ユーザ「そうだね。。。」 ボット「いまオフィスに向かっていますね」 ユーザ「そのとおり。。。」 ボット「オフィスに着きましたね。これから一日仕事ですね」 ユーザ「もう！ほっといてくれ！」 教訓 ユーザにとって有益な情報を提供しよう（そのボットは何のためのもの？） (5) 忘れられないボット (The bot that can\u0026rsquo;t forget) 昔の会話で入力した内容を、今回の会話でも有効な情報として使おうとしてしまう。 ユーザ「旅行に行きたいんだ。イタリアへ。」 ボット「ラスベガスへの交通費は $200 かかります。よろしいですか？」 ユーザ「ラスベガス？？？」 ボット「あなたは1月5日にラスベガス行きのチケットを予約しました」 ユーザ「あぁ、半年前の話ね。。。」 教訓 ユーザが以前の話題を持ち出そうとしない限り、今回開始した話題に集中すること。 例外的な割り込みに対応するミドルウェア ユーザからの特殊な入力に対して「割り込んで」反応するミドルウェアを導入することで、ボットの強引さをいくらか軽減することができます。 具体的には、ユーザから下記のような入力があった場合に、現在の会話への応答として処理するのではなく、例外的な特殊コマンドとして処理するようにします。 cancel: 処理を中断する help: システムの使い方を表示する（処理は継続する） more info: 現在のコンテキストに沿って詳しい情報を表示する（料理メニューの一覧とか、電話番号でも予約できます、とか） これらの振る舞いは、特定の話題に結び付いたものではなく汎用的に使用できるものなので、ミドルウェアとしての実装は一種類だけで済みます。 これらの簡単なコマンドを実装するだけで、ユーザが路頭に迷ってしまうリスクを下げることができます。 ミドルウェアに認識できない入力が来た場合は、現在の会話への入力なのだと判断して、通常通りのコンテキストに応じた処理を行います。 それでも認識できないユーザ発言が繰り返されるようでしたら、最終的にはメインメニューの表示へフォールバックさせます。 具体的な質問 (specific question) で揺らぎのある回答を防ぐ ボットがユーザ発話を自然言語処理する際には、正規表現や LUIS などの文章解析サービスが利用されます。 しかし、高度な言語処理を実装するのはとても大変な作業です。 それよりも、ユーザがあいまいな返答をしないようにうまく質問で誘導することで、自然言語処理の手間を省くということを考慮すべきでしょう。 悪い例 ボット「あなたの名前は何ですか？」 ユーザ「私は山田です」 ボット「こんにちは、“私は 山田”さん」 よい例 ボット「名前を入力してください（入力例: 山田 太郎）」 ユーザ「山田 花子」 ボット「こんにちは、“山田 花子”さん」 このように、入力例を示すというのはとても効果的です。 他にも、次のように入力の例を複数示したり、受け付けるフォーマットを示すのもよいでしょう。 「どこが痛いですか？（入力例: 肩/頭/腕/ひざ）」 「誕生日はいつですか？ (yyyy/MM/dd)」 このような例示では完ぺきではないという人もいるかもしれませんが、何も示さずに自由回答形式で質問するよりは100倍マシです。 高度なサービスを制御するための入り口として使用する 専門的な用途に特化したボットであれば、コマンド入力専用の構文を用意しておくのもよい考えです。 DebOps ボットの例 ユーザ「/STOP VM XYZ」 ボット「仮想マシン \u0026quot;XYZ\u0026quot; を停止します」 ユーザ「/START VM ABC」 ボット「仮想マシン \u0026quot;ABC\u0026quot; を起動します」 このようなコマンドを用意することで、ネット上に構築された高度なサービスを利用するための、敷居の低い入口としてチャットクライアントを使用できるようになります。 ネット上のサービスは常に進化を続け、できることはどんどん増えていきます。 チャットボットをサービス操作のインターフェイスとして配置すれば、チャットボットが最初にユーザに挨拶をするときにサービスの最新情報を伝えることができます。 また、ユーザは help と入力するだけで、いつでも最新の機能を把握することができます。"
},
{
url: "/p/ubmu3bj/",
title: "Next.js で HelloWorld（プロジェクト作成からサーバー起動まで）",
date: "2021-04-18T00:00:00Z",
body: "Next.js で HelloWorld（プロジェクト作成からサーバー起動まで） Next.js とは Next.js は、React.js アプリ開発に必要なアレコレを詰め込んだパッケージです。 React.js を素の状態で導入すると、他にもいろいろなツールやライブラリを組み合わせていくことになるのですが、Next.js を使うとモダンな Web アプリ開発に必要なものが一気に揃えられます。 React.js は基本的に SPA（シングルページアプリ）を想定していますが、Next.js では複数ページによる構成や、サーバーサイドレンダリングなどをサポートしています。 これは、Next.js が単なる React.js 用のコンポーネントライブラリでないことを示しています。 Next.js には次のような特徴があります。 ゼロコンフィグ: 何も設定しなくても、最初から開発サーバーの立ち上げ、プロダクト用ビルドを行えるようになっています。これらは、最適なパフォーマンスが出るようメンテナンスが続けられています。カスタマイズしたいときも、複雑怪奇な webpack.config.js を作成する必要はなく、next.config.js による最小限の設定で済みます。できれば何も設定しないのが理想です。 SSR/SSG によるプリレンダリング: React.js はクライアントサイドで JavaScript を実行する CSR (Client Side Rendering) で動作しますが、Next.js は SSR (Server Side Rendering) や SSG (Static Site Generation) をサポートしています。これは、一般的な Node.js の API を利用してページを構築できることを意味します。開発元の Vercel は、パフォーマンスの面から SSG を推奨しています。 TypeScript をサポート: いまどきの Web アプリ開発では TypeScript はほぼ必須なので、標準サポートはうれしいです。空の tsconfig.js を置くだけで、TypeScript 対応は完了です（設定は自動で行われます）。 ファイルベースのルーティング: pages ディレクトリ以下の構成をそのままルーティング用のリンク名として使うことができます。例えば、pages/xxx/yyy.js は、/xxx/yyy というリンク名にマッピングされます。React Router によるルーティング設定が面倒だと感じている人にとってはうれしいかもしれません。 部分的な高速リロード (Fast Refresh): Next.js の開発サーバーを使って開発しているときに、React コンポーネントのステートを保ったままコード修正を反映できます。例えば、フォームに入力された値を保ったままページ内容を部分的に更新できます。 サーバーレス API: アプリ作成用に、簡易な Web API を作る機能が備わっています。pages/api ディレクトリに JS ファイルを置くだけで API の完成です。 CSS Modules \u0026amp; Sass: コンポーネントから CSS ファイルを import できるようにする CSS modules の仕組みを標準サポートしています。もちろん生の CSS ではなく、Sass で記述できます。生の CSS を使った場合も、ベンダープレフィックスや Flexbox の不具合などを考慮してくれるため、ブラウザの互換性を考慮する必要がありません。CSS-in-JS な styled-jsx もデフォルトで使えます。 コードスプリッティング: 効率的なウェブサイト表示のためのコードスプリッティング機能をサポートしています。これは自動で行われるため、特に意識しなくても最適な形で Web サイトをデプロイできます。 Next.js の Hello World アプリを作成する create-next-app によるアプリ生成 次のように create-next-app コマンドを実行すると、カレントディレクトリに Next.js アプリの雛形として myapp ディレクトリが作成されます（Node.js はインストール済みとします）。 Next.js アプリの新規作成 $ npx create-next-app myapp Creating a new Next.js app in /Users/maku/myapp. Installing react, react-dom, and next using npm... ... Initialized a git repository. Success! Created myapp at /Users/maku/myapp 開発サーバーで動作確認 各種 NPM パッケージのインストールが完了したら、次のようにして開発用のサーバーを起動できます。 開発サーバーの起動 $ cd myapp $ npm run dev Web ブラウザで http://localhost:3000/ にアクセスして、次のようなページが表示されれば成功です。 ディレクトリ構成を見てみる create-next-app で作成した Next.js アプリのディレクトリ構成は次のような感じになっています。 GitHub へ Push する準備までできています（create-react-app と同様）。 myapp/ +-- .git/ ... Git リポジトリ +-- .next/ ... サーバー実行時に生成される +-- node_package/ ... NPM パッケージ +-- pages/ ... 表示する Web ページ（`.js` や `.ts` などを格納する） +-- public/ ... 画像などの静的リソース +-- styles/ ... スタイルシート +-- .gitignore ... Git 用の無視ファイルリスト +-- package.json ... Node.js 設定ファイル +-- README.md ... GitHub 用のリードミー Web サイトのトップページを提供するファイルは、pages/index.js です。 Next.js の開発サーバーを起動した状態で、このファイルの内容を書き換えると、自動的に Web ブラウザがリロードされます。 特徴的なのは、HTML ファイルが存在しない ということでしょうか。 Next.js では、コードの主体は JavaScript ファイルであり、HTML ファイルを作成する必要はありません。 Next.js アプリをホスティングする（Next.js サーバー） Next.js の SSR（サーバーサイドレンダリング）機能やサーバーレス API を使ったアプリケーションは、Next.js サーバー上で動作させる必要があります。 自分でホスティングする場合 (next server) 任意の PC 上で本番環境用の Next.js サーバーを起動するには次のようにします。 $ npm run build # ビルド（.next ディレクトリが使われます） $ npm start # サーバー起動 開発時は npm run dev で自動ビルドまでセットになった開発サーバーを起動しましたが、リリース用には npm run build で明示的にビルドし、その内容を npm start の本番サーバーでホスティングします。 ちなみに、Next.js サーバーのポート番号を変更するには、next start コマンドの -p オプションを使います。 package.json（抜粋） \u0026#34;start\u0026#34;: \u0026#34;next start -p 12340\u0026#34;, Vercel サービスを使う場合 Next.js の開発元である Vercel は、同名の Vercel という Next.js アプリホスティング用のサービスを提供しています。 非営利目的で個人で使う分には無料で使えます。 Vercel のサイト上で GitHub リポジトリとの連携設定を行うだけで、簡単に Next.js アプリを公開できます。 Web サイトを更新したいときは、変更内容を GitHub へプッシュするだけで、Vercel サービスが自動的にビルドして反映してくれます（GitHub Actions の設定すらいりません）。 変更を事前確認したいときなどは、GitHub 上で PullRequest を作成すれば、確認用のサイトを生成してくれます。 いたれりつくせりです。 参考リンク Next.js アプリを Vercel で公開する 静的 HTML のエクスポート Next.js の Static HTML Export 機能を使うと、Next.js アプリを静的な HTML ファイルとしてビルドできます。 これであれば、静的なファイルしかホスティングできない Web サーバーでも、Next.js アプリを公開できます。 Static HTML Export を行うには、Production ビルド (next build) を実行した後に、next export コマンドを実行します。 すると、ビルド結果が out ディレクトリに生成されます。 $ npx next build # TypeScript (JavaScript) のビルド $ npx next export # 静的 HTML の形でエクスポート ... $ ls out 404.html _next/ favicon.ico index.html vercel.svg package.json の NPM スクリプトとして、次のように export スクリプト（および preexport）を定義しておくと便利です。 package.json ... \u0026#34;scripts\u0026#34;: { \u0026#34;dev\u0026#34;: \u0026#34;next dev\u0026#34;, \u0026#34;build\u0026#34;: \u0026#34;next build\u0026#34;, \u0026#34;preexport\u0026#34;: \u0026#34;npm run build\u0026#34;, \u0026#34;export\u0026#34;: \u0026#34;next export\u0026#34; }, ... あとは、次のように実行すれば、デプロイ用の out ディレクトリが作成されます。 $ npm run export 参考リンク Next.js アプリを GitHub Actions でビルドして GitHub Pages で公開する 次のステップ Next.js のアプリは TypeScript で作成することをオススメします。 Next.js のプロジェクトを TypeScript 化する"
},
{
url: "/p/zkxamw9/",
title: "AWS CloudFormation をコマンドライン (CLI) で操作する",
date: "2021-03-11T00:00:00Z",
body: "AWS CloudFormation をコマンドライン (CLI) で操作する テンプレートファイルが正しく記述できているか確認する (cloudformation validate-template) YAML や JSON 形式で作成した CloudFormation 用のテンプレートファイルが、正しく記述できているかを調べることができます。 正しく記述できている場合 $ aws cloudformation validate-template --template-body file://template.json Description: Sample template Parameters: [] 不正なフォーマットの場合 An error occurred (ValidationError) when calling the ValidateTemplate operation: Template format error: JSON not well-formed. (line 5, column 2) 不正なプロパティがある場合 An error occurred (ValidationError) when calling the ValidateTemplate operation: Invalid template property or properties [ABC] スタックを作成する (cloudformation create-stack) ローカルの YAML テンプレートから生成 $ aws cloudformation create-stack --stack-name mystack \\ --template-body file://template.yml 実行結果 StackId: arn:aws:cloudformation:ap-northeast-1:123456789012:stack/mystack/b810c3cd-e492-eb11-6cab-b7f82d02a2e5 S3 バケット上の YAML テンプレートから生成 $ aws cloudformation create-stack --stack-name mystack \\ --template-url https://s3.xxx.xxx/.../template.yaml パラメーターを指定する場合 $ aws cloudformation create-stack --stack-name mystack \\ --template-body file://template.yml \\ --parameters \u0026#34;ParameterKey=Key1,ParameterValue=Value1\u0026#34; \\ \u0026#34;ParameterKey=Key2,ParameterValue=Value2\u0026#34; \\ \u0026#34;ParameterKey=Key3,ParameterValue=Value3\u0026#34; スタックの情報を取得する (cloudformation describe-stacks, describe-stack-resources) スタックの一覧を取得する $ aws cloudformation describe-stacks 指定したスタックの情報を取得する $ aws cloudformation describe-stacks --stack-name \u0026lt;スタック名\u0026gt; 実行結果 Stacks:- CreationTime:\u0026#39;2021-04-01T12:21:20.064000+00:00\u0026#39;DisableRollback:falseDriftInformation:StackDriftStatus:NOT_CHECKEDEnableTerminationProtection:falseNotificationARNs:[]RollbackConfiguration:{}StackId:arn:aws:cloudformation:ap-northeast-1:123456789012:stack/mystack/b810c3cd-e492-eb11-6cab-b7f82d02a2e5StackName:mystackStackStatus:CREATE_COMPLETETags:[] 指定したスタック内のリソースリストを取得する $ aws cloudformation describe-stack-resources --stack-name \u0026lt;スタック名\u0026gt; 実行結果（1つのS3バケットがある場合） StackResources:- DriftInformation:StackResourceDriftStatus:NOT_CHECKEDLogicalResourceId:HelloBucketPhysicalResourceId:mystack-hellobucket-npd68k1m8ut8aResourceStatus:CREATE_COMPLETEResourceType:AWS::S3::BucketStackId:arn:aws:cloudformation:ap-northeast-1:123456789012:stack/mystack/de70c0f6-f192-eb11-1b8b-55dc1106bc7dStackName:mystackTimestamp:\u0026#39;2021-04-01T13:54:43.857000+00:00\u0026#39; スタックを削除する (cloudformation delete-stack) $ aws cloudformation delete-stack --stack-name \u0026lt;STACK_NAME\u0026gt; スタックが特定のステータスになるまで待機する (cloudformation wait) スタックが CREATE_COMPLETE になるまで待機する $ aws cloudformation wait stack-create-complete --stack-name \u0026lt;STACK_NAME\u0026gt; チェンジセットが CREATE_COMPLETE になるまで待機する $ aws cloudformation wait change-set-create-complete \\ --stack-name \u0026lt;STACK_NAME\u0026gt; \\ --change-set-name \u0026lt;CHANGE_SET_NAME\u0026gt;"
},
{
url: "/p/pcp3doy/",
title: "Amazon EC2 で Hello World (1) キーペアの作成",
date: "2021-03-02T00:00:00Z",
body: "Amazon EC2 で Hello World (1) キーペアの作成 EC2 を使う前に SSH キーペアを作成しておく 立ち上げた EC2 インスタンスは SSH で接続して操作するため、まずはキーペア（公開鍵＋秘密鍵）を作成して、その公開鍵を EC2 に登録しておく必要があります。 一度公開鍵を登録すると、EC2 インスタンスを作成するときに、割り当てる公開鍵をプルダウンから選択できるようになります。 EC2 コンソールからキーペアを作成する SSH 接続用のキーペアは、ローカルで作成して EC2 に登録することもできますし、EC2 コンソール上で新規作成することもできます。 EC2 上で作成すると、公開鍵が自動的に EC2 に登録された状態になるのでちょっとだけ楽です。 ここでは、次のように EC2 上でキーペアを作成します。 EC2 マネージメントコンソール を開く サイドバーから キーペア を選択し、キーペアを作成 をクリック キーペアの作成画面で名前とファイル形式を入力し、キーペアを作成 をクリック 名前: ec2key など自由に入力 ファイル形式:（使用する SSH クライアントに合わせて選択） pem 形式 \u0026hellip; OpenSSH を使う場合（主に Linux/macOS） ppk 形式 \u0026hellip; PuTTY を使う場合（主に Windows） すると、自動的に ec2key.pem（秘密鍵）のダウンロードが始まるので、~/.ssh ディレクトリなどに確実に保存します。 この キーファイルを再度ダウンロードすることはできないので注意してください。 EC2 コンソール上に次のように表示されていれば、今後 EC2 インスタンスを生成するときにこのキーを選択できます。 秘密鍵ファイルのパーミッションを設定する ローカル PC に保存した秘密鍵ファイル (.pem) には、自分だけを読み取り可能にするよう、適切なパーミッションを設定しておく必要があります。 これをやっておかないと、ssh コマンドを実行するときに、WARNING: UNPROTECTED PRIVATE KEY FILE! といった警告が出て接続ができません。 $ chmod 0400 ~/.ssh/ec2key.pem これで、EC2 インスタンスに接続するためのキーペアの準備は完了です。 次のステップ → Amazon EC2 で Hello World (2) EC2 インスタンスの起動と接続"
},
{
url: "/p/5mv5dkt/",
title: "DynamoDB を Node.js で操作する（SDK ver.3 の場合）",
date: "2021-03-02T00:00:00Z",
body: "DynamoDB を Node.js で操作する（SDK ver.3 の場合） ここでは、Node.js 用の AWS SDK ver.3 を使って Amazon DynamoDB を操作する方法を説明します。 TypeScript の基本的な環境構築 は終わっているものとします。 DynamoDB 用の Node.js SDK (ver.3) をインストールする まずは、AWS SDK version 3 の DynamoDB 用パッケージをインストールします。 DynamoDB を操作するときに主に次のようなクライアントクラスを使用するのですが、後者の DynamoDBDocumentClient の方は、前者の DynamoDBClient インスタンスをラップして扱いやすくするためのクラスなので、必要に応じてインストールしてください（主にテーブル内のアイテムを扱うときに便利です）。 DynamoDBClient DynamoDB を扱うための基本クラス（DB クライアントと呼ばれる） @aws-sdk/client-dynamodb パッケージが必要 DynamoDBDocumentClient 上記を扱いやすくするためのクラス（Document クライアントと呼ばれる） @aws-sdk/lib-dynamodb パッケージが必要 @aws-sdk/util-dynamodb パッケージも必要っぽい ### yarn の場合 $ yarn add @aws-sdk/client-dynamodb $ yarn add @aws-sdk/lib-dynamodb @aws-sdk/util-dynamodb # Document クライアント ### npm の場合 $ npm install @aws-sdk/client-dynamodb $ npm install @aws-sdk/lib-dynamodb @aws-sdk/util-dynamodb # Document クライアント これで、TypeScript コードから次のようにパッケージ内のクラスをインポートできるようになります。 main.ts import { DynamoDBClient } from \u0026#39;@aws-sdk/client-dynamodb\u0026#39; import { DynamoDBDocumentClient } from \u0026#39;@aws-sdk/lib-dynamodb\u0026#39; DynamoDBClient / DynamoDBDocumentClient インスタンスの生成 DynamoDB の API を呼び出すには、まずは DynamoDBClient インスタンスを生成する必要があります。 さらに、抽象度の高い API を使用したい場合は、DynamoDBDocumentClient インスタンスも生成します。 import { DynamoDBClient, DynamoDBClientConfig } from \u0026#39;@aws-sdk/client-dynamodb\u0026#39; import { DynamoDBDocumentClient } from \u0026#39;@aws-sdk/lib-dynamodb\u0026#39; const config: DynamoDBClientConfig = { // ...接続設定... } const dbClient = new DynamoDBClient(config) const documentClient = DynamoDBDocumentClient.from(dbClient) DynamoDBClient のコンストラクタには、DynamoDBClientConfig オブジェクトを渡すようになっており、これで接続先のリージョンやエンドポイント URL などを設定できるようになっています。 下記に、いくつか接続設定の例を示します。 DynamoDB Local（テスト用ローカルサーバー）に接続する場合 DynamoDB Local テストサーバ (localhost:8000) に接続するには次のように設定します。 ポイントは endpoint プロパティにローカルアドレスを指定するところです。 region や credentials はダミーの値で大丈夫です。 const config: DynamoDBClientConfig = { endpoint: \u0026#39;http://localhost:8000\u0026#39;, region: \u0026#39;ap-northeast-1\u0026#39;, credentials: { accessKeyId: \u0026#39;FAKE\u0026#39;, secretAccessKey: \u0026#39;FAKE\u0026#39; }, } 環境変数で設定した Credential 情報で接続する const config: DynamoDBClientConfig = { endpoint: process.env.DYNAMODB_ENDPOINT, region: process.env.DYNAMODB_REGION ?? \u0026#39;ap-northeast-1\u0026#39;, credentials: { accessKeyId: process.env.DYNAMODB_ACCESS_KEY_ID ?? \u0026#39;FAKE\u0026#39;, secretAccessKey: process.env.DYNAMODB_SECRET_ACCESS_KEY ?? \u0026#39;FAKE\u0026#39;, }, } DynamoDB Local ではなく、本物の DynamoDB サービスに接続する場合は、endpoint プロパティを undefined にしておけば OK です（つまり、prcess.env.DYNAMODB_ENDPOINT 環境変数を設定しなければ OK）。 Cognito 認証＆認可で取得したアクセストークンで接続する Web アプリなどから AWS 上の DynamoDB にアクセスしたいのであれば、Cognito による認証情報などを使って、次のようなコンフィギュレーションを行えば接続できます。 // import { Auth } from \u0026#39;aws-amplify\u0026#39; const config: DynamoDBClientConfig = { region: \u0026#39;ap-northeast-1\u0026#39;, credentials: await Auth.currentCredentials() // Cognito サインイン済みと仮定 } 認証情報ファイルの設定で接続する aws configure コマンドなど で設定した認証情報を使って DynamoDB に接続する場合は、コンフィグ情報に何も設定しなければ OK です。 const config: DynamoDBClientConfig = {} （おまけ）SDK version 2 時代のコンフィグ SDK version 2 版 古い AWS SDK (version 2) では、接続情報を AWS.config を使ってグローバルに設定していました。 AWS.config.update({ region: \u0026#39;ap-northeast-1\u0026#39;, accessKeyId: \u0026#39;FAKE\u0026#39;, secretAccessKey: \u0026#39;FAKE\u0026#39;, dynamodb: { apiVersion: \u0026#39;2012-08-10\u0026#39;, endpoint: \u0026#39;http://localhost:8000\u0026#39; } }) この方法は、プログラムの途中で設定を変更できてしまうため、全体の振る舞いを把握しにくくなってしまう問題がありました。 AWS SDK version 3 では、各クライアントクラスのコンストラクタでコンフィグ情報を渡すことを強制しているため、一貫した動作が保証されます。 テーブルを作成する (CreateTableCommand) DynamoDB のテーブルを作成するには、DynamoDBClient#send メソッドで、CreateTableCommand を送ります。 次の例では、Games という名前のテーブルを作成しています。 DynamoDB は NoSQL なので、基本的に属性を前もって定義しておく必要はありませんが、プライマリーキー（パーティションキー、およびソートキー）だけはテーブル作成時に指定する必要があります。 Games テーブルでは、次のようなプライマリーキーを定義しています。 Hardware: 文字列型 (S) のパーティションキー (HASH) GameId: 文字列型 (S) のソートキー (RANGE) create-table.ts import { CreateTableCommand, DynamoDBClient } from \u0026#39;@aws-sdk/client-dynamodb\u0026#39; const dbClient = new DynamoDBClient({ endpoint: \u0026#39;http://localhost:8000\u0026#39;, }) // テーブルを作成する async function createTable() { try { const command = new CreateTableCommand({ TableName: \u0026#39;Games\u0026#39;, // テーブル名 KeySchema: [ { AttributeName: \u0026#39;Hardware\u0026#39;, KeyType: \u0026#39;HASH\u0026#39; }, // パーティションキー { AttributeName: \u0026#39;GameId\u0026#39;, KeyType: \u0026#39;RANGE\u0026#39; }, // ソートキー ], AttributeDefinitions: [ { AttributeName: \u0026#39;Hardware\u0026#39;, AttributeType: \u0026#39;S\u0026#39; }, // 文字列属性 { AttributeName: \u0026#39;GameId\u0026#39;, AttributeType: \u0026#39;S\u0026#39; }, // 文字列属性 ], ProvisionedThroughput: { ReadCapacityUnits: 1, WriteCapacityUnits: 1, }, StreamSpecification: { StreamEnabled: false, }, }) const output = await dbClient.send(command) console.log(\u0026#39;SUCCESS: Table created:\u0026#39;, output) } catch (err) { console.error(\u0026#39;ERROR:\u0026#39;, err) } } createTable() DynamoDBClient#send メソッドの戻り値は Promise 型になるので、コマンドの結果を参照する場合は、上記のように await で待機する必要があります。 実行結果 SUCCESS: Table created: { \u0026#39;$metadata\u0026#39;: { httpStatusCode: 200, requestId: \u0026#39;0074dc26-ba2e-4eab-b432-14874d58fd91\u0026#39;, extendedRequestId: undefined, cfId: undefined, attempts: 1, totalRetryDelay: 0 }, TableDescription: { ArchivalSummary: undefined, AttributeDefinitions: [ [Object], [Object] ], BillingModeSummary: undefined, CreationDateTime: 2021-02-27T14:44:46.724Z, GlobalSecondaryIndexes: undefined, GlobalTableVersion: undefined, ItemCount: 0, KeySchema: [ [Object], [Object] ], LatestStreamArn: undefined, LatestStreamLabel: undefined, LocalSecondaryIndexes: undefined, ProvisionedThroughput: { LastDecreaseDateTime: 1970-01-01T00:00:00.000Z, LastIncreaseDateTime: 1970-01-01T00:00:00.000Z, NumberOfDecreasesToday: 0, ReadCapacityUnits: 1, WriteCapacityUnits: 1 }, Replicas: undefined, RestoreSummary: undefined, SSEDescription: undefined, StreamSpecification: undefined, TableArn: \u0026#39;arn:aws:dynamodb:ddblocal:000000000000:table/Games\u0026#39;, TableId: undefined, TableName: \u0026#39;Games\u0026#39;, TableSizeBytes: 0, TableStatus: \u0026#39;ACTIVE\u0026#39; } } 例外 すでに同名のテーブルが存在するときに CreateTableCommand を送ると、ResourceInUseException という例外が発生します。 err.code === 'ResourceInUseException' \u0026hellip; Table already exists テーブルを削除する (DeleteTableCommand) DynamoDB から既存のテーブルを削除するには、DynamoDBClient.send で DeleteTableCommand を送ります。 パラメーターはテーブル名 (TableName) だけでいいので簡単です（もちろんテーブルの削除は慎重に行わなければいけませんが）。 delete-table.ts import {DeleteTableCommand, DynamoDBClient} from \u0026#39;@aws-sdk/client-dynamodb\u0026#39; const dbClient = new DynamoDBClient({ endpoint: \u0026#39;http://localhost:8000\u0026#39; }) // テーブルを削除する async function deleteTable() { try { const command = new DeleteTableCommand({ TableName: \u0026#39;Games\u0026#39;, }) const output = await dbClient.send(command) console.log(\u0026#39;SUCCESS: Table deleted:\u0026#39;, output) } catch (err) { console.error(\u0026#39;ERROR:\u0026#39;, err) } } deleteTable() 実行結果 SUCCESS: Table deleted: { \u0026#39;$metadata\u0026#39;: { httpStatusCode: 200, requestId: \u0026#39;99d6402d-5de7-4b3f-91b6-c11e97aae417\u0026#39;, extendedRequestId: undefined, cfId: undefined, attempts: 1, totalRetryDelay: 0 }, TableDescription: { ArchivalSummary: undefined, AttributeDefinitions: [ [Object], [Object] ], BillingModeSummary: undefined, CreationDateTime: 2021-02-27T14:16:30.122Z, GlobalSecondaryIndexes: undefined, GlobalTableVersion: undefined, ItemCount: 0, KeySchema: [ [Object], [Object] ], LatestStreamArn: undefined, LatestStreamLabel: undefined, LocalSecondaryIndexes: undefined, ProvisionedThroughput: { LastDecreaseDateTime: 1970-01-01T00:00:00.000Z, LastIncreaseDateTime: 1970-01-01T00:00:00.000Z, NumberOfDecreasesToday: 0, ReadCapacityUnits: 1, WriteCapacityUnits: 1 }, Replicas: undefined, RestoreSummary: undefined, SSEDescription: undefined, StreamSpecification: undefined, TableArn: \u0026#39;arn:aws:dynamodb:ddblocal:000000000000:table/Games\u0026#39;, TableId: undefined, TableName: \u0026#39;Games\u0026#39;, TableSizeBytes: 0, TableStatus: \u0026#39;ACTIVE\u0026#39; } } 例外 削除しようとしたテーブルが存在しない場合や、使用中の場合は例外が発生します。 err.code === 'ResourceNotFoundException' \u0026hellip; Table not found err.code === 'ResourceInUseException' \u0026hellip; Table in use テーブルの一覧を取得する (ListTablesCommand) DynamoDB に存在するテーブルの一覧を取得するには、DynamoDBClient#send で ListTablesCommand を送ります。 パラメータは空っぽの ListTablesInput オブジェクトを渡しておけば OK です。 戻り値の ListTablesCommandOutput オブジェクトの TableNames プロパティに、テーブル名のリストが格納されています。 list-tables.ts import { DynamoDBClient, ListTablesCommand } from \u0026#39;@aws-sdk/client-dynamodb\u0026#39; const dbClient = new DynamoDBClient({ endpoint: \u0026#39;http://localhost:8000\u0026#39;, }) // テーブルの一覧を取得する async function listTables() { try { const command = new ListTablesCommand({}) const output = await dbClient.send(command) if (output.TableNames) { console.log(output.TableNames.join(\u0026#39;, \u0026#39;)) } console.log(output) } catch (err) { console.error(\u0026#39;ERROR\u0026#39;, err) } } listTables() 実行結果 Games { \u0026#39;$metadata\u0026#39;: { httpStatusCode: 200, requestId: \u0026#39;f80bd8f7-788f-4f17-b81e-dd6e2f529ebf\u0026#39;, extendedRequestId: undefined, cfId: undefined, attempts: 1, totalRetryDelay: 0 }, LastEvaluatedTableName: undefined, TableNames: [ \u0026#39;Games\u0026#39; ] } テーブルの詳細情報を取得する (DescribeTableCommand) 指定したテーブルの詳細情報（スキーマなど）を調べるには、DynamoDBClient#send で DescribeTableCommand を送ります。 パラメータには TableName を指定します。 describe-table.ts import { DescribeTableCommand, DynamoDBClient } from \u0026#39;@aws-sdk/client-dynamodb\u0026#39; const dbClient = new DynamoDBClient({ endpoint: \u0026#39;http://localhost:8000\u0026#39;, }) // テーブルの詳細情報を取得する async function describeTable() { try { const command = new DescribeTableCommand({ TableName: \u0026#39;Games\u0026#39;, }) const output = await dbClient.send(command) console.log(\u0026#39;SUCCESS (describe table):\u0026#39;, JSON.stringify(output, null, 2)) } catch (err) { console.error(\u0026#39;ERROR:\u0026#39;, err) } } describeTable() 実行結果 SUCCESS (describe table): { \u0026#34;$metadata\u0026#34;: { \u0026#34;httpStatusCode\u0026#34;: 200, \u0026#34;requestId\u0026#34;: \u0026#34;b700a435-c7ee-4231-a010-6e05dbda9ab6\u0026#34;, \u0026#34;attempts\u0026#34;: 1, \u0026#34;totalRetryDelay\u0026#34;: 0 }, \u0026#34;Table\u0026#34;: { \u0026#34;AttributeDefinitions\u0026#34;: [ { \u0026#34;AttributeName\u0026#34;: \u0026#34;Hardware\u0026#34;, \u0026#34;AttributeType\u0026#34;: \u0026#34;S\u0026#34; }, { \u0026#34;AttributeName\u0026#34;: \u0026#34;GameId\u0026#34;, \u0026#34;AttributeType\u0026#34;: \u0026#34;S\u0026#34; } ], \u0026#34;CreationDateTime\u0026#34;: \u0026#34;2021-02-27T15:07:34.953Z\u0026#34;, \u0026#34;ItemCount\u0026#34;: 0, \u0026#34;KeySchema\u0026#34;: [ { \u0026#34;AttributeName\u0026#34;: \u0026#34;Hardware\u0026#34;, \u0026#34;KeyType\u0026#34;: \u0026#34;HASH\u0026#34; }, { \u0026#34;AttributeName\u0026#34;: \u0026#34;GameId\u0026#34;, \u0026#34;KeyType\u0026#34;: \u0026#34;RANGE\u0026#34; } ], \u0026#34;ProvisionedThroughput\u0026#34;: { \u0026#34;LastDecreaseDateTime\u0026#34;: \u0026#34;1970-01-01T00:00:00.000Z\u0026#34;, \u0026#34;LastIncreaseDateTime\u0026#34;: \u0026#34;1970-01-01T00:00:00.000Z\u0026#34;, \u0026#34;NumberOfDecreasesToday\u0026#34;: 0, \u0026#34;ReadCapacityUnits\u0026#34;: 1, \u0026#34;WriteCapacityUnits\u0026#34;: 1 }, \u0026#34;TableArn\u0026#34;: \u0026#34;arn:aws:dynamodb:ddblocal:000000000000:table/Games\u0026#34;, \u0026#34;TableName\u0026#34;: \u0026#34;Games\u0026#34;, \u0026#34;TableSizeBytes\u0026#34;: 0, \u0026#34;TableStatus\u0026#34;: \u0026#34;ACTIVE\u0026#34; } } アイテムを追加する (PutItemCommand) テーブルに新しいアイテムを追加したいとき（あるいは既存のアイテムの属性値を上書きしたいとき）は、DynamoDBClient#send メソッドで PutItemCommand を送ります。 追加するアイテムのプライマリキー属性（パーティションキー、およびソートキー）の指定は必須ですが、その他の属性はオプショナルです。 プライマリキーと一致するアイテムがまだ存在しない場合は、新規アイテムの追加になり、プライマリキーと一致するアイテムがすでに存在する場合は、属性値のリプレースになります（このとき、指定しなかった属性値は消えてしまうことに注意してください）。 put-item.ts import {DynamoDBClient, PutItemCommand} from \u0026#39;@aws-sdk/client-dynamodb\u0026#39; const dbClient = new DynamoDBClient({ endpoint: \u0026#39;http://localhost:8000\u0026#39; }) // テーブルにアイテムを追加する async function putItem() { try { const command = new PutItemCommand({ TableName: \u0026#39;Games\u0026#39;, Item: { Hardware: { S: \u0026#39;SNES\u0026#39; }, GameId: { S: \u0026#39;1990-SuperMarioWorld\u0026#39; }, Title: { S: \u0026#39;Super Mario World\u0026#39; }, Players: { N: \u0026#39;2\u0026#39; }, Genre: { S: \u0026#39;ACT\u0026#39; }, }, }) const output = await dbClient.send(command) console.log(\u0026#39;SUCCESS (put item):\u0026#39;, output) } catch (err) { console.log(\u0026#39;ERROR:\u0026#39;, err) } } putItem() 実行結果 SUCCESS (put item): { \u0026#39;$metadata\u0026#39;: { httpStatusCode: 200, requestId: \u0026#39;e230fba2-732b-4f44-a0f2-ddca742f63fe\u0026#39;, extendedRequestId: undefined, cfId: undefined, attempts: 1, totalRetryDelay: 0 }, Attributes: undefined, ConsumedCapacity: undefined, ItemCollectionMetrics: undefined } 上書きされる前のアイテムの内容を取得する PutItemCommand コマンドを送信したときに、プライマリキーと一致するアイテムがすでに存在する場合は、新しく指定した属性値でその内容が置き換えられます。 このとき、もとのアイテムがどのような属性を持っていたかを調べたいときは、PutItemCommand を生成するときに、ReturnValues プロパティを指定します。 コマンド送信の結果の Attributes プロパティでもとの属性値を参照できます。 async function putItem() { try { const command = new PutItemCommand({ TableName: \u0026#39;Games\u0026#39;, Item: { Hardware: { S: \u0026#39;SNES\u0026#39; }, GameId: { S: \u0026#39;1990-SuperMarioWorld\u0026#39; }, Title: { S: \u0026#39;XXXXX\u0026#39; }, // 値を適当に変えてみる Players: { N: \u0026#39;2\u0026#39; }, Genre: { S: \u0026#39;ACT\u0026#39; }, }, ReturnValues: \u0026#39;ALL_OLD\u0026#39;, // もとの属性値を取得 }); const output = await dbClient.send(command); console.log(\u0026#39;SUCCESS (put item):\u0026#39;, output.Attributes); } catch (err) { console.log(\u0026#39;ERROR:\u0026#39;, err); } } 実行結果 SUCCESS (put item): { Title: { S: \u0026#39;Super Mario World\u0026#39; }, Hardware: { S: \u0026#39;SNES\u0026#39; }, Genre: { S: \u0026#39;ACT\u0026#39; }, GameId: { S: \u0026#39;1990-SuperMarioWorld\u0026#39; }, Players: { N: \u0026#39;2\u0026#39; } } すでにアイテムが存在する場合に無視する PutItemCommand コマンドはデフォルトではアイテムの内容を上書きしますが、この振る舞いを抑制したいときは、コマンドのパラメータに次のように ConditionExpression を指定します。 このようにすると、プライマリキーが一致するアイテムがすでに存在する場合に ConditionalCheckFailedException 例外が発生するようになります。 const command = new PutItemCommand({ TableName: \u0026#39;Games\u0026#39;, Item: { Hardware: { S: \u0026#39;SNES\u0026#39; }, GameId: { S: \u0026#39;1990-SuperMarioWorld\u0026#39; }, Title: { S: \u0026#39;XXXXX\u0026#39; }, // 値を適当に変えてみる Players: { N: \u0026#39;2\u0026#39; }, Genre: { S: \u0026#39;ACT\u0026#39; }, }, ConditionExpression: \u0026#39;attribute_not_exists(Hardware)\u0026#39;, }); アイテムの属性値を部分的に更新する (UpdateItemCommand) DynamoDBClient クラスを使う方法（複雑） 既存のアイテムの内容（属性値）を部分的に更新したいときは、DynamoDBClient#send メソッドで UpdateItemCommand を送ります。 PutItemCommand でも既存のアイテムを更新できますが、PutItemCommand は完全に上書きのため、すべての属性値を指定し直さないといけないません。 一方、UpdateItemCommand を使用すると、指定した属性のみを部分的に更新できます。 なお、どちらも指定したアイテム自体が存在しない場合にアイテムが生成されるのは同様です。 UpdateItemCommand で属性値を更新するときのパラメータの指定方法は若干複雑で、プレースホルダを使って新しい属性名 (#xxx) と属性値 (:xxx) を指定する必要があります。 次の例では、既存のアイテムの Title 属性の値を更新し、さらに新しい属性 Maker を追加しています。 update-item.ts（DynamoDBClient を使う方法） import { DynamoDBClient, UpdateItemCommand } from \u0026#39;@aws-sdk/client-dynamodb\u0026#39; const dbClient = new DynamoDBClient({ endpoint: \u0026#39;http://localhost:8000\u0026#39;, }) // アイテムの属性値を部分的に更新する async function updateItem() { try { const command = new UpdateItemCommand({ TableName: \u0026#39;Games\u0026#39;, Key: { Hardware: { S: \u0026#39;SNES\u0026#39; }, GameId: { S: \u0026#39;1990-SuperMarioWorld\u0026#39; }, }, UpdateExpression: \u0026#39;set Title = :x, #a = :y\u0026#39;, ExpressionAttributeNames: { \u0026#39;#a\u0026#39;: \u0026#39;Maker\u0026#39;, }, ExpressionAttributeValues: { \u0026#39;:x\u0026#39;: { S: \u0026#39;Mario 4\u0026#39; }, \u0026#39;:y\u0026#39;: { S: \u0026#39;Nintendo\u0026#39; }, }, }) const output = await dbClient.send(command) console.log(\u0026#39;SUCCESS (update item):\u0026#39;, output) } catch (err) { console.log(\u0026#39;ERROR:\u0026#39;, err) } } updateItem() 実行結果 SUCCESS (update item): { \u0026#39;$metadata\u0026#39;: { httpStatusCode: 200, requestId: \u0026#39;b2bae6de-ceed-42c6-8946-455b75d2472e\u0026#39;, extendedRequestId: undefined, cfId: undefined, attempts: 1, totalRetryDelay: 0 }, Attributes: undefined, ConsumedCapacity: undefined, ItemCollectionMetrics: undefined } DynamoDBDocumentClient クラスを使う方法（簡単） DynamoDBClient をラップする DynamoDBDocumentClient を使うと、もう少し簡単にアイテム内容（属性値）の更新を行うことができます。 コマンドとしては、@aws-sdk/lib-dynamodb モジュールが提供する UpdateCommand を使用します（なぜ対称性のある UpdateItemCommand という名前にしなかったのかは不明）。 update-item.ts（DynamoDBDocumentClient を使う方法） import { DynamoDBClient } from \u0026#39;@aws-sdk/client-dynamodb\u0026#39; import { DynamoDBDocumentClient, UpdateCommand, UpdateCommandInput, } from \u0026#39;@aws-sdk/lib-dynamodb\u0026#39; const dbClient = new DynamoDBClient({ endpoint: \u0026#39;http://localhost:8000\u0026#39;, }) const documentClient = DynamoDBDocumentClient.from(dbClient) // アイテムの属性値を部分的に更新する async function updateItem() { try { const command = new UpdateCommand({ TableName: \u0026#39;Games\u0026#39;, Key: { Hardware: \u0026#39;SNES\u0026#39;, // Partition key GameId: \u0026#39;1990-SuperMarioWorld\u0026#39;, // Sort key }, UpdateExpression: \u0026#39;set Title = :x, #a = :y\u0026#39;, ExpressionAttributeNames: { \u0026#39;#a\u0026#39;: \u0026#39;Maker\u0026#39;, }, ExpressionAttributeValues: { \u0026#39;:x\u0026#39;: \u0026#39;Mario 4\u0026#39;, \u0026#39;:y\u0026#39;: \u0026#39;Nintendo\u0026#39;, }, } as UpdateCommandInput) const output = await documentClient.send(command) console.log(\u0026#39;SUCCESS (update item):\u0026#39;, output) } catch (err) { console.log(\u0026#39;ERROR:\u0026#39;, err) } } updateItem() プライマリキーの指定 (Key) や、新しい属性値の指定 (ExpressionAttributeValues) において、各値の型（S など）を指定する必要がなくなり、コードがスッキリしました！（というか標準のクラスの方でこうなっているべきな気がしますけど\u0026hellip;）。 アイテムを取得する (GetItemCommand, GetCommand) DynamoDBClient を使う方法（複雑） DynamoDB のテーブルから既存のアイテムを 1 つ取得するときは、DynamoDBClient#send メソッドで GetItemCommand を送ります。 パラメータには、テーブル名 (Table) と、アイテムを特定するためのプライマリキー情報 (Key) を指定します。 get-item.ts import { DynamoDBClient, GetItemCommand } from \u0026#39;@aws-sdk/client-dynamodb\u0026#39; const dbClient = new DynamoDBClient({ endpoint: \u0026#39;http://localhost:8000\u0026#39; }) // アイテムを取得する async function getItem() { try { const command = new GetItemCommand({ TableName: \u0026#39;Games\u0026#39;, Key: { Hardware: {S: \u0026#39;SNES\u0026#39;}, GameId: {S: \u0026#39;1990-SuperMarioWorld\u0026#39;}, } }) const output = await dbClient.send(command) console.log(\u0026#39;SUCCESS (get item):\u0026#39;, output) } catch (err) { console.log(\u0026#39;ERROR:\u0026#39;, err) } } getItem(); 実行結果 SUCCESS (get item): { \u0026#39;$metadata\u0026#39;: { httpStatusCode: 200, requestId: \u0026#39;162f4a24-8b5c-4174-a83d-c581df44ca80\u0026#39;, extendedRequestId: undefined, cfId: undefined, attempts: 1, totalRetryDelay: 0 }, ConsumedCapacity: undefined, Item: { Title: { S: \u0026#39;Super Mario World\u0026#39; }, Hardware: { S: \u0026#39;SNES\u0026#39; }, Genre: { S: \u0026#39;ACT\u0026#39; }, GameId: { S: \u0026#39;1990-SuperMarioWorld\u0026#39; }, Players: { N: \u0026#39;2\u0026#39; } } } 指定したプライマリキーに一致するアイテムが見つからないときは、Item プロパティの値が undefined になります。 DynamoDBDocumentClient を使う方法（簡単） DynamoDBDocumentClient を使うと、プライマリキーや戻り値の値の型指定（S など）を省略することができます。 DynamoDB テーブルから 1 つのアイテムを取得するには、DynamoDBDocumentClient#send メソッドで GetCommand を送ります。 get-item.ts import { DynamoDBClient } from \u0026#39;@aws-sdk/client-dynamodb\u0026#39; import { DynamoDBDocumentClient, GetCommand } from \u0026#39;@aws-sdk/lib-dynamodb\u0026#39; const dbClient = new DynamoDBClient({ endpoint: \u0026#39;http://localhost:8000\u0026#39; }) const documentClient = DynamoDBDocumentClient.from(dbClient) async function getItem() { try { const command = new GetCommand({ TableName: \u0026#39;Games\u0026#39;, Key: { Hardware: \u0026#39;SNES\u0026#39;, GameId: \u0026#39;1990-SuperMarioWorld\u0026#39;, } }) const output = await documentClient.send(command) console.log(\u0026#39;SUCCESS (get item):\u0026#39;, output) } catch (err) { console.log(\u0026#39;ERROR:\u0026#39;, err) } } 実行結果 SUCCESS (get item): { \u0026#39;$metadata\u0026#39;: { httpStatusCode: 200, requestId: \u0026#39;162f4a24-8b5c-4174-a83d-c581df44ca80\u0026#39;, extendedRequestId: undefined, cfId: undefined, attempts: 1, totalRetryDelay: 0 }, ConsumedCapacity: undefined, Item: { Title: \u0026#39;Super Mario World\u0026#39;, Hardware: \u0026#39;SNES\u0026#39;, Genre: \u0026#39;ACT\u0026#39;, GameId: \u0026#39;1990-SuperMarioWorld\u0026#39;, Players: 2 } } アイテムを削除する (DeleteItemCommand) DynamoDB のテーブルからアイテムを削除するには、DynamoDBClient#send メソッドで DeleteItemCommand を送ります。 コマンドのパラメータには、テーブル名 (Table) と、削除対象のアイテムを特定するためのプライマリキー情報 (Key) を渡す必要があります。 複合プライマリキーを使用している場合は、パーティションキーとソートキーの両方を指定する必要があります。 delete-item.ts import {DeleteItemCommand, DynamoDBClient} from \u0026#39;@aws-sdk/client-dynamodb\u0026#39;; const dbClient = new DynamoDBClient({ endpoint: \u0026#39;http://localhost:8000\u0026#39; }); // アイテムを削除する async function deleteItem() { try { const command = new DeleteItemCommand({ TableName: \u0026#39;Games\u0026#39;, Key: { Hardware: {S: \u0026#39;SNES\u0026#39;}, GameId: {S: \u0026#39;1990-SuperMarioWorld\u0026#39;}, } }); const output = await dbClient.send(command); console.log(\u0026#39;SUCCESS (delete item):\u0026#39;, output); } catch (err) { console.log(\u0026#39;ERROR:\u0026#39;, err); } } deleteItem(); 実行結果 SUCCESS (delete item): { \u0026#39;$metadata\u0026#39;: { httpStatusCode: 200, requestId: \u0026#39;cdfcb727-b39e-413a-a643-c3f6a11b95c0\u0026#39;, extendedRequestId: undefined, cfId: undefined, attempts: 1, totalRetryDelay: 0 }, Attributes: undefined, ConsumedCapacity: undefined, ItemCollectionMetrics: undefined } 指定したプライマリキーに一致するアイテムが存在しない場合でも、特に例外が発生するということはないようです。 テーブル内のアイテムをすべて取得する (ScanCommand) DynamoDBClient を使う方法（複雑） DynamoDB のテーブルからすべてのアイテムを取得（＝スキャン）するには、DynamoDBClient#send メソッドで ScanCommand を送ります。 コマンドのパラメータには、テーブル名 (Table) を指定します。 上記ドキュメントサイトにも記載がありますが、1 度のスキャンで取得できる最大データサイズは 1MB です。 それを超える場合は、レスポンスに含まれている LastEvaluatedKey を使って続きのデータを要求できます（ページング処理）。 最初から何件ずつアイテムを取得すべきかが決まっている（例えば、テーブルに 10 件ずつ表示する）のであれば、ScanCommand の Limit プロパティにその数を指定できます。 scan.ts（DynamoDBClient を使う場合） import { DynamoDBClient, ScanCommand } from \u0026#39;@aws-sdk/client-dynamodb\u0026#39; const dbClient = new DynamoDBClient({...}) // 全てのアイテムをスキャンする async function scan() { try { const command = new ScanCommand({ TableName: \u0026#39;Games\u0026#39;, // Limit: 10, }) const output = await dbClient.send(command) console.log(JSON.stringify(output, null, 2)) } catch (err) { console.log(\u0026#39;ERROR:\u0026#39;, err) } } scan() 実行結果 { \u0026#34;$metadata\u0026#34;: { \u0026#34;httpStatusCode\u0026#34;: 200, \u0026#34;requestId\u0026#34;: \u0026#34;V4KQNSO5AEMVJF66Q9ASUAAJGJ3B11BRMBKKTVASP614LRKL6D7V\u0026#34;, \u0026#34;attempts\u0026#34;: 1, \u0026#34;totalRetryDelay\u0026#34;: 0 }, \u0026#34;Count\u0026#34;: 2, \u0026#34;Items\u0026#34;: [ { \u0026#34;Title\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;Super Mario World\u0026#34; }, \u0026#34;Hardware\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;SNES\u0026#34; } }, { \u0026#34;Title\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;Dr. Mario\u0026#34; }, \u0026#34;Hardware\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;NES\u0026#34; } } ], \u0026#34;ScannedCount\u0026#34;: 2 } DynamoDBDocumentClient を使う方法（簡単） 上記の実行結果を見ると分かるように、DynamoDBClient#scan(ScanCommand) で返される JSON データは扱いやすい形式になっていません（いちいち S とか N とかフィールドタイプが入る）。 そこで、ドキュメントクライアント (DynamoDBDocumentClient) の出番です。 DynamoDBDocumentClient は DynamoDBClient を扱いやすくするためのクラスで、これを使うと、テーブルのスキャン結果を扱いやすい JavaScript オブジェクトとして取得することができます。 下記は、DynamoDBDocumentClient を使ったテーブルスキャン（全アイテム取得）の例です。 ScanCommand は @aws-sdk/client-dynamodb モジュールが提供するものではなく、@aws-sdk/lib-dynamodb が提供するものを使う必要があります。 scan.ts（DynamoDBDocumentClient を使う場合） import { DynamoDBClient } from \u0026#39;@aws-sdk/client-dynamodb\u0026#39; import { DynamoDBDocumentClient, ScanCommand, ScanCommandInput, ScanCommandOutput, } from \u0026#39;@aws-sdk/lib-dynamodb\u0026#39; const dbClient = new DynamoDBClient({ endpoint: \u0026#39;http://localhost:8000\u0026#39;, }) const documentClient = DynamoDBDocumentClient.from(dbClient) async function scan() { try { const command = new ScanCommand({ TableName: \u0026#39;Games\u0026#39;, } as ScanCommandInput) const output: ScanCommandOutput = await documentClient.send(command) console.log(JSON.stringify(output, null, 2)) } catch (err) { console.log(\u0026#39;ERROR:\u0026#39;, err) } } scan() 実行結果 { \u0026#34;$metadata\u0026#34;: { \u0026#34;httpStatusCode\u0026#34;: 200, \u0026#34;requestId\u0026#34;: \u0026#34;V4KQNSO5AEMVJF66Q9ASUAAJGM9T8IOD909C85GIL0MDN8F27NFV\u0026#34;, \u0026#34;attempts\u0026#34;: 1, \u0026#34;totalRetryDelay\u0026#34;: 0 }, \u0026#34;Count\u0026#34;: 2, \u0026#34;Items\u0026#34;: [ { \u0026#34;Title\u0026#34;: \u0026#34;Super Mario World\u0026#34;, \u0026#34;Hardware\u0026#34;: \u0026#34;SNES\u0026#34; }, { \u0026#34;Title\u0026#34;: \u0026#34;Dr. Mario\u0026#34;, \u0026#34;Hardware\u0026#34;: \u0026#34;NES\u0026#34; } ], \u0026#34;ScannedCount\u0026#34;: 2 } こちらの実行結果を見ると、Items プロパティの下に、JavaScript オブジェクトの配列が直感的な形式で格納されています。 このプロパティ値に TypeScript の型情報を付けてやれば、あとは簡単にデータ参照できます。 const games = output.Items as Game[] 上記で実装した scan() 関数を外から呼び出したい場合は、次のような感じで Promise オブジェクトを返すように実装します。 export async function getGames(): Promise\u0026lt;Game[]\u0026gt; { const command = new ScanCommand({ TableName: \u0026#39;Games\u0026#39;, } as ScanCommandInput) const output: ScanCommandOutput = await documentClient.send(command) return output.Items as Game[] }"
},
{
url: "/p/xbipv39/",
title: "AWS の初期設定: 管理者用の IAM ユーザーを作成する",
date: "2021-02-07T00:00:00Z",
body: "AWS の初期設定: 管理者用の IAM ユーザーを作成する 何をするか？ AWS のベストプラクティスでは、管理者であっても普段の作業では AWS アカウントのルートユーザーを直接使うべきではないとされています。 参考: AWS アカウント、IAM ユーザー、グループ、ポリシーの違い そこで、まずは管理者の普段の作業用に IAM ユーザーを作成します。 この作成作業は、AWS アカウントのルートユーザーで行う必要があります（初期状態ではユーザー作成の権限がルートユーザーにしかないため）。 ここでは、下記のような名前の IAM ユーザーとグループを作成することにします。 IAM ユーザー: admin IAM グループ: Admins \u0026hellip; （AdministratorAccess ポリシーを割り当てます） 管理者用 IAM ユーザーの作成 AWS IAM コンソール にサインインし、次のような感じで IAM ユーザーを作成します。 アクセス管理 → ユーザー → ユーザーを追加 を選択し、次のように入力 ユーザー名: admin アクセスの種類: CLI などで操作するなら プログラムによるアクセス にチェック ユーザーをグループに追加 → グループの作成 を選択し、次のように入力 グループ名: Admins ポリシー: AdministratorAccess を選択 アクセスキーや、シークレットアクセスキーを作成したのであれば、このタイミングで表示されるので、なくさないよう厳重に保存します（後から確認することはできません）。 これで、管理者用の普段の作業も、ルートユーザーではなく、admin という IAM ユーザーで行えるようになります。 （応用）開発者用の IAM ユーザーの作成 上記では管理者用の IAM ユーザーを作成しましたが、それ以外の IAM ユーザー（開発者用など）も同様に作成することができます。 AWS は開発者用の IAM ポリシーをいくつか定義しています。 AdministratorAccess ポリシーとの大きな違いは、IAM 関連の操作（つまりユーザー管理）をするための権限を持っていないことです。 職務機能の AWS 管理ポリシー データベース管理者 : DatabaseAdministrator データサイエンティスト : DataScientist 開発者パワーユーザー : PowerUserAccess ネットワーク管理者 : NetworkAdministrator セキュリティ監査人 : SecurityAudit サポートユーザー : SupportUser システム管理者 : SystemAdministrator 閲覧専用ユーザー : ViewOnlyAccess ここでは、AWS CLI を使って、コマンドラインからユーザーの作成と、PowerUserAccess ポリシーの割り当てをしてみます。 事前準備として、AWS CLI の初期設定 は完了しており、AdministratorAccess ポリシーの付いた IAM ユーザーのアクセスキーでコマンド実行できるようになっているものとします。 IAM ユーザー (maku) の作成 $ aws iam create-user --user-name maku User: Arn: arn:aws:iam::098342099475:user/maku CreateDate: \u0026#39;2021-02-07T12:20:38+00:00\u0026#39; Path: / UserId: ABS2Q6S3VUAIDAQXINMCQ UserName: maku IAM ユーザーのアクセスキーを発行 $ aws iam create-access-key --user-name=maku AccessKey: AccessKeyId: AOXINMCQO7AASOQAKIAQ CreateDate: \u0026#39;2021-02-07T12:38:11+00:00\u0026#39; SecretAccessKey: MbX17I/DSInIN7dD1YOh5cE19EqG4gmblXSotFTj Status: Active UserName: maku ここで、忘れずにアクセスキー (AccessKeyId) とシークレットアクセスキー (SecretAccessKey) を保存しておきます。 IAM ユーザーに PowerUserAccess ポリシーを割り当てる $ aws iam attach-user-policy --user-name=maku --policy-arn=arn:aws:iam::aws:policy/PowerUserAccess これで、開発用に使用する IAM ユーザーの作成は完了です。"
},
{
url: "/p/ubkt3ai/",
title: "GitHub OAuth トークンを取得する (1) 処理の流れを理解する",
date: "2020-08-16T00:00:00Z",
body: "GitHub OAuth トークンを取得する (1) 処理の流れを理解する GitHub の OAuth トークンとは GitHub API を使って GitHub 上の情報（リポジトリ情報やユーザー情報）を取得するには、GitHub によって発行されるアクセストークンが必要です。 GitHub API ver.3 (REST API) ではアクセストークンを必要としない API もありましたが、GitHub API ver.4 (GraphQL API) では必ずアクセストークンが必要です。 アクセストークンにはいくつか種類があり、GitHub の Web サイト上で作成する パーソナルアクセストークン や、Web アプリの OAuth プロセスで取得する OAuth アクセストークン などがあります。 アクセストークンの取得方法は異なりますが、いずれも取得した後は同じように使用できます。 パーソナルアクセストークン : ユーザーが GitHub サイト上で作成 OAuth アクセストークン : Web アプリ内の OAuth プロセスで取得 通常、Web アプリから GitHub API を使用する場合は、後者の OAuth を使用してアクセストークンの取得を自動化します。 ここでは、GitHub の OAuth アクセストークン取得の流れを、実装コードを示しながら説明していきます。 GitHub の OAuth の流れ (Web application flow) Web アプリから OAuth トークンを取得するまでの流れはざっと次のような感じになります。 (1) GitHub のログイン画面に遷移 Web アプリから次のようなアドレスで GitHub のログインページにジャンプします。 https://github.com/login/oauth/authorize?client_id=XXX\u0026amp;scope=YYY` すると、GitHub のサイト上で、この Web アプリに情報を提供してもいいかの確認が表示されるので、ここでユーザーが OK すると、あらかじめ登録してあったコールバックアドレスに Web ブラウザがリダイレクトされます。 OAuth アプリの登録方法に関しては後述しますが、上記 URL の client_id パラメータには登録済みの OAuth アプリの ID を指定し、scope パラメータには取得したい情報のスコープ（repo や user）を指定します。 (2) 一時コードの取得 GitHub からのリダイレクト要求により、リダイレクト先のページ（自分の Web サイト内）に Web ブラウザが自動的にジャンプします。 このとき、URL の末尾にアクセストークン取得用の一時コード (temporary code) が次のような形で付いてきます。 http://localhost:1234?code=ABCDEABCDEABCDE この 一時コードはアクセストークンではない ので注意してください。 アクセストークンは、後述の HTTP POST メソッドで、一時コードを送ることで取得することができます。 この段階では、JavaScript などで URL をパースし、一時コードを抽出しておきます。 一時コードの有効期間は 10 分間 とされているので、すぐにアクセストークンを取得する必要があります。 アクセストークンの方は Revoke されるまで有効です。 (3) アクセストークンの取得 前のステップで取得した一時コードを使って、次のアドレスに POST リクエストを送ると、晴れて OAuth アクセストークンを取得することができます。 https://github.com/login/oauth/access_token POST リクエストには、次のようなパラメータを含めておく必要があります。 client_id \u0026hellip; 登録した OAuth アプリに割り当てられたクライアント ID（文字列） client_secret \u0026hellip; 登録した OAuth アプリに割り当てられたクライアントシークレット（文字列） code \u0026hellip; 前のステップで取得した一時コード（文字列） レスポンスの形式は、POST リクエスト時に指定した Accept ヘッダの値によって変化します。 例えば、Accept: application/json と指定してリクエストすると、次のような JSON 形式のレスポンスが返ってきます。 { \u0026#34;access_token\u0026#34;: \u0026#34;e72e16c7e42f292c6912e7710c838347ae178b4a\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;repo,gist\u0026#34;, \u0026#34;token_type\u0026#34;: \u0026#34;bearer\u0026#34; } この中の access_token が、OAuth アクセストークンです。 これを GitHub API を呼び出すときのリクエストヘッダに指定することになります。 ☝️ CORS 制約 残念ながら、最後のステップのアクセストークンを取得する API は、クロスオリジン通信 (CORS) の制約のため、Web ブラウザ上で動作する JavaScript からは呼び出せないようになっています。 GitHub のアクセストークンは、外部サーバなどで動作する Node.js プログラムなどを経由して取得しなければいけません。 ここでは、最後のステップの HTTP POST リクエストだけ Node.js プログラムを使って実行し、アクセストークンが正しく取得できるところまでを確認します。 OAuth アプリの登録 GitHub から一時コードを発行してもらうには、下記の設定ページから OAuth アプリを登録して、クライアント ID を生成しておく必要があります。 登録と言っても、アプリ名と一時コード発行時のコールバックアドレスなどを設定するだけで簡単に終わります。 GitHub / Settings / Developer settings / OAuth App Web アプリでの GitHub 認証時には、ここで設定したアプリ名がユーザーに提示されることになります。 怪しいアプリだと思われないように、アプリ名はちゃんとしたものを設定しましょう（登録後も簡単に変更できますが）。 今回は、開発用 Web サーバーのローカルアドレス (localhost) の登録なので、アプリ名は適当に付けちゃって大丈夫です。 重要なのは Authorization callback URL で、このアドレスが、一時コード取得時のリダイレクト先になります。 最後に Register application ボタンを押すと、次のように、クライアント ID とクライアントシークレットが発行されます。 これらの値を使って、一時コードやアクセストークンを取得することになります。 発行された値は、登録済み OAuth アプリの一覧 からいつでも確認することができるので、特に保存しておく必要はありません。 Web アプリの実装 (1) GitHub のログイン画面に遷移 まず、GitHub のログインサイトへのリンクを張ります。 認証後は GitHub からリダイレクトされて戻ってくるので、単純にページ遷移してしまえば OK です。 アドレス末尾のクエリ文字列として、前述の OAuth アプリ登録で発行されたクライアント ID (client_id) と、情報のスコープ (scope) を指定する必要があります。 HTML \u0026lt;a href=\u0026#34;https://github.com/login/oauth/authorize?client_id=e971ec6b4a72cebc398c\u0026amp;scope=repo\u0026#34;\u0026gt;Sign In\u0026lt;/a\u0026gt; もちろん、JavaScript から次のようにページ遷移しても OK です。 JavaScript const CLIENT_ID = \u0026#39;e971ec6b4a72cebc398c\u0026#39;; window.location.href = `https://github.com/login/oauth/authorize?client_id=${CLIENT_ID}\u0026amp;scope=repo`; ☝️ クライアント ID は公開してよい？ クライアント ID は、GitHub に登録されたアプリの単なる識別子であり、秘密のキーではないので、上記のように HTML ファイルや JavaScript ファイルにハードコードしても問題ありません。 (2) 一時コードの取得 上記のリンクにアクセスすると、GitHub の認証（認可）画面が表示されます。 ユーザーが情報へのアクセスを許可すると、OAuth アプリ登録で指定しておいたコールバックアドレスにリダイレクトされます。 リダイレクトされた URL のクエリ文字列部分に一時コードが入ってくるので、これを window.location.search などから抽出すれば、一時コードの取得は完了です。 JavaScript const params = window.location.search; //=\u0026gt; \u0026#34;?code=4f7b17572bee8cac9587\u0026#34; const code = params.startsWith(\u0026#39;?code=\u0026#39;) ? params.split(\u0026#39;=\u0026#39;)[1] : undefined; if (code) { alert(\u0026#39;一時コード: \u0026#39; + code); //=\u0026gt; \u0026#34;4f7b17572bee8cac9587\u0026#34; } URL に一時コードが含まれているときは、code 変数にその値が格納されます。 一時コードが含まれていないときは、code 変数の値は undefined になります。 実際の Web アプリの実装では、この code 変数の値が設定されている場合に次のアクセストークン取得のステップに進む、といった流れになると思います。 (3) アクセストークンの取得 最後に、前のステップで取得した一時コード (code) を使ってアクセストークンを取得するのですが、クロスオリジン通信 (CORS) の制約があるため、残念ながら Web ブラウザ上の JavaScript からは、直接アクセストークンを取得することはできません。 ここでは、別途 Node.js のプログラムを作成し、そのプログラムを使ってアクセストークンを取得できることを確認してみます。 後述のプログラムでは、HTTP リクエストを発行するために node-fetch モジュールを使用しているので、先にインストールしておきます。 ちなみに、この node-fetch モジュールは、Web ブラウザの fetch 関数と同様の機能を Node.js アプリから使えるようにするためのものです。 $ npm install node-fetch 下記のコードを実行すると、HTTP POST リクエストを発行してアクセストークンを取得します。 get-token.js const fetch = require(\u0026#39;node-fetch\u0026#39;); // 下記の値は自分の OAuth アプリのものに変更してください const URL = \u0026#39;https://github.com/login/oauth/access_token\u0026#39;; const CLIENT_ID = \u0026#39;e971ec6b4a72cebc398c\u0026#39;; const CLIENT_SECRET = \u0026#39;fae0b936df633dc526ab754731b3015c6b14afcb\u0026#39;; const TEMP_CODE = \u0026#39;4f7b17572bee8cac9587\u0026#39;; // 一時コード // HTTP リクエストのカスタマイズ const fetchOption = { method: \u0026#39;POST\u0026#39;, headers: { Accept: \u0026#39;application/json\u0026#39;, \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39;, }, body: JSON.stringify({ client_id: CLIENT_ID, client_secret: CLIENT_SECRET, code: TEMP_CODE, }) }; // HTTP POST リクエストを送信 fetch(URL, fetchOption) .then(res =\u0026gt; { if (!res.ok) { throw new Error(`${res.status}${res.statusText}`); } return res.json(); }) // ここでレスポンスの JSON オブジェクトを出力 .then(json =\u0026gt; console.log(json)) // エラーはまとめて処理 .catch(err =\u0026gt; console.error(err)); コードをシンプルにするために、クライアント ID などをハードコードしているので、先頭部分の次の定数を適切な値に変更してから実行してください。 CLIENT_ID \u0026hellip; 登録した OAuth アプリのクライアント ID CLIENT_SECRET \u0026hellip; 登録した OAuth アプリのクライアントシークレット TEMP_CODE \u0026hellip; 前述のステップで取得した一時コード 特に、一時コード (TEMP_CODE) は発行後 10 分で期限切れになるので、素早くコード修正して実行してくださいｗ アクセストークンの取得に成功すると、次のような結果が表示されます。 実行例 $ node get-token { access_token: \u0026#39;e08644f37543bf0722d9d79dcb64973cfdbcb9e4\u0026#39;, token_type: \u0026#39;bearer\u0026#39;, scope: \u0026#39;repo\u0026#39; } この中の access_token プロパティの値が、我々が望んでいた OAuth アクセストークンです。 GitHub API を実行するときは、このトークンを HTTP リクエストヘッダに指定して呼び出すことになります。 次のステップへ これで、GitHub の OAuth アクセストークンの取得の流れがわかりました。 ただ今回は、最後のアクセストークンの発行で、ローカルの Node.js プログラムを使いました。 これでは静的な Web サイトにおいて自動でアクセストークンを取得することはできないので、実際にはアクセストークンを取得するための独自のバックエンドサーバーを用意して、Web サイトはそこ経由でアクセストークンを取得することになります。 その話はまた 次回 。。。"
},
{
url: "/p/r7fov4b/",
title: "React + TypeScript の環境を整える (2) Parcel を使う方法",
date: "2020-08-15T00:00:00Z",
body: "React + TypeScript の環境を整える (2) Parcel を使う方法 Parcel とは Parcel は、ゼロ設定 をウリとした Web アプリバンドラーです。 React + TypeScript + SCSS + CSS Modules といった環境を自力でセットアップしようとすると なかなか大変な設定が必要 なのですが、Parcel を使うと、開発環境がサクサクッと完成します。 React プロジェクトを作成するときは、create-react-app を使って雛形を生成する方法もありますが、余計なファイルがたくさん作られたりして、あまり分かりやすいとは言えません。 そんなときは Parcel を使ってみると、そのシンプルさに驚くと思います。 Parcel を使うと、次のような機能がほとんど設定なしでいきなり使えます。 コマンドラインオプションの一覧 を見ると、どのような機能があるかをざっと把握することができます。 開発用の Web サーバー機能（HMR: Hot Module Replacement 対応） TypeScript の自動変換（HTML ファイルから直接ロードする記述が可能） PostCSS による CSS 生成（SCSS、ベンダープレフィックス） CSS ファイルのインポート (CSS Modules) JSON ファイルのインポート PNG ファイルのインポート Pug (Jade) による HTML 生成 リリース用の minify また、Parcel は Node モジュールの自動インストール機能を備えており、parcel コマンドで開発用 Web サーバーを起動すると、自動的に依存モジュールをインストールしてくれます。 例えば、HTML ファイルから TypeScript ファイルを読み込んでいると、typescript モジュールが自動的にインストールされます。 Parcel のインストール Web サイト用のディレクトリを作成し、parcel モジュールを開発用にインストールします。 $ mkdir myapp \u0026amp;\u0026amp; cd myapp $ npm init -y $ npm install --save-dev parcel これで、Parcel の開発用サーバーを起動したり、Web サイトコンテンツのビルドを行えるようになります。 TypeScript のインストールは Parcel による自動インストールに任せることができるので、ここでは手動ではインストールしないことにします。 明示的にインストールしておきたければ次のように実行しておきます。 これは手動で行わなくてよい $ npm install --save-dev typescript ☝️ ワンポイント 依存モジュールの自動インストール機能は、リリース用ビルド (parcel build) を行う場合はデフォルトで無効になっています。 自動インストール機能は便利ですが、基本的には Node モジュールは明示的にインストールした方がよいかもしれません。 Parcel によって依存モジュールが自動インストールされるときは、package.json の依存情報が更新されます。 更新された package.json をコミットするのを忘れないようにしてください。 Web サイトのコンテンツを用意する Web サイトのコンテンツとして、適当な HTML ファイルと TypeScript ファイルを用意します。 ソースコードとなる HTML ファイルおよび TypeScript ファイルは、src ディレクトリ以下に配置することにします。 src/index.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;ja\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1\u0026#34;\u0026gt; \u0026lt;title\u0026gt;My App\u0026lt;/title\u0026gt; \u0026lt;script src=\u0026#34;script/index.ts\u0026#34; async\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div id=\u0026#34;root\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; HTML ファイルの中から、直接 TypeScript ファイル (index.ts) を読み込んでいる ことに注目してください。 このように記述しておくだけで、Parcel が自動的に TypeScript トランスパイルを実行し、HTML ファイルから正しい JavaScript ファイルを読み込むように変換してくれます。 下記の TypeScript コードは、上記の HTML ファイルから読み込むファイルです。 src/script/index.ts const root = document.getElementById(\u0026#39;root\u0026#39;) as HTMLElement; root.innerText = \u0026#39;Hello Parcel\u0026#39;; これくらいのコードであれば TypeScript にする必要はほとんどありませんが、ここでは TypeScript のトランスパイルが自動的に実行されることを示すために .js ではなく .ts ファイルを使用しています。 開発用 Web サーバーを起動する (parcel serve) src ディレクトリ以下に必要な HTML ファイルと TypeScript ファイルを作成したら、次のように parcel (parcel server) コマンドを実行して、開発用の Web サーバーを起動します。 --open オプションを付けると、自動的に Web ブラウザを開いてくれます。 ポート番号をデフォルトの 1234 から変更したい場合は、--port オプションを使用してください。 $ npx parcel src/index.html --open Server running at http://localhost:1234 ✨ Built in 131ms. この時点で、TypeScript モジュールがインストールされていない場合は、Parcel が自動的にインストールし、さらにトランスパイルまで実行してくれます。 変換後の HTML ファイルや JavaScript ファイルは、デフォルトで dist ディレクトリに出力されます。 出力先のディレクトリを変更したい場合は、-d オプションを使用します。 開発用の Web サーバーでは HMR (Hot Module Replacement) 機能が有効になっているので、TypeScript コード (index.ts) の内容を変更すると、再起動なしで自動的に反映されます。 root.innerText = 'Hello Parcel' の行を変更して、表示が変更されることを試してみてください。 開発用の Web サーバーでは、環境変数 NODE_ENV=development が設定されます。 これを利用して、開発時のみ有効なコードブロックを記述できます。 if (process.env.NODE_ENV === \u0026#39;development\u0026#39;) { // 開発中のみ有効なコード } デプロイ用にビルドする (parcel build) parcel build コマンドを実行すると、公開用の Web サーバーにデプロイするためのファイル群を作成します。 デフォルトの出力先が、parcel (serve) で開発用サーバーを起動した場合と同じ dist ディレクトリになっているので、ファイルが混在しないように、-d オプションで出力先を変えておいた方がよいでしょう。 次の例では、出力先を build ディレクトリに設定しています。 $ npx parcel build src/index.html -d build ✨ Built in 1.50s. build/script.6d3c0223.js 1.18 KB 757ms build/script.6d3c0223.js.map 280 B 2ms build/index.html 193 B 693ms あとは、build ディレクトリ以下に生成されたファイル群を Web サーバーにデプロイするだけです。 parcel build によるバンドル時には、デフォルトで HTML、CSS、JS ファイルの圧縮（改行削除や、変数名の簡略化）が有効になっています。 その他の特徴は、下記の公式ドキュメントを参照してください。 参考: Parcel - Production package.json にビルド用スクリプトを追加する ここまでの例では、直接 parcel コマンドを実行していましたが、npm のスクリプトとして登録しておくと便利です。 package.json（抜粋） \u0026#34;scripts\u0026#34;: { \u0026#34;start\u0026#34;: \u0026#34;parcel src/index.html --open\u0026#34;, \u0026#34;build\u0026#34;: \u0026#34;rm -rf build \u0026amp;\u0026amp; parcel build src/index.html -d build\u0026#34; }, このように記述しておくと、npm start で開発用サーバーの起動、npm run build で本番用ビルドを行えるようになります。 ☝️ build ディレクトリの削除 parcel build コマンドは、前回のビルド時に出力したファイルを削除してくれません。 余計なファイルがデプロイされてしまうのを防ぐため、上記のように build スクリプトで古いファイルを削除しておくとよいでしょう。 React (Preact) のセットアップ 次に React コンポーネント (.tsx) を読み込めるようにしてみます。 React 関連の NPM パッケージは先に手動でインストールしておきます。 React 本体は Parcel による自動インストールに任せることもできるのですが、TypeScript の型定義ファイルは自動インストールしてくれないみたいです。 $ npm install --save react react-dom $ npm install --save-dev @types/react @types/react-dom ここでは、次のような簡単な App コンポーネントを作って表示してみます。 JSX コードが含まれているので、拡張子を .tsx にすることに注意してください。 src/script/components/App.tsx import * as React from \u0026#39;react\u0026#39;; export const App: React.FC = () =\u0026gt; { return \u0026lt;h1\u0026gt;Hello React\u0026lt;/h1\u0026gt;; }; index.ts ファイルの拡張子も .tsx に変更し、上記の App コンポーネントを読み込んで使用します。 src/script/index.tsx import * as React from \u0026#39;react\u0026#39;; import * as ReactDOM from \u0026#39;react-dom\u0026#39;; import { App } from \u0026#39;./components/App\u0026#39;; ReactDOM.render(\u0026lt;App /\u0026gt;, document.getElementById(\u0026#39;root\u0026#39;)); 最後に index.html ですが、index.ts ではなく index.tsx を読み込むようにするところだけ変更します。 src/index.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;ja\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1\u0026#34;\u0026gt; \u0026lt;title\u0026gt;My App\u0026lt;/title\u0026gt; \u0026lt;script src=\u0026#34;script/index.tsx\u0026#34; async\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div id=\u0026#34;root\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; あとは何も設定しなくても、次のようにおもむろに Parcel の開発用サーバを起動するだけで、React を使った Web サイトが表示されます。 $ npm start 本当に「ゼロ設定」ですね！ こんなに簡単でよいのでしょうか。 おまけ：SCSS の有効化 生の CSS をゴリゴリ記述するのはつらいので、SCSS は使えるようにしておいた方がよいでしょう。 Parcel で SCSS を使用するには、ちょっとだけ設定が必要です。 Parcel で SCSS を使うための設定 公式サイト の記述通りですが、次のように sass モジュールをインストールし、 sass モジュールのインストール $ npm install --save-dev sass 下記のような設定ファイル (.sassrc) をプロジェクトルートに配置すれば OK です。 .sassrc { \u0026#34;includePaths\u0026#34;: [\u0026#34;node_modules\u0026#34;] } SCSS を使ってみる 次のような簡単な SCSS ファイルを使ってみます。 src/css/main.scss $BG_COLOR: yellow; .app-title { background: $BG_COLOR; } あとは、HTML ファイルから次のように参照しておけば、 src/index.html（抜粋） \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;css/main.scss\u0026#34;\u0026gt; React コンポーネント (.tsx) から次のように CSS クラスを参照できるようになります。 src/script/components/App.tsx import * as React from \u0026#39;react\u0026#39;; export const App: React.FC = () =\u0026gt; { return \u0026lt;h1 className=\u0026#34;app-title\u0026#34;\u0026gt;Hello React\u0026lt;/h1\u0026gt; }; index.html の中でスタイルシートを読み込むのではなく、.tsx の中でインポートして参照することもできます。 この場合は、.tsx ファイルのあるディレクトリからの相対パスになることに注意してください。 CSS クラスの使用方法は上記と同様です。 import \u0026#39;../../css/main.scss\u0026#39;; ただ、このように .tsx ファイルの中から CSS ファイルをインポートするのであれば、下記の CSS Modules の仕組みを使って、そのコンポーネント専用の CSS ファイルをインポートするようにした方がよいでしょう。 おまけ：CSS Modules の有効化 CSS Modules の仕組みを使用するときも、ちょっとだけ設定が必要です。 Parcel で CSS Modules を使うための設定 ほぼ 公式サイトの説明 通りですが、postcss-modules のインストールが必要です。 $ npm install --save-dev postcss-modules そして、プロジェクトルートに次のような設定ファイル (.postcssrc) を配置します。 .postcssrc { \u0026#34;modules\u0026#34;: true } CSS Modules を使ってみる CSS Modules の仕組みでスタイル定義する場合は、React コンポーネントと同じディレクトリに .css ファイル（あるいは .scss ファイル）を置いておくと、コンポーネントとしてのまとまりがよくなります。 前述の SCSS の設定を行っておけば、.scss ファイルも CSS Modules の仕組みで読み込むことができます。 下記の App.scss ファイルでは、App コンポーネント用のスタイル定義を行っています。 CSS Modules の仕組みを使うと、CSS クラス名の名前空間がファイルごとに分離されるため、シンプルなクラス名を付けることができます。 src/script/components/App.scss .title { background: red; } ここでは、app-title というクラス名から app プレフィックスを省略して、title というシンプルなクラス名に変更してみました。 モジュール化されたスタイシートは、.tsx ファイルから次のように使用します。 src/script/components/App.tsx import * as React from \u0026#39;react\u0026#39;; import styles from \u0026#39;./App.scss\u0026#39;; export const App: React.FC = () =\u0026gt; { return \u0026lt;h1 className={styles.title}\u0026gt;Hello React\u0026lt;/h1\u0026gt; }; おまけ： favicon の設定 エントリポイントとなる index.html の head 要素の中に、次のように favicon 設定をしておくと、Parcel によるサイトビルド時に自動的に favicon ファイルがコピーされます。 index.html（抜粋） \u0026lt;link rel=\u0026#34;icon\u0026#34; type=\u0026#34;image/png\u0026#34; href=\u0026#34;assets/img/favicon-32x32.png\u0026#34; /\u0026gt; favicon ファイルは、この index.html からの相対パスで配置します。 今回は index.html を src ディレクトリ以下に置くことにしたので、favicon ファイルを src/assets/img/favicon-32x32.png というパスで配置します。"
},
{
url: "/p/ter4eq2/",
title: "Electron で Hello World (1) 最小構成で作る",
date: "2020-06-08T00:00:00Z",
body: "Electron で Hello World (1) 最小構成で作る Electron とは Electron | Build cross-platform desktop apps with JavaScript, HTML, and CSS. Electron は GitHub が開発した、デスクトップアプリを開発するためのプラットフォームで、2020 年現在も活発な開発が続けられています。 Node.js や HTML5 技術を利用しており、 様々な OS (Windows, macOS, Linux) で動作するデスクトップアプリ を作成することができます。 フロントエンド（UI 表示部分）に Chromium (HTML/CSS) を使用し、バックエンド（OSとの連携部分）に Node.js を使用するという構成になっています。 Electron で作成されている有名なアプリケーションに Visual Studio Code や Slack などがあります。 これらのアプリケーションの完成度を見れば、大規模なアプリケーション開発にも使用できるプラットフォームだということが分かります。 Node.js さえ入っていれば、簡単にデスクトップアプリの開発を始められる ので、下記の Hello World だけでも試してみてください。 Electron で Hello World アプリを作成する package.json の作成 Electron アプリは Node.js アプリとして作成するので、プロジェクトのルートディレクトリに package.json を作成します。 npm init コマンドなどでベースとなる package.json ファイルをサクッと生成し、 $ npm init -y 次のような内容を含むように修正します。 package.json { \u0026#34;name\u0026#34;: \u0026#34;myapp\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;0.0.1\u0026#34;, \u0026#34;main\u0026#34;: \u0026#34;main.js\u0026#34;, \u0026#34;scripts\u0026#34;: { \u0026#34;start\u0026#34;: \u0026#34;electron .\u0026#34; } } main プロパティでは、パッケージングされた Electron アプリのエントリポイントを指定します。 開発中は npm start コマンドでアプリ起動することになりますが、上記のように scripts.start プロパティを指定しておくと、electron コマンド経由で main.js を起動してくれるようになります。 electron モジュールのインストール Electron のパッケージは、Node.js の npm install コマンドでインストールできます。 次のように -D (--save-dev) オプションを付けて実行することで、プロジェクトの package.json ファイルに開発用の依存情報として記録します。 $ npm install electron --save-dev メインウィンドウ用の HTML (index.html) を作成 アプリ起動時に表示するコンテンツとして、index.html ファイルを作成します。 Hello World なので、簡単な内容で構いません。 index.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Hello Electron!\u0026lt;/title\u0026gt; \u0026lt;!-- https://electronjs.org/docs/tutorial/security#csp-meta-tag --\u0026gt; \u0026lt;meta http-equiv=\u0026#34;Content-Security-Policy\u0026#34; content=\u0026#34;script-src \u0026#39;self\u0026#39; \u0026#39;unsafe-inline\u0026#39;;\u0026#34; /\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Hello Electron!\u0026lt;/h1\u0026gt; \u0026lt;ul\u0026gt; \u0026lt;li\u0026gt;Node ver: \u0026lt;script\u0026gt;document.write(process.versions.node)\u0026lt;/script\u0026gt; \u0026lt;li\u0026gt;Chrome ver: \u0026lt;script\u0026gt;document.write(process.versions.chrome)\u0026lt;/script\u0026gt; \u0026lt;li\u0026gt;Electron ver: \u0026lt;script\u0026gt;document.write(process.versions.electron)\u0026lt;/script\u0026gt;. \u0026lt;/ul\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; ここでのポイントは、 Web ページ内の JavaScript なのに、Node.js の process モジュールを使用できている というところです。 秘密は下記で説明する nodeIntegration: true という設定にあります。 エントリポイント (main.js) の作成 プログラムのエントリポイントとなる main.js では、メインウィンドウ (electron.BrowserWindow) を生成し、そこに上記の HTML ファイル (index.html) を読み込みます。 main.js const { app, BrowserWindow } = require(\u0026#39;electron\u0026#39;) function createWindow () { // 新規ウィンドウを作成する const win = new BrowserWindow({ width: 400, height: 300, webPreferences: { nodeIntegration: true // Node 機能の使用を許可 } }) // ウィンドウ内に HTML ファイルを表示 win.loadFile(\u0026#39;index.html\u0026#39;) // 起動と同時に Chrome の DevTools を開く // win.webContents.openDevTools() } // Electron の初期化が完了したらウィンドウを作成 app.whenReady().then(createWindow); 上記の例では、nodeIntegration プロパティを true にセットしていますが、これはレンダラープロセスから Node.js の機能を呼び出すことを許可するためのものです。 ここではローカルの index.html を実行するので大丈夫ですが、インターネット上のファイルを読み込む場合は XSS 攻撃を防ぐために false にしておく必要があります。 main.js ファイルの作成が終わったら、次のように Electron アプリを起動できます。 $ npm start macOS の Dock に対応する 多くの macOS アプリは、ウィンドウを閉じても Dock にアプリのアイコンが残り、そこから再度ウィンドウを表示できるという仕様になっています。 このような振る舞いを実現するには、main.js ファイルに次のようなコードを追加します。 main.js（追記） // Quit when all windows are closed. app.on(\u0026#39;window-all-closed\u0026#39;, () =\u0026gt; { // On macOS it is common for applications and their menu bar // to stay active until the user quits explicitly with Cmd + Q if (process.platform !== \u0026#39;darwin\u0026#39;) { app.quit() } }); app.on(\u0026#39;activate\u0026#39;, () =\u0026gt; { // On macOS it\u0026#39;s common to re-create a window in the app when the // dock icon is clicked and there are no other windows open. if (BrowserWindow.getAllWindows().length === 0) { createWindow() } }); 次のステップ → Electron で Hello World (2) TypeScript で開発できるようにする"
},
{
url: "/p/vxoctbs/",
title: "Azure Pipelines の使い方 (Hello World)",
date: "2020-03-25T00:00:00Z",
body: "Azure Pipelines の使い方 (Hello World) ここでは、Azure Pipelines の Hello World として、任意の GitHub リポジトリへ git push したときのビルド処理を自動化してみます。 ビルド処理は、Hello World らしく、echo Hello, world! を実行するだけにしておきます。 DevOps organization を作成する Azure Pipelines は、Azure DevOps の中の 1 サービスであり、まず最初に Azure DevOps の organization（組織）を作成する必要があります。 Azure アカウント上でまだ DevOps organization を作成していない場合は、下記 URL にアクセスすることで作成することができます。 https://dev.azure.com/ DevOps organization の構成は次のようになっており、organization 以下に複数のプロジェクトを作成することができます。 各プロジェクトには、複数の Repos（Gitリポジトリ）や Pipelines (CI/CDの仕組み) を設定することができます。 + Azure DevOps organization + Project - Repos (Gitリポジトリ） - Pipelines (CI/CDの仕組み) - Boards（かんばん、バックログ管理など） - ... + Project - Repos - Pipelines - Boards - ... DevOps organization の作成が完了すると、その organization のポータルサイトには、次のような URL でアクセスできるようになります。 https://dev.azure.com/\u0026lt;organization名\u0026gt;/ DevOps organization 内にプロジェクトを作成する 最初は DevOps organization 内に 1 つもプロジェクトが存在しないので、まずは DevOps のサイト からプロジェクトを作成してください。 サイトにアクセスすると、自動的にプロジェクトの生成を促されるはずです。 プロジェクト名を入力して、Create project ボタンを押せばすぐに作成は完了します。 ここでは、helloworld というプロジェクト名を付けてみました。 プロジェクトを作成すると、そのプロジェクトのページには、次のような URL でアクセスできるようになります。 https://dev.azure.com/\u0026lt;organization名\u0026gt;/\u0026lt;project名\u0026gt;/ プロジェクト内に Pipelines を作成する Git リポジトリの準備 Pipelines を設定するには、何らかの Git リポジトリが必要になるので、先に GitHub などに適当なリポジトリを用意してください。 既存のリポジトリでも構いませんが、Azure Pipelines と連携させるため、自分が設定権限を持っているリポジトリでなければいけません。 あるいは、DevOps プロジェクト内にある Azure Repos に新しく Git リポジトリを作成することもできます。 参考リンク Azure DevOps で無料のプライベート Git リポジトリ (Repos) を使用する Pipelines の作成 DevOps プロジェクトのサイドバーには、DevOps で使用できるサービスのアイコンが並んでいます。 Azure Pipelines を示す ロケット型のアイコン を選択すると、新しく Pipelines を作成することができます。 Create Pipelines ボタンを押したら、ダイアログに従って、次のような項目を選択していけば Pipelines の作成が完了します。 連携する Git リポジトリ（GitHub や Azure Repos 上の Git リポジトリを選ぶ） 作成する Pipelines 設定ファイルのテンプレート (azure-pipelines.yml) ☝️ ワンポイント 作成する Pipelines 設定ファイル (azure-pipelines.yml) は、複数のテンプレートの中から選択することができるのですが、Git リポジトリ内に既存プロジェクトのコードが存在する場合は、その内容に基づいてテンプレートの候補を提示してくれます。 ここでは、ほぼ空っぽのテンプレートである Starter pipeline を選択しておきます。 最後に Save and run ボタンを押すと、次のような設定ファイルが Git リポジトリにコミットされ、最初のビルドが実行されます。 azure-pipelines.yml trigger:- masterpool:vmImage:\u0026#39;ubuntu-latest\u0026#39;steps:- script:echo Hello, world!displayName:\u0026#39;Run a one-line script\u0026#39;- script:|echo Add other tasks to build, test, and deploy your project. echo See https://aka.ms/yamldisplayName:\u0026#39;Run a multi-line script\u0026#39; 上記の記述から大体想像がつくと思いますが、次のような内容の Pipelines 設定となっています。 起動トリガは master ブランチの変更とする 実行環境として Ubuntu Linux を使用する ビルド処理としてシェルスクリプトで echo コマンドを実行する Pipelines の実行結果を確認する Azure Pipelines のページを開くと、実行された Pipelines の処理結果を確認することができます。 上の図では、azure-pipelines.yml の中で次のように設定されたスクリプトが実行されていることを確認できます。 - script:echo Hello, world!displayName:\u0026#39;Run a one-line script\u0026#39; これで、Azure Pipelines の Hello World は完成です。 あとは、azure-pipelines.yml の記述を更新することで、ビルド処理をカスタマイズしていきます。"
},
{
url: "/p/ejar7k8/",
title: "逆引き Azure CLI: Azure にログインする (az login)",
date: "2020-03-17T00:00:00Z",
body: "逆引き Azure CLI: Azure にログインする (az login) az login コマンドを使って Azure にログインすると、Azure アカウントに紐づいた情報（サブスクリプション情報など）を取得できるようになります。 パラメータなしで実行してブラウザ上で認証することもできるし、コマンドラインからユーザ名とパスワードを指定することもできます。 ブラウザを起動して認証 $ az login ユーザー名をパラメータで指定 $ az login -u yourname@example.com Password: ******** ユーザー名とパスワードをパラメータで指定 $ az login -u yourname@example.com -p yourpass ログインが成功すると、az account show コマンドで、使用しているサブスクリプションの情報を確認できるようになります。 $ az account show { \u0026#34;environmentName\u0026#34;: \u0026#34;AzureCloud\u0026#34;, \u0026#34;homeTenantId\u0026#34;: \u0026#34;b431a0d2-3656-ed42-9497-c0dfd20ae040\u0026#34;, \u0026#34;id\u0026#34;: \u0026#34;343f3fd9-1f19-1d49-7b92-5f365bbc6fd6\u0026#34;, \u0026#34;isDefault\u0026#34;: true, \u0026#34;managedByTenants\u0026#34;: [], \u0026#34;name\u0026#34;: \u0026#34;従量課金\u0026#34;, \u0026#34;state\u0026#34;: \u0026#34;Enabled\u0026#34;, \u0026#34;tenantId\u0026#34;: \u0026#34;b431a0d2-3656-ed42-9497-c0dfd20ae040\u0026#34;, \u0026#34;user\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;yourname@example.com\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;user\u0026#34; } }"
},
{
url: "/p/j8mzbnx/",
title: "Unityメモ: Unity の動画を撮る (Unity Recorder)",
date: "2020-02-10T00:00:00Z",
body: "Unityメモ: Unity の動画を撮る (Unity Recorder) Unity Recorder を使用すると、Unity のゲーム画面を簡単に動画ファイル（mp4 など）にして保存することができます。 Unity Recorder のインストール Unity Recorder は Package Manager からインストールします（Unity 2018 より以前は Asset Store で配布されていましたが、Unity 2019 以降は Package Manager からインストールしたものしか動作しません）。 Package Manager は Unity のメニューから下記のように辿ると起動できます。 Window → Package Manager Unity Recorder は、Preview Package として配布されているので、まず、Package Manager の Advanced というプルダウンメニューから Show preview packages を選択してください。 図: Preview Package を表示する すると、リストに Unity Recorder が表示されるので、選択して Install ボタンを押せばインストールできます。 図: Unity Recorder のインストール Unity Recorder で動画を作成する まず Unity Recorder の設定を行い、mp4 で録画するための設定を行います。 メニューから次のように辿り、Recorder ウィンドウを開きます。 Window → General → Recorder → Recorder Window この Recorder ウィンドウは、Inspector ウィンドウの下などにドッキングしておくと使いやすいです。 Add New Recorders ボタンを押すと、どんな形式のファイルを作成するかのプルダウンメニューが表示されるので、ここでは Movie を選択します。 図: Recorder ウィンドウ すると、動画ファイルの保存先や、ファイル名などを入力するフィールドが表示されるので、好きなように設定してください。 File Name のフィールドで、ワイルドカードを使ったファイル名を設定しておくと、録画するたびに自動的に異なるファイル名を付けてくれます。 例えば、movie-\u0026lt;Take\u0026gt; としておくと、movie-001.mp4、movie-002.mp4 と連番を付けてファイルを作成してくれます。 あとは、 左上の録画開始ボタン を押すと、Unity のシーンが自動的に実行され、同時に録画も開始されます。 シーンの実行を停止すると、録画も自動的に停止されます。"
},
{
url: "/p/2snuk25/",
title: "TypeScriptの型: クラスに static プロパティを定義する",
date: "2020-02-04T00:00:00Z",
body: "TypeScriptの型: クラスに static プロパティを定義する TypeScript のクラス内に、static（静的）なプロパティを定義するには、その名の通り static キーワードを付けるだけで済みます。 下記の例では、MyClass クラスの中に DEBUG という static プロパティを定義しています。 このプロパティを参照するときは、クラス名を前に付けて、MyClass.DEBUG と記述します。 class MyClass { static DEBUG: boolean = true; hello() { if (MyClass.DEBUG) { console.log(\u0026#39;hello!\u0026#39;); } } } const obj = new MyClass(); obj.hello(); static プロパティに、さらに readonly キーワードを付加することで、読み取り専用にすることができます（TypeScript 2.0 移行）。 static readonly DEBUG: boolean = true; 参考リンク TypeScript: クラス定数を定義する (static readonly)"
},
{
url: "/p/xyzwod2/",
title: "Azure Table Strage を使ってみる (1) テーブルの作成",
date: "2020-01-28T00:00:00Z",
body: "Azure Table Strage を使ってみる (1) テーブルの作成 ストレージアカウントを作成する Table Storage や BLOB Storage などの個々のストレージ系サービスは、ストレージアカウントに紐づく形で管理されます。 まずは、ストレージアカウントを作成しておく必要があります。 Azure のストレージアカウントを作成する Table Storage にテーブルを作ってみる テーブルの作成 上記で作成したストレージアカウントを選択し、Table Service → テーブル を選択し、作成 ボタンを押すと、Table Service 上に新しいテーブルを作成することができます。 ここでは、書籍を管理するための、books テーブルを作成してみました。 エンティティの追加 テーブルができたら、そこに適当にデータを追加していきます。 Table Strorage では、テーブル内の個々のデータのことを「エンティティ」と呼びます（RDB でいうレコードです）。 ストレージアカウントのメニューにある、「Storage Explorer」を使ってエンティティを追加できます。 「エンティティの追加」ダイアログが表示されるので、ここでエンティティの情報を入力していきます。 デフォルトでは、PartitionKey と RowKey というプロパティ（RDB でいうフィールド）が定義されていますが、本の情報を入力するために、タイトル (Title) と著者 (Author) のプロパティを追加しておきます。 プロパティ名は、C# の慣例に従って、単語の先頭を大文字で始める CamelCase で定義 しておくのがよいようです（C# から使うとは限らないのですが^^;）。 最初のデータとして次のように入力してます。 PartitionKey : book RowKey : 1 Title : まくの秘密 Author : まく PartitionKey と RowKey は、Table Storage がデフォルトで用意する文字列型プロパティで、これらを組み合わせたものがテーブル内でデータを一意に特定する情報になります（RDB のプライマリキーのようなもの）。 詳しくは後述しますが、ここでは単純に book というパーティション名を付けています。 ここでは、次のように 3 つのエンティティを登録してみました。 データの登録時間を示す Timestamp というプロパティが自動的に付加されるみたいですね。 ☝️ キー情報に数字をいれるときは固定長にする 上記の例では、RowKey に 1 という数字を入れてしまっていますが、PartitionKey も RowKey も文字列データとして扱われるため、 数字であれば 0000001 のような 0-padding した固定長のデータとして格納すべき とされています（参考）。 If you are using an integer value for the key value, you should convert the integer to a fixed-width string, because they are canonically sorted. For example, you should convert the value 1 to 0000001 to ensure proper sorting. 固定長にしておかないと、ソート処理で文字ベースの比較が行われるため、100 が 50 よりも小さいとみなされてしまいます。 PartitionKey と RowKey について Table Storage のテーブル設計は、PartitionKey と RowKey にどのような値を入れるかがパフォーマンス上の重要なファクターになってきます。 PartitionKey テーブル内のエンティティが所属するパーティションを指定します。PC のストレージのパーティションと同じような概念で、データ取得時（検索時）には、内部的にこの PartitionKey の範囲で検索することになります。同一のパーティションに含まれるデータは、1回のクエリで取得することができます。 RowKey RDB のプライマリキーに相当するものです。任意の文字列を指定できますが、同一の PartitionKey の中で一意になるようにしなければいけません。Table Storage 用の検索クエリを用いると、この値の大小比較によるデータ検索を行うことができます。 Table Storage はこの 2 つを組み合わせて内部でインデックスを作成するため、Table Storage から高速にデータを取得するためには、なるべくこの 2 つの値を指定して検索できるように設計しなければいけません。 テーブルのプロパティをどのように定義するかのガイドラインは、下記の Azure Table Storage ドキュメントに記載されています。 中でも、「テーブルの設計パターン」はたくさんの事例とノウハウが記載されていて参考になります。 参考: Azure ストレージ テーブル設計のガイドライン | Microsoft Docs 参考: Azure ストレージ テーブルの設計パターン | Microsoft Docs 例えば、ログデータであれば、PartitionKey に「年月」の情報を入れておけば、月単位のログ分析が効率的に行えるようになります。 しかし、頻繁な書き込みが発生する場合は、PartitionKey が「月」の情報になっていると、同一のパーティションに書き込みが集中し、パフォーマンスが低下します（Microsoft ではこれを ホットパーティション と呼んでいます）。 そのため、別のパーティションに書き込みが分散されるように、ParitionKey に「部署名」のようなものを入れる設計が考えられます。 PartitionKey : 部署名 RowKey : 日時＋イベントID これで書き込みは部署ごとに分散されるようになるのですが、今度は、日時指定でデータ取得したいときに、複数のパーティションにまたがったデータ取得が実行されるため効率が悪くなるという問題が発生します。 というわけで、ログデータに関しては PartitionKey と RowKey をどのように設計しても一長一短があり、上記ドキュメントでは BLOB ストレージを推奨しています（なにーっ！）。 データを冗長化して持たせるという思想は、RDB でテーブルを正規化してきた人にとっては受け入れにくい考え方かもしれませんが、NoSQL の世界では一般的な考え方なので慣れるしかありません。 データありきではなく、Usage ドリブンでうまくデータを作っていくということですね。"
},
{
url: "/p/27m3brm/",
title: "TypeScriptの環境: tsconfig.json の基本",
date: "2019-10-01T00:00:00Z",
body: "TypeScriptの環境: tsconfig.json の基本 tsconfig.json があれば TypeScript プロジェクト tsconfig.json は TypeScript の設定ファイルであり、このファイルが置かれたディレクトリが TypeScript プロジェクトのルートディレクトリだとみなされます。 tsconfig.json の記述内容は空っぽ（{} の2文字）でも正しい設定ファイルであり、その場合は、すべてデフォルトの設定値で動作することになります。 TypeScript のトランスパイラである tsc コマンドを実行すると、カレントディレクトリにある tsconfig.json が読み込まれてトランスパイラの動作設定が行われます。 tsconfig.json が見つからない場合は、親ディレクトリを上りながらファイルを探します。 つまり、tsc コマンドは TypeScript のプロジェクト内であれば、どのディレクトリからでも実行できます。 変換対象とするファイルを指定する (files/include/exclude) 最も大切な設定は、TypeScript のトランスパイラがどのファイルを変換対象とみなすかの設定です。 入力ファイルの指定は、設定ファイルの最上位プロパティとして指定する files、include、exclude プロパティを使って行います。 ファイル名を 1 つずつ指定する (files) tsconfig.json { \u0026#34;files\u0026#34;: [ \u0026#34;index.ts\u0026#34;, \u0026#34;module1.ts\u0026#34;, \u0026#34;module2.ts\u0026#34; ] } files プロパティを使って、変換対象の TypeScript ファイルを 1 ファイルずつ指定することができます。 ファイル名のパターン（グロブ）で指定する (include) tsconfig.json { \u0026#34;includes\u0026#34;: [ \u0026#34;src/**/*\u0026#34; ], \u0026#34;exclude\u0026#34;: [ \u0026#34;node_modules\u0026#34;, \u0026#34;**/*.spec.ts\u0026#34; ] } include プロパティを使用すると、ファイルグロブを使って変換対象とするファイルを指定できます。 ファイルグロブは、下記のようなワイルドカードを使ってファイル名をパターン指定する仕組みです。 ** は 0 文字以上の任意の文字にマッチします（ディレクトリセパレータも含みます） * は 0 文字以上の任意の文字にマッチします（ディレクトリセパレータは含みません） ? は 1 文字の任意の文字にマッチします つまり、上記の src/**/* という表現は、src ディレクトリ以下のすべてのファイルにマッチします。 ただし、パスの末尾が * で終わっている場合、デフォルトでは TypeScript の拡張子 (.ts / .tsx / .d.ts) を持つファイルにだけマッチするようになっています。 ☝️ ワンポイント 末尾のワイルドカード * を JavaScript ファイルの拡張子 (.js /.jsx) にもマッチさせたい場合は、明示的に拡張子を指定するか、compilerOptions.allowJs オプションを true に設定します。 exclude プロパティには、include の対象外とするファイル（フォルダ）のパターンを指定します。 つまり、include のパターンに一致したファイルであっても、exclude のパターンに一致するファイルは変換対象とはみなされません。 一方で、files で指定されているファイルは必ず変換対象になることに注意してください。 exclude のパターンに一致しても除外されません。 exclude プロパティを省略すると、デフォルトで node_modules や bower_components などのディレクトリが除外対象になります（上記の例では、他のファイルパターンも指定しているので、node_modules を明示的に指定しています）。 デフォルトの振る舞い files プロパティと include プロパティのいずれも指定されなかった場合は、デフォルトでプロジェクト内のすべての TypeScript ファイルが変換対象となります。 テンポラリのつもりで作成した TypeScript ファイルも変換対象になったりしてしまうので、できれば include プロパティで src/**/* のようなディレクトリを指定することをお勧めします。 ファイル依存の解決 TypeScript コード間の依存関係も自動的に考慮されます。 例えば、A.ts がコード内で B.ts を参照している場合は、B.ts は自動的にトランスパイラによる変換対象になります。 tsconfig.json の files プロパティや include プロパティで B.ts ファイルが指定されている必要はありません。 同一ディレクトリに A.ts と A.js というファイルが存在する場合、A.ts が入力ファイル、A.js が出力ファイルとみなされます。 tsc コマンドを実行するたびに A.js の内容は上書きされます。 コンパイラオプションの設定 (compilerOptions) tsc コンパイラ自体の振る舞いは compilerOptions プロパティで指定します。 下記サイトに記述されているように、たくさんのコンパイラオプションが用意されています。 Compiler Options | Type Script オプションという名の通り、これらの設定は省略してもデフォルトの振る舞いでちゃんと動作してくれます。 少しずつオプションの意味を理解しながらカスタマイズしていけばよいでしょう。 下記は、tsc --init コマンドを実行したときに自動生成される tsconfig.json の設定内容です（実際には説明コメントがたくさん記述されています）。 tsconfig.json { \u0026#34;compilerOptions\u0026#34;: { \u0026#34;target\u0026#34;: \u0026#34;es5\u0026#34;, \u0026#34;module\u0026#34;: \u0026#34;commonjs\u0026#34;, \u0026#34;strict\u0026#34;: true, \u0026#34;esModuleInterop\u0026#34;: true } } compilerOptions.target プロパティでは、JavaScript に変換するときにどの ECMAScript バージョンに準拠したコードで出力するかを指定します。 デフォルトでは ES3 バージョンのコードで出力されますが、若干古すぎるので、ES2015 (ES6) あたりを指定しておくのがよいでしょう（ES2015 は JavaScript に正式にクラスが導入されたバージョンです）。 Web アプリであれば、どれだけ古い Web ブラウザに対応するかによって決めることになりますが、最新の Node.js 上で動かすようなサービスであれば、ES2020 などで攻めてみるのもよいでしょう。 一般的には、新しい構文を使ったコードの方が効率的に動作すると考えられます。 他にも、JavaScript コードを入力ファイルとみなす allowJs オプションや、出力先のディレクトリを設定する outDir などがあります。 これらは、既存の JavaScript プロジェクトに TypeScript を適用する際に便利なオプションです。 このあたりは、下記の記事で詳しく紹介します。 参考リンク 既存の JavaScript プロジェクトを TypeScript に乗り換える"
},
{
url: "/p/cd9bg3x/",
title: "Azure Cosmos DB にアカウントを作って MongoDB API でアクセスする",
date: "2019-05-21T00:00:00Z",
body: "Azure Cosmos DB にアカウントを作って MongoDB API でアクセスする Azure Cosmos DB と MongoDB API Azure Cosmos DB は、Microsoft の Azure 上に配置できるスケーラブルなデータベースで、SQL や MongoDB API など様々なインタフェースでアクセスできるようになっています。 MongoDB を使った既存のアプリケーションがある場合、接続先を Azure Cosmos DB アカウントのアドレスに変更するだけで、簡単にクラウド上のデータを扱えるようになります。 ローカルの MongoDB サーバ (mongod) に接続する代わりに、Azure Cosmos DB に接続するということです。 ここでは、MongoDB API（MongoDB シェル）による Azure Cosmos DB へのアクセスを試してみます。 まずは、Azure 上に Cosmos DB のリソースを作成します。 Azure Cosmos DB アカウントを作成する Azure ポータルへログインし、Azure Cosmos DB のページを開き、Azure Cosmos DB アカウントの作成 をクリックします。 次の画面では、アカウント名 や API の種類を設定します。 アカウント名 に入力した値は、下記のように接続 URI の一部として使われます。 よって、このアカウント名は世界中で一意である必要があります。 mongodb://＜アカウント名＞:＜キー＞@＜アカウント名＞.documents.azure.com:10255/?ssl=true\u0026amp;replicaSet=globaldb API の種類には、MongoDB API を指定してください。 各項目の入力が終わったら、確認と作成 を押して数分待つと、Azure Cosmos DB アカウントの作成が完了します。 MongoDB シェル (mongo) を使って Cosmos DB へ接続する MongoDB クライアントから Azure Cosmos DB へ接続するには、接続用の URL が必要です。 Azure ポータルから Azure Cosmos DB のリソースを開き、接続文字列 のページを開くと接続文字列を確認することができます。 この URL をコピーして、mongo コマンドのパラメータとして渡せば、Azure Cosmos DB に接続できます。 MongoDB シェルから Cosmos DB へ接続 $ mongo mongodb://my-cosmos-db:ABC(キーは長いので省略)==@my-cosmos-db.documents.azure.com:10255/?ssl=true MongoDB shell version v4.0.9 connecting to: mongodb://my-cosmos-db.documents.azure.com:10255/?gssapiServiceName=mongodb\u0026amp;ssl=true WARNING: No implicit session: Logical Sessions are only supported on server versions 3.6 and greater. Implicit session: dummy session MongoDB server version: 3.2.0 WARNING: shell and server versions do not match globaldb:PRIMARY\u0026gt; あとは、普通に mongo シェルでデータベースの操作を行うだけです。 globaldb:PRIMARY\u0026gt; use mydb switched to db mydb globaldb:PRIMARY\u0026gt; exit bye"
},
{
url: "/p/m7ju6fq/",
title: "Ansible とは？ Ansible をインストールする",
date: "2016-10-22T00:00:00Z",
body: "Ansible とは？ Ansible をインストールする Ansible とは？ Ansible は、2012 年に Michael DeHaan 氏によって公開されたコンフィギュレーションツールです。 Ansible を実行するホスト自身の構成を行うこともできるし、複数のホストに対して一括して設定することもできます。 Chef や Puppet に比べて、導入や設定が容易という特徴があります。 同様のツール Puppet \u0026hellip; 2005 年に Luke Kanies 氏が公開。Ruby 製。構成管理情報は「マニフェスト」と呼ぶ。 Chef \u0026hellip; 2009 年に Adam Jacob 氏が公開。Ruby + Erlang 製。構成管理情報は「クックブック」と呼ぶ。 Ansible \u0026hellip; 2012 年に Michael DeHaan 氏が公開。Python 製。構成管理情報は「Playbook」と呼ぶ。 Ansible の特徴 ツール自体は Python で記述されています。 コントロールされる側のホストには、Python と SSH さえ入っていればよく、導入が非常に容易です（コントロールする側のホストから、SSH で Python スクリプトを流し込んで実行するという手法）。 複数のホストをプッシュ型でコントロールするので、大量のホスト（数千）の制御も問題なく行えます（複数のホストで並列にコンフィギュレーションが実行される）。ansible-pull というツールを導入すれば、プル型で動作させることも可能です（リモートホストがプロキシ環境内にある場合など）。 設定・構成情報は YAML 形式のテキストファイル (Playbook) で記述します。 Playbook で定義する各種処理（タスク）はモジュールによって提供されており、モジュール自身は様々な言語で実装することが可能 です（200 を超える組み込みモジュールは Python で記述されています）。 実行後の状態に関して冪等性（べきとうせい）が保証されており、何度実行しても同じ状態になるようになっています。Playbook には、「期待する状態」を「宣言的」に記載します。処理手順ではなく、目指すべき姿を定義するということです。 どのような環境でも実行可能な汎用的な Playbook を記述するというよりは、自分たちの組織用にカスタマイズされた Playbook を作成するという用途に向いています。たとえば、apt と yum のどっちのパッケージ管理ツールが使えるのかなどは意識して記述する必要があります。 Ansible のインストール Ansible のコントロールノードとなるマシンには、ansible コマンドをインストールする必要があります。 必要条件は、Linux 系の OS（macOS でも OK）であり、Python 3.8 以上がインストールされていることです。 内部で fork などを使用する都合上、Windows への ansible コマンドのインストールはサポートされていません（WSL を使って動かすことはできます）。 Ansible 2.10 からは、以下の 2 種類のパッケージが提供されており、いずれも Python の pip コマンドや、OS ごとのパッケージ管理コマンドでインストールできます。 ansible（コミュニティパッケージ） 従来の ansible に相当するもので、いくつかの基本的なモジュールがバンドルされています。 ansible-core 最小限の構成のパッケージで、必要なモジュールは適宜 Ansible Galaxy などからインストールする必要があります。 慣れないうちは、前者のコミュニティパッケージの方を使った方がトラブルが少ないと思います。 詳細なインストール方法は 公式マニュアル に記載がありますが、基本的には pip コマンドでインストールしてしまえば OK です。 pip でインストールする方法（全 OS 共通） Ansible は Python 製のツールなので、Python のパッケージマネージャである pip でインストールできます。 $ python3 -m pip install --user ansible グローバルにインストールしたい場合は、上記のコマンドから --user オプションを外して、sudo を付けて実行します。 ただし、システム全体に影響してしまうので、--user オプションでのインストールが推奨されています。 最後に、インストールがうまくいったか確認しましょう。 $ ansible --version ansible [core 2.12.2] config file = None configured module search path = [\u0026#39;...\u0026#39;] ... もし、ansible: command not found というエラーになったら、次のようにして ansible がインストールされたディレクトリを検索して、PATH 環境変数に設定します（参考: pip - Installing to the User Site）。 $ python3 -m site --user-base /Users/maku/Library/Python/3.10 ←たぶんこの下の bin ディレクトリにある $ ~/Library/Python/3.10/bin/ansible --version ansible [core 2.12.2] ... ~/.bash_profile（下記を追加） export PATH=$PATH:$HOME/Library/Python/3.10/bin 各種 Linux 系パッケージマネージャでインストールする方法 Fedora の場合 $ sudo dnf install ansible RHEL の場合 $ sudo yum install ansible CentOS の場合 $ sudo yum install epel-release $ sudo yum install ansible yum の拡張リポジトリ (EPEL: Extra Package for Enterprise Linux) から Ansible をインストールするために、最初に epel-release をインストールする必要があります。 Ubuntu の場合 $ sudo apt update $ sudo apt install software-properties-common $ sudo add-apt-repository --yes --update ppa:ansible/ansible $ sudo apt install ansible 拡張リポジトリ (PPA: Personal Package Archive) を登録して情報更新してから install を実行する必要があります。"
},
{
url: "/p/cfnkkhk/",
title: "Jadeメモ: jade コマンドをインストールする",
date: "2013-12-28T00:00:00Z",
body: "Jadeメモ: jade コマンドをインストールする Jade は Node.js 製のテンプレートエンジンです。 HTML ファイルを直接記述するよりも簡潔なフォーマットで Web ページを作成することができます。 jade コマンドは Node Package Manager (npm) を使ってインストールすることができます。 下記のようにグローバルインストールすれば、どのディレクトリからでも jade コマンドを実行できるようになります。 Jade のインストール $ sudo npm install jade --global 参考サイト http://jade-lang.com/ http://jade-lang.com/reference/"
},
{
url: "/p/je8stcd/",
title: "gnuplot: gnuplot の基本設定",
date: "2002-08-28T00:00:00Z",
body: "gnuplot: gnuplot の基本設定 初期化ファイル (~/.gnuplot or gnuplot.ini) 初期化ファイルは gnuplot を起動した時に、自動的に読み込まれるファイルです。 Unix の場合は ~/.gnuplot、Windows の場合は gnuplot.ini が読み込まれます。 gnuplot.ini は次に説明する「作業フォルダ」内に置きます。 例えば、作業フォルダを D:\\home\\gnuplot とした場合は、よく使う関数を D:\\home\\gnuplot\\lib\\func.gp などに書いておいて、gnuplot.ini で次のように起動時に読み込むようにしておくと便利です。 gnuplot.ini load \u0026#39;lib/func.gp\u0026#39; gnuplot のホームディレクトリの設定 gnuplot を起動した時にカレントとなるディレクトリを指定しておくと便利です。 デフォルトでは、gnuplot の実行ファイルのあるディレクトリがカレントディレクトリになっているので、出力したファイルがそのディレクトリにできてしまいます。 起動時のカレントディレクトリを変更するには次のようにします。 gnuplot.ini (~/.gnuplot) cd \u0026#39;D:\\home\\gnuplot\u0026#39; 初期化ファイルの中で、ディレクトリを移動しているだけです。 あるいは、Windows では wgnuplot.exe のショートカットを作成して、そのプロパティの作業フォルダで指定する方法もあります。 wgnuplot.exe のショートカット右クリック → プロパティ ショートカット タブの 作業フォルダ に D:\\home\\gnuplot などを設定 上のように設定してショートカットをダブルクリックすると、好きなディレクトリで作業を始められます。 この方法を使うと、ショートカットごとに作業ディレクトリを変更することができます。"
},
{
url: "/p/uhu7hs4/",
title: "Ansible で Hello World",
date: "2022-02-17T00:00:00Z",
body: "Ansible で Hello World インベントリーファイルを作る Ansible で制御したいホストは、インベントリーファイル (inventory file) に列挙しておく必要があります。 これは、想定外のホストを操作してしまうのを防ぐための安全策です。 デフォルトでは、インベントーリファイルとして /etc/ansible/hosts というファイルが読み込まれます。 コマンドラインオプション (-i) などで、読み込むファイルを指定する こともできます。 /etc/ansible/hosts（記述例） localhost 192.168.1.20 host.example.com インベントリーファイル内では、上記のように「ホスト名」や「IP アドレス」で制御対象のホスト (managed node) を列挙します。 ここでは、3 つのホストを Ansible のコマンド（ansible や ansible-playbook）で制御できるようにしています。 localhost 以外のホストは、SSH で接続できる状態になっている必要があります。 ansible コマンドで ping モジュールを実行してみる インベントリーファイルを用意したら、まずは制御対象のホストに ping を実行してみます。 ping は Ansible の組み込みモジュールとして提供されており、ターゲットホストへの接続確認のために使われます。 いわゆる Linux の ping コマンド (ICMP ping) ではないことに注意してください。 ローカルホストを制御する まずは、localhost に対して（自分自身を制御対象として）、ping を実行してみます。 制御対象とするホスト名は、ansible コマンドの第 1 パラメータで指定します。 次のように SUCCESS 表示が出れば成功です。 例: localhost に対して ping を実行 $ ansible localhost -c local -m ping localhost | SUCCESS =\u0026gt; { \u0026#34;changed\u0026#34;: false, \u0026#34;ping\u0026#34;: \u0026#34;pong\u0026#34; } Ansible はデフォルトで SSH 接続しようとするので、ローカルホストを制御対象とするときは -c local オプションを指定します。 -m ping オプションは、ping モジュールを使用してタスクを実行することを示しています。 イベントリーファイルで、ホスト変数として ansible_connection=local を指定しておくと、ansible コマンド実行時の -c local の指定を省略できます。 /etc/ansible/hosts（接続方式をホスト変数で指定） localhost ansible_connection=local 192.168.1.20 インベントリーファイルに定義されていないホスト名を指定すると、ansible コマンドは次のような警告メッセージを出力して終了します。 例: インベントリーに登録されていないホストを指定した場合 $ ansible unknown-host -m ping [WARNING]: Could not match supplied host pattern, ignoring: unknown-host [WARNING]: No hosts matched, nothing to do SSH 経由で制御する 次に、SSH で接続可能なターゲットホストに対して ping モジュールを実行してみます。 あらかじめターゲットホストには SSH 鍵による接続ができることを確認しておいてください。 参考: ssh-id-copy で SSH の公開鍵をリモートホストに登録する パスワード認証でも Ansible による制御は可能ですが、追加で sshpass パッケージをインストールするなどの対応が必要になります。 SSH 鍵による公開鍵認証方式で接続できるようになっていれば、次のように ansible コマンドで制御できるはずです。 SSH での接続ユーザー名は maku だと仮定しています。 例: SSH 接続で ping を実行 $ ansible 192.168.1.20 -u maku -m ping Enter passphrase for key \u0026#39;/Users/maku/.ssh/id_rsa\u0026#39;: （SSH鍵のパスワードを入力） 192.168.1.20 | SUCCESS =\u0026gt; { \u0026#34;changed\u0026#34;: false, \u0026#34;ping\u0026#34;: \u0026#34;pong\u0026#34; } 上の例では、接続ユーザー名を -u オプションで指定していますが、インベントリーファイルの中で次のようにユーザー名を設定しておくこともできます。 /etc/ansible/hosts localhost ansible_connection=local 192.168.1.20 ansible_ssh_user=maku これらのホスト変数設定により、ansible コマンド実行時にはほとんどのオプションを省略できます。 $ ansible localhost -m ping $ ansible 192.168.1.20 -m ping すべてのターゲットホストをまとめて制御する ansible コマンドの第 1 引数（ターゲット名）として all を指定すると、インベントリーファイルに記述したすべてのターゲットホストを一度に制御することができます。 $ ansible all -m ping localhost | SUCCESS =\u0026gt; { \u0026#34;changed\u0026#34;: false, \u0026#34;ping\u0026#34;: \u0026#34;pong\u0026#34; } Enter passphrase for key \u0026#39;/Users/maku/.ssh/id_rsa\u0026#39;: （SSH鍵のパスワードを入力） 192.168.1.20 | SUCCESS =\u0026gt; { \u0026#34;changed\u0026#34;: false, \u0026#34;ping\u0026#34;: \u0026#34;pong\u0026#34; } 接続方法 (local or ssh) や接続ユーザー名は、インベントリーファイルなどで指定しておく必要があります。 /etc/ansible/hosts localhost ansible_connection=local 192.168.1.20 ansible_ssh_user=maku おまけ: ping モジュールのヘルプを確認する ansible-doc コマンドを使うと、Ansible モジュールのドキュメントを表示することができます。 $ ansible-doc ping \u0026gt; ANSIBLE.BUILTIN.PING (/Users/maku/Library/Python/3.10/lib/python/site-packages/ansible/modules/ping.py) A trivial test module, this module always returns `pong\u0026#39; on successful contact. It does not make sense in playbooks, but it is useful from `/usr/bin/ansible\u0026#39; to verify the ability to login and that a usable Python is configured. This is NOT ICMP ping, this is just a trivial test module that requires Python on the remote-node. For Windows targets, use the [ansible.windows.win_ping] module instead. For Network targets, use the [ansible.netcommon.net_ping] module instead. ...（省略）... 例えば、上記のように ping モジュールの説明を読むと、data というオプションを指定できることがわかります。 次のように data オプションを付けて ping モジュールを実行すると、指定した値がターゲットホストからそのまま返ってきます。 モジュールのオプションは -a に続けて入力します。 $ ansible localhost -m ping -a data=Hello localhost | SUCCESS =\u0026gt; { \u0026#34;changed\u0026#34;: false, \u0026#34;ping\u0026#34;: \u0026#34;Hello\u0026#34; } トラブルシューティング: Python interpreter の警告が出る場合 Ansible のバージョンによっては、ansible コマンドの実行時に次のような警告が出ることがあります。 [WARNING]: Platform darwin on host localhost is using the discovered Python interpreter at /Library/Frameworks/Python.framework/Versions/3.10/bin/python3.10, but future installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-core/2.12/reference_appendices/interpreter_discovery.html for more information. これは、ターゲットホスト上の Python 実行環境としてどれを使えばよいか判別できないということを示しています。 Ansible の設定ファイル に次のような感じで Python の実行ファイルパスを指定すれば警告は消えます。 ansible.cfg [defaults] interpreter_python = /usr/bin/python3 # 次のようにパスを自動解決させることもできます # interpreter_python = auto_silent"
},
{
url: "/p/8t7iu6g/",
title: "DynamoDB を Node.js で操作する（SDK ver.2 の場合）",
date: "2021-05-01T00:00:00Z",
body: "DynamoDB を Node.js で操作する（SDK ver.2 の場合） ここでは、Node.js 用の AWS SDK ver.2 を使って Amazon DynamoDB を操作する方法を説明します。 TypeScript の基本的な環境構築 は終わっているものとします。 SDK ver.3 を使う方法はこちらの記事 を参照してください。 基本的には ver.3 の使用が推奨されていますが、AWS の Lambda 実行環境は現時点（2021年5月）でも ver.2 がインストールされていたりするので、ver.2 の需要はまだあると思います。 Dynamo DB 用の SDK (ver.2) をインストールする AWS SDK version 2 で DynamoDB を扱うには、次のように AWS SDK パッケージ全体をインストールする必要があります（version 3 では DynamoDB サービスなどのパッケージを個別にインストールできます）。 $ npm install aws-sdk --save これで、TypeScript コードから次のように SDK モジュールをインポートできるようになります。 import * as AWS from \u0026#39;aws-sdk\u0026#39;; AWS.DynamoDB だけ参照したければ、次のようにインポートできます。 import { DynamoDB } from \u0026#39;aws-sdk\u0026#39;; DynamoDB インスタンスの生成 基本 DynamoDB の API を呼び出すには、まずは AWS.DynamoDB インスタンスを生成する必要があります。 import * as AWS from \u0026#39;aws-sdk\u0026#39;; const dynamoDb = new AWS.DynamoDB(); 接続設定 (config) DynamoDB コンストランクタ の引数でオプションオブジェクトを渡すと、接続先のリージョンやエンドポイントを設定することができます。 例えば、エンドポイントを http://localhost:8000 に設定すれば、DynamoDB Local によるテスト用サーバに接続できます。 import * as AWS from \u0026#39;aws-sdk\u0026#39;; const dynamoDb = new AWS.DynamoDB({ apiVersion: \u0026#39;2012-08-10\u0026#39;, region: \u0026#39;ap-northeast-1\u0026#39;, endpoint: \u0026#39;http://localhost:8000\u0026#39;, accessKeyId: \u0026#39;fakeMyKeyId\u0026#39;, secretAccessKey: \u0026#39;fakeSecretAccessKey\u0026#39;, }); 認証情報ファイルなど で実行ユーザーに適切な接続情報が設定されていれば、上記のようにコード内で接続設定する必要はありませんが、少なくとも apiVersion は明示しておくとが推奨されています。 環境変数（AWS_REGION、AWS_ACCESS_KEY_ID、AWS_SECRET_ACCESS_KEY など）で接続情報を設定することもできます。 接続情報の優先順位は次の通りです。 プログラム内での設定（ローカル設定 ＞ グローバル設定） 環境変数での設定 (AWS_REGION, AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_SESSION_TOKEN) 認証情報ファイルでの設定 (~/.aws/credentials, ~/.aws/config) SDK 全体のグローバル設定を変更する場合は、AWS.config.update メソッドに AWS.Config オブジェクトを渡します。 このグローバル設定は、これ以降に生成されるクライアントオブジェクトのデフォルト設定として使用されます。 AWS.config.update({ region: \u0026#39;ap-northeast-1\u0026#39;, accessKeyId: \u0026#39;fakeMyKeyId\u0026#39;, secretAccessKey: \u0026#39;fakeSecretAccessKey\u0026#39;, dynamodb: { apiVersion: \u0026#39;2012-08-10\u0026#39;, endpoint: \u0026#39;http://localhost:8000\u0026#39; } }); プロキシ設定 社内のプロキシ環境などから接続するときは、AWS.Config の httpOptions プロパティを使用します。 proxy-agent のインストール $ npm install proxy-agent --save import * as AWS from \u0026#39;aws-sdk\u0026#39;; import * as proxy from \u0026#39;proxy-agent\u0026#39;; AWS.config.update({ httpOptions: { agent: proxy(\u0026#39;http://internal.proxy.com\u0026#39;) } }); DynamoDB.DocumentClient インスタンス AWS.DynamoDB インスタンスの代わりに、AWS.DynamoDB.DocumentClient インスタンスを使うと、もう少し抽象度の高い API で CRUD 系操作を行えるようです。 用途によってはこちらを使った方が楽かもしれませんが、createTable などテーブル自体の操作はできません。 Class: AWS.DynamoDB.DocumentClient — AWS SDK for JavaScript インスタンスの作成方法は AWS.DynamoDB と同様です。 import * as AWS from \u0026#39;aws-sdk\u0026#39;; const dynamoDb = new AWS.DynamoDB.DocumentClient(option); テーブルを作成する (createTable) import * as AWS from \u0026#39;aws-sdk\u0026#39;; const dynamoDb = new AWS.DynamoDB({ apiVersion: \u0026#39;2012-08-10\u0026#39;, region: \u0026#39;ap-northeast-1\u0026#39; }); async function createTable() { // 作成するテーブルの情報 const params: AWS.DynamoDB.CreateTableInput = { TableName: \u0026#39;Games\u0026#39;, // テーブル名 BillingMode: \u0026#39;PAY_PER_REQUEST\u0026#39;, // 課金方法 KeySchema: [ { AttributeName: \u0026#39;Hardware\u0026#39;, KeyType: \u0026#39;HASH\u0026#39; }, // パーティションキー { AttributeName: \u0026#39;GameId\u0026#39;, KeyType: \u0026#39;RANGE\u0026#39; }, // ソートキー ], AttributeDefinitions: [ { AttributeName: \u0026#39;Hardware\u0026#39;, AttributeType: \u0026#39;S\u0026#39; }, // 文字列属性 { AttributeName: \u0026#39;GameId\u0026#39;, AttributeType: \u0026#39;S\u0026#39; }, // 文字列属性 ], StreamSpecification: { StreamEnabled: false, }, }; try { const result = await dynamoDb.createTable(params).promise(); // テーブルの作成に成功したら、ARN 情報を取得してみる console.log(result.TableDescription?.TableArn); } catch (err) { console.error(err); } } 実行結果 arn:aws:dynamodb:ap-northeast-1:123456789012:table/Games 参考: DynamoDB.createTable テーブルを削除する (deleteTable) async function deleteTable() { const params: AWS.DynamoDB.DeleteTableInput = { TableName: \u0026#39;Games\u0026#39; // 削除するテーブルの名前 }; try { const result = await dynamoDb.deleteTable(params) .promise(); console.log(result.TableDescription?.TableArn) } catch (err) { console.error(err); } } deleteTable(); 実行結果 arn:aws:dynamodb:ap-northeast-1:123456789012:table/Games 参考: DynamoDB.deleteTable テーブルの一覧を取得する (listTables) async function listTables() { const params: AWS.DynamoDB.ListTablesInput = { Limit: 10 // 一度に取得するテーブル数 } try { const result = await dynamoDb.listTables(params).promise(); console.log(result.TableNames?.join(\u0026#39;\\n\u0026#39;)); } catch (err) { console.error(err); } } listTables(); 参考: DynamoDB.listTables テーブルの詳細情報を取得する (describeTable) 指定したテーブルのスキーマ情報などを取得できます。 async function describeTable() { const params: AWS.DynamoDB.DescribeTableInput = { TableName: \u0026#39;Games\u0026#39; }; try { const result = await dynamoDb.describeTable(params).promise(); console.log(result.Table?.KeySchema); } catch (err) { console.error(err); } } describeTable(); 実行結果 [ { AttributeName: \u0026#39;Hardware\u0026#39;, KeyType: \u0026#39;HASH\u0026#39; }, { AttributeName: \u0026#39;GameId\u0026#39;, KeyType: \u0026#39;RANGE\u0026#39; } ] 参考: DynamoDB.describeTable アイテムを追加する (putItem) DynamoDB を使う場合 putItem メソッドでテーブルに要素を追加するときは、少なくともプライマリキー属性（パーティションキー、およびソートキー）の指定が必要です（Games テーブルの例では Hardware と GameId）。 すでに同じキーの要素が存在する場合、デフォルトでは新しい値で上書きされます。 ReturnValues プロパティに ALL_OLD を指定しておくと、もともと格納されていた値を戻り値として取得できます。 async function putItem() { // 追加先のテーブル名や、追加するアイテムを指定 const params: AWS.DynamoDB.PutItemInput = { TableName: \u0026#39;Games\u0026#39;, Item: { Hardware: { S: \u0026#39;SFC\u0026#39; }, GameId: { S: \u0026#39;1990-SuperMarioWorld\u0026#39; }, Title: { S: \u0026#39;Super Mario World\u0026#39; }, Players: { N: \u0026#39;2\u0026#39; }, Genre: { S: \u0026#39;ACT\u0026#39; }, }, ReturnValues: \u0026#39;ALL_OLD\u0026#39; // 同じプライマリキーの値があったら、過去の値を返す }; try { const result = await dynamoDb.putItem(params).promise(); console.log(result); } catch (err) { console.error(err); } } putItem(); 実行結果（2回目以降の実行時） { Attributes: { Title: { S: \u0026#39;Super Mario World\u0026#39; }, Genre: { S: \u0026#39;ACT\u0026#39; }, GameId: { S: \u0026#39;1990-SuperMarioWorld\u0026#39; }, Hardware: { S: \u0026#39;SFC\u0026#39; }, Players: { N: \u0026#39;2\u0026#39; } } } putItem メソッドはデフォルトではアイテムの内容を上書きしますが、この振る舞いを抑制したいときは、コマンドのパラメータに次のように ConditionExpression を指定します。 このようにすると、プライマリキーが一致するアイテムがすでに存在する場合に、ConditionalCheckFailedException 例外が発生するようになります。 async function putItem() { const params: AWS.DynamoDB.PutItemInput = { TableName: \u0026#39;Games\u0026#39;, Item: { Hardware: { S: \u0026#39;SFC\u0026#39; }, GameId: { S: \u0026#39;1990-SuperMarioWorld\u0026#39; }, Title: { S: \u0026#39;Super Mario World\u0026#39; }, Players: { N: \u0026#39;2\u0026#39; }, Genre: { S: \u0026#39;ACT\u0026#39; }, }, ConditionExpression: \u0026#39;attribute_not_exists(Hardware)\u0026#39; }; // ... } 参考: DynamoDB.putItem DynamoDB.DocumentClient を使う場合 DocumentClient インスタンスを使用すると、属性値の指定が若干シンプルになります（S や N などのタイプ指定が必要なくなります）。 それ以外は同じです。 import * as AWS from \u0026#39;aws-sdk\u0026#39;; const documentClient = new AWS.DynamoDB.DocumentClient({ apiVersion: \u0026#39;2012-08-10\u0026#39;, region: \u0026#39;ap-northeast-1\u0026#39; }); async function documentClient_put() { const params: AWS.DynamoDB.DocumentClient.PutItemInput = { TableName: \u0026#39;Games\u0026#39;, Item: { Hardware: \u0026#39;SFC\u0026#39;, GameId: \u0026#39;1990-SuperMarioWorld\u0026#39;, Title: \u0026#39;Super Mario World\u0026#39;, Players: 2, Genre: \u0026#39;ACT\u0026#39;, }, ReturnValues: \u0026#39;ALL_OLD\u0026#39; // 同じプライマリキーの値があったら、過去の値を返す }; try { const result = await documentClient.put(params).promise(); console.log(result); } catch (err) { console.error(err); } } documentClient_put(); 実行結果の形式も少しだけシンプルになります。 実行結果（2回目以降の実行時） { Attributes: { Title: \u0026#39;Super Mario World\u0026#39;, Genre: \u0026#39;ACT\u0026#39;, GameId: \u0026#39;1990-SuperMarioWorld\u0026#39;, Hardware: \u0026#39;SFC\u0026#39;, Players: 2 } } 参考: DynamoDB.DocumentClient.put アイテムの属性値を部分的に更新する (updateItem) DynamoDB を使う場合 putItem に似たメソッドに updateItem があります。 putItem はプライマリーキー属性が一致するアイテムがあると、その内容を完全に置き換えますが、updateItem の場合は、指定した属性の値のみを更新 します（まだ存在しない属性を指定すると追加されます）。 プライマリーキー属性に一致するアイテムが見つからない場合に、新しいアイテムを追加するのは putItem も updateItem も同様です。 属性値の更新内容は、SQL のプレースホルダーを使った構文のような感じで指定する必要があります。 DynamoDB の API は複雑すぎるとは聞いていましたが、確かにこの API 仕様はクレイジーですね・・・（AWS SDK が低レベルすぎるだけかもしれませんが）。 次の例では、既存のアイテムの Title 属性の値を更新し、さらに新しい属性 Maker を追加しています。 新しい属性名は #xxx、新しい属性値は :xxx といった形のプレースホルダーで指定する必要があります。 async function updateItem() { const params: AWS.DynamoDB.UpdateItemInput = { TableName: \u0026#39;Games\u0026#39;, // 更新するアイテムを特定するプライマリーキー属性 Key: { Hardware: { S: \u0026#39;SFC\u0026#39; }, GameId: { S: \u0026#39;1990-SuperMarioWorld\u0026#39; } }, // 属性値の更新方法を下記 3 プロパティで設定 UpdateExpression: \u0026#39;set Title = :x, #a = :y\u0026#39;, ExpressionAttributeNames: { \u0026#39;#a\u0026#39;: \u0026#39;Maker\u0026#39;, }, ExpressionAttributeValues: { \u0026#39;:x\u0026#39;: { S: \u0026#39;Mario 4\u0026#39; }, \u0026#39;:y\u0026#39;: { S: \u0026#39;Nintendo\u0026#39; } }, // 更新後の内容を戻り値で知りたいとき（ALL_OLD なら更新前の値が返される） ReturnValues: \u0026#39;ALL_NEW\u0026#39;, }; try { const result = await dynamoDb.updateItem(params).promise(); console.log(result); } catch (err) { console.error(err); } } updateItem(); 実行結果 { Attributes: { Title: { S: \u0026#39;Mario 4\u0026#39; }, Maker: { S: \u0026#39;Nintendo\u0026#39; }, GameId: { S: \u0026#39;1990-SuperMarioWorld\u0026#39; }, Hardware: { S: \u0026#39;SFC\u0026#39; }, Players: { N: \u0026#39;2\u0026#39; } } } 参考: DynamoDB.updateItem DynamoDB.DocumentClient を使う場合 DocumentClient インスタンスを使用すると、属性値の指定が若干シンプルになります（S や N などのタイプ指定が必要なくなります）。 それ以外は同じです。 import * as AWS from \u0026#39;aws-sdk\u0026#39;; const documentClient = new AWS.DynamoDB.DocumentClient({ apiVersion: \u0026#39;2012-08-10\u0026#39;, region: \u0026#39;ap-northeast-1\u0026#39; }); async function documentClient_update() { const params: AWS.DynamoDB.DocumentClient.UpdateItemInput = { TableName: \u0026#39;Games\u0026#39;, Key: { Hardware: \u0026#39;SFC\u0026#39;, GameId: \u0026#39;1990-SuperMarioWorld\u0026#39; }, UpdateExpression: \u0026#39;set Title = :x, #a = :y\u0026#39;, ExpressionAttributeNames: { \u0026#39;#a\u0026#39;: \u0026#39;Maker\u0026#39; }, ExpressionAttributeValues: { \u0026#39;:x\u0026#39;: \u0026#39;Mario 4\u0026#39;, \u0026#39;:y\u0026#39;: \u0026#39;Nintendo\u0026#39; }, ReturnValues: \u0026#39;ALL_NEW\u0026#39;, }; try { const result = await documentClient.update(params).promise(); console.log(result); } catch (err) { console.error(err); } } documentClient_update(); 実行結果の形式も少しだけシンプルになります。 実行結果 { Attributes: { Title: \u0026#39;Mario 4\u0026#39;, Maker: \u0026#39;Nintendo\u0026#39;, GameId: \u0026#39;1990-SuperMarioWorld\u0026#39;, Genre: \u0026#39;ACT\u0026#39;, Hardware: \u0026#39;SFC\u0026#39;, Players: 2 } } 参考: DynamoDB.DocumentClient.update アイテムを取得する (getItem) DynamoDB を使う場合 アイテムを 1 つ取得するときは、テーブル名 (Table) と、アイテムを特定するためのプライマリーキー (Key) を指定します。 複合プライマリキーを使用している場合は、パーティションキーとソートキーの両方を指定する必要があります（ValidationException が発生します）。 async function getItem() { const params: AWS.DynamoDB.GetItemInput = { TableName: \u0026#39;Games\u0026#39;, Key: { Hardware: { S: \u0026#39;SFC\u0026#39; }, GameId: { S: \u0026#39;1990-SuperMarioWorld\u0026#39; } } }; try { const result = await dynamoDb.getItem(params).promise(); console.log(result); } catch (err) { console.error(err); } } 実行結果 { Item: { Title: { S: \u0026#39;Super Mario World\u0026#39; }, GameId: { S: \u0026#39;1990-SuperMarioWorld\u0026#39; }, Hardware: { S: \u0026#39;SFC\u0026#39; }, Players: { N: \u0026#39;2\u0026#39; } } } 参考: DynamoDB.getItem DynamoDB.DocumentClient を使う場合 DocumentClient インスタンスを使用すると、プライマリーキーの指定が若干シンプルになります（S や N などのタイプ指定が必要なくなります）。 それ以外は同じです。 import * as AWS from \u0026#39;aws-sdk\u0026#39;; const documentClient = new AWS.DynamoDB.DocumentClient({ apiVersion: \u0026#39;2012-08-10\u0026#39;, region: \u0026#39;ap-northeast-1\u0026#39; }); async function documentClient_get() { const params: AWS.DynamoDB.DocumentClient.GetItemInput = { TableName: \u0026#39;Games\u0026#39;, Key: { Hardware: \u0026#39;SFC\u0026#39;, GameId: \u0026#39;1990-SuperMarioWorld\u0026#39; } }; try { const result = await documentClient.get(params).promise(); console.log(result); } catch (err) { console.error(err); } } documentClient_get(); 実行結果の形式も少しだけシンプルになります。 実行結果 { Item: { Title: \u0026#39;Super Mario World\u0026#39;, Genre: \u0026#39;ACT\u0026#39;, GameId: \u0026#39;1990-SuperMarioWorld\u0026#39;, Hardware: \u0026#39;SFC\u0026#39;, Players: 2 } } 参考: DynamoDB.DocumentClient.get アイテムを削除する (deleteItem) DynamoDB を使う場合 async function deleteItem() { const params: AWS.DynamoDB.DeleteItemInput = { TableName: \u0026#39;Games\u0026#39;, Key: { Hardware: { S: \u0026#39;SFC\u0026#39; }, GameId: { S: \u0026#39;1990-SuperMarioWorld\u0026#39; } }, ReturnValues: \u0026#39;ALL_OLD\u0026#39; // 削除されたアイテムの内容を戻り値で取得 }; try { const result = await dynamoDb.deleteItem(params).promise(); console.log(result); } catch (err) { console.error(err); } } 実行結果 { Item: { Title: { S: \u0026#39;Super Mario World\u0026#39; }, GameId: { S: \u0026#39;1990-SuperMarioWorld\u0026#39; }, Hardware: { S: \u0026#39;SFC\u0026#39; }, Players: { N: \u0026#39;2\u0026#39; } } } アイテムを削除するときは、テーブル名 (Table) と、アイテムを特定するためのプライマリーキー (Key) を指定します。 複合プライマリキーを使用している場合は、パーティションキーとソートキーの両方を指定する必要があります（ValidationException が発生します）。 参考: DynamoDB.deleteItem DynamoDB.DocumentClient を使う場合 DocumentClient インスタンスを使用すると、プライマリーキーの指定が若干シンプルになります（S や N などのタイプ指定が必要なくなります）。 それ以外は同じです。 import * as AWS from \u0026#39;aws-sdk\u0026#39;; const documentClient = new AWS.DynamoDB.DocumentClient({ apiVersion: \u0026#39;2012-08-10\u0026#39;, region: \u0026#39;ap-northeast-1\u0026#39; }); async function documentClient_delete() { const params: AWS.DynamoDB.DocumentClient.DeleteItemInput = { TableName: \u0026#39;Games\u0026#39;, Key: { Hardware: \u0026#39;SFC\u0026#39;, GameId: \u0026#39;1990-SuperMarioWorld\u0026#39; }, ReturnValues: \u0026#39;ALL_OLD\u0026#39; // 削除されたアイテムの内容を戻り値で取得 }; try { const result = await documentClient.delete(params).promise(); console.log(result); } catch (err) { console.error(err); } } documentClient_delete(); 実行結果の形式も少しだけシンプルになります。 実行結果 { Attributes: { Title: \u0026#39;Super Mario World\u0026#39;, Genre: \u0026#39;ACT\u0026#39;, GameId: \u0026#39;1990-SuperMarioWorld\u0026#39;, Hardware: \u0026#39;SFC\u0026#39;, Players: 2 } } 参考: DynamoDB.DocumentClient.delete バッチ処理 - 複数のアイテムを追加・削除する (batchWriteItem) DynamoDB テーブルに複数のアイテムを追加、削除したいときは、putItem や deleteItem を何度も呼び出すよりも、batchWriteItem を使うのが効率的です。 ただし、最大でも 25 項目までといった細かな制約があります。 その他の制約などは、BatchWriteItem の仕様 を確認してください。 次の例では、Games テーブルに 2 つの項目を追加し、1 つの項目を削除しています。 DynamoDB を使う場合 async function batchWriteItem() { const params: AWS.DynamoDB.BatchWriteItemInput = { RequestItems: { \u0026#39;Games\u0026#39;: [ { PutRequest: { Item: { Hardware: { S: \u0026#39;FC\u0026#39; }, GameId: { S: \u0026#39;1984-lode-runner\u0026#39; }, Title: { S: \u0026#39;Lode Runner\u0026#39; }, Players: { N: \u0026#39;1\u0026#39; }, Genre: { S: \u0026#39;ACT\u0026#39; }, } }, }, { PutRequest: { Item: { Hardware: { S: \u0026#39;FC\u0026#39; }, GameId: { S: \u0026#39;1985-exed-exes\u0026#39; }, Title: { S: \u0026#39;Exed Exes\u0026#39; }, Players: { N: \u0026#39;2\u0026#39; }, Genre: { S: \u0026#39;STG\u0026#39; }, } } }, { DeleteRequest: { Key: { Hardware: { S: \u0026#39;SFC\u0026#39; }, GameId: { S: \u0026#39;1990-SuperMarioWorld\u0026#39; }, } } } ] } }; try { const result = await dynamoDb.batchWriteItem(params).promise(); console.log(result); } catch (err) { console.error(err); } } batchWriteItem() 実行結果 { UnprocessedItems: {} } 参考: DynamoDB.batchWriteItem DynamoDB.DocumentClient を使う場合 DocumentClient インスタンスを使用すると、属性値の指定が若干シンプルになります（S や N などのタイプ指定が必要なくなります）。 それ以外は同じです。 async function documentClient_batchWrite() { const params: AWS.DynamoDB.DocumentClient.BatchWriteItemInput = { RequestItems: { \u0026#39;Games\u0026#39;: [ { PutRequest: { Item: { Hardware: \u0026#39;FC\u0026#39;, GameId: \u0026#39;1984-lode-runner\u0026#39;, Title: \u0026#39;Lode Runner\u0026#39;, Players: 1, Genre: \u0026#39;ACT\u0026#39; }} }, { PutRequest: { Item: { Hardware: \u0026#39;FC\u0026#39;, GameId: \u0026#39;1985-exed-exes\u0026#39;, Title: \u0026#39;Exed Exes\u0026#39;, Players: 1, Genre: \u0026#39;STG\u0026#39; }} }, { DeleteRequest: { Key: { Hardware: \u0026#39;SFC\u0026#39;, GameId: \u0026#39;1990-SuperMarioWorld\u0026#39; }} } ] } }; try { const result = await documentClient.batchWrite(params).promise(); console.log(result); } catch (err) { console.error(err); } } 参考: DynamoDB.DocumentClient.batchWrite batchWrite のパラメーターを作るユーティリティ関数を作る DynamoDB.DocumentClient.batchWrite メソッドに渡すパラメーターをハードコードするのは大変なので、現実的には、複数アイテムをまとめて追加するためのラッパー関数的なものを用意することになると思います。 こんな感じ type Game = { Hardware: string, GameId: string, Title: string, Players: number, Genre: string }; /** DocumentClient.batchWrite に渡すオブジェクトを生成します */ function createParams(games: Game[]): AWS.DynamoDB.DocumentClient.BatchWriteItemInput { return { RequestItems: { \u0026#39;Games\u0026#39;: games.map(g =\u0026gt; ({ PutRequest: { Item: g } })) } }; } テーブル内の要素をすべて取得する (scan) DynamoDB テーブル内のすべてのアイテムを取得するには scan メソッドを使用します。 フィルタ条件を指定することもできますが、内部的には「全アイテムの取得 → フィルタ」という動作になるため、scan メソッドは基本的にはアイテム数が少ない場合にのみ使用できます（返却するデータは 1MB までなどの制約があります）。 プライマリーキーで検索条件を指定できる場合は、scan ではなく query メソッドを使うことで効率的な取得が可能です。 DynamoDB クラスにも DynamoDB.DocumentClient クラスにも同名の scan メソッドがありますが、後者の方が若干シンプルに記述できる（S や N などの属性タイプ指定を省略できる）ので、そちらを使ったサンプルコードを示します。 async function scan() { const params: AWS.DynamoDB.DocumentClient.ScanInput = { TableName: \u0026#39;Games\u0026#39; }; try { const result = await documentClient.scan(params).promise(); console.log(result); } catch (err) { console.error(err); } } scan(); 実行結果 { Items: [ { Title: \u0026#39;Lode Runner\u0026#39;, Genre: \u0026#39;ACT\u0026#39;, GameId: \u0026#39;1984-lode-runner\u0026#39;, Hardware: \u0026#39;FC\u0026#39;, Players: 1 }, { Title: \u0026#39;Exed Exes\u0026#39;, Genre: \u0026#39;STG\u0026#39;, GameId: \u0026#39;1985-exed-exes\u0026#39;, Hardware: \u0026#39;FC\u0026#39;, Players: 2 }, { Title: \u0026#39;Super Mario World\u0026#39;, Genre: \u0026#39;ACT\u0026#39;, GameId: \u0026#39;1990-SuperMarioWorld\u0026#39;, Hardware: \u0026#39;SNES\u0026#39;, Players: 2 } ], Count: 3, ScannedCount: 3 } scan 結果を何らかの条件で絞り込みたい場合は、FilterExpression パラメーターを使用します。 次の例では、Genre 属性が ACT のアイテムだけを取得しています。 ただし前述のように、FilterExpression による絞り込みは、全アイテム取得後にフィルターしているだけなので注意してください（アイテム数が増えてくると機能しなくなります）。 scan 用のフィルター条件を追加 const params: AWS.DynamoDB.DocumentClient.ScanInput = { TableName: \u0026#39;Games\u0026#39;, FilterExpression: \u0026#39;Genre = :genre\u0026#39;, ExpressionAttributeValues: { \u0026#39;:genre\u0026#39;: \u0026#39;ACT\u0026#39; } }; 参考: DynamoDB.scan 参考: DynamoDB.DocumentClient.scan 参考: Scan API 仕様 テーブル内の要素をプライマリーキーでフィルタして取得する (query) DynamoDB テーブルから、指定したプライマリーキーに一致するアイテムを検索するには、query メソッドを使用します。 主に、複合キー（パーティションキー + ソートキー）で構成されているテーブルから、 パーティションキーのみの指定 パーティションキー + ソートキーの条件指定 といった検索を行います。 ソートキーの方は部分一致や大小比較など、ある程度柔軟なフィルタ条件を指定できますが、パーティションキーの方は、あくまで完全一致させる必要があります。 async function query() { const params: AWS.DynamoDB.DocumentClient.QueryInput = { TableName: \u0026#39;Games\u0026#39;, KeyConditionExpression: \u0026#39;Hardware = :hard and GameId \u0026gt; :game\u0026#39;, ExpressionAttributeValues: { \u0026#39;:hard\u0026#39;: \u0026#39;FC\u0026#39;, \u0026#39;:game\u0026#39;: \u0026#39;1984-\u0026#39; } }; try { const result = await documentClient.query(params).promise(); console.log(result); } catch (err) { console.error(err); } } query(); 実行結果 { Items: [ { Title: \u0026#39;Lode Runner\u0026#39;, Genre: \u0026#39;ACT\u0026#39;, GameId: \u0026#39;1984-lode-runner\u0026#39;, Hardware: \u0026#39;FC\u0026#39;, Players: 1 }, { Title: \u0026#39;Exed Exes\u0026#39;, Genre: \u0026#39;STG\u0026#39;, GameId: \u0026#39;1985-exed-exes\u0026#39;, Hardware: \u0026#39;FC\u0026#39;, Players: 2 } ], Count: 2, ScannedCount: 2 } 参考: DynamoDB.query 参考: DynamoDB.DocumentClient.query 参考: Query API 仕様"
},
{
url: "/p/ny9fmty/",
title: "Next.js のプロジェクトを TypeScript 化する",
date: "2021-04-26T00:00:00Z",
body: "Next.js のプロジェクトを TypeScript 化する 何をするか？ create-next-app コマンドで Next.js プロジェクトを生成するときに --typescript (--ts) オプションをつけて実行すると、TypeScript 対応したプロジェクトを生成することができます。 $ npx create-next-app myapp --typescript # ただ、こっちのテンプレートを使う方法の方が若干洗練されてる気はする $ npx create-next-app myapp --example with-typescript また、Next.js は既存の JavaScript プロジェクトを TypeScript 化する機能も備えています。 ここから先は、その方法を説明します。 参考リンク Next.js で HelloWorld TypeScript 環境の導入 Next.js は、プロジェクトのルートに tsconfig.json ファイルがあると、自動的に TypeScript モードで動作するようになります。 次のようにして、空の tsconfig.json ファイルを作成し、TypeScript 用のパッケージをインストールします。 $ touch tsconfig.json $ npm install typescript @types/node @types/react --save-dev なんと、これだけで Next.js プロジェクトへの TypeScript 導入は完了です。 お手軽〜 自動生成される設定ファイルを見ておく 上記のステップで、TypeScript の設定ファイル (tsconfig.json) に何も記述していないことに気づいたかもしれません。 実は、Next.js のビルド（next dev や next build）を実行すると、自動的に設定ファイルの内容を更新してくれるようになっています。 Next.js 開発サーバーの起動 (next dev) $ npm run dev 例えば上記のように開発サーバーを起動すると、空っぽだった tsconfig.json が次のような内容に初期化されます。 まさにゼロコンフィグです。 tsconfig.json（自動更新された内容） { \u0026#34;compilerOptions\u0026#34;: { \u0026#34;target\u0026#34;: \u0026#34;es5\u0026#34;, \u0026#34;lib\u0026#34;: [ \u0026#34;dom\u0026#34;, \u0026#34;dom.iterable\u0026#34;, \u0026#34;esnext\u0026#34; ], \u0026#34;allowJs\u0026#34;: true, \u0026#34;skipLibCheck\u0026#34;: true, \u0026#34;strict\u0026#34;: false, \u0026#34;forceConsistentCasingInFileNames\u0026#34;: true, \u0026#34;noEmit\u0026#34;: true, \u0026#34;esModuleInterop\u0026#34;: true, \u0026#34;module\u0026#34;: \u0026#34;esnext\u0026#34;, \u0026#34;moduleResolution\u0026#34;: \u0026#34;node\u0026#34;, \u0026#34;resolveJsonModule\u0026#34;: true, \u0026#34;isolatedModules\u0026#34;: true, \u0026#34;jsx\u0026#34;: \u0026#34;preserve\u0026#34; }, \u0026#34;include\u0026#34;: [ \u0026#34;next-env.d.ts\u0026#34;, \u0026#34;**/*.ts\u0026#34;, \u0026#34;**/*.tsx\u0026#34; ], \u0026#34;exclude\u0026#34;: [ \u0026#34;node_modules\u0026#34; ] } さらに、Next.js はプロジェクトのルートに next-env.d.ts というファイルを生成します。 このファイルには、Next.js が提供するコンポーネントなどの型情報が含まれています。 next-env.d.ts /// \u0026lt;reference types=\u0026#34;next\u0026#34; /\u0026gt; /// \u0026lt;reference types=\u0026#34;next/types/global\u0026#34; /\u0026gt; デフォルトでは上記のような内容になっていて、node_modules/next 下にインストールされた型情報ファイルを参照するようになっています。 このファイルは Next.js が勝手に更新するので、マニュアルで更新する必要はありません。 既存の JavaScript コードを TypeScript コードに置き換える 拡張子を .js から .tsx に置換する TypeScript 環境の導入をサクッと完了したら、既存の JavaScript ファイル (.js) を TypeScript ファイル（.ts および .tsx）に置き換えていきます。 JavaScript ファイルは pages ディレクトリ以下に格納されているので、まずは、それらのファイルの拡張子を変更します。 pages/ +-- _app.js (→ _app.tsx) +-- api/ | +-- hello.js (→ hello.ts) +-- index.js (→ index.tsx) api ディレクトリの中の .js ファイルには JSX が含まれていないので、それだけは .ts にして、他のファイルは .tsx にしてしまえばよいでしょう。 厳格な型チェック（strict モード）を ON にする ファイルの拡張子を .ts と .tsx にしたので、ビルド時に TypeScript の型チェックが働くようになるはずが、npm run dev や npm run build してもビルドエラーにはなりません。 なぜなら、tsconfig.json の strict 設定が false になっており、暗黙的な any 型の使用が許されているからです。 次のように tsconfig.json を修正して、型チェックを強制するようにしましょう。 ついでに、allowJs はもう必要ないので false にしておきます。 tsconfig.json（修正箇所抜粋） { ... \u0026#34;allowJs\u0026#34;: false, // ← js ファイルは扱わない \u0026#34;skipLibCheck\u0026#34;: true, \u0026#34;strict\u0026#34;: true, // ← 型チェックなどを厳密に行う ... } これで、ビルド時にちゃんと型情報に関するエラーを出してくれるようになります。 $ npm run build ... Failed to compile. ./pages/_app.tsx:3:18 Type error: Binding element \u0026#39;Component\u0026#39; implicitly has an \u0026#39;any\u0026#39; type. ... TypeScript コードの修正 ビルドエラーにならないように、TypeScript コードに型情報を追加していきます。 pages/_app.tsx import type { AppProps } from \u0026#39;next/app\u0026#39; function MyApp({ Component, pageProps }: AppProps): JSX.Element { return \u0026lt;Component {...pageProps} /\u0026gt; } export default MyApp pages/api/hello.ts import type { NextApiRequest, NextApiResponse } from \u0026#39;next\u0026#39; export default (req: NextApiRequest, res: NextApiResponse) =\u0026gt; { res.status(200).json({ name: \u0026#39;John Doe\u0026#39; }) } これで、正しくビルドが通るようになります。 Next.js が提供する他の型情報に関しては、下記のサイトを参考にしてください。 参考リンク Basic Features: TypeScript | Next.js おまけ（example オプションでさまざまな環境が整ったプロジェクトを作成する） create-next-app コマンドで Next.js プロジェクトを作成するときに、--example オプションを使用すると、GitHub 上の任意のテンプレートを使ってプロジェクトを作成できます。 Next.js (Vercel) 公式のテンプレートが、下記のリポジトリにたくさん用意されています。 https://github.com/vercel/next.js/tree/master/examples 例えば、TypeScript + ESLint + Jest 導入済みのテンプレートである with-typescript-eslint-jest を使って Next.js プロジェクトを作成したいときは、次のように create-next-app コマンドを実行します。 $ npx create-next-app myapp --example with-typescript-eslint-jest こうすれば、最初から色々な環境が整った状態でプロジェクトが作成されるので、すぐに本質的な開発作業に取りかかることができます。 とはいえ、 ひとつずつ手作業で導入していった方が理解しやすいという側面もあるので、好きな導入方法を選べばよいと思います。"
},
{
url: "/p/whu7hr3/",
title: "Amazon EC2 で Hello World (2) EC2 インスタンスの起動と接続",
date: "2021-03-02T00:00:00Z",
body: "Amazon EC2 で Hello World (2) EC2 インスタンスの起動と接続 EC2 インスタンスの起動 EC2 インスタンスに接続するための キーペアを作成 したら、実際に EC2 インスタンスを起動してみます。 ここでは、マシンイメージ (AMI) として EC2 用に最適化された Amazon Linux 2 を選択することにします。 EC2 マネージメントコンソール を開く サイドバーの インスタンス を選択し、インスタンスを起動 ボタンを押す Amazon マシンイメージ (AMI) の選択画面で、Amazon Linux 2 を選択 インスタンスタイプの選択画面で、一番安い t2.nano や、一年間の無料枠がある t2.micro を選択（料金の参考: EC2Instances.info） 確認と作成 ボタンを押す 使用するキーペアを選択する画面が表示されるので、あらかじめ設定しておいた キーペアを選択して、インスタンスの作成 ボタンを押す 図: キーペアの選択 あとは数分待てば、EC2 インスタンスが起動します。 EC2 インスタンスへの SSH 接続 EC2 インスタンスが無事起動したら、SSH で接続してみます。 接続用のユーザー名やアドレスは、次のようにして確認することができます。 EC2 マネージメントコンソール を開く サイドバーの インスタンス を選択し、対象の EC2 インスタンスを選択 接続 ボタンを押す すると、次のような感じで接続先のユーザー名（ec2-user）や DNS アドレス（ec2-XXXXX) を確認することができます。 図: EC2 インスタンスの接続情報 あとは、この情報を使って ssh コマンドで接続するだけです。 EC2 Instance Connect タブで 接続 ボタンを押すと、ブラウザ上で動作する端末画面から接続することもできます。 $ ssh -i ~/.ssh/ec2key.pem ec2-user@ec2-52-193-255-XXX.ap-northeast-1.compute.amazonaws.com __| __|_ ) _| ( / Amazon Linux 2 AMI ___|\\___|___| https://aws.amazon.com/amazon-linux-2/ [ec2-user@ip-52-193-255-XXX ~]$ 上記では、DNS アドレス (FQDN) を使っていますが、IP アドレスでも接続できます。 $ ssh -i ~/.ssh/ec2key.pem ec2-user@52.193.255.XXX これらのアドレスは、EC2 インスタンスを再起動すると変化することに注意してください。 EC2 インスタンスの停止 EC2 インスタンスは立ち上がっているかぎり従量課金で使用料がかかるので、しばらく使わない場合は忘れずに停止しておきます。 EC2 コンソール上でインスタンスを選択し、インスタンスの状態 プルダウンから、インスタンスの停止 を選択することで停止できます。 図: EC2 インスタンスの停止 これで、EC2 の Hello World は完了です。"
},
{
url: "/p/ar2bjs2/",
title: "GitHub OAuth トークンを取得する (2) Azure Functions 経由で取得する",
date: "2020-08-18T00:00:00Z",
body: "GitHub OAuth トークンを取得する (2) Azure Functions 経由で取得する 何をするか？ ここでは、静的な Web サイト（の JavaScript) から、GitHub の OAuth トークンを取得できるようにしてみます。 この処理を実装すると、GitHub と連携した Web アプリを、GitHub Pages や Azure Static Web Apps などの、静的サイト用のホスティングサービス上で公開できるようになります。 汎用的な Web サーバー（VPSなど）でホスティングする場合と比べ、非常に安価に運用することができます。 前提知識として、下記の GitHub の OAuth トークン取得の流れを理解しているものとします。 参考: GitHub OAuth トークンを取得する (1) 処理の流れを理解する 静的な Web サイトから GitHub のアクセストークンを取得するときにネックになるのが、クロスオリジン通信 (CORS) の制約です。 また、GitHub のアクセストークンリクエストには、クライアントシークレット情報が必須であり（2020年、2021年現在）、これをクライアントサイドの JavaScript にハードコードするわけにはいきません。 よって、ブラウザ上で実行される JavaScript からは、実質アクセストークンの取得ができないので、何らかのバックエンドサーバーを介す形でアクセストークンを取得する必要があります。 バックエンドサーバーはどのようなものでも構わないのですが、ここではサーバーレス環境である Azure Functions を使ってアクセストークンの取得機能を実装します。 Azure Functions に関数を追加する Azure Functions に HTTP トリガーで起動する関数を追加し、GitHub の OAuth トークンを取得する処理を実装します。 まずは下記の記事を参考にして、Functions アプリ（プロジェクト）を作成してください。 参考: Azure Functions で簡単な関数を作ってみる 作成する関数の仕様は次のとおりとします。 HTTP GET リクエストのクエリ文字列で、OAuth アプリのクライアント ID (client_id) と、GitHub から取得した一時コード (code) を受け取る。 OAuth アプリのクライアントシークレット (client_secret) は Functions アプリの環境変数（アプリケーション設定）で設定しておく（ハードコードしない）。 GitHub に対してアクセストークンの取得リクエスト (HTTP POST) を送り、その結果をクライアントへそのまま返す。ただし、クライアントから指定されたクライアント ID (client_id) がそもそも不正な場合は、アクセストークンの取得は行わず、直ちに 400 (Bad Request) エラーを返す。 環境変数の設定 Functions アプリの 環境 → 構成 を開き、GitHub に登録した OAuth アプリの「クライアントID」と「クライアントシークレット」を登録してください。 ここでは次のような名前で登録することにします。 MYAPP_CLIENT_ID \u0026hellip; クライアント ID MYAPP_CLIENT_SECRET \u0026hellip; クライアントシークレット アプリケーション設定を追加した場合は、最後に 保存 ボタンを押して反映するのを忘れないでください（これを忘れてハマりがち\u0026hellip;）。 ここで設定した変数は、関数の JavaScript コードから process.env で参照できます。 CORS の設定 ブラウザ上の JavaScript から Azure Functions の関数を実行するときは、CORS 設定をしてクロスオリジン通信を許可しておく必要があります。 Functions アプリの API → CORS を開いて、Web サイトをホスティングするドメインを登録してください。 典型的には、 https://example.com といったドメイン名でアドレスを指定しますが、開発用のサーバーでテストする場合は、次のようなローカルアドレスを登録しておきます。 http://localhost:1234 Node モジュールのインストール HTTP リクエスト用のモジュールとして node-fetch を使用するので、Functions アプリの 開発ツール → コンソール を開いてインストールしてください。 D:\\home\\site\\wwwroot\u0026gt; npm init -y D:\\home\\site\\wwwroot\u0026gt; npm install node-fetch --save もちろん、ローカルで実行して package.json をデプロイする方法でも大丈夫です。 ここでは、サクッと Azure ポータル上で作業を完了させてしまいます。 関数を作成する まずは Funtions アプリに任意の名前で HTTP trigger 型の関数を追加してください。 ここでは、GitHubToken という名前で関数を作成し、下記のようなコードを入力します。 若干長いですが、やっていることは HTTP POST リクエストで GitHub のアクセストークン取得リクエストを送っているだけです。 GitHubToken/index.js const fetch = require(\u0026#39;node-fetch\u0026#39;); const RESPONSE_400_BAD_REQUEST = { status: 400, body: \u0026#39;Request paramters are invalid\u0026#39; }; /** 正しく環境変数がセットされているか確認する */ function checkEnv() { if (!process.env.MYAPP_CLIENT_ID) return false; if (!process.env.MYAPP_CLIENT_SECRET) return false; return true; } /** クライアントIDに対応するクライアントシークレットを取得する */ function getClientSecret(clientId) { if (clientId === process.env.MYAPP_CLIENT_ID) { return process.env.MYAPP_CLIENT_SECRET; } return undefined; } /** GitHub からアクセストークンを取得する */ async function requestToken(clientId, clientSecret, code, context) { const URL = \u0026#39;https://github.com/login/oauth/access_token\u0026#39;; // HTTP リクエストの設定 const option = { method: \u0026#39;POST\u0026#39;, headers: { Accept: \u0026#39;application/json\u0026#39;, \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39;, }, body: JSON.stringify({ client_id: clientId, client_secret: clientSecret, code: code, }) }; // HTTP POST リクエストを送信 try { const res = await fetch(URL, option); context.log.info(`Response from GitHub: status=${res.status}`); return { status: res.status, body: await res.json() }; } catch (err) { context.log.error(JSON.stringify(err)); throw err; } } /** 関数のエントリポイント */ module.exports = async function (context, req) { if (!checkEnv()) throw new Error(\u0026#39;Environment variables are not set\u0026#39;); const clientId = req.query.client_id; const code = req.query.code; context.log(`Request from client: client_id=${clientId}, code=${code}`); const clientSecret = getClientSecret(clientId); if (!clientSecret || !code) { context.log.warn(RESPONSE_400_BAD_REQUEST.body); context.res = RESPONSE_400_BAD_REQUEST; return; } context.res = await requestToken(clientId, clientSecret, code, context); } Web アプリ側の JavaScript を実装する 以上で、Azure Functions に GitHub アクセストークンを取得するための関数を追加できました。 あとはこれを利用して、静的な Web サイトの JavaScript からアクセストークンを取得できます。 ここでは、GitHub から取得したアクセストークンをローカルストレージに GITHUB_TOKEN というキーで保存し、その値の有無によって「サインイン済み」かどうかを判断しています。 画面上の Sing In ボタンを押すと、一時トークンの取得要求を送信し、そのコールバックを受けてアクセストークンを取得しに行きます。 アクセストークンの取得が完了すると、その値をローカルストレージに保存し、UI を更新します。 サインイン済みのときは、Sign In ボタンの代わりに Sign Out ボタンを表示するようにしています。 1 つの HTML ファイル（JS コード含む）でサインイン・アウト処理をひととおり実現しているので、若干スパゲッティコードになってます。すみません（^^; index.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;ja\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1\u0026#34;\u0026gt; \u0026lt;title\u0026gt;My App\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;My App\u0026lt;/h1\u0026gt; \u0026lt;button id=\u0026#34;btnSignIn\u0026#34; onclick=\u0026#34;signIn()\u0026#34; hidden\u0026gt;Sign In\u0026lt;/button\u0026gt; \u0026lt;button id=\u0026#34;btnSignOut\u0026#34; onclick=\u0026#34;signOut()\u0026#34; hidden\u0026gt;Sign Out\u0026lt;/button\u0026gt; \u0026lt;div id=\u0026#34;message\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;script\u0026gt; const GITHUB_CLIENT_ID = \u0026#39;29ed0f3a65af5342d5bd\u0026#39;; const GITHUB_API_SCOPE = \u0026#39;repo\u0026#39;; window.addEventListener(\u0026#39;DOMContentLoaded\u0026#39;, (event) =\u0026gt; { updateUi(); }) // 画面更新（サインイン済みかどうかで内容を変える） function updateUi() { const btnSignIn = document.getElementById(\u0026#39;btnSignIn\u0026#39;) const btnSignOut = document.getElementById(\u0026#39;btnSignOut\u0026#39;) const message = document.getElementById(\u0026#39;message\u0026#39;) if (isSignedIn()) { btnSignIn.hidden = true btnSignOut.hidden = false message.innerText = \u0026#39;サインイン済み: token=\u0026#39; + localStorage.getItem(\u0026#39;GITHUB_TOKEN\u0026#39;) } else { btnSignIn.hidden = false btnSignOut.hidden = true message.innerText = \u0026#39;サインインしていません\u0026#39; } } // GitHub のサインイン（OAuth 認証処理を開始） // すでに認可されているなら GitHub から即リダイレクトされる function signIn() { window.location.href = \u0026#39;https://github.com/login/oauth/authorize?\u0026#39; + `client_id=${GITHUB_CLIENT_ID}\u0026amp;scope=${GITHUB_API_SCOPE}`; } // サインアウト（ローカルストレージを削除するだけ） function signOut() { localStorage.removeItem(\u0026#39;GITHUB_TOKEN\u0026#39;); updateUi() } function isSignedIn() { const token = localStorage.getItem(\u0026#39;GITHUB_TOKEN\u0026#39;) return token != null } // GitHub からのリダイレクト時にアクセストークンを取得する function handleSignInCallback() { const params = window.location.search; const code = params.startsWith(\u0026#39;?code=\u0026#39;) ? params.split(\u0026#39;=\u0026#39;)[1] : undefined; if (code) { // 一時コードを取得したらアドレスを戻しておく window.history.replaceState(null, null, window.location.pathname); getGitHubToken(code); } } function getGitHubToken(code) { const URL = \u0026#39;https://sample-xxx.azurewebsites.net/api/GitHubToken\u0026#39; + `?client_id=${GITHUB_CLIENT_ID}\u0026amp;code=${code}`; fetch(URL) .then(res =\u0026gt; res.json()) .then(json =\u0026gt; { if (json.access_token) { localStorage.setItem(\u0026#39;GITHUB_TOKEN\u0026#39;, json.access_token) updateUi() } else { throw new Error(\u0026#39;Could not obtain access token (bad request)\u0026#39;); } }) .catch(err =\u0026gt; alert(err.name + \u0026#39;: \u0026#39; + err.message)); } handleSignInCallback(); \u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; これで、Web サイト内の JavaScript から GitHub API を呼び出せるようになります。 ただ、これくらい複雑になってくると、React などを使ってコンポーネント化していった方がよいですね。 React を使って実装する サインイン状態に応じた表示の切り替えなどは、React を使って実装するとスッキリします。 例えば React Router を使って、URL のパスとコンポーネントを次のように構成します。 全体構成 現在サインイン状態かどうかは、Web ブラウザのローカルストレージに GitHub のアクセストークン (GITHUB_TOKEN) が保存されているかどうかで判断します（前述の例と同じ）。 / \u0026hellip; Top コンポーネント 未サインインの場合： 「サインイン」ボタンが配置されたトップ画面を表示。「サインイン」ボタンを押すと /signin へリダイレクト。 サインイン済の場合： /main へリダイレクト。 /signin \u0026hellip; SignIn コンポーネント GitHub のサインインページ（認証・認可）へジャンプし、/signin?code=XXX というコールバックで一時コードを受け取る。一時コードを受け取ったら、HTTP リクエストでアクセストークンを取得し、ローカルストレージに保存する。最後に /main（あるいは /）へリダイレクト。 /signout \u0026hellip; SignOut コンポーネント ローカルストレージに保存されたアクセストークンを削除して、/ へリダイレクト。 /main \u0026hellip; Main コンポーネント 未サインインの場合： / へリダイレクト。 サインイン済の場合： GitHub API を利用するアプリのメイン画面を表示。 ここでは、/signin というパスで GitHub からの一時コードを受け取ることにしているので、最初に GitHub の OAuth Apps の設定 で、コールバックアドレスを /signin に変更しておく必要があります。 以下、それぞれのコンポーネントを順番に見ていきます。 App コンポーネント まず、全体のルーティングを管理する App コンポーネントです。 React Router のパス指定によって、表示するコンポーネントを切り替えます。 App.tsx import * as React from \u0026#39;react\u0026#39;; import { BrowserRouter as Router, Redirect, Route, Switch } from \u0026#39;react-router-dom\u0026#39;; import { Main } from \u0026#39;./Main\u0026#39;; import { SignIn } from \u0026#39;./SignIn\u0026#39;; import { SignOut } from \u0026#39;./SignOut\u0026#39;; import { Top as Top } from \u0026#39;./Top\u0026#39;; export const App: React.FC = () =\u0026gt; { return ( \u0026lt;Router\u0026gt; \u0026lt;Switch\u0026gt; \u0026lt;Route path=\u0026#34;/\u0026#34; exact={true} component={Top} /\u0026gt; \u0026lt;Route path=\u0026#34;/signin\u0026#34; component={SignIn} /\u0026gt; \u0026lt;Route path=\u0026#34;/signout\u0026#34; component={SignOut} /\u0026gt; \u0026lt;Route path=\u0026#34;/main\u0026#34; component={Main} /\u0026gt; \u0026lt;Redirect to=\u0026#34;/\u0026#34; /\u0026gt; \u0026lt;/Switch\u0026gt; \u0026lt;/Router\u0026gt; ); }; Config クラス 下記の Config クラスは、React コンポーネントではありませんが、GitHub のアクセストークンをローカルストレージに保存するためのユーティリティとして作成しておきます。 Config.ts export class Config { /** ローカルストレージ用のキー */ private static KEY_GITHUB_TOKEN = \u0026#39;GITHUB_TOKEN\u0026#39;; /** サインイン済みかどうか確認します。 */ public static isSignedIn(): boolean { return !!this.getToken(); } /** アクセストークンを保存します。 */ public static setToken(token: string) { localStorage.setItem(this.KEY_GITHUB_TOKEN, token); } /** アクセストークンを取得します。 */ public static getToken(): string { return localStorage.getItem(this.KEY_GITHUB_TOKEN); } /** アクセストークンを削除します。 */ public static removeToken() { localStorage.removeItem(this.KEY_GITHUB_TOKEN); } } Top コンポーネント 最上位のパス (/) にアクセスしたときは、Top コンポーネントを表示します。 Top コンポーネントは、ユーザーがまだサインインしていない場合は Welcome メッセージ的なものを表示し、サインインするためのボタンを表示します。 サインイン済みであれば、メイン画面 (/main) にリダイレクトします。 Top.tsx import * as React from \u0026#39;react\u0026#39;; import { Link, Redirect } from \u0026#39;react-router-dom\u0026#39;; import { Config } from \u0026#39;./Config\u0026#39;; export const Top: React.FC = () =\u0026gt; { if (Config.isSignedIn()) { return \u0026lt;Redirect to=\u0026#34;/main\u0026#34; /\u0026gt;; } return \u0026lt;\u0026gt; \u0026lt;h1\u0026gt;Top（トップ画面）\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt; サインインボタンを押すと、サインイン処理 (/signin) を行い、\u0026lt;br /\u0026gt; メイン画面 (/main) へ遷移します。\u0026lt;br /\u0026gt; すでにサインイン済みであれば、自動的にメイン画面へ遷移します。 \u0026lt;/p\u0026gt; \u0026lt;Link to=\u0026#34;/signin\u0026#34;\u0026gt;サインイン\u0026lt;/Link\u0026gt; \u0026lt;/\u0026gt;; }; Main コンポーネント サインイン後のメイン画面は Main コンポーネントが担当します。 まだサインインしていない場合は、トップ画面 (/) へ飛ばします。 つまり、Top コンポーネントと逆の振る舞いですね。 Main.tsx import * as React from \u0026#39;react\u0026#39;; import { Link, Redirect } from \u0026#39;react-router-dom\u0026#39;; import { Config } from \u0026#39;./Config\u0026#39;; export const Main: React.FC\u0026lt;{}\u0026gt; = () =\u0026gt; { if (!Config.isSignedIn()) { return \u0026lt;Redirect to=\u0026#34;/\u0026#34; /\u0026gt;; } return \u0026lt;\u0026gt; \u0026lt;h1\u0026gt;Main（メイン画面）\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt; GitHub 認証後に表示可能なメイン画面です。\u0026lt;br /\u0026gt; GitHub API で取得した情報を表示します。\u0026lt;br /\u0026gt; サインアウトボタンを押すと、サインアウト処理 (/signout) を行い、\u0026lt;br /\u0026gt; ようこそ画面 (/) に戻ります。 \u0026lt;/p\u0026gt; \u0026lt;Link to=\u0026#34;/signout\u0026#34;\u0026gt;サインアウト\u0026lt;/Link\u0026gt; \u0026lt;/\u0026gt;; }; SignIn コンポーネント React Router で /signin にアクセスすると、GitHub のサインイン処理（一時コード取得＆アクセストークン取得）が実行されます。 GitHub からのコールバック（リダイレクト）を処理するため、処理が若干複雑になっています。 SignIn.tsx import * as querystring from \u0026#39;querystring\u0026#39;; import * as React from \u0026#39;react\u0026#39;; import { Redirect } from \u0026#39;react-router-dom\u0026#39;; import { Config } from \u0026#39;./Config\u0026#39;; const GITHUB_CLIENT_ID = \u0026#39;29ed0f3a65af5342d5bd\u0026#39;; const GITHUB_API_SCOPE = \u0026#39;repo\u0026#39;; //const GITHUB_API_SCOPE = \u0026#39;repo read:user\u0026#39;; /** * GitHub のサインイン（OAuth 認証処理を開始）画面へ遷移します。 * すでに認可されている場合は、GitHub からコールバック URL へ即リダイレクトされます。 */ function signIn() { const query = querystring.stringify({ client_id: GITHUB_CLIENT_ID, scope: GITHUB_API_SCOPE, }); window.location.href = \u0026#39;https://github.com/login/oauth/authorize?\u0026#39; + query; } /** * GitHub からのリダイレクト時に URL からアクセストークンを取得します。 */ function handleSignInCallback() { const params = window.location.search; const code = params.startsWith(\u0026#39;?code=\u0026#39;) ? params.split(\u0026#39;=\u0026#39;)[1] : undefined; return code; } /** * Azure Functions 経由で GitHub のアクセストークンを取得します。 */ function getGitHubToken(code: string, callback: (token: string) =\u0026gt; void) { const query = querystring.stringify({ client_id: GITHUB_CLIENT_ID, code: code, }); const url = \u0026#39;https://sample-xxx.azurewebsites.net/api/GitHubToken?\u0026#39; + query; fetch(url) .then(res =\u0026gt; res.json()) .then(json =\u0026gt; { if (json.access_token) { callback(json.access_token); } else { throw new Error(\u0026#39;Could not obtain access token (bad request)\u0026#39;); } }) .catch(err =\u0026gt; alert(err.name + \u0026#39;: \u0026#39; + err.message)); } export const SignIn: React.FC = () =\u0026gt; { const [isSignedIn, setIsSignedIn] = React.useState(false); // 非同期なサインイン処理は useEffect の中で行う React.useEffect(() =\u0026gt; { // サインイン済みであればステートを変更して終了 if (Config.isSignedIn()) { setIsSignedIn(true); return; } // URL から GitHub からの一時コードを抽出 const code = handleSignInCallback(); if (code) { // 一時コードを見つけたらアクセストークンの取得処理を行う // alert(\u0026#39;一時コード: \u0026#39; + code); getGitHubToken(code, (token: string) =\u0026gt; { // alert(\u0026#39;アクセストークン: \u0026#39; + token); Config.setToken(token); setIsSignedIn(true); }); } else { // 純粋な \u0026#39;/signin\u0026#39; へのアクセスであれば、GitHub の認証ページへジャンプ signIn(); } }, []); if (isSignedIn) { return \u0026lt;Redirect to=\u0026#34;/main\u0026#34; /\u0026gt;; } else { return \u0026lt;p\u0026gt;サインイン処理中...\u0026lt;/p\u0026gt;; } }; GITHUB_CLIENT_ID に関しては、ローカル開発用と本番サーバー用では違うものを登録することになるため、実際には次のような感じで切り替えて使用する必要があります。 この ID によって、GitHub から一時コードが返されるときのコールバック URL が切り替わります。 // GitHub Client ID はローカル開発用と本番サーバ用で分ける const GITHUB_CLIENT_ID = process.env.NODE_ENV === \u0026#39;development\u0026#39; ? \u0026#39;29ed0f3a65af5342d5bd\u0026#39; : \u0026#39;a18ace3b4680392f5225\u0026#39;; SignOut コンポーネント パス /signout にアクセスすると、サインアウト処理が実行されます。 といっても、ローカルストレージに保存されたアクセストークンを削除し、トップ画面 (/) にリダイレクトするだけなので、サインイン処理ほど複雑ではありません。 SignOut.tsx import * as React from \u0026#39;react\u0026#39;; import { Redirect } from \u0026#39;react-router-dom\u0026#39;; import { Config } from \u0026#39;./Config\u0026#39;; export const SignOut: React.FC\u0026lt;{}\u0026gt; = () =\u0026gt; { Config.removeToken(); return \u0026lt;Redirect to=\u0026#34;/\u0026#34; /\u0026gt;; }; 以上で、React アプリの中で GitHub の OAuth アクセストークンを取得する実装は完成です。 メイン画面 (/main) にアクセスしている最中は、サインイン状態であることが保証されているので、アクセストークンを利用して GitHub API を呼び出すことができます。 GraphQL 版の GitHub API (ver.4) を使用するときは、Apollo Client と React を組み合わせて使う とシンプルに実装できます。"
},
{
url: "/p/78whxix/",
title: "Electron で Hello World (2) TypeScript で開発できるようにする",
date: "2020-06-28T00:00:00Z",
body: "Electron で Hello World (2) TypeScript で開発できるようにする 概要 前回の記事（Electron で Hello World (1) 最小構成で作る）では、プレーンな JavaScript を使用して簡単な Electron アプリを作成しましたが、本格的な開発を始めるときは TypeScript の環境を導入しておいた方がよいでしょう。 ここでは、上記のプレーンな JavaScript による Hello World ができているとして、TypeScript の環境を追加でセットアップします。 次のように、src ディレクトリ内に .ts ファイルを作成し、トランスパイルされた .js ファイルを build ディレクトリに出力するように設定することにします。 myapp/ +-- build/ # トランスパイル後の .js ファイルを格納 +-- src/ # .ts ファイルを格納 +-- public/ # そのままパッケージングするもの | +-- index.html +-- package.json # Node.js 用設定ファイル +-- tsconfig.json # TypeScript 用設定ファイル ビルド設定 TypeScript をインストールします。 $ npm install typescript --save-dev Node.js ライブラリ用の型宣言ファイル (node.d.ts) をインストールします。 $ npm install @types/node --save-dev ☝️ ワンポイント Electron の型定義については、Electron パッケージにデフォルトで含まれているので、型定義ファイルを別途インストールする必要はありません。 TypeScript の設定ファイル (tsconfig.json) を作成します。 次のように tsc --init コマンドでテンプレートファイルを生成し、必要に応じて内容を修正するのが手っ取り早いです。 $ npx tsc --init 次のような感じの内容になるように tsconfig.json を修正します。 プロジェクトのディレクトリ構成に合わせて outDir と rootDir を正しく指定するところがポイントでしょうか。 tsconfig.json { \u0026#34;compilerOptions\u0026#34;: { \u0026#34;target\u0026#34;: \u0026#34;es6\u0026#34;, \u0026#34;module\u0026#34;: \u0026#34;commonjs\u0026#34;, \u0026#34;lib\u0026#34;: [\u0026#34;esnext\u0026#34;,\u0026#34;dom\u0026#34;], \u0026#34;outDir\u0026#34;: \u0026#34;build\u0026#34;, \u0026#34;rootDir\u0026#34;: \u0026#34;src\u0026#34;, \u0026#34;sourceMap\u0026#34;: true, \u0026#34;strict\u0026#34;: true, \u0026#34;esModuleInterop\u0026#34;: true, \u0026#34;skipLibCheck\u0026#34;: true, \u0026#34;forceConsistentCasingInFileNames\u0026#34;: true } } ☝️ skipLibCheck プロパティ 上記 tsconfig.json ファイル内の skipLibCheck: true は、型定義ファイル内の型チェックを行わないようにする指定です。 執筆時点では Electron が Node.js の新しい型定義に対応していない ため、このプロパティをセットしておかないと、tsc によるトランスパイル時にエラーになります。 package.json ファイルを修正し、build スクリプトや start スクリプトで tsc によるトランスパイルを実行するようにしておきます。 エントリポイントとなるファイルが main.js から build/main.js に変わったので、そのパスの変更も忘れずに。 package.json { \u0026#34;name\u0026#34;: \u0026#34;myapp\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;0.0.1\u0026#34;, \u0026#34;main\u0026#34;: \u0026#34;build/main.js\u0026#34;, \u0026#34;scripts\u0026#34;: { \u0026#34;build\u0026#34;: \u0026#34;tsc\u0026#34;, \u0026#34;start\u0026#34;: \u0026#34;tsc \u0026amp;\u0026amp; electron .\u0026#34; }, \u0026#34;devDependencies\u0026#34;: { \u0026#34;@types/node\u0026#34;: \u0026#34;^14.0.14\u0026#34;, \u0026#34;electron\u0026#34;: \u0026#34;^9.0.2\u0026#34;, \u0026#34;typescript\u0026#34;: \u0026#34;^3.9.5\u0026#34; } } TypeScript で開発するための基本的なビルド設定はこれで完了です。 実装 tsconfig.json の rootDir プロパティで指定した通り、TypeScript のソースコードは、src ディレクトリ以下に作成するようにします。 モジュールのインポートには、ECMAScript 2015 (ES6) の import ~ from 構文を使うようにし、必要に応じて関数や変数をタイプアノテーションで型付けします。 src/main.ts import { app, BrowserWindow } from \u0026#39;electron\u0026#39;; function createWindow () { const options: Electron.BrowserWindowConstructorOptions = { width: 400, height: 300, webPreferences: { nodeIntegration: true // Node 機能の使用を許可 } } const win = new BrowserWindow(options); win.loadFile(\u0026#39;public/index.html\u0026#39;); } // Electron の初期化が完了したらウィンドウを作成 app.whenReady().then(createWindow); 実行 あとは、次のように実行すれば、TypeScript のトランスパイルが実行され、Electron アプリが起動します（npm start は npm run start の省略記法です）。 $ npm start TypeScript のトランスパイルのみを実行したい場合は次のようにします。 $ npm run build 次のステップ → Electron で Hello World (3) React を使えるようにする"
},
{
url: "/p/kevcr7m/",
title: "Azure Pipelines で Hugo サイトのビルド＆デプロイ",
date: "2020-03-30T00:00:00Z",
body: "Azure Pipelines で Hugo サイトのビルド＆デプロイ 前提知識 Azure Pipelines の基本的な使い方は下記ページを参考にしてください。 Azure Pipelines の使い方 (Hello World) hugo deploy コマンドによる Hugo サイトのデプロイについては下記ページを参考にしてください。 hugo deploy コマンドで Azure などのクラウドサービス上にデプロイする | まくまくHugo/Goノート 事前準備 ここでは、Azure Pipelines の設定の説明をしますので、下記の作成・準備は終わっているものとします。 Hugo コンテンツ用の Git リポジトリ Azure Repos や GitHub の Git リポジトリに、Hugo サイトのコンテンツをコミットしてください。 hugo deploy コマンドのための設定 Hugo の設定ファイル config.toml に、deployment.targets などの設定をしてください。 Azure Pipelines の作成 Azure DevOps のプロジェクト内に、上記の Git リポジトリと連携する Pipelines を作成してください。 Hugo 自動ビルド＆デプロイのための Azure Pipelines 設定 azure-pipelines.yml trigger:- mastervariables:hugo_version:\u0026#39;0.68.3\u0026#39;pool:vmImage:\u0026#39;ubuntu-latest\u0026#39;steps:- script:wget -O hugo.deb https://github.com/gohugoio/hugo/releases/download/v$(hugo_version)/hugo_extended_$(hugo_version)_Linux-64bit.debdisplayName:\u0026#39;Download Hugo $(hugo_version)\u0026#39;- script:sudo dpkg -i hugo.debdisplayName:\u0026#39;Install Hugo $(hugo_version)\u0026#39;- script:hugodisplayName:\u0026#39;Build Hugo site\u0026#39;- script:hugo deploydisplayName:\u0026#39;Deploy Hugo site\u0026#39;env:AZURE_STORAGE_ACCOUNT:$(AZURE_STORAGE_ACCOUNT)AZURE_STORAGE_KEY:$(AZURE_STORAGE_KEY) この Pipelines 設定では、下記のことを順番にシェルスクリプトで実行しています。 Hugo パッケージのダウンロード（ここでは Linux の deb パッケージ） Hugo パッケージのインストール Web サイトのビルド (hugo) Web サイトのデプロイ (hugo deploy) 順番に内容を見ていきます。 Hugo パッケージのダウンロード - script:wget -O hugo.deb https://github.com/gohugoio/hugo/releases/download/v$(hugo_version)/hugo_extended_$(hugo_version)_Linux-64bit.debdisplayName:\u0026#39;Download Hugo $(hugo_version)\u0026#39; wget コマンドを使って、Hugo 本家のサイトから deb パッケージをダウンロードします。 ダウンロードする Hugo のバージョンは、YAML ファイルの先頭部分の変数で指定できるようにしています。 variables:hugo_version:0.68.3 Hugo パッケージのインストール - script:sudo dpkg -i hugo.debdisplayName:\u0026#39;Install Hugo $(hugo_version)\u0026#39; dpkg コマンドを使って、1 つ前のステップでダウンロードした deb パッケージをインストールします。 Web サイトのビルド - script:hugodisplayName:\u0026#39;Build Hugo site\u0026#39; hugo コマンドを使って、Web サイトコンテンツをビルドします。 Pipelines 上のワーキングディレクトリに public ディレクトリが生成されます。 Web サイトのデプロイ - script:hugo deploydisplayName:\u0026#39;Deploy Hugo site\u0026#39;env:AZURE_STORAGE_ACCOUNT:$(AZURE_STORAGE_ACCOUNT)AZURE_STORAGE_KEY:$(AZURE_STORAGE_KEY) hugo deploy コマンドを使って、public ディレクトリの内容を Azure などのクラウドストレージにデプロイします。 例えば、Hugo の設定ファイルで次のように設定されている場合は、Azure の BLOB ストレージへのデプロイが実行されます。 config.toml [[deployment.targets]] URL = \u0026#34;azblob://$web\u0026#34; このとき、Azure ストレージのアカウント名とキーを環境変数 (AZURE_STORAGE_ACCOUNT / AZURE_STORAGE_KEY) に設定しておく必要があるのですが、これらの秘密情報は、 Azure Pipelines の変数として設定 して、その値を環境変数に伝搬させるようにしています。 Pipelines 上の変数は、Pipelines のエディット画面の右上の Variables ボタンから設定することができます。 変数名と値のペアを入力するダイアログが表示されるので、ここで必要な変数を設定します。 このとき、Keep this value secret にチェックを入れておくと、値が *** のようにマスクされるようになります。 すべての変数の設定が終わったら、最後に Save ボタンを押すのを忘れないでください（個々の変数の OK ボタンだけでは保存されません）。 これで、Azure Pipelines による Hugo サイトのビルド＆デプロイが自動化されます。 GitHub などの Markdown コンテンツが更新されると、次のような Job が走り、自動的に Web サイトが更新されます。 （おまけ）コンテンツを格納するディレクトリを指定する プロジェクトの構成によっては、Web サイトのコンテンツファイルが、Git リポジトリのルートディレクトリにないことがあると思います。 例えば、Hugo 関連のファイル群が、次のように website ディレクトリ以下にあるケースなどです。 YourRepository +-- azure-pipelines.yml +-- website/ +-- architypes/ +-- assets/ +-- content/ +-- layouts/ +-- resources/ +-- static/ +-- config.toml 次の Pipelines 設定では、root_dir 変数を定義して、そこを作業ディレクトリとして hugo コマンドを実行するようにしています。 azure-pipelines.yml（抜粋） variables:hugo_version:\u0026#39;0.68.3\u0026#39;root_dir:\u0026#39;website\u0026#39;steps://...省略...- script:hugodisplayName:\u0026#39;Build Hugo site\u0026#39;workingDirectory:$(root_dir)- script:hugo deploydisplayName:\u0026#39;Deploy Hugo site\u0026#39;workingDirectory:$(root_dir)env:AZURE_STORAGE_ACCOUNT:$(AZURE_STORAGE_ACCOUNT)AZURE_STORAGE_KEY:$(AZURE_STORAGE_KEY) 上記のように、Azure Pipelines 組み込みの Command Line タスク には、workingDirectory オプションを指定できるようになっています。 ここでは root_dir 変数で指定したディレクトリを作業ディレクトリとして使用するようにしています。 ☝️ cd コマンドを使えばいいのでは？ スクリプトで cd $(root_dir) \u0026amp;\u0026amp; hugo としてもほとんど同じですが、できるだけ OS 非依存の記述になるように、workindDirectory オプションを使った方がよいでしょう。"
},
{
url: "/p/7g9seub/",
title: "逆引き Azure CLI: プロキシ環境下で Azure CLI (az) を使用する",
date: "2020-03-17T00:00:00Z",
body: "逆引き Azure CLI: プロキシ環境下で Azure CLI (az) を使用する 会社などのプロキシ環境下において az コマンドを実行する場合は、環境変数 https_proxy を設定しておきます。 Windows の場合 C:\\\u0026gt; set https_proxy=http://proxy.example.com:8080 Linux/Mac の場合 $ export https_proxy=http://proxy.example.com:8080"
},
{
url: "/p/nky6cbb/",
title: "TypeScriptの型: クラス定数を定義する (static readonly)",
date: "2020-02-12T00:00:00Z",
body: "TypeScriptの型: クラス定数を定義する (static readonly) static readonly プロパティを定義する TypeScript 2.0 移行では、クラス内の static プロパティに readonly キーワードを付けて読み取り専用であることを示すことができます。 class SiteInfo { // クラス定数の定義 static readonly FAQ_URL = \u0026#39;https://example.com/faq/\u0026#39;; } クラス定数を別ファイルから参照する このようなクラスをモジュールとして公開 (export) すれば、アプリ全体でそのクラス定数を共有できます。 （export側）siteInfo.ts export class SiteInfo { static readonly FAQ_URL = \u0026#39;https://example.com/faq/\u0026#39;; } （import側）index.ts import { SiteInfo } from \u0026#39;siteInfo\u0026#39;; console.log(SiteInfo.FAQ_URL); 配列をクラス定数にする (ReadonlyArray) readonly キーワードは、その変数への代入を禁止するだけなので、オブジェクト自体のセット系メソッドは呼び出せてしまいます。 配列に関しても各要素の値が変更できてしまうのは同様ですが、TypeScript にはそれを禁止するための ReadonlyArray\u0026lt;T\u0026gt; というジェネリッククラスが用意されています。 クラス定数として読み取り専用配列を定義 class Coordinates { static readonly ORIGIN: ReadonlyArray\u0026lt;number\u0026gt; = [0, 0]; } Coordinates.ORIGIN = [1, 1]; // Error (readonly により防止) Coordinates.ORIGIN[0] = 100; // Error (ReadonlyArray により防止) get アクセサを定義する方法 ECMAScript5 で導入された get アクセサを使う方法でも、クラス定数のような表現が可能です。 class SiteInfo { static get FAQ_URL(): string { return \u0026#39;https://example.com/faq/\u0026#39;; } } console.log(SiteInfo.FAQ_URL); ただし、get アクセサは関数定義になるので、若干記述が冗長になってしまうのと、呼び出しごとに処理が走るという違いがあります。 （コラム）const キーワードは使えない TypeScript や、そのベースになっている JavaScript では、次のようにクラス内の static プロパティに const を付けようとするとエラーになります。 間違った方法 export class SiteInfo { static const FAQ_URL = \u0026#39;https://example.com/faq/\u0026#39;; // Error! } エラーメッセ―ジ A class member cannot have the `const` keyword. なので、const の代わりに、TypeScript 2.0 で導入された readonly キーワードを使用しましょう。 TypeScript 2.0 より前のバージョンしか使えない場合は、次のように namespace を使えば、一応クラス定数っぽいものを定義することができます。 （コラム）namespace を使ったクラス定数もどき 名前空間 (namespace) 内で定数を定義すると、あたかもクラス定数のように使用することができます。 この namespace を使った定義方法であれば、TypeScript 2.0 より前のバージョンでも使用できます。 siteInfo.ts export namespace SiteInfo { // 名前空間内に定数を定義して公開する export const FAQ_URL = \u0026#39;https://example.com/faq/\u0026#39;; } export は名前空間と定数の両方に付けなければいけないことに注意してください。 最初の export は、このモジュール（ファイル）が SiteInfo 名前空間を公開することを示し、2 つ目の export は、SiteInfo 名前空間が FAQ_URL を公開することを示しています。 上記のように定義した定数は、次のように import して参照することができます。 参照方法は、クラス定数 (static readonly) を扱う場合と同様です。 index.ts import { SiteInfo } from \u0026#39;siteInfo\u0026#39;; console.log(SiteInfo.FAQ_URL); ただし、このように定義した SiteInfo はクラスではなく名前空間なので、そこにインスタンスメソッドを追加するといったことはできません。 名前空間は、あくまで定数を階層化して管理したい場合のみに使用できます。"
},
{
url: "/p/dofzeua/",
title: "Azure Table Strage を使ってみる (2) 接続情報（キー）を確認する",
date: "2020-01-31T00:00:00Z",
body: "Azure Table Strage を使ってみる (2) 接続情報（キー）を確認する Table Storage サービスの ストレージアカウントを作成 すると、各種プログラムから Table Storage にアクセスするための接続情報（キー）を取得することができます。 Table Storage の接続情報は、Azure ポータル からストレージアカウントのリソースを開き、設定 → アクセスキー と辿ると確認することができます。 Python や Node.js などのプログラムから Azure Storage に接続するには、上の図の中の、 ストレージアカウント名 と キー のペア 接続文字列 のいずれかの情報が必要です。"
},
{
url: "/p/ak7u3h3/",
title: "TypeScriptの環境: Visual Studio Code で TypeScript の開発環境を構築する",
date: "2019-09-24T00:00:00Z",
body: "TypeScriptの環境: Visual Studio Code で TypeScript の開発環境を構築する はじめに TypeScript は Microsoft が開発している言語で、同じく Microsoft が開発している IDE である Visual Studio Code（以下 VS Code）が TypeScript コードの編集に適しています。 VS Code による TypeScript の開発環境を構築するには、下記をインストールする必要があります。 Visual Studio Code Node.js（npm コマンド） TypeScript（tsc コマンド) 開発環境をインストールする Visual Studio Code のインストール VS Code は下記からインストーラーをダウンロードしてインストールできます。 Download Visual Studio Code TypeScript のソースコード (.ts) ファイルは、単純なテキストエディタでも編集できますが、この VS Code を使って編集すると、プロパティ名の自動補完などができて効率的に開発を行えます。 コマンドラインから code と入力して、VS Code を起動できるようになれば OK です。 VS Code をインストールしたのに code コマンドが認識されない場合は、こちらの記事 を参考にしてパスを通してください。 Node.js のインストール TypeScript のトランスパイラである tsc コマンドは、Node.js のパッケージとして提供されているため、先に Node.js をインストールしておく必要があります。 Node.js は下記からインストーラーをダウンロードしてインストールできます。 Download Node.js Node.js をインストールすると、パッケージ管理用の Node Package Manager（npm コマンド）も一緒にインストールされます。 Node.js アプリ用のプロジェクトを作成する VS Code でプロジェクトを開く VS Code は 1 つのディレクトリを 1 つのプロジェクトとみなします。 まずはプロジェクト用のディレクトリを作成して、それを VS Code で開きます。 $ mkdir myapp $ code myapp VS Code を起動するときは、ディレクトリを開く というところがポイントで、.js ファイルや .ts ファイルを直接開いてしまうと、プロジェクトに設定したビルドタスク（後述）を実行できません。 Windows エクスプローラーなどでディレクトリを右クリックして Open with Code を選択する方法でも OK です。 package.json の作成 このプロジェクトを Node.js アプリとして認識させるため、package.json を作成します。 VS Code 上で Ctrl + ` と入力するとターミナルを開くことができるので、下記のように実行します。 $ npm init -y プロジェクトのパッケージ依存関係やビルドスクリプトなどは、この package.json に記述します。 TypeScript のビルド設定を行う VS Code で TypeScript コード (.ts) をトランスパイルして JavaScript コード (.js) に変換するには、下記のような状態にセットアップされている必要があります。 VS Code でディレクトリ（ワークスペース）を開いている そのディレクトリ内に TypeScript の設定ファイル (tsconfig.json) が存在する TypeScript (tsc) のインストール まず、TypeScript のトランスパイラ（tsc コマンド）をインストールします。 次のようにすると、プロジェクトに TypeScript がインストールされ、package.json の依存情報 (devDependencies) が更新されます。 $ npm install typescript --save-dev $ npm install @types/node --save-dev インストールする際のパッケージ名は tsc ではなく typescript なので注意してください。 後者の @types/node パッケージは、Node.js コアライブラリ用の TypeScript 型定義です。 必須ではありませんが、これをインストールしておくと、例えば process モジュールなどの型補完が効くようになります。 プロジェクトのディレクトリから、次のように tsc コマンドを実行できるようになればインストールは完了です。 $ npx tsc -v Version 4.0.2 npx は、プロジェクト内にインストールした NPM パッケージが提供するコマンドを実行するためのコマンドです（Node.js が提供する機能です）。 ここでは、プロジェクト内にインストールした tsc` コマンドを実行しています。 ☝️ TypeScript のグローバルインストール npm install で TypeScript をインストールするときに、-g オプションを付けると tsc コマンドをシステムグローバルにインストールすることができます。 その場合は、どのディレクトリからでも tsc コマンドを実行できるようになります（npx コマンド経由にする必要がありません）。 ただ、Node.js アプリを作成する場合は、開発環境の依存を防ぐために、TypeScript はプロジェクトローカルにインストールしておいた方がよいでしょう。 tsconfig.json を作成する TypeScript 用のビルド設定ファイルである tsconfig.json を作成します。 tsc コマンドを使って、ひな形となる設定ファイルを作成することができます。 $ npx tsc --init message TS6071: Successfully created a tsconfig.json file. デフォルトでは、例えば下記のような感じの設定ファイルが生成されます（コメント類は削除）。 TypeScript のバージョンによって、生成される内容は多少異なります。 tsconfig.json { \u0026#34;compilerOptions\u0026#34;: { \u0026#34;target\u0026#34;: \u0026#34;es5\u0026#34;, \u0026#34;module\u0026#34;: \u0026#34;commonjs\u0026#34;, \u0026#34;strict\u0026#34;: true, \u0026#34;esModuleInterop\u0026#34;: true, \u0026#34;skipLibCheck\u0026#34;: true, \u0026#34;forceConsistentCasingInFileNames\u0026#34;: true } } target はトランスパイル後の JavaScript バージョンで、デフォルトでは若干古い Web ブラウザなどを想定したバージョン (es5) になっています。最終的な実行環境として Node.js を使うのであれば、ES2020 などの新しいバージョンを指定してもよいでしょう。 .ts ファイルの格納ディレクトリや、.js ファイルの出力先ディレクトリを変更したい場合は、次のような感じで設定します。 同じディレクトリに、トランスパイル前の .ts ファイルと、トランスパイル後の .js ファイルが混在すると紛らわしいので、この設定を行っておくことをオススメします。 tsconfig.json { \u0026#34;compilerOptions\u0026#34;: { // ... \u0026#34;outDir\u0026#34;: \u0026#34;./build\u0026#34;, }, \u0026#34;include\u0026#34;: [\u0026#34;./src/**/*\u0026#34;] } TypeScript コードをビルドして実行する ビルドと実行 Cmd/Ctrl + N で新規ファイルを作成し、下記のように実装して Cmd/Ctrl + S で main.ts という名前で保存します。 tsconfig.json で include ディレクトリの設定を行った場合は、それに合わせて src ディレクトリ以下に保存することに注意してください。 src/main.ts function greet(name: string): string { return `Hello, ${name}!`; } console.log(greet(\u0026#39;Maku\u0026#39;)); main.ts ファイルを作成したら、tsc コマンドでビルド（トランスパイル）することができます。 あるいは、VS Code 上で次のようにビルドすることもできます（同様に tsc コマンドを呼び出すだけです）。 Cmd/Ctrl + Shift + B （あるいはメニューから Terminal → Run Build Task\u0026hellip;） tsc: build - tsconfig.json を選択して Enter すると、下記のように JavaScript にトランスパイルされた main.js ファイルが生成されます。 build/main.js \u0026#34;use strict\u0026#34;; function greet(name) { return \u0026#34;Hello, \u0026#34; + name + \u0026#34;!\u0026#34;; } console.log(greet(\u0026#39;Maku\u0026#39;)); あとは、次のように node コマンドで実行できます。 $ node build/main.js Hello, Maku! npm start で実行できるようにする package.json に NPM スクリプトを定義しておくと、npm run スクリプト名 と入力するだけで様々なコマンドを実行できるようになります。 この設定により、ビルドコマンドを簡略化したり、エントリポイント (build/main.js) を意識せずにプログラムを起動できるようになります。 package.json { // ... \u0026#34;scripts\u0026#34;: { \u0026#34;start\u0026#34;: \u0026#34;node build/main.js\u0026#34;, \u0026#34;build\u0026#34;: \u0026#34;tsc\u0026#34;, \u0026#34;build:watch\u0026#34;: \u0026#34;tsc --watch\u0026#34; }, // ... } Ctrl + ` でターミナルを開き、次のように入力すると、ビルドやアプリの起動を行えます。 $ npm run build # ビルド（トランスパイル）の実行 $ npm start # ビルド済みプログラムの起動 $ npm run build:watch # watch モードでビルド（後述） ちなみに、npm start は npm run start のエイリアスです。 NPM スクリプトは、基本的に npm run スクリプト名 で起動するのですが、start スクリプトは頻繁に使用するので、このようなエイリアスで起動できるようになっています。 tsc コマンドをターミナルから実行するときは npx tsc と npx 経由で実行していましたが、NPM スクリプト内では npx を省略することができます。 （応用）TypeScript コードの変更を監視する (tsc: watch) tsc: watch 上記の説明では、Ctrl + Shift + B から tsc: build というビルドタスクを実行して TypeScript コードをトランスパイルしましたが、代わりに tsc: watch というビルドタスクを実行すると、TypeScript ファイル (.ts) の変更を監視する watch モードに入ります。 これは、コマンドラインから下記のように、tsc --watch を起動するのと同様です。 $ npx tsc --watch 前述のように、package.json 内の NPM スクリプトとして build:watch を定義している場合は、次のように起動することもできます。 $ npm run build:watch この watch モードに入ってから、TypeScript ファイルを編集して Ctrl + S で保存すると、その度に自動的に JavaScript ファイルへのトランスパイル (tsc) が実行されます。 VS Code 上で tsc: watch を起動すると、ターミナルが tsc watch によって占有されたように見えますが、実は新しい起動したターミナル上で実行されています。 別のコマンド (node build/main.js など）を入力したくなったら、ドロップダウンリストから使用するターミナルを切り替えれば実行できます。 あるいは、Ctrl + Shift + ` と入力して新しいターミナルを開くこともできます。 nodemon さらに、Node.js でサーバープログラムを開発している場合は、 nodemon コマンドを使って Node サーバーを起動しておくと、JS コードが生成されるたびに自動的にサーバーを再起動してくれるので、開発効率がすごく上がります。 $ nodemon build/index.js 参考: nodemon で Node.js サーバの再起動を自動化する | まくまくNode.jsノート VS Code のターミナルを分割して効率化 VS Code のターミナル上で tsc --watch などの監視ビルドを起動すると、別のコマンドを実行するときにターミナルを切り替えないといけないので面倒です。 そんなときは、ターミナルの分割機能 (Cmd + \\ ) を使って、一方を監視ビルド用、もう一方を別のコマンド実行用（npm start など）に使うと便利です。 これで、.ts ファイルを修正したときに左側のペインで自動ビルド結果を確認しつつ、必要に応じて右側のペインでアプリを起動する、といったことが可能になります。"
},
{
url: "/p/onvso3a/",
title: "Jadeメモ: jade コマンドの使い方",
date: "2013-12-30T00:00:00Z",
body: "Jadeメモ: jade コマンドの使い方 jade コマンドで HTML を生成する コマンドラインから jade コマンドを実行するには下記のようにします。 いずれの場合も index.jade ファイルの内容から HTML を生成します。 $ jade index.jade # index.html を作成 $ jade \u0026lt; index.jade # 標準出力へ HTML を出力 $ jade --pretty \u0026lt; index.jade # 改行を追加して見やすく出力 テスト 実際に index.jade というファイルから、HTML を生成してみます。 index.jade doctype html html body h1 Hello World jade コマンドの実行 $ jade \u0026lt; index.jade \u0026lt;!DOCTYPE html\u0026gt;\u0026lt;html\u0026gt;\u0026lt;body\u0026gt;\u0026lt;h1\u0026gt;Hello World\u0026lt;/h1\u0026gt;\u0026lt;/body\u0026gt;"
},
{
url: "/p/ffyw55u/",
title: "gnuplot: 2次元プロットの基本",
date: "2004-01-03T00:00:00Z",
body: "gnuplot: 2次元プロットの基本 関数をプロットする Syntax plot \u0026lt;expression\u0026gt; [with \u0026lt;line_style\u0026gt;] line_style 一覧 lines \u0026ndash; 線だけ (関数をプロットする時のデフォルト) points \u0026ndash; 記号だけ (ファイルのデータをプロット時のデフォルト) linespoints \u0026ndash; 線と点 例: y = 0.5x \u0026#43; 1 plot 0.5*x + 1 複数の関数をプロットする Syntax plot \u0026lt;expression\u0026gt; [, \u0026lt;expression\u0026gt;...] 複数のグラフを重ねたい場合は、 plot の後ろにカンマ (,) で区切って関数を並べます。 一行が長くなってしまう場合は \\ の次に改行すれば複数行に渡ってコマンドを書くことができます。 最後に実行した plot を再び実行する Syntax replot [\u0026lt;expression\u0026gt;] replot と入力すると、最後にプロットしたグラフを再表示します。 replot の引数に別の関数を指定すれと、 最後に実行した plot の出力に重ねてグラフを表示することができます。 連続して replot を実行すればどんどんグラフが重なっていきます。 replot は主に環境設定を変更した際に使用します。 例: sin(x) と cos(x) と tan(x) を重ねたグラフを描画 plot sin(x) replot cos(x) replot tan(x) 次のようにしても同じ plot sin(x), cos(x), tan(x) ファイルのデータをプロットする Syntax plot \u0026#39;\u0026lt;filename\u0026gt;\u0026#39; [with \u0026lt;line_style\u0026gt;] 例: ファイルからデータを読み込んで表示 plot \u0026#39;sample.dat\u0026#39; with linespoints # x y 10 412.4 20 234.2 40 301.3 1行に1つの点を表す座標を書きます。 データは空白かタブで区切ります。 # 以降その行はコメントと見なされます。 データの間に空行を入れると、空行で分けられた点と点はプロットした際に線で結ばれなくなります。 ファイル内の複数のデータをプロットする plot \u0026#34;test.dat\u0026#34; using 1:2 with lines,\\ \u0026#34;test.dat\u0026#34; using 1:3 with lines,\\ \u0026#34;test.dat\u0026#34; using 1:4 with lines test.dat # x y1 y2 y3 1 0 0 0 2 14 19 24 3 50 60 70 x 座標を共有する、複数のデータをまとめて上のようなフォーマットで記述することができます。 using 1:2 は 1 列目のデータ (x) と、 2 列目のデータ (y1) を使用することを示しています。 つまり、上の例では 3 本の線が引かれることになります。 プロットデータを直接入力する Syntax plot \u0026#39;-\u0026#39; [with line_style] [x1] y1 [x2] y2 [x3] y3 : e x 座標を省略すると、0, 1, 2 \u0026hellip; が指定されたと見なされます。 例 plot \u0026#39;-\u0026#39; with linespoints 0 0 1 12 2 34 3 20 e"
},
{
url: "/p/xjw8it5/",
title: "Next.js アプリのソースコードを GitHub で管理する",
date: "2021-04-24T00:00:00Z",
body: "Next.js アプリのソースコードを GitHub で管理する Next.js のプロジェクトは、create-next-app コマンドで作成済みであるとします。 参考: Next.js で HelloWorld create-next-app コマンドで Next.js アプリを新規作成すると、アプリのトップディレクトリに、Git リポジトリ (.git/) が自動的に生成されます。 git log コマンドを実行すると、初回のコミットがすでに生成されていることがわかります。 $ git log commit 4607ecdd2f3f9f3d0d4c86442463c3b86856e88a (HEAD -\u0026gt; main) Author: maku \u0026lt;maku@example.com\u0026gt; Date: Sun Apr 18 23:28:22 2021 +0900 Initial commit from Create Next App この Next.js アプリを GitHub で管理したいときは、以下の手順で GitHub リポジトリと結びつけます。 GitHub 上に 新規リポジトリを追加 します リポジトリ名は create-next-app で指定したアプリ名と合わせましょう。 Initialize this repository with: の項目では、README.txt の作成にはチェックを入れないでください。リポジトリファイル (.git) はすでに create-next-app によって生成されているので、GitHub 側のリポジトリは空の状態で作成する必要があります。 既存の Next.js アプリを上記の GitHub リポジトリに結びつけます $ cd myapp $ git remote add origin https://github.com/\u0026lt;username\u0026gt;/myapp.git 既存の Next.js アプリの内容（前述の初回コミット）をプッシュします $ git push -u origin main あとは、コード修正しながらコミット＆プッシュを繰り返し、Next.js アプリを育てていけば OK です。"
},
{
url: "/p/6pybmv6/",
title: "Electron で Hello World (3) React を使えるようにする",
date: "2020-07-03T00:00:00Z",
body: "Electron で Hello World (3) React を使えるようにする 概要 ここでは、Electron アプリの開発に React を導入する手順を示します。 React を導入すると、HTML をフラットな形でゴリゴリ記述していくのではなく、独自コンポーネント（例: \u0026lt;MyButton\u0026gt; コンポーネント）を定義して、まとまりのある単位でコンテンツを構築していくことができます。 下記の手順により、Electron + TypeScript による開発環境が構築できていることを前提とします。 Electron で Hello World (1) 最小構成で作る Electron で Hello World (2) TypeScript で開発できるようにする この記事の手順が完了すると、Electron + TypeScript + React による開発環境が整います。 一応 webpack などのバンドルツールを使わなくても開発を始められるので、Electron と React の開発環境としての相性はよさそうです。 React のセットアップ React モジュールのインストール React モジュールおよび、TypeScript 用の型定義ファイルをインストールします。 $ npm install --save react react-dom $ npm install --save-dev @types/react @types/react-dom package.json の内容は次のような感じになります。 package.json { \u0026#34;name\u0026#34;: \u0026#34;myapp\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;0.0.1\u0026#34;, \u0026#34;main\u0026#34;: \u0026#34;build/main.js\u0026#34;, \u0026#34;scripts\u0026#34;: { \u0026#34;build\u0026#34;: \u0026#34;tsc\u0026#34;, \u0026#34;start\u0026#34;: \u0026#34;tsc \u0026amp;\u0026amp; electron .\u0026#34; }, \u0026#34;devDependencies\u0026#34;: { \u0026#34;@types/node\u0026#34;: \u0026#34;^14.0.14\u0026#34;, \u0026#34;@types/react\u0026#34;: \u0026#34;^16.9.41\u0026#34;, \u0026#34;@types/react-dom\u0026#34;: \u0026#34;^16.9.8\u0026#34;, \u0026#34;electron\u0026#34;: \u0026#34;^9.0.5\u0026#34;, \u0026#34;typescript\u0026#34;: \u0026#34;^3.9.6\u0026#34; }, \u0026#34;dependencies\u0026#34;: { \u0026#34;react\u0026#34;: \u0026#34;^16.13.1\u0026#34;, \u0026#34;react-dom\u0026#34;: \u0026#34;^16.13.1\u0026#34; } } JSX コードの有効化 TypeScript の設定ファイル (tsconfig.json) を編集し、 .tsx ファイル内に記述した JSX コードを認識できるようにします。 JSX コードはトランスパイルによって、通常の JavaScript コードに変換されます。 tsconfig.json { \u0026#34;compilerOptions\u0026#34;: { \u0026#34;target\u0026#34;: \u0026#34;es6\u0026#34;, \u0026#34;module\u0026#34;: \u0026#34;commonjs\u0026#34;, \u0026#34;lib\u0026#34;: [\u0026#34;esnext\u0026#34;,\u0026#34;dom\u0026#34;], \u0026#34;outDir\u0026#34;: \u0026#34;build\u0026#34;, \u0026#34;rootDir\u0026#34;: \u0026#34;src\u0026#34;, \u0026#34;jsx\u0026#34;: \u0026#34;react\u0026#34;, // .tsx ファイル内の JSX を認識 \u0026#34;sourceMap\u0026#34;: true, \u0026#34;strict\u0026#34;: true, \u0026#34;esModuleInterop\u0026#34;: true, \u0026#34;skipLibCheck\u0026#34;: true, \u0026#34;forceConsistentCasingInFileNames\u0026#34;: true } } これだけで、Electron + TypeScript の開発環境上で React を使用できるようになります。 実装 React コンポーネント (Hello.tsx) src/components ディレクトリ以下に、独自の React コンポーネントを定義するための .tsx ファイルを格納することにします。 ここでは、Hello コンポーネントを作成します。 Hello 要素は、オプショナルな name 属性（プロパティ）を指定できるようにしてみます。 JSX 形式のコードを含むので、拡張子は .tsx にすることに注意してください（.jsx の TypeScript 版です）。 src/components/Hello.tsx import React from \u0026#39;react\u0026#39;; // Hello コンポーネントの属性（プロパティ） export interface HelloProps { name?: string; } // Hello コンポーネントの定義 export class Hello extends React.Component\u0026lt;HelloProps\u0026gt; { public render(): React.ReactNode { const name = this.props.name ?? \u0026#39;Mr. Unknown\u0026#39;; return ( \u0026lt;h1\u0026gt;Hello {name} in Electron\u0026lt;/h1\u0026gt; ); } } レンダラープロセス (renderer.tsx) 上記で定義した Hello コンポーネントを表示するためのレンダラープロセスを実装します。 ここでも JSX コードを使うので、拡張子は .tsx を使います。 src/renderer.tsx import * as React from \u0026#39;react\u0026#39;; import * as ReactDOM from \u0026#39;react-dom\u0026#39;; import { Hello } from \u0026#39;./components/Hello\u0026#39;; ReactDOM.render( \u0026lt;Hello /\u0026gt;, document.querySelector(\u0026#39;#root\u0026#39;) ); このコードは、HTML 内の \u0026lt;div id=\u0026quot;root\u0026quot;\u0026gt; 要素の内容を、Hello コンポーネントが出力する内容に置き換えます。 パッと見、React クラスのインポートは不要に見えますが、JSX コードが React クラスを使うコードに変換されるので、インポートしておかないとコンパイルエラーになります。 次の HTML ファイルから、上記のスクリプトを読み込みます。 public/index.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Hello Electron!\u0026lt;/title\u0026gt; \u0026lt;!-- https://electronjs.org/docs/tutorial/security#csp-meta-tag --\u0026gt; \u0026lt;meta http-equiv=\u0026#34;Content-Security-Policy\u0026#34; content=\u0026#34;script-src \u0026#39;self\u0026#39; \u0026#39;unsafe-inline\u0026#39;;\u0026#34; /\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div id=\u0026#34;root\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;script\u0026gt;require(\u0026#39;../build/renderer.js\u0026#39;);\u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; メインプロセス (main.ts) 最後に、Electron アプリのエントリポイントとなるメインプロセス (main.ts) の実装です。 このコードは特に変更はなく、単純に public/index.html を読み込んで表示します。 src/main.ts import { app, BrowserWindow } from \u0026#39;electron\u0026#39;; // メインウィンドウの表示 function createWindow () { const options: Electron.BrowserWindowConstructorOptions = { width: 500, height: 200, webPreferences: { nodeIntegration: true // とりあえず import のため } } const win = new BrowserWindow(options); win.loadFile(\u0026#39;public/index.html\u0026#39;); } // Electron の初期化が完了したらウィンドウを作成 app.whenReady().then(createWindow);"
},
{
url: "/p/o8ufwct/",
title: "Azure Table Strage を使ってみる (3) Python からテーブル操作してみる",
date: "2020-01-29T00:00:00Z",
body: "Azure Table Strage を使ってみる (3) Python からテーブル操作してみる azure-cosmosdb-table パッケージのインストール Python から Azure Table Storage を操作するには、azure-cosmosdb-table というライブラリを使用します。 azure-cosmosdb-table のインストール $ pip install azure-cosmosdb-table ☝️ ワンポイント Cosmos DB をまったく使わない場合でも cosmosdb と名前のついたライブラリを使わせようとするのは、 Microsoft の策略 Cosmos DB に力を入れているという意思表示でしょう。 正直なところ Cosmos DB はお金がかかりすぎて個人の趣味レベルでは使えないのですが。。。 （追記: 2021年）CosmosDB に無料枠ができて少しずつ個人利用もできそうな感じになってきました。 TableService オブジェクトの生成 Azure Storage にアクセスするには、接続情報（ストレージアカウント名とキー）が必要になるので、Azure ポータル で確認しておいてください。 参考: Azure Storage の接続情報（キー）を確認する Table Storage にアクセスしてごにょごにょするには、TableService クラス のメソッドを使用します。 TableService のコンストラクタには、ストレージアカウント名とキーを渡します。 from azure.cosmosdb.table.tableservice import TableService STORAGE_NAME = \u0026#39;maku77storage\u0026#39; STORAGE_KEY = \u0026#39;XlgKN4Hv...(省略)...F55o3N9g==\u0026#39; table_service = TableService(account_name=STORAGE_NAME, account_key=STORAGE_KEY) ☝️ URL の指定は必要ない？ 接続先アドレス (URL) の構築は TableService クラスがよろしくやってくれるので、実装コードがとてもスッキリします。 ストレージアカウント名は Azure 内（世界中）で一意になっているので、ストレージアカウント名さえ指定すれば、Web API の URL も自動的に決まるということですね。 ストレージアカウントのキーを環境変数から取得する ストレージアカウントにアクセスするためのキー情報をスクリプト内にハードコーディングするのは望ましくないので、環境変数などから取得するようにしておくとよいでしょう。 環境変数から Azure Storage のアクセスキーを取得 import os import sys if \u0026#39;AZURE_STORAGE_KEY\u0026#39; not in os.environ: print(\u0026#39;Error: AZURE_STORAGE_KEY not found\u0026#39;, file=sys.stderr) sys.exit(1) storage_key = os.getenv(\u0026#39;AZURE_STORAGE_KEY\u0026#39;) プロキシ環境からアクセスする場合 TableService クラスをプロキシ環境内で使用する場合は、OS の https_proxy 環境変数で設定してしまうのが簡単です。 OS の https_proxy 環境変数を設定するのを避けたいときは、Python スクリプトの中からプロキシを設定してしまうこともできます。 プロキシ情報をハードコードする import os os.environ[\u0026#39;https_proxy\u0026#39;] = \u0026#39;http://proxy.example.com:12345\u0026#39; OS の https_proxy 環境変数を設定するのも嫌だし、Python スクリプト内にプロキシ情報をハードコードするのも嫌なときは、例えば、独自の AZURE_PROXY のような 独自の環境変数 を用意して、その値をプロキシ情報として使用するという方法があります。 AZURE_PROXY 環境変数の値をプロキシ情報として使う if \u0026#39;AZURE_PROXY\u0026#39; in os.environ: os.environ[\u0026#39;https_proxy\u0026#39;] = os.getenv(\u0026#39;AZURE_PROXY\u0026#39;) テーブルの操作 ここから先のテーブル操作に関しては、前述の TableService オブジェクトの生成が終わっていることを想定しています。 テーブルのリストを取得する (list_tables) Table Storage 上に存在するテーブルの一覧を取得するには、TableService クラスの list_tables() メソッド を使用します。 このメソッドの戻り値を for ループで処理すると、azure.cosmosdb.table.models.Table オブジェクトを 1 つずつ取り出すことができます。 テーブル名を示す name プロパティしかありませんが。。。 すべてのテーブルを列挙 for table in table_service.list_tables(): print(table.name) 仮に、books と todos というテーブルが作成済みであれば、次のように表示されます。 実行結果 books todos テーブルの存在を確認する (exist) Table Storage 上に、指定した名前のテーブルが存在するかどうかをチェックするには、TableService クラスの exists() メソッド を使用します。 if table_service.exists(\u0026#39;books\u0026#39;): print(\u0026#39;books テーブルが存在するよ\u0026#39;) テーブルを作成する (create_table) Table Storage 上に、新しいテーブルを作成するには、TableService クラスの create_table() メソッド を使用します。 テーブルの作成に成功すると True を返します。 result = table_service.create_table(\u0026#39;mytable\u0026#39;) if result: print(\u0026#39;テーブルを作成しました\u0026#39;) ☝️ ワンポイント テーブルのプロパティ（RDB のカラムに相当するもの）の指定がありませんが、プロパティはエンティティを追加するときに自動的に生成されるので、ここで指定しておく必要はありません。 テーブルを削除する (delete_table) Table Storage 上の、既存のテーブルを削除するには、TableService クラスの delete_table() メソッド を使用します。 テーブルを削除すると、そこに含まれているすべてのエンティティも削除されてしまうので注意してください。 table_service.delete_table(\u0026#39;mytable\u0026#39;) エンティティの操作 テーブルにエンティティを追加する (insert_xxx) 指定したテーブルにデータ（エンティティ）を追加するには、TableService クラスの下記のいずれかのメソッドを使用します。 同じキー情報を持つエンティティを追加しようとしたときの振る舞いだけが異なります。 insert_entity() テーブル内に既に同じ PartitionKey と RowKey を持つエンティティがある場合は、例外を発生します。 insert_or_merge_entity() テーブル内に既に同じ PartitionKey と RowKey を持つエンティティがある場合は、指定したプロパティだけ上書きされます（既存エンティティのプロパティとマージされる）。 insert_or_replace_entity() テーブル内に既に同じ ParitionKey と RowKey を持つエンティティがある場合は、指定したエンティティに置き換えられます。 これらのメソッドのパラメータはすべて同じで、追加先のテーブル名と、追加するエンティティを渡します。 insert_entity(table_name, entity, timeout=None) insert_or_merge_entity(table_name, entity, timeout=None) insert_or_replace_entity(table_name, entity, timeout=None) entity パラメータには、辞書オブジェクトか Entity クラス のオブジェクトを渡すことができます。 辞書でデータを指定する方法 book = { \u0026#39;PartitionKey\u0026#39;: \u0026#39;book\u0026#39;, # 必須のキー情報 \u0026#39;RowKey\u0026#39;: \u0026#39;0004\u0026#39;, # 必須のキー情報 \u0026#39;Title\u0026#39;: \u0026#39;雪男の秘密\u0026#39;, \u0026#39;Author\u0026#39;: \u0026#39;雪男\u0026#39; } table_service.insert_or_replace_entity(\u0026#39;books\u0026#39;, book) Entity オブジェクトでデータを指定する方法 from azure.cosmosdb.table.models import Entity book = Entity() book.PartitionKey = \u0026#39;book\u0026#39; # 必須のキー情報 book.RowKey = \u0026#39;0004\u0026#39; # 必須のキー情報 book.Title = \u0026#39;雪男の秘密\u0026#39; book.Author = \u0026#39;雪男\u0026#39; table_service.insert_or_replace_entity(\u0026#39;books\u0026#39;, book) 別に Entity オブジェクトを使ったところで型安全になるわけでもないので、辞書オブジェクトをそのまま使った方が楽かもしれません。 ☝️ 存在しないプロパティは自動で追加される insert 系メソッドでエンティティを追加するときに、テーブルにまだ存在しないプロパティを指定することもできます。 その場合、自動的にテーブルにそのプロパティが追加されるので、プロパティ名は間違えないように要注意です。 指定したキーのエンティティを取得する (get_entity) 取得したいエンティティのキー（PartitionKey と RowKey）が分かっている場合は、TableService クラスの get_entity() メソッド を使って Entity オブジェクトを取得することができます。 指定したキーのエンティティが見つからない場合は、例外が発生します。 book = table_service.get_entity( table_name=\u0026#39;books\u0026#39;, partition_key=\u0026#39;book\u0026#39;, row_key=\u0026#39;0004\u0026#39;) print(book.Title) print(book.Author) 特定のプロパティしか参照しないことが分かっている場合は、select パラメータでプロパティ名を列挙しておくと、通信量を節約することができます。 book = table_service.get_entity( table_name=\u0026#39;books\u0026#39;, partition_key=\u0026#39;book\u0026#39;, row_key=\u0026#39;0004\u0026#39;, select=\u0026#39;Title,Author\u0026#39;) # Title と Author プロパティだけ取得 指定したキーのエンティティを削除する (delete_entity) 指定したキー（PartitionKey と RowKey）のエンティティを削除するには、TableService クラスの delete_entity() メソッド を使用します。 指定したキーのエンティティが見つからない場合は、例外が発生します。 table_service.delete_entity( table_name=\u0026#39;books\u0026#39;, partition_key=\u0026#39;book\u0026#39;, row_key=\u0026#39;0004\u0026#39;) エンティティのリストを取得する (query_entities) テーブルから条件に一致するエンティティをすべて取得するには、TableService クラスの query_entities() メソッド を使用します。 条件なしで検索 books = table_service.query_entities( table_name=\u0026#39;books\u0026#39;, num_results=5) for book in books: print(book.Title, book.Author) 検索条件は、filter パラメータを使って指定することができます。filter パラメータには文字列でフィルタ条件を指定するのですが、どのようなフォーマットで指定すればよいかは、下記のサイトが参考になります。 参考: Querying tables and entities (REST API) - Azure Storage | Microsoft Docs 参考: Azure ストレージ テーブルの設計パターン | Microsoft Docs 例: PartitionKey が Python である filter パラメータに ParitionKey eq 'Python' と指定すると、PartitionKey が Python であるエンティティをすべて取得することができます。 python_books = table_service.query_entities( \u0026#39;books\u0026#39;, filter=\u0026#34;PartitionKey eq \u0026#39;Python\u0026#39;\u0026#34;) for book in python_books: print(book.Title, book.Author) 例: RowKey が 0002 より大きい filter パラメータに RowKey gt '0002' と指定すると、RowKey が 0002 よりも大きいエンティティのみを取得することができます。 filter 条件を指定して検索 books = table_service.query_entities( table_name=\u0026#39;books\u0026#39;, filter=\u0026#34;RowKey gt \u0026#39;0002\u0026#39;\u0026#34;) for book in books: print(book.Title, book.Author) へむの秘密 へむ ちいの秘密 ちい 雪男の秘密 雪男 バッチ処理化 複数のエンティティを追加したい場合などは、バッチ処理で行うようにすると、サーバーとの通信回数を減らすことができます。 バッチ処理を行うには、TableService クラスの batch() メソッド を使用します。 book1 = {\u0026#39;PartitionKey\u0026#39;: \u0026#39;book\u0026#39;, \u0026#39;RowKey\u0026#39;: \u0026#39;001\u0026#39;, Title: \u0026#39;Title1\u0026#39;} book2 = {\u0026#39;PartitionKey\u0026#39;: \u0026#39;book\u0026#39;, \u0026#39;RowKey\u0026#39;: \u0026#39;002\u0026#39;, Title: \u0026#39;Title2\u0026#39;} book3 = {\u0026#39;PartitionKey\u0026#39;: \u0026#39;book\u0026#39;, \u0026#39;RowKey\u0026#39;: \u0026#39;003\u0026#39;, Title: \u0026#39;Title3\u0026#39;} with table_service.batch(\u0026#39;books\u0026#39;) as batch: batch.insert_entity(book1) batch.insert_entity(book2) batch.insert_entity(book3)"
},
{
url: "/p/67swums/",
title: "gnuplot: 棒グラフのプロット (with boxes)",
date: "2004-01-18T00:00:00Z",
body: "gnuplot: 棒グラフのプロット (with boxes) 棒グラフをプロット 棒グラフをプロットしたい時は、ラインスタイルに boxes を指定します。 範囲とボックスの幅を指定しない場合は、隣のボックスとくっつくように表示されます。 例: 棒グラフのプロット plot \u0026#39;test.dat\u0026#39; with boxes test.dat 1 10 2 30 3 25 4 40 5 20 範囲を指定しないと、上のように見にくいグラフになってしまうので、棒グラフを表示する場合は範囲指定を行うか、マージンなどを設定するとよいです。 例: 範囲を指定してプロット plot [0:6] [0:50] \u0026#39;test.dat\u0026#39; with boxes 例: マージンを設定してプロット set yrange [0:] set offset 1, 1, 1, 0 # left, right, top, bottom の順 (後ろの方は省略できる) plot \u0026#39;test.dat\u0026#39; with boxes ボックスの幅を指定する Syntax set boxwidth \u0026lt;width\u0026gt; # ボックスの幅を指定 set boxwidth # ボックスの幅を自動調整に戻す 例: ボックスの幅を 0.7 にする set boxwidth 0.7 plot [0:6] [0:50] \u0026#39;test.dat\u0026#39; with boxes さらに、with lines で線を引いてやれば度数分布多角形を表示することができます。 例: 度数分布多角形を表示 (続けて実行すること) replot \u0026#39;test.dat\u0026#39; with lines 関数の棒グラフ表示 関数を棒グラフ表示することもできます （あんまり使い道ないかもしれないけど^^）。 例: sin(x) の棒グラフ表示 plot [-pi:pi] sin(x) with boxes 関数の棒グラフのボックス幅を変更する場合は、次のようにしてサンプル数を変更してやります（サンプル数のデフォルトは 100）。 ボックス間の隙間を開けることはできないみたいです（たぶん）。 例: サンプル数を 20 にした場合 set samples 20 plot [-pi:pi] sin(x) with boxes"
},
{
url: "/p/au8ju6g/",
title: "Next.js アプリを GitHub Actions でビルドして GitHub Pages で公開する",
date: "2021-04-24T00:00:00Z",
body: "Next.js アプリを GitHub Actions でビルドして GitHub Pages で公開する 何をするか？ ここでは、Next.js アプリを次のような構成でホスティング（Web サイトとして公開）できるようにします。 create-next-app で作成した Next.js アプリのコードを GitHub で管理する main ブランチにプッシュ（マージ）したら GitHub Actions で下記を実行 Next.js アプリをビルド (npm run build, npm run export) GitHub Pages にデプロイ つまり、この設定が終わると、GitHub に Next.js アプリのコードをプッシュするだけで、自動的にビルドされて、Web サイトに反映されるようになります。 GitHub リポジトリの準備 空の GitHub リポジトリを作成し、そこに create-next-app で作成した Next.js アプリをプッシュします。 リポジトリ名は、最終的な Web サイトのアドレスをどうしたいかで、次のように作り分けます。 ユーザーサイト（あるいは Organization サイト） 公開 URL: https://\u0026lt;username\u0026gt;.github.io/ 作成するリポジトリ名: \u0026lt;username\u0026gt;.github.io プロジェクトサイト 公開 URL: https://\u0026lt;username\u0026gt;.github.io/\u0026lt;repository\u0026gt;/ 作成するリポジトリ名: \u0026lt;repository\u0026gt; ここでは、プロジェクトサイトとして myapp というリポジトリを作成した場合の例で説明していきます。 $ npx create-next-app myapp $ cd myapp $ git remote add origin https://github.com/\u0026lt;username\u0026gt;/myapp.git $ git push -u origin main 上記のように実行すると、初期状態の Next.js アプリが GitHub にプッシュされます。 参考リンク Next.js アプリのソースコードを GitHub で管理する package.json および next.config.js の修正 package.json package.json を修正して、Next.js の静的 HTML のエクスポート機能 (next export) を NPM スクリプト経由で実行できるようにしておきます。 これは、後述の GitHub Actions のビルドスクリプトから npm run export で起動できるようにするためです。 ... \u0026#34;scripts\u0026#34;: { \u0026#34;dev\u0026#34;: \u0026#34;next dev\u0026#34;, \u0026#34;build\u0026#34;: \u0026#34;next build\u0026#34;, \u0026#34;export\u0026#34;: \u0026#34;next export\u0026#34;, // これを追加 \u0026#34;start\u0026#34;: \u0026#34;next start\u0026#34; } ... 修正したら、コミット＆プッシュしておきます。 $ git commit -m \u0026#34;Add export script\u0026#34; . $ git push next.config.js GitHub Pages のサイトを「プロジェクトサイト」として作成する場合、つまり、https://\u0026lt;username\u0026gt;.github.io/\u0026lt;repository\u0026gt;/ という URL で公開する場合は、トップページがドメインルートではなくなります。 そのままだと、Next.js アプリ内の JS ファイルや CSS ファイルが軒並み 404 Not Found になってしまうので、Next.js ビルド用に追加のプレフィックス設定 (assetPrefix) が必要です。 さらに、Link (next/link) や Router (next/router) によるリンクのベースパスとしては、basePath の設定の方が反映されるので、こちらも合わせて設定が必要です。 次の next.conf.js の記述例では、環境変数 URL_PREFIX が設定されているときに、その値を URL のプレフィックスとして使用するように設定しています（先頭にスラッシュ / を付けないとうまくいかないようなので注意）。 この環境変数は、後ほど GitHub Actions のビルドスクリプトの中で、リポジトリ名に合わせて設定します。 next.config.js（新規作成） const urlPrefix = process.env.URL_PREFIX ? \u0026#39;/\u0026#39; + process.env.URL_PREFIX : \u0026#39;\u0026#39; module.exports = { // ... assetPrefix: urlPrefix, basePath: urlPrefix, trailingSlash: true, // ... }; また、trailingSlash を true に設定しておくことで、pages/aaa.js というコードが、aaa.html というファイルではなく、aaa/index.html というファイルとして出力されるようになります。 これにより、Web ブラウザに直接 https://\u0026lt;username\u0026gt;.github.io/myapp/aaa/ といった URL を入力したときにも正しくページが表示されるようになります（Web ブラウザはこのような URL を入力すると、aaa/index.html を探しに行くので、aaa.html というファイルを配置するとうまく動作しません）。 トップページからリンクを辿っていくだけであればデフォルト状態でも動作するのですが、特定のページでリロードやブックマークできるようにするにはこの設定が必要です。 ちなみに、クライアントサイド JS からこういった URL プレフィックス情報を直接参照するには、ちょっとした工夫が必要です（Next.js の Image コンポーネントなどを使う場合は気にする必要はありません）。 参考: Next.js の public 以下のファイルのパスを正しく扱う GitHub Actions の設定 GitHub リポジトリのページで Actions タブを選択し、次のように新規ワークフローを作成します。 set up a workflow yourself をクリック YAML ファイルの編集画面になるので、次のように入力して Start commit をクリック 各ステップで何をしているかは、name プロパティを読めば大体わかると思います。 myapp/.github/workflows/main.yml name:Deploy Next.js appon:push:branches:[main ]pull_request:branches:[main ]jobs:build:runs-on:ubuntu-lateststeps:- name:Checkout repositoryuses:actions/checkout@v2- name:Setup Node.jsuses:actions/setup-node@v2with:node-version:14.x- name:Install NPM packagesrun:npm ci- name:Build Next.js apprun:npm run buildenv:URL_PREFIX:myapp- name:Export Next.js apprun:npm run export- name:Deploy to GitHub Pagesuses:peaceiris/actions-gh-pages@v3with:github_token:${{ secrets.GITHUB_TOKEN }}publish_dir:out npm run build の環境変数 URL_PREFIX の値 (myapp) は、GitHub リポジトリ名に合わせて修正してください。 この値は、前述の next.config.js の中で参照しています。 ただし、GitHub Pages をユーザーサイトとして作成している場合（リポジトリ名が \u0026lt;username\u0026gt;.github.io の場合）は、この環境変数は必要ありません。 肝心の GitHub Pages 用のデプロイには、actions-gh-pages を使用しています。 このアクションは、publish_dir で指定したディレクトリ（上記では out）の中身を、gh-pages ブランチにコミットしてくれます。 ここで out ディレクトリを指定しているのは、npm run export (next export) のデフォルトの出力先が out ディレクトリになっているからです。 main.yml のコミットが完了したら、自動的に GitHub Actions によるビルドが開始され、Actions タブからビルドの状況を確認できます。 数十秒くらいしてビルドが完了すると、GitHub リポジトリに gh-pages ブランチが生成されて、そこに Web サイトのコンテンツ（npm run export で生成した out ディレクトリの内容）が格納されていることを確認できます。 今後は、GitHub にソースコードをプッシュするたびに、このビルドプロセスが自動的に実行されます。 GitHub Pages を有効にする 最後に、GitHub Pages 機能を有効にして、gh-pages ブランチの内容を Web サイトの形で見えるようにします。 GitHub リポジトリのページから Settings → Pages と選択して GitHub Pages の設定画面を開きます Source の項目でブランチ gh-pages を選択して Save ボタンを押します Enforce HTTPS のチェックも入れておきましょう（http によるアクセスが自動で https にリダイレクトされます） しばらくして、https://\u0026lt;username\u0026gt;.github.io/myapp/ にアクセスして、Next.js アプリのトップページが表示されれば成功です！ 参考リンク GitHub Actions で Web サイトをビルドして GitHub Pages へ公開する"
},
{
url: "/p/ccoonon/",
title: "Azure Table Strage を使ってみる (4) Node.js からテーブル操作してみる",
date: "2020-01-31T00:00:00Z",
body: "Azure Table Strage を使ってみる (4) Node.js からテーブル操作してみる azure-storage パッケージのインストール Node.js から Azure Table Storage を操作するには、azure-storage というライブラリを使用します。 npm コマンドで簡単にインストールすることができます。 azure-storage のインストール $ npm install --save azure-storage 参考: npm によるパッケージのインストール | Node.js ノート TableService オブジェクトの生成 Azure Storage にアクセスするには、接続情報（ストレージアカウント名とキー）が必要になるので、Azure ポータル で確認しておいてください。 参考: Azure Storage の接続情報（キー）を確認する 接続情報としてデフォルトの環境変数を使用する Node.js から Table Storage を扱うには、azure-storage モジュールが提供する TableService クラス を使用します。 TableService のインスタンスは下記のように生成することができます。 const azure = require(\u0026#39;azure-storage\u0026#39;); const tableService = new azure.TableService(); 上記のように、TableService のコンストラクのパラメータを何も指定しないと、接続のために下記のような環境変数が参照されます。 AZURE_STORAGE_ACCOUNT \u0026hellip; Azure Storage の「ストレージアカウント名」 AZURE_STORAGE_ACCESS_KEY \u0026hellip; Azure Storage の「キー」 AZURE_STORAGE_CONNECTION_STRING \u0026hellip; Azure Storage の「接続文字列」 1 と 2 を両方とも設定するか、3 を設定しておけば Azure Storage にアクセスできるようになります。 接続情報を明示的に指定する TableService のコンストラクタの引数で、明示的に接続情報を渡すこともできます。 // 接続文字列だけを渡す場合 const tableService = new azure.TableService(connectionString); // ストレージアカウント名とキーのペアを渡す場合 const tableService = new azure.TableService(storageAccount, storageAccessKey); 複数のストレージアカウントを使い分けたい場合は、独自の環境変数に「接続文字列」を設定しておくとよいでしょう。 ここでは、MAKU_AZURE_STORAGE_CONNECTION_STRING という環境変数に「接続文字列」を設定してみます。 const azure = require(\u0026#39;azure-storage\u0026#39;); // Azure Storage の接続文字列を環境変数から取得 const connectionString = process.env.MAKU_AZURE_STORAGE_CONNECTION_STRING; if (typeof connectionString === \u0026#39;undefined\u0026#39;) { console.error(\u0026#39;MAKU_AZURE_STORAGE_CONNECTION_STRING is not set\u0026#39;); process.exit(1); } // TableService オブジェクトを取得 const tableService = new azure.TableService(connectionString); プロキシ環境からアクセスする場合 TableService クラスをプロキシ環境内で使用する場合は、OS の https_proxy 環境変数で設定してしまうのが簡単です。 OS の https_proxy 環境変数を設定するのを避けたいときは、TableService クラスの setProxy() メソッドを使ってプロキシを設定することもできます。 プロキシ情報をハードコードする tableService.setProxy(\u0026#39;http://proxy.example.com:12345\u0026#39;); プロキシ情報は環境変数で定義したいけど、OS の https_proxy 環境変数を設定するのは避けたいということであれば、例えば、独自の MAKU_AZURE_PROXY のような 独自の環境変数 を用意するとよいでしょう。 // MAKU_AZURE_PROXY 環境変数が設定されていたらプロキシ情報として使う if (process.env.MAKU_AZURE_PROXY) { tableService.setProxy(process.env.MAKU_AZURE_PROXY); } テーブルの操作 ここから先のテーブル操作に関しては、前述の TableService オブジェクトの生成が終わっていることを想定しています。 テーブルを作成する (createTable, createTableIfNotExists) Table Storage 上に、新しいテーブルを作成するには、TableService クラスの下記のメソッドを使用します。 createTable() メソッド createTableIfNotExists() メソッド mytable テーブルを作成する tableService.createTableIfNotExists(\u0026#39;mytable\u0026#39;, function(error, result, response) { if (error) { console.error(error); process.exit(1); } // result contains true if created; false if already exists console.log(result); }); 実行結果（テーブルが作成された場合） { isSuccessful: true, statusCode: 204, TableName: \u0026#39;mytable\u0026#39;, created: true } 実行結果（テーブルが既に存在していた場合） { isSuccessful: true, statusCode: 200, TableName: \u0026#39;mytable\u0026#39;, created: false } エンティティの操作 エンティティを取得する (queryEntities) 条件を指定してエンティティのリストを取得するには、TableService クラスの queryEntities() メソッド を使用します。 books テーブルのエンティティをすべて取得 tableService.queryEntities(\u0026#39;books\u0026#39;, null, null, function (error, result) { if (error) { console.error(error); process.exit(1); } const entries = result.entries; console.log(entries); }); 実行結果 [ { PartitionKey: { \u0026#39;$\u0026#39;: \u0026#39;Edm.String\u0026#39;, _: \u0026#39;book\u0026#39; }, RowKey: { \u0026#39;$\u0026#39;: \u0026#39;Edm.String\u0026#39;, _: \u0026#39;001\u0026#39; }, Timestamp: { \u0026#39;$\u0026#39;: \u0026#39;Edm.DateTime\u0026#39;, _: 2020-01-29T02:28:15.137Z }, Title: { _: \u0026#39;まくの秘密\u0026#39; }, Author: { _: \u0026#39;まく\u0026#39; }, \u0026#39;.metadata\u0026#39;: { etag: `W/\u0026#34;datetime\u0026#39;2020-01-29T02%3A28%3A15.1370872Z\u0026#39;\u0026#34;` } }, { PartitionKey: { \u0026#39;$\u0026#39;: \u0026#39;Edm.String\u0026#39;, _: \u0026#39;book\u0026#39; }, RowKey: { \u0026#39;$\u0026#39;: \u0026#39;Edm.String\u0026#39;, _: \u0026#39;002\u0026#39; }, Timestamp: { \u0026#39;$\u0026#39;: \u0026#39;Edm.DateTime\u0026#39;, _: 2020-01-29T02:29:48.875Z }, Title: { _: \u0026#39;へむの秘密\u0026#39; }, Author: { _: \u0026#39;へむ\u0026#39; }, \u0026#39;.metadata\u0026#39;: { etag: `W/\u0026#34;datetime\u0026#39;2020-01-29T02%3A29%3A48.8751116Z\u0026#39;\u0026#34;` } }, { PartitionKey: { \u0026#39;$\u0026#39;: \u0026#39;Edm.String\u0026#39;, _: \u0026#39;book\u0026#39; }, RowKey: { \u0026#39;$\u0026#39;: \u0026#39;Edm.String\u0026#39;, _: \u0026#39;003\u0026#39; }, Timestamp: { \u0026#39;$\u0026#39;: \u0026#39;Edm.DateTime\u0026#39;, _: 2020-01-29T02:30:28.677Z }, Title: { _: \u0026#39;ちいの秘密\u0026#39; }, Author: { _: \u0026#39;ちい\u0026#39; }, \u0026#39;.metadata\u0026#39;: { etag: `W/\u0026#34;datetime\u0026#39;2020-01-29T02%3A30%3A28.6771054Z\u0026#39;\u0026#34;` } } ] queryEntities() メソッドの第2パラメータに TableQuery オブジェクト を渡すと、エンティティを検索するための条件を指定することができます。 const query = new azure.TableQuery() .top(3) // 最大 3 件まで取得 .where(\u0026#39;PartitionKey eq ?\u0026#39;, \u0026#39;book\u0026#39;) // PartitionKey が book である .and(\u0026#39;RowKey \u0026gt;= ?\u0026#39;, \u0026#39;2\u0026#39;) // かつ RowKey が 002 以上である .select(\u0026#39;Title\u0026#39;) // Title プロパティのみを取得 tableService.queryEntities(\u0026#39;books\u0026#39;, query, null, function (error, result) { if (error) { console.error(error); process.exit(1); } const entries = result.entries; console.log(entries); }); 実行結果 [ { Title: { _: \u0026#39;へむの秘密\u0026#39; }, \u0026#39;.metadata\u0026#39;: { etag: `W/\u0026#34;datetime\u0026#39;2020-01-29T02%3A29%3A48.8751116Z\u0026#39;\u0026#34;` } }, { Title: { _: \u0026#39;ちいの秘密\u0026#39; }, \u0026#39;.metadata\u0026#39;: { etag: `W/\u0026#34;datetime\u0026#39;2020-01-29T02%3A30%3A28.6771054Z\u0026#39;\u0026#34;` } } ]"
},
{
url: "/p/awbbari/",
title: "gnuplot: 三次元プロットの基本",
date: "2004-01-03T00:00:00Z",
body: "gnuplot: 三次元プロットの基本 三次元グラフの表示 Syntax splot \u0026lt;expression\u0026gt; 例: z = x2 \u0026#43; 10y splot x**2 + 10*y メッシュの細かさを指定する Syntax set isosample \u0026lt;x_rate\u0026gt;, \u0026lt;y_rate\u0026gt; デフォルトの細かさは 10, 10 です。 例: メッシュの細かさを 20, 20 にする set isosample 20, 20 等高線を表示する Syntax set contour 例: z = -x2-y2 の等高線を表示 set contour splot -x**2 - y**2"
},
{
url: "/p/ncyuy3e/",
title: "gnuplot: 実行したコマンドのファイルへの保存・読み込み",
date: "2004-01-03T00:00:00Z",
body: "gnuplot: 実行したコマンドのファイルへの保存・読み込み 実行したコマンドをファイルへ保存 Syntax save \u0026#39;\u0026lt;filename\u0026gt;\u0026#39; 今まで実行したコマンドをファイルに保存したい場合は、save を使います。 ファイルの拡張子には .plt をつけることが多いみたいです。 上書きのチェックはしてくれないので注意してください。 例: sample.plt にコマンドを保存 save \u0026#39;sample.plt\u0026#39; ファイルからコマンドを読み込み Syntax load \u0026#39;\u0026lt;filename\u0026gt;\u0026#39; 逆に保存したファイルを読み込んで実行するには、load を使います。 例: sample.plt を実行 load \u0026#39;sample.plt\u0026#39;"
},
{
url: "/p/ojm4was/",
title: "gnuplot: 画像ファイルへの保存",
date: "2004-01-03T00:00:00Z",
body: "gnuplot: 画像ファイルへの保存 GIF で出力 Syntax set terminal gif [transparent] [interlace] [font_size] [size x, y] [bg_color] [border_color] [axes_color] [line1_color line2_color ...] set terminal gif のオプション optionvalueDefaultdescription transparenttransparent | なしなし背景を透過するか interlaceinterlace | なしなしインターレースにするか font_sizesmallsmall6x12 medium7x13 (Bold) large8x16 sizesize \u0026lt;x\u0026gt;, \u0026lt;y\u0026gt;640, 480画像の幅と高さ bg_color\u0026lt;xRRGGBB\u0026gt;xFFFFFF (白)背景色 border_color\u0026lt;xRRGGBB\u0026gt;x000000 (黒)枠の色 axes_color\u0026lt;xRRGGBB\u0026gt;xCCCCCC (灰)軸の色 lineX_color\u0026lt;xRRGGBB\u0026gt;xFF0000 (赤)x00FF00 (緑)x0000FF (青)線の色を順に指定 例: test.gif に出力する設定 set terminal gif size 400, 300 set output \u0026#39;test.gif\u0026#39; 例: test.gif に出力する設定（白色を透過） set terminal gif size 400, 300 transparent xffffff set output \u0026#39;test.gif\u0026#39; これに続けて plot すれば、カレントディレクトリ (pwd で確認できます) に GIF ファイルが作成されます。 画面で出力を確認しておいてから出力先をファイルに変更し、replot を実行するのがおすすめです。 PostScript 形式で出力 Syntax set terminal postscript {\u0026lt;mode\u0026gt;} {\u0026lt;enhancement\u0026gt;} {\u0026lt;color\u0026gt;} {\u0026lt;lineStyle\u0026gt;} {\u0026lt;duplexing\u0026gt;} {\u0026#34;\u0026lt;fontName\u0026gt;\u0026#34;} {\u0026lt;fontSize\u0026gt;} set terminal postscript のオプション OptionValueDefaultDescription \u0026lt;mode\u0026gt; landscape | portrait | eps | default landscape グラフのモード。向きなどを指定する。 \u0026lt;enhancement\u0026gt; enhanced | noenhanced | plus | noplus noenhanced 拡張ポストスクリプトを有効にするか無効にするか。 \u0026lt;color\u0026gt; color | monochrome monochrome カラーで出力するかモノクロで出力するか。 \u0026lt;lineStyle\u0026gt; dashed | solid dashed グラフのラインに破線を使うか全て実線にするか。 \u0026lt;duplexing\u0026gt; defaultplex | simplex | duplex defaultplex 片面印刷か両面印刷か。 \u0026quot;\u0026lt;fontName\u0026gt;\u0026quot; \u0026quot;Times-Roman\u0026quot; など \u0026quot;Helvetica\u0026quot; PS で使用できるフォントを指定。 \u0026lt;fontSize\u0026gt; 12 など 14 フォントのポイント数。 EPS で出力 例: 白黒で EPS ファイルに出力する設定 set term postscript eps enhanced set output \u0026#39;test.eps\u0026#39; 例: カラーで EPS ファイルに出力する設定 set term postscript eps enhanced color set output \u0026#39;test.eps\u0026#39; 例: 論文用の EPS ファイルを出力する設定 # set term postscript eps plusset term postscript eps enhanced set size 0.6,0.6 set lmargin 8 set bmargin 3 set rmargin 2 set tmargin 1 set output \u0026#34;fig1.eps\u0026#34; 論文用の EPS ファイルを作成する場合は、マージンやサイズを変更しないといけないかもしれません。 LaTeX に epsfig で EPS ファイルを貼るときは、普通に plot すると文字が小さくて読めないので、LaTeX のほうでは \\epsfig{file=data.eps, scale=1.5} くらいにするといいです。 思い通りの大きさにするには、gnuplot のほうでも set size を指定してください。 コラム: EPS ファイルを直接編集してポイント（記号）の大きさを変える 記号の横と縦のサイズは /hpt_ と /vpt_ で定義されています。 サイズを大きくした場合は、ここの数字を大きい値に変更します。 EPS ファイルの 17, 18 行目くらい /hpt_ 31.5 def % 横のサイズ /vpt_ 31.5 def % 縦のサイズ"
},
{
url: "/p/taiqx6d/",
title: "TypeScript で AWS SDK を使う開発環境を整える",
date: "2021-02-25T00:00:00Z",
body: "TypeScript で AWS SDK を使う開発環境を整える TypeScript のプロジェクトを作成する 何をできるようにするか？ ここでは、Node.js はインストール済みであるという前提で、次のようなことを行える TypeScript 環境を整えます。 npm run build で src ディレクトリ以下の .ts ファイルをコンパイルする （.js ファイルが build ディレクトリ以下に出力される） npm start でコンパイルされた build/main.js を起動する 下記のセットアップ手順の 詳しい意味はこちらを参照 していただくとして、ここでは一気にセットアップを終わらせてしまいます。 セットアップ # アプリ用のディレクトリを作成 $ mkdir myapp $ cd myapp # Node.js アプリの設定ファイル (package.json) を生成 $ npm init -y # TypeScript および Node 型情報をインストール $ npm install typescript -D $ npm install @types/node -D # TypeScript の設定ファイル (tsconfig.json) を生成 $ npx tsc --init package.json を次のような感じで修正します。 主に scripts の定義です。 package.json { \u0026#34;name\u0026#34;: \u0026#34;myapp\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1.0.0\u0026#34;, \u0026#34;scripts\u0026#34;: { \u0026#34;start\u0026#34;: \u0026#34;node build/main.js\u0026#34;, \u0026#34;build\u0026#34;: \u0026#34;tsc\u0026#34;, \u0026#34;build:watch\u0026#34;: \u0026#34;tsc --watch\u0026#34; }, \u0026#34;devDependencies\u0026#34;: { \u0026#34;@types/node\u0026#34;: \u0026#34;^14.14.31\u0026#34;, \u0026#34;typescript\u0026#34;: \u0026#34;^4.2.2\u0026#34; } } tsconfig.json を次のような感じで修正します。 主に、outDir と include の調整です。 tsconfig.json { \u0026#34;compilerOptions\u0026#34;: { \u0026#34;target\u0026#34;: \u0026#34;ES2018\u0026#34;, \u0026#34;module\u0026#34;: \u0026#34;commonjs\u0026#34;, \u0026#34;strict\u0026#34;: true, \u0026#34;esModuleInterop\u0026#34;: true, \u0026#34;skipLibCheck\u0026#34;: true, \u0026#34;forceConsistentCasingInFileNames\u0026#34;: true, \u0026#34;outDir\u0026#34;: \u0026#34;./build\u0026#34;, }, \u0026#34;include\u0026#34;: [\u0026#34;./src/**/*\u0026#34;] } これで、基本的な環境構築は完了です。 動作確認 TypeScript で HelloWorld を実行してテストします。 src ディレクトリ以下に次のような main.ts ファイルを作成してください。 src/main.ts console.log(\u0026#39;Hello World\u0026#39;); 次のようにビルドして、起動できることを確認します。 $ npm run build $ npm start build/main.js が実行されて、Hello World と表示できれば成功です。 あとは、必要に応じて AWS SDK のパッケージをインストールして、TypeScript でプログラムを作成していきます。 例えば、S3 や DynamoDB サービスを使うプログラムを作成するのであれば、次のようにライブラリをインストールします。 $ npm install @aws-sdk/client-s3 $ npm install @aws-sdk/client-dynamodb ☝️ AWS SDK は devDependencies でインストールすべき？ npm install で NPM パッケージをインストールするとき、実行時に必要なものは --save で、開発時のみ必要なものは --save-dev でインストールします。 この考え方からすると、AWS SDK (@aws-sdk) は --save オプションでインストールするのが自然なのですが、Lambda 関数用のプロジェクトではちょっと事情が違ってきます。 なぜなら、AWS の Lambda 実行環境にはデフォルトで AWS SDK がインストールされているからです。 AWS SDK を --save と --save-dev のどちらでインストールすべきかは、そのプロジェクトでデプロイ用の ZIP パッケージをどう作成するかによっても変わってきます（パッケージングするときに @aws-sdk パッケージを含めないようにするのであれば、--save でインストールしても問題ない）。 よく分からないときは、ZIP パッケージの肥大化を防ぐため、AWS SDK はとりあえず --save-dev でインストールしておくのがよいと思います。 参考: Lambda にデプロイするための ZIP パッケージを npm で作成する （おまけ）AWS SDK Version 2 ではなく Version 3 を使う Node.js 用の AWS SDK は 2020年12月に Version 3 が公開されました。 世の中には Version 2 のコードがあふれていますが、Version 3 には次のような利点があります。 使用する AWS サービスのパッケージだけを個別にインストール／インポートできる Version 2 では、aws-sdk パッケージでたくさんのパッケージを丸ごとインポートしていた Version 3 では、例えば DynamoDB だけを使うのであれば、@aws-sdk/client-dynamodb だけインポートする → バンドルサイズを小さくでき、インポート時のオーバーヘッドも減らせる ミドルウェアの仕組みを利用できる 例えば、全てのリクエストをフックして、任意のヘッダを付加することができる デフォルトで TypeScript に対応 例えば、TypeScript コードから @aws-sdk/client-s3 をインポートすると、型付けされた S3 用クラスを扱える Version 2 と 3 では、パッケージのインポート方法も次のように異なっています。 Version 3 のパッケージ名には、先頭に @ が付くので簡単に判別できます（@aws-sdk というプレフィックスは、AWS SDK チームが開発したパッケージであることを示しています）。 Version 2（古い） // SDK 全体のインポート import * as AWS from \u0026#39;aws-sdk\u0026#39;; // モジュールを個別にインポート import { DynamoDB } from \u0026#39;aws-sdk\u0026#39;; Version 3（新しい） // DynamoDB クライアントを使用する（V3 のコマンドベースの API (send) を使う場合） import { DynamoDBClient, ListTablesCommand } from \u0026#39;@aws-sdk/client-dynamodb\u0026#39;; // DynamoDB を使用する（V2 のような API を使う場合） import { DynamoDB } from \u0026#39;@aws-sdk/client-dynamodb\u0026#39;; 今から AWS SDK for JavaScript (Node.js) を使う場合は、余計なオーバーヘッドを防ぐためにも、Version 3 の方を使い、XxxxClient のようなクラスを個別にインポートする 方法をお勧めします。 さらに、デフォルトで TypeScript の型情報が提供されているので、できるだけ TypeScript でコーディングするようにしましょう。 参考リンク DynamoDB を Node.js (AWS SDK) で操作する"
},
{
url: "/p/j6ht5fq/",
title: "Next.js アプリを Vercel で公開する",
date: "2021-05-07T00:00:00Z",
body: "Next.js アプリを Vercel で公開する Vercel とは？ Vercel は Next.js を開発している企業であり、同名の Vercel というサービスを提供しています。 Vercel - Develop. Preview. Ship. For the best frontend teams Vercel サービスは Next.js アプリのホスティングに特化しており、GitHub などのリポジトリと連携させることにより、ビルドから Next.js サーバーによるホスティングまでを簡単に自動化することができます（実際には、Vercel サービスは、Next.js 以外で作成した Web サイト、例えば、Hugo で作成したブログなどのホスティングにも対応しています）。 Next.js アプリで SSR (Server-side Rendering) や API ルートなどの機能を使用している場合は、Next.js サーバー上で Web サイトをホスティングする必要があるのですが、現状そのような環境をサーバーレスなサービスとして提供しているのは Vercel のみです（一応 Serverless Next.js という AWS Lambda で動かすものもあったりしますが）。 Next.js の開発サーバー (next dev) で何らかのアプリをローカルで動かせているのであれば、Vercel を使って、ほぼそのままの形でネット上に公開することができます。 小規模な Web サイトであれば無料で動かせますし、とっても簡単なので、一度試してみるとよいです。 Vercel で Next.js アプリを公開する ここでは、GitHub にプッシュした Next.js アプリを Vercel を使って公開してみます。 まずは、下記を参考にして、GitHub に何らかの Next.js コードをプッシュしてください（といっても create-next-app で生成したコードをそのままプッシュするだけで OK です）。 Next.js アプリのソースコードを GitHub で管理する Vercel のアカウントを作成する 下記のページから、Vercel のアカウントを作成します。 メールアドレスでサインアップしてもいいですが、どうせ GitHub を使うので、Continue with GitHub を選択すればいいでしょう。 クレジットカード登録などは必要ありませんが、スマホのショートメッセージによる認証だけ必要です。 Sign Up – Vercel GitHub リポジトリと連携させる 下記のページから、Next.js アプリの GitHub リポジトリを登録します。 New Project – Vercel ここで、ビルドに使用するコマンド（デフォルトは npm run build）や、環境変数の設定などを行うことができます。 特に設定の必要がなければ、そのまま Deploy ボタンを押すと、リポジトリのクローンとビルドが始まります。 しばらくすると、次のような画面が表示されて、Web サイトが公開されます。 Congratulations! Visit ボタンを押すと、公開された Web サイトを開くことができます。 URL は、https://\u0026lt;AppName\u0026gt;-\u0026lt;AccountName\u0026gt;.vercel.app/ のような感じになりますが、独自ドメインの設定も可能です。 トピックブランチによるプレビューサイト生成 Vercel は GitHub リポジトリにブランチが作成されると、そのブランチのコードをビルドして、プレビュー用のサイトを生成してくれます (Preview Deployment)。 プレビュー用の URL は、https://\u0026lt;AppName\u0026gt;-\u0026lt;Hash値\u0026gt;-\u0026lt;AccountName\u0026gt;.vercel.app/ のようなテンポラリ URL になります（ブランチ名を含むエイリアス URL も作られたりします）。 生成されたプレビューサイトの一覧は、Vercel プロジェクトの Preview Deployments や、GitHub リポジトリの Deployments (Environments) から確認できます。 さらに、GitHub 上でこのブランチの PullRequest を作成すると、Vercel のボットが自動的にプレビューサイトの URL をコメント記入してくれます。 なので、基本的にはすべて GitHub から辿ることができます。 Vercel は、このプレビューを利用したサイト公開までのフローを、DPS ワークフロー と読んでいます（Vercel のトップページで）。 D: Develop \u0026hellip; 開発サーバー (next dev / vercel dev) での開発 P: Preview \u0026hellip; プレビューサイトでの確認（と PullRequest レビュー） S: Ship \u0026hellip; 本番環境へ公開（main ブランチへのマージ） 公開中の Web サイトの内容をいきなり変更するのが心配な場合は、まずはトピックブランチの作成＆プレビューサイトによる確認を行ってから、main ブランチにマージするのがよいでしょう。"
},
{
url: "/p/9vakw8i/",
title: "Vercel のウェブサイトに独自ドメインを割り当てる",
date: "2021-05-07T00:00:00Z",
body: "Vercel のウェブサイトに独自ドメインを割り当てる Vercel で公開している Web サイトに、お名前.com で取得した独自ドメインを割り当てる方法を説明します。 Vercel 上での Next.js アプリ公開までの手順は、下記の記事を参考にしてください。 参考: Next.js アプリを Vercel で公開する ここでは、独自ドメインを「お名前.com」で取得済みだと仮定しますが、別のレジストラで取得している場合もほぼ同様に設定できるはずです。 大きく分けて、次の 2 種類の設定方法があります。 Vercel の DNS サーバーを使う方法 Vercel 以外の DNS サーバーを使う方法 独自ドメインの「レジストラ」と「DNS サーバー」の関係については、下記の記事で簡単にまとめていますので参考にしてください。 後述の設定で何をしているのかが分かりやすくなると思います。 参考リンク ドメイン管理と DNS 管理の違いを理解する Vercel の DNS サーバーを使う方法 お名前.com などのレジストラで独自ドメインを取得すると、そのドメインをどの DNS サーバーで運用するかという設定を行えるはずです。 次のように Vercel 側の DNS サーバー設定を行うと、お名前.com 側に設定すべき DNS サーバー名を確認できます。 (1) Vercel のサイト から対象アプリのページを開き、Settings → Domains と選択し、取得済みの独自ドメイン名を入力して Add ボタンを押してください。ここでは、例として example.com というドメインを管理するとします（ドメイン自体は「お名前.com」で取得したものです）。 図: Vercel に独自ドメインを設定する (2) example.com に加えて www.example.com もエイリアスとして設定するかというダイアログが出ますが、example.com だけでよければ、Add example.com を選択すれば　OK です。 (3) Vercel にドメインが登録されて、一時的に Invalid Configuration の状態になります。ここで、Nameservers を選択すると、お名前.com 側に設定すべき DNS サーバーアドレスが分かります。下の図のように、Vercel の DNS サーバーは、ns1.vercel-dns.com と ns2.vercel-dns.com であることが分かります。 図: Vercel の DNS サーバーアドレス あとは、お名前.com 側にこのアドレスを設定してやれば OK です。 お名前.com Navi にログインして、ドメイン → 利用ドメイン一覧 → ネームサーバー のような感じで辿ると、外部の DNS サーバーを設定できるはずです。 DNS のレコード設定をしてしばらく待つと、次のように Invalid Configuration だったところが Valid Configuration の表示に代わり、独自ドメインを使って Web サイトにアクセスできるようになります。 図: Vercel の独自ドメイン設定完了！ 参考リンク お名前.com - DNS設定の変更手続きをしてから有効になるまでの期間は？） DNS Checker（DNS 設定がどれだけ伝搬しているかの確認） Vercel 以外の DNS サーバーを使う方法 すでにどこかの DNS サーバーでドメインを管理している場合は、そこに Vercel サーバーのアドレスを A レコード（ドメイン名 → IP アドレスのマッピング）として登録するという方法が使えます。 登録すべき A レコードの情報は、Vercel サーバー側で次のように設定すると確認できます。 (1) Vercel の対象アプリのページを開き、Settings → Domains と選択し、取得済みの独自ドメイン名を入力して Add ボタンを押してください。ここでは、例として example.com というドメインを管理するとします（ドメイン自体は「お名前.com」で取得したものです）。 図: Vercel に独自ドメインを設定する (2) example.com に加えて www.example.com もエイリアスとして設定するかというダイアログが出ますが、Add example.com を選択すれば　OK です。 (3) 一時的に Invalid Configuration の状態になり、DNS サーバーに設定すべき A レコードの値を確認できます（A レコードとして 76.76.21.21 を設定すればいいことが分かります）。 図: DNS サーバーに設定すべき値 example.com ではなく、myapp.example.com のようなサブドメインを割り当てることも可能です。 その場合は、A レコードの代わりに次のように CNAME が表示されます。 あとは、DNS サーバー側に上記のレコード情報（A レコード or CNAME レコード）を登録をするだけですが、この設定画面は使っているサービスによって UI が異なるので、詳しくはそのサービスのマニュアルに従ってください。 例えば、お名前.com の DNS サーバー（01.dnsv.jp など）を使っている場合は、お名前.com Navi にログインして、次のような感じで辿れば設定できるはずです。 トップメニューから DNS → ドメインのDNS設定 を選択 サイドバーから ネームサーバーの設定 → DNS設定/転送設定 を選択 DNSレコード設定を利用する の 設定する ボタンを押す 図: お名前.com の DNS サーバーの設定画面 ☝️ お名前.com のレンタルサーバーの DNS を使っている場合 すでにお名前.com のレンタルサーバを使って Web サイトを運用している場合は、おそらくレンタルサーバー側の DNS サーバー（dns01.gmoserver.jp など）を使う設定になっています。その場合は、上記の画面からではなく、レンタルサーバーのコントロールパネル の「独自ドメイン設定」メニューから DNS レコード設定を行う必要があります。 DNS のレコード設定をしてしばらく待つと、次のように Invalid Configuration だったところが Valid Configuration の表示に代わり、独自ドメインを使って Web サイトにアクセスできるようになります。 図: Vercel の独自ドメイン設定完了！ DNS の設定がどれだけ早く反映されるかに依存しますが、私の場合は数分で全ての設定が反映されました。 最初に生成された xxxxx.vercel.app を削除する 独自ドメインの設定が完了すると、Vercel でアプリを登録したときに自動生成された myapp-xxx-xxx.vercel.app といったドメイン名は不要になります。 Domains の画面から Edit ボタンを押して、ドメイン自体を削除してしまうか、新しく設定した独自ドメインにリダイレクトするように指定します。 削除してしまうのが心配であれば、308 Permanent Redirect を選んで、独自ドメインにリダイレクトするようにしておけば OK です。 さいごにちょっと広告（＾＾ お名前.com でのドメイン取得はこちらから →"
},
{
url: "/p/vfr3cnw/",
title: "React コンポーネント実装の基本（関数コンポーネントとクラスコンポーネント）",
date: "2020-07-09T00:00:00Z",
body: "React コンポーネント実装の基本（関数コンポーネントとクラスコンポーネント） React で独自コンポーネントを作成する方法として、大きく次の 2 種類の方法があります。 関数コンポーネント (Function Components) クラスコンポーネント (Class Components) 昔は、ステートを持つコンポーネントは「クラスコンポーネント」で作成し、ステートを持たないものは「関数コンポーネント」として作成するという使い分けがありました。 現在は、関数コンポーネントでも Hook の仕組みでステートを管理することができるようになったため、関数コンポーネントの使用が推奨されています。 関数コンポーネント 関数コンポーネントの基本 下記は、固定のテキストを表示するシンプルな関数コンポーネントの定義例です。 TypeScript (@types/react) では、関数コンポーネントの型は React.FunctionComponent インタフェースとして定義されています。 エイリアスとして React.FC が定義されているので、こちらを使えばより短く記述できます。 components/Hello.tsx import * as React from \u0026#39;react\u0026#39;; // Hello コンポーネントの定義 export const Hello: React.FC = () =\u0026gt; { return \u0026lt;h1\u0026gt;Hello\u0026lt;/h1\u0026gt; }; HTML ファイルから読み込む JS ファイルでは、ReactDOM.render() で上記の Hello コンポーネントを描画します。 次のコードを実行すると、\u0026lt;div id=\u0026quot;root\u0026quot;\u0026gt; 要素の内容が、Hello コンポーネントの内容に置き換えられます。 index.tsx（使用例） import * as React from \u0026#39;react\u0026#39;; import * as ReactDOM from \u0026#39;react-dom\u0026#39;; import { Hello } from \u0026#39;./components/Hello\u0026#39;; ReactDOM.render(\u0026lt;Hello /\u0026gt;, document.getElementById(\u0026#39;root\u0026#39;)); 一見すると、1 行目の React モジュールのインポートは必要ないように見えますが、JSX コードが変換されると React を参照するコードになるので、この行を消してはいけません。 プロパティを定義する (props) 関数のパラメータとして、表示すべき値（プロパティ: props）を受け取ることができます。 このプロパティには、HTML 要素でいうところの「属性」として指定された値が格納されています。 TypeScript を使っているのであれば、プロパティの型をちゃんと定義して、React.FC の型パラメータとして指定します。 次の例では、2 つのプロパティ（name と age）を受け取る関数コンポーネントを定義しています。 components/Hello.tsx import * as React from \u0026#39;react\u0026#39;; // Hello コンポーネントのプロパティ type Props = { name: string; age: number; }; // Hello コンポーネントの定義 export const Hello: React.FC\u0026lt;Props\u0026gt; = (props) =\u0026gt; { return \u0026lt;h1\u0026gt;私は{props.name}です {props.age}歳です\u0026lt;/h1\u0026gt; }; index.tsx（使用例） ReactDOM.render( \u0026lt;Hello name=\u0026#34;まく\u0026#34; age={14} /\u0026gt;, document.getElementById(\u0026#39;root\u0026#39;) ); 私はまくです 14歳です と表示されれば成功です。 プロパティをオプショナルにする あるプロパティをオプションにしたいときは、TypeScript の型定義をするときに、プロパティ名の末尾に ? を付けます。 次の例では、age プロパティの指定をオプショナルにしています。 components/hello.ts import * as React from \u0026#39;react\u0026#39;; // Hello コンポーネントのプロパティ type Props = { name: string; age?: number; }; // Hello コンポーネントの定義 export const Hello: React.FC\u0026lt;Props\u0026gt; = (props) =\u0026gt; { const ageText = props.age ? `${props.age}歳` : \u0026#39;秘密\u0026#39;; return \u0026lt;h1\u0026gt;私は{props.name}です 年齢は{ageText}です\u0026lt;/h1\u0026gt; }; プロパティのデフォルト値を設定する React.FC の deafultProps で、プロパティのデフォルト値を定義しておくことができます。 次の例では、Hello コンポーネントの name と age をオプショナルプロパティとして定義し、それぞれ指定されなかった場合のデフォルト値を設定しています。 components/Hello.tsx import * as React from \u0026#39;react\u0026#39;; type Props = { name?: string; age?: number; }; export const Hello: React.FC\u0026lt;Props\u0026gt; = (props) =\u0026gt; { return \u0026lt;h1\u0026gt;私は{props.name}です {props.age}歳です\u0026lt;/h1\u0026gt; }; // プロパティのデフォルト値 Hello.defaultProps = {name: \u0026#39;名無し\u0026#39;, age: 0}; 実は、defaultProps を使わずに、次のように分割代入の構文を使って、デフォルト値を設定してしまった方がシンプルです。 export const Hello: React.FC\u0026lt;Props\u0026gt; = (props) =\u0026gt; { const {name = \u0026#39;名無し\u0026#39;, age = 0} = props; return \u0026lt;h1\u0026gt;私は{name}です {age}歳です\u0026lt;/h1\u0026gt; }; TypeScript の Nullish coalescing operator (??) を使ってデフォルト値を設定してしまう方法もあります。 分割代入の構文に慣れていないうちはこっちのほうが直感的かもしれません。 export const Hello: React.FC\u0026lt;Props\u0026gt; = (props) =\u0026gt; { const name = props.name ?? \u0026#39;名無し\u0026#39;; const age = props.age ?? 0; return \u0026lt;h1\u0026gt;私は{name}です {age}歳です\u0026lt;/h1\u0026gt; }; （おまけ）props の型定義を簡略化する 次の例では、1 つの文字列を持つ Props 型を定義し、その型で受け取った値を分割代入によって name 変数に格納しています。 type Props = { name: string; }; export const Hello: React.FC\u0026lt;Props\u0026gt; = (props) =\u0026gt; { const {name} = props; return \u0026lt;h1\u0026gt;私は{name}です\u0026lt;/h1\u0026gt; }; これくらいシンプルな Props であれば、React.FC の型パラメータ部分にインライン記述してしまうことも可能です。 次の例では、name 変数への分割代入も、アロー関数のパラメータ部分で行っています。 export const Hello: React.FC\u0026lt;{name: string}\u0026gt; = ({name}) =\u0026gt; { return \u0026lt;h1\u0026gt;私は{name}です\u0026lt;/h1\u0026gt;; }; オプショナルな props を定義して、デフォルト値を設定する場合も同様に記述できます。 export const Hello: React.FC\u0026lt;{name?: string}\u0026gt; = ({name = \u0026#39;名無し\u0026#39;}) =\u0026gt; { return \u0026lt;h1\u0026gt;私は{name}です\u0026lt;/h1\u0026gt;; }; クラスコンポーネント クラスコンポーネントの基本 React コンポーネントをクラスの形で定義することもできます。 TypeScript であれば、React.Component を継承し、render() メソッドを実装します。 コンポーネントにプロパティを持たせることができるのは、関数コンポーネントの場合と同様です。 components/Hello.tsx import * as React from \u0026#39;react\u0026#39;; type Props = { name: string; }; export class Hello extends React.Component\u0026lt;Props\u0026gt; { public render() : JSX.Element { return \u0026lt;h1\u0026gt;私は{this.props.name}です\u0026lt;/h1\u0026gt; } }; index.tsx（使用例） import * as React from \u0026#39;react\u0026#39;; import * as ReactDOM from \u0026#39;react-dom\u0026#39;; import { Hello } from \u0026#39;./components/Hello\u0026#39;; ReactDOM.render(\u0026lt;Hello name=\u0026#34;まく\u0026#34; /\u0026gt;, document.getElementById(\u0026#39;root\u0026#39;)); 注意点として、関数コンポーネントのときに関数のパラメータで受け取っていたプロパティ (props) は、クラスコンポーネントの場合はメンバ変数（こちらをプロパティと呼ぶと紛らわしい^^;）として参照するというところです。 つまり、this を付けて、this.props.プロパティ名 という形で参照する必要があります。 プロパティのデフォルト値を設定する クラスコンポーネントのオプショナルなプロパティにデフォルト値を設定するには、次のように static な defaultPorps を定義します。 components/Hello.tsx import * as React from \u0026#39;react\u0026#39;; type Props = { name?: string; }; export class Hello extends React.Component\u0026lt;Props\u0026gt; { private static defaultProps: Props = { name: \u0026#39;名無し\u0026#39; } public render() : JSX.Element { return \u0026lt;h1\u0026gt;私は{this.props.name}です\u0026lt;/h1\u0026gt; } }; プロパティの一部だけがオプショナルになっている場合は、defaultProps の型は HelloProps ではなく、ES5 の Partial を使って Partial\u0026lt;HelloProps\u0026gt; のように定義する必要があります（こうしないと、必須プロパティの name が指定されていないと言うエラーになります）。 次の例では、プロパティ age だけをオプショナルにし、そのデフォルト値を 0 に設定しています。 components/Hello.tsx import * as React from \u0026#39;react\u0026#39;; type Props = { name: string; age?: number; }; export class Hello extends React.Component\u0026lt;Props\u0026gt; { private static defaultProps: Partial\u0026lt;Props\u0026gt; = { age: 0 } public render() : JSX.Element { return \u0026lt;h1\u0026gt;私は{this.props.name}です {this.props.age}歳です\u0026lt;/h1\u0026gt; } }; と、ここまで defaultProps を使う方法を説明しましたが、実は次のようにプロパティの値を見て条件分岐してしまった方が簡単です。 public render() : JSX.Element { const name = this.props.name; const age = this.props.age ?? 0; // const {name, age = 0} = this.props; return \u0026lt;h1\u0026gt;私は{name}です {age}歳です\u0026lt;/h1\u0026gt; } 状態を持たせる (state) クラスコンポーネントには、状態を持たせることができ、その値を使って描画内容を動的に変更することができます。 状態の型は、React.Component の 2 番目の型パラメータとして指定します（1 番目はプロパティの型）。 現在の状態は、インスタンスプロパティ state によって管理します。 state の値は、コンストラクタで初期化できます。 次の例では、ボタンを押すごとにカウントアップする CountButton コンポーネントを定義しています。 図: CountButton の表示結果 components/CountButton.tsx import * as React from \u0026#39;react\u0026#39;; // CountButton コンポーネントの状態の型 type CountButtonState = { count: number; }; // CountButton コンポーネントの定義 export class CountButton extends React.Component\u0026lt;{}, CountButtonState\u0026gt; { constructor(props: {}) { super(props); this.state = { count: 0 }; // 状態を初期化 } public render(): JSX.Element { return ( \u0026lt;div\u0026gt; \u0026lt;button onClick={this.handleClick}\u0026gt;増やす\u0026lt;/button\u0026gt; \u0026lt;b\u0026gt;カウント = {this.state.count}\u0026lt;/b\u0026gt; \u0026lt;/div\u0026gt; ); } // ボタンが押されたときの処理 private handleClick = (e: React.SyntheticEvent) =\u0026gt; { // デフォルト動作を抑制したい場合 e.preventDefault(); // コンポーネントの状態を変更する → 新しい状態で render() が実行される this.setState({ count: this.state.count + 1 }); } } index.tsx（使用例） import * as React from \u0026#39;react\u0026#39;; import * as ReactDOM from \u0026#39;react-dom\u0026#39;; import { CountButton } from \u0026#39;./components/CountButton\u0026#39;; ReactDOM.render(\u0026lt;CountButton /\u0026gt;, document.getElementById(\u0026#39;root\u0026#39;)); いくつか実装上のポイントがあるので、まとめておきます。 コンストラクタで props を受け取る： クラスコンポーネントのコンストラクタを定義するときは、パラメータとしてプロパティ (props) を受け取り、親クラス (super) に渡してやる必要があります。上記の CountButton コンポーネントはプロパティを持たないので、型パラメータとしては {} を指定していますが、その場合でもコンストラクタのパラメータでは props を受け取るように実装しておく必要があります。 render 関数の return 直後に開き括弧： return の直後に改行を入れると、JavaScript が自動的にセミコロンを挿入してしまうので、すぐに改行したいときは return ( のように、開き括弧の後ろで改行する必要があります。 onClick と handleClick： JSX コードの中で配置したボタンのクリックイベントをハンドルするには、onClick という属性にイベントハンドラを指定します。イベントハンドラ名は handleClick のように、名前に handle というプレフィックスを付けるのが慣例となっています。 イベントハンドラはアロー関数で： this で呼び出し元のオブジェクトを参照できるように、handleClick メソッドは function キーワードを使わずに、アロー関数の形で定義します。 デフォルト動作を抑止する： button 要素などのクリック時のデフォルト動作（フォーム内容の post など）を抑制するには、イベントハンドラのパラメータで渡される React.SyntheticEvent オブジェクトの preventDefault() メソッドを呼び出します。 状態の変更は setState 関数で： state プロパティはリードオンリーになっているので、コンポーネントの状態を変更したいときは、setState() 関数を使用します（コンストラクタでは例外的に代入できます）。setState() を使って状態を変更すると、自動的に render() メソッドが呼び出され、新しい状態 (state) で画面上の表示が更新されます。"
},
{
url: "/p/t8rfkjn/",
title: "Azure: Cosmos DB の SQL API をプロキシ経由で使用する",
date: "2019-09-05T00:00:00Z",
body: "Azure: Cosmos DB の SQL API をプロキシ経由で使用する 参照するサンプルコード Azure の Cosmos DB を SQL API で操作するための最初の手順は下記のドキュメントに記載されています。 クイック スタート:Azure Cosmos DB SQL API アカウントを使用して Node.js アプリを構築する ここに Node.js 用のサンプルコードがあり、@azure/cosmos パッケージが提供する CosmosClient クラスを使用したコードになっています（昔のサンプルコードでは documentdb というライブラリを使用していたりしますが、今は Microsoft が提供する @azure/cosmos を使用すると完結なコードを記述できます）。 const CosmosClient = require(\u0026#39;@azure/cosmos\u0026#39;).CosmosClient; 基本的には、config.js ファイルに記述されたエンドポイントとキーを下記のような感じで設定すれば実行できるようになるのですが、 config.js var config = {}; config.endpoint = \u0026#39;https://your-cosmosdb.documents.azure.com:443/\u0026#39;; config.key = \u0026#39;9Hp4WSwgvggexAuGy4dKdl...snipped...lV9Nm44Pg8WVkH==\u0026#39;; 会社などのプロキシ環境内からだとうまく接続できず、次のような感じのエラーが発生すると思います。 $ node app.js Completed with error {\u0026#34;message\u0026#34;:\u0026#34;request to https://your-cosmosdb.documents.azure.com:443/dbs/FamilyDatabase failed, reason: connect ETIMEDOUT 123.34.56.78:443\u0026#34;,\u0026#34;type\u0026#34;:\u0026#34;system\u0026#34;,\u0026#34;errno\u0026#34;:\u0026#34;ETIMEDOUT\u0026#34;, \u0026#34;code\u0026#34;:\u0026#34;ETIMEDOUT\u0026#34;,\u0026#34;headers\u0026#34;:{\u0026#34;x-ms-throttle-retry-count\u0026#34;:0,\u0026#34;x-ms-throttle-retry-wait-time-ms\u0026#34;:0}} HTTPS_PROXY 環境変数を設定しても同様で効果がありません。 プロキシ経由で CosmosClient を使用する CosmosClient クラスでの Cosmos DB へのアクセスをプロキシ経由で行うには、コンストラクタのパラメータとして渡せる CosmosClientOptions の agent プロパティを設定します。 ここでは、エージェントとして proxy-agent モジュールを使用します。 proxy-agent のインストール $ npm install --save proxy-agent sample.js const { CosmosClient } = require(\u0026#39;@azure/cosmos\u0026#39;); const ProxyAgent = require(\u0026#39;proxy-agent\u0026#39;); // HTTP, HTTPS, or SOCKS proxy to use const PROXY_URI = \u0026#39;http://proxy.example.com:3128/\u0026#39;; const client = new CosmosClient({ endpoint: config.endpoint, key: config.key, agent: new ProxyAgent(PROXY_URI) }); プロキシを使用するかどうかを簡単に切り替えられるようにするには、例えば、AZURE_PROXY 環境変数に URI がセットされていたら、それをプロキシアドレスとして使用する、というように処理を分けるとよいでしょう。 sample.js const { CosmosClient } = require(\u0026#39;@azure/cosmos\u0026#39;); const options = { endpoint: config.endpoint, key: config.key }; // AZURE_PROXY 環境変数がセットされていたらプロキシ経由のアクセスにする if (process.env.AZURE_PROXY) { const ProxyAgent = require(\u0026#39;proxy-agent\u0026#39;); options.agent = new ProxyAgent(process.env.AZURE_PROXY); } const client = new CosmosClient(options); あとは、普通に CosmosClient インスタンスを使用して API を呼び出すだけです。 my-db データベースの my-collection コレクションに、適当な JSON データを格納してみます。 async function createItem(item) { // Create the database if it does not exist const { database } = await client.databases.createIfNotExists({ id: \u0026#39;my-db\u0026#39; }); // Create the container if it does not exist const { container } = await database.containers.createIfNotExists({ id: \u0026#39;my-collection\u0026#39; }); // Create the item if it does not exist const { resource } = await container.items.upsert(item); } // コレクションに追加してみる const item = { id: \u0026#39;id1\u0026#39;, key1: \u0026#39;value1\u0026#39;, key2: \u0026#39;value2\u0026#39; }; createItem(item).catch(err =\u0026gt; { console.error(err); }); Azure ポータル から Cosmos DB の データエクスプローラー を開くと、my-db データベースの my-collection コレクションにアイテムが追加されていることを確認できます。 図: Cosmos DB データエクスプローラー"
},
{
url: "/p/q8hqz7f/",
title: "Next.js のスタイル設定 (CSS)",
date: "2021-12-15T00:00:00Z",
body: "Next.js のスタイル設定 (CSS)"
},
{
url: "/p/eycnw8h/",
title: "VS Code の設定メモ",
date: "2021-11-13T00:00:00Z",
body: "VS Code の設定メモ"
},
{
url: "/p/q7fov5c/",
title: "Amazon S3",
date: "2021-06-16T00:00:00Z",
body: "Amazon S3"
},
{
url: "/p/wn52kog/",
title: "AWS IAM のメモ",
date: "2021-02-07T00:00:00Z",
body: "AWS IAM のメモ"
},
{
url: "/p/qcp2cnx/",
title: "Apollo Client で GitHub GraphQL API を使う (Node \u0026 React)",
date: "2020-07-31T00:00:00Z",
body: "Apollo Client で GitHub GraphQL API を使う (Node \u0026 React) Apollo Client とは Apollo パッケージは、GraphQL を使ったクライアントアプリやサーバーを作成するためのライブラリ群です。 クライアントアプリを作るためのライブラリは、Apollo Client として @apollo/client という NPM パッケージにまとめられています。 Web アプリのコンポーネントを作成するときは React がよく使われますが、Apollo は GraphQL を扱いやすくする React コンポーネント（ApolloProvider、Query、Mutation、Subscription）や React Hook 拡張（useQuery) などを提供しています。 ここでは、Apollo Client パッケージを使用して、 Node.js アプリ（コマンドラインアプリの JS）から GraphQL API の実行 React アプリ（Web サイトの JS）から GraphQL API の実行 を行ってみます。 呼び出す GraphQL API は何でもよいのですが、今回は GitHub GraphQL API を利用することにします。 Node パッケージのインストール Apollo Client Apollo Client 関連のパッケージとしては、@apollo/client と、それが使用する graphql をインストールします。 Apollo Client のインストール ### yarn の場合 $ yarn add @apollo/client graphql ### npm の場合 $ npm install @apollo/client graphql fetch ポリフィル Apollo クライアント内部の実装では、Web ブラウザの fetch API を利用しています。 React アプリから Apollo クライアントを利用する場合は問題ないのですが、コンソールで動作する Node.js アプリから利用する場合は、fetch API の埋め合わせ (polyfill) をするモジュールが必要になります。 ここでは、cross-fetch パッケージをインストールしておきます。 fetch ライブラリのインストール ### yarn の場合 $ yarn add cross-fetch ### npm の場合 $ npm install cross-fetch （コラム）古いパッケージ Apollo のクライアント系パッケージはいろいろな名前で提供されていましたが、すべて @apollo/client 以下にまとめられました。 次のようなパッケージはもう使用しません。 apollo-client: すべて @apollo/client に統合されたので使いません apollo-boost: 次のように ApolloClient コンストラクタを使えばOKです (import {ApolloClient} from '@apollo/client/core') graphql-tag: GraphQL をパースするための gql も @apollo/client に統合されています (import {gql} from '@apollo/client') GitHub アクセストークンの発行 GitHub の GraphQL API を使用するには、下記のように POST リクエストのヘッダで GitHub アクセストークンを付加する必要があります。 authorization: Bearer a4304a13bc6cdd52509c90a38a676fce962ce518 アクセストークンを付加しないと、API 実行時に次のような HTTP 401 エラーが返されます。 ApolloError: Response not successful: Received status code 401 GitHub のアクセストークンは、下記の設定画面から Generate new token ボタンを押すことで作成できます。 GitHub / Settings / Developer settings / Personal Access Tokens このとき、公開するデータのスコープ設定を行うのですが、何もチェックしなくても Public なリポジトリ情報やユーザー情報は取得可能です。 repo にチェックを入れると、Private なリポジトリの読み書きが可能になり、user にチェックを入れると、ユーザー情報の読み書きが可能になります。 read:user にだけチェックを入れると、ユーザー情報の読み込みだけが可能になります。 残念ながら、Private リポジトリをリードオンリーで扱うスコープは存在しないようです（設計ミス？）。 スコープの詳細については、下記の GitHub ドキュメントを参考にしてください。 参考: Scopes for OAuth Apps - GitHub Docs Node.js アプリから Apollo Client を使用する まずは、Node.js を使ったコマンドラインアプリから、ApolloClient を使って GitHub GraphQL API を呼び出してみます。 下記のサンプルコードでは、指定した GitHub リポジトリ (apollographql/apollo) の最新 Issue 5件分を取得しています。 このコードを実行できるようになれば、あとはクエリ部分を変更することでいろいろな情報を取得できます。 ポイントとしては、下記のあたりでしょうか。 cross-fetch/polyfill モジュールをインポートして、Web ブラウザの fetch 関数をエミュレートする authorization ヘッダで GitHub のアクセストークンを指定する GraphQL クエリを gql`クエリ文字列` という形で定義する サンプルコード main.ts import {ApolloClient, ApolloError, InMemoryCache, gql} from \u0026#39;@apollo/client/core\u0026#39;; import \u0026#39;cross-fetch/polyfill\u0026#39;; // グローバルな fetch 関数を定義する // トークンは環境変数などから取得するのが常套手段 // const token = \u0026#39;a4304a13bc6cdd52509c90a38a676fce962ce518\u0026#39;; const token = process.env.MYAPP_GITHUB_TOKEN; if (typeof token === \u0026#39;undefined\u0026#39;) { throw new Error(\u0026#39;MYAPP_GITHUB_TOKEN cannot be found\u0026#39;); } // GraphQL クライアントを生成 const apolloClient = new ApolloClient({ uri: \u0026#39;https://api.github.com/graphql\u0026#39;, headers: {authorization: `Bearer ${token}`}, cache: new InMemoryCache(), }); // 発行する GraphQL クエリ const searchQuery = gql` query { search(query: \u0026#34;repo:apollographql/apollo is:issue\u0026#34;, type: ISSUE, first: 5) { issueCount nodes { ... on Issue { number title } } } } `; // クエリを発行 apolloClient.query({query: searchQuery}) .then(result =\u0026gt; handleApolloResult(result.data)) .catch(handleApolloError); // GraphQL レスポンスをハンドル function handleApolloResult(data: any) { const {issueCount, nodes} = data.search; console.log(`Num of issues: ${issueCount}`); for (const issue of nodes) { console.log(`* ${issue.number}: ${issue.title}`); } } // GraphQL のエラーをハンドル function handleApolloError(err: ApolloError) { console.error(err.message); } 実行結果 Num of issues: 176 * 937: Broken code display in blog for scaling GraphQL * 934: Unknown directives * 929: start apollo gateway * 926: using REST services in apolo federation * 909: Get a Graph Manager API key instructions need updating React アプリから Apollo Client を使用する 次に、React アプリから Apollo Client を使って GraphQL API を実行してみます。 Apollo Client はもともと React アプリから使用することを想定して作られているため、とてもきれいに実装できます。 GitHub のアクセストークンは相変わらず必要なので、上記の説明 を参考にして取得しておいてください。 下記の例では、GitHub のアクセストークンを TypeScript コードに埋め込んでいますが、本番用の Web アプリでは、OAuth などの仕組みを使って動的にユーザーのアクセストークンを取得する必要があります。 OAuth 関連の実装を説明すると長くなってしまうので、そのあたりは下記の記事を参考にしてください。 GitHub OAuth トークンを取得する (1) 処理の流れを理解する GitHub OAuth トークンを取得する (2) Azure Functions 経由で取得する サンプルコード 次の App コンポーネントでは、前述のコマンドラインアプリと同様に ApolloClient インスタンスを生成しています。 このインスタンスを、ApolloProvider コンポーネントの client プロパティにセットすると、下位のコンポーネントから簡単に GraphQL API を呼び出せるようになります（後述）。 App.tsx import * as React from \u0026#39;react\u0026#39;; import {ApolloClient, ApolloProvider, InMemoryCache} from \u0026#39;@apollo/client\u0026#39;; import {Issues} from \u0026#39;./Issues\u0026#39;; // 注意: 本番環境ではアクセストークンは OAuth などで動的に取得すること const GITHUB_TOKEN = \u0026#39;a4304a13bc6cdd52509c90a38a676fce962ce518\u0026#39;; // GraphQL クライアントを生成 const apolloClient = new ApolloClient({ uri: \u0026#39;https://api.github.com/graphql\u0026#39;, headers: {authorization: `Bearer ${GITHUB_TOKEN}`}, cache: new InMemoryCache(), }); export const App: React.FC = () =\u0026gt; { return ( \u0026lt;ApolloProvider client={apolloClient}\u0026gt; \u0026lt;Issues /\u0026gt; \u0026lt;/ApolloProvider\u0026gt; ); }; 次の Issues コンポーネントは、Apollo Client を使って GitHub GraphQL API を呼び出し、指定したリポジトリの最新 Issue 5件分を取得して表示します（前述のコマンドラインアプリと同様です）。 クエリの実行方法はとても簡単で、Apollo Client が提供する useQuery フックを呼び出すだけです。 クエリの実行結果により、ロード中 (loading)、エラー発生 (error)、取得完了 (data) の戻り値を得られるので、現在の状況に応じて描画内容を切り替えることができます。 Issues.tsx import * as React from \u0026#39;react\u0026#39;; import {gql, useQuery} from \u0026#39;@apollo/client\u0026#39;; // 発行する GraphQL クエリ const GET_ISSUES = gql` query { search(query: \u0026#34;repo:apollographql/apollo is:issue\u0026#34;, type: ISSUE, first: 5) { issueCount nodes { ... on Issue { number title } } } } `; export const Issues: React.FC = () =\u0026gt; { // GraphQL のクエリを実行 const {loading, error, data} = useQuery(GET_ISSUES); // クエリ実行中の表示 if (loading) return \u0026lt;p\u0026gt;Loading ...\u0026lt;/p\u0026gt;; // エラー発生時（レスポンスがないとき）の表示 if (error) return \u0026lt;p style={{color: \u0026#39;red\u0026#39;}}\u0026gt;{error.message}\u0026lt;/p\u0026gt;; // クエリの結果が返ってきたときの表示 const {issueCount, nodes: issues} = data.search; return \u0026lt;\u0026gt; \u0026lt;h2\u0026gt;Num of issues: {issueCount}\u0026lt;/h2\u0026gt; \u0026lt;ul\u0026gt; { issues.map(i =\u0026gt; \u0026lt;li key={i.number}\u0026gt;{i.number} - {i.title}\u0026lt;/li\u0026gt;) } \u0026lt;/ul\u0026gt; \u0026lt;/\u0026gt;; }; 実行結果 図: クエリ実行中 図: 結果の取得後 ここでは、クエリ実行中に「Loading \u0026hellip;」と表示するだけにしていますが、ロード中のくるくるアイコンなどを表示すると、かなりそれっぽくなります。 ローカルストレージに保存したアクセストークンを使用する 上記の例では、GitHub のアクセストークンをハードコードしていますが、実運用ではこのようなコードはデプロイできません。 ここでは、ローカルストーレージ (GITHUB_TOKEN) に保存されたアクセストークンを使って、ApolloClient および ApolloProvider を生成する方法を紹介します。 OAuth によってアクセストークンを取得し、ローカルストレージに保存するまでの流れは次の記事を参考にしてください。 GitHub OAuth トークンを取得する (2) Azure Functions 経由で取得する 次のサンプルコンポーネント GitHubApolloProvider は、GitHub のアクセストークンを HTTP ヘッダに付けて GraphQL クエリを発行するための ApolloProvider を提供します。 このような ApolloClient のカスタマイズ方法は、Apollo 本家サイトの Authentication のページ で説明されています。 GitHubApolloProvider.tsx import * as React from \u0026#39;react\u0026#39;; import { ApolloClient, ApolloProvider, createHttpLink, InMemoryCache, } from \u0026#39;@apollo/client\u0026#39;; import { setContext } from \u0026#39;@apollo/client/link/context\u0026#39;; const httpLink = createHttpLink({ uri: \u0026#39;https://api.github.com/graphql\u0026#39; }); const authLink = setContext((_, { headers }) =\u0026gt; { // Get the authentication token from local storage if it exists const token = localStorage.getItem(\u0026#39;GITHUB_TOKEN\u0026#39;); // Return the headers to the context so httpLink can read them return { headers: { ...headers, authorization: token ? `Bearer ${token}` : \u0026#39;\u0026#39;, } } }); // Create a GraphQL client const apolloClient = new ApolloClient({ link: authLink.concat(httpLink), cache: new InMemoryCache() }); export const GitHubApolloProvider: React.FC = (prop) =\u0026gt; { return \u0026lt;ApolloProvider client={apolloClient}\u0026gt; {prop.children} \u0026lt;/ApolloProvider\u0026gt;; }; あとは、ApolloProvider を使っていたところを次のように GitHubApolloProvider に置き換えれば、それ以下のコンポーネントでアクセストークン付きの GraphQL クエリを発行できるようなります。 App.tsx import * as React from \u0026#39;react\u0026#39;; import {GitHubApolloProvider} from \u0026#39;./GitHubApolloProvider\u0026#39;; import {Issues} from \u0026#39;./Issues\u0026#39;; export const App: React.FC = () =\u0026gt; { return ( \u0026lt;GitHubApolloProvider\u0026gt; \u0026lt;Issues /\u0026gt; \u0026lt;/GitHubApolloProvider\u0026gt; ); }; ローカルストレージに保存されたアクセストークンは、GraphQL のリクエストを実行するたびに参照してくれるので、ApolloClient インスタンスを生成した後でアクセストークンが設定された場合にもうまく動作します。 環境変数に設定したアクセストークンを使用する ローカル環境での開発時に、何らかの理由で、環境変数に保存した GitHub アクセストークン (Personal access token) を使用したい場合は、index.tsx の最初の方で、次のような感じで環境変数の値をローカルストレージにコピーしてしまえば OK です。 index.tsx if (process.env.NODE_ENV === \u0026#39;development\u0026#39; \u0026amp;\u0026amp; process.env.MYAPP_GITHUB_TOKEN) { console.warn(\u0026#39;In development mode, use MYAPP_GITHUB_TOKEN env variable.\u0026#39;); localStorage.setItem(\u0026#39;GITHUB_TOKEN\u0026#39;, process.env.MYAPP_GITHUB_TOKEN); } おまけ： GraphQL クエリにパラメータを設定する パラメータ付きの GraphQL クエリを実行するには、useQuery フック の第2パラメータで、次のような形で変数オブジェクト（変数名と値の連想配列）を渡します。 const {loading, error, data} = useQuery(QUERY, {variables: 変数オブジェクト}); 下記のサンプルコードでは、変数で指定した GitHub リポジトリのイシューを取得しています。 Issues.tsx import * as React from \u0026#39;react\u0026#39;; import {gql, useQuery} from \u0026#39;@apollo/client\u0026#39;; const QUERY = gql` query($searchQuery: String!) { search(query: $searchQuery, type: ISSUE, first: 5) { nodes { ... on Issue { number title } } } } `; export const Issues: React.FC = () =\u0026gt; { // 変数を渡して GraphQL クエリを実行 const queryVars = { searchQuery: \u0026#39;repo:apollographql/apollo is:issue\u0026#39; }; const {loading, error, data} = useQuery(QUERY, {variables: queryVars}); if (loading) return \u0026lt;p\u0026gt;Loading ...\u0026lt;/p\u0026gt;; if (error) return \u0026lt;p style={{color: \u0026#39;red\u0026#39;}}\u0026gt;{error.message}\u0026lt;/p\u0026gt;; const {nodes} = data.search; return \u0026lt;\u0026gt; \u0026lt;ul\u0026gt; {nodes.map(x =\u0026gt; \u0026lt;li key={x.number}\u0026gt;{x.number} - {x.title}\u0026lt;/li\u0026gt; )} \u0026lt;/ul\u0026gt; \u0026lt;/\u0026gt;; };"
},
{
url: "/p/as4cmu4/",
title: "VS Code のショートカットキーを使いこなす（ウィンドウ操作編）",
date: "2020-06-10T00:00:00Z",
body: "VS Code のショートカットキーを使いこなす（ウィンドウ操作編） ショートカットキーで Cmd になっているところは、Windows の場合は Ctrl に置き換えればほぼ動作します。 とりあえずは、サイドバーやターミナルパネルを On/Off する Cmd + B や Cmd + J から覚えて、画面を広く使えるようになりましょう。 アクティビティバー／サイドバーの操作 ショートカット 説明 Cmd + B サイドバー全体の表示／非表示 Cmd + Shift + E Explorer を開く Cmd + Shift + F(H) Search を開く（H なら置換モード） Ctrl + Shift + G Source Control を開く Cmd + Shift + D Debug を開く Cmd + Shift + X Extension を開く ターミナル／出力パネル 画面の下の方に表示されるターミナルなどのパネルを開くためのショートカットキーです。 ショートカット 説明 Cmd + J パネル全体の表示／非表示 Ctrl + ` Terminal パネルを開く Cmd + Shift + Y Debug Console パネルを開く Cmd + Shift + M Problem パネルを開く Cmd + Shift + U Output パネルを開く 外部コマンドを実行するときは、Terminal パネルを使用する代わりに、Cmd + Shift + C で OS 標準のターミナルを開くこともできます（Windows なら Ctrl + Shift + C でコマンドプロンプトが開きます）。 フルスクリーン／禅モード ショートカット 説明 Ctrl + Cmd + F フルスクリーン表示（終了方法も同じ） Cmd + K → Z 禅モード表示（終了は Esc x 2） 禅モードに入ると、編集テキストのみの表示になり、集中して作業できるようになります。 禅モードに入るためのショートカットキーは覚えにくいので、Cmd + Shift + P でコマンドパレットを開き、zen → Enter で入る方が簡単かもしれません。 禅モードから通常表示に戻るときは Esc → Esc ですが、フルスクリーン化のショートカットキー Ctrl + Cmd + F でも戻れます。"
},
{
url: "/p/i6549xd/",
title: "Azure Pipelines の Pull Request 時の起動トリガ設定",
date: "2020-05-13T00:00:00Z",
body: "Azure Pipelines の Pull Request 時の起動トリガ設定 ビルドしない azure-pipelines.yml trigger:none # will disable CI builds entirely Azure Pipelines によるビルドを起動しないようにします。 trigger プロパティを省略すると、デフォルトですべてのブランチへのプッシュ時にビルドが走るので、ビルドしないようにするには、上記のように明示的に none 指定が必要です。 この設定を行うと、pr プロパティの設定（後述）も無効になります（Pull Request 時もビルドは実行されない）。 master ブランチへのプッシュ or マージでビルド？ azure-pipelines.yml trigger:- master 次のように複数のブランチをビルド対象とすることもできます。 trigger:- master- release このように記述すると、指定したブランチへのプッシュ or マージ時にのみ Pipelines が起動しそうに見えますが、この指定だけだと、 あらゆる Pull Request の作成時に Pipelines が起動します。 master ブランチや release ブランチをターゲットとしない Pull Request でもビルドが走ります。 なぜなら、Pull Request トリガの設定がデフォルトで次のようになっているからです。 pr:branches:include:- \u0026#39;*\u0026#39; このため、一連のステップにデプロイ処理まで組み込んでいると、レビュー用に Pull Request を上げただけでデプロイまで実行されてしまうという振る舞いになります。 Pull Request 時にビルドしない azure-pipelines.yml trigger:- masterpr:none # no PR triggers 上記のように設定しておくと、Pull Request を作成したときには Pipelines は起動しなくなります。 つまり、master ブランチへのプッシュ or マージ時のみビルドが実行されます。 特定のブランチをターゲットとした Pull Request 時にビルドする azure-pipelines.yml pr:- master master ブランチをターゲットとする Pull Request を作成したとき（および追加プッシュ）があった場合にのみ Pipelines が起動します。 これも trigger の指定と同様に、複数のターゲットブランチを指定できます。 pr:- master- releases/* Pull Request 時のみビルドする azure-pipelines.yml trigger:- DUMMY_BRANCH_TO_BUILD_ONLY_ON_PR これ、正式なやり方が分かりませんでした。 pr プロパティはデフォルトで全 Pull Request に対してビルドを実行する設定になっているのですが、master ブランチへのプッシュ時のビルドを停止するために trigger: none を指定してしまうと、Pull Request 時のビルドも無効になってしまうし。。。 しょうがないので、絶対に使わないであろうブランチ名を trigger に指定しています。 結果として、master ブランチなどへのプッシュ時にはビルドは実行されず、任意の Pull Request を作成したときのみにビルドが実行されるようになります。 特定のファイルがコミットされた場合はビルドしない azure-pipelines.yml trigger:branches:include:- masterpaths:include:- \u0026#39;*\u0026#39;# same as \u0026#39;/\u0026#39; for the repository rootexclude:- \u0026#39;/azure-pipelines-for-pr.yml\u0026#39;- \u0026#39;/docs/*\u0026#39;# same as \u0026#39;/docs/\u0026#39; trigger 設定は上記のように階層化して記述することで、さらに細かい設定を行うことができます。 例えば、 ドキュメントの更新時にはビルドは必要ない (/docs/*） 別の Pipelines 設定ファイルの更新は無視したい (/azure-pipelines-for-pr.yml) といった場合は、上記のように trigger.paths.exclude プロパティでファイルのパスを指定することで除外できます。"
},
{
url: "/p/teq2cmv/",
title: "Azure Pipelines のビルド結果を GitHub にバッジ表示する",
date: "2020-04-10T00:00:00Z",
body: "Azure Pipelines のビルド結果を GitHub にバッジ表示する ステータスバッジとは ステータスバッジというのは、GitHub プロジェクトのトップページ (README.md) でよく見かける上のようなアイコンのことです。 ステータスバッジを貼り付けておくことで、最新のソースコードが正しくビルドできていることを一目で確認することができますし、ちゃんと開発しているんだということをアピールすることにもなります。 Azure Pipelines のビルド結果を示すステータスバッジは、下記のように簡単に追加することができます。 Azure Pipelines のステータスバッジを表示する ステータスバッジは、画像ファイルの URL の形で提供されているので、GitHub の README.md などにその URL を貼り付けるだけで OK です。 ステータスバッジの画像 URL を確認するには、Azure Pipelines のページを開き、右上のメニューアイコン → Status badge と選択します。 画像の URL と一緒に、Markdown ファイルに記述する場合のコード (Sample markdown) も表示してくれるので、GitHub のページに貼り付ける場合はそちらを使えばよいでしょう。 右側のコピーアイコンを押してクリップボードにコピーし、GitHub の README.md ファイルに次のような感じで貼り付ければ OK です。 これで、GitHub プロジェクトのトップページアクセスしたときに、次のようにステータスバッジが表示されるはずです。 ステータスバッジの画像が表示されないとき Azure DevOps にサインインしていない状態で、ステータスバッジが表示されない場合は、Pipelines の設定を確認してみてください。 上記のように、Disable anonymous access to badge という項目を OFF にすれば表示されるようになると思います。"
},
{
url: "/p/gkardu9/",
title: "Azure Storage で静的 Web サイトをホスティングする",
date: "2020-03-17T00:00:00Z",
body: "Azure Storage で静的 Web サイトをホスティングする （Azure Storage による静的な Web サイトのホスティング機能は 2018 年末にリリース されました） ストレージアカウントを作成する（まだ作成していない場合） Azure 上に静的な Web サイトをホスティングするためのストレージを作成するには、ストレージアカウントが必要です。 まだ作成していない場合は、下記の手順に従ってストレージアカウントを作成してください。 静的な Web サイトをホスティングする場合は、アカウントの種類 (Account kind) の項目で StorageV2（汎用v2） というのを選んで作成しておく必要があります。 → Azure のストレージアカウントを作成する 静的な Web サイトを有効にする ストレージアカウントを作成したら、コンテンツのアップロード先である Azure ストレージコンテナーと、Web サイトの URL を生成します。 といっても、ストレージアカウントがあれば、Azure ポータル から数秒で自動作成できます。 ストレージアカウントのページを開き、設定 → 静的な Web サイト を選択します。 静的な Web サイト のスイッチを 有効 に切り替えて 保存 ボタンを押します。 これで、Web サイトをホスティングするための Azure ストレージコンテナー（BLOB を入れるコンテナー）が作成されます。 コンテナー名は自動的に $web になるようです。 同時に、Web サイトの URL も自動的に生成されます。 これが Web ブラウザからサイトにアクセスするときのアドレスになります。 あとは、コンテナーに HTML ファイルをアップロードするだけです。 Web サイトのコンテンツをアップロードする 作成されたコンテナー ($web) にコンテンツをアップロードするには、Azure CLI などのコマンドラインツールを使用します。 Azure ポータルのサイト上で BLOB リソースの項目からポチポチやってアップロードすることもできますが、自動化のことを考えると、コマンドラインツールを使った方がよいでしょう。 Azure CLI で単一ファイルをアップロードする 手始めに、Azure CLI の az コマンドを使って、index.html をアップロードしてみます。 Azure CLI をインストールしていない場合は、先にインストールしてください。 実際は 1 行で実行 $ az storage blob upload --account-name \u0026lt;ストレージアカウント名\u0026gt; --account-key \u0026lt;ストレージアカウントのキー\u0026gt; -c $web --file index.html --name index.html Finished[########################################] 100.0000% { \u0026#34;etag\u0026#34;: \u0026#34;\\\u0026#34;0x8D7CA465578BC90\\\u0026#34;\u0026#34;, \u0026#34;lastModified\u0026#34;: \u0026#34;2020-03-17T07:39:32+00:00\u0026#34; } Web ブラウザから、プライマリエンドポイント（https://xxx.yyy.web.core.windows.net/) にアクセスして、index.html の内容が表示されれば成功です。 参考リンク 逆引き Azure CLI: BLOB ストレージにファイルをアップロードする (storage blob upload) AzCopy で複数のファイルをまとめてアップロードする Azure CLI (az) では、1 つのファイル (BLOB) ずつしか転送できません。 複数のファイルをまとめて転送するには、azcopy コマンドを使用します。 各プラットフォーム用の azcopy コマンドは以下からダウンロードできます。 AzCopy v10 を使用して Azure Storage にデータをコピーまたは移動する Windows であれば、ダウンロードした azcopy.exe を C:\\mybin ディレクトリなどにコピーして PATH を通しておけばよいでしょう。 azcopy コマンドを使うには SAS トークン が必要で、これは Azure CLI（az コマンド）などで生成することができます。 例えば、次のようにして $web コンテナーにアクセスするための SAS トークンを生成します。 SAS トークンの生成（実際は1行） $ az storage container generate-sas --name \u0026#34;$web\u0026#34; --expiry \u0026#34;2020-07-07T00:00:00Z\u0026#34; --permission racwdl --connection-string \u0026lt;ストレージアカウントの接続文字列\u0026gt; \u0026#34;se=2020-07-07T00%3A00%3A00Z\u0026amp;sp=racwdl\u0026amp;sv=2018-11-09\u0026amp;sr=c\u0026amp;sig=c7bapOBvLkHVlebBIEQFQc2bGd%2BjmfScqKCbkLUzzoo%3D\u0026#34; 参考リンク 逆引き Azure CLI: Azure ストレージの SAS トークンを生成する (storage container generate-sas) 標準出力に表示された \u0026quot;se=...\u0026quot; という文字列が SAS トークンです。 SAS トークンが取得できたら、それを使って azcopy sync コマンド で BLOB へのファイルアップロードを行うことができます（似たようなものに azcopy copy コマンドもありますが、azcopy sync の方を使うと、タイムスタンプを比較して更新されているもののみをアップロードしてくれます）。 例えば、src ディレクトリ内のファイルをすべてアップロードするには次のようにします。 ディレクトリ内のファイルをアップロード（実際は1行） $ azcopy sync --delete-destination true src https://\u0026lt;ストレージアカウント名\u0026gt;.blob.core.windows.net/\u0026lt;コンテナー名\u0026gt;?\u0026lt;SASトークン\u0026gt; オプションの意味: --delete-destination true: コピー元にないファイルはコピー先から削除する ストレージアカウント名と、SAS トークンは実際に使用するものに置き換えてください。 コンテナー名は $web で共通ですね。 実行例 $ azcopy sync --delete-destination true src https://yourstorage.blob.core.windows.net/$web?\u0026#34;se=...\u0026#34; 認証に失敗して 40X 系のエラーが出る場合は、末尾の ? 以降に指定する SAS トークンが間違っていることが多いです。 SAS トークンはダブルクォーテーション (\u0026quot;) で囲まれたものをそのまま指定することに注意してください。 静的な Web サイトのコスト Azure Storage による静的な Web サイトをホスティングしたときの利用料金は、 ストレージコスト（コンテンツの容量に応じた維持コスト） → Azure Storage Overview pricing データ送信料（Web サイトの表示時の転送量に応じたコスト） → Bandwidth Pricing Details によって決まります。 いずれにしても、小規模なサイトであればめちゃくちゃ安くすむと思います。 1GB のストレージコストは 10 円/月以下、転送サイズは 5GB までは無料で、それを超えた場合でも 10 円/GB 程度です。 1 ヵ月当たりの転送量が 100 GB を超えたりする場合は、毎月 1000 円以上取られることになるので、ちょっと考えた方がよいですね。 （おまけ）PowerShell スクリプトでアップロードを自動化する 下記のスクリプトを実行すると、src ディレクトリ内に格納されたファイル群 (HTMLファイルなど）を、$STORAGE_ACCOUNT で指定したストレージコンテナーに転送（同期）します。 src ディレクトリ内に存在しないファイルは、Azure 側からも削除されるので注意してください。 upload.ps1 $STORAGE_ACCOUNT = \u0026#39;yourstorage\u0026#39; # ストレージアカウント名 $SRC_DIR = \u0026#39;src\u0026#39; # ローカルファイルが格納されたディレクトリ $CONTAINER = \u0026#39;$web\u0026#39; # 転送先の Storage コンテナ名 $CONN_STR = $env:AZURE_STORAGE_CONNECTION_STRING # 接続文字列 # 環境変数にストレージアカウントの接続文字列がセットされているか確認 if ([string]::IsNullOrEmpty($CONN_STR)) { Write-Host \u0026#39;AZURE_STORAGE_CONNECTION_STRING is not set\u0026#39; exit } # 有効期限の日時文字列を生成（現在から10分後） $expiry = (Get-Date).AddMinutes(10).ToUniversalTime().ToString(\u0026#39;yyyy-MM-ddTHH:mm:ssZ\u0026#39;) # SASトークンを生成 Write-Host \u0026#39;Generate SAS Token...\u0026#39; $sas = az storage container generate-sas ` --name $CONTAINER ` --expiry $expiry ` --permission racwdl ` --connection-string $CONN_STR # src ディレクトリ内のファイルをすべてアップロード Write-Host \u0026#39;Upload Files...\u0026#39; azcopy sync --delete-destination true $SRC_DIR ` \u0026#34;https://$STORAGE_ACCOUNT.blob.core.windows.net/${CONTAINER}?$sas\u0026#34; 事前準備としては下記が必要です。 スクリプトの先頭にある $STORAGE_ACCOUNT 変数の値を、アップロード先のストレージアカウント名に変更する 環境変数 STORAGE_ACCOUNT_CONNECTION_STRING に、ストレージアカウントの「接続文字列」を指定しておく Azure CLI (az) と AzCopy (azcopy) を使用できるようにしておく（パスを通しておく） あと、当然ですが、この upload.ps1 スクリプトと同じディレクトリ内に、src ディレクトリを作成し、そこに index.html などのコンテンツファイルを格納してください。 コマンドプロンプトから実行するには下記のようにします。 C:\\\u0026gt; powershell ./upload.ps1 Generate SAS Token... Upload Files..."
},
{
url: "/p/3wk5vnw/",
title: "逆引き Azure CLI: ストレージアカウントのキーを確認する (storage account keys list)",
date: "2020-03-17T00:00:00Z",
body: "逆引き Azure CLI: ストレージアカウントのキーを確認する (storage account keys list) Azure ストレージアカウントのキー（鍵）情報を取得するには、Azure にログイン した状態で、以下のように実行します。 $ az storage account keys list --account-name ストレージアカウント名 [ { \u0026#34;keyName\u0026#34;: \u0026#34;key1\u0026#34;, \u0026#34;permissions\u0026#34;: \u0026#34;Full\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;7s+V+j4CcwDNHyTvx7/UXlgKN4HvFoUuIhOuzH1YLaBWgVTWQadQB2vFjRPTAv2aoGP2mpyQcMm4C+R55o3N9g==\u0026#34; }, { \u0026#34;keyName\u0026#34;: \u0026#34;key2\u0026#34;, \u0026#34;permissions\u0026#34;: \u0026#34;Full\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;+uzKfRt3rCP7RkNBXG93lqEqD7MLvgFQmKxudWHjYbDMUeFH0VmdMhN8V/6ChCwVANi6jaDL4ZKopfwV5RjY9g==\u0026#34; } ] このストレージアカウントキーは、az storage コマンドを使って Azure ストレージ上のデータを操作するときに必要になります。 参考リンク BLOB ストレージにファイルをアップロードする (storage blob upload)"
},
{
url: "/p/hquhjki/",
title: "逆引き Azure CLI: ストレージアカウントの接続文字列を確認する (storage account show-connection-string)",
date: "2020-03-17T00:00:00Z",
body: "逆引き Azure CLI: ストレージアカウントの接続文字列を確認する (storage account show-connection-string) Azure CLI で Azure ストレージアカウントの接続文字列（アカウント名とキーがペアになったもの）を取得するには、az storage account show-connection-string コマンドを使用します。 このコマンドを実行する前に、az login で Azure にログイン しておく必要があります。 ストレージアカウントの接続文字列を取得 $ az storage account show-connection-string --name yourstorage { \u0026#34;connectionString\u0026#34;: \u0026#34;DefaultEndpointsProtocol=https;EndpointSuffix=core.windows.net;AccountName=yourstorage;AccountKey=7s+V+j4CcwDNHyTvxTAv2aoGP2mpyQcMm4C+R7/UXlgKN4HvFoUuIhOuzH1YLaBWgVTWQadQB2vFjRP55o3N9g==\u0026#34; } 参考リンク az storage account show-connection-string コマンド"
},
{
url: "/p/6iuo8aj/",
title: "TypeScriptの型: リテラル型を定義する (Literal types)",
date: "2020-02-04T00:00:00Z",
body: "TypeScriptの型: リテラル型を定義する (Literal types) TypeScript のリテラル型は enum 型（列挙型）の制約を緩めたようなものです。 enum 型は 整数値 で値を保持しますが、リテラル型は 任意の型 で格納可能な値を定義します。 例えば、次のように定義した Answer 型は、その値として yes あるいは no という文字列のみ格納できるようになります。 // Answer というリテラル型を定義する type Answer = `yes` | `no`; // Answer 型の変数には \u0026#39;yes\u0026#39; か \u0026#39;no\u0026#39; のみ格納可能 let answer: Answer answer = \u0026#39;yes\u0026#39;; // OK answer = \u0026#39;no\u0026#39;; // OK answer = \u0026#39;maybe\u0026#39;; // Error answer = 100; // Error 参考リンク TypeScript: 列挙型を定義する (enum) TypeScript: タイプエイリアスを定義する (type)"
},
{
url: "/p/5zoqtmi/",
title: "TypeScriptの型: タイプエイリアスを定義する (type)",
date: "2019-09-26T00:00:00Z",
body: "TypeScriptの型: タイプエイリアスを定義する (type) TypeScript の タイプエイリアス (Type alias) を使用すると、既存の型を組み合わせて新たな型を定義することができます。 下記の例では、string 型と number 型の 2 つの値を保持する Person という型を定義しています。 タイプエイリアスの定義では、代入 (=) の構文を使用すること注意してください。 type Person = { name: string; age: number; }; let p: Person = { name: \u0026#39;Maku\u0026#39;, age: 14 }; console.log(p.name); console.log(p.age); Person 型の変数を初期化するときは、上記のように各プロパティの値を漏れなく明示する必要があります。 次のように、プロパティの指定に過不足があるとコンパイルエラーが発生します。 間違った例 let p1: Person = { name: \u0026#39;Maku\u0026#39; }; // プロパティが不足 let p2: Person = { name: \u0026#39;Maku\u0026#39;, age: 14, xxx: 20 }; // 未知のプロパティ エラーメッセージ sample.ts:6:5 - error TS2741: Property \u0026#39;age\u0026#39; is missing in type \u0026#39;{ name: string; }\u0026#39; but required in type \u0026#39;Person\u0026#39;. sample.ts:7:43 - error TS2322: Type \u0026#39;{ name: string; age: number; xxx: number; }\u0026#39; is not assignable to type \u0026#39;Person\u0026#39;. Object literal may only specify known properties, and \u0026#39;xxx\u0026#39; does not exist in type \u0026#39;Person\u0026#39;. 参考リンク TypeScript: リテラル型を定義する (Literal types)"
},
{
url: "/p/cdazjwv/",
title: "TypeScriptの型: 共用体を定義する (Union types)",
date: "2019-09-26T00:00:00Z",
body: "TypeScriptの型: 共用体を定義する (Union types) 共用体 (union) の基本 変数の型をタイプアノテーションで指定するときに、複数の型を | (or) でつなげて指定すると、それらのいずれの型の値でも格納できる 共用体 (union) となります。 例: 文字列と数値を格納できる変数 let a: string | number; a = \u0026#39;Hello\u0026#39;; // OK a = 123; // OK a = true; // NG 例: 文字列あるいは数値のパラメータをとる関数 function foo(value: string | number) { // ... } 共用体のタイプエイリアスを定義する ある種類の共用体を繰り返し使用する場合、タイプエイリアスを定義しておくと、何度も同じ記述をしなくて済みます。 // interface Context {}; type ContextOrString = Context | string; 定義したタイプエイリアスは、通常の型と同様に使用することができます。 function onMessage(context: ContextOrString) { // ... }"
},
{
url: "/p/fdjk4hh/",
title: "TypeScriptの型: 列挙型を定義する (enum)",
date: "2019-09-26T00:00:00Z",
body: "TypeScriptの型: 列挙型を定義する (enum) 列挙型 (enum) の基本 TypeScript で列挙型を定義するには、enum キーワードを使用します。 enum Fruits { Apple, //= 0 Banana, //= 1 Orange //= 2 } console.log(Fruits.Apple); //=\u0026gt; 0 console.log(Fruits[Fruits.Apple]); //=\u0026gt; Apple デフォルトでは、各要素の値として先頭から順番に 0、1、2 という連番の 整数値 が内部的に割り当てられます（C 言語や Java と同様です）。 この値は任意の数値に変更することができます。 次の例は、ビットフラグとして使用することを想定した enum の定義例です。 各値が 2 のべき乗の値になっていることに注意してください。 enum OpenModes { Read = 1, Write = 2, Append = 4 } const mode = OpenModes.Read | OpenModes.Write; if ((mode \u0026amp; OpenModes.Write) == OpenModes.Write) { console.log(\u0026#39;Write フラグが指定されています\u0026#39;); } enum 値をインライン展開する (Constant enumeration) enum 定義を行うときに const キーワードを付加すると、その enum 値を使用した場所に値がハードコードされる形で展開されます（JavaScript のコードに変換するときに、0 や 1 といった値をインライン展開する）。 TypeScript のコード enum NormalEnum { A, B, C } const enum ConstEnum { A, B, C } console.log(NormalEnum.A) console.log(ConstEnum.A) 上記の TypeScript が JavaScript にトランスパイルされると、enum 値の参照箇所はそれぞれ下記のように出力されます。 JavaScript に変換されたコード // ...省略... console.log(NormalEnum.A); console.log(0 /* A */); ConstEnum.A という部分は、0 という値でハードコードされているのが分かります。 参考リンク TypeScript: リテラル型を定義する (Literal types)"
},
{
url: "/p/q8hry9h/",
title: "MongoDB サーバー (mongod デーモン)",
date: "2015-04-13T00:00:00Z",
body: "MongoDB サーバー (mongod デーモン)"
},
{
url: "/p/vm2ft83/",
title: "React フック: useSWR でデータフェッチ",
date: "2021-06-22T00:00:00Z",
body: "React フック: useSWR でデータフェッチ SWR とは useSWR フック SWR (useSWR) は、Next.js を開発している人たち (Vercel) が開発したデータフェッチ用の React フックライブラリです。 React アプリでデータフェッチを真面目に実装しようとすると、大体最後にこのライブラリに行き着きますので、最初からこれを使いましょう（GraphQL の場合は Apollo Client がありますが）。 SWR - React Hooks library for data fetching React コンポーネント内から Web API などを呼び出してデータフェッチを行う場合、標準の仕組みだけで実現しようとすると、useEffect フックなどで fetch 関数を呼び出したりすることになります。 useEffect による不完全なデータフェッチ実装 function Page () { const [user, setUser] = useState(null) useEffect(() =\u0026gt; { fetch(\u0026#39;/api/user\u0026#39;) .then(res =\u0026gt; res.json()) .then(data =\u0026gt; setUser(data)) }, []) // ... } もちろん、それで実現は可能なのですが、「データ取得前の表示」「エラー処理/リトライ処理」「非同期処理のキャンセル処理」などをちゃんとやろうとすると非常に煩雑なコードになってきます（上記コードはそれらが全く考慮できていません）。 useSWR フックを使うと、クライアントサイド JavaScript からのデータフェッチ処理をとても綺麗に記述することができます。 useSWR の使用例 import { FC } from \u0026#39;react\u0026#39; import useSWR from \u0026#39;swr\u0026#39; const fetcher = (url: string) =\u0026gt; fetch(url).then((r) =\u0026gt; r.json()) const Profile: FC = () =\u0026gt; { const { data, error } = useSWR(\u0026#39;/api/user\u0026#39;, fetcher) if (error) return \u0026lt;div\u0026gt;Failed to load\u0026lt;/div\u0026gt; if (!data) return \u0026lt;div\u0026gt;Loading...\u0026lt;/div\u0026gt; return \u0026lt;div\u0026gt;Hello {data.name}!\u0026lt;/div\u0026gt; } export default FC useSWR の特徴 useSWR は高度なキャッシュコントロール機能を備えています。 キー名によるキャッシュ共有 第1パラメータのキー名を共通にするだけで、ページ間でキャッシュを共有できます。 useEffect などでデータフェッチを行おうとすると、無駄なフェッチを防ぐために、トップレベルのコンポーネントで一度だけデータ取得して子コンポーネントにたらい回ししていく、という実装になりがちです。 useSWR であれば、各コンポーネントで個別にデータフェッチする感覚で呼び出せます。 自動リトライ、ポーリング エラー発生時のリトライ処理 (exponential backoff アルゴリズム)、ネットワーク復帰時の自動フェッチ ({ revalidateOnReconnect: true })、ブラウザのタブ切り替え時の自動フェッチ ({ revalidateOnFocus: true }) などをデフォルトで行ってくれるため、ユーザーが最新データにアクセスしやすくなります。これらの設定は useSWR 呼び出し時のオプションで制御できます（参考: useSWR のオプション）。 手動でのキャッシュ更新（ミューテート） useSWR フックは、任意のタイミングでキャッシュ更新をかけるためのミューテート関数 (mutate) を提供してくれます。キャッシュが更新されると、自動的にコンポーネントは再描画されます。また、グローバルな mutate API も提供されており、指定したキーのキャッシュをどこからでも更新できます。 フェッチ関数は自由 useSWR フックは、デフォルトでフェッチ関数として fetch を使用（JSONデータを想定）しますが、Promise を返す任意のフェッチ関数を使用することができます。 TypeScript、Next.js 対応 Vercel 製なので、もちろん Next.js に対応していて、プリレンダリング時にも呼び出せます。Web サイトビルド時にはその時点でのデータで静的なページを生成しておいて、実行時は最新データをフェッチ＆キャッシュするといったことが可能です。TypeScript の型情報も標準でサポートしています。 （コラム） SWR = stale-while-revalidate SWR という名前の由来は、RFC5861 で提唱されている HTTP レスポンスヘッダの Cache-Control 拡張のひとつである stale-while-revalidate から来ています。 Cache-Control はデータフェッチ後のキャッシュ有効期間を示すために導入されたもので、例えば、Cache-Control: max-age=600 が返された場合は、ブラウザは 600 秒間キャッシュを保持します（その間のデータフェッチ要求ではサーバーアクセスしない）。 そして、600 秒経過するとキャッシュは古い (stale) とみなされて、次のデータフェッチ時には実際にサーバーアクセスが発生します。 このとき、データフェッチ処理が同期的に行われるため、ユーザーはデータ表示まで少し待たされることになります。 この待ち時間を軽減しようというのが stale-while-revalidate (SWR) という拡張で、例えば、 Cache-Control: max-age=600, stale-while-revalidate=300 というレスポンスが返されると、max-age の 600 秒経過後も、stale-while-revalidate で指定された 300 秒間は、古いキャッシュ (stale cache) がブラウザでの描画に使われます。 そして、その背後でサーバーに対してデータフェッチを行うことで、キャッシュの更新も同時に行います。 この仕組みにより、（多少古いかもしれない）キャッシュでとりあえず高速に初期表示しつつ、常に最新のデータをキャッシュしておく、ということが実現できます。 React ライブラリの useSWR フックもこの思想をもとに実装されており、ブラウザ側のキャッシュを使って高速な表示をしつつ、背後でキャッシュの更新を行って必要に応じて再描画を行う、といったことを可能にしています。 useSWR フックのすごいところは、この辺りの複雑なキャッシュコントロールを意識せずに、シンプルにデータフェッチ処理を記述できるところにあります。 SWR のインストール SWR フックライブラリは yarn あるいは npm で簡単にインストールできます。 ### yarn の場合 $ yarn add swr ### npm の場合 $ npm install swr これで、次のように useSWR 関数をインポートできるようになります。 import useSWR from \u0026#39;swr\u0026#39; useSWR 関数の使い方 基本的な使い方 下記のコンポーネントは、GitHub のユーザー情報を REST API を使って取得＆表示します。 src/components/GitHubUser.tsx import { FC } from \u0026#39;react\u0026#39; import useSWR from \u0026#39;swr\u0026#39; const fetcher = (url: string) =\u0026gt; fetch(url).then((r) =\u0026gt; r.json()) type Props = { login: string } // コンポーネントの props の型 type Data = { name: string } // フェッチするデータの型 export const GitHubUser: FC\u0026lt;Props\u0026gt; = ({ login }: Props) =\u0026gt; { const url = `https://api.github.com/users/${login}` const { data, error } = useSWR\u0026lt;Data, Error\u0026gt;(url, fetcher) if (error) return \u0026lt;div\u0026gt;Failed to load\u0026lt;/div\u0026gt; if (!data) return \u0026lt;div\u0026gt;Loading...\u0026lt;/div\u0026gt; return \u0026lt;div\u0026gt;Name: {data.name}\u0026lt;/div\u0026gt; } // 使用例: \u0026lt;GitHubUser login=\u0026#34;octocat\u0026#34; /\u0026gt; useSWR 関数の第1パラメーターは、フェッチ関数に渡すパラメーターであり、キャッシュを識別するためのキーとしても使われます。 典型的には Web API の URL を渡しますが、配列の形で付加データを渡すことも可能です。 戻り値の data プロパティには、フェッチ関数によって取得したデータ（Promise.resolve() された値）が格納されますが、データ取得が完了するまでは data の値は undefined になります。 なので、ロード中であるかどうかを if (!data) で簡単に判別できます（isLoading とか存在しません）。 error プロパティも同様で、エラーが発生していなければ undefined になり、エラーが発生したらエラー内容（Promise.reject() された値）が格納されます。 フェッチ関数を指定する useSWR の第2パラメーターでは、データフェッチに使用するフェッチ関数を指定することができます。 下記は、JSON データを返す Web API を呼び出すときに使う典型的なフェッチ関数の使用例です。 const fetcher = (url: string) =\u0026gt; fetch(url).then((r) =\u0026gt; r.json()) export const Hello: FC = () =\u0026gt; { // ... const { data, error } = useSWR\u0026lt;Data, Error\u0026gt;(url, fetcher) // ... } フェッチ関数と言うと特殊なもののように聞こえますが、単なる getter 関数であり、Promise\u0026lt;Xxx\u0026gt; を返す非同期関数であれば、そのままフェッチ関数として使えると考えればよいです。 次の例では、fetchBookData 関数をフェッチ関数として使用しています。 この fetchBookData 関数はそれ単独でも使えるものですが、それをそのまま useSWR に渡すことができます。 src/components/BookList.tsx import useSWR from \u0026#39;swr\u0026#39; type BookData = { author: string titles: string[] } async function fetchBookData(author: string): Promise\u0026lt;BookData\u0026gt; { try { // ...本当はここで fetch 処理など const bookData = { author: author, titles: [\u0026#39;Title1\u0026#39;, \u0026#39;Title2\u0026#39;, \u0026#39;Title3\u0026#39;], } return bookData } catch (err) { // Error を再スローするだけなら、通常は try ... catch は必要ない throw err } } const BookList: React.FC = () =\u0026gt; { const { data: bookData, error } = useSWR\u0026lt;BookData, Error\u0026gt;(\u0026#39;Author1\u0026#39;, fetchBookData) if (error) return \u0026lt;p\u0026gt;Error: {error.message}\u0026lt;/p\u0026gt; if (!bookData) return \u0026lt;p\u0026gt;Loading...\u0026lt;/p\u0026gt; return ( \u0026lt;ul\u0026gt; {bookData.titles.map((title) =\u0026gt; ( \u0026lt;li key={title}\u0026gt; {bookData.author} - {title} \u0026lt;/li\u0026gt; ))} \u0026lt;/ul\u0026gt; ) } パラメーターが 2 つ以上の関数をフェッチ関数として使いたい場合は、useSWR の第1パラメータ―に引数を配列でまとめて渡します。 フェッチ関数側に配列が渡されるわけではないことに注意してください。 // パラメーターが 2 つ必要なフェッチ関数 async function fetchData(key1: string, key2: string): Promise\u0026lt;Data\u0026gt; { // ... } // useSWR 経由で上記関数を呼び出す export const MyComponent: FC = () =\u0026gt; { const { data, error } = useSWR\u0026lt;Data, Error\u0026gt;([\u0026#39;aaa\u0026#39;, \u0026#39;bbb\u0026#39;], fetchData) // ... } フェッチ関数の仕組みは非常に柔軟で、時間がかかるデータフェッチをシミュレートしたり、エラーが発生したときにどう見えるかを簡単に確認できます。 例えば次のフェッチ関数は 1 秒後に現在時刻を返すか、エラーを発生させます。 通常、フェッチ関数のパラメーターとして、useSWR の第 1 引数で渡された値を受け取りますが、このフェッチ関数は特殊でパラメーターなしです。 const fetchCurrentTime = async () =\u0026gt; { // 1秒待つ await new Promise((res) =\u0026gt; setTimeout(res, 1000)) // 現在時刻の文字列を返すか、エラーを発生させる if (Math.random() \u0026gt; 0.3) { return new Date().toLocaleString() } else { throw new Error(\u0026#39;An error has occurred!\u0026#39;) } } // 使用例 const { data, error } = useSWR\u0026lt;string, Error\u0026gt;(\u0026#39;/fake\u0026#39;, fetchCurrentTime) フェッチ関数の中でスローした Error オブジェクトは、useSWR 関数の戻り値オブジェクトの error プロパティにされます（エラーがしなかった場合は undefined）。 フェッチ関数を省略する SWRConfig コンポーネント を使用すると、子コンポーネント内で useSWR を使用するときの共通設定（グローバル設定）を行うことができます。 具体的には、useSWR の第 3 引数に渡すオプションオブジェクトのデフォルト値として扱われます。 このオブジェクトには、次のようにのフェッチ関数 (fetcher) を指定しておくことができます。 pages/_app.tsx import type { AppProps } from \u0026#39;next/app\u0026#39; import { SWRConfig } from \u0026#39;swr\u0026#39; /** Default fetcher for useSWR hook. */ const fetcher = (url: string) =\u0026gt; fetch(url).then((r) =\u0026gt; r.json()) export default function MyApp({ Component, pageProps }: AppProps): JSX.Element { return ( \u0026lt;SWRConfig value={{ fetcher }}\u0026gt; \u0026lt;Component {...pageProps} /\u0026gt; \u0026lt;/SWRConfig\u0026gt; ) } これで、子コンポーネントから useSWR 関数を呼び出すときにフェッチ関数を省略できるようになります。 const { data: projects } = useSWR(\u0026#39;/api/projects\u0026#39;) useSWR はカスタムフックにラップして使う useSWR 特有の話ではないですが、データフェッチ処理に関してはコンポーネントの実装から分離して、カスタムフックの形で定義しておくと保守性の高いコードになります。 次の useIssueCount カスタムフックは、指定した GitHub リポジトリ ($org/$repo) のイシュー数を取得します。 src/hooks/useIssueCount.ts import useSWR from \u0026#39;swr\u0026#39; type UseIssueCountInput = { org: string repo: string } type UseIssueCountOutput = { count?: number error?: Error isLoading: boolean } const fetcher = (url: string) =\u0026gt; fetch(url).then((r) =\u0026gt; r.json()) export const useIssueCount = ( input: UseIssueCountInput ): UseIssueCountOutput =\u0026gt; { const { org, repo } = input const url = `https://api.github.com/repos/${org}/${repo}/issues` const { data, error } = useSWR\u0026lt;[], Error\u0026gt;(url, fetcher) return { count: data?.length, error, isLoading: !error \u0026amp;\u0026amp; !data, } } そして描画を担うコンポーネント側の実装では、データ取得処理はカスタムフックの呼び出しだけで済ませます。 カスタムフックを呼び出している時点で、データ取得処理が完全に分離できているとは言えませんが、こうすることで「見た目」の定義に集中できます。 src/components/IssueCount.tsx（使用例） import { FC } from \u0026#39;react\u0026#39; import { useIssueCount } from \u0026#39;../hooks/useIssueCount\u0026#39; export const IssueCount: FC = () =\u0026gt; { const { count, error, isLoading } = useIssueCount({ org: \u0026#39;vercel\u0026#39;, repo: \u0026#39;swr\u0026#39;, }) if (error) return \u0026lt;div\u0026gt;Error\u0026lt;/div\u0026gt; if (isLoading) return \u0026lt;div\u0026gt;Loading...\u0026lt;/div\u0026gt; return \u0026lt;div\u0026gt;Count: {count}\u0026lt;/div\u0026gt; } ちなみに、さらに「見た目」と「ロジック」を分離する手法に、Presentational component / Container component という方法があります。 これは、React コンポーネントを「見た目」用と「ロジック」用の 2 種類に分けて実装する考え方です。 Presentational component \u0026hellip; 純粋な UI コンポーネント。渡された props をそのまま表示するだけ。 Cotainer component \u0026hellip; ロジック（フックなどの呼び出し）を含むコンポーネント。内部でのデータ取得結果などを Presentational component に props で渡す。 応用 フェッチ関数に追加のデータを渡す API 呼び出し時に、フェッチ関数にトークン情報を渡したいことがあるかもしれません。 そのような場合は、useSWR 関数のキーパラメータを配列にすることで、トークン情報が変化した時に再フェッチさせることができます。 const { data: user } = useSWR([\u0026#39;/api/user\u0026#39;, token], fetchWithToken) フェッチ関数 fetchWithToken は、2 つのパラメーター（上の例であれば、/api/user と token）を受け取り、Promise\u0026lt;Xxx\u0026gt; を返すように実装します。 パラメーターとして配列を受け取るわけではないことに注意してください（配列の要素が個別パラメーターとして渡されてきます）。 type Output = { user: string } async function fetchWithToken(url: string, token: string): Promise\u0026lt;Output\u0026gt; { // ... return { user: \u0026#39;Jojo\u0026#39; } } 依存関係のある useSWR の連続呼び出し useSWR 関数の第1パラメーターが偽とみなされる値 (falsy) 場合、フェッチ処理はスキップされます。 次の例では、この性質を利用して、1番目の useSWR の結果を取得した段階で、2番目の useSWR によるデータフェッチを発火させています。 それまでは、1番目の useSWR の結果のみを使ってコンポーネントが描画されます。 const { data: user } = useSWR([\u0026#39;/api/user\u0026#39;, token], fetchWithToken) const { data: orders } = useSWR(user ? [\u0026#39;/api/orders\u0026#39;, user] : null, fetchWithUser) ちなみに、useSWR は React フックなので、データフェッチが必要ないケースでも上記のように必ず呼び出す必要があります（条件分岐して呼び出し自体をスキップしてはいけません）。 フェッチ関数から独自のエラーを投げる useSWR 関数の第 2 引数で指定した独自のフェッチ関数からエラーオブジェクトを throw すると、useSWR 関数の戻り値オブジェクトの error プロパティとして受け取ることができます。 useSWR 関数を使用する箇所で、データフェッチに関する細かいエラー処理を行いたいのであれば、フェッチ関数の中で詳細情報を詰めたエラーオブジェクトを throw すれば OK です。 // 独自のエラークラスの定義例 export class GameError extends Error { errorId: string // 独自のエラー ID statusCode: number // HTTP ステータスコード constructor(errorId: string, statusCode: number, message?: string) { // Error オブジェクト用の設定 super(message ?? `Error ${errorId}occurred.`) this.name = new.target.name // 独自のエラー情報 this.errorId = errorId this.statusCode = statusCode } } // 独自のフェッチ関数 export async function fetchGame(url: string): Promise\u0026lt;Game\u0026gt; { const res = await fetch(url) if (!res.ok) { // ステータスコードが 2xx 以外の場合は、独自エラーを投げる throw new GameError(\u0026#39;FETCH_GAME_ERROR\u0026#39;, res.status) } return (await res.json()) as Game } useSWR を呼び出すときは、第 2 型パラメーターでエラーオブジェクトの型を指定できます。 const { data, error } = useSWR\u0026lt;Game, GameError\u0026gt;(url, fetchGame) if (error) { console.error(error.errorId) // FETCH_GAME_ERROR console.error(error.statusCode) // 404 など console.error(error.message) // Error FETCH_GAME_ERROR occurred. }"
},
{
url: "/p/w8s8kx9/",
title: "AWS CloudFormation で Lambda 関数のリソースを生成する",
date: "2021-04-05T00:00:00Z",
body: "AWS CloudFormation で Lambda 関数のリソースを生成する 何をするか？ AWS CloudFormation を使うと Lambda 関数を含むインフラ（AWS リソース群）をまとめて生成することができますが、AWS CloudFormation の拡張である AWS SAM を使うと、もっと簡潔に Lambda 関数のリソースを生成することができます。 例えば、CloudFormation テンプレートの AWS::Lambda::Function リソースでは、Role プロパティが必須でしたが、SAM テンプレートの AWS::Serverless::Function リソースでは、Role プロパティはオプショナルになっています。 Role プロパティを省略すると、Lambda 関数に付けた論理 ID (Logical ID) をもとに、\u0026lt;論理ID\u0026gt;Role という名前のロールが自動生成されます。 ここでは、AWS SAM を使った Lambda 関数生成の基本として、次のようなパターンで CloudFormation スタックを生成してみます。 SAM テンプレートに関数コードを埋め込んでデプロイ S3 バケット上の関数の ZIP ファイルを使ってデプロイ SAM テンプレートに関数コードを埋め込んでデプロイ まずは、一番シンプルな例として、SAM テンプレート内に Lambda 関数の実装をハードコーディングしてしまい、それをデプロイ（CloudFormation スタックの生成）してみます。 下記が SAM テンプレートです。 SAM で Lambda 関数のリソースを定義するときは、リソースタイプとして AWS::Serverless::Function を指定します（CloudFormation では AWS::Lambda::Function です）。 ここでは関数の実装を InlineCode プロパティでハードコーディングし、単純な Hello World! メッセージをレスポンスとして返すようにしています。 template.yml AWSTemplateFormatVersion:\u0026#39;2010-09-09\u0026#39;Transform:AWS::Serverless-2016-10-31Description:Simple Lambda FunctionResources:HelloFunction:Type:AWS::Serverless::FunctionProperties:Runtime:python3.7Handler:index.handlerInlineCode:|def handler(event, context): return {\u0026#39;body\u0026#39;: \u0026#39;Hello World!\u0026#39;, \u0026#39;statusCode\u0026#39;: 200} この例では省略していますが、Function リソースのプロパティ PackageType はデフォルトで Zip となっており、この場合は、関数の実体を CodeUri（ZIP ファイルのパス）か、InlineCode（ハードコーディング）のどちらかで指定します。 この例では、InlineCode で関数の内容を埋め込んでいます。 SAM テンプレートを記述したら、次のようにして CloudFormation のスタックを生成できます。 Lambda 関数のサービスロール（実行ロール）を自動生成するために、--capabilities CAPABILITY_IAM オプションの指定が必要です。 スタックの生成 $ aws cloudformation deploy --stack-name mystack \\ --template-file template.yml \\ --capabilities CAPABILITY_IAM スタックの作成が完了したら、次のようにしてスタック情報を確認できます。 スタック内に生成された Lambda 関数リソースの情報を見てみましょう。 作成したスタックの情報を表示 # スタックの情報 $ aws cloudformation describe-stacks --stack-name mystack # リソースの一覧（ここでは Lambda 関数と自動生成された IAM ロール） $ aws cloudformation describe-stack-resources --stack-name mystack describe-stack-resources の実行結果 StackResources:- DriftInformation:StackResourceDriftStatus:NOT_CHECKEDLogicalResourceId:HelloFunctionPhysicalResourceId:mystack-HelloFunction-1DVW05LYWG4L2ResourceStatus:CREATE_COMPLETEResourceType:AWS::Lambda::FunctionStackId:arn:aws:cloudformation:ap-northeast-1:123456789012:stack/mystack/bc300a10-967f-11eb-9e10-0a2f97775449StackName:mystackTimestamp:\u0026#39;2021-04-06T02:29:10.784000+00:00\u0026#39;- DriftInformation:StackResourceDriftStatus:NOT_CHECKEDLogicalResourceId:HelloFunctionRolePhysicalResourceId:mystack-HelloFunctionRole-OCUMJ1FS9U0IResourceStatus:CREATE_COMPLETEResourceType:AWS::IAM::RoleStackId:arn:aws:cloudformation:ap-northeast-1:123456789012:stack/mystack/bc300a10-967f-11eb-9e10-0a2f97775449StackName:mystackTimestamp:\u0026#39;2021-04-06T02:29:07.591000+00:00\u0026#39; 作成された Lambda 関数リソース (AWS::Lambda::Function) の PhysicalResouceID を見ると、Lambda 関数の物理 ID (Physical ID) が、スタック名と論理 ID (Logical ID) の組み合わせで自動的に作成されていることが分かります（ここでは mystack-HelloFunction-1DVW05LYWG4L2）。 この物理 ID は、Lambda のマネージメントコンソール上で関数名として表示される名前です。 つまり、CloudFormation の外の世界から見える名前であり、アカウント内で一意な Lambda 関数名です。 Lambda 関数の物理 ID が分かれば、次のように CLI からテスト実行することができます。 Lambda 関数を呼び出してみる $ aws lambda invoke --function-name mystack-HelloFunction-1DVW05LYWG4L2 out.txt ExecutedVersion: $LATEST StatusCode: 200 $ cat out.txt {\u0026#34;body\u0026#34;: \u0026#34;Hello World!\u0026#34;, \u0026#34;statusCode\u0026#34;: 200} 最後に CloudFormation のスタックを削除しておきます。 スタックごと全てのリソースを削除 $ aws cloudformation delete-stack --stack-name mystack これで、スタック内に生成した Lambda 関数（およびそれ用のロール）などのリソースが全て消え去ります。すっきりすっきり。 S3 バケット上の関数の ZIP ファイルを使ってデプロイ 外部ライブラリなどを利用する Lambda 関数を作成する場合は、それらをまとめて ZIP 化して S3 バケットにアップロードしておく必要があります。 SAM テンプレート（CloudFormation テンプレート）では、S3 バケット上の ZIP ファイルを参照して Lambda 関数リソースを生成するように記述します。 S3 バケットに Lambda 関数の ZIP をアップロード まずは ZIP ファイル置き場にする S3 バケットを作成しておきます。 関数のコード自体は GitHub などで管理するでしょうから、この S3 バケットは一時的な転送用のバッファ、くらいの感覚で使えばよいと思います。 $ aws s3 mb s3://bucket-123456789012-functions ここでは、次のような Lambda 関数コードを ZIP 化することにします（簡単にするため依存ライブラリはなし）。 src/index.py def handler(event, context): return {\u0026#39;body\u0026#39;: \u0026#39;Hello World!\u0026#39;, \u0026#39;statusCode\u0026#39;: 200} src ディレクトリ内のコードを ZIP ファイルにまとめます。 $ (cd src \u0026amp;\u0026amp; zip -r ../function.zip *) あとは、次のように S3 バケットにアップロードします。 $ aws s3 cp function.zip s3://bucket-123456789012-functions S3 バケットの ZIP を使って Lambda 関数をデプロイ（CloudFormation スタックを生成） SAM テンプレート内から、S3 バケット上の ZIP ファイルを参照するには次のように記述します。 template.yml AWSTemplateFormatVersion:\u0026#39;2010-09-09\u0026#39;Transform:AWS::Serverless-2016-10-31Description:Simple Lambda FunctionResources:HelloFunction:Type:AWS::Serverless::FunctionProperties:Runtime:python3.7Handler:index.handlerCodeUri:s3://bucket-123456789012-functions/function.zip InlineCode プロパティで関数実装をハードコードしていた部分を削除し、CodeUri プロパティで S3 バケット上の ZIP ファイルを指定するようにします。 スタックの生成コマンドは、前述の例と同じです。 スタックの生成 $ aws cloudformation deploy --stack-name mystack \\ --template-file template.yml \\ --capabilities CAPABILITY_IAM （応用）S3 への ZIP アップロードも CloudFormation で行う 上記の例では、aws s3 cp コマンドで Lambda 関数の ZIP ファイルを S3 バケットにアップロードしていましたが、aws cloudformation package コマンドで同様のことを行うことができます。 前提条件として、ローカルに function.zip の作成はできているとします。 SAM テンプレートを次のように書き換えます。 変更点は、CodeUri プロパティの値が、S3 バケット上の ZIP オブジェクトではなく、ローカルファイルを示す function.zip になっているところです。 template.yml AWSTemplateFormatVersion:\u0026#39;2010-09-09\u0026#39;Transform:AWS::Serverless-2016-10-31Description:Simple Lambda FunctionResources:HelloFunction:Type:AWS::Serverless::FunctionProperties:Runtime:python3.7CodeUri:function.zipHandler:index.handler 次のように実行すると、ローカルの function.zip ファイルが --s3-bucket オプションで指定した S3 バケットにアップロードされ、新しい SAM テンプレートファイル (template-pkg.yml) が生成されます。 function.zip を S3 バケットへアップロードしてテンプレート生成 $ aws cloudformation package --template-file template.yml \\ --s3-bucket bucket-123456789012-functions \\ --output-template-file template-pkg.yml 生成される SAM テンプレートの内容は次のようになっています。 template-pkg.yml（自動生成） AWSTemplateFormatVersion:\u0026#39;2010-09-09\u0026#39;Transform:AWS::Serverless-2016-10-31Description:Simple Lambda FunctionResources:HelloFunction:Type:AWS::Serverless::FunctionProperties:Runtime:python3.7CodeUri:s3://bucket-123456789012-functions/c70430a6ec3e54f77073b5209ecea744Handler:index.handler CodeUri の値が置換されており、S3 バケット上にアップロードされた ZIP ファイルを示す URI に変わっています。 オブジェクト名は function.zip ファイルのハッシュコードになっており、ZIP ファイルの内容が変わるとオブジェクト名も変わるようになっています（つまり、package するたびに、S3 バケット内に別名の ZIP ファイルが溜まっていきます）。 あとは、前述の例と同様に、自動生成された SAM テンプレートを使って、CloudFormation スタックを生成するだけです（template.yml ではなく、自動生成された template-pkg.yml を指定することに注意してください）。 $ aws cloudformation deploy --stack-name mystack \\ --template-file template-pkg.yml \\ --capabilities CAPABILITY_IAM （応用）ZIP パッケージ化も CloudFormation で行う ここまでは、ローカルに Lambda 関数用の ZIP ファイルを作成しておく前提でしたが、実は ZIP 化と S3 へのアップロードは aws cloudformation package コマンドでまとめて行うことができます。 例えば、プロジェクトのディレクトリ構成が次のようになっていて、src 以下のファイル群を ZIP 化したいとします。 - template.yml - src/ +-- index.py SAM テンプレート内の CodeUri プロパティ で、ZIP ファイル名の代わりに src ディレクトリを指定するようにします。 Handler プロパティは、src ディレクトリからの相対パスで指定します。 template.yml AWSTemplateFormatVersion:\u0026#39;2010-09-09\u0026#39;Transform:AWS::Serverless-2016-10-31Resources:HelloFunction:Type:AWS::Serverless::FunctionProperties:Runtime:python3.7CodeUri:src/Handler:index.handler あとはこれまでと同様に、次のように package コマンドを実行します。 $ aws cloudformation package --template-file template.yml \\ --s3-bucket bucket-123456789012-functions \\ --output-template-file template-pkg.yml すると、src ディレクトリ内のファイル群が内部的に ZIP 化されて S3 バケットにアップロードされます（ローカルに ZIP ファイルは生成されません）。 CodeUri が S3 バケットの URI に書き換わったテンプレートが生成されるので、次のように deploy コマンドで CloudFormation スタックを生成（更新）すればデプロイ完了です。 $ aws cloudformation deploy --stack-name mystack \\ --template-file template-pkg.yml \\ --capabilities CAPABILITY_IAM この方法の注意点としては、CodeUri で指定したディレクトリ（ここでは src）の下のファイル群がすべて ZIP にパッケージングされてしまう という点です。 カスタマイズされた方法で ZIP パッケージを作成したい場合（特定のファイルを含めたくないときなど）は、この方法は使えないかもしれません。 参考リンク AWS Lambda にデプロイするための ZIP パッケージを npm で作成する (npm-pack-zip)"
},
{
url: "/p/n4yqdys/",
title: "逆引き Azure CLI: Azure ストレージの SAS トークンを生成する (storage container generate-sas)",
date: "2020-03-17T00:00:00Z",
body: "逆引き Azure CLI: Azure ストレージの SAS トークンを生成する (storage container generate-sas) Azure ストレージの操作を行うとき、有効期限付きのアクセストークンである SAS トークン が必要になることがあります。 SAS トークンは、az storage container generate-sas コマンドで生成することができます。 実際は 1 行 $ az storage container generate-sas --name \u0026lt;BLOBコンテナー名\u0026gt; --expiry \u0026#34;2020-07-07T00:00:00Z\u0026#34; --permission acdlrw --connection-string \u0026lt;ストレージアカウントの接続文字列\u0026gt; ストレージアカウントの接続文字列さえあれば、特に Azure ログインしたりせずに生成できます。 接続文字列自体を Azure CLI で取得することもできます。 SAS トークン生成時に指定するオプションの詳細は下記のコマンドリファレンスを参照してください。 参考リンク az storage container generate-sas コマンド 実行に成功すると、次のような文字列が標準出力に出力されます。 これが SAS トークンです。 \u0026#34;se=2020-07-07T00%3A00%3A00Z\u0026amp;sp=racwdl\u0026amp;sv=2018-11-09\u0026amp;sr=c\u0026amp;sig=c7bapOBvLkHVlebBIEQFQc2bGd%2BjmfScqKCbkLUzzoo%3D\u0026#34; この SAS トークンは、AzCopy (azcopy) ツールなどで、BLOB ストレージにファイル転送したりするときに必要になります。 SAS トークンの生成には、有効期限を示す --expiry オプションの指定が必須になっています（なくてもトークンの生成には成功しますが、使用時に認証エラーになるようです。不親切）。 ここで指定する日時のフォーマットは、少しでも間違えると出力される SAS トークンの se パラメータが無効なものになってしまうので要注意です（こちらも生成時にはエラーになりません。不親切）。 生成される SAS トークンの最後には、このトークン自体の署名がついています。 これにより、SAS トークン内の有効期限 (se) などを部分的に改ざんしたりできないようになっています。"
},
{
url: "/p/ptx36ue/",
title: "逆引き Azure CLI: BLOB ストレージにファイルをアップロードする (storage blob upload)",
date: "2020-03-17T00:00:00Z",
body: "逆引き Azure CLI: BLOB ストレージにファイルをアップロードする (storage blob upload) Azure CLI を使ってストレージアカウント上に作成された、既存の BLOB コンテナにコンテンツをアップロードするには、az storage blob upload コマンドを使用します。 Azure ポータルのサイト上でポチポチやってアップロードすることもできますが、自動化のことを考えると、コマンドラインを使った方がよいでしょう。 書式 az storage blob upload --account-name \u0026lt;ストレージアカウント名\u0026gt; --account-key \u0026lt;キー\u0026gt; -c \u0026lt;コンテナ名\u0026gt; --file \u0026lt;ローカルファイル名\u0026gt; --name \u0026lt;アップロード後のファイル名\u0026gt; 実行例 $ az storage blob upload --account-name yourstorage --account-key vFjRP7s+V+j4CcwDNHyTvxT7/UXlgKN4HvFoUuIhOuzH1YLaBWgVTWQadQB2Av2aoGP2mpyQcMm4C+R55o3N9g== -c $web --file index.html --name index.html Finished[#############################################################] 100.0000% { \u0026#34;etag\u0026#34;: \u0026#34;\\\u0026#34;0x8D7CA465578BC90\\\u0026#34;\u0026#34;, \u0026#34;lastModified\u0026#34;: \u0026#34;2020-03-17T07:39:32+00:00\u0026#34; } アップロード時にストレージアカウントのキーを指定するので、あらかじめ az login で Azure にログインしておく必要はありません。 参考リンク 逆引き Azure CLI: ストレージアカウントのキーを確認する (storage account keys list)"
},
{
url: "/p/fbu8k8j/",
title: "TypeScriptでモジュールを作成する／インポートする (export, import)",
date: "2019-11-21T00:00:00Z",
body: "TypeScriptでモジュールを作成する／インポートする (export, import) モジュールとは TypeScript で大きなプログラムを作成するときは、モジュールの仕組みを使って 複数のファイルに分割 していきます。 ファイルを分割することでコードを管理しやすくなるだけでなく、名前空間のコンテキストが分けられることになるので、 名前の衝突の問題も解決 することができます。 モジュールを作るのは簡単で、export キーワードを含む .ts ファイルを作ればそれがモジュールになります。 export キーワードでは、クラスやインタフェースをまるごと公開することもできるし、関数や変数の単位で公開することもできます。 export の使い方のポイントは、次のように、 クラスや変数を定義するときにプレフィックスとして付加する というところです。 基本的には、定義済みのオブジェクトを後から export するという使い方はしません。 export class \u0026hellip; export interface \u0026hellip; export const \u0026hellip; export let \u0026hellip; ここからは、具体的な export の使い方を見ていきます。 クラスやインタフェースの定義を export する 下記の lib/mylib.ts ファイルでは、MyInterface インタフェースと、MyClass クラスを公開しています。 それぞれの定義の前に export キーワードを付けるだけでよいので簡単ですね。 lib/mylib.ts export interface MyInterface { name: string; } export class MyClass implements MyInterface { constructor(public name: string) {} } 次の index.ts ファイルからは、上記のクラスモジュールを import して読み込んでいます。 index.ts（個別に import） import { MyInterface, MyClass } from \u0026#39;./lib/mylib\u0026#39;; const obj: MyInterface = new MyClass(\u0026#39;Maku\u0026#39;); console.log(obj.name); //=\u0026gt; Maku from の後ろに指定するファイルパスには、 拡張子の .ts を記述しない ことに注意してください（実際に読み込むファイルは .js なので、.ts の指定は意味的にも間違っています）。 上記の例では、インタフェースやクラスの名前を直接指定して、個別の変数に読み込んでいますが、次のようにワイルドカードを使って export されているものを 1 つの変数にすべて読み込むこともできます。 index.js（まとめて import） import * as mylib from \u0026#39;./lib/mylib\u0026#39;; const obj: mylib.MyInterface = new mylib.MyClass(\u0026#39;Maku\u0026#39;); console.log(obj.name); //=\u0026gt; Maku ここでは、as キーワード を使って mylib という変数のプロパティ経由で公開されているインタフェースにアクセスできるようにしています。 ワイルドカードを使用する場合、この変数の指定は必須 であることに注意してください（それにより、不注意による名前の衝突を防げるようになっています）。 個別の変数に読み込む場合でも、as キーワードを使って別名を付けることができます。 使用頻度は高くないかもしれませんが、名前の衝突が起こってしまう場合や、長いインタフェース名を短い名前で参照したいときなどに使えるテクニックです。 index.js（別名を付ける） import { MyInterface as MI, MyClass as MC } from \u0026#39;./lib/mylib\u0026#39;; const obj: MI = new MC(\u0026#39;Maku\u0026#39;); console.log(obj.name); //=\u0026gt; Maku 単一の変数や定数、関数などを export する const や let を使って変数を定義するときに、export キーワードを付けておくと、その変数を単独で公開できます。 次の config.ts モジュールは、config 変数（Config クラスのインスタンス）を公開しています。 config.ts class Config { debug: boolean = true; animSpeed: number = 10; } export const config = new Config(); 参照側では次のようにして config 変数を扱うことができます。 index.ts import { config } from \u0026#39;./config\u0026#39;; console.log(config.debug); //=\u0026gt; true ちなみに、このような設定情報であれば、次のように各プロパティを static なクラス変数として定義し、クラスごと export した方がシンプルでよいかもしれません。 config.ts export class Config { static readonly DEBUG: boolean = true; } 参考リンク TypeScript: クラス定数を定義する (static readonly) index.ts import { Config } from \u0026#39;./config\u0026#39;; console.log(Config.DEBUG); //=\u0026gt; true 定数や関数を単独で公開することもできます。 mylib.ts export const MAX_CHANNELS = 100; export function greet() { console.log(\u0026#39;Hello\u0026#39;); } index.ts import { MAX_CHANNELS, greet } from \u0026#39;./config\u0026#39;; console.log(MAX_CHANNELS); //=\u0026gt; 100 greet(); //=\u0026gt; Hello 次のように、export するときに別名を付けることもできます。 mylib.ts function greet() { console.log(\u0026#39;Hello\u0026#39;); } export { greet as myGreet } 再 export (Re-export) 次のように export を使用すると、別のモジュールから export されているインタフェースを、あたかも自分が export しているかのように見せることができます。 export { Foo, Bar } from \u0026#39;./submodule\u0026#39;; 次のように、別名を付けて再 export したり、すべてのインタフェースを再 export することもできます。 export { Foo as MyFoo } from \u0026#39;./submodule\u0026#39;; export * from \u0026#39;./submodule\u0026#39;; このようにワイルドカードを使用する場合は、import の場合と違い、as による別名を付けなくてよいことに注意してください。 この再 export の仕組みを使用すれば、複数のサブモジュールで構成されたライブラリを、 1 つの大きなモジュールとして見せることができます。 デフォルト export （この仕組みはオススメしません） export default を指定すると、モジュールの中の 1 つのメンバーをデフォルト export に設定することができ、シンプルな記述で import できるようになります。 次の例では、Book クラスの定義をデフォルト export しています。 book.ts export default class Book { constructor(public title: string) {} } このクラスは下記のようにシンプルに import できます（変数名を {} で囲んだりする必要がありません）。 index.ts import Book from \u0026#39;./book\u0026#39;; const book = new Book(\u0026#39;Title\u0026#39;); デフォルト export された Book クラスは、次のように別の名前の変数にも代入できてしまいます（それでも実体は Book クラスです）。 index.ts import Hoge from \u0026#39;./book\u0026#39;; const book = new Hoge(\u0026#39;Title\u0026#39;); このように名前の変更ができてしまうので、デフォルト export を使ったコードは分かりにくくなってしまう可能性があります。 そのため、デフォルト export の仕組みはあまりオススメできません。 export default は、次のように、単一のインスタンス（ここでは Config オブジェクト）を公開するのにも使用できます。 config.ts class Config { debug: boolean = true; animSpeed: number = 10; } export default new Config(); 次のように import すれば、モジュール側で生成された Config オブジェクトを直接参照できます。 index.ts import config from \u0026#39;./config\u0026#39;; console.log(config.debug); //=\u0026gt; true とはいえ、通常の export の使い方でも同様のことを実現できるため、やはり export default の使用はオススメできません。 オブジェクト export (Object export) （この仕組みもオススメしません） 単一のオブジェクトだけを公開したい場合は、上で説明した export default の仕組みを使用する方法以外にも、 export = オブジェクト; という構文を使用する方法があります。 CommonJS の exports \u0026amp; requre のようなものだというと伝わる人には伝わるかもしれません。 次の config.ts モジュールでは、唯一 Config クラスのインスタンスだけを export しています。 class Config { debug: boolean = true; animSpeed: number = 10; } export = new Config(); このモジュールを読み込む側では、import/from ではなく、import/require を使って読み込む必要があります。 import config = require(\u0026#39;./config\u0026#39;); console.log(config.debug); //=\u0026gt; true この方法でモジュールを読み込む場合、公開されているオブジェクトの名前と合わせた変数に代入する必要はありません（上記の例では意図的に config と合わせているだけです）。 import hogehoge = require(\u0026#39;./config\u0026#39;); このように使用側で名前を勝手に変更できてしまう点は、export default との共通点であり、オススメできない理由でもあります。"
},
{
url: "/p/2sdyex5/",
title: "Jadeの構文: タブとスペースを混ぜない",
date: "2013-12-30T00:00:00Z",
body: "Jadeの構文: タブとスペースを混ぜない Jade では、インデントとしてスペースとタブのどちらでも使用できますが、テンプレートファイル (.jade) 内では、どちらか一方に統一する必要があります。 スペースとタブが混ざっていると、変換時に Invalid indentation のエラーが発生します。 エラーになる例 $ jade test.jade /usr/local/lib/node_modules/jade/lib/runtime.js:200 throw err; ^ Error: test.jade:4 2| div 3| b Maku \u0026gt; 4| b Moja 5| 6| Invalid indentation, you can use tabs or spaces but not both"
},
{
url: "/p/xfp42np/",
title: "gnuplot: グラフ内に矢印や直線を表示する",
date: "2004-01-03T00:00:00Z",
body: "gnuplot: グラフ内に矢印や直線を表示する 矢印・直線を表示する Syntax set arrow \u0026lt;tag\u0026gt; from \u0026lt;sx\u0026gt; \u0026lt;sy\u0026gt; to \u0026lt;ex\u0026gt; \u0026lt;ey\u0026gt; [[no]head] # 2次元の場合 set arrow \u0026lt;tag\u0026gt; from \u0026lt;sx\u0026gt; \u0026lt;sy\u0026gt; \u0026lt;sz\u0026gt; to \u0026lt;ex\u0026gt; \u0026lt;ey\u0026gt; \u0026lt;ez\u0026gt; [[no]head] # 3次元の場合 nohead オプションを付けると、矢印でなく直線になります。 \u0026lt;tag\u0026gt; は他のコマンドで対象となる矢印を指定するために 1 以上の値を指定します。 ※プロットの範囲の中に矢印が収まっていないと変な表示になることがあります。 例: 原点付近に十字を表示 set arrow 1 from 0, -3 to 0, 3 nohead set arrow 2 from -3, 0 to 3, 0 nohead 矢印を非表示にする Syntax set noarrow \u0026lt;tag\u0026gt; \u0026lt;tag\u0026gt; には、set arrow で設定した数値を指定します。"
},
{
url: "/p/eyeq2do/",
title: "AWS Lambda のメモ",
date: "2021-06-06T00:00:00Z",
body: "AWS Lambda のメモ"
},
{
url: "/p/pbo2dpy/",
title: "AWS CloudFormation の設定例: Lambda 関数の設定いろいろ",
date: "2021-04-08T00:00:00Z",
body: "AWS CloudFormation の設定例: Lambda 関数の設定いろいろ タイムアウト時間 (Timeout) Lambda 関数のタイムアウト時間（最大実行可能時間）を設定するには、Timeout プロパティで秒単位の指定を行います。 例: タイムアウトを 15 秒にする AWSTemplateFormatVersion:\u0026#39;2010-09-09\u0026#39;Transform:AWS::Serverless-2016-10-31Resources:MyLambda:Type:AWS::Serverless::FunctionProperties:Runtime:nodejs14.xCodeUri:function.zipHandler:index.handlerTimeout:15 すべての Lambda 関数の Timeout 値をまとめて設定したいときは、Globals セクションを使います。 AWSTemplateFormatVersion:\u0026#39;2010-09-09\u0026#39;Transform:AWS::Serverless-2016-10-31Globals:Function:Runtime:nodejs14.xCodeUri:function.zipTimeout:15Resources:MyLambda1:Type:AWS::Serverless::FunctionProperties:Handler:index.handler1MyLambda2:Type:AWS::Serverless::FunctionProperties:Handler:index.handler2 環境変数 (Environment) Lambda 関数の中から参照可能な環境変数を設定するには、Variables プロパティに、キーと値のペアを指定します。 すべての Lambda 関数に共通で設定する環境変数は、Globals セクションで定義します。 Globals:Function:Environment:Variables:STAGE:ProductionTABLE_NAME:global-tableResources:MyFunction:Type:AWS::Serverless::FunctionProperties:Environment:Variables:TABLE_NAME:resource-tableNEW_VAR:hello トリガー設定 (Events) Lambda 関数を呼び出すためのトリガー（イベント）は、Events プロパティで定義できます。 Resouces プロパティと同様に、Events プロパティの一階層目にはイベントの論理 ID (Logical ID) を記述して、その下にそのイベントの設定を記述します。 Events プロパティの構成 Resources:MyFunction:Type:AWS::Serverless::FunctionProperties:Events:イベントの論理ID1:イベントの設定...イベントの論理ID2:イベントの設定... 一定時間ごとに呼び出す (Type: Schedule) Lambda 関数を一定時間ごとに呼び出したり、毎日決まった時刻に呼び出したりするには、Type: Schedule のイベントを設定します。 実際に生成される AWS リソースは EventBridge (CloudWatch Events) ルールです（リソースタイプは AWS::Events::Rule）。 次の例では、5 分おきに Lambda 関数を呼び出すように設定しています。 AWSTemplateFormatVersion:\u0026#39;2010-09-09\u0026#39;Transform:AWS::Serverless-2016-10-31Resources:HelloFunction:Type:AWS::Serverless::FunctionProperties:Runtime:python3.7Handler:index.handlerCodeUri:src/Events:MySchedule:Type:ScheduleProperties:Schedule:\u0026#39;rate(5 minutes)\u0026#39;# Schedule: \u0026#39;cron(0 * * * ? *)\u0026#39;Description:test schedule# Enabled: False 生成される AWS::Events::Rule の物理 ID (Physical ID) は、スタックやリソースの名前（論理 ID）を組み合わせて、次のような名前が自動的に割り当てられます。 mystack-HelloFunctionMySchedule-H5JKY9WW8AOI 物理 ID を明示的に指定したい場合は、Schedule イベントの Name プロパティを指定します。 参考リンク Schedule - AWS Serverless Application Model Amazon EventBridge ルールのスケジュール式 S3 バケットからのイベント (Type: S3) 次の例では、指定したバケット（論理 ID: SrcBucket）にオブジェクトが作成されたときに Lambda 関数を呼び出すように指定しています。 AWSTemplateFormatVersion:\u0026#39;2010-09-09\u0026#39;Transform:AWS::Serverless-2016-10-31Resources:CreateThumbnail:Type:AWS::Serverless::FunctionProperties:Runtime:python3.7Handler:index.handlerCodeUri:src/Events:CreateThumbnailEvent:Type:S3Properties:Bucket:!Ref SrcBucketEvents:s3:ObjectCreated:*SrcBucket:Type:AWS::S3::Bucket Lambda のポリシーの設定 (Policies) SAM で Lambda 関数 (AWS::Lambda::Function) を生成すると、暗黙的に生成されるロールがデフォルトロールとして設定されます。 Policies プロパティを使うと、このデフォルトロールに対して任意の管理ポリシーや、インラインポリシーを追加で設定することができます。 なお、Role プロパティで明示的にロールを指定している場合は、デフォルトロールではなく、そちらのロールを使うことになるので、Policies プロパティを指定することはできません。 Resources:MyFunction:Type:AWS::Serverless::FunctionProperties:Handler:index.handler...Policies:- AWSLambdaInvocation-DynamoDB- Version:\u0026#39;2012-10-17\u0026#39;Statement:- Effect:AllowAction:- s3:GetObject- s3:GetObjectACLResource:\u0026#39;arn:aws:s3:::my-bucket/*\u0026#39; Policies プロパティには、リスト形式で複数のポリシーを指定することができます。 上記の例では、管理ポリシーとして AWSLambdaInvocation-DynamoDB を指定し、その下に YAML 形式のインラインポリシーを指定しています。 管理プロパティを 1 つだけ指定すればよいのであれば、Policies: AWSLambdaInvocation-DynamoDB のように一行で記述することができます。 (参考) AWSLambdaInvocation-DynamoDB ポリシー { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;lambda:InvokeFunction\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;dynamodb:DescribeStream\u0026#34;, \u0026#34;dynamodb:GetRecords\u0026#34;, \u0026#34;dynamodb:GetShardIterator\u0026#34;, \u0026#34;dynamodb:ListStreams\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } 次の例では、SAM ポリシーテンプレート として標準で定義されている S3CrudPolicy を設定し、S3 バケット（論理 ID: MyBucket）への読み書きを許可しています。 Resources:MyFunction:Type:AWS::Serverless::FunctionProperties:Runtime:nodejs14.xHandler:build/index.handlerCodeUri:function.zipPolicies:- S3CrudPolicy:BucketName:!Ref MyBucketEnvironment:Variables:BUCKET_NAME:!Ref MyBucketMyBucket:Type:AWS::S3::Bucket 上記では、S3 バケット用に S3CrudPolicy を使用していますが、DynamoDB の場合も同様の DynamoDBCrudPolicy ポリシーが定義されています。 Policies:- DynamoDBCrudPolicy:TableName:!Ref MyTable Lambda の実行ロールの設定 (Role) SAM で Lambda 関数 (AWS::Lambda::Function) を生成すると、暗黙的に実行ロールが生成されてアタッチされますが、明示的に作成した IAM ロールを Role プロパティで指定することもできます。 Resources:AppendItemToListFunction:Type:AWS::Lambda::FunctionProperties:Runtime:nodejs14.xHandler:index.handlerRole:!GetAtt LambdaExecutionRole.ArnCode:ZipFile:!Sub |var response = require(\u0026#39;cfn-response\u0026#39;);exports.handler = function(event, context) {var responseData = {Value: event.ResourceProperties.List};responseData.Value.push(event.ResourceProperties.AppendedItem);response.send(event, context, response.SUCCESS, responseData);};LambdaExecutionRole:Type:AWS::IAM::RoleProperties:AssumeRolePolicyDocument:Version:\u0026#39;2012-10-17\u0026#39;Statement:- Effect:AllowPrincipal:Service:- lambda.amazonaws.comAction:- sts:AssumeRolePath:\u0026#34;/\u0026#34;Policies:- PolicyName:rootPolicyDocument:Version:\u0026#39;2012-10-17\u0026#39;Statement:- Effect:AllowAction:- logs:*Resource:arn:aws:logs:*:*:* 上記の例では、テンプレート内で定義した IAM ロールを次のように論理 ID で指定しています。 Role:!GetAtt LambdaExecutionRole.Arn すでに別のスタックなどで生成したロールをアタッチする場合は、次のように ARN で指定することができます。 Role:!Sub \u0026#34;arn:aws:iam::${AWS::AccountId}:role/service-role/my-function-role-hfow8uki\u0026#34;"
},
{
url: "/p/emdtiio/",
title: "TypeScriptのモジュールのインポートには import を使う",
date: "2020-02-04T00:00:00Z",
body: "TypeScriptのモジュールのインポートには import を使う require ではなく import を使う TypeScript で型情報付きのモジュールをインポートするときは、ECMAScript 2015 の module 構文 で定義されている import を使うようにすると、VSCode などで型情報を使った補完がうまく効くようにになります。 これを使う // Good import * as mod from \u0026#39;mod\u0026#39;; 下記のように、Node.js で一般的に使用されていた CommonJS 形式の require を使ってもインポートできますが、any 型の変数を定義していることになるため、型情報を用いた補完が効きません。 これは使わない // NG const mod = require(\u0026#39;mod\u0026#39;); TypeScript でモジュールをインポートするときには、できるだけ import を使う ようにしましょう。 インポートの例（関数ベースのモジュール） Node.js のコアモジュール（os や path など）は、もともと TypeScript 用に作成されたものではありませんが、TypeScript 用の型情報が @types/node モジュールとして提供されています。 Node.js コアモジュールの型情報をインストール $ npm install --save-dev @types/node これで、Node.js のコアモジュールを下記のように型情報付きでインポートできるようになります。 これは、複数の関数を export する TypeScript モジュールをインポートする方法のよい例です。 よい例: 型として認識される import * as path from \u0026#39;path\u0026#39;; // 全ての関数をインポート import { join } from \u0026#39;path\u0026#39;; // 個別の関数をインポート これで、VSCode などの IDE で次のように補完が聞くようになります。 逆に、次のようにインポートしてしまうと、any 型の path 変数が定義されているものとみなされ、補完機能がうまく働きません。 悪い例: 型として認識されない const path = require(\u0026#39;path\u0026#39;); インポートの例（クラスのインポート） モジュールが export しているクラスを個々にインポートする場合も同様に import を使用します。 よい例: 型として認識される import { QnAMaker } from \u0026#39;botbuilder-ai\u0026#39;; 悪い例: 型として認識されない const { QnAMaker } = require(\u0026#39;botbuilder-ai\u0026#39;); 前者のように、import キーワードを使ってインポートすれば、QnAMaker は型情報だとみなされるため、TypeScript の型安全性をいかしたコーディングを行うことができます。 class Faq { qnaMaker: QnAMaker; // QnAMaker 型のプロパティを定義 // ... }"
},
{
url: "/p/eycnx9i/",
title: "Ansible でインベントリーファイルの場所を指定する",
date: "2016-10-22T00:00:00Z",
body: "Ansible でインベントリーファイルの場所を指定する Ansible のコマンド（ansible や ansible-playbook）を実行すると、下記の順でインベントリーファイルが検索されます。 コマンドラインオプション -i で指定したファイル コンフィグファイル ansible.cfg 内の hostfile で指定したファイル（参考: ansible.cfg ファイルの検索パス） /etc/ansible/inventry 以下の例は、いずれもカレントディレクトリ内の hosts というファイルをインベントリファイルとして使用するように指定しています。 例: コマンドラインオプション (-i) で指定する方法 $ ansible myserver -i hosts -m ping 例: コンフィグファイル (ansible.cfg) で指定する方法 [defaults] hostfile = hosts"
},
{
url: "/p/n6cwnk7/",
title: "Jadeの構文: クラス属性と ID 属性を設定する",
date: "2013-12-30T00:00:00Z",
body: "Jadeの構文: クラス属性と ID 属性を設定する Jade のテンプレートファイルでは、CSS セレクタと同じ表現で、HTML タグのクラス属性、ID 属性を指定することができます。 p.class1 AAA #=\u0026gt; \u0026lt;p class=\u0026#34;class1\u0026#34;\u0026gt;AAA\u0026lt;/p\u0026gt; span#id1 BBB #=\u0026gt; \u0026lt;span id=\u0026#34;id1\u0026#34;\u0026gt;BBB\u0026lt;/span\u0026gt; もちろんクラス属性値は、複数指定可能です。 p.class1.class2.class3 AAA #=\u0026gt; \u0026lt;p class=\u0026#34;class1 class2 class3\u0026#34;\u0026gt;AAA\u0026lt;/p\u0026gt; クラス属性、ID 属性を指定するときに、タグ名を省略すると、デフォルトで div タグとみなされます。 .class1 AAA #=\u0026gt; \u0026lt;div class=\u0026#34;class1\u0026#34;\u0026gt;AAA\u0026lt;/div\u0026gt; #id1 BBB #=\u0026gt; \u0026lt;div id=\u0026#34;id1\u0026#34;\u0026gt;BBB\u0026lt;/div\u0026gt; クラス属性と ID 属性は、どちらを先に指定しても構いません。 .class1#id1.class2 #=\u0026gt; \u0026lt;div id=\u0026#34;id1\u0026#34; class=\u0026#34;class1 class2\u0026#34;\u0026gt;AAA\u0026lt;/div\u0026gt;"
},
{
url: "/p/adxysxf/",
title: "gnuplot: グラフ内にコメントを表示する",
date: "2004-01-03T00:00:00Z",
body: "gnuplot: グラフ内にコメントを表示する コメントを表示する Syntax set label tag \u0026#39;text\u0026#39; at [coordinate] x, [coordinate] y [justification] tag にはコメントを識別するための 1 以上の整数を指定します。 オプショナルパラメータの coordinate には、どのような座標系でコメント位置を指定するかを設定できます。 first (default) \u0026ndash; x、y 軸の座標系 second \u0026ndash; x2、y2 軸の座標系 graph \u0026ndash; グラフの左下を (0, 0)、右上を (1, 1) とする座標系 screen \u0026ndash; 表示全体の左下 (0, 0)、右上を (1, 1) とする座標系 justification パラメータでは、指定した座標のどちら側にコメントを表示するかを設定できます。 left (default) \u0026ndash; 指定した座標の左側 right \u0026ndash; 指定した座標の右側 center \u0026ndash; 指定した座標の中央 例 set label 1 \u0026#34;Label 1\u0026#34; at 5, 4 set label 2 \u0026#34;Label 2\u0026#34; at 10, 7"
},
{
url: "/p/dzdq3ep/",
title: "AWS CloudFormation の設定例: Lambda 関数から S3 にアクセスできるようにする",
date: "2021-04-12T00:00:00Z",
body: "AWS CloudFormation の設定例: Lambda 関数から S3 にアクセスできるようにする CloudFormation (SAM) を利用して、Lambda 関数および S3 バケットを作成し、Lambda 関数から S3 バケットにアクセスできるようにポリシー設定するテンプレートの例です。 参考までに Lambda 関数の TypeScript コードも載せましたが、あくまで SAM テンプレートの記述例を示すことを目的としています。 SAM テンプレートの記述例 次の SAM テンプレートでは、AWS リソースとして S3 バケット (MyBucket) と Lambda 関数 (MyFunction) を定義しています。 template.yml AWSTemplateFormatVersion:\u0026#39;2010-09-09\u0026#39;Transform:AWS::Serverless-2016-10-31Resources:# S3 バケットの定義MyBucket:Type:AWS::S3::Bucket# Lambda 関数の定義MyFunction:Type:AWS::Serverless::FunctionProperties:Runtime:nodejs14.xHandler:build/index.handlerCodeUri:function.zipPolicies:- S3CrudPolicy:BucketName:!Ref MyBucketEnvironment:Variables:BUCKET_NAME:!Ref MyBucket S3 バケットは単純にスタック内に新規作成するだけなので、何もプロパティ設定していません。 ポイントは、Lambda 関数側のポリシー設定（Policies プロパティ）です。 Policies:- S3CrudPolicy:BucketName:!Ref MyBucket ここでは、AWS が標準で用意している S3CrudPolicy というポリシーを使っています。 このポリシーの BucketName パラメータとして、作成した S3 バケットの物理 ID (Physical ID) を渡すことで、Lambda 関数から S3 バケットの読み書き（CRUD 操作）が可能になります。 S3 バケットの Physical ID は、Ref 関数に Logical ID を渡すことで取得することができます。 ☝️ ポリシーは実行ロールに追加される SAM テンプレートで Lambda 関数を定義すると、自動的にデフォルトの実行ロールが生成されてアタッチされます（Role プロパティを指定した場合を除く）。 このデフォルトロールには、CloudWatch Logs へのログの書き込み権限など、最低限の権限が付与されています。 Policies プロパティでポリシーを定義すると、このデフォルトロールに対して追加する形でポリシーが設定されます。 SAM テンプレートで S3 バケットを作成する場合、そのバケット名 (Physical ID) を何らかの方法で Lambda 関数のコードに知らせてやる必要があります。 S3 バケット (AWS::S3::Bucket) の定義時に、BucketName プロパティで固定のバケット名を指定してやる方法もありますが、上記の例では、動的に生成された S3 バケット名を Lambda 関数に環境変数 (BUCKET_NAME) として渡しています。 Environment:Variables:BUCKET_NAME:!Ref MyBucket Lambda 関数の実装コード 参考までに、S3 バケットにアクセスする Lambda 関数の実装コード (TypeScript) を載せておきます。 環境変数 BUCKET_NAME で渡されたバケットに対して、オブジェクトを追加しています。 src/index.ts import { S3 } from \u0026#39;aws-sdk\u0026#39;; const s3 = new S3(); export async function handler(): Promise\u0026lt;any\u0026gt; { if (!process.env.BUCKET_NAME) { throw new Error(\u0026#39;Env variable BUCKET_NAME is not set\u0026#39;); } const request: S3.PutObjectRequest = { Bucket: process.env.BUCKET_NAME, Key: \u0026#39;Key1\u0026#39;, Body: \u0026#39;Body1\u0026#39;, }; return s3.putObject(request).promise(); }"
},
{
url: "/p/ef8i8dx/",
title: "Jadeの構文: ブロック展開 (block expansion) によってネストを減らす",
date: "2013-12-29T00:00:00Z",
body: "Jadeの構文: ブロック展開 (block expansion) によってネストを減らす Jade の ブロック展開 (block expansion) を使うと、改行とインデントによるネストを一行で表現できます。 例えば、 div.box div.prompt Hello というネストされた構文は、下記のように一行で記述することができます。 div.box: div.prompt Hello ただし、以下のように、上位の要素にテキストノードが存在する場合は、ブロック展開を使った記述は行えません。 div.box Hello div.prompt World 間違い div.box Hello: div.prompt World"
},
{
url: "/p/538wdr7/",
title: "gnuplot: アスキーアートでグラフを出力する (dumb 端末)",
date: "2004-01-03T00:00:00Z",
body: "gnuplot: アスキーアートでグラフを出力する (dumb 端末) Syntax set term(inal) dumb [feed \u0026lt;x幅\u0026gt; \u0026lt;y幅\u0026gt;] set terminal で dumb 端末を指定すると、グラフをアスキーアートで出力できます。 テキストベースのメールやチャットでグラフを送る場合に便利です。 例: -10 log(x) gnuplot\u0026gt; set term dumb gnuplot\u0026gt; plot [0:] -10*log(x) 15 ++-----------+------------+-----------+------------+-----------++ + + + + -10*log(x) ****** + 10 ++* ++ | * | 5 ++ * ++ | *** | 0 ++ ** ++ | ** | -5 ++ ** ++ | ** | -10 ++ ***** ++ | ****** | -15 ++ ******* ++ | ********* | -20 ++ ************* ++ + + + + + ********** -25 ++-----------+------------+-----------+------------+-----------++ 0 2 4 6 8 10 グラフの形だけを示したい場合は、目盛りを消したほうが見た目がきれいになります。 例: -10 log(x) gnuplot\u0026gt; set term dumb feed 40 15 gnuplot\u0026gt; set noxtics gnuplot\u0026gt; set noytics gnuplot\u0026gt; plot [0:] -10*log(x) +*---------------------------------+ | * -10*log(x) ****** | | * | | * | | * | | ** | | *** | | ** | | ***** | | ****** | | ******* | +-----------------------------******"
},
{
url: "/p/cxcozak/",
title: "Amazon EC2 関連記事",
date: "2021-03-02T00:00:00Z",
body: "Amazon EC2 関連記事 Amazon EC2 (Amazon Elastic Compute Cloud) は、AWS が提供するクラウド上の仮想サーバーサービスです。 Linux や Windows などの環境を手軽に立ち上げることができ、SSH 経由で接続して操作することができます。"
},
{
url: "/p/wwao94j/",
title: "Jadeの構文: テキストブロックでテキストノードを生成する",
date: "2013-12-29T00:00:00Z",
body: "Jadeの構文: テキストブロックでテキストノードを生成する Jade のテンプレートファイルでは、次のように要素名の後ろに続けてテキストを記述することで、要素内にテキストノードを作成 することができます。 p Hello World テキストの内容が長くなり、複数行に分けて記述したいときは、バー記法 (bar notation) やドット記法 (dot notation) を使用した「テキストブロック」 を作成します。 バー記法によるテキストブロックの例 p | long long long long long | long long long long long | long long long description. ドット記法によるテキストブロックの例 p. long long long long long long long long long long long long long description. ドットは、必ずタグ名の直後にスペースを入れずに記述 してください。 スペースを入れると、ドットがテキスト内容として認識されてしまいます。 出力 \u0026lt;p\u0026gt;long long long long long long long long long long long long long description.\u0026lt;/p\u0026gt; これらの記法は、ソースコードなど、改行やインデントが重要なテキストを pre 要素として出力する際に便利です。 pre. #include \u0026lt;iostream\u0026gt; int main() { return 0; } バー記法 (bar notation) によるテキストブロックは、テキストノードの前後に同じ階層で別の要素がある場合にも使用します。 div span AAA | BBB span CCC"
},
{
url: "/p/fyjpvb2/",
title: "gnuplot: サンプル数を上げて強引に塗りつぶす（積分領域の表示）",
date: "2004-01-03T00:00:00Z",
body: "gnuplot: サンプル数を上げて強引に塗りつぶす（積分領域の表示） 強引な塗りつぶし表示 set samples 1000 plot [-pi:pi] sin(x) with impulse （追記: 2013-05-02）最近の gnuplot だと、こんな強引なことしなくても、plot するときに with filledcurve の指定をするだけで、塗りつぶし表示ができるみたいです。 しかも、凡例の表示もそれっぽく代わってくれます。 参考 http://gnuplot.sourceforge.net/demo_cvs/fillcrvs.html http://gnuplot.sourceforge.net/demo_cvs/transparent.html"
},
{
url: "/p/au8is4e/",
title: "AWS CodeBuild のメモ",
date: "2021-02-22T00:00:00Z",
body: "AWS CodeBuild のメモ"
},
{
url: "/p/d8cx8a3/",
title: "Jadeの構文: CSS や JavaScript を使用する",
date: "2013-12-29T00:00:00Z",
body: "Jadeの構文: CSS や JavaScript を使用する Jade テンプレート内に、直接 CSS や JavaScript のコードを記述するときは、ドット記法によるテキストブロック内に記述します。 test.jade style. body { color: #111; background: #ccc; } script. var message = \u0026#39;Hello\u0026#39;; alert(message); 実行結果 $ jade --pretty \u0026lt; test.jade \u0026lt;style\u0026gt; body { color: #111; background: #ccc; } \u0026lt;/style\u0026gt; \u0026lt;script\u0026gt; var message = \u0026#39;Hello\u0026#39;; alert(message); \u0026lt;/script\u0026gt; link タグや script タグによって、外部の CSS や JavaScript コードをロードするには、以下のようにします。 test.jade doctype html html head meta(charset=\u0026#39;UTF-8\u0026#39;) link(rel=\u0026#39;stylesheet\u0026#39;, href=\u0026#39;main.css\u0026#39;) title Hello script(src=\u0026#39;jquery.js\u0026#39;) script(src=\u0026#39;main.js\u0026#39;) body p Hello 実行結果 $ jade --pretty \u0026lt; test.jade \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;main.css\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Hello\u0026lt;/title\u0026gt; \u0026lt;script src=\u0026#34;jquery.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;main.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Hello\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;"
},
{
url: "/p/tbxfo2c/",
title: "gnuplot: 場合分けをして不連続関数を描画する",
date: "2004-01-03T00:00:00Z",
body: "gnuplot: 場合分けをして不連続関数を描画する 次のようにすると、x の範囲によって値を不連続に変化させることができます。 f(x) = (x \u0026gt; 0) ? 1 : -1 set samples 10000 plot f(x) 上のように連続した関数じゃない場合は、サンプル数が少ないと x=0 の場所の縦線が斜めになってしまうようです。 （追記: 2013-05-03）plot するときに、plot f(x) with steps とすれば、少なくとも線が斜めになってしまうのは防げるようです。 ただ、samples の数は増やしておかないと、x=0 の位置より少しずれた場所で y の値が変化してしまうので、やっぱり set samples は必要です。"
},
{
url: "/p/sdq2cnx/",
title: "AWS CloudFormation/SAM/CDK のメモ",
date: "2022-04-17T00:00:00Z",
body: "AWS CloudFormation/SAM/CDK のメモ"
},
{
url: "/p/a3eh9w2/",
title: "TypeScriptで名前空間を定義する (namespace)",
date: "2019-11-21T00:00:00Z",
body: "TypeScriptで名前空間を定義する (namespace) namespace ではなくモジュールの仕組みを使うべし TypeScript では、namespace キーワードを使って名前空間を定義することができますが、通常はより柔軟性の高い モジュールの仕組み を使うようにしてください（といっても .ts ファイルを分けるだけですが）。 namespace を使うと、同じファイル内で階層化された名前空間を作ることができますが、あくまでその階層構造はグローバルに共有されています。 一方、モジュールの仕組みを使うと、ファイル単位で名前空間のコンテキストを分けることができます。 大きなプロジェクトであっても、適切な単位でモジュール（ファイル）を分割している限り、名前の衝突は本質的には発生しません。 とはいえ、これは namespace の記事なので、ここからは namespace の使い方の説明をします。 namespace による名前空間の定義 namespace による名前空間の定義は簡単で、namespace Xxx { ... } というブロックで囲むだけです。 次の例では、First と Second という名前空間を作成し、それぞれに同じ名前の Person というクラスを定義しています。 namespace First { export class Person { greet() { console.log(\u0026#39;First.Person\u0026#39;); } } } namespace Second { export class Person { greet() { console.log(\u0026#39;Second.Person\u0026#39;); } } } const p1 = new First.Person(); const p2 = new Second.Person(); p1.greet(); //=\u0026gt; First.Person p2.greet(); //=\u0026gt; Second.Person namespace の中で定義したクラスなどは、デフォルトではその外の名前空間からは見えないようになっています。 外からアクセスしたい場合は、上記のようにクラス定義の前に export を付けて公開しておく必要があります。 名前空間は、ドットで区切って入れ子で定義することもできます。 namespace First.Second.Third { export class Person { greet() { console.log(\u0026#39;Hello\u0026#39;); } } } const p = new First.Second.Third.Person(); 上記は、下記のように定義するのと同等です。 namespace First { export namespace Second { export namespace Third { export class Person { greet() { console.log(\u0026#39;Hello\u0026#39;); } } } } } 内部の namespace は、export で公開しなければ外からアクセスできないため、上記のように export の連続になります。 import を使って、名前空間内のメンバーに別名（エイリアス）をつけてアクセスすることもできます。 namespace First { export class Person { greet() { console.log(\u0026#39;First.Person\u0026#39;); } } } import Person = First.Person; const p = new Person(); p.greet(); 同じ階層にあるクラスと名前空間名が同じ名前の場合は、クラス定義が先にある限り TypeScript トランスパイラがうまくマージしてくれます。 class Foo { greet() { console.log(\u0026#39;greet1\u0026#39;); } } namespace Foo { export function greet() { console.log(\u0026#39;greet2\u0026#39;); } } new Foo().greet(); Foo.greet(); もちろん、このような名前の重複は発生しないように定義すべきですし、そもそも namespace は使わずに モジュールの仕組み だけで名前空間の管理をすれば、このような混乱が発生することはないでしょう。"
},
{
url: "/p/tzaeb9x/",
title: "チャットボット (1-1) Bot Builder SDK とは",
date: "2019-03-04T00:00:00Z",
body: "チャットボット (1-1) Bot Builder SDK とは Microsoft の Azure は Chatbot サービスを作成する機能を提供しています。 Microsoft が提供している Bot Framework は、この Chatbot サービスを作成するとき、あるいは Chatbot を使用するクライアントを作成するときに使用するツール群（あるいは仕組み）やそれらを取り巻く環境の総称です。 Microsoft Bot Framework ボットのサーバを実装するためのライブラリは、Bot Builder SDK という名前で提供されています。 現状では、ボットは Node.js と .NET による開発が想定されているため、Bot Builder SDK も Node.js と .NET 用のものが提供されています（2019年3月現在、Python と Java 版が preview リリースされているようです）。 Bot Builder SDK (for Node.js) Bot Builder SDK (for .Net) Bot Builder サンプルコード集 Node.js と .NET のどちらを使って開発するかに迷ったら、非同期処理を前提にして設計されている Node.js 版を選択するのがよいでしょう。 Node.js の Bot Builder SDK は、NPM パッケージとして公開されているため、npm コマンドを使って簡単にインストールすることができます。 $ mkdir mybot $ cd mybot $ npm init -y $ npm install --save botbuilder@4.x Bot Builder SDK はメジャーバージョン間で API の互換性がまったくないので、上記のようにメジャーバージョンを指定してインストールすることをお勧めします。 インターネットに公開されているサンプルコードは、SDK V3 用のものと V4 用のものが混在しているため、どの SDK バージョンを使ったコードなのかを意識しておく必要があります。"
},
{
url: "/p/you6q5r/",
title: "チャットボット (1-2) Bot Builder SDK で Echo ボットを作成する",
date: "2019-03-04T00:00:00Z",
body: "チャットボット (1-2) Bot Builder SDK で Echo ボットを作成する ここでは、Microsoft の Bot Builder SDK を使ったボット作成のファーストステップとして、チャットクライアントから入力されたテキストをそのままオウム返しするだけの Echo ボットを作成します。 言語としては JavaScript (Node.js) を使用することにします。 ここで作成するのはボットの本体（サービス側）で、クライアントとしては Microsoft が提供している Bot Framework Emulator を使用します。 Bot Builder SDK をインストールする Node.js 版の Bot Builder SDK（botbuilder パッケージ）は、npm コマンドを使ってインストールすることができます。 パッケージの依存関係を管理するための package.json ファイルも、npm init コマンドで作成しておきます。 $ mkdir mybot $ cd mybot $ npm init -y $ npm install --save botbuilder@4.x Bot Service のインタフェースは REST API として提供することが定められているのですが、Bot Builder SDK には REST API サーバを作成する機能は含まれていません。 そこで、REST API サーバを作成するための restify パッケージも一緒にインストールしておきます（express などでも実装できると思いますが、リファレンス実装では restify が使用されています）。 $ npm install --save restity Echo ボットの作成 下記の実装は、http://localhost:3978/api/messages というアドレスで、チャットクライアントからのメッセージを待ち受けてオウム返しで応答する最低限の実装です。 app.js const botbuilder = require(\u0026#39;botbuilder\u0026#39;); const restify = require(\u0026#39;restify\u0026#39;); // Server settings const PORT = 3978; // Create a bot adapter, which defines how the bot sends and receives messages. const adapter = new botbuilder.BotFrameworkAdapter(); // Create an HTTP server const server = restify.createServer(); server.listen(PORT, () =\u0026gt; { console.log(\u0026#39;%s listening to %s\u0026#39;, server.name, server.url); }); // Listen for incoming requests at /api/messages. server.post(\u0026#39;/api/messages\u0026#39;, (req, res) =\u0026gt; { // Use the adapter to process the incoming web request into a TurnContext object. adapter.processActivity(req, res, async (turnContext) =\u0026gt; { if (turnContext.activity.type === \u0026#39;message\u0026#39;) { const utterance = turnContext.activity.text; await turnContext.sendActivity(`You said: ${ utterance }`); } }); }); ネット上にあるサンプルコードでは、BotFrameworkAdapter コンストラクタのパラメータとして appId や appPassword を指定しているものがありますが、ローカル PC 上で Bot サーバを立ち上げるのであれば、上記のようなコードだけで十分です。 最初は最小限のコードで動かしてみましょう。 このボットは下記のように起動します。 $ node app.js restify listening to http://[::]:3978 Bot Framework Emulator から接続してみる ボットのサーバーが無事に立ち上がったら、Bot Framework Emulator を使って接続のテストを行ってみます。 Emulator は下記からダウンロードしてインストールします。 Microsoft/BotFramework-Emulator: Bot Framework Emulator Emulator を起動したら、メニューの File → New Bot Configuration を選択し、下記のように接続設定を行います。 入力するのは、Bot name（任意のボット名）と Endpoint URL（restify サーバで公開した URL）です。 ここで入力した Bot name は、ボットの設定ファイルの名前に使用されます（上記の例の場合、MyBot.bot というファイル名になる）。 Save and connect のボタンを押すと、MyBot.bot ファイルが保存され、Bot サーバに接続されます。 次回からは、この MyBot.bot ファイルを使って接続することができます。 メッセージ欄に Hello と入力して送信すると、Bot サーバから正しく You said: Hello という応答が返ってきていることがわかります。 これで、ローカルでの Echo ボットサーバの立ち上げと接続テストは成功です (^o^)/"
},
{
url: "/p/tttou4o/",
title: "チャットボット (2-1) Azure でボットをホストするための Web App Bot リソースを作成する",
date: "2019-03-19T00:00:00Z",
body: "チャットボット (2-1) Azure でボットをホストするための Web App Bot リソースを作成する Web App Bot リソースを作成する 作成したボットプログラムは、Azure 上の Web App Bot リソース上で動作させることができます。 このリソースのことを特にボットサービスと呼んだりします。 Azure ポータル にログインし、下記のように辿ることで Web App Bot リソースの作成画面を表示できます。 ＋リソースの作成 AI + Machine Learning Web App Bot 下記のような Web App Bot リソースの設定画面が表示されるので、1 つずつ入力していきます。 ボット名 任意のボット名称。後から自由に変更することができるので、自分のわかりやすい名前を付けておけば OK です。例: maku-bot サブスクリプション 月額の請求先となるサブスクリプションを選択します。最初の Azure トライアル期間であれば、Free Trial などを選択できるはずです。 リソースグループ この Web App Bot リソースを所属させるリソースグループを選択します。存在しない場合は 新規作成 のリンクをクリックして新しく作成します。 場所 リソースグループの場所を選択。ここでは、地理的に近い Japan East を選択してます。 価格レベル チャンネルに応じたメッセージ制限解除のためのプラン設定です。 スタンダードチャンネル（Skype、Cortana、Teams、Facebook、Slack などの一般的なクライアント）とのやりとりは無制限なので、通常は F0 の無料プランを選択しておけば OK です。 一方で、プレミアムチャンネル（ユーザ独自のチャンネルや、Web ページ埋め込みチャットボットなど）と多くのメッセージをやりとりする予定がある場合は、有料の S1 プランを選択する必要があります。 無料の F0 だと 1 か月に 10,000 メッセージまでの制限があります。 （参考: Standard channels と Premium channels について） アプリ名 ボットサービスのエンドポイント URL となる XXX.azurewebsites.net の XXX の部分を指定します。 URL なので、世界中で一意である必要があります。 アプリ名は後から変更することはできません。 ボットテンプレート 自動生成されるボットのソースコードの種類を選択します。ベースとする SDK バージョンや、言語を指定します。 今回は、最もシンプルな構成になるように、SDK v4、Node.js、Echo Bot と選択しています。 App Service プラン めっちゃ重要。 App Service プランは、ボットを稼働させるために使用するコンピューティングリソース (VM) の課金プランです。 サーバ使用料と言えば分りやすいかもしれません。 上記で設定した「価格レベル」はあくまでチャットのメッセージ数制限を取り払うためのプラン設定であり、サーバの代金はこちらのプランによって変化します。 QnA Maker などで App Service プランを作成している場合は、それに乗っかる形で同じものを選択することができます。 App Service プランが存在しない場合はここから新規作成することができます。 App Service プラン名は、分かりやすいように maku-bot-service-plan のような名前を付けておくことをオススメします。 デフォルトでは有料の価格レベルである S1 Standard で作成されます。 お試しで使うのであれば、ここは無料の F1 に変更しておいた方がよいのですが、この画面からは選択できないようなので、後から App Service プランのリソースのページから価格レベルを変更しておく必要があります（後述）。これはワナかぁ～^^; Azure Storage ボットプログラムがステータスを保持するために使用するストレージを選択します。最初は新規作成を選択しておけば OK です。 Application Insights アプリのトラフィックなどを分析するリソースを作成するかどうか。最初は必要ないと思ったら、余計なリソースを増やさないようにオフにしておけばよいです。 Microsoft アプリ ID とパスワード 自動作成にしておけば OK。Application Registration Portal で別途作成したものを設定することも可能です。ちなみに、これまでに作成したアプリの ID のリストもそのサイトで確認できます。 App Service プランの価格レベルを変更する 上記で App Service サービスプランを新規作成した場合は、価格レベルが S1 Standard になっているので、お試しで使うのであれば、忘れずにフリーの価格レベル F1 Free に変更しておきましょう。 まず、Azure ポータルのすべてのリソースから、先ほど作成した App Service プラン のリソースのページを開きます（下記の例では maku-bot-service-plan）。 App Service プランのリソースページが開いたら、 スケールアップ 開発／テスト F1（無料） 適用 ボタン と順番にクリックしていけば価格レベルが F1 Free に変更されます。 スケールアップから入るところがなかなか分かりにくいですね。 でも、これをやっておかないと、知らない間にガンガン課金されていた、ってことになりかねません。 Web App Bot の動作確認 Web App Bot のリソースの作成が終わったら、チャットボットの動作確認をしておきましょう。 下記のようにすると、Azure ポータル上で Web チャット UI を表示してテストすることができます。 すべてのリソース を選択 作成した Web App Bot のリソースを選択 Web チャットでテスト を選択 今回は、Echo Bot のテンプレートを使用したので、「こんにちわ」と入力したときに、「You said \u0026ldquo;こんにちわ\u0026rdquo;」という応答が返ってきています。 次のステップはこちら： Web App Bot で生成されたボットのコードを編集する Azure にチャットボットをデプロイする"
},
{
url: "/p/bpqkm2o/",
title: "チャットボット (2-2) Web App Bot で生成されたボットのコードを編集する",
date: "2019-03-20T00:00:00Z",
body: "チャットボット (2-2) Web App Bot で生成されたボットのコードを編集する チャットボットのソースコードをダウンロードする 下記のページの手順に従い、Azure ポータル上で Web App Bot のリソースを作成すると、自動的に Echo Bot のテンプレートコードが生成されているはずです（選択したテンプレートの種類によって変わりますが、ここでは Node.js 版の Echo Bot テンプレートを指定しているとします）。 Azure でボットをホストするための Web App Bot リソースを作成する ボットプログラムを作成する場合は、基本的にはこのテンプレートコードをベースにして修正を行っていくのがよいでしょう。 自動生成されたコードは、Azure ポータルから下記のように辿ると ZIP アーカイブでダウロードすることができます。 すべてのリソース を選択 対象の Web アプリボット リソースを選択（下記の例では maku-bot） ボット管理 の ビルド を選択 ボットのソースコードをダウンロードする のボタンをクリック 図: ボットコードをダウンロード bot ファイルの復号化・暗号化 botFileSecret とは ダウンロードした ZIP アーカイブの中には、ボットサーバの設定ファイルである .bot ファイルが含まれています。 このファイルは、ローカルでボットサーバを立ち上げたり、エミュレータからそのサーバに接続するときの設定ファイルとして使用するのですが、自動生成された .bot ファイルは、接続情報などの値が暗号化されています。 .bot ファイルの復号化、および暗号化に使用されているキーのことを botFileSecret と呼びます。 ボットサーバやエミュレータを正しく起動するためには、この botFileSecret を使って .bot ファイルをあらかじめ復号化しておくか、環境変数などでキーを設定しておく必要があります。 .bot ファイルを復号化した場合は、Azure 上の Web App Bot サービスにデプロイする前に、忘れずに暗号化しておく必要があります。 botFileSecret の取得 初期の暗号化に使用されている botFileSecret は、Azure ポータルから下記のように辿ることで参照することができます。 すべてのリソース を選択 対象の Web アプリボット リソースを選択（下記の例では maku-bot） App Service 設定 → アプリケーション設定 を選択 アプリケーション設定 のセクションの中に botFileSecret という項目が見つかります 図: botFileSecret の確認 ちなみに、ここの変数は自由に変更できるようになっています。 .bot ファイルの暗号化に使うキーを変更したときは、ここの設定も忘れずに変更しておく必要があります。 .bot ファイルの復号化・暗号化 .bot ファイルの暗号化や復号化を行うためのコマンドラインツールとして、msbot というツールが提供されています。 Node.js の npm コマンドを使用して以下のようにインストールすることができます。 msbot コマンドのインストール npm install -g msbot .bot ファイルの復号化と暗号化は下記のように行います。 .bot ファイルの復号化 msbot secret --bot \u0026lt;bot-file\u0026gt; --secret \u0026#34;\u0026lt;bot-file-secret\u0026gt;\u0026#34; --clear .bot ファイルの暗号化 msbot secret --bot \u0026lt;bot-file\u0026gt; --secret \u0026#34;\u0026lt;bot-file-secret\u0026gt;\u0026#34; --new ローカル PC 上でボットサーバを起動する ローカル環境でボットの開発を進めるには、ローカル PC 上でボットサーバを立ち上げて、エミュレータから接続してテストを行います（もちろん、エミュレータから Azure 上のボットサービスに接続することもできます）。 ダウンロードした ZIP アーカイブの中には、ボットサーバのエントリポイントとなる index.js や、パッケージ依存関係を記述した package.json が含まれています。 まず、npm コマンドを使って必要な Node パッケージ群をインストールします（参考: まくまく Node.js ノート（npm コマンドの使い方など））。 ボットサーバに必要な Node パッケージをインストール $ npm install 次に、ボットサーバが使用する .bot ファイルのパスと、復号化のためのキーを、それぞれ botFilePath 環境変数と botFileSecret 環境変数に設定しておく必要があります。 あるいは、下記のようにプロジェクトのルートディレクトリに、.env ファイルを作成して、その中に環境変数を設定することもできます。 .env botFilePath=./maku-bot.bot botFileSecret=skaE77l/x98D/IdSYXPaiqe4YxsGhiSpXGSuKZsclE3= .env ファイルに botFileSecret の情報を記述する場合は、.env ファイルを間違えて Azure 上にデプロイしてしまったり、Git リポジトリにコミットしてしまわないように注意してください。 デフォルトで生成される .gitignore のエントリには、.env ファイルを Git のコミット対象にしないよう設定されています。 ここまでの設定が終わったら、npm start コマンドでボットサーバを起動することができます。 $ npm start \u0026gt; echobot-with-counter@1.0.0 start /Users/maku/maku-bot \u0026gt; node index.js restify listening to http://[::]:3978 Get Bot Framework Emulator: https://aka.ms/botframework-emulator To talk to your bot, open echoBot-with-counter.bot file in the Emulator 次に、エミュレータからこのボットサーバに接続します。 Bot Framework Emulator からボットサーバに接続する ローカルのボットサーバへ接続する チャットボットのテストは、Bot Framework Emulator を使って行います。 このエミュレータがインストールされていれば、.bot ファイルをダブルクリックするだけで、ローカルに立ち上げたボットサーバ、あるいは Azure 上の Web App Bot サービスに接続することができます。 暗号化された .bot ファイルをダブルクリックしてエミュレータを立ち上げようとすると、下記のようなダイアログが表示されるので、ここに botFileSecret を入力してください。 図: エミュレータでの botFileSecret の入力 デフォルトでは、下記のように、ローカルで立ち上げたボットサーバに接続しに行くはずです。 左に表示されている、ENDPOINT の development が、ローカルへの接続設定を表しています。 図: エミュレータからローカルのボットーサーバに接続 ここまでできるようになれば、チャットボットの開発を本格的に進められるようになっているはずです。 Azure 上の Web App Bot サービスへ接続する Azure で自動生成された .bot ファイルには、Azure 上の Web App Bot サービスに接続するための情報も記載されています（エンドポイント名 production として登録されています）。 接続のためのアプリ ID やキーも含まれているため、.bot ファイルがあれば接続設定はすべて揃うようになっています。 ひとつだけ、エミュレータからリモートのサーバへ接続する場合は、ngrok というプロキシソフトをインストールしておく必要があります。 エミュレータを立ち上げたときに、LOG の欄にも ngrok が設定されていないというメッセージが表示されています。 図: エミュレータの ngrok の設定を促すメッセージ ngrok は下記からダウンロードしてインストールしてください。 ngrok ngrok のインストールが完了したら、エミュレータの設定アイコンをクリックし、ngrok の実行ファイルのパスを設定します。 図: エミュレータに ngrok のパスを設定する この設定が終われば、ENDPOINT の欄から production を選択することで、Azure 上に構築した Web App Bot サービスに接続できるようになります。"
},
{
url: "/p/gxm9shf/",
title: "チャットボット (2-3) Azure の Web App Bot リソースにボットをデプロイする",
date: "2019-03-20T00:00:00Z",
body: "チャットボット (2-3) Azure の Web App Bot リソースにボットをデプロイする まず前提として、下記の手順により、Azure 上に Web App Bot リソースが作成済みであることとします。 ここに、ローカルで作成したボットをデプロイすることになります。 Azure でボットをホストするための Web App Bot リソースを作成する Web ブラウザでデプロイする方法（KUDU の Zip Deploy UI） プロジェクトのファイルを ZIP ファイルとしてアーカイブし、Zip Deploy UI という Web ページにドラッグ＆ドロップでデプロイする方法です。 この Web サイトには、下記のような URL でアクセスできます。 \u0026lt;app_name\u0026gt; の部分は、自分のボットアプリ名に置き換えてください。 https://\u0026lt;app_name\u0026gt;.scm.azurewebsites.net/ZipDeployUI 図: Web App Bot の Zip Deploy UI 左上に表示されるロゴからも分かるように、Azure の Web App サービスでは、Kudu というデプロイエンジンが使われているようですね。 この /wwwroot ディレクトリの内容が表示されている画面で、エクスプローラ領域に ZIP ファイルをドラッグ＆ドロップすると、ZIP ファイル内のファイルがまとめて /wwwroot にアップロードされます。 図: ZIP ファイルのドラッグ＆ドロップでデプロイ ボットプログラムのエントリポイントとなる bot.js ファイルを編集してから ZIP 化し、デプロイすることで、ボットの動作が変わることを確認できると思います。 ZIP アーカイブ作成時の注意 ZIP ファイルの中身が展開された状態でデプロイされるので、ZIP の展開後に余計なディレクトリ階層ができないように ZIP アーカイブを作成してください。 具体的には、プロジェクトのディレクトリを ZIP 化するのではなく、プロジェクトのディレクトリ内のファイル群を ZIP 化します。 コマンドラインから ZIP アーカイブを作成するには、プロジェクトのルートディレクトリから下記のようにします。 Bash の場合 zip -r \u0026lt;file-name\u0026gt;.zip . PowerShell の場合 Compress-Archive -Path * -DestinationPath \u0026lt;file-name\u0026gt;.zip Windows であれば、プロジェクトのディレクトリで Ctrl + A でファイルを全選択し、右クリックから 送る → 圧縮（zip形式）フォルダー とするのが手っ取り早いかもしれません。 ちなみに、上記のサイトで、ファイル名の横にある編集アイコン（鉛筆マーク）をクリックすると、Web サイト上でソースコードを直接編集することができます。 ここでチョチョイとコードを変更すれば、直ちにボットの応答に反映されます。"
},
{
url: "/p/iob68qa/",
title: "チャットボット: Azure ポータルで生成されるボットのテンプレートコードを解読＆リファクタしてみる",
date: "2019-03-26T00:00:00Z",
body: "チャットボット: Azure ポータルで生成されるボットのテンプレートコードを解読＆リファクタしてみる Azure が生成するテンプレートコードを理解する 下記の手順に従って Azure ポータル上で Web App Bot リソースを作成すると、ボットプログラムのテンプレートとして index.js や bot.js などのコードが自動生成されます。 Azure でボットをホストするための Web App Bot リソースを作成する ボットサーバのエントリポイントとなる index.js には、設定情報の読み取りと Web サーバの立ち上げ処理が記述されており、bot.js の方にはボットの応答処理を記述するようになっています。 つまり、基本的にボットの作成者は bot.js の方にボットのコア部分を実装していけばよいのですが、LUIS や QnA Maker などのサービスと連携する場合は、それぞれの初期化処理が必要であり、結局のところ index.js 側の実装に関してもある程度理解しておく必要があります。 Azure ポータルで自動生成される index.js は決して理解しやすいものではないので（少なくとも記述時点では）、ここでは index.js の内容を理解する目的と、わかりやすくリファクタする目的を兼ねて、ボットのベースとなるコードを作成していきます。 最終的には Azure が生成するテンプレートコードと同様の振る舞いになることを想定しています（少なくとも、環境変数の名前などは合わせておいた方がよいです）。 全体の流れ ボットプログラムのエントリポイントとなる index.js では、大まかに下記のような処理を行います。 .env ファイルを読み込み、環境変数の情報とマージする 1 の情報を基に、.bot ファイルを読み込む 2 の情報を基に、ボットサーバーを立ち上げる Azure ポータルで生成されるテンプレートコードでは、上記の処理をすべて index.js の中で行っているのですが、ここでは設定の読み込み部分と、ボットサーバの立ち上げ部分を明確に分離してみます。 config.js: 環境変数や .env ファイルの情報を基に、.bot ファイルの設定を読み込む。 index.js: 上記の設定情報を基にボットサーバを立ち上げる。 という感じにします。 ステップ(1) 環境変数あるいは .env ファイルの読み込み (config.js) ボットサーバーは、.bot ファイルに記述された設定情報に基づいて動作します。 この .bot ファイルを読み込むための情報（ファイルパスなど）は、環境変数や .env ファイルに記述されているため、まずはこれらを読み込まなければいけません。 環境変数や .env ファイルでは、下記のような情報が設定されています。 少なくとも、botFilePath と botFileSecret の設定は必須とされています。 変数名 意味 設定例 botFilePath .bot ファイルのパス ./maku-bot.bot botFileSecret .bot ファイルの復号化／暗号化キー 9l/b88E/hiSpcIdxskqe4YSaE7sGSYXPaiuKZslE3XG= NODE_ENV 実行環境（.bot のどのセクションを読むか） development: ローカルテスト用 (DEFAULT) production: 本番環境用 下記の loadEnvFile メソッドは、上記のような情報を読み込んでオブジェクトとして返します。 config.js // .env ファイルの設定を環境変数 (process.env) とマージし、 // .bot ファイルを読み込むための情報（パスなど）を返す。 function loadEnvFile() { const dotenv = require(\u0026#39;dotenv\u0026#39;); const path = require(\u0026#39;path\u0026#39;); const ROOT_DIR = __dirname; // Read .env file and merge info to process.env dotenv.config({ path: path.join(ROOT_DIR, \u0026#39;.env\u0026#39;) }); return { // Absolute path of .bot file botFilePath: path.join(ROOT_DIR, (process.env.botFilePath || \u0026#39;\u0026#39;)), // Secret key of .bot file botFileSecret: process.env.botFileSecret, // Name of the endpoint configuration section from the .bot file botEnv: process.env.NODE_ENV || \u0026#39;development\u0026#39;, } } ステップ(2) .bot ファイルの読み込み .bot ファイルの読み込みには、Microsoft が提供している botframework-config モジュールの BotConfiguration クラスを使用します。 上記のステップで取得した、.bot ファイルのパス (botFilePath) と、復号化キー (botFileSecret) が必要になります。 下記の loadBotFile 関数は、ステップ (1) で取得した情報をパラメータで受け取り、.bot ファイルを読み込みます。 config.js（続き） // 暗号化された .bot ファイルを読み込み、 // 指定されたエンドポイント (developement や production) の設定情報を返す。 function loadBotFile(env) { const { BotConfiguration } = require(\u0026#39;botframework-config\u0026#39;); let botConfig; try { // Read bot configuration from .bot file. botConfig = BotConfiguration.loadSync(env.botFilePath, env.botFileSecret); } catch (err) { console.error(`\\nError reading bot file. Please ensure you have valid botFilePath and botFileSecret set for your environment.`); console.error(`\\n - You can find the botFilePath and botFileSecret in the Azure App Service application settings.`); console.error(`\\n - If you are running this bot locally, consider adding a .env file with botFilePath and botFileSecret.`); console.error(`\\n - See https://aka.ms/about-bot-file to learn more about .bot file its use and bot configuration.\\n\\n`); process.exit(); } // Get bot endpoint configuration by service name (such as \u0026#34;development\u0026#34; and \u0026#34;production\u0026#34;) const endpointConfig = botConfig.findServiceByNameOrId(env.botEnv); return { appId: endpointConfig.appId || process.env.microsoftAppID, appPassword: endpointConfig.appPassword || process.env.microsoftAppPassword, channelService: process.env.ChannelService, openIdMetadata: process.env.BotOpenIdMetadata, } } これで、config.js が担うべき設定情報の読み込み処理は完成です。 コードの末尾部分では、実際にこれらの関数を呼び出し、モジュールのプロパティとして参照できるように公開しておきます。 config.js（続き） const env = loadEnvFile(); module.exports = loadBotFile(env); ボットのエントリポイントとなる index.js から、このファイルを require('./config.js') で読み込んで使用します。 ステップ(3) ボットサーバーを立ち上げる ここまでのステップで、ボットサーバーを立ち上げるための設定情報を読み込めるようになりました。 次に、実際にその情報を使ってボットを設定し、起動します。 ボットは、restify モジュールを使って起動した Web サーバーの上で動作します。 Bot Builder SDK として公開されている BotFrameworkAdapter クラスは、チャンネル（チャットクライアント）と、ボットの本体プログラムを繋ぐアダプタとして動作します。 接続における認証処理などもこのクラスが担ってくれるので、とても重要なクラスです。 下記の index.js は、ボットのエントリポイントとなるファイルで、 設定情報の読み込み (上記で作成した config.js を使用） その設定を使ってアダプタを初期化 ボットの本体となる Bot オブジェクトを生成（後述の bot.js を使用） Web サーバを立ち上げ、アダプタでチャンネルとボット本体を接続する という処理を行います。 index.js // ボットアダプターを生成する。 // Connector と Bot プログラムの橋渡し、認証処理などを行う。 function createBotAdapter(config) { // See https://aka.ms/about-bot-adapter to learn more about bot adapter. const { BotFrameworkAdapter } = require(\u0026#39;botbuilder\u0026#39;); const adapter = new BotFrameworkAdapter(config); // Catch-all for any unhandled errors in your bot. adapter.onTurnError = async (context, error) =\u0026gt; { // This check writes out errors to console log .vs. app insights. console.error(`\\n [onTurnError]: ${ error }`); // Send a message to the user await context.sendActivity(`Oops. Something went wrong!`); }; return adapter; } // ボットサーバーを起動する function startServer(adapter, bot) { const restify = require(\u0026#39;restify\u0026#39;); let server = restify.createServer(); server.listen(process.env.port || process.env.PORT || 3978, function() { console.log(`\\nBot server listening to ${ server.url }`); }); // Listen for incoming activities and route them to your bot main dialog. server.post(\u0026#39;/api/messages\u0026#39;, (req, res) =\u0026gt; { adapter.processActivity(req, res, async (context) =\u0026gt; { await bot.onTurn(context); }); }); } // エントリポイント (function main() { const config = require(\u0026#39;./config.js\u0026#39;); const adapter = createBotAdapter(config); const { Bot } = require(\u0026#39;./bot.js\u0026#39;); const bot = new Bot(); startServer(adapter, bot); })(); ステップ(4) ボット本体 (bot.js) 最後にボット本体となる Bot クラスの実装です（すでに上記の index.js から参照していますが）。 ここでは、チャットクライアントから受け取ったメッセージをそのままオウム返ししています。 bot.js const { ActivityTypes } = require(\u0026#39;botbuilder\u0026#39;); class Bot { async onTurn(turnContext) { const type = turnContext.activity.type; if (type === ActivityTypes.Message) { const text = turnContext.activity.text; await turnContext.sendActivity(`You said \u0026#34;${text}\u0026#34;`); } else { await turnContext.sendActivity(`[${type}event detected]`); } } } exports.Bot = Bot; テスト実行 これで、チャットボットのひと通りのベース実装は完成です。 下記のように実行すれば、チャットサーバーが起動して、Bot Framework Emulator などから接続できるようになります。 $ node index.js Bot server listening to http://[::]:3978 Azure ポータルで自動生成された package.json ファイルがあるはずなので、下記のようにしても起動できると思います。 $ npm start 起動できない場合は、.env ファイルに .bot ファイルの情報が正しく設定されているか確認してみてください。 .env botFilePath=./maku-bot.bot botFileSecret=9l/b88E/hiSpcIdxskqe4YSaE7sGSYXPaiuKZslE3XG= ソースコード ここで作成したソースコードを置いておきます。"
},
{
url: "/p/8choj4w/",
title: "チャットボット: MS Bot Framework の .bot ファイルで接続情報を管理する",
date: "2019-04-03T00:00:00Z",
body: "チャットボット: MS Bot Framework の .bot ファイルで接続情報を管理する エミュレータのための .bot ファイル Bot Framework Emulator は、自分自身（チャットクライアント）が接続するボットサーバのアドレスを .bot ファイルから取得します。 .bot ファイルの中には、\u0026quot;type\u0026quot;: \u0026quot;endpoint\u0026quot; というエンドポイント定義が 1 つ以上記述されており、ここにはボットプログラムのアドレスが記述されています。 エミュレータの設定で、どのエンドポイント設定を使用するかを切り替えることで、実際に接続するボットを使い分けることができます。 典型的には、開発時にローカルホスト上で動作させたボットサーバに接続するための development と、実稼働用に Azure 上で動作させたボットサーバに接続するための production というエンドポイントを定義します。 図: エミュレータ上でのエンドポイント切り替え ボットプログラムのための .bot ファイル .bot ファイルは、ボットプログラムからも利用されます（こちらの方がメイン）。 .bot ファイルには、LUIS や QnA Maker のサービスを利用するためのエンドポイント情報（アドレスやエンドポイントキー）が定義されており、ボットプログラムはこれらの情報を使って各サービスの API を利用します。 こららの情報は、ボット自体がローカルホスト上で動作していても、Azure 上で動作していても同様に利用されます。 また、ここでもボット自体の endpoint エントリが参照され、各種チャンネル（チャットクライアント）がボットにアクセスするときの認証処理のために使用されます。 このあたりの処理は、Bot Builder SDK を使ってボット実装を行っていれば、Adapter クラスとして抽象化されるため、特に意識せずに実装することができます。 .bot ファイルに LUIS や QnA Maker の接続設定を記述する .bot ファイルは XML ファイルなので、フォーマットさえ理解すればテキストエディタなどで編集してしまうことはできますが、エンドポイントキー部分の復号化・暗号化が必要だったりして面倒です。 Bot Framework Emulator には、.bot ファイルの内容を GUI で編集する機能が付いているのでこの機能を使うのがよいでしょう。 LUIS/QnA Maker サービスへの接続情報を設定する .bot ファイルをダブルクリックしてエミュレータを起動したら、左上の SERVICES の ＋ ボタンを押すことで各サービスの接続設定を行うことができます。 図: LUIS の接続設定を .bot ファイルに追加する Azure portal にログインしていない状態だと、ログインを求められるので、そのまま指示にしたがって Azure portal にログインします。 手順に従って LUIS/QnA Maker の接続情報を自動取得 or 手動入力します。 無事設定ができると、.bot ファイルの中に、次のような感じで LUIS/QnA Maker 接続のためのエンドポイント情報が保存されるはずです。 maku-bot.bot（一部抜粋） { \u0026#34;services\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;luis\u0026#34;, \u0026#34;appId\u0026#34;: \u0026#34;c5514855-fa6b-8f4c-c695-9ac7d3519412\u0026#34;, \u0026#34;authoringKey\u0026#34;: \u0026#34;Z5JHftI7h6CqW19iorgMeQ==!qmpIv7UyWR5KizeKQ/P5WotwnIw6LXYdhsSfRXbAjwMYoGTXVNd9uw/r8II5ph2B\u0026#34;, \u0026#34;id\u0026#34;: \u0026#34;c5514855-fa6b-8f4c-c695-9ac7d3519412\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;maku-luis-sample\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;westus\u0026#34;, \u0026#34;subscriptionKey\u0026#34;: \u0026#34;wGtV6dpEVwVRSn/1jiuqUw==!0KjfCqHek8hruxRyGdG9cMhYJqEpPp5hY/2or4vfoIRi2fvBNZavAvz6odDdG64Y\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;0.1\u0026#34; }, { \u0026#34;type\u0026#34;: \u0026#34;qna\u0026#34;, \u0026#34;endpointKey\u0026#34;: \u0026#34;etu4UQESnuvypEFZe+i+Qw==!ETEcbh/FkXtnQRjnHJlNXbYtD7Yha7WboqBX6skYAeXVh07qLO53UeqBPtohVZFQ\u0026#34;, \u0026#34;hostname\u0026#34;: \u0026#34;https://maku-qna-resource.azurewebsites.net\u0026#34;, \u0026#34;kbId\u0026#34;: \u0026#34;c78ec3e7-a58d-ca44-dbb6-e7805d8130c6\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;maku-qna-sample\u0026#34;, \u0026#34;subscriptionKey\u0026#34;: \u0026#34;LiFCYQxahtplAwEFQvLEWg==!QHxCEIby0NjXr4jsFbuDhGSzdvBslfWxDlfomiGiyHIa+T4keDRvTpxdtseddvmt\u0026#34;, \u0026#34;id\u0026#34;: \u0026#34;231\u0026#34; } ], } エンドポイントキーの暗号化について LUIS の authoringKey/subscriptionKey、QnA Maker の endpointKey/subscriptionKey の部分は暗号化されていますが、この暗号化処理はエミュレータが自動でやってくれます。 .bot ファイルの内容を手動で書き換えた場合は、botbuilder-tools に付属している msbot コマンドを使って暗号化できます。 コマンドラインで .bot ファイルを暗号化する場合 $ msbot secret -b maku-bot.bot --secret XXXXXX ボットプログラムから .bot ファイルを読み込む ボットプログラムから .bot ファイルを読み込んで、LUIS や QnA Maker への接続情報を取得することができます。 .bot ファイルの読み込み方に関しては下記の記事を参照してください。 LUIS や QnA Maker サービスへの接続情報を .bot ファイルから取得する"
},
{
url: "/p/o2bqajv/",
title: "チャットボット: LUIS や QnA Maker サービスへの接続情報を .bot ファイルから取得する",
date: "2019-04-15T00:00:00Z",
body: "チャットボット: LUIS や QnA Maker サービスへの接続情報を .bot ファイルから取得する 参考: MS Bot Framework の .bot ファイルで接続情報を管理する ここで作るもの こちらの実装 では、最初のステップとしてボットサーバ自体 (Azure Web Apps) のエンドポイント情報を .bot ファイルから取得する実装を行いました (config.js)。 ここでは、さらに、LUIS サービスや QnA Maker サービスを利用することを想定し、これらの情報も .bot ファイルから取得できるように拡張します。 使用イメージとしては、下記のようにしてそれぞれの接続情報を簡単に読み込めるようにします。 const config = require(\u0026#39;./config.js\u0026#39;); const LUIS_APP_NAME = \u0026#39;maku-luis-sample\u0026#39;; const QNA_APP_NAME = \u0026#39;maku-qna-sample\u0026#39;; const botEndpoint = config.loadBotEndpoint(); // ボット自体への接続情報 const luisEndpoint = config.loadLuisEndpoint(LUIS_APP_NAME); // LUIS への接続情報 const qnaEndpoint = config.loadQnaEndpoint(QNA_APP_NAME); // QnA Maker への接続情報 単一のオブジェクトとしてまとめて取得するように実装することもできるのですが、分かりやすさのために、3 つの情報に分けて取得するようにしています。 LUIS や QnA Maker は、複数のアプリ（ナレッジベース）を同時に使用する可能性があるので、アプリ名を指定して接続情報を取得できるようにしています。 取得した情報は、次のように BotBuilder SDK が提供するクラスへの入力として使用することを想定しています。 botEndpoint オブジェクトは、botbuilder パッケージの BotFrameworkAdapter クラスのコンストラクタに渡されます。 luisEndpoint オブジェクトは、botbuilder-ai パッケージの LuisRecognizer クラスのコンストラクタに渡されます。 qnaEndpoint オブジェクトは、botbuilder-ai パッケージの QnAMaker クラスのコンストラクタに渡されます。 下記は、実際に取得されるオブジェクトの内容の例です。 これらのオブジェクトは、上記のように SDK のクラスへの入力用に使用するので、各プロパティの値を直接参照することはないと思います。 上記のコードで得られる情報の例 botEndpoint = { appId: \u0026#39;921c6a01-1948-0f4d-9a82-75daf6a6d43c\u0026#39;, appPassword: \u0026#39;16lgoF+phvG:MPeg1eIDma*fcNU#!5jv\u0026#39;, ... } luisEndpoint = { applicationId: \u0026#39;c5514855-fa6b-8f4c-c695-9ac7d3519412\u0026#39;, endpointKey: \u0026#39;9ccff1530f4214fd8e319434a1408fa2\u0026#39;, endpoint: \u0026#39;https://westus.api.cognitive.microsoft.com\u0026#39; } qnaEndpoint = { knowledgeBaseId: \u0026#39;c78ec3e7-a58d-ca44-dbb6-e7805d8130c6\u0026#39;, endpointKey: \u0026#39;c9153f6c-980c-bd41-4ba6-370392cda0e8\u0026#39;, host: \u0026#39;https://maku-qna-sample.azurewebsites.net/qnamaker\u0026#39; } botframework-config パッケージのインストール .bot ファイルのロードには、Node の botframework-config パッケージが提供する BotConfiguration クラスを使用します。 必要があれば、下記のようにインストールして、package.json に依存関係を追記します。 $ npm install botframework-config --save 実装 config.js 全体のコード class Config { /** * コンストラクタ。 * 環境変数や .env ファイルに書かれた botFilePath や botFileSecret の * 情報を基に、.bot ファイルを読み込みます。 */ constructor() { const env = this._loadEnvFile(); this.botEnv = env.botEnv; this.botConfig = this._loadBotFile(env.botFilePath, env.botFileSecret); } /** * 指定された Bot Endpoint (developement や production) への * 接続情報を取得します。 */ loadBotEndpoint() { // Get bot endpoint configuration by service name // Bot configuration as defined in .bot file const endpointConfig = this.botConfig.findServiceByNameOrId(this.botEnv); return { appId: endpointConfig.appId || process.env.microsoftAppID, appPassword: endpointConfig.appPassword || process.env.microsoftAppPassword, channelService: process.env.ChannelService, openIdMetadata: process.env.BotOpenIdMetadata, } } /** * 指定した LUIS アプリへの接続情報を取得します。 * botbuilder-ai パッケージの LuisRecognizer クラスの * 初期化情報として使用することを想定しています。 * 設定が見つからない場合は空のオブジェクトを返します。 */ loadLuisEndpoint(luisAppName) { const luisConfig = this.botConfig.findServiceByNameOrId(luisAppName); if (luisConfig == null) { return {}; } // Map the contents to the required format for `LuisRecognizer`. return { applicationId: luisConfig.appId, endpointKey: luisConfig.subscriptionKey, endpoint: luisConfig.getEndpoint() }; } /** * 指定した QnA Maker アプリへの接続情報を取得します。 * botbuilder-ai パッケージの QnAMaker クラスの初期化情報として * 使用することを想定しています。 * 設定が見つからない場合は空のオブジェクトを返します。 */ loadQnaEndpoint(qnaAppName) { const qnaConfig = this.botConfig.findServiceByNameOrId(qnaAppName); if (qnaConfig == null) { return {}; } // Map the contents to the required format for `QnAMaker`. return { knowledgeBaseId: qnaConfig.kbId, endpointKey: qnaConfig.endpointKey, host: qnaConfig.hostname }; } /** * .env ファイルの設定を環境変数 (process.env) とマージし、 * .bot ファイルを読み込むための情報（パスなど）を返します。 */ _loadEnvFile() { const dotenv = require(\u0026#39;dotenv\u0026#39;); const path = require(\u0026#39;path\u0026#39;); const ROOT_DIR = __dirname; // Merge .env info to process.env dotenv.config({ path: path.join(ROOT_DIR, \u0026#39;.env\u0026#39;) }); return { // Absolute path of .bot file botFilePath: path.join(ROOT_DIR, (process.env.botFilePath || \u0026#39;\u0026#39;)), // Secret key of .bot file botFileSecret: process.env.botFileSecret, // Name of the endpoint configuration section from the .bot file botEnv: process.env.NODE_ENV || \u0026#39;development\u0026#39;, } } /** * 暗号化された .bot ファイルを読み込みます。 */ _loadBotFile(botFilePath, botFileSecret) { const { BotConfiguration } = require(\u0026#39;botframework-config\u0026#39;); try { return BotConfiguration.loadSync(botFilePath, botFileSecret); } catch (err) { console.error(\u0026#39;Error reading bot file.\u0026#39;); console.error(err.message + \u0026#39;\\n\u0026#39;); console.error(\u0026#39;Please ensure you have valid botFilePath\u0026#39; + \u0026#39; and botFileSecret set for your environment.\u0026#39;); console.error(\u0026#39;You can find the botFilePath and botFileSecret\u0026#39; + \u0026#39; in the Azure App Service application settings.\u0026#39;); console.error(\u0026#39;If you are running this bot locally, consider adding\u0026#39; + \u0026#39; a .env file with botFilePath and botFileSecret.\u0026#39;); process.exit(1); } } } module.exports = new Config(); BotConfiguration.loadSync() のエラーについてのメモ BotConfiguration.loadSync() でエラーが発生して .bot ファイルがうまく読み込めなかった場合、Microsoft 公式のサンプルコードでは「botFilePath と botFileSecret をちゃんと設定してください」といった感じのメッセージだけ表示して済ませています。 しかし、実際には .bot ファイルを読み込めても記述内容がおかしい場合にはエラーが発生します（URL が求められているプロパティなのに URL の形式になっていない場合など）。 このチグハグなエラーメッセージのせいで結構ハマりました。。。 .bot ファイルの読み込みがエラーになった場合に、その原因を明確にするためには、最低限 Error オブジェクトの内容（err.message など）を出力してあげた方がよいです。 BotConfiguration#findServiceByNameOrId() で返される接続情報についてのメモ BotConfiguration#findServiceByNameOrId() で返される各サービスの接続情報に何が含まれるかは、下記の TypeScript のクラスとして定義されています。 EndpointService class appId、appPassword、endpoint プロパティなどを持つ。 LuisService class appId、authoringKey、region、subscriptionKey、version プロパティ、getEndpoint() メソッドなどを持つ。 getEndpoint() メソッドの戻り値を使用すれば、通常は region や version プロパティの値を個別に参照する必要はない。 authoringKey は管理用のキーなので、実運用では subscriptionKey を LUIS のエンドポイントキーとして使用すること。 QnaMakerService class endpointKey、hostname、kbId、subscriptionKey プロパティなどを持つ。 subscriptionKey は管理用のキーなので、実運用では endpointKey を QnA Maker のエンドポイントキーとして使用すること。 LUIS と QnAMaker のキーはそれぞれ 2 種類ずつあって、どちらを実際のエンドポイントキーとして使用するかは注意すべきポイントです。 キーの区別がよくわからなくなってきた場合は、こちらの記事「LUIS と QnA Maker でキーの管理方法が異なるのはなぜか？」を参照してください。 findServiceByNameOrId() の返すオブジェクトには、各種サービスの API を利用するために必要十分な情報が含まれていますが、.bot ファイルに記述した内容をすべて取得できるというわけではないことに注意してください。 他にも、DispatchService、FileService、CosmosDbService、BlobStorageService など、サービスタイプに応じたクラスが定義されています。 サービスタイプの一覧は、ServiceType enum の定義を見れば分かるでしょう。 使用例 上記の config.js で取得した接続情報の使用例です。 ボットコード全体を示すと長大になってしまうので、ここでは、BotFrameworkAdapter、LuisRecgonizer、QnAMaker クラスのインスタンスを作成する部分を抜粋して示します。 BotFrameworkAdapter の初期化 const { BotFrameworkAdapter } = require(\u0026#39;botbuilder\u0026#39;); const config = require(\u0026#39;./config.js\u0026#39;); const adapter = new BotFrameworkAdapter(config.loadBotEndpoint()); LuisRecognizer の初期化 const { LuisRecognizer } = require(\u0026#39;botbuilder-ai\u0026#39;); const config = require(\u0026#39;./config.js\u0026#39;); const LUIS_APP_NAME = \u0026#39;your-luis-app-name\u0026#39;; const luisEndpoint = config.loadLuisEndpoint(LUIS_APP_NAME); const luisOptions = { includeAllIntents: true, log: true, staging: false }; const luisRecognizer = new LuisRecognizer(luisEndpoint, luisOptions, true); QnAMaker の初期化 const { QnAMaker } = require(\u0026#39;botbuilder-ai\u0026#39;); const config = require(\u0026#39;./config.js\u0026#39;); const QNA_APP_NAME = \u0026#39;your-qna-app-name\u0026#39;; const qnaEndpoint = config.loadQnaEndpoint(QNA_APP_NAME); const qnaOptions = {}; const qnaMaker = new QnAMaker(qnaEndpoint, qnaOptions);"
},
{
url: "/p/asuzg7k/",
title: "チャットボット: 作成したチャットボットを LINE に接続する",
date: "2019-04-19T00:00:00Z",
body: "チャットボット: 作成したチャットボットを LINE に接続する LINE に Messaging API チャネルを作成する 自作したチャットボットアプリを LINE から「友だち」として見えるようにするには、まず LINE 側に「プロバイダー」を作成し、そこに「Messaging API チャネル」を追加する必要があります。 この Messaging API チャネルは、LINE アプリから「友だち」として見える単位だと考えればよいでしょう。 LINE に開発者として登録する LINE のプロバイダー登録作業などは、下記の LINE Developer Console から行うことができます。 初めてアクセスする場合は、開発者としての登録を求められるので、LINE アカウントでログインして開発者情報を入力してください。 LINE Developer Console プロバイダーを新規作成する LINE に開発者登録できたら、新規プロバイダー作成 のボタンを押して、プロバイダーを作成します。 Messaging API チャネルを追加する プロバイダーの作成が終わったら、そこに Messaging API チャネル を追加します。 チャネルの作成時には、アプリアイコンやアプリ名を自由に登録することができます。 アプリ名は一度設定すると 7 日間は変更できないようなので慎重に決めましょう（アイコンは 1 時間経てば変更できます）。 下のように、プロバイダー上に Messaging API チャネルが追加されていれば OK です。 スマホの LINE に友達登録する Messaging API のチャネルを選択し、チャネル基本設定 タブを見ると、LINE アプリ用の QR コードが見つかります。 この QR コードを LINE アプリのカメラで読み取ることで、チャットボットを友達追加することができます。 ただ、まだボットアプリ本体（自分で作成したボット実装）には接続していないので、話しかけても何も返答してくれません。 下記のようなテンプレートメッセージだけが表示されます。 メッセージありがとうございます。 申し訳ございませんが、このアカウントから個別に返信することはできません。 次回の配信をお楽しみに。 LINE のチャネルを Azure 上の自作ボットに接続する LINE の Developer Console から Messaging API チャネルを作成すると、LINE アプリからチャットボットが見えるようになります。 ただし、この時点では何も頭脳を持たない空っぽのボットです。 この Messaging API チャネルを、自作したボットアプリ（Azure 上にした配置したプログラムなど）に接続することで、LINE アプリと自作したボットとの間で会話できるようになります。 LINE チャネルから接続用の情報を取得する Azure の Web アプリボットのチャンネルとして LINE を登録するには、LINE 側で生成された チャンネルシークレット と、チャンネルアクセストークン が必要です。 先ほど作成した LINE の Messaging API チャネルのページを開き、チャンネル基本設定 のタブを選択するとこれらの値を確認できます。 図: チャンネルシークレットの確認 図: チャンネルアクセストークンの確認 アクセストークンが表示されていない場合は、再発行 ボタンを押すと表示されます。 Azure 上の Web アプリボットに LINE を接続する LINE 側のチャンネルシークレットと、アクセストークンを確認したら、Azure 上のチャットボットアプリを開き、チャンネル → LINE を選択します。 図: Azure 上の Web アプリボットへの LINE チャンネルの追加 LINE の資格情報を入力 というセクションに、LINE 側で発行された チャンネルシークレット と アクセストークン をコピペしてください。 図: Azure 上の Web アプリボットへの LINE チャンネルの追加 最後に、LINE との双方向通信を行えるようにするために、上の図の緑枠で表示された Webhook URL を LINE 側に登録する必要があります。 URL をコピーして、下記のように LINE 側のチャンネル基本設定のページで、Webhook URL を設定し、Webhook 送信 を「利用する」に変更します。 図: LINE チャンネルに webhook URL を登録 これで、LINE アプリと、自作したボットが繋がります！ あれ？「返信することはできません」の自動応答メッセージがまだ出たままですね。 この自動応答メッセージは、LINE の チャネル基本設定 の 自動応答設定 からオフにすることができます。"
},
{
url: "/p/rtxqceq/",
title: "チャットボット: 作成したチャットボットを Slack に接続する",
date: "2019-06-20T00:00:00Z",
body: "チャットボット: 作成したチャットボットを Slack に接続する Slack に Bot Framework で作成したボットを接続する 図: ボットとのダイレクトメッセージによる会話 Microsoft Azure 上に作成したボットアプリを Slack に接続するには、下記の Bot Service 公式ドキュメントで説明されている手順に従ってください。 （日本語）ボットを Slack に接続する - Bot Service ｜ Microsoft Docs （英語）Connect a bot to Slack - Bot Service ｜ Microsoft Docs 接続のおおまかな手順は下記のような感じです。 Slack アプリを作成する（何らかのワークスペースに所属させる形で作成する） Slack アプリにボット用のユーザーを登録する Azure ポータルから、Web アプリボットのチャンネルとして Slack を追加（Slack アプリ側の Client ID、Client Secret、Verification Token をコピペすれば OK） この作業が終わると、ボット（アプリ）が Slack のワークスペースに参加している状態になります。 その時点ではどのチャンネルにも参加していませんが、ダイレクトメッセージを使って一対一でボットと会話することができます。 特定のチャンネルで会話している最中に @ボット名 と話かけると、そのチャンネルにボットを招待することができます。 チャンネルにボットが参加すると、後はそのチャンネルに対してつぶやくだけでボットが反応するようになります。 わかりにくいところの補足 図入りで説明されているので、特に迷うことはないと思いますが、Microsoft の Bot チームのドキュメント通りにはうまくいかない部分があるので若干補足しておきます。 ボットハンドル 「ボットのイベントをサブスクライブ」するという項目で、下記のような Request URL でボットハンドル (YourBotHandle) を指定するところがあります。 https://slack.botframework.com/api/Events/{YourBotHandle} ドキュメント内では、ボットハンドルは ボットポータル 上でボットを選択すると確認できると記述されていますが、そもそもボットを Azure ポータル から作成しているようなケースでは、ボットポータル上でボットを参照することができません。 ボットハンドルには、Azure ポータル上で見える Web アプリボットリソースの名前（上図）と同じものを指定すれば OK です。 Azure ポータル上でリソース名を確認しましょう。"
},
{
url: "/p/a6yzskr/",
title: "チャットボット: Chatdown（.chat ファイル）を使ってボットの会話をデザインする",
date: "2019-03-27T00:00:00Z",
body: "チャットボット: Chatdown（.chat ファイル）を使ってボットの会話をデザインする Chatdown フォーマットとは Chatdown フォーマットは、会話の設計をテキストベースで行うことを意図したフォーマットです。 拡張子は .chat で、下記のような感じで会話例を記述していきます。 sample.chat user=Joe bot=LulaBot bot: Hi! user: yo! bot: [Typing][Delay=3000] Greetings! What would you like to do? * update - You can update your account * List - You can list your data * help - you can get help user: I need the bot framework logo. 上記のように、チャットボットがタイプ中であることや、応答までのディレイなどもデザインすることができます。 Markdown 形式で書式設定できるようになっているのが Chatdown という名前の由来ですね。 Bot Framework Emulator で会話を再現する Bot Framework Emulator で会話ファイルを読み込むと、チャット UI 上で会話を再現することができます。 ただし、Emulator が読み込むことのできるファイルは .transcript 形式のファイルなので、あらかじめ .chat ファイルを変換して .transcript ファイルを生成しておく必要があります。 chatdown ツールによる transcript ファイルの生成 chatdown というコマンドラインツールを使用して、.chat ファイルから .transcript ファイルを生成することができます。 botbuilder-tools/packages/Chatdown at master · Microsoft/botbuilder-tools chatdown コマンドは、Node パッケージとして公開されているので npm コマンドで簡単にインストールすることができます。 chatdown コマンドのインストール $ npm install -g chatdown 下記のように実行すると、.chat ファイルから .transcript ファイルを生成できます。 .transcript ファイルを生成 $ chatdown sample.chat \u0026gt; sample.transcript Bot Framework Emulator で会話を再現する .transcript ファイルが用意できたら、Bot Framework Emulator で読み込むことで会話を再現することができます。 Bot Framework Emulator を起動する メニューから File → Open transcript\u0026hellip; と辿り、.transcript ファイルを選択する すると、下記のようにチャットクライアント上であたかも実際の会話があったかのように表示されます。 図: Bot Framework Emulator による会話の再現 トラブルシューティング: chatdown コマンドがフリーズする場合 プロキシ環境下などでは、chatdown コマンドを実行したときに処理が進まなくなることがあるようです（Version 2.0.0 で発生することを確認）。 コードを調べたところ、latest-version モジュールの latestVersion 関数を同期呼び出ししており、そこでフリーズしてしまっているようです。 このような場合は、スクリプト本体である chatdown.js ファイルを、下記のようにコメントアウトすれば動かせるようになります。 %APPDATA%\\npm\\node_modules\\chatdown\\bin\\chatdown.js async function runProgram() { const args = minimist(process.argv.slice(2)); if (args.prefix) { intercept(function(txt) { return `[${pkg.name}]\\n${txt}`; }); } // let latest = await latestVersion(pkg.name, { version: `\u0026gt;${pkg.version}` }) // .catch(error =\u0026gt; pkg.version); // if (semver.gt(latest, pkg.version)) { // process.stderr.write(chalk.default.white(`\\n Update available `)); // process.stderr.write(chalk.default.grey(`${pkg.version}`)); // process.stderr.write(chalk.default.white(` -\u0026gt; `)); // process.stderr.write(chalk.default.greenBright(`${latest}\\n`)); // process.stderr.write(chalk.default.white(` Run `)); // process.stderr.write(chalk.default.blueBright(`npm i -g ${pkg.name} `)); // process.stderr.write(chalk.default.white(`to update.\\n`)); // } // ..."
},
{
url: "/p/mgujykj/",
title: "チャットボット: ActivityHandler でボットのイベントハンドラ実装を簡略化する",
date: "2019-06-09T00:00:00Z",
body: "チャットボット: ActivityHandler でボットのイベントハンドラ実装を簡略化する Bot Builder SDK (Node.js) の botbuilder-core パッケージには、ActivityHandler という、ボットのイベントハンドラ部分の実装を簡略化するためのライブラリが含まれています。 ボットの世界では、「Activity」はひとつのメッセージの処理単位のことを示しています。 この Activity をうまくハンドルするためのクラスだから ActivityHandler という名前が付けられているんですね。 ここでは、独自のボットクラス (MyBot) を、ActivityHandler を利用せずに実装した場合と、利用して実装した場合で比較してみたいと思います。 ActivityHandler を使わない場合 例えば、下記のように BotFrameworkAdapter で受信したイベントの処理を MyBot.onTurn() に委譲するとします。 mybot.js const myBot = new MyBot(); const adapter = new BotFrameworkAdapter({}); const server = require(\u0026#39;restify\u0026#39;).createServer(); server.post(\u0026#39;/api/messages\u0026#39;, (req, res) =\u0026gt; { adapter.processActivity(req, res, async (context) =\u0026gt; { await myBot.onTurn(context); // あとは MyBot に丸投げ }); }); このイベントは、ユーザからメッセージを送られたときだけでなく、ユーザがチャットに参加したとき (ConversationUpdate) などにも発生するため、MyBot.onTurn() の実装の中でアクティビティタイプを見て分岐処理を行わなければなりません。 class MyBot { constructor() { // ... } async onTurn(context) { if (context.activity.type === ActivityTypes.Message) { const utterance = context.activity.text; await context.sendActivity(`You said: ${utterance}`); } else if (context.activity.type === ActivityTypes.ConversationUpdate) { await context.sendActivity(`[ConversationUpdate event detected]`); } else { await context.sendActivity(`[${turnContext.activity.type}event detected]`); } } } このあたりの分岐処理を簡潔にしてくれるのが ActivityHandler クラスです。 ActivityHandler を使う場合 下記は、ActivityHandler を利用したボット実装の例です。 onMessage() メソッドを使って通常メッセージのハンドラを登録し、onConversationUpdate() メソッドを使って会話更新時のハンドラを登録します。 mybot.js class MyBot extends ActivityHandler { constructor() { super(); // アクティビティタイプごとのイベントハンドラを登録する this.onMessage(this.handleMessage); this.onConversationUpdate(this.handleConversationUpdate); } async handleMessage(context, next) { const utterance = context.activity.text; await context.sendActivity(`You said: ${utterance}`); await next(); } async handleConversationUpdate(context, next) { await context.sendActivity(\u0026#39;[ConversationUpdate event detected]\u0026#39;); await next(); } } Microsoft のサンプルコードでは、onMessage() のパラメータとしてラムダ式をそのまま渡しているものが多いのですが、ネストが深くなってしまうので、上記のようにメソッド化しておいた方がよいでしょう。 あとは、BotFrameworkAdapter でアダプタで受信したイベントを、ActivityHandler.run() に渡してやれば、アクティビティタイプに従って適切なハンドラを呼び出してくれます。 server.post(\u0026#39;/api/messages\u0026#39;, (req, res) =\u0026gt; { adapter.processActivity(req, res, async (context) =\u0026gt; { await myBot.run(context); //★ }); }); ちなみに、ここでは ActivityHandler クラスを継承する形でボットクラスを実装していますが、ActivityHandler をそのままインスタンス化して使用することもできます。 const myBot = new ActivityHandler(); myBot.onMessage(async (context, next) =\u0026gt; { const utterance = context.activity.text; await context.sendActivity(`You said: ${utterance}`); await next(); }); 全体のコード ActivityHandler を使ったボットプログラムの全体のコードを示します。 ローカルでのテスト用なので、Azure 上のボットサービスとして動作させるための設定などは省略しています。 mybot.js const { ActivityHandler, BotFrameworkAdapter } = require(\u0026#39;botbuilder\u0026#39;); // ボット実装 class MyBot extends ActivityHandler { constructor() { super(); this.onMessage(this.handleMessage); this.onConversationUpdate(this.handleConversationUpdate); } async handleMessage(context, next) { const utterance = context.activity.text; await context.sendActivity(`You said: ${utterance}`); await next(); } async handleConversationUpdate(context, next) { await context.sendActivity(\u0026#39;[ConversationUpdate event detected]\u0026#39;); await next(); } } // 下記はほぼテンプレート const myBot = new MyBot(); const adapter = new BotFrameworkAdapter({}); adapter.onTurnError = async (context, error) =\u0026gt; { console.error(`[onTurnError]: ${error}`); }; const server = require(\u0026#39;restify\u0026#39;).createServer(); server.post(\u0026#39;/api/messages\u0026#39;, (req, res) =\u0026gt; { adapter.processActivity(req, res, async (context) =\u0026gt; { await myBot.run(context); }); }); server.listen(process.env.port || process.env.PORT || 3978, () =\u0026gt; { console.log(`Bot server listening to ${server.url}`); });"
},
{
url: "/p/onctywi/",
title: "チャットボット: ユーザーの参加／離脱のイベントをハンドルする",
date: "2019-06-28T00:00:00Z",
body: "チャットボット: ユーザーの参加／離脱のイベントをハンドルする Bot Builder SDK の ActivityHandler を使って、ユーザーが会話に参加したこと、離脱したことをハンドルする方法を説明します。 ActivityHandler を使ったボット実装の基本に関しては下記を参照してください。 チャットボット: ActivityHandler でボットのイベントハンドラ実装を簡略化する 下記は、ユーザーが新しく会話に参加したときに、ボットから挨拶するように実装した例です。 ユーザー参加のイベントをハンドルするには、ActivityHandler#onMembersAdded() で、イベントハンドラを登録します。 mybot.js const { ActivityHandler, BotFrameworkAdapter } = require(\u0026#39;botbuilder\u0026#39;); // ボット実装 class MyBot extends ActivityHandler { constructor() { super(); this.onMessage(this.handleMessage); this.onMembersAdded(this.handleMembersAdded); } async handleMessage(context, next) { const name = context.activity.from.name; const utterance = context.activity.text; await context.sendActivity(`${name}さんは、${utterance}と言いました。`); await next(); } async handleMembersAdded(context, next) { const members = context.activity.membersAdded; for (let i = 0; i \u0026lt; members.length; ++i) { const m = members[i]; if (m.id !== context.activity.recipient.id) { // ボット以外のユーザが参加したときにメッセージを表示 await context.sendActivity(`${m.name}さん、こんにちは！`); } } await next(); } } exports.MyBot = MyBot; ちなみに、このイベントハンドラは、ボット自身が会話に参加したときにも呼び出されます。 ボット以外のユーザーが参加したときだけメッセージを送るには、context.activity.recipient.id と参加者の ID を比較し、通常のユーザーであることを確認します（recipient.id にはボットの ID が入っています）。 上記の例では、ユーザーが参加したときのイベントをハンドルしていますが、ユーザー離脱時のイベントも ActivityHandler#onMembersRemoved() を使って同様にハンドルすることができます。 Bot Framework Emulator を使っている場合は、画面上部の Restart conversation ボタンを押せば、ボットからのメッセージを確認することができます。 Slack をチャンネル（クライアント）として使用している場合は、あるチャンネルにボットを招待したときや、そのチャンネルに新しくユーザーを招待したときに onMembersAdded() が呼び出されるようです。 なので、このイベントハンドラはそんなに頻繁に呼び出されるものではありません。"
},
{
url: "/p/3fnyk44/",
title: "チャットボット: Bot Builder SDK で会話の状態を保存する (Storage)",
date: "2019-06-11T00:00:00Z",
body: "チャットボット: Bot Builder SDK で会話の状態を保存する (Storage) ボットは基本的にステートレスで動作するので、ユーザとの会話のコンテキストを把握するには、ステートの管理を明示的に行う必要があります。 Bot Builder SDK にはそのためのユーティリティクラスが用意されています。 ここでは、Node.js の botbuilder パッケージを使って説明します。 Storage インタフェース botbuilder パッケージに含まれている Storage インタフェースは、抽象化されたストレージに JSON オブジェクトを保存するための API を定義しています。 write、read、delete の 3 つの API のみなのでとてもシンプルです。 write メソッド JSON オブジェクトをストレージに保存するための API です。 オブジェクトを保存するときには、名前（キー）を付けて、キー＆バリューの形のオブジェクトとして保存します。 下記の例では、保存したい state オブジェクトに、botState という名前を付けて保存しています。 state.topic = \u0026#39;someTopic\u0026#39;; await storage.write({ \u0026#39;botState\u0026#39;: state }); read メソッド ストレージに保存されたオブジェクトを読み出すための API です。 読み出したいオブジェクトの名前を配列で渡すと、オブジェクトの連想配列が返ってきます。 下記の例では、botState という名前で保存されたオブジェクトを、state 変数に取り出しています。 const items = await storage.read([\u0026#39;botState\u0026#39;]); const state = items[\u0026#39;botState\u0026#39;] || {}; delete メソッド ストレージに保存されたオブジェクトを削除するための API です。 削除したいオブジェクトの名前を配列で渡します。 await storage.delete([\u0026#39;botState\u0026#39;]); MemoryStorage クラス 実際にストレージを扱うには、Storage インタフェースを実装したクラスが必要です。 MemoryStorage クラス はローカルテスト用のインメモリストレージで、ボットのプロセスが終了するまで情報を保持します。 MemoryStorage のインスタンス化 const { MemoryStorage } = require(\u0026#39;botbuilder\u0026#39;); const storage = new MemoryStorage(); テスト実装 下記はローカル環境で MemoryStorage の振る舞いをテストするためのシンプルなボット実装です。 ユーザがメッセージを送るたびに、state オブジェクトに保持したカウンタの値が 1 ずつ増えていきます。 ローカルテスト用のボット実装 const { ActivityTypes, BotFrameworkAdapter, MemoryStorage } = require(\u0026#39;botbuilder\u0026#39;); // ストレージインスタンスの生成 const storage = new MemoryStorage(); // ストレージにアクセスカウンタを保存 async function onTurn(context) { const items = await storage.read([\u0026#39;state\u0026#39;]); const state = items[\u0026#39;state\u0026#39;] || { \u0026#39;count\u0026#39;: 0 }; await context.sendActivity(`state.count = ${state.count}`); state.count += 1; await storage.write({\u0026#39;state\u0026#39;: state}); } // 以下ほぼテンプレート const adapter = new BotFrameworkAdapter({}); adapter.onTurnError = async (context, error) =\u0026gt; { console.error(`[onTurnError]: ${error}`); }; const server = require(\u0026#39;restify\u0026#39;).createServer(); server.post(\u0026#39;/api/messages\u0026#39;, (req, res) =\u0026gt; { adapter.processActivity(req, res, async (context) =\u0026gt; { if (context.activity.type === ActivityTypes.Message) { await onTurn(context); } }); }); server.listen(process.env.port || process.env.PORT || 3978, () =\u0026gt; { console.log(`Bot server listening to ${server.url}`); }); 別の Storage 実装 上記の例ではインメモリのストレージ実装として MemoryStorage クラスを使用しましたが、会話の状態を永続化するには別のストレージ実装を使用する必要があります。 例えば、Azure Blob Storage や Cosmos DB を使用するためのストレージ実装が用意されています。 BlobStorage クラス \u0026hellip; Azure Blob Storage を保存先とする Storage 実装 CosmosDbStorage クラス \u0026hellip; Azure Cosmos DB Storage を保存先とする Storage 実装 （おまけ）ActivityHandler を使った実装 下記は、上記のボットプログラムを ActivityHandler を使って実装し直したものです。 ボットのメイン処理をボットクラスとして実装すると、何をするボットなのかがわかりやすくなります。 ローカルテスト用のボット実装 const { ActivityHandler, BotFrameworkAdapter, MemoryStorage } = require(\u0026#39;botbuilder\u0026#39;); // ボット実装 class MyBot extends ActivityHandler { constructor() { super(); // ストレージインスタンスの生成 this.storage = new MemoryStorage(); // イベントハンドラの登録 this.onMessage(async (context, next) =\u0026gt; { // ストレージにアクセスカウンタを保存 const items = await this.storage.read([\u0026#39;state\u0026#39;]); const state = items[\u0026#39;state\u0026#39;] || { \u0026#39;count\u0026#39;: 0 }; await context.sendActivity(`state.count = ${state.count}`); state.count += 1; await this.storage.write({\u0026#39;state\u0026#39;: state}); await next(); }); } } // 以下ほぼテンプレート const bot = new MyBot(); const adapter = new BotFrameworkAdapter({}); adapter.onTurnError = async (context, error) =\u0026gt; { console.error(`[onTurnError]: ${error}`); }; const server = require(\u0026#39;restify\u0026#39;).createServer(); server.post(\u0026#39;/api/messages\u0026#39;, (req, res) =\u0026gt; { adapter.processActivity(req, res, async (context) =\u0026gt; { await bot.run(context); }); }); server.listen(process.env.port || process.env.PORT || 3978, () =\u0026gt; { console.log(`Bot server listening to ${server.url}`); }); コンテキストごとに状態を保存する ここまで見てきたように、Storage インタフェースを使用すると、複数の Activity（メッセージのやりとり）をまたぐように状態を保存できるようになります。 しかし、これはいわゆるグローバルな状態保持であり、会話ごとの状態や、ユーザーごとの状態を保存するためには追加の仕組みが必要になります。 Bot Builder SDK には、そのような用途を想定した BotState クラス が用意されています。 下記の記事では BotState クラスの使い方を説明します。 チャットボット: Bot Builder SDK で会話の状態を保存する (BotState, ConversationState, UserState)"
},
{
url: "/p/6wtzzq4/",
title: "チャットボット: Bot Builder SDK で会話の状態を保存する (BotState)",
date: "2019-06-28T00:00:00Z",
body: "チャットボット: Bot Builder SDK で会話の状態を保存する (BotState) BotState クラス Bot Builder SDK の BotState クラス は、ボットとの会話内の特定のコンテキストにおける状態を保持するためのクラスです。 というと難しいですが、簡単に言うと、会話ごとの状態保存や、ユーザーごとの状態保存を行うための便利クラスです。 BotState クラスには次のようなサブクラスが定義されています。 ConversationState クラス \u0026hellip; 会話ごとの状態を保存する UserState クラス \u0026hellip; ユーザーごとの状態を保存する PrivateConversationState クラス \u0026hellip; 会話ごとのユーザごとの状態を保存する これらのクラスは、内部で Storage オブジェクトを利用します。 ≪生成コード\u0026#x1F4D6;≫ Storage がグローバルに状態保存を行っていたのに対し、BotState はネームスペースを考慮して状態保存を行うものだと考えることができます。 実際に、ConversationState クラスや UserState クラスの実装を覗いてみると、getStorageKey() というメソッドでストレージ用の保存キーを作成しており、それぞれ次のように構成しています。 ConversationState が使用する保存キー ${ channelId }/conversations/${ conversationId }/${ this.namespace } UserState が使用する保存キー ${ channelId }/users/${ userId }/${ this.namespace } PrivateConversationState が使用するキー ${ channelId }/conversations/${ conversationId }/users/${ userId }/${ this.namespace } 実用的なボットの状態管理を行うには、Storage インタフェースをそのまま使うのではなく、ConversationState / UserState / PrivateConversationState などを使うことになるでしょう。 ConversationState と UserState クラスを使用する インスタンス化 ConversationState や UserState のインスタンスを作成するには、コンストラクタに Storage オブジェクトを渡します。 const { ConversationState, UserState, MemoryStorage } = require(\u0026#39;botbuilder\u0026#39;); const storage = new MemoryStorage(); const convState = new ConversationState(storage); const userState = new UserState(storage); ここでは、ストレージとして MemoryStorage を使用していますが、CosmosDbStorage などを使用することもできます。 UserState クラスでカウンタを保存する 下記のボットクラスでは、UserState オブジェクトを使って、ユーザーがメッセージを送った回数をカウントしています。 UserState に対して値を読み書きするには、UserState#createProperty() を使ってプロパティアクセサーを作成します。 ここでは、counter という名前のプロパティアクセサーを作成しています。 mybot.js const { ActivityHandler, BotFrameworkAdapter, UserState } = require(\u0026#39;botbuilder\u0026#39;); // ボット実装 class MyBot extends ActivityHandler { constructor(storage) { super(); this._createStateObjects(storage); // イベントハンドラの登録 this.onMessage(async (context, next) =\u0026gt; { const user = context.activity.from.name; const text = context.activity.text; // カウンタープロパティの値を読み取る（初期値は 1） const cnt = await this.counterProp.get(context, 1); // メッセージを返信 await context.sendActivity(`${user}さん、${cnt}回目のメッセージですね: ${text}`); // カウンタープロパティの値を更新（+1 する） await this.counterProp.set(context, cnt + 1); // UserState をすべてストレージに保存する await this.userState.saveChanges(context); }); } // 状態管理用のオブジェクトを作成 _createStateObjects(storage) { this.userState = new UserState(storage); // UserState としてカウンターを保存するプロパティへのアクセサーを作成 this.counterProp = this.userState.createProperty(\u0026#39;counter\u0026#39;); } } exports.MyBot = MyBot; これで、ユーザーごとに、ボットと会話した回数をカウントできるようになります。 上記のボットクラス実装では、UserState が使用する Storage オブジェクトをコンストラクタで受け取るようにしています。 index.js など、ボットクラスを生成する側で MemoryStorage や CosmosDbStorage などのインスタンスを渡すようにしてください。 const myBot = new MyBot(new MemoryStorage()); ConversationState クラスでカウンタを保存する 上記の例では、UserState を使ってカウント値を保存していたので、ユーザーごとにカウント値がインクリメントされていきます。 new UserState という部分を、new ConversationState に変えるだけで、会話ごとにカンウント値を管理できるようになります。 例えば、Slack で考えてみるとわかりやすいです。 UserState にカウント値を保存した場合は、ユーザーがチャンネルを移動しながら会話をしたときに、カウント値が引き継がれてインクリメントされていきます。 Channel1: 1 → 2 → 7 Channel2: 3 → 5 → 9 Channel3: 4 → 6 → 8 一方、ConversationState にカウント値を保存した場合は、チャンネルごとにカウント値が管理されるので、各チャンネルごとに初期値の 1 からインクリメントされていきます。 ただし、このカウント値はチャンネルの中で一意なものになるので、ユーザー間で共有されます。 Channel1: 1 → 2 → 3 Channel2: 1 → 2 → 3 Channel3: 1 → 2 → 3"
},
{
url: "/p/w36evii/",
title: "チャットボット: Bot Builder SDK の Dialog で会話の流れをデザインする (1) ダイアログの基本",
date: "2019-07-01T00:00:00Z",
body: "チャットボット: Bot Builder SDK の Dialog で会話の流れをデザインする (1) ダイアログの基本 Dialog を使わない会話管理 Bot Builder SDK の UserState や ConversationState を使う と、ユーザーや会話ごとの状態管理を行うことできるため、複数回のやりとりが必要な会話を実現することができます。 例えば、下記のような会話ができるボットを実装してみます。 User: こんにちは Bot: あなたの名前は？ User: まく Bot: こんにちは まく さん User: おやすみなさい Bot: また来てね まく さん 次のボット実装は、UserState クラスを使って、pos という名前のプロパティを作成し、会話がどこまで進んでいるかを管理しています。 mybot.js const { ActivityHandler, UserState } = require(\u0026#39;botbuilder\u0026#39;); class MyBot extends ActivityHandler { constructor(storage) { super(); this._createStateObjects(storage); this.onMessage(async (context, next) =\u0026gt; { const prop = await this.nameProp.get(context, { pos: \u0026#39;init\u0026#39; }); // プロパティの \u0026#39;pos\u0026#39; により処理を分岐させる if (prop.pos === \u0026#39;init\u0026#39;) { prop.pos = \u0026#39;askName\u0026#39;; await context.sendActivity(\u0026#39;あなたの名前は？\u0026#39;); } else if (prop.pos === \u0026#39;askName\u0026#39;) { prop.pos = \u0026#39;end\u0026#39;; prop.name = context.activity.text; await context.sendActivity(`こんにちは ${prop.name}さん`); } else { prop.pos = \u0026#39;init\u0026#39;; await context.sendActivity(`また来てね ${prop.name}さん`); } // プロパティに保存 await this.nameProp.set(context, prop); await this.userState.saveChanges(context); }); } // 状態管理用のオブジェクトを作成 _createStateObjects(storage) { this.userState = new UserState(storage); this.nameProp = this.userState.createProperty(\u0026#39;name\u0026#39;); } } exports.MyBot = MyBot; 会話の流れに従って、pos プロパティの値は init → askName → end と変化していきます（最後に init に戻る）。 このように、UserState を使った状態管理だけでも、会話の流れを表現することはできるのですが、こんな状態管理を各トピックごとに実装するのは非常に骨が折れます。 そこで Bot Builder SDK は、Dialog という会話の流れを簡潔に実装するための便利クラスを用意しています。 Dialog を使った会話管理 ここでは、順序通り会話を進めるためのダイアログである WaterfallDialog を使います。 BotBuilder SDK の提供するダイアログ系クラスを使用するには、botbuilder-dialogs パッケージをインストールしておく必要があります。 $ npm install --save botbuilder-dialogs 下記は、WaterfallDialog を使って、ユーザーから名前を聞き出すボットの実装例です。 大まかな流れは次のような感じになります。 ボット起動時に DialogSet に必要な Dialog（会話トピックごとの実装）をセットアップする。 ユーザーからのメッセージを受信 (ActvityHandler#onMessage) するたびに、DialogContext#continueDialog() を呼び出して、処理を 1 ステップずつ進める。 mybot.js const { ActivityHandler, UserState } = require(\u0026#39;botbuilder\u0026#39;); const { DialogSet, DialogTurnStatus, TextPrompt, WaterfallDialog } = require(\u0026#39;botbuilder-dialogs\u0026#39;); // 最初に起動するダイアログの名前 const USER_PROFILE_DIALOG = \u0026#39;userProfileDialog\u0026#39;; class MyBot extends ActivityHandler { constructor(storage) { super(); this.userState = new UserState(storage); this.userProfile = this.userState.createProperty(\u0026#39;userProfile\u0026#39;); this._setupDialogSet(this.userProfile); this.onMessage(async (context, next) =\u0026gt; { // Create DialogContext for the current turn const dc = await this.dialogSet.createContext(context); // Try to continue executing an active multi-turn dialog const ret = await dc.continueDialog(); // Send greeting if no other dialogs active if (ret.status == DialogTurnStatus.empty) { await dc.beginDialog(USER_PROFILE_DIALOG); } await next(); }); this.onDialog(async (context, next) =\u0026gt; { // ダイアログスタックの状態を保持するためにこのコードが必要 await this.userState.saveChanges(context); await next(); }); } _setupDialogSet(propertyAccessor) { // Create a dialog set to manage all dialogs this.dialogSet = new DialogSet(propertyAccessor); // Add dialogs this.dialogSet.add(new WaterfallDialog(USER_PROFILE_DIALOG, [ async (step) =\u0026gt; { return await step.prompt(\u0026#39;askName\u0026#39;, \u0026#39;あなたの名前は？\u0026#39;); }, async (step) =\u0026gt; { const name = step.result; // 前のステップの結果を取得 await step.context.sendActivity(`こんにちは、${name}さん`) return await step.endDialog(); } ])); // Add prompts this.dialogSet.add(new TextPrompt(\u0026#39;askName\u0026#39;)); } } exports.MyBot = MyBot; ポイントは、コンストラクタから呼び出している _setupDialogSet() メソッドで、この中で DialogSet というダイアログ群を管理するオブジェクトを構築しています。 DialogSet のコンストラクタには、ダイアログの状態を管理するための、StatePropertyAccessor オブジェクトを渡します。 このオブジェクトは、UserState#createProperty() あるいは ConversationState#createProperty() で作成できます。 _setupDialogSet(propertyAccessor) { // Create a dialog set to manage all dialogs this.dialogSet = new DialogSet(propertyAccessor); // Add prompts this.dialogSet.add(new TextPrompt(\u0026#39;askName\u0026#39;)); // Add dialogs this.dialogSet.add(new WaterfallDialog(USER_PROFILE_DIALOG, [ async (step) =\u0026gt; { return await step.prompt(\u0026#39;askName\u0026#39;, \u0026#39;あなたの名前は？\u0026#39;); }, async (step) =\u0026gt; { const name = step.result; // 前のステップの結果を取得 await step.context.sendActivity(`こんにちは、${name}さん`) return await step.endDialog(); } ])); } DialogSet#add() を使い、ボットが使用する一連の Dialog を追加しておく必要があります。 ここでは、SDK が提供する WaterfallDialog と TextPrompt という Dialog オブジェクトを追加しています。 TextPrompt はユーザーにテキストの入力を促すための Dialog 実装です（正確には Dialog を継承した Prompt クラスを継承しています）。 ≪生成コード\u0026#x1F4D6;≫ TextPrompt は WaterfallDialog の処理の中から使用するのですが、後から呼び出すために名前を付けて DialogSet に追加しておく必要があります。 名前は DialogSet 中で一意であれば OK です（ここでは、askName という名前を付けています）。 this.dialogSet.add(new TextPrompt(\u0026#39;askName\u0026#39;)); 起点となる WaterfallDialog の方も名前を付けて DialogSet に追加します。 そして、第2引数のコールバック配列で、各ステップのボット応答を実装します。 各ステップには WaterfallStepContext が渡され、これを使って各ステップをどう進んでいくかを定義します。 上記の例では、最初のステップとして、ユーザーに名前の入力を促すためのプロンプト (TextPrompt) を表示するように指定しています。 async (step) =\u0026gt; { return await step.prompt(\u0026#39;askName\u0026#39;, \u0026#39;あなたの名前は？\u0026#39;); }, 最初のパラメータで、あらかじめ登録しておいた askName というプロンプト名を指定しています。 ユーザーが名前を入力すると、今度はその次に指定したコールバックが呼び出されます。 このようなステップ連鎖を実装していき、最後に endDialog() でダイアログ全体の処理を完了します。 async (step) =\u0026gt; { const name = step.result; // 前のステップの結果を取得 await step.context.sendActivity(`こんにちは、${name}さん`) return await step.endDialog(); } step.result には、前のステップでユーザーが入力したテキストが格納されています。 ここでは、その名前を表示して、全体のダイアログ処理を終了 (step.endDialog()) しています（実際には、必要に応じて UserState に保存したりします）。 この WaterfallDialog を起動するエントリポイントとなっているのは、ボットクラスの onMessage ハンドラです。 this.onMessage(async (context, next) =\u0026gt; { // Create DialogContext for the current turn const dc = await this.dialogSet.createContext(context); // Try to continue executing an active multi-turn dialog const ret = await dc.continueDialog(); // Send greeting if no other dialogs active if (ret.status == DialogTurnStatus.empty) { await dc.beginDialog(USER_PROFILE_DIALOG); } await next(); }); 現在アクティブになっているダイアログの処理を 1 ステップずつ進めていくには、ボットクラスの onMessage が呼び出されるたびに、DialogContext#continueDialog() を呼び出さなければいけません。 この関数は、戻り値として (DialogTurnResult) オブジェクトを返し、ダイアログの各ステップの結果や、ダイアログ全体の進捗状態を取得することができます。 ダイアログがまだ起動していない（アクティブなダイアログが存在しない）場合は、DialogTurnResult#state プロパティの値が empty となるため、このときに DialogContext#beginDialog() でダイアログを起動するようにします。 これはお決まりの実装パターンです。 最後に忘れてはいけないのが、onDialog ハンドラの実装です。 this.onDialog(async (context, next) =\u0026gt; { // ダイアログスタックの状態を保持するためにこのコードが必要 await this.userState.saveChanges(context); await next(); }); onDialog ハンドラは各ターンの終わりに呼び出されます。 ダイアログの状態（どのステップまで進んだかという情報）は、BotState オブジェクトで管理されるので、ここで忘れずに保存するようにします。 これを忘れると、WaterfallDialog のステップがいつまでたっても進まなくなります。 Dialog の実装を別クラスに切り出す (ComponentDialog) ボットクラス（ActivityHandler を継承したクラス）の中に、WaterfallDialog などを使用したダイアログ関連の実装を入れてしまうと、コードが煩雑になってしまいます。 ここでは、ダイアログに関する実装を、Dialog クラスを継承した別クラスとして抽出します。 ダイアログクラス側の実装 ダイアログクラスは、ComponentDialog を継承して作成するのが楽です。 ComponentDialog は Dialog を継承したクラスで、addDialog() を使って自分自身が複数の Dialog（あるいは Prompt）を子ダイアログとして保持することができるようになっています。 下記の UserProfileDialog クラスは、ユーザーの名前と年齢を収集する WaterfallDialog を含んだダイアログクラスの実装例です。 間接的に Dialog クラスを継承しているため、DialogSet に格納して起動することができます。 userProfileDialog.js const { ComponentDialog, NumberPrompt, TextPrompt, WaterfallDialog, } = require(\u0026#39;botbuilder-dialogs\u0026#39;); exports.UserProfileDialog = class UserProfileDialog extends ComponentDialog { constructor() { super(\u0026#39;UserProfileDialog\u0026#39;); // Add control flow dialogs（これが最初に起動される） this.addDialog(new WaterfallDialog(\u0026#39;start\u0026#39;, [ async (step) =\u0026gt; { // Ask user their name return await step.prompt(\u0026#39;namePrompt\u0026#39;, `What\u0026#39;s your name?`); }, async (step) =\u0026gt; { // Remember the users answer step.values[\u0026#39;name\u0026#39;] = step.result; // Ask user their age. return await step.prompt(\u0026#39;agePrompt\u0026#39;, `Hi ${step.values[\u0026#39;name\u0026#39;]}. How old are you?`); }, async (step) =\u0026gt; { // Remember the users answer step.values[\u0026#39;age\u0026#39;] = step.result; // End the component and return the completed profile. return await step.endDialog(step.values); } ])); // Add prompts this.addDialog(new TextPrompt(\u0026#39;namePrompt\u0026#39;)); this.addDialog(new NumberPrompt(\u0026#39;agePrompt\u0026#39;)); } }; WaterfallDialog の各ステップで渡される WaterfallStepContext パラメータの result プロパティには、前のステップでユーザーから取得した値が含まれています。 values プロパティ（連想配列）に、その値を格納しておくと、次のステップへ値を引き継いでいくことができます。 step.values['name'] = step.result; 最後のステップでダイアログを終了させるときに、収集した値を endDialog() のパラメータとして渡してやることで、ダイアログの起動元へ結果を返すことができます。 return await step.endDialog(step.values); ボットクラス側の実装 次に、このダイアログクラスを起動するためのボットクラスを作成します。 Microsoft のサンプルコードとして、DialogBot という任意のダイアログを起動するボットクラス実装が紹介されているので、これを参考にすることにします。 サンプルコードでは、ルートの DialogSet に関する処理を、ダイアログクラス側の run() メソッドに実装していますが、特にダイアログクラス側に入れる必要はないと思いますので、ここでは DialogBot 側の実装で DialogSet に関する処理もやってしまうことにします。 ちなみにこの実装では、ダイアログの状態を保存するために、UserState ではなく ConversationState を使っていることに注意してください。 用途によっては使用する BotState オブジェクトを変更する必要があるかもしれません。 dialogBot.js const { ActivityHandler } = require(\u0026#39;botbuilder\u0026#39;); const { DialogSet, DialogTurnStatus } = require(\u0026#39;botbuilder-dialogs\u0026#39;); exports.DialogBot = class DialogBot extends ActivityHandler { /** * Creates a bot instance. * * @param {ConversationState} conversationState * @param {UserState} userState * @param {Dialog} dialog to be shown as a root dialog */ constructor(conversationState, userState, dialog) { super(); if (!conversationState) throw new Error( \u0026#39;[DialogBot]: Missing parameter. conversationState is required\u0026#39;); if (!userState) throw new Error( \u0026#39;[DialogBot]: Missing parameter. userState is required\u0026#39;); if (!dialog) throw new Error( \u0026#39;[DialogBot]: Missing parameter. dialog is required\u0026#39;); this.convState = conversationState; this.userState = userState; this.dialog = dialog; this.dialogSet = new DialogSet(this.convState.createProperty(\u0026#39;DialogState\u0026#39;)); this.dialogSet.add(this.dialog); this.onMessage(async (context, next) =\u0026gt; { // Run the Dialog with the new message Activity. const dc = await this.dialogSet.createContext(context); const ret = await dc.continueDialog(); switch (ret.status) { case DialogTurnStatus.empty: // アクティブなダイアログがない場合は、ダイアログを開始 await dc.beginDialog(this.dialog.id); break; case DialogTurnStatus.complete: // ダイアログが完了したら、結果をここで表示してみる // （通常はダイアログの処理の中で結果を使ってしまえばよい） console.debug(ret.result); // TODO: Remove this in release build await context.sendActivity(JSON.stringify(ret.result, null, 2)); break; } // By calling next() you ensure that the next BotHandler is run. await next(); }); this.onDialog(async (context, next) =\u0026gt; { // Save any state changes. // The load happened during the execution of the Dialog. await this.convState.saveChanges(context, false); await this.userState.saveChanges(context, false); // By calling next() you ensure that the next BotHandler is run. await next(); }); } }; この DialogBot クラスは、任意の Dialog を起動するための汎用的なクラスとして使用することができます。 やっていることはとてもシンプルで、onMessage ハンドラの中で、DialogContext#beginDialog() や DialogContext#continueDialog() を呼び出して、対象のダイアログのステップを順番に進めているだけです。 DialogContext#continueDialog() は、ダイアログの進捗具合 (status) や WaterfallDialog の各ステップの結果 (result) を含む DialogTurnResult オブジェクトを返します。 WaterfallDialog のすべてのステップが完了すると（endDialog() が呼び出されると）、status プロパティは completed となり、ダイアログ側から endDialog() で渡された最終結果を result プロパティで参照することができます（DialogTurnResult の中に result プロパティがあるのでちょっとネーミングが気持ち悪い）。 ダイアログ側で収集したユーザー情報は、ダイアログ側の実装で使ってしまえばよいのですが、UserProfileDialog の動作を確認するために、上記のボットクラスではコンソールおよびユーザーへの返答として表示するようにしています。 おまけ: WaterfallDialog の各ステップの登録方法いろいろ WaterfallDialog の API ドキュメント にも書いてありますが、各ステップのコールバック関数は、コンストラクタの第 2 引数の配列でまとめて渡す以外にも、次のような設定方法があります。 クロージャーとして 1 つずつ追加する方法 const dialog = new WaterfallDialog(\u0026#39;myDialog\u0026#39;); dialog.addStep(async (step) =\u0026gt; { await step.context.sendActivity(`Hello World!`); return await step.endDialog(); }); 通常の関数を追加する方法（メソッドじゃない関数） async function stepFunc1(step) { await step.context.sendActivity(`Hello World!`); return await step.endDialog(); } dialog.addStep(stepFunc1); 各ステップをメソッド化して this に bind して追加する方法 const dialog = new WaterfallDialog(\u0026#39;myDialog\u0026#39;); dialog.addStep(this.stepFunc1.bind(this)); dialog.addStep(this.stepFunc2.bind(this)); dialog.addStep(this.stepFunc3.bind(this)); 各ステップをメソッド化してまとめて追加 class RootDialog extends ComponentDialog { constructor() { super(\u0026#39;RootDialog\u0026#39;); // Add control flow dialogs this.addDialog(new WaterfallDialog(\u0026#39;start\u0026#39;, [ this._nameStep.bind(this), this._lastStep.bind(this) ])) // Add prompts this.addDialog(new TextPrompt(\u0026#39;namePrompt\u0026#39;)); } async _nameStep(step) { const options = { prompt: \u0026#39;名前を教えてください。\u0026#39; }; return await step.prompt(\u0026#39;namePrompt\u0026#39;, options); } async _lastStep(step) { step.values[\u0026#39;name\u0026#39;] = step.result; await step.context.sendActivity(`こんにちは、${step.values[\u0026#39;name\u0026#39;]}さん！`); await step.context.sendActivity(\u0026#39;また来てね！\u0026#39;); return await step.endDialog(step.values); } } こんな感じでメソッドで追加する方法がオススメかなぁ。 ダイアログはクラス化して実装したいので。"
},
{
url: "/p/6arjar6/",
title: "チャットボット: Bot Builder SDK の Dialog で会話の流れをデザインする (2) スタック管理",
date: "2019-07-19T00:00:00Z",
body: "チャットボット: Bot Builder SDK の Dialog で会話の流れをデザインする (2) スタック管理 ダイアログの基本 で説明したように、Dialog クラスを使用した会話フローでは、ユーザーからメッセージを受け取るたびに DialogContext#continueDialog() を呼び出すことで、1 ステップずつ処理を進めていきます。 ダイアログには、スタック構造で会話を管理する仕組みがあり、次のようなメソッドを使って、ダイアログの起動（スタックに積む）、ダイアログの終了（スタックから降ろす）という操作を行うことが可能です。 DialogContext#beginDialog(\u0026quot;ID\u0026quot;) \u0026hellip; ダイアログを開始する（スタックに積む） DialogContext#endDialog() \u0026hellip; アクティブなダイアログを終了する（スタックから降ろす） DialogContext#replaceDialog(\u0026quot;ID\u0026quot;) \u0026hellip; アクティブなダイアログを別のダイアログに置き換える（スタックの一番上を入れ替え） DialogContext#cancelAllDialog() \u0026hellip; すべてのダイアログを終了する（スタックをクリア） ここでは、RootDialog と GreetDialog という名前の 2 つのダイアログクラス作成し、RootDialog から GreetDialog を起動してダイアログのスタックを積むような実装を行ってみます。 図: ダイアログ遷移のイメージ 下記は、実際のチャットクライアントの表示例です。 右側のバーで示すように、 最初に RootDialog による選択肢が表示され、次に GreetDialog の処理に遷移し、最後に RootDialog に戻ってくるという流れです。 図: チャットのイメージ 下記は、最初に起動される RootDialog クラスの実装です。 前回の説明 で使用した DialogBot クラスを使って RootDialog を起動することを想定しています。 ウォーターフォールダイアログの最初のステップ (_step1) として、ユーザーに選択肢を提示し、「挨拶する」を選んだ場合に、GreetDialog を新たに起動するようにしています。 dialogs/rootDialog.js const { ChoiceFactory, ChoicePrompt, ComponentDialog, ListStyle, WaterfallDialog, } = require(\u0026#39;botbuilder-dialogs\u0026#39;); const { GreetDialog } = require(\u0026#39;./greetDialog.js\u0026#39;); /** * 会話のエントリポイントとなるルートダイアログ。 */ exports.RootDialog = class RootDialog extends ComponentDialog { constructor() { super(\u0026#39;RootDialog\u0026#39;); // Create dialog instances this.greetDialog = new GreetDialog(); this.choicePrompt = new ChoicePrompt(\u0026#39;choicePrompt\u0026#39;); this.choicePrompt.style = ListStyle.heroCard; // Add control flow dialogs and prompts this.addDialog(new WaterfallDialog(\u0026#39;start\u0026#39;, [ this._step1.bind(this), this._step2.bind(this), this._step3.bind(this) ])); this.addDialog(this.greetDialog); this.addDialog(this.choicePrompt); } async _step1(step) { return await step.prompt(this.choicePrompt.id, { prompt: \u0026#39;やりたいことを選んでね。\u0026#39;, choices: ChoiceFactory.toChoices([\u0026#39;挨拶する\u0026#39;, \u0026#39;バイバイ\u0026#39;]) }); } async _step2(step) { const text = step.result.value; const ctx = step.context; if (text.match(/挨拶/)) { return await step.beginDialog(this.greetDialog.id); } else { await ctx.sendActivity(\u0026#39;さようなら\u0026#39;); return await step.endDialog(); } } async _step3(step) { const ctx = step.context; await ctx.sendActivity(\u0026#39;また来てね\u0026#39;); return await step.endDialog(); } }; 下記は、RootDialog から起動される（スタックに積まれる） GreetDialog の実装です。 ユーザーに名前の入力を促し、ユーザーに対して挨拶をしたらダイアログを終了します。 dialogs/greetDialog.js const { ComponentDialog, TextPrompt, WaterfallDialog, } = require(\u0026#39;botbuilder-dialogs\u0026#39;); /** * 挨拶を行うダイアログ。 */ exports.GreetDialog = class GreetDialog extends ComponentDialog { constructor() { super(\u0026#39;GreetDialog\u0026#39;); // Create dialog instances this.namePrompt = new TextPrompt(\u0026#39;namePrompt\u0026#39;); // Add control flow dialogs and prompts this.addDialog(new WaterfallDialog(\u0026#39;start\u0026#39;, [ this._nameStep.bind(this), this._lastStep.bind(this) ])); this.addDialog(this.namePrompt); } async _nameStep(step) { return await step.prompt(this.namePrompt.id, \u0026#39;あなたの名前は？\u0026#39;); } async _lastStep(step) { const text = step.result; const ctx = step.context; await ctx.sendActivity(`こんにちは、${text}さん`); return await step.endDialog(); } }; 2 つのダイアログクラスは、自分が担当する会話のトピックのみに集中して実装できているところがポイントです。 このようなダイアログクラスを作成し、組み合わせていくことで、柔軟な会話を表現できるようになっていきます。"
},
{
url: "/p/q7vw95i/",
title: "チャットボット: Bot Builder SDK で画像やリストなどのリッチなメッセージを送る (MessageFactory)",
date: "2019-07-04T00:00:00Z",
body: "チャットボット: Bot Builder SDK で画像やリストなどのリッチなメッセージを送る (MessageFactory) Activity オブジェクトと MessageFactory Bot Builder SDK によるボット実装において、ユーザーにメッセージを送るには TurnContext クラス の sendActivity() メソッドを使用します。 下記は、単純なテキストメッセージを送る例です。 await context.sendActivity(\u0026#39;Hello!\u0026#39;); sendActivity() の第一引数には、このように文字列を渡すことができますが、その名の通り Activity オブジェクトを渡すこともできるようになっています。 Activity オブジェクトを使うと、単純なテキストよりもリッチな形式で表示を行うことができます（どう表示されるかは各チャンネルの実装によりますが）。 Activity インタフェースは botframework-schema モジュール で定義されていますが、このインタフェースを意識してオブジェクトを作成することはあまりありません。 というのも、いろいろな用途の Activity オブジェクトを生成するためのファクトリーである MessageFactory クラス が用意されているからです。 例えば、MessageFactory#text() は単純なテキストメッセージを送るための Activity オブジェクトを生成します。 // const { MessageFactory } = require(\u0026#39;botbuilder\u0026#39;); const msg = MessageFactory.text(\u0026#39;Hello!\u0026#39;); await context.sendActivity(msg); これは実は下記のようにするのと同じです。 await context.sendActivity(\u0026#39;Hello!\u0026#39;); TurnContext#sendActivity() に直接文字列を渡した場合は、内部で前者のような MessageFactory.text() による Activity 生成が行われています。 単純なテキストを送るだけであれば、sendActivity('Hello') としてしまうのが早いでしょう。 MessageFactory でリッチなメッセージを作成する MessageFactory が提供するファクトリメソッドを使って、リッチなメッセージを送る例をいくつか紹介します。 ここでは、Bot Framework Emulator の表示例を載せておきます。 画像・動画を表示する \u0026ndash; contentUrl() const msg = MessageFactory.contentUrl( \u0026#39;https://maku.blog/assets/img/site-logo.png\u0026#39;, // 画像や動画のURL \u0026#39;image/png\u0026#39;, // 画像や動画のMIMEタイプ \u0026#39;タイトル\u0026#39;, // タイトル（画像が見つからないときの代替テキスト） \u0026#39;説明文\u0026#39; // 説明文（オプション） ); await context.sendActivity(msg); 上記の例では png 画像を表示していますが、mp4 などの動画を指定することもできます。 Youtube のアドレスをそのまま記述してもいいみたいです。 const msg = MessageFactory.contentUrl( \u0026#39;https://youtu.be/Tu_c1PfJ0nE\u0026#39;, \u0026#39;video/mp4\u0026#39;, \u0026#39;上野さんは不器用\u0026#39; ); await context.sendActivity(msg); Bot Framework Emulator では埋め込みで動画再生できましたが、Slack ではテキストリンクになりました（上記の例では“上野さんは不器用”というテキスト）。 選択肢を表示する \u0026ndash; suggestedActions() const msg = MessageFactory.suggestedActions( [\u0026#39;Red\u0026#39;, \u0026#39;Blue\u0026#39;, \u0026#39;Yellow\u0026#39;], \u0026#39;好きな色を選んでください\u0026#39; ); await context.sendActivity(msg); 選択肢のボタンをクリック（あるいはタップ）すると、ユーザーがその文字列をタイプしたのと同様にメッセージが送られます。 ボットが想定する入力が限定されているシーンでは、このように選択肢を表示してあげるのがよいです。"
},
{
url: "/p/fn3amda/",
title: "チャットボット: 独自のミドルウェアを作成してログを記録する",
date: "2019-07-23T00:00:00Z",
body: "チャットボット: 独自のミドルウェアを作成してログを記録する ミドルウェアとは Bot Framework において、クライアントから受信したメッセージはアダプターを介してボットに届けられますが、アダプターにミドルウェアを設定しておくことで、メッセージがボットに届く前に割り込んで処理を行うことができます。 Adapter → Middleware1 → Middleware2 → Middleware3 → ... → YourBot ミドルウェアは上記のように複数登録することができ、登録された順に呼び出されていきます。 アダプターにミドルウェアを追加するには、BotFrameworkAdapter#use() メソッドを使用します。 ミドルウェアの追加 const { BotFrameworkAdapter } = require(\u0026#39;botbuilder\u0026#39;); const adpater = new BotFrameworkAdapter(endpoint); adapter.use(new Middleware1()); adapter.use(new Middleware2()); adapter.use(new Middleware3()); ミドルウェアを実装する 独自のミドルウェアを作成するには、Middleware インタフェース が提供する onTurn メソッドを実装します。 ここでは、ユーザーの入力をコンソールに出力するだけの ConsoleLogger というミドルウェアクラスを実装してみます。 middlewares/consoleLogger.js exports.ConsoleLogger = class ConsoleLogger { async onTurn(context, next) { if (context.activity.type === \u0026#34;message\u0026#34;) { console.log(context.activity.text); } await next(); // Invoke a next middleware } }; とても簡単ですね。 あと、onTurn() を抜ける前に忘れずに next() を呼び出して、後続のミドルウェアが正しく呼び出されるようにしておく必要があります。 このミドルウェアをアダプターに登録するには次のようにします。 // const { ConsoleLogger } = require(\u0026#39;./middlewares/consoleLogger.js\u0026#39;); const adapter = new BotFrameworkAdapter(botEndpoint); adapter.use(new ConsoleLogger()); これで、ユーザーがチャットクライアント（チャンネル）から こんにちは と入力すると、ボットサーバー側のコンソールに こんにちは と出力されるようになります。 ちなみに、上記のミドルウェアを TypeScript で実装すると下記のような感じになります。 ./middlewares/consoleLogger.ts import { Middleware, TurnContext } from \u0026#34;botbuilder\u0026#34;; export class ConsoleLogger implements Middleware { public async onTurn(context: TurnContext, next: () =\u0026gt; Promise\u0026lt;void\u0026gt;) { if (context.activity.type === \u0026#39;message\u0026#39;) { console.log(context.activity.text); } await next(); } } BotBuilder SDK 組み込まれているロギング用ミドルウェアを使用する TranscriptLoggerMiddleware を使う BotBuilder SDK の botbuilder モジュールには、組み込みのロギング用ミドルウェアとして TranscriptLoggerMiddleware が含まれています。 TranscriptLogger interface | Microsoft Docs botbuilder-js/transcriptLogger.ts このミドルウェアをアダプターに登録するには次のようにします。 const { ConsoleTranscriptLogger, TranscriptLoggerMiddleware } = require(\u0026#39;botbuilder\u0026#39;); adapter.use(new TranscriptLoggerMiddleware(new ConsoleTranscriptLogger())); ここでは、出力先をコンソールにするために、パラメータとして ConsoleTranscriptLogger オブジェクトを渡しています。 このようにミドルウェアを登録してからボットにアクセスすると、次のようなログがコンソールに出力されるようになります（Bot Framework Emulator から「こんにちは」と入力した場合の例です）。 Activity Log: { text: \u0026#39;こんにちは\u0026#39;, textFormat: \u0026#39;plain\u0026#39;, type: \u0026#39;message\u0026#39;, channelData: { clientActivityID: \u0026#39;15638683487740.6rm1ga5nebo\u0026#39; }, channelId: \u0026#39;emulator\u0026#39;, from: { id: \u0026#39;a586cec4-adad-4c63-b4ce-db0c15cdb093\u0026#39;, name: \u0026#39;User\u0026#39;, role: \u0026#39;user\u0026#39; }, locale: \u0026#39;\u0026#39;, timestamp: 2019-07-23T07:52:28.783Z, conversation: { id: \u0026#39;31bef070-ad1b-11e9-8f89-2777303f4e30|livechat\u0026#39; }, id: \u0026#39;d18d3ff0-ad1e-11e9-9bd2-c9d526d6b73b\u0026#39;, localTimestamp: 2019-07-23T07:52:28.000Z, recipient: { id: \u0026#39;3\u0026#39;, name: \u0026#39;Bot\u0026#39;, role: \u0026#39;bot\u0026#39; }, serviceUrl: \u0026#39;http://localhost:51706\u0026#39; } ユーザーがチャンネルに送信したメッセージ（アクティビティ）と、ボットがチャンネルに送信したメッセージ（アクティビティ）は別々のログとして出力されることに注意してください。 Bot Framework において、「アクティビティ」はあくまで片道のメッセージを表す単位です。 独自の TranscriptLogger 実装 ちなみに、上記のサンプルコードで使用している ConsoleTranscriptLogger() の実装は下記のようになっています (transcriptLogger.ts (L.162))。 transcriptLogger.ts（抜粋） /** * ConsoleTranscriptLogger , writes activities to Console output. */ export class ConsoleTranscriptLogger implements TranscriptLogger { /** * Log an activity to the transcript. * @param activity Activity being logged. */ public logActivity(activity: Activity): void | Promise\u0026lt;void\u0026gt; { if (!activity) { throw new Error(\u0026#39;Activity is required.\u0026#39;); } // tslint:disable-next-line:no-console console.log(\u0026#39;Activity Log:\u0026#39;, activity); } } logActivity() メソッドを持つクラスを作ればよいだけなので、下記のように簡単に独自の TranscriptLogger を実装できます。 ここでは、コンソールにログを出力していますが、必要に応じて Azure Storage や CosmosDB などに出力するとよいでしょう。 class MyLogger { logActivity(activity) { if (!activity) { throw new Error(\u0026#39;Activity is required.\u0026#39;); } console.log(\u0026#39;Activity Log: \u0026#39;, JSON.stringify(activity, null, 2)); } } // こうやって使う adapter.use(new TranscriptLoggerMiddleware(new MyLogger())); この MyLogger は ConsoletranscriptLogger とほぼ同様の内容ですが、Activity オブジェクトの内容を JSON.stringify() を使って全階層出力するようにしています。 応用: ミドルウェア側でセットした値をボット側で参照する ミドルウェアの実装（onTurn() 内）で、TurnContext#turnState.set() を使って何らかの値をセットしておくと、後続のボット本体の実装の中で、TurnContext#turnState.get() でその値を参照できるようになります。 ミドルウェアの実装 class MyMiddleware { async onTurn(context, next) { context.turnState.set(\u0026#39;testKey\u0026#39;, \u0026#39;testValue\u0026#39;); await next(); } }; ボット本体の実装 class MyBot extends ActivityHandler { constructor() { super(); this.onMessage(async (context, next) =\u0026gt; { const value = context.turnState.get(\u0026#39;testKey\u0026#39;); console.log(value); //=\u0026gt; \u0026#39;testValue\u0026#39; // ... } }"
},
{
url: "/p/gt9g2na/",
title: "チャットボット: 独自のミドルウェアを作成して禁止ワードを拒否するようにする",
date: "2019-07-23T00:00:00Z",
body: "チャットボット: 独自のミドルウェアを作成して禁止ワードを拒否するようにする 前回の記事 では、チャットボットに独自のミドルウェアを追加して、ユーザー入力をログ出力できるようにしました。 今回は、ユーザーが NG ワードを入力したときに、警告を表示して処理を中断するようなミドルウェアを作成してみます。 その名も NgWordMiddleware です！ middlewares/NgWordMiddleware.js const NG_WORDS = /アホ|まぬけ|バカ/; exports.NgWordMiddleware = class NgWordMiddleware { async onTurn(context, next) { if (context.activity.type === \u0026#39;message\u0026#39;) { const line = context.activity.text; if (NG_WORDS.test(line)) { await context.sendActivity(\u0026#39;そんなこと言っちゃダメ\u0026#39;); return; } } await next(); // Invoke a next middleware } }; 上記の例では、NG_WORDS 定数に、禁止語句を正規表現の形で登録しています。 ユーザーが入力したテキストに、禁止語句が含まれていたら、「そんなこと言っちゃダメ」と返事して処理を進めないようにします（next() を呼び出さないことで後続の処理を打ち切る）。 このミドルウェアは、下記のようにアダプターに追加することで有効化できます。 // const { NgWordMiddleware } = require(\u0026#39;./middlewares/ngWordMiddleware.js\u0026#39;); const adapter = new BotFrameworkAdapter(botEndpoint); adapter.use(new NgWordMiddleware()); この例では、単純に禁止語句が含まれているかだけをチェックしているので、「バカルディ」と入力した場合にも弾かれてしまいます。 このあたりは工夫して処理しなきゃですね。"
},
{
url: "/p/i5ht5fq/",
title: "Next.js のコンポーネントとレイアウト",
date: "2021-08-10T00:00:00Z",
body: "Next.js のコンポーネントとレイアウト"
},
{
url: "/p/ugt6gr4/",
title: "AWS CloudFormation で S3 バケットのリソースを作成する",
date: "2021-04-09T00:00:00Z",
body: "AWS CloudFormation で S3 バケットのリソースを作成する S3 バケット定義の基本 AWS CloudFormation で S3 バケットを作成・設定するには、次のようにテンプレートファイル内で AWS::S3::Bucket タイプのリソースを定義します。 template.yml AWSTemplateFormatVersion:\u0026#39;2010-09-09\u0026#39;Resources:MyBucket:Type:AWS::S3::Bucket 上記の例では、論理 ID (Logical ID) が MyBucket の S3 バケットを定義しています。 論理 ID はこのテンプレートで生成するスタック内で一意の ID です。 実際に生成される S3 バケット名（物理 ID）は CloudFormation が自動で生成します（後述）。 このテンプレートを使って、CloudFormation スタック（ここでは S3 バケットのみ含まれる）を生成するには、次のように aws cloudformation deploy コマンドを実行します。 mystack スタックを生成 $ aws cloudformation deploy --template-file template.yml --stack-name mystack スタック内に生成された AWS リソースの一覧は次のように確認できます。 $ aws cloudformation describe-stack-resources --stack-name mystack StackResources: - DriftInformation: StackResourceDriftStatus: NOT_CHECKED LogicalResourceId: MyBucket PhysicalResourceId: mystack-mybucket-bq8iux8uepew ResourceStatus: CREATE_COMPLETE ResourceType: AWS::S3::Bucket StackId: arn:aws:cloudformation:ap-northeast-1:123456789012:stack/mystack/c7e06a46-9902-11eb-9a29-8b1f770a16f7 StackName: mystack Timestamp: \u0026#39;2021-04-09T07:09:13.622000+00:00\u0026#39; PhysicalResourceId のところを見ると、実際に作成された S3 バケットの物理 ID (Physical ID) が分かります。 PhysicalResourceId:mystack-mybucket-bq8iux8uepew S3 バケット名（物理 ID）は、このように、スタック名とテンプレートで指定した論理 ID (Logical ID) をもとに自動生成されます。 もちろん、バケット名を自分で指定することもできます（後述）。 他のスタック内の AWS リソースからこの S3 バケットを参照するときは、この物理 ID（および ARN）を使用することになります。 S3 バケットリソースの各種設定 CloudFormation テンプレート内で S3 バケットリソース (AWS::S3::Bucket) を定義するときに、様々なプロパティを設定することができます。 これらのプロパティはすべてオプショナルです。 BucketName（バケット名を明示する） バケット名の生成を CloudFormation に任せるのではなく、BucketName プロパティで明示的に指定することが可能です。 Resources:MyBucket:Type:AWS::S3::BucketProperties:BucketName:bucket-123456789012-myapp-log-march-2020 バケット名に使える名前は制約が多く、すべて小文字で、世界中でユニークになるように命名する必要があるので注意してください。 一般的には、上の例のように、単語をハイフン区切りで繋げた名前を付けます。 アカウント ID を含めると、名前の衝突を避けやすくなります。 参考: バケットの名前付け - Amazon Simple Storage Service CloudFormation の Sub 関数 と、AWS::AccountID 擬似パラメータ を使用すると、アカウント ID のハードコーディングを避けることができます。 BucketName:!Sub \u0026#39;bucket-${AWS::AccountId}-myapp-log-march-2020\u0026#39; DeletionPolicy（スタック削除時に S3 バケットを消さない） CloudFormation スタックを削除すると、デフォルトではそのスタック内の S3 バケットも同時に削除されます。 プロダクション環境では、S3 バケット内のデータが簡単に削除されてしまっては困るので、次のように DeletionPolicy を設定して、スタック削除時に S3 バケットが削除されないようにします。 Resources:MyBucket:Type:AWS::S3::BucketDeletionPolicy:Retain DeletionPolicy は、リソース共通の設定項目なので、論理 ID (Logical ID) のすぐ下の階層で定義することに注意してください（Properties の下ではありません）。 この状態で CloudFormation スタックを削除すると、S3 バケットはスタックから独立したリソースとして残ります。 Tags（タグを設定する） S3 バケットにタグを割り当てるときは、Tags プロパティで指定します。 Resources:MyBucket:Type:AWS::S3::BucketProperties:Tags:- Key:DepartmentValue:Marketing- Key:CostCenterValue:1234ABCDE 何か書き方が煩わしいです。SAM のように キー: 値 という形で指定したいですね。。。 参考情報 参考リンク AWS::S3::Bucket - AWS CloudFormation S3 バケット定義時に指定できるプロパティの一覧があります。"
},
{
url: "/p/e2dpycn/",
title: "React コンポーネントのプロパティでハンドラメソッドを渡す",
date: "2020-07-18T00:00:00Z",
body: "React コンポーネントのプロパティでハンドラメソッドを渡す ここでは、次のようにプロパティ（属性）でハンドラメソッドを設定可能な React コンポーネントの実装例を示します。 \u0026lt;MyButton onClick={handleClick} /\u0026gt; ハンドラメソッドを設定可能なコンポーネントを実装する 次の MyButton コンポーネントは、ボタンクリック時に呼び出されるイベントハンドラを、onClick プロパティで設定できるようにしています。 この MyButton コンポーネントは、クリックするたびに内部のカウンタ (state.count) を +1 し、その値を指定されたイベントハンドラへ通知します。 components/myButton.tsx import * as React from \u0026#39;react\u0026#39;; // MyButton のプロパティ（属性）の型 export interface MyButtonProps { onClick?: (count: number) =\u0026gt; void; } // MyButton の状態（ステート）の型 interface MyButtonState { count: number; } // MyButton コンポーネント export class MyButton extends React.Component\u0026lt;MyButtonProps, MyButtonState\u0026gt; { constructor(props: MyButtonProps) { super(props); this.state = {count: 0}; } public render(): React.ReactNode { const {count} = this.state; return \u0026lt;div\u0026gt; \u0026lt;button onClick={this.handleClick}\u0026gt;MyButton {count}\u0026lt;/button\u0026gt; \u0026lt;/div\u0026gt;; } private handleClick = () =\u0026gt; { // カウンタを +1 して再描画 const newCount = this.state.count + 1; this.setState({count: newCount}); // onClick 属性でハンドラが指定されていたら呼び出す this.props.onClick?.(newCount); } } MyButton のプロパティの型を定義しているのは次の部分です。 onClick? とプロパティ名の末尾に ? を付けることで、属性の指定をオプショナルにしています。 export interface MyButtonProps { onClick?: (count: number) =\u0026gt; void; } 属性として設定されたハンドラメソッドは、コンポーネント内の handleClick() メソッドの中で呼び出しています。 private handleClick = () =\u0026gt; { // カウンタを +1 して再描画 const newCount = this.state.count + 1; this.setState({count: newCount}); // onClick 属性でハンドラが指定されていたら呼び出す this.props.onClick?.(newCount); } ハンドラメソッドの指定はオプショナルなので、演算子 ?. を使って、ハンドラメソッドが指定されている場合のみ呼び出しています。 MyButton の使用例 下記は、上記で作成した MyButton の使用例です。 ボタンをクリックすると、onClick 属性で指定したハンドラメソッドが呼び出されます。 index.tsx import * as React from \u0026#39;react\u0026#39;; import * as ReactDOM from \u0026#39;react-dom\u0026#39;; import {MyButton} from \u0026#39;./components/myButton\u0026#39;; const handleClick = (count: number) =\u0026gt; { alert(`新しい値は ${count}です`); }; ReactDOM.render( \u0026lt;MyButton onClick={handleClick} /\u0026gt;, document.getElementById(\u0026#39;root\u0026#39;) );"
},
{
url: "/p/av9mxak/",
title: "React コンポーネントのプロパティで配列データを渡す",
date: "2020-07-09T00:00:00Z",
body: "React コンポーネントのプロパティで配列データを渡す React コンポーネントのプロパティには、文字列や数値などの単純なスカラ値だけではなく、配列などの複雑なオブジェクトを渡すことができます。 使用イメージは次のような感じです。 \u0026lt;MyComponent values={配列変数} /\u0026gt; 配列型のプロパティを扱うコンポーネントを作成する 次の Books コンポーネントは、プロパティ titles で文字列配列を受け取り、それぞれの値を li 要素で描画します。 配列の map メソッドを使用すると、複数の li 要素を簡単に生成することができます。 components/books.tsx（Books コンポーネント） import * as React from \u0026#39;react\u0026#39;; // Books コンポーネントのプロパティの型 export interface BooksProps { titles: string[] } // Books コンポーネントの定義 export const Books: React.FC\u0026lt;BooksProps\u0026gt; = (props) =\u0026gt; { // titles プロパティの要素数が 0 であれば何も描画しない if (props.titles.length == 0) return null; // titles プロパティの値を使って、複数の li 要素を作る const listItems = props.titles.map((title: string) =\u0026gt; \u0026lt;li\u0026gt;{title}\u0026lt;/li\u0026gt; ); // ul 要素の描画 return \u0026lt;ul\u0026gt;{listItems}\u0026lt;/ul\u0026gt;; }; この Books コンポーネントは次のような感じで使用します。 index.tsx（使用例） import * as React from \u0026#39;react\u0026#39;; import * as ReactDOM from \u0026#39;react-dom\u0026#39;; import { Books } from \u0026#39;./components/books\u0026#39;; const titles = [\u0026#39;タイトル1\u0026#39;, \u0026#39;タイトル2\u0026#39;, \u0026#39;タイトル3\u0026#39;]; ReactDOM.render( \u0026lt;Books titles={titles} /\u0026gt;, document.getElementById(\u0026#39;root\u0026#39;) ); これで、次のような HTML 要素が生成されます。 \u0026lt;ul\u0026gt; \u0026lt;li\u0026gt;タイトル1\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;タイトル2\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;タイトル3\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; リスト要素に key を与える 上記のコードを実行すると、React は次のような警告を出力します。 Warning: Each child in a list should have a unique \u0026#34;key\u0026#34; prop. React は 配列要素の再描画処理を効率的に行うため、要素を特定するための key プロパティ（数値 or 文字列）を要求します。 配列の map メソッドで複数の要素を生成するとき に、それぞれの要素の key プロパティとして何らかのユニーク値を設定してやれば、この警告は消えます。 これは li 要素以外の要素（例えば div 要素）であっても同様です。 const listItems = props.titles.map((title: string, index: number) =\u0026gt; \u0026lt;li key={index}\u0026gt;{title}\u0026lt;/li\u0026gt; ); key プロパティの値は、同階層のリスト要素間で一意であればよいので、上記のようにリスト要素のインデックスを key に指定することである程度うまく動作します。 ただし、この方法ではリスト要素の順番が入れ替わった場合などに効率の悪い再描画が発生します。 よりよい方法は、次のように、表示するデータが持っている一意な ID やハッシュ値を指定することです。 const listItems = books.map((book: Book) =\u0026gt; \u0026lt;li key={book.id}\u0026gt;{book.title}\u0026lt;/li\u0026gt; ); このような書き方を可能にするには、元の Books コンポーネントのプロパティで、データオブジェクト (Book) の配列を受け取れるように修正する必要があります。 下記に修正後の全体のコードを示します。 components/books.tsx import * as React from \u0026#39;react\u0026#39;; // Books コンポーネントの items 配列プロパティの要素の型 export interface Book { id: number; title: string; } // Books コンポーネントのプロパティ export interface BooksProps { items: Book[] } // Books コンポーネント export const Books: React.FC\u0026lt;BooksProps\u0026gt; = (props) =\u0026gt; { if (props.items.length == 0) return null; const listItems = props.items.map((book: Book) =\u0026gt; \u0026lt;li key={book.id}\u0026gt;{book.title}\u0026lt;/li\u0026gt; ); return \u0026lt;ul\u0026gt;{listItems}\u0026lt;/ul\u0026gt;; }; index.tsx（使用例） import * as React from \u0026#39;react\u0026#39;; import * as ReactDOM from \u0026#39;react-dom\u0026#39;; import { Book, Books } from \u0026#39;./components/books\u0026#39;; const books: Book[] = [ { id: 100, title: \u0026#39;タイトル1\u0026#39; }, { id: 200, title: \u0026#39;タイトル2\u0026#39; }, { id: 300, title: \u0026#39;タイトル3\u0026#39; }, ]; ReactDOM.render( \u0026lt;Books items={books} /\u0026gt;, document.getElementById(\u0026#39;root\u0026#39;) ); （おまけ）コンポーネント内で自主的にデータを取得する 下記の Books コンポーネントは、DOM 要素として追加された段階 (componentDidMount) で、自分が表示すべきデータを取得して描画を行います。 コンポーネントのライフサイクルメソッドをオーバーライドするため、関数コンポーネントではなく、クラスコンポーネントとして定義する必要があります。 ここでは固定のデータを state に設定していますが、ネットワークからデータ取得するようなケースでも、このタイミングでデータ取得するとよいでしょう。 components/books.tsx import * as React from \u0026#39;react\u0026#39;; interface Book { id: number; title: string; } // Books コンポーネントの state の型 interface BooksState { books: Book[] } // Books コンポーネントの定義 export class Books extends React.Component\u0026lt;{}, BooksState\u0026gt; { constructor(props: {}) { super(props); // 初期状態のデータは空っぽでOK this.state = { books: [] }; } public render(): React.ReactNode | null { const books = this.state.books; if (books.length == 0) return null; const listItems = books.map((b: Book) =\u0026gt; \u0026lt;li key={b.id}\u0026gt;{b.title}\u0026lt;/li\u0026gt; ); return \u0026lt;ul\u0026gt;{listItems}\u0026lt;/ul\u0026gt;; } // 描画準備ができたときに呼び出される public componentDidMount() { // 実際はここでデータフェッチを行う想定 const newBooks: Book[] = [ { id: 100, title: \u0026#39;タイトル1\u0026#39; }, { id: 200, title: \u0026#39;タイトル2\u0026#39; }, { id: 300, title: \u0026#39;タイトル3\u0026#39; }, ]; // データ取得が完了したら state を更新して再描画 this.setState({ books: newBooks }); } }; Books コンポーネントは自らデータを取得するため、Books コンポーネントを使用する側ではデータを渡す必要はありません。 index.tsx（使用例） import * as React from \u0026#39;react\u0026#39;; import * as ReactDOM from \u0026#39;react-dom\u0026#39;; import { Books } from \u0026#39;./components/books\u0026#39;; ReactDOM.render(\u0026lt;Books /\u0026gt;, document.getElementById(\u0026#39;root\u0026#39;));"
},
{
url: "/p/zn2er4g/",
title: "VS Code でビルドタスクやテストタスクを登録する (tasks.json)",
date: "2020-06-10T00:00:00Z",
body: "VS Code でビルドタスクやテストタスクを登録する (tasks.json) タスク設定とは VS Code のビルドタスク設定 (tasks.json) をしておくと、 Cmd + Shift + B (Ctrl + Shift + B) というショートカットキーで、任意のビルドタスクを実行できるようになります。 「ビルド」タスクと言っていますが、実際には任意のコマンドを実行することができます。 例えば、Node.js アプリを起動するための npm start や、シェル上でのコマンドを素早く実行できるようになります。 ここでは、下記のようなコマンドを実行するタスクを VS Code に登録してみます。 npm start コマンド（Node.js アプリの起動） echo コマンド（Hello World と表示するだけ） サンプルアプリの準備 npm start で起動するサンプルアプリとして、簡単な Node.js アプリを作成しておきます。 プロジェクト用のディレクトリと package.json を作成し、VS Code で開きます。 $ mkdir myapp $ cd myapp $ npm init -y # package.json の生成 $ code . # VS Code で開く VS Code にプロジェクトとして認識させるには、ファイルではなくディレクトリを開く必要があることに注意してください。 VS Code が開いたら、Cmd + N で新しくエディタを開き、次のような内容の main.js を保存します。 main.js console.log(\u0026#39;Hello World\u0026#39;); これで、サンプルアプリは完成です。 Ctrl + ` でターミナルパネルを開いて、次のように実行できるかテストしましょう。 $ node main 最後に、npm start でアプリ起動できるように、package.json に start スクリプトを登録しておきます。 package.json { \u0026#34;name\u0026#34;: \u0026#34;myapp\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;0.0.1\u0026#34;, \u0026#34;scripts\u0026#34;: { \u0026#34;start\u0026#34;: \u0026#34;node main\u0026#34; // start スクリプト } } これで、node main とする代わりに、npm start でアプリを起動できるようになります。 ビルドタスクの設定 VS Code で作成したコードを実行するときに、毎回ターミナルから node main とか npm start とか入力するのは面倒です。 VS Code のビルドタスクを設定すると、こういったコマンドを、Cmd + Shift + B というショートカット一発で起動できるようになります（Windows の場合は Ctrl + Shift + B）。 npm start をタスクとして登録する まずは、npm start コマンドを VS Code のビルドタスクとして実行できるようにしてみましょう。 VS Code 上でビルドを実行するために Cmd + Shift + B と入力すると、最初は次のように No build task to run found. Configure Build Task... といったメッセージが表示されるはずです。 これは、「ビルドタスクが何も登録されていない」というメッセージなので、そのまま Enter キーを押して、ビルドタスクの登録に進みます。 ☝️ ワンポイント Configure Build Task の項目が表示されない場合は、Cmd + Shift + P でコマンドパレットを開き、Tasks: Configure Default Build Task を選択します。 すると、デフォルトのビルドタスクとして何を登録するかを選択するメニューが表示されるので、npm start を選択します。 VS Code は、package.json のスクリプト設定を認識し、タスクとして登録するものの候補を表示してくれます。 これで、次のようなタスク設定ファイル (tasks.json) が自動生成されます（コメントを追加しています）。 .vscode/tasks.json { \u0026#34;version\u0026#34;: \u0026#34;2.0.0\u0026#34;, \u0026#34;tasks\u0026#34;: [ { \u0026#34;label\u0026#34;: \u0026#34;npm: start\u0026#34;, // コマンドパレットに表示される名前 \u0026#34;detail\u0026#34;: \u0026#34;node main\u0026#34;, // その下に表示される説明文 \u0026#34;type\u0026#34;: \u0026#34;npm\u0026#34;, // npm によるタスク実行 \u0026#34;script\u0026#34;: \u0026#34;start\u0026#34;, // 実行する npm スクリプト名 \u0026#34;group\u0026#34;: { \u0026#34;kind\u0026#34;: \u0026#34;build\u0026#34;, // ビルドタスクとして認識させる \u0026#34;isDefault\u0026#34;: true // Cmd + Shift + B で即実行 }, \u0026#34;problemMatcher\u0026#34;: [] } ] } このタスクは、デフォルトのビルドタスクとして登録されている (\u0026quot;isDefault\u0026quot;: true) ので、今後は Cmd + Shift + B と入力するだけで、npm start が実行されるようになります。 ターミナルパネルに main.js の実行結果が表示されるか確認しましょう。 任意のコマンド (echo) をタスクとして登録する 次に、別のビルドタスクとして、echo コマンドを実行するタスクを登録してみます。 tasks.json の tasks プロパティに、次のように Hello World という名前のタスクを追加します。 .vscode/tasks.json { \u0026#34;version\u0026#34;: \u0026#34;2.0.0\u0026#34;, \u0026#34;tasks\u0026#34;: [ { \u0026#34;label\u0026#34;: \u0026#34;npm: start\u0026#34;, \u0026#34;detail\u0026#34;: \u0026#34;node main\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;npm\u0026#34;, \u0026#34;script\u0026#34;: \u0026#34;start\u0026#34;, \u0026#34;group\u0026#34;: { \u0026#34;kind\u0026#34;: \u0026#34;build\u0026#34;, \u0026#34;isDefault\u0026#34;: true }, \u0026#34;problemMatcher\u0026#34;: [] }, { \u0026#34;label\u0026#34;: \u0026#34;Hello World\u0026#34;, \u0026#34;detail\u0026#34;: \u0026#34;Hello World と出力するだけです。\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;shell\u0026#34;, // シェルコマンドを実行する \u0026#34;command\u0026#34;: \u0026#34;echo\u0026#34;, // 実行するコマンド \u0026#34;args\u0026#34;: [ // コマンドへ渡す引数 \u0026#34;Hello World\u0026#34; ], \u0026#34;group\u0026#34;: \u0026#34;build\u0026#34;, // ビルドタスクとして認識させる \u0026#34;presentation\u0026#34;: { \u0026#34;reveal\u0026#34;: \u0026#34;always\u0026#34;, // Terminal パネルを必ず開く \u0026#34;clear\u0026#34;: true, // 実行前に Terminal をクリア \u0026#34;echo\u0026#34;: false // タスク名をエコー表示しない }, \u0026#34;problemMatcher\u0026#34;: [] } ] } type で shell と指定するところと、command で実行したいコマンド（ここでは echo）を指定するところがポイントですね。 上記の例では、さらに presentation.clear を true に設定することで、タスク実行のたびにターミナルをクリアするようにしています。 前回の実行結果を参照する必要がない場合は、この設定をしておくと出力がスッキリするのでおすすめです。 このビルドタスク (Hello World) は、デフォルトタスクとしては登録していないので、Cmd + Shift + B コマンドで起動することはできません。 Cmd + Shift + P でコマンドパレットを開き、Tasks: Run Build Task を選択すると、タスク一覧が表示されるので、その中から Hello World タスクを選ぶことで実行できます。 タスク名は定義した順に表示されるのではなく、最近実行したものが上に表示されるみたいですね。 テストタスクの設定 上記ではビルドタスク (kind: build) を登録しましたが、テストタスク (kind: test) としてタスクを登録することもできます。 タスクを種類ごとにグルーピングして管理できるということです。 サンプルのテストコマンドを用意する ここでは、package.json にテスト用スクリプト (test) を追加し、それを VS Code のテストタスクとして実行できるようにしてみます。 テストコマンドは、次のように単純に echo Test するだけです。 package.json { \u0026#34;name\u0026#34;: \u0026#34;myapp\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;0.0.1\u0026#34;, \u0026#34;scripts\u0026#34;: { \u0026#34;start\u0026#34;: \u0026#34;node main\u0026#34;, \u0026#34;test\u0026#34;: \u0026#34;echo Test\u0026#34; // テストを実行しているつもり } } package.json に登録されているスクリプトは、VS Code がうまいこと認識してくれるので、実はこの時点でタスクとして実行できるようになっています。 Cmd + Shift + P でコマンドパレットを開き、Tasks: Run Test Task を選択 テストタスクの一覧が表示されるので、npm: test を選択 package.json でのスクリプト名が test になっているだけで、VS Code はテストタスクとして認識してくれるんですね。 デフォルトのテストタスクとして登録する このままでも十分使えますが、ここでは VS Code にデフォルトのテストタスクとしてちゃんと登録してみます。 tasks.json にテストタスクを追加するには、次のようにします。 Cmd + Shift + P でコマンドパレットを開き、Tasks: Configure Default Test Task を選択 候補の中から npm: test を選択 これで、tasks.json にテストタスクが追加されます。 .vscode/tasks.json { \u0026#34;version\u0026#34;: \u0026#34;2.0.0\u0026#34;, \u0026#34;tasks\u0026#34;: [ // 省略 { \u0026#34;label\u0026#34;: \u0026#34;npm: test\u0026#34;, \u0026#34;detail\u0026#34;: \u0026#34;echo Test\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;npm\u0026#34;, \u0026#34;script\u0026#34;: \u0026#34;test\u0026#34;, \u0026#34;group\u0026#34;: { \u0026#34;kind\u0026#34;: \u0026#34;test\u0026#34;, \u0026#34;isDefault\u0026#34;: true }, \u0026#34;problemMatcher\u0026#34;: [] } ] } ビルドタスクの場合は group.kind が build になっていましたが、テストタスクの場合は test になっています。 npm test がデフォルトのテストタスクとして登録されたので、Cmd + Shift + P のコマンドパレットから Tasks: Run Test Task を選択するだけで npm test が実行されるようになります。 テストタスク実行用のショートカットキーを登録する もっと簡単にテストタスクを起動したいのであれば、テストタスクを起動するためのショートカットキーを登録しておくとよいでしょう（ビルドタスクには Cmd + Shift + B というショートカットキーがデフォルトで登録されていますが、テストタスクには登録されていません）。 ショートカットキーの設定画面は、 Cmd + K → Cmd + S で開くことができます。 ここでは、Tasks: Run Test Task のショートカットキーを Cmd + Shift + T に設定します。 ☝️ ワンポイント Cmd + Shift + T は、デフォルトでは View: Reopen Closed Editor に割り当てられていますが、テストタスクの方が頻繁に実行されるという想定で、ここでは Tasks: Run Test Task に割り当てちゃいました。"
},
{
url: "/p/s7wk5k3/",
title: "TypeScriptの型: 既存の JavaScript ライブラリに型情報を追加する（.d.ts ファイル）",
date: "2020-02-27T00:00:00Z",
body: "TypeScriptの型: 既存の JavaScript ライブラリに型情報を追加する（.d.ts ファイル） アンビエント宣言とは TypeScript の アンビエント宣言 (Ambient Declarations) を行うと、既存の JavaScript ライブラリに型情報を付加することができます。 この仕組みを利用すると、 サードパーティ製の JavaScript ライブラリ（npm パッケージ）や、自作の JavaScript ライブラリ（ただし TypeScript 化はしたくないもの）を TypeScript コードから使用する jQuery などのブラウザ上でロードされるライブラリを TypeScript コードから使用する といったことが可能になります。 ようするに、TypeScript トランスパイラに対して、このオブジェクトはこういう型のものとして外から提供されているので、型チェックエラーを出さないでね、と知らせることができます。 さらに、VisualStudio Code などのエディタを使用している場合は、アンビエント型宣言があることにより、エディタ上での補完入力ができるようになります。 アンビエント宣言 (declare) 参考: TypeScript - Declaration Reference どこか別の場所でロードされる予定の JavaScript モジュールに対して、自力で型情報を付けたい場合は declare キーワードを使用します。 例えば、jQuery はもともと JavaScript 用のライブラリなので、TypeScript 用の型情報は提供していませんが、次のように自力で型情報を付けることで、TypeScript コードから利用できるようになります（実際には、DefinitelyTyped プロジェクトが提供する @types/jquery を使用するのが簡単です）。 index.ts // $ という変数を参照できるようにする（実体は実行時に後付けで定義される予定） declare var $: any; // これで、$ という未定義の変数を参照してもエラーにならない $(\u0026#39;#id\u0026#39;).html(\u0026#39;Hello!\u0026#39;); この仕組みを使わずに、いきなり $ を参照してしまうと、そのような変数は定義されていないというエラーになってしまいます。 TypeScript トランスパイラは、declare によって付けられた型情報を正しいものと判断するため、この型情報は間違えないように指定する必要があります。 また、実行時にはそのオブジェクトの実体がどこかで生成されていなければいけません。 もっと明確な型付けを行うなら次のような感じで、クラスや関数などの型を定義していきます。 index.ts declare class jQuery { html(html: string): void; } declare function $(query: string): jQuery; $(\u0026#39;#id\u0026#39;).html(\u0026#39;Hello!\u0026#39;); 型宣言ファイル (.d.ts) プロジェクト全体でアンビエント宣言を共有したい場合は、次のような型宣言ファイル .d.ts をソースツリーのルートに配置します。 globals.d.ts declare var $: any; .d.ts という拡張子は、オブジェクトの実体ではなく、型情報のみが含まれていることを示しています。 このファイルは TypeScript ビルド時のみに参照されるものであり、.js ファイルの生成は行われません。 アンビエントモジュール (declare module) declare キーワードは、単一の変数や関数、クラスに型情報を与えるものですが、declare module 'モジュール名' のように使用すると、モジュール単位で型情報を付加することができます。 この仕組みを アンビエントモジュール (Ambient Modules) と呼びます。 これで型情報を定義しておくと、指定したモジュールをインポートしたときに、自動的に型情報が付加されるようになります。 参考: TypeScript - Ambient Modules 次の例では、foo モジュール用の型情報を定義しています。 globals.d.ts // foo モジュール用の型宣言 declare module \u0026#39;foo\u0026#39; { export val bar: number; } 次のように foo モジュールをインポートすると、bar 変数が export されているモジュールとして扱うことができます。 型情報のインポート import * as foo from \u0026#39;foo\u0026#39;; console.log(foo.bar); 典型的なのは、CSS Modules を使用できるようにするための次のような定義です。 TSDoc/JSDoc 形式でドキュメンテーションコメントを記述しておけば、VS Code などのエディタ上でドキュメント表示してくれるようになります。 globals.d.ts declare module \u0026#39;*.css\u0026#39; { /** CSS クラスを参照するためのオブジェクトです。 */ const styles: { [className: string]: string }; export default styles; } 対象モジュールを any としてだけ扱えればよいのであれば、次のように型定義部分を省略可能です。 globals.d.ts declare module \u0026#39;*.css\u0026#39;; これで、次のように .css ファイルをインポートしたときに、TypeScript の型エラーが発生しなくなります。 import * as styles from \u0026#39;./App.css\u0026#39;; 存在する JavaScript ファイルに型宣言ファイルを提供する プロジェクト内にすで存在する JavaScript モジュール（.js ファイル）に対して、後付けで型宣言ファイル (.d.ts) を提供したい場合があります。 例えば、社内の別の人が作成した JavaScript ライブラリを、TypeScript コードから参照したい場合などです。 そのような場合は、対象の .js ファイルと同じ階層に、同じモジュール名で モジュール名.d.ts というファイルを作成します。 例えば、次のような JavaScript ライブラリがあったとします。 lib/util.js exports.greet = function(name) { console.log(`Hello, ${name}`); } この lib/util.js は、greet 関数を公開していますが、パラメータと戻り値の型が定義されておらず、そのままでは TypeScript コードから使用できません（noImplictAny 設定時）。 この lib/util.js ファイルの内容を変更せずに、型情報付きの TypeScript モジュールとして利用したいときは、同じディレクトリに lib/util.d.ts ファイルを作成 します。 lib/util.d.ts export function greet(name: string): void; すると、JavaScript で作成されたライブラリを、型情報付きのモジュール lib/util として参照できるようになります。 VisualStudio Code などで次のように型情報の補完が効くようになります。 図: main.ts TypeScript のビルド時には、import で指定されたモジュール名に対して .ts、.tsx、.d.ts という順でファイル検索が行われます。 そのため、ここでは lib/util.d.ts という型宣言ファイルが読み込まれることになります。 一方、実行時に使用されるのは lib/util.js というライブラリ本体側のファイルであることに注意してください。 .js ファイルと .d.ts ファイルを同じディレクトリに格納して、インポート時のパスが一致するようにしているのは、このあたりに理由があります。 .d.ts ファイルが一種の緩衝材のようになり、TypeScript と JavaScript の世界をうまくつないでくれています。 既存ライブラリの例 各 NPM パッケージに埋め込まれた型宣言ファイルを使う NPM パッケージとして公開されている JavaScript ライブラリには、自分自身の NPM パッケージ内に TypeScript 用の型宣言ファイル (.d.ts) を含んでいるものもあります。 型宣言ファイルのパスは、次のように package.json ファイルの types プロパティで指定されています。 package.json { \u0026#34;name\u0026#34;: \u0026#34;awesome\u0026#34;, \u0026#34;author\u0026#34;: \u0026#34;Vandelay Industries\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1.0.0\u0026#34;, \u0026#34;main\u0026#34;: \u0026#34;./lib/main.js\u0026#34;, \u0026#34;types\u0026#34;: \u0026#34;./lib/main.d.ts\u0026#34; } このような NPM パッケージは、そのまま TypeScript ライブラリとしてインポートできます。 DefinitelyTyped で公開される @types/xxx を使う jQuery ライブラリなどの有名な JavaScript ライブラリの型宣言ファイルは、DefinitelyTyped プロジェクトでまとめて公開されています。 パッケージ名は、 @types/XXX という名前になっており、次のようにインストールすることができます。 jQuery 用の TypeScript 型宣言をインストール $ npm install --save-dev @types/jquery これでインストールされるのは型宣言のみなので、jQuery ライブラリ本体は何らかの方法で参照できるようにしておく必要があります。 最終的に生成された JavaScript を Web ブラウザから実行するのであれば、HTML ファイルの script タグなどで jQuery 本体をロードすることになるでしょう。 ここでは、テストのため、npm コマンドでインストールしてしまうことにします。 jQuery 本体をインストール（JavaScript 用の NPM パッケージ） $ npm install --save jquery ☝️ ワンポイント @types/jquery はビルド時のみ必要なので --save-dev フラグでインストールしていますが、jquery モジュールは実行時に必要になるので --save フラグでインストールしていることに注意してください。 このようにインストールした型宣言ファイルは node_modules/@types 以下に格納されており、TypeScript はデフォルトでこのディレクトリ以下のモジュールをインポートするパスを通しています（tsconfig.json の compilerOptions.typeRoots プロパティでカスタマイズ可能）。 つまり、@types/ というプレフィックスを付けずに、次のようにインポートすることができます main.ts import * as $ from \u0026#39;jquery\u0026#39;; const footerElem = $(\u0026#39;#footer\u0026#39;); このように、あたかも最初から TypeScript 用のライブラリとして提供されているかのように JavaScript ライブラリを参照できるようになります（実際には .d.ts の型情報だけ見てトランスパイルしてるだけですが）。 ただこれだと、生成される JavaScript ファイル内に import 文が残ってしまうので、jQuery の場合は、次のようにコメント形式で .d.ts の定義を参照する方法がよいかもしれません。 /// \u0026lt;reference path=\u0026#34;../node_modules/@types/jquery/index.d.ts\u0026#34; /\u0026gt; const footerElem = $(\u0026#39;#footer\u0026#39;); その他 String ではなく string を使う 型宣言ファイル (.d.ts) の中では、大文字で始まる String ではなく、TypeScript プリミティブな string 型を使い、効率的なコードを生成するようにします。 Number、Boolean、Symbol、Object なども同様に、すべて小文字の型の方を使います。 参考: Do\u0026rsquo;s and Don\u0026rsquo;ts）。 .ts ファイルから .d.ts ファイルを生成する TypeScript ファイル (.ts) をトランスパイルするときに、.js ファイルに加えて .d.ts ファイルを生成したいときは、ビルドオプションで --declaration を指定します。 TypeScript で作成したライブラリを NPM パッケージとして公開するときは、このように作成した .js ファイルと .d.ts ファイルをパッケージングします（逆に .ts ファイルはパッケージに入れてはいけません）。"
},
{
url: "/p/oanzbmx/",
title: "MongoDB クライアント (mongo シェル)",
date: "2015-04-13T00:00:00Z",
body: "MongoDB クライアント (mongo シェル)"
},
{
url: "/p/xz9iry9/",
title: "TypeScript プロジェクトに ESLint を導入する",
date: "2021-05-20T00:00:00Z",
body: "TypeScript プロジェクトに ESLint を導入する ESLint とは ESLint は JavaScript/TypeScript 向けの Lint ツール（静的解析ツール）です。 プロジェクト内のソースコードに対して eslint コマンドを実行することで、コーディングルールに従っていない部分や、不具合の原因になりそうな部分を検出してくれます。 ☝️ eslint vs tslint もともと TypeScript 用には tslint という Lint ツールが提供されていましたが、Microsoft の TypeScript チームが eslint への統合を 公式に発表 してから（2019年以降）は、TypeScript においても eslint が事実上の標準 Lint ツールとなっています。参考: TypeScript の ESLint 対応プロジェクト ESLint のインストール eslint コマンドは npm でインストールできます。 TypeScript プロジェクトのディレクトリ内で、次のように開発用にインストールすることが推奨されています（package.json は作成済みだと想定します）。 ESLint のインストール $ npm install eslint --save-dev ESLint の初期設定 eslint コマンドを実行するためには、設定ファイル .eslintrc.{js,yml,json} を作成しておく必要があります。 設定ファイルの生成 $ npx eslint --init 上記のように実行すると、ウィザード形式でどのような用途に使用するかを質問されるので、順番に答えていくだけで設定ファイルを生成できます。 最後にその構成に必要なモジュールをまとめてインストールできます。 ここでは、eslint v7.26.0 における表示例を示しています。 質問1 ? How would you like to use ESLint? … To check syntax only To check syntax and find problems ❯ To check syntax, find problems, and enforce code style ここでは「構文チェック」「問題の発見」「スタイル強制」をすべて行いたいので、カーソルキーで一番下の項目を選んで Enter キーを押します。 質問2 ? What type of modules does your project use? … ❯ JavaScript modules (import/export) CommonJS (require/exports) None of these モジュールのインポート形式には import/export を選択します。 質問3 ? Which framework does your project use? … ❯ React Vue.js None of these React.js や Vue.js を使うのであれば、ここで選択します。 質問4 ? Does your project use TypeScript? No / Yes TypeScript を使うかどうかを聞かれるので、Yes を選択します。 質問5 ? Where does your code run? … ✔ Browser Node 実行環境を選択します（スペースキーで選択をトグルします）。 コードの中で、どのようなグローバルオブジェクトを参照するかに応じて選択します。 Web ブラウザ上で動作させる JavaScript コードであれば Browser を選択し、Node.js 環境で動作させるコードであれば Node を選択します。 質問6 ? How would you like to define a style for your project? … ❯ Use a popular style guide Answer questions about your style Inspect your JavaScript file(s) 最初の質問で一番下の enforce code style を選んでいると、ここでどのようなコーディングスタイルを使うかを質問されます。 ここでは、ポピュラーなスタイルをそのまま使うことにします。 質問7 ? Which style guide do you want to follow? … Airbnb: https://github.com/airbnb/javascript ❯ Standard: https://github.com/standard/standard Google: https://github.com/google/eslint-config-google XO: https://github.com/xojs/eslint-config-xo 実際にどのスタイルを提供するかを指定します。 有名どころの Airbnb スタイルや JavaScript Standard スタイルなどを選択できます。 ここでは、行末のセミコロンを省略するスタイルである Standard を選択することにします。 参考: TypeScript のコーディング規約（ルール／ガイドライン） 質問8 ? What format do you want your config file to be in? … JavaScript ❯ YAML JSON コンフィグファイルの形式を選択します。 基本的には一番簡潔に記述できる YAML 形式を選び、何らかの動的処理が必要な場合のみ JavaScript 形式を選べばよいと思います。 JSON 形式は記述が冗長になるし、コメントも記述できないので、選択しないようにしましょう。 質問9 The config that you\u0026#39;ve selected requires the following dependencies: eslint-plugin-react@latest @typescript-eslint/eslint-plugin@latest eslint-config-standard@latest eslint@^7.12.1 eslint-plugin-import@^2.22.1 eslint-plugin-node@^11.1.0 eslint-plugin-promise@^4.2.1 @typescript-eslint/parser@latest ? Would you like to install them now with npm? No / Yes 必要なパッケージの一覧が表示されるので、Yes を選択してインストールします。 これらの依存情報は、package.json の devDependencies に自動的に追加されます。 これで、ESLint の初期設定は完了です。 作成された .eslintrc.yml の内容は次のような感じになっています。 .eslintrc.yml env:browser:truees2021:trueextends:- \u0026#39;plugin:react/recommended\u0026#39;- standardparser:\u0026#39;@typescript-eslint/parser\u0026#39;parserOptions:ecmaFeatures:jsx:trueecmaVersion:12sourceType:moduleplugins:- react- \u0026#39;@typescript-eslint\u0026#39;rules:{} ESLint の実行 カレントディレクトリ以下の .ts および .tsx ファイルに対して、ESLint をかけるには次のように実行します。 $ npx eslint . --ext ts,tsx 標準出力に警告がずらずらと表示されるはずです。 上記コマンドは、NPM スクリプトとして package.json に登録しておくと楽です。 package.json（抜粋） { //... \u0026#34;scripts\u0026#34;: { \u0026#34;lint:eslint\u0026#34;: \u0026#34;eslint . --ext ts,tsx\u0026#34;, \u0026#34;fix:eslint\u0026#34;: \u0026#34;eslint . --ext ts,tsx --fix\u0026#34;, ここでは、単純にチェックだけかける lint:eslint コマンドと、自動修正までしてしまう fix:eslint コマンドを定義してみました。 これで、次のように簡単に ESLint を実行できるようになります。 $ npm run lint:eslint # ESLint の実行 $ npm run fix:eslint # 自動修正 npm スクリプト名を単純に lint、fix にしていないのは、追加で Prettier（自動整形ツール）を導入することを想定したものです。 Prettier の方にも同様の機能があるため、lint:prettier、fix:prettier という名前を付ける余地を残しています。 参考リンク TypeScript/JavaScript コードを Prettier で自動整形する （おまけ）VS Code への ESLint プラグインのインストール エディターとして VS Code を使用している場合は、VS Code 用の ESLint プラグインもインストールしておきましょう。 次のような機能が有効になります。 編集中にエディター上にエラー表示 エラーの一覧を Output パネル (Ctrl + Shift + M) に表示 上記それぞれから Quick Fix 可能 ESLint プラグインのインストールと有効化 ESLint - Visual Studio Marketplace ESLint プラグインは上記のサイトあるいは、VS Code の Extensions メニューからワンクリックでインストールできます。 ESLint プラグインをインストールした直後は、次のような警告が出て ESLint が有効になっていない可能性があります。 その場合は、VS Code 右下の ESLint という部分をクリックして有効化できます。 VS Code のフォーマッター設定 VS Code には、JavaScript/TypeScript のフォーマッターがデフォルトで搭載されています。 これらのフォーマットスタイルは ESLint で設定したスタイルに合わないことがあるので、ESLint のスタイル設定を優先するように設定しておきます。 Ctrl + , で設定画面を開いて、Formatter などで検索すると設定項目を見つけられます。 これで、Shift + Alt + F（あるいは Ctrl + Shift + P → Format Document）で編集中ファイルのフォーマットを実行できます。 （おまけ）React 用の設定 最新の React では、TypeScript コード内に JSX が含まれていても React モジュールをインポートする必要がなくなっています。 ESLint がこれを認識できずに、次のようなエラーを出力することがあります。 4:10 error \u0026#39;React\u0026#39; must be in scope when using JSX react/react-in-jsx-scope このチェックを無効にするには、設定ファイルの rules プロパティで次のように指定します。 .eslintrc.yml（抜粋） rules:react/react-in-jsx-scope:off （おまけ）Airbnb スタイルで TypeScript のインポートエラーが出る場合 eslint --init で導入される Airbnb スタイルは、TypeScript のインポートまわりの扱いが不十分で、多少のマニュアル設定が必要になることがあります（2021-05 現在）。 具体的には、Airbnb スタイルの import 設定 が .js ファイルを前提としており、拡張子を省略して .ts ファイルをインポートできません（import/no-unresolved、import/extensions エラーが出ます）。 このエラーは、次のように設定を上書きすることで回避することができます。 .eslintrc.yml（抜粋） rules:import/extensions:- error- ts:nevertsx:neverjs:neverjsx:neversettings:import/resolver:node:extensions:[.ts, .tsx, .js, .jsx] あるいは、airbnb (eslint-config-airbnb) 共有設定を使うのではなく、airbnb-typescript (eslint-config-airbnb-typescript) という共有設定を使う方法もあります。 こちらであれば、最初から TypeScript ファイルのインポートに対応しています（React にも対応しています）。 ただし、eslint --init でインストールできる共有設定は airbnb の方なので、airbnb-typescript を使いたい場合は、マニュアルで npm install する必要があります。 extends:- airbnb-typescriptparserOptions:ecmaVersion:2021project:./tsconfig.json 他にも、Standard スタイルで TypeScript を使う場合の eslint-config-standard-typescript などがあります。 extends:- standard-typescriptparserOptions:ecmaVersion:2021project:./tsconfig.json インストール方法や、.eslintrc.* ファイルの記述方法は、各パッケージの GitHub サイトを参照してください。 参考リンク GitHub - iamturns/eslint-config-airbnb-typescript GitHub - standard/eslint-config-standard-with-typescript （おまけ）Standard スタイルか Airbnb スタイルか JavaScript/TypeScript の世界で一般的に採用されているスタイルは こちら で簡単にまとめていますが、個人的には、Standard スタイルのセミコロン省略はかなり楽でいいなと感じています。 単純にコードの見た目がスッキリするし、} の後ろにセミコロンを入れるか入れないかの一瞬の無駄な思考時間をゼロにできます。 一方で、もっと厳密にスタイルを定義したいのであれば、Airbnb スタイルを使うのがよいかもしれません。 Airbnb スタイルを適用した上で、セミコロンだけ省略するスタイルにするのもありですね。 .eslintrc.yml env:es2021:trueextends:- airbnb-typescript# - airbnb-typescript/base # React を使わない場合parser:\u0026#34;@typescript-eslint/parser\u0026#34;parserOptions:ecmaVersion:12ecmaFeatures:jsx:trueproject:./tsconfig.jsonplugins:- react- \u0026#34;@typescript-eslint\u0026#34;rules:semi:[error, never] # セミコロンを省略するスタイルにするreact/react-in-jsx-scope:off# JSX 用の React インポートエラー抑制 参考 ESLint の設定ファイル (.eslintrc) の各プロパティの意味を理解する ESLint + Prettier の設定方法まとめ"
},
{
url: "/p/r8iry9g/",
title: "TypeScriptの型: 環境変数 (process.env) 用の型情報を定義する",
date: "2020-10-12T00:00:00Z",
body: "TypeScriptの型: 環境変数 (process.env) 用の型情報を定義する Node.js で環境変数を参照するためのオブジェクト process.env の型情報は、@types/node で次のように文字列型ディクショナリ Dict\u0026lt;string\u0026gt; として定義されています。 node_modules/@types/node/process.d.ts（抜粋） declare module \u0026#34;process\u0026#34; { global { var process: NodeJS.Process; namespace NodeJS { interface ProcessEnv extends Dict\u0026lt;string\u0026gt; {} //... } } export = process; } この型定義は @types/node モジュールをインストールするだけで簡単に使用できるようになるのですが、具体的なキー名（環境変数名）が定義されていないので、Visual Studio Code などで process.env 以降の入力補完が効きません。 VS Code 上で環境変数名を補完入力 できるようにするには、次のような型定義ファイル (globals.d.ts) をソースツリーのルートに作成します。 globals.d.ts declare namespace NodeJS { // 環境変数名の定義 interface ProcessEnv { /** 現在の Node.js 実行環境 */ readonly NODE_ENV: \u0026#39;development\u0026#39; | \u0026#39;production\u0026#39; | \u0026#39;test\u0026#39;; /** GitHub アクセストークン */ readonly MYAPP_GITHUB_TOKEN: string; } } 環境変数 NODE_ENV の値は、決められた 3 種類の値 (development/production/test) のいずれかであると定義しているので、それ以外の値と比較しようとしたときに警告してくれます。 if (process.env.NODE_ENV === \u0026#39;hoge\u0026#39;) { // 警告メッセージ ts(2367) // This condition will always return \u0026#39;false\u0026#39; since the types // \u0026#39;\u0026#34;development\u0026#34; | \u0026#34;production\u0026#34; | \u0026#34;test\u0026#34;\u0026#39; and \u0026#39;\u0026#34;hoge\u0026#34;\u0026#39; have no overlap. また、上記の型定義のように TSDoc/JSDoc ドキュメンテーションコメントを記述しておけば、VS Code で入力補完するときにドキュメントを表示してくれます。 ちなみに、このような型情報の追加が可能なのは、TypeScript の interface 定義が後付けで拡張できる (open-ended) という性質を持っているからです。"
},
{
url: "/p/tdpybmw/",
title: "React コンポーネントで入力フォームを作成する (1) 自力編",
date: "2020-07-10T00:00:00Z",
body: "React コンポーネントで入力フォームを作成する (1) 自力編 制御コンポーネント (controlled components) React コンポーネントでフォームを構成する場合、コンポーネントの状態 (state) に基づいて表示を行うように実装すると、フォームの表示内容を制御しやすくなります。 このように、コンポーネントの表示内容が、完全にその状態 (state) によって決まるように実装されたものを、制御されたコンポーネント (controlled components) と呼びます。 このように設計することで、若干コード量は増えますが、表示内容を変更したいときはコンポーネントの state を変更するだけで済むようになります。 例えば、ネットワークから取得したデータをフォームに表示するような場合、そのフォームの構造を知る必要はなく、単純に state を更新するだけでよくなります。 これは、データとビューが分離された設計になっており、アプリ設計におけるベストプラクティスのひとつです。 input 要素の実装例 下記は、\u0026lt;input type=\u0026quot;text\u0026quot;\u0026gt; 要素と \u0026lt;input type=\u0026quot;submit\u0026quot;\u0026gt; 要素を持つ MessageForm コンポーネントの実装例です。 ユーザーがテキストを入力するたびに handleChange() が呼び出され、コンポーネントの状態 (state) が更新されます。 setState() の呼び出しにより state が変更が変更されると、再度 render() が実行され、表示内容が state の値に基づいて更新されます。 まずは、クラスコンポーネント形式での実装例。 components/MessageForm.tsx import * as React from \u0026#39;react\u0026#39;; interface IState { msg: string; } // テキスト入力エリアと、submit ボタンを持つフォームを表示するコンポーネント export class MessageForm extends React.Component\u0026lt;{}, IState\u0026gt; { constructor(props: {}) { super(props); // ステートの初期化（最初は入力エリアは空っぽ） this.state = {msg: \u0026#39;\u0026#39;}; } // input 要素でのキー入力のたびに呼び出される private handleChange = (e: React.ChangeEvent\u0026lt;HTMLInputElement\u0026gt;) =\u0026gt; { // ステートを変更することで表示を更新する this.setState({msg: e.target.value}); } // submit ボタンを押したときに呼び出される private handleSubmit = (e: React.FormEvent) =\u0026gt; { // submit ボタンのデフォルトの振る舞い (GET や POST) を抑制する e.preventDefault(); // 実際にはここでメッセージ送信を行う（内容は state から取得する） alert(\u0026#39;次のメッセージが送信されました: \u0026#39; + this.state.msg); } render() { return \u0026lt;form onSubmit={this.handleSubmit}\u0026gt; \u0026lt;label\u0026gt;メッセージ： \u0026lt;input type=\u0026#34;text\u0026#34; value={this.state.msg} onChange={this.handleChange} /\u0026gt; \u0026lt;/label\u0026gt; \u0026lt;input type=\u0026#34;submit\u0026#34; value=\u0026#34;送信\u0026#34; /\u0026gt; \u0026lt;/form\u0026gt;; } } 下記は、関数コンポーネントでの実装例です。 コメントを削ったというのもありますが、やはり関数コンポーネントにするとコードがすっきりしますね。 components/MessageForm.tsx import * as React from \u0026#39;react\u0026#39;; export const MessageForm: React.FC = () =\u0026gt; { // ステート用のフック（テキストの初期値は空っぽ） const [message, setMessage] = React.useState(\u0026#39;\u0026#39;); const handleChange = (e: React.ChangeEvent\u0026lt;HTMLInputElement\u0026gt;) =\u0026gt; { setMessage(e.target.value); }; const handleSubmit = (e: React.FormEvent) =\u0026gt; { e.preventDefault(); alert(\u0026#39;次のメッセージが送信されました: \u0026#39; + message); }; return \u0026lt;form onSubmit={handleSubmit}\u0026gt; \u0026lt;label\u0026gt;メッセージ： \u0026lt;input type=\u0026#34;text\u0026#34; value={message} onChange={handleChange} /\u0026gt; \u0026lt;/label\u0026gt; \u0026lt;input type=\u0026#34;submit\u0026#34; value=\u0026#34;送信\u0026#34; /\u0026gt; \u0026lt;/form\u0026gt;; }; 上記のように作成した MessageForm コンポーネントは次のように使用します（といってもポンっと置いてるだけですが）。 index.tsx（使用例） import * as React from \u0026#39;react\u0026#39;; import * as ReactDOM from \u0026#39;react-dom\u0026#39;; import { MessageForm } from \u0026#39;./components/MessageForm\u0026#39;; ReactDOM.render(\u0026lt;MessageForm /\u0026gt;, document.getElementById(\u0026#39;root\u0026#39;)); 他のフォーム要素の場合（textarea 要素など） 他の要素も同様に使える 他のフォーム要素を使う場合も、前述の例（\u0026lt;input type=\u0026quot;text\u0026quot;\u0026gt; 要素）とほぼ同様に記述することができます。 例えば、テキスト入力用に \u0026lt;textarea\u0026gt; 要素を使用する場合も、次のように onChange 属性で指定したイベントハンドラ内でステートを更新すれば OK です。 const handleChange = (e: React.ChangeEvent\u0026lt;HTMLTextAreaElement\u0026gt;) =\u0026gt; { setMessage(e.target.value); }; // ... \u0026lt;textarea value={message} onChange={handleChange} /\u0026gt; 注意点としては、イベントハンドラのパラメータの型が微妙に変わる ということです（型パラメータとして HTMLInputElement ではなく、HTMLTextAreaElement を使用します）。 また、通常の HTML の textarea 要素の場合、\u0026lt;textarea\u0026gt;こんにちわ\u0026lt;/textarea\u0026gt; のように、開始タグと終了タグの間に値を記述しましたが、JSX の textarea の値は value 属性で指定する ことに注意してください（他の input 要素と共通の value 属性で値をセットできるよう考慮されています）。 各種フォーム要素の実装例 input type=\u0026ldquo;submit\u0026rdquo; 要素 / button type=\u0026ldquo;submit\u0026rdquo; 要素 FormEvent 型のイベントオブジェクトを受け取ります。 const handleSubmit = (e: React.FormEvent) =\u0026gt; { e.preventDefault(); alert(\u0026#39;メッセージ: \u0026#39; + message); }; \u0026lt;form onSubmit={handleSubmit}\u0026gt; ... \u0026lt;input type=\u0026#34;submit\u0026#34; value=\u0026#34;送信\u0026#34; /\u0026gt; \u0026lt;button type=\u0026#34;submit\u0026#34; onClick={handleSubmit}\u0026gt;送信\u0026lt;/button\u0026gt; \u0026lt;/form\u0026gt; input type=\u0026ldquo;text\u0026rdquo; 要素 ChangeEvent\u0026lt;HTMLInputElement\u0026gt; 型のイベントオブジェクトを受け取ります。 const handleChange = (event: React.ChangeEvent\u0026lt;HTMLInputElement\u0026gt;) =\u0026gt; { setMessage(event.target.value); } \u0026lt;input type=\u0026#34;text\u0026#34; value={message} onChange={handleChange} /\u0026gt; input type=\u0026ldquo;checkbox\u0026rdquo; 要素 ChangeEvent\u0026lt;HTMLInputElement\u0026gt; 型のイベントオブジェクトを受け取ります（type=\u0026ldquo;text\u0026rdquo; と同じ）。 export const MyForm: React.FC = () =\u0026gt; { const [isOpen, setIsOpen] = React.useState(false); const handleChange = (e: React.ChangeEvent\u0026lt;HTMLInputElement\u0026gt;) =\u0026gt; { setIsOpen(e.target.checked); } return \u0026lt;form\u0026gt; \u0026lt;label\u0026gt;Is open: \u0026lt;input type=\u0026#34;checkbox\u0026#34; checked={isOpen} onChange={handleChange} /\u0026gt; \u0026lt;/label\u0026gt; \u0026lt;/form\u0026gt;; }; textarea 要素 ChangeEvent\u0026lt;HTMLTextAreaElement\u0026gt; 型のイベントオブジェクトを受け取ります。 const handleChange = (e: React.ChangeEvent\u0026lt;HTMLTextAreaElement\u0026gt;) =\u0026gt; { setMessage(e.target.value); } \u0026lt;textarea value={message} onChange={handleChange} /\u0026gt; select 要素 ChangeEvent\u0026lt;HTMLSelectElement\u0026gt; 型のイベントオブジェクトを受け取ります。 import * as React from \u0026#39;react\u0026#39;; export const MyForm: React.FC = () =\u0026gt; { const [color, setColor] = React.useState(\u0026#39;red\u0026#39;); const handleSubmit = (e: React.FormEvent) =\u0026gt; { e.preventDefault(); alert(\u0026#39;Color: \u0026#39; + color); //=\u0026gt; \u0026#39;red\u0026#39; } const handleChange = (e: React.ChangeEvent\u0026lt;HTMLSelectElement\u0026gt;) =\u0026gt; { setColor(e.target.value); } return \u0026lt;form onSubmit={handleSubmit}\u0026gt; \u0026lt;label\u0026gt; Pick your favorite color: \u0026lt;select value={color} onChange={handleChange}\u0026gt; \u0026lt;option value=\u0026#34;red\u0026#34;\u0026gt;Red\u0026lt;/option\u0026gt; \u0026lt;option value=\u0026#34;green\u0026#34;\u0026gt;Green\u0026lt;/option\u0026gt; \u0026lt;option value=\u0026#34;yellow\u0026#34;\u0026gt;Yellow\u0026lt;/option\u0026gt; \u0026lt;/select\u0026gt; \u0026lt;/label\u0026gt; \u0026lt;input type=\u0026#34;submit\u0026#34; value=\u0026#34;Submit\u0026#34; /\u0026gt; \u0026lt;/form\u0026gt;; }; キーハンドル onKeyDown や onKeyPress 属性でセットしたイベントハンドラには、KeyboardEvent オブジェクトが渡されます。 このオブジェクトからどんな値を取得できるかは、公式の Keyboard Events の説明 を参照してください。 import * as React from \u0026#39;react\u0026#39;; export const MyForm: React.FC = () =\u0026gt; { const [message, setMessage] = React.useState(\u0026#39;\u0026#39;); const handleKeyEvent = (e: React.KeyboardEvent) =\u0026gt; { console.log(e); } const handleChange = (e: React.ChangeEvent\u0026lt;HTMLInputElement\u0026gt;) =\u0026gt; { setMessage(e.target.value); } return \u0026lt;form\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; value={message} onKeyDown={handleKeyEvent} onChange={handleChange} /\u0026gt; \u0026lt;/form\u0026gt;; }; カスタムフックで input 要素の属性を簡単にセットする フォームに複数の input 要素を配置する場合、各要素の value 属性と onChange 属性をセットするのが煩わしく感じるかもしれません。 そのようなときは、下記の useInput 関数のように、input 要素用の属性値（value と onChange）を生成して返す関数を作ると楽になるかもしれません。 components/MyForm.tsx import * as React from \u0026#39;react\u0026#39;; // カスタムフックを定義（input 要素用の属性を生成する） const useInput = (initValue) =\u0026gt; { const [value, setValue] = React.useState(initValue); return { value, onChange: (e: React.ChangeEvent\u0026lt;HTMLInputElement\u0026gt;) =\u0026gt; setValue(e.target.value) }; }; export const MyForm: React.FC = () =\u0026gt; { const msg1 = useInput(\u0026#39;\u0026#39;); const msg2 = useInput(\u0026#39;\u0026#39;); const handleSubmit = (e: React.FormEvent) =\u0026gt; { e.preventDefault(); alert(msg1.value + \u0026#39;, \u0026#39; + msg2.value); }; return \u0026lt;form onSubmit={handleSubmit}\u0026gt; \u0026lt;label\u0026gt;Message1: \u0026lt;input type=\u0026#34;text\u0026#34; {...msg1} /\u0026gt;\u0026lt;/label\u0026gt; \u0026lt;label\u0026gt;Message2: \u0026lt;input type=\u0026#34;text\u0026#34; {...msg2} /\u0026gt;\u0026lt;/label\u0026gt; \u0026lt;input type=\u0026#34;submit\u0026#34; value=\u0026#34;送信\u0026#34; /\u0026gt; \u0026lt;/form\u0026gt;; }; ちなみに、この useInput 関数のように内部でフック関数（useState など）を呼び出すものを、カスタムフック と呼びます。 カスタムフックにも呼び出し順序などの制約が生まれる、標準のフック関数と同様に use で始まる名前を付けることが推奨されています。 参考: 独自フックの作成 – React React アプリでフォームを作るなら React アプリにおけるフォームの扱い方を理解したら、実際には React Hook Form (react-hook-form) のようなライブラリを使ってフォームを作成することをオススメします。 下手に自力でフォームを処理するよりも、簡潔で高速なコードを記述できます。 React Hook Form で入力フォームを作る"
},
{
url: "/p/mkwnnsz/",
title: "LUIS (1) LUIS とは？",
date: "2019-03-13T00:00:00Z",
body: "LUIS (1) LUIS とは？ LUIS でできること Microsoft が提供している LUIS (Language Understanding Intelligent Service) サービスを使用すると、自然言語による文章（発話テキスト）を、コンピュータが理解しやすい形式に翻訳することができます。 主にチャットボットのバックエンドとして使用されることが想定されているようです。 LUIS (Language Understanding) - Cognitive Services - Microsoft Azure LUIS - Endpoint API メインのクエリ用 REST API LUIS - Authoring API アプリ管理用の REST API LUIS は、入力した発話テキストをインテントとエンティティに分解します。 インテント … 意図、目的。ユーザが何をしたいのかを表す。 エンティティ … 文章の中のプレースホルダに当たる部分の値。求めているものや、条件などを示す部分。 例えば、下記のような入力テキストがあったとすると、 15時から4人で使える部屋はない？ LUIS は次のようなインテント＋エンティティの情報に翻訳します。 インテント: SearchMeetingRoom エンティティ: Time=15時、People=4人 チャットボットのプログラムは、この翻訳された情報を見て、「ミーティングルームを探す」処理を、パラメータ「15時」、「4人」で行えばよいことになります。 LUIS は上記のような翻訳処理を行うためのサービスなので、その先のミーティングルームの検索処理などは独自に実装する必要があります。 LUIS の Web サイト上では、このような発話例 (Utterance) と、インテント、エンティティの情報を登録していくことで、モデルの学習を進めることができます。 LUIS のモデルを公開する LUIS ポータル上で作成した自然言語解析のモデルを、Web API (REST API) の形で使用できるようにするには、下記のようなステップを踏みます（QnA Maker のサービスと同様の手順です）。 Azure ポータルの リソースの作成 から Language Understanding (LUIS) のリソースを作成する LUIS ポータルで LUIS アプリ（モデル）を作成する（上記で作成した Azure の LUIS リソース経由でアクセスできるよう関連付ける） LUIS ポータルでモデルを Publish して REST API として呼び出せるようにする 上記のようにしてナレッジベースを公開すれば、Node.js や C# など任意の言語から LUIS API を使用できるようになります。 その他 LUIS に関するメモ LUIS のドキュメントに出てくる「app」というのはいわゆる「モデル」のこと。 インテントのリストには「None」というインテントが最初から存在しており、LUIS が発話テキストを理解できなかった場合のインテントとして使用される。None インテントにも、発話例としていくつかの文章を登録しておくのがよい。 各インテントには発話テキストの例 (Utterance) を登録していく。 例: \u0026ldquo;評価が 70 以上のカベルネはありますか？\u0026rdquo; 例: \u0026ldquo;シャンパンを評価 50 で検索してください\u0026rdquo; 例: \u0026ldquo;評価が 80 以上の白ワインには何がありますか？\u0026rdquo; 2つ、3つの発話テキストを登録するだけでも、インテントに対応するコードを構築するのに十分役立つモデルを生成できる。 エンティティには様々なエンティティタイプがあるが、通常は既定の simple を選択しておけば、チャットボットが操作できる値を抽出するに十分である（LUIS のエンティティタイプはまだ開発中の機能である）。 既製のエンティティ (prebuilt entities) を使用すると、カスタムコードをあまり書かなくて済む。例えば、number というエンティティは、70 や seventy などのワードを認識できるようになっている（現状、数字は半角で入力する必要がある）。他にも、money、ordinal、percentage、keyPhrase、url、email、phoneNumber などが用意されている。 MS Bot Framework (SDK) において既製のエンティティ (prebuilt entities) を参照する場合、builtin. というプレフィックスが付く（例: builtin.number）。 LUIS がユーザから受信した発話テキストの一覧は、Review endpoint utterance のタブを選択すると確認できる。 LUIS モデルを使用するには、そのモデルを公開 (publish) する必要がある。"
},
{
url: "/p/pamv6gq/",
title: "Ansible の ansible.cfg ファイルの検索順序",
date: "2016-10-23T00:00:00Z",
body: "Ansible の ansible.cfg ファイルの検索順序 Ansible の実行環境が参照する設定ファイル (ansible.cfg) は、下記のようなパスから検索されます。 環境変数 ANSIBLE_CONFIG で指定されたファイル ansible.cfg（カレントディレクトリ以下のファイル） ~/.ansible.cfg（ホームディレクトリ以下のファイル） /etc/ansible/ansible.cfg Git などで管理する場合は、Playbook の近くに一緒に入れておくとわかりやすいです（上記の 2 番目の方法）。"
},
{
url: "/p/taoir3i/",
title: "gnuplot: グラフにタイトルを表示する",
date: "2004-01-03T00:00:00Z",
body: "gnuplot: グラフにタイトルを表示する グラフにタイトルを入れる Syntax set title \u0026#34;\u0026lt;title\u0026gt;\u0026#34; [\u0026lt;x_offset\u0026gt;] [, \u0026lt;y_offset\u0026gt;] タイトルはシングルクォーテーション (') で囲んでも構いませんが、改行 (\\n) を入れる場合はダブルクォーテーション (\u0026quot;) で囲む必要があります。 タイトルはデフォルトでは表の上部中央に表示されますが、x_offset に移動させる文字数を指定することができます。 タイトルを消したいときは、set title を実行します。 例: タイトルを「Normal Distribution (正規分布)」にする normal_distribution(x, a, b) = exp(-((x-b)**2)/(2*(a**2))) / sqrt(2*pi)*a set title \u0026#34;Normal Distribution\u0026#34; plot normal_distribution(x, 3, 0) タイトルを消す set title タイトルを消したい場合は、タイトル文字列を指定せずに set title を実行します。 複数行のタイトルを入れる set title \u0026#34;これは\\n複数行にわたる\\nタイトルだよ\u0026#34; タイトルに改行をいれるには \\n を使います。 複数行のタイトルを指定する場合は、' (シングルクォーテーション) ではなくて \u0026quot; (ダブルクォーテーション) で囲む必要があります。"
},
{
url: "/p/k7it5fp/",
title: "React コンポーネントで入力フォームを作成する (2) react-hook-form 編",
date: "2022-02-06T00:00:00Z",
body: "React コンポーネントで入力フォームを作成する (2) react-hook-form 編 React Hook Form とは React アプリで入力フォームを自力で作ろうとすると、各入力エリアのステート管理などが 意外と大変だったりします。 React Hook Form ライブラリ (react-hook-form) を使用すると、そのあたりの定型処理をシンプルに記述することができます。 React Hook Form / npm / GitHub React Hook Form は次のような特徴を備えています。 軽量（別のライブラリに依存しない） TypeScript をサポート パフォーマンスがよい（不要なレンダリングを軽減） HTML 標準のフォームバリデーション との互換性 required / min / max / minLength / maxLength / pattern / validate React Native でも使える 2022 年 2 月時点で活発に開発が進められており、npm のダウンロード数は右肩上がりに増えています。 GitHub のスター数も 25,000 を超えているため、しばらくは安心して使えそうなライブラリです。 React Hook Form を導入する react-hook-form パッケージは、npm あるいは yarn で簡単にインストールできます。 既存の React プロジェクト内で次のように実行してください。 $ npm install react-hook-form あるいは $ yarn add react-hook-form React Hook Form の基本的な使い方 次の MyForm コンポーネントは、1 つのテキスト入力フィールドと、1 つの数値入力フィールドを持つフォームの実装例です。 ここでは TypeScript を使い、フォームの入力要素の型を FormData と定義しています。 components/MyForm.tsx import { FC } from \u0026#39;react\u0026#39; import { SubmitHandler, useForm } from \u0026#39;react-hook-form\u0026#39; /** フォームの各要素の名前と型を定義 */ type FormData = { name: string age: number } /** Submit ボタンを押したときの処理 */ const onSubmit: SubmitHandler\u0026lt;FormData\u0026gt; = (data) =\u0026gt; { // data には FormData 型の値が入っている alert(JSON.stringify(data, null, 2)) } export const MyForm: FC = () =\u0026gt; { const { handleSubmit, register } = useForm\u0026lt;FormData\u0026gt;() return ( \u0026lt;form onSubmit={handleSubmit(onSubmit)}\u0026gt; \u0026lt;input {...register(\u0026#39;name\u0026#39;)} placeholder=\u0026#34;Name\u0026#34; /\u0026gt; \u0026lt;input type=\u0026#34;number\u0026#34; {...register(\u0026#39;age\u0026#39;)} placeholder=\u0026#34;Age\u0026#34; /\u0026gt; \u0026lt;button type=\u0026#34;submit\u0026#34;\u0026gt;OK\u0026lt;/button\u0026gt; \u0026lt;/form\u0026gt; ) } 表示イメージ OK React Hook Form の機能は、useForm フックの形で提供されているので、使いたい機能（関数）を、コンポーネントの先頭で次のように取得します。 const { handleSubmit, register } = useForm\u0026lt;FormData\u0026gt;() あとは、各入力要素の属性に、register 関数の戻り値をセットしてやれば OK です（戻り値には onChange や name、ref などが含まれています）。 他の属性（type や placeholder など）は、これまで通り一緒に指定できます。 \u0026lt;input {...register(\u0026#39;name\u0026#39;)} placeholder=\u0026#34;Name\u0026#34; /\u0026gt; \u0026lt;input type=\u0026#34;number\u0026#34; {...register(\u0026#39;age\u0026#39;)} placeholder=\u0026#34;Age\u0026#34; /\u0026gt; このように記述するだけで、入力要素が React Hook Form に登録され、内部で入力内容が管理されるようになります。 もっとも、実装者はこのあたりの動きを意識する必要はなく、通常は Submit ボタンを押したときにフォーム入力値を参照するだけで済みます。 const onSubmit: SubmitHandler\u0026lt;FormData\u0026gt; = ({ name, age }) =\u0026gt; { console.log(name, age) } なお、register 関数に渡す名前は、自分で定義した FormData 型のプロパティ名に合わせる必要があることに注意してください。 上記の例の場合は、name と age 以外の名前を渡そうとするとエラーになります。 TypeScript を使っていることで、このような指定ミスを早期に発見できます。 入力制限と Validation 処理 React Hook Forms で各フィールドの Validation 処理を行うには、register 関数の第 2 引数 (options) のオプションプロパティを使用します。 例えば、下記の入力フィールドは、値の入力が必須 (required) で、8 文字以上なければいけない (minLength) ことを示しています。 \u0026lt;input {...register('name', { required: true, minLength: 8 })} /\u0026gt; ユーザーが不適切な値を入力した場合は、useForm 関数が返すオブジェクトの、formState.errors にエラー情報が格納されるので、これを使ってユーザーに修正を促すことができます。 入力必須のフィールド 入力必須なフィールドを作成するには、register 関数の第 2 引数 (options) に渡すオブジェクトの required プロパティに、true あるいは文字列を指定します。 components/MyForm.tsx import { FC } from \u0026#39;react\u0026#39; import { useForm } from \u0026#39;react-hook-form\u0026#39; type FormData = { firstName: string } export const MyForm: FC = () =\u0026gt; { const { formState: { errors }, handleSubmit, register, } = useForm\u0026lt;FormData\u0026gt;() return ( \u0026lt;form onSubmit={handleSubmit((d) =\u0026gt; alert(JSON.stringify(d)))}\u0026gt; \u0026lt;label\u0026gt; First name \u0026lt;input aria-invalid={errors.firstName ? \u0026#39;true\u0026#39; : \u0026#39;false\u0026#39;} {...register(\u0026#39;firstName\u0026#39;, { required: true })} /\u0026gt; \u0026lt;/label\u0026gt; {errors.firstName \u0026amp;\u0026amp; \u0026lt;span role=\u0026#34;alert\u0026#34;\u0026gt;このフィールドは必須です\u0026lt;/span\u0026gt;} \u0026lt;button type=\u0026#34;submit\u0026#34;\u0026gt;OK\u0026lt;/button\u0026gt; \u0026lt;/form\u0026gt; ) } 上記の例では、required プロパティに true を指定していますが、代わりにエラー時に表示したいテキストを指定しておくこともできます。 このテキストは、エラー発生時（Invalid 時）にエラーオブジェクトの message プロパティで参照できるようになります。 次のコードは、前述のコードと同様に振る舞います。 \u0026lt;input aria-invalid={errors.firstName ? \u0026#39;true\u0026#39; : \u0026#39;false\u0026#39;} {...register(\u0026#39;firstName\u0026#39;, { required: \u0026#39;このフィールドは必須です\u0026#39; })} /\u0026gt; {errors.firstName \u0026amp;\u0026amp; \u0026lt;span role=\u0026#34;alert\u0026#34;\u0026gt;{errors.firstName.message}\u0026lt;/span\u0026gt;} なお、デフォルトでは、ユーザーが一度も Submit ボタンを押していない状態では、入力必須フィールドに何も入力されていなくてもエラー状態にはなりません。 これは、フォーム表示時に最初からエラー状態にならないようにするためです。 数値範囲や文字数の制約 入力文字数に制約を持たせたいときは minLength/maxLength オプションを使用します。 次の例では、8 〜 20 文字での入力を必須にしています。 required プロパティを同時に指定しておかないと、何も入力しなかったときに Valid（妥当）だと判断されてしまうので注意してください。 \u0026lt;label\u0026gt; First name \u0026lt;input aria-invalid={errors.firstName ? \u0026#39;true\u0026#39; : \u0026#39;false\u0026#39;} {...register(\u0026#39;firstName\u0026#39;, { required: \u0026#39;名前の入力は必須です\u0026#39;, minLength: { value: 8, message: \u0026#39;8文字以上必要です\u0026#39; }, maxLength: { value: 20, message: \u0026#39;20文字以下にしてください\u0026#39; }, })} /\u0026gt; \u0026lt;/label\u0026gt; {errors.firstName \u0026amp;\u0026amp; \u0026lt;span role=\u0026#34;alert\u0026#34;\u0026gt;{errors.firstName.message}\u0026lt;/span\u0026gt;} 数値の範囲に制約を持たせたいときは min/max オプションを指定します。 使い方は同様です。 \u0026lt;label\u0026gt; Age \u0026lt;input type=\u0026#34;number\u0026#34; min={0} max={200} aria-invalid={errors.age ? \u0026#39;true\u0026#39; : \u0026#39;false\u0026#39;} {...register(\u0026#39;age\u0026#39;, { required: \u0026#39;年齢の入力は必須です\u0026#39;, min: { value: 0, message: \u0026#39;年齢が不正です\u0026#39; }, max: { value: 200, message: \u0026#39;年齢が不正です\u0026#39; }, })} /\u0026gt; \u0026lt;/label\u0026gt; {errors.age \u0026amp;\u0026amp; \u0026lt;span role=\u0026#34;alert\u0026#34;\u0026gt;{errors.age.message}\u0026lt;/span\u0026gt;} ☝️ ワンポイント ここでは、register 関数のオプションオブジェクトだけではなく、input 要素自体の min / max 属性を指定していますが、これらを指定することで、ブラウザ本来の入力制限機能が有効になります。 両方指定すると煩雑になりそうですが、実際の振る舞いを見て、どちらがユーザビリティが高いか判断するのがよさそうです。 required、minLength、maxLength、pattern などに関しても同様です。 正規表現パターンによる制約 次の例では、メールアドレス形式の文字列がちゃんと入力されているかをチェックしています。 \u0026lt;label\u0026gt; Email \u0026lt;input type=\u0026#34;email\u0026#34; aria-invalid={errors.email ? \u0026#39;true\u0026#39; : \u0026#39;false\u0026#39;} {...register(\u0026#39;email\u0026#39;, { pattern: { value: /\\S+@\\S+\\.\\S+/, message: \u0026#39;メールアドレスが不正です\u0026#39;, }, })} /\u0026gt; \u0026lt;/label\u0026gt; {errors.email \u0026amp;\u0026amp; \u0026lt;span role=\u0026#34;alert\u0026#34;\u0026gt;{errors.email.message}\u0026lt;/span\u0026gt;} 入力エラー時の handleSubmit の振る舞い フォームが正しく入力されていない状態（Invalid 状態）のときに Submit ボタンが押された場合、handleSubmit の第 1 引数に指定したハンドラ関数は呼び出されません。 \u0026lt;form onSubmit={handleSubmit(onSubmit)}\u0026gt; なので、上記の onSubmit 関数は、正しい入力値（妥当だと判断された FormData オブジェクト）が渡されてくるという前提で実装して構いません。 もし、Invalid 状態で何らかのハンドラ関数を呼び出して欲しいのであれば、handleSubmit の第 2 引数 (onInvalid) に追加のハンドラ関数を渡せます。 \u0026lt;form onSubmit={handleSubmit(onSubmit, onValidationFailed)}\u0026gt; 入力値をリセットする フォームの入力値を初期状態に戻すには、useForm フックから返された、reset メソッドを呼び出します。 次の例では、Reset ボタンを押すことでフォーム要素をクリアするようにしています。 フォーム内に配置した button 要素はデフォルトでサブミットボタンとして機能するため、このような特殊用途で使う場合は、type=\u0026quot;button\u0026quot; の指定が必要であることに注意してください。 const { handleSubmit, register, reset } = useForm\u0026lt;FormData\u0026gt;() // ... \u0026lt;button type=\u0026#34;button\u0026#34; onClick={() =\u0026gt; reset()}\u0026gt;Reset\u0026lt;/button\u0026gt; \u0026lt;button type=\u0026#34;submit\u0026#34;\u0026gt;OK\u0026lt;/button\u0026gt; ただし、フォームには明示的なリセットボタンは配置しないほうがよいとされています。 リセットボタンは OK ボタンと間違えて押されてしまうことの方が多く、ユーザーをイラつかせてしまうためです。"
},
{
url: "/p/j6iu7it/",
title: "ESLint の設定ファイル (.eslintrc) の各プロパティの意味を理解する",
date: "2021-05-22T00:00:00Z",
body: "ESLint の設定ファイル (.eslintrc) の各プロパティの意味を理解する 何を説明するか 下記は、TypeScript を使った React アプリ実装用に用意した ESLint 設定ファイル (.eslint.yml) の例です。 トップレベルのプロパティとして、env や extends などがありますが、これらが何を意味しているかをざっと説明します。 .eslint.yml（例） root:trueenv:browser:truees2021:trueparser:\u0026#39;@typescript-eslint/parser\u0026#39;parserOptions:ecmaVersion:2021project:./tsconfig.jsonplugins:- react- react-hooks- \u0026#39;@typescript-eslint\u0026#39;extends:- eslint:recommended- plugin:react/recommended- plugin:react-hooks/recommended- plugin:@typescript-eslint/recommended- plugin:@typescript-eslint/recommended-requiring-type-checkingrules:react/react-in-jsx-scope:off 各プロパティの説明 root: true ESLint は、実行時のカレントディレクトリを起点にして、上位のディレクトリの設定ファイル (.eslintrc.*) を探していきます。 root: true の指定があると、この検索の振る舞いをそこで停止できます。 プロジェクトのトップディレクトリに置く .eslintrc.* には、この指定をしておくとよいです。 env: 実行環境の指示 どのようなグローバルオブジェクトを宣言なしで参照可能にするかを ESLint に知らせるための設定です。 例えば、Web ブラウザ上で動作させる JavaScript コードであれば browser、Node.js 環境で動作させるコードであれば node を true に設定します。 内部的には、選択した環境ごとに globals オプションの設定が行われます。 設定例 env:browser:truenode:truees2021:true 参考リンク ESLint - Specifying Environments parser: 使用するパーサー ESLint は標準で JavaScript コードのパースに対応していますが、TypeScript コード (.ts、.tsx) を扱えるようにするには、TypeScript 用のパーサー (@typescript-eslint/parser) をインストールして指定する必要があります。 設定例 parser:\u0026#39;@typescript-eslint/parser\u0026#39; parserOption: パーサーの設定 ESLint のデフォルトパーサーは ECMAScript 5 の構文で記述されたコードを想定します。 別のバージョンの ECMAScript 構文で記述したいときは、ecmaVersion でバージョンを設定します。 他にも、React アプリ内で JSX コードを使用する場合の指定などもここで行えます。 設定例 parserOptions:ecmaFeatures:jsx:trueecmaVersion:2021# same as 12sourceType:module # use import/export parser に @typescript-eslint/parser を指定したのであれば、TypeScript 用の parserOptions 設定 を行います。 パーサーを変更すると、parserOptions で指定すべき項目や、それぞれのデフォルト値が変化することに注意してください。 例えば、jsx オプションは通常必要ありません（ファイルの拡張子が .tsx の場合は、デフォルトで JSX コードを認識します）。 設定例 parser:\u0026#39;@typescript-eslint/parser\u0026#39;parserOptions:ecmaVersion:2021# デフォルト値は 2018project:./tsconfig.json # プロジェクト内の型認識に使用 参考リンク ESLint - Specifying Parser Options typescript-eslint/README.md - Configuration plugins: 使用するプラグインの指定 ESLint プラグインを使用するには、あらかじめ npm でインストールした上で、ここに列挙しておく必要があります。さらに、実際にルールを有効化するには、extends なども指定する必要があります。 次の例では、npm でインストールした @typescript-eslint/eslint-plugin プラグイン、および eslint-plugin-react をロードするように指示しています。 設定例 plugins:- react # means eslint-plugin-react- \u0026#39;@typescript-eslint\u0026#39;# means @typescript-eslint/eslint-plugin 上記の例からも分かるように、eslint-plugin というプレフィックスは省略できるようになっています（参考: Naming convention）。 参考リンク ESLint - Configuring Plugins extends: 共有設定の適用 (Sharable configuration) 複数のルールをまとめたコンフィギュレーション名を適用します。 ここで指定可能ものを sharable configuration オブジェクトと呼びます。 ESLint 標準のもの（eslint:recommeded など）以外は、npm パッケージをインストールすることで指定できるようになります。 設定例 extends:- \u0026#39;eslint:recommended\u0026#39;- \u0026#39;plugin:react/recommended\u0026#39;- \u0026#39;plugin:@typescript-eslint/recommended\u0026#39; 内部のルール設定が重複する場合は、後から指定したものが優先されることに注意してください。 例えば、plugin:@typescript-eslint/recommended は eslint:recommended より後に指定する必要があります（TypeScript 用の設定で上書きする必要があるため）。 sharable configuration のみを提供している npm パッケージには、eslint-config- というプレフィックスが付けられており、extends プロパティで指定するときは、このプレフィックスを省略できます。 eslint-config-airbnb パッケージ → airbnb eslint-config-standard パッケージ → standard npm パッケージのうち、ESLint プラグインと呼ばれているものは、その中のひとつの機能として sharable configuration を提供しています。 これを extends で指定するときは、次のようなフォーマットでコンフィグ名を指定します。 plugin:プラグインの省略名/コンフィグ名 例えば、eslint-plugin-react プラグインが提供する recommended コンフィグを使う場合は、plugin:react/recommended と指定します。 @typescript-eslint/eslint-plugin プラグインが提供する recommended コンフィグを使う場合は、plugin:@typescript-eslint/recommended と指定します。 rules: 各ルールの設定 個々のルール単位で有効／無効にする設定を行います。 多くのケースでは、extends による共有設定で大まかなルール設定を行い、ここで個別ルールを細かく調整します。 参考リンク ESLint - Rules"
},
{
url: "/p/b3wwe4b/",
title: "gnuplot: 座標軸にラベルを表示する",
date: "2004-01-03T00:00:00Z",
body: "gnuplot: 座標軸にラベルを表示する 座標軸にラベルを表示する Syntax set xlabel \u0026#34;\u0026lt;label\u0026gt;\u0026#34; [x [, y]] set ylabel \u0026#34;\u0026lt;label\u0026gt;\u0026#34; [x [, y]] set zlabel \u0026#34;\u0026lt;label\u0026gt;\u0026#34; [x [, y]] set x2label \u0026#34;\u0026lt;label\u0026gt;\u0026#34; [x [, y]] set y2label \u0026#34;\u0026lt;label\u0026gt;\u0026#34; [x [, y]] 例: x軸の名前を「経過時間(ms)」にする set xlabel \u0026#34;経過時間(ms)\u0026#34; 好きな位置にラベルを表示する set label \u0026#34;\u0026lt;label\u0026gt;\u0026#34; x, y y 軸のラベルを回転させて表示する set ylabel=\u0026#34;\\rotate=270 ylabel\u0026#34; ※拡張版 gnuplot のみ対応。"
},
{
url: "/p/yfow6dk/",
title: "ESLint + Prettier の設定方法まとめ",
date: "2021-05-23T00:00:00Z",
body: "ESLint + Prettier の設定方法まとめ ここでは、とにかく混乱しがちな ESLint + Prettier の設定方法をまとめておきます。 まず、基本的な構成として、TypeScript (with React) の Lint をかけられるようにして、必要に応じて Airbnb スタイル を追加で設定する、という流れにしたいと思います。 TypeScript プロジェクトの準備 前提条件として、TypeScript (+ React) のプロジェクト自体は作成済みとします。 何も準備できていなければ、Next.js の create-next-app コマンドを使うと簡単に作成できます（typescript および @types/node、@types/react、@types/react-dom などの型情報が導入された状態のプロジェクトが作成されます）。 2 つやり方あるけど、大体中身は同じ # テンプレートを使う方法 $ create-next-app myapp --example with-typescript # typescript オプションを使う方法 $ create-next-app myapp --typescript 参考リンク Next.js で HelloWorld（プロジェクト作成からサーバー起動まで） Next.js のプロジェクトを TypeScript 化する Prettier + ESLint の基本設定 (for TypeScript with React) 必要なパッケージのインストール # Prettier 本体 $ yarn add --dev --exact prettier # ESLint 本体 $ yarn add --dev eslint # ESLint 用のプラグインおよび共有設定 $ yarn add --dev @typescript-eslint/eslint-plugin $ yarn add --dev @typescript-eslint/parser $ yarn add --dev eslint-plugin-react $ yarn add --dev eslint-plugin-react-hooks $ yarn add --dev eslint-config-prettier # npm スクリプトの並列実行用 $ yarn add --dev npm-run-all npm の場合 # Prettier 本体 $ npm install prettier --save-dev --save-exact # ESLint 本体 $ npm install eslint --save-dev # ESLint 用のプラグインおよび共有設定 $ npm install @typescript-eslint/eslint-plugin --save-dev $ npm install @typescript-eslint/parser --save-dev $ npm install eslint-plugin-react --save-dev $ npm install eslint-plugin-react-hooks --save-dev $ npm install eslint-config-prettier --save-dev # npm スクリプトの並列実行用 $ npm install npm-run-all --save-dev .prettierrc（必要に応じて Prettier フォーマット設定） semi:false# 行末のセミコロンは省略するsingleQuote:true# 引用符にはシングルクォートを使う .prettierignore（Prettier の無視設定） .next/ build/ *.html .eslintrc.yml（ESLint 設定） root:trueenv:browser:truees2021:trueextends:- eslint:recommended- plugin:react/recommended- plugin:react-hooks/recommended- plugin:@typescript-eslint/recommended- plugin:@typescript-eslint/recommended-requiring-type-checking- prettierparser:\u0026#34;@typescript-eslint/parser\u0026#34;parserOptions:ecmaVersion:12ecmaFeatures:jsx:trueproject:./tsconfig.jsonplugins:- react- react-hooks- \u0026#34;@typescript-eslint\u0026#34;rules:react/react-in-jsx-scope:off package.json（npm スクリプト設定） // ... scripts: { \u0026#34;lint\u0026#34;: \u0026#34;run-p -c -l lint:**\u0026#34;, \u0026#34;lint:prettier\u0026#34;: \u0026#34;prettier --check .\u0026#34;, \u0026#34;lint:eslint\u0026#34;: \u0026#34;eslint . --ext .ts,.tsx\u0026#34;, \u0026#34;lint:tsc\u0026#34;: \u0026#34;tsc\u0026#34;, \u0026#34;fix\u0026#34;: \u0026#34;run-s -l fix:**\u0026#34;, \u0026#34;fix:prettier\u0026#34;: \u0026#34;prettier --write .\u0026#34;, \u0026#34;fix:eslint\u0026#34;: \u0026#34;eslint . --ext .ts,.tsx --fix\u0026#34;, これで、次のようにして Prettier + ESLint による Lint チェックと自動修正をかけられるようになります。 Prettier と ESLint の実行 # yarn の場合 $ yarn lint # Lint チェック $ yarn fix # 自動修正 # npm の場合 $ npm run lint # Lint チェック $ npm run fix # 自動修正 fix を実行すると多数のファイルが自動修正されることになるので、lint が実行できた段階で、一度 Git へ設定をコミットしておくことをオススメします。 ts/tsx ファイルを src ディレクトリにまとめる Next.js 9.1 からは、pages ディレクトリを src/pages というパスで作成できるようになりました。 next コマンドは、プロジェクトのルートに pages が見つからないとき、src/pages を参照してくれます。 この仕組みを利用すると、.ts、.tsx ファイルは全て src ディレクトリ以下にまとめられるので、プロジェクトのルートディレクトリがスッキリします。 ただし、tsconfig.json や public ディレクトリは、これまで通りルートディレクトリに配置する必要があります。 .ts/.tsx ファイルの入ったディレクトリを src 以下にまとめる $ mkdir src $ git mv components src $ git mv interfaces src $ git mv pages src $ git mv utils src あとは、各種コマンドの対象パスなどを変更すれば OK です。 package.json \u0026#34;scripts\u0026#34;: { \u0026#34;lint\u0026#34;: \u0026#34;run-p -c -l lint:**\u0026#34;, - \u0026#34;lint:prettier\u0026#34;: \u0026#34;prettier --check .\u0026#34;, - \u0026#34;lint:eslint\u0026#34;: \u0026#34;eslint . --ext .ts,.tsx\u0026#34;, + \u0026#34;lint:prettier\u0026#34;: \u0026#34;prettier --check src\u0026#34;, + \u0026#34;lint:eslint\u0026#34;: \u0026#34;eslint src --ext .ts,.tsx\u0026#34;, \u0026#34;lint:tsc\u0026#34;: \u0026#34;tsc\u0026#34;, \u0026#34;fix\u0026#34;: \u0026#34;run-s -l fix:**\u0026#34;, - \u0026#34;fix:prettier\u0026#34;: \u0026#34;prettier --write .\u0026#34;, - \u0026#34;fix:eslint\u0026#34;: \u0026#34;eslint . --ext .ts,.tsx --fix\u0026#34;, + \u0026#34;fix:prettier\u0026#34;: \u0026#34;prettier --write src\u0026#34;, + \u0026#34;fix:eslint\u0026#34;: \u0026#34;eslint src --ext .ts,.tsx --fix\u0026#34;, tsconfig.json \u0026#34;target\u0026#34;: \u0026#34;esnext\u0026#34; }, \u0026#34;exclude\u0026#34;: [\u0026#34;node_modules\u0026#34;], - \u0026#34;include\u0026#34;: [\u0026#34;**/*.ts\u0026#34;, \u0026#34;**/*.tsx\u0026#34;] + \u0026#34;include\u0026#34;: [\u0026#34;src/**/*.ts\u0026#34;, \u0026#34;src/**/*.tsx\u0026#34;] } ここまでの結果をテンプレートにする ここで作成したプロジェクトを GitHub にプッシュしておけば、create-next-app コマンドのテンプレートとして使用できるようになります。 次のように、--example オプションで GitHub リポジトリの URL を指定するだけで OK です。 例: TypeScript、ESLint、Prettier 設定済みのプロジェクトを生成 $ create-next-app myapp --example \\ https://github.com/maku77/template-nextjs-ts-eslint-prettier Airbnb スタイルを追加導入する JavaScript のコーディングスタイルとしては、Airbnb のスタイルが有名です。 ここでは、前述の基本的な ESLint + Prettier 設定が終わっている想定で、追加で Airbnb スタイルを導入してみます。 Airbnb は ESLint 用の eslint-config-airbnb 共有設定を用意しているのですが、これをそのまま使うと TypeScript 用のカスタマイズが厄介なので、最初から TypeScript 用の対応が入った eslint-config-airbnb-typescript を使うことにします。 公式サイトを見ると、eslint-config-airbnb-typescript の依存パッケージとして下記が必要ということが分かるので、まだインストールしていないものを追加でインストールします。 eslint-plugin-import eslint-plugin-jsx-a11y eslint-plugin-react （インストール済み） eslint-plugin-react-hooks （インストール済み） @typescript-eslint/eslint-plugin （インストール済み） eslint-config-airbnb-typescript のインストール $ yarn add --dev eslint-config-airbnb-typescript $ yarn add --dev eslint-plugin-import $ yarn add --dev eslint-plugin-jsx-a11y npm の場合 $ npm install eslint-config-airbnb-typescript --save-dev $ npm install eslint-plugin-import --save-dev $ npm install eslint-plugin-jsx-a11y --save-dev .eslintrc.yml（airbnb-typescript を使うよう修正） root:trueenv:browser:truees2021:trueextends:- airbnb-typescript- prettierparser:\u0026#34;@typescript-eslint/parser\u0026#34;parserOptions:ecmaFeatures:jsx:trueecmaVersion:12project:./tsconfig.jsonplugins:- react- \u0026#34;@typescript-eslint\u0026#34;rules:react/react-in-jsx-scope:off# JSX 用の React インポートエラー抑制 実行方法はこれまで通りで変化なしです（npm run lint と npm run fix）。 ESLint と Prettier の設定で気を付けること ESLint および Prettier の設定のポイントや、ハマりがちなことをまとめておきます。 TypeScript 型情報のチェックを ESLint で行う @typescript-eslint/eslint-plugin プラグインが提供する recommended-requiring-type-checking という共有設定を有効にすると、TypeScript の型情報を利用した Lint チェックを行うことができます。 このとき、内部では TypeScript コンパイラが使用されるため、parserOptions.project で tsconfig.json ファイルの位置を知らせてやる必要があります（指定しないとエラーになります）。 .eslintrc.yml root:trueparser:\u0026#39;@typescript-eslint/parser\u0026#39;parserOptions:ecmaVersion:2021project:./tsconfig.json # ★型チェックに必要plugins:- \u0026#39;@typescript-eslint\u0026#39;extends:- eslint:recommended- plugin:@typescript-eslint/recommended- plugin:@typescript-eslint/recommended-requiring-type-checking # ★型チェック TypeScript の型チェックを行うよう設定すると、追加で TypeScript コンパイラが動作するようになるため、ESLint の実行に時間がかかるようになります。 tsconfig.json の情報をそのまま使うのではなく、ESLint 用に tsconfig.eslint.json を作成してパフォーマンス向上させる方法が提案されています。 いずれにしても、型チェックの仕組みはあまり洗練されているとは言えないので、型チェックに関しては TypeScript コードの tsc ビルド時にだけ行うと割り切ってもいいかもしれません（VS Code デフォルトの検出機能もあります）。 参考リンク typescript-eslint - Getting Started - Linting with Type Information TypeScript / Prettier の設定は後ろへ .eslintrc.yml plugin:- react- @typescript-eslintextends:- eslint:recommended- plugin:react/recommended- plugin:@typescript-eslint/recommended- plugin:@typescript-eslint/recommended-requiring-type-checking TypeScript 用の共有設定 plugin:@typescript-eslint/recommended は、eslint:recommended などにより定義されるルールのうち、TypeScript と競合するものを解決してくれます。 なので、TypeScript に関する設定は extends の中で最後の方に指定して設定を上書きする必要があります。 具体的には、plugin:@typescript-eslint/eslint-recommended がこの競合を解決するものであり、plugin:@typescript-eslint/recommended から利用されています。 同様に、コードフォーマッターの Prettier を使用する場合は、Prettier が自動修正してくれる部分を ESLint が指摘しないように、一番最後に eslint-config-prettier 関連の共有設定を指定する必要があります。 extends:- eslint:recommended- plugin:react/recommended- plugin:@typescript-eslint/recommended- plugin:@typescript-eslint/recommended-requiring-type-checking- prettier 参考リンク typescript-eslint/typescript-eslint - Usage with prettier Airbnb スタイルは React 込み .eslintrc.yml extends: - - eslint:recommended - - plugin:react/recommended + - airbnb + - airbnb/hooks extends プロパティで airbnb (eslint-config-airbnb) を指定する場合、eslint:recommended や plugin:react/recommeded の設定は airbnb 側でほぼカバーされるので、指定する必要はありません。 逆に、React を使わない場合は、eslint-config-airbnb ではなく eslint-config-airbnb-base の方を使います。 eslint-config-airbnb が依存するパッケージを調べる .eslintrc.* ファイルの extends プロパティで airbnb を指定するには、あらかじめ eslint-config-airbnb パッケージをインストールするだけでなく、その依存パッケージ (peerDependencies) もインストールしておく必要があります。 依存パッケージは次のように確認することができます。 $ npm info \u0026#34;eslint-config-airbnb@latest\u0026#34; peerDependencies { eslint: \u0026#39;^5.16.0 || ^6.8.0 || ^7.2.0\u0026#39;, \u0026#39;eslint-plugin-import\u0026#39;: \u0026#39;^2.22.1\u0026#39;, \u0026#39;eslint-plugin-jsx-a11y\u0026#39;: \u0026#39;^6.4.1\u0026#39;, \u0026#39;eslint-plugin-react\u0026#39;: \u0026#39;^7.21.5\u0026#39;, \u0026#39;eslint-plugin-react-hooks\u0026#39;: \u0026#39;^4 || ^3 || ^2.3.0 || ^1.7.0\u0026#39; }"
},
{
url: "/p/mdyedwq/",
title: "LUIS (2) LUIS のオーサリングキー、エンドポイントキーとは",
date: "2019-03-14T00:00:00Z",
body: "LUIS (2) LUIS のオーサリングキー、エンドポイントキーとは LUIS アプリで使用するキーの種類には、オーサリングキー (Authoring Key) とエンドポイントキー (Endpoint Key) の 2 種類があります。 オーサリングキー (Authoring Key) オーサリングキーは LUIS アカウントの作成時に自動的に作成される、無料のキーです。 オーサリングキーはリージョン内で共通であり、1 つだけ作成されます。 最初に作成されるので、スターターキー (Starter Key)、作成者キーとも呼ばれます。 オーサリングキーは、LUIS アカウントに結び付けられているので、LUIS 右上のアカウント名をクリックし、Settings を選択することで確認できるようになっています。 オーサリングキーは、LUIS アプリ自体の作成や、公開、コラボレーターの管理、バージョン管理などを行うときに必要になります。 つまり、あなたが作成する LUIS アプリの管理用のキーであり、LUIS の Web サイトで行えることほぼすべてをこのキーを使ったオーサリング API 経由で行えます。 LUIS ポータル上にログインして作業している間は、オーサリングキーの存在を意識しなくても LUIS アプリの管理を行うことができますが、Web API を使って LUIS アプリの管理作業を自動化したいときなどにオーサリングキーが必要になります。 作成した個々の LUIS アプリに対するクエリ実行のためにもオーサリングキーを使用できますが、これは実装中のテスト用途に限られます（権限の強いオーサリングキーを、公開アプリからのクエリ用途に使うのは避けるべきです）。 実運用でのクエリ実行は、後述のエンドポイントキーを使用します。 ちなみに、オーサリングキーは Microsoft のユーザアカウントごとに割り当てられるものです。 LUIS アプリのコラボレータとして登録されたユーザは、自分のオーサリングキーを使って LUIS アプリの管理を行います。 エンドポイントキー (Endpoint Key) 運用環境で LUIS アプリに対するクエリ実行を行うには、Azure の LUIS リソースとして作成されたエンドポイント URL とエンドポイントキーを使用します。 Azure ポータル にログインして、LUIS リソースを作成することでエンドポイントキーを取得できます。 Azure 上の LUIS リソースは、1 つのリソースグループに所属し、そのリソースグループは 1 つのサブスクリプションに所属します。 毎月の課金はサブスクリプションに対して行われます。 階層的には下記のような感じで LUIS リソースが配置されているイメージです。 Azureアカウント └ サブスクリプション └ リソースグループ └ LUISリソース ← LUISポータルで作成したアプリをこのリソースで動かす Azule ポータルで作成した LUIS リソースに割り当てられたエンドポイントキーは、Azure ポータルの LUIS (Language Understanding) リソースの Keys のページで確認することができます。 Azure のリソースにアクセスするためのキーなので、リソースキーと呼ばれることもあります。 それにしても、キーの呼び名が統一されてなくてわかりにくいですね。。。 LUIS ポータルで LUIS アプリを Azure リソースに結びつける 実運用で LUIS アプリへのクエリをかける場合、Azure ポータルで作成した LUIS リソース上で LUIS アプリを稼働させる必要があります（正確には LUIS リソースを作成した時点で稼働しているので、Azure の LUIS リソースのエンドポイントを、LUIS アプリと関連付けるというのが正しいです）。 ユーザ → Azure の LUIS リソース ⇔ LUIS アプリ LUIS ポータルで MANAGE タブ → Keys and Endpoints と辿ると、デフォルトでは 1 つのエンドポイント (URL) がリソース名 Starter_Key というリソースで動作するように登録されています。 これは、LUIS アプリ管理用のエンドポイントであり、オーサリングキー（スターターキー）を使用して API 呼び出しを行えるようになっています（アプリ自体の管理や、クエリのテスト実行に使用する）。 この、Starter_Key というリソースは LUIS ポータル上で LUIS アプリを作成すると自動的に作成されるため、Azure ポータル上で LUIS リソースを割り当てなくても最初から API 呼び出しができるようになっています。 ただし、実運用で LUIS アプリを使用するときは、Azure 上で作成した LUIS リソースを、この LUIS アプリに結び付けなければいけません。 ＋Assign resources ボタンを押すと、Azure 上の LUIS リソースを関連付けるためのダイアログが表示されます。 LUIS resource name というところで、結び付けたい Azure の LUIS リソース名を選択します。 すると、Endpoint Keys の一番下のところに、Azure の LUIS リソースを使うためのエンドポイント URL と、エンドポイントキーのペアが登録されます。 ここに表示されるエンドポイントキーは、Azure ポータル上の LUIS リソースに設定されているエンドポイントキーと同じ値になっているはずです。 これで、Azure の LUIS リソースのエンドポイントへのアクセスが、この LUIS アプリに関連付けられて動作するようになります。 全体的には下記のようなイメージでつながっていると考えるとわかりやすいです。 まず、LUIS ポータルは LUIS アプリを作成することを一番の目的としていますが、同時に、そのアプリ自体を管理するためのエンドポイントとして Starter_Key というリソースが自動的に生成されます。 管理者はこのリソースに対してオーサリングキーでアクセスして LUIS アプリの管理を行えます。 一方で、一般クライアント（Skype チャネルや Slack チャネルなど）からは、Azure ポータルに作成した LUIS リソース経由で LUIS アプリを使います。 このとき使用するキーは、Azure ポータルの LUIS リソースに対して発行されたエンドポイントキーで、クエリ用途に特化されています。 ちなみに、LUIS アプリに他の開発者をコラボレータとして登録した場合は、コラボレータから見ると、エンドポイントのリストのところに、This app has 1 collaborator key(s) you do not have permission to view. のように表示されるようです。 このあたり複数人コラボレータがいても 1 collaborator と表示されたり、若干不安定なところがありますが、少なくともコラボレータからは、LUIS アプリのオーナー（作成者）が管理しているエンドポイントの情報は見えないようになっているようです。"
},
{
url: "/p/tewj3gs/",
title: "LUIS (3) Node.js から LUIS の API を利用する",
date: "2019-03-14T00:00:00Z",
body: "LUIS (3) Node.js から LUIS の API を利用する LUIS API を呼び出すためのエンドポイント情報を調べる LUIS アプリの Publish REST API 経由で LUIS アプリによる発話解析を行うには、LUIS ポータル上で対象の LUIS アプリを Train し、Publish しておく必要があります（LUIS アプリというのは、いわゆる訓練されたモデルのことだと考えるとよいです）。 API 実行用のエンドポイント URL とキーを確認する Publish 処理が完了すると、エンドポイント URL と エンドポイントキー (Endpoint key) を使って、LUIS アプリに対してクエリ要求を投げることができるようになります。 テスト用途であれば、LUIS ポータル上で最初に作成される オーサリングキー (Authoring key) でもクエリを実行できますが、最終的なユーザ環境でのクエリ実行には Azure 上で作成したリソースに付けられたエンドポイント URL とエンドポイントキーのペアを使用する必要があります。 参考: オーサリングキー、エンドポイントキーとは LUIS の REST API を呼び出すための URL は、下記のような情報から構成されています（下記例の ID はデタラメです）。 Application ID: 5c548551-f6ba-4fc8-c695-529ac194317d Application version: 0.1 エンドポイントキー: ff824a1409f929c8e2a15301ccff431d Application ID と Application version は、MANAGE タブの Application Information のページで確認することができます。 エンドポイントキーは、MANAGE タブの Keys and Endpoints のページで確認することができます。 下記の例では、2 つのエンドポイントが登録されています。 エンドポイント URL でアクセスする先の実体はリソースとして管理されており、2 つのリソース上で LUIS アプリが動作していると考えることができます。 左端のカラムはリソース名です。 下の Starter_Key という名前のリソースは、LUIS アプリを作成したときに自動的に作られるオーサリング用（管理用）のリソース／エンドポイントです。 オーサリング API は、各 LUIS ユーザに割り当てられたオーサリングキーを使って呼び出すことになるため、ここのキー情報（Key 1 カラム）としては、LUIS ユーザのオーサリングキーが表示されています。 オーサリングキーは 1 つしかないので、ここの表示も 1 つだけになっています。 その上の、maku-luis-resoure という名前のリソースは、Azure 上に作成した LUIS リソースへアクセスするためのエンドポイント情報で、上にある Assign resource ボタンを使って LUIS アプリにあらかじめ関連付けしておいたリソースです。 ここに表示されるキー情報や、エンドポイント URL は、Azure ポータルで作成した LUIS リソースにより提供されているものです。 Azure 上の LUIS リソースにはデフォルトで 2 つのエンドポイントキーが割り当てられるため、ここの表示も 2 つになっています。 Web ブラウザで LUIS API を呼び出してみる LUIS のドキュメントなどで登場する「予測クエリ」という単語は、LUIS の基本機能となる、発話テキストからのインテント＆エンティティへの変換機能を意味しています。 この予測クエリ REST API を実行するためのアドレス (URL) は、MANAGE タブの Keys and Endpoints のページの Endpoint の欄で確認することができます。 上記の例では、2 つのリソースの Endpoint となる URL が表示されていますが、それぞれ次のようなアドレスになっています。 Azure LUIS リソース側のアドレス https://japaneast.api.cognitive.microsoft.com/luis/v2.0/apps/＜AppID＞?verbose=true\u0026amp;timezoneOffset=-360\u0026amp;subscription-key=＜EndpointKey＞\u0026amp;q= Starter_Key リソース側のアドレス https://westus.api.cognitive.microsoft.com/luis/v2.0/apps/＜AppID＞?verbose=true\u0026amp;timezoneOffset=-360\u0026amp;subscription-key=＜EndpointKey＞\u0026amp;q= Azure 上の LUIS リソース maku-luis-resource のリージョン（上記の例では japaneast）と、LUIS アプリのオーサリング用の Starter_Key リソースのリージョン（上記の例では westus）が異なっていることに注意してください。 このあたりの、Azure におけるリソースのリージョン配置に関してはいろいろと制約があるようなので、なるべく最新のドキュメントを確認するようにしてください。 予測クエリ用の REST API に関する詳細は下記のドキュメントに記載されています。 LUIS - Endpoint API このアドレスの末尾部分（q= の後ろ）に、発話テキストをつなげる形で HTTP GET リクエストを送れば、LUIS アプリによって解析された結果が JSON 形式のテキストで返ってきます。 HTTP GET なので、Web ブラウザのアドレス欄に直接入力してテストすることができます。 例えば、下記のようなアドレスを Web ブラウザから開けば、Web ブラウザ上に解析結果の JSON テキストが表示されます。 ここでは、「XYZって何？」という発話テキストを送信しています。 https://japaneast.api.cognitive.microsoft.com/luis/v2.0/apps/855c5451-fa6b-8f4c-c695-194157d293ac?verbose=true\u0026amp;timezoneOffset=-360\u0026amp;subscription-key=55bb936a080577af2124fbb86be43123\u0026amp;q=XYZって何？ ☝️ ワンポイント 「XYZって何？」というテキストは実際には URL エンコードした状態で HTTP GET リクエストで送信しなければいけませんが、Web ブラウザのアドレス欄に入力した場合は自動的に URL エンコード処理が行われるため、特に意識する必要はありません。 プログラムから HTTP GET リクエストを実行するときは、明示的に URL エンコード処理を行ってください。 結果の例 { \u0026#34;query\u0026#34;: \u0026#34;XYZって何？\u0026#34;, \u0026#34;topScoringIntent\u0026#34;: { \u0026#34;intent\u0026#34;: \u0026#34;SearchMeaning\u0026#34;, \u0026#34;score\u0026#34;: 0.921842635 }, \u0026#34;intents\u0026#34;: [ { \u0026#34;intent\u0026#34;: \u0026#34;SearchMeaning\u0026#34;, \u0026#34;score\u0026#34;: 0.921842635 }, { \u0026#34;intent\u0026#34;: \u0026#34;None\u0026#34;, \u0026#34;score\u0026#34;: 0.0479163341 } ], \u0026#34;entities\u0026#34;: [ { \u0026#34;entity\u0026#34;: \u0026#34;xyz\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;Word\u0026#34;, \u0026#34;startIndex\u0026#34;: 0, \u0026#34;endIndex\u0026#34;: 2, \u0026#34;score\u0026#34;: 0.5719831 } ] } 2 つのエンドポイントは同じ LUIS アプリに関連付けられているため、どちらの URL を使用して API 呼び出ししても同じ結果が返ってきます。 テストの段階では Starter_Key リソースの方のエンドポイント URL を使用してもよいのですが、ユーザーに提供するアプリケーションから LUIS API を呼び出すときは、必ず Azure 上の LUIS リソースの方のエンドポイント URL を使うようにしてください。 Starter_Key リソースの方のキー（オーサリングキー）が漏れると、予測クエリ API だけではなく、LUIS アプリ管理用の API が実行されてしまいます。 オーサリング API を呼び出す LUIS API には、LUIS アプリ自体を管理するためのオーサリング API もたくさん用意されています。 LUIS - Authoring API こちらのオーサリング API を呼び出す場合は、クエリ API とは異なり、エンドポイントキーとしてオーサリングキーを使用しなければいけないことに注意してください。 エンドポイント URL も、LUIS ポータルで Starter_Key リソースに割り当てられている URL を使わなければいけません。 URL の構成もクエリ用 API のものとは若干異なっています。 例えば、下記のアドレスは、指定した LUIS アプリに登録されているインテントの一覧を取得する REST API のアドレスです。 https://[location].api.cognitive.microsoft.com/luis/api/v2.0/apps/{appId}/versions/{versionId}/intents また、オーサリング API を呼び出すときには、Ocp-Apim-Subscription-Key: という HTTP ヘッダでオーサリングキーを付加して呼び出す必要があります（ちなみに、クエリ API の場合も、エンドポイントキーをクエリパラメータではなく、このヘッダ情報として送ることができます）。 下記は、Linux の curl コマンドを使ってインテントの一覧を取得する LUIS API を呼び出す例です。 例: 登録されているインテントの一覧を取得（ID はデタラメです） curl -s -k -X GET https://westus.api.cognitive.microsoft.com/luis/api/v2.0/apps/c5548551-6bfa-8f4c-695c-512919d34ac7/versions/0.1/intents -H \u0026#39;Ocp-Apim-Subscription-Key: 1408fd8e319434ccff15afa2214930f4\u0026#39; 正常なレスポンスの例 [{\u0026#34;id\u0026#34;:\u0026#34;2e900016-9a0e-4704-bf99-7392a68767c0\u0026#34;,\u0026#34;name\u0026#34;:\u0026#34;None\u0026#34;,\u0026#34;typeId\u0026#34;:0,\u0026#34;readableType\u0026#34;:\u0026#34;Intent Classifier\u0026#34;},{\u0026#34;id\u0026#34;:\u0026#34;04082f4d-6b63-4058-a976-4289786821e4\u0026#34;,\u0026#34;name\u0026#34;:\u0026#34;SearchMeaning\u0026#34;,\u0026#34;typeId\u0026#34;:0,\u0026#34;readableType\u0026#34;:\u0026#34;Intent Classifier\u0026#34;}] None インテントと SearchMeaning インテントの情報が返ってきていることを確認できます。 ちなみに、正しいオーサリングキーを使わずに API を呼び出すと、次のようなエラーレスポンスが返ってきます。 エラーレスポンスの例 { \u0026#34;statusCode\u0026#34;: 401, \u0026#34;message\u0026#34;: \u0026#34;Access denied due to invalid subscription key.Make sure to provide a valid key for an active subscription.\u0026#34; } Node.js から LUIS の REST API を呼び出す Node.js から HTTP GET リクエストを送って JSON レスポンスを取得してみます。 HTTP リクエストを行うためのモジュールとして、ここでは request モジュールを使用します。 JavaScript ファイルを作成するディレクトリと同じディレクトリ内で、下記のようにインストールしておいてください。 $ npm install request 下記のサンプルコードは、コマンドライン引数で入力した「発話テキスト」を LUIS API のリクエストとして送り、その結果を標準出力へ出力します。 ここでは、エンドポイントキーを Ocp-Apim-Subscription-Key ヘッダとして送っています。 luis.js const HOST_NAME = \u0026#39;https://japaneast.api.cognitive.microsoft.com\u0026#39;; const LUIS_APP_ID = \u0026#39;xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\u0026#39;; const ENDPOINT_KEY = \u0026#39;xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\u0026#39;; // request モジュールの初期化 const request = require(\u0026#39;request\u0026#39;).defaults({ headers: { \u0026#39;Ocp-Apim-Subscription-Key\u0026#39;: `${ENDPOINT_KEY}` }, // HTTP プロキシをハードコードする場合（HTTP_PROXY 環境変数でも設定可） // proxy: \u0026#39;http://proxy.example.com:23400/\u0026#39; }) // GET リクエスト用のデータを作成する function createRequest(text) { const q = encodeURIComponent(text); return { uri: `${HOST_NAME}/luis/v2.0/apps/${LUIS_APP_ID}?verbose=true\u0026amp;timezoneOffset=-360\u0026amp;q=${q}` } } // LUIS からのレスポンスを処理する（標準出力に出力するだけ） function onResponse(err, res, body) { if (err) { console.error(\u0026#39;Error: \u0026#39; + err.message); return; } console.log(body); } // エントリポイント（REST API を呼び出す） (function main() { const text = process.argv[2] request.get(createRequest(text), onResponse); })(); 実行例 $ node luis.js \u0026#34;XYZ って何？\u0026#34; { \u0026#34;query\u0026#34;: \u0026#34;XYZ って何？\u0026#34;, \u0026#34;topScoringIntent\u0026#34;: { \u0026#34;intent\u0026#34;: \u0026#34;SearchMeaning\u0026#34;, \u0026#34;score\u0026#34;: 0.921842635 }, \u0026#34;intents\u0026#34;: [ { \u0026#34;intent\u0026#34;: \u0026#34;SearchMeaning\u0026#34;, \u0026#34;score\u0026#34;: 0.921842635 }, { \u0026#34;intent\u0026#34;: \u0026#34;None\u0026#34;, \u0026#34;score\u0026#34;: 0.0479163341 } ], \u0026#34;entities\u0026#34;: [ { \u0026#34;entity\u0026#34;: \u0026#34;xyz\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;Word\u0026#34;, \u0026#34;startIndex\u0026#34;: 0, \u0026#34;endIndex\u0026#34;: 2, \u0026#34;score\u0026#34;: 0.5719831 } ] }"
},
{
url: "/p/zsdpkyg/",
title: "gnuplot: 凡例（ラインの名前）を表示する",
date: "2004-01-03T00:00:00Z",
body: "gnuplot: 凡例（ラインの名前）を表示する 凡例の名前を変える Syntax plot \u0026lt;expression\u0026gt; title \u0026#39;\u0026lt;線の名前\u0026gt;\u0026#39; 例 plot 0.5*x title \u0026#34;my line\u0026#34; title オプションは、with オプションよりも前に指定する必要があります。 凡例を消す set nokey 全ての凡例を消すには set nokey を実行します。 線ごとに凡例を消すには plot のオプションで notitle を指定します。 例: 特定のラインだけ凡例を消す plot 0.5*x notitle, -0.5*x 凡例と線種の表示順を逆にする set key reverse 凡例を四角で囲む set key box 四角を消したくなった場合は nobox をセットします。 set key nobox 凡例の行間を変える set key spacing \u0026lt;倍率\u0026gt; 凡例に表示する線の長さを変える set key samplen \u0026lt;長さ\u0026gt; 線の長さは文字数で指定します。 例えば 10 と指定した場合は 10 文字分の長さになります。 凡例の表示位置を指定する Syntax set key \u0026lt;y 座標\u0026gt;, \u0026lt;y 座標\u0026gt; set key left | right | top | bottom 例: 凡例を (100, 100) に表示 set key 100,100 例: 凡例を右下に表示 set key right bottom"
},
{
url: "/p/dexgg8o/",
title: "ESLint (4) ESLint の設定方法まとめ (for Next.js 11)",
date: "2021-07-19T00:00:00Z",
body: "ESLint (4) ESLint の設定方法まとめ (for Next.js 11) Next.js 11 が ESLint を組み込みサポート Next.js 11 で ESLint を Next.js が組み込みでサポートしました。 これで、create-next-app で新規作成するアプリでは、ESLint に関してもゼロコンフィグで next eslint とするだけで実行できるようになります。 ただ、ESLint には色々な共有設定 (config) があるわけで、Next.js がデフォルトで設定してくれているもの以外（TypeScript や Prettier 関連）は自分で設定する必要があります。 ここでは、Next.js 11 がデフォルトで提供する .eslintrc にそれらの設定を追加します。 Next.js 11 デフォルトの ESLint 設定 Next.js 11 が生成する .eslintrc ファイルは次のようなシンプルなものです。 .eslintrc { \u0026#34;extends\u0026#34;: [\u0026#34;next\u0026#34;, \u0026#34;next/core-web-vitals\u0026#34;] } 問題はこれらがどのような共有設定を含んでいるかですが、eslint-config-next のコードを見ると、次のような感じになっています。 module.exports = { extends: [ \u0026#39;plugin:react/recommended\u0026#39;, \u0026#39;plugin:react-hooks/recommended\u0026#39;, \u0026#39;plugin:@next/next/recommended\u0026#39;, ], // ... } React 系の共有設定はここに含まれているので、\u0026quot;extends\u0026quot;: [\u0026quot;next\u0026quot;] だけでカバーできそうです。 公式ドキュメントの ESLint - Base Configuration にも同様の説明が書かれています。 逆に、TypeScript 関連や、Prettier 関連の共有設定は自分で追加しなければいけません。 ESLint 設定を追加する ここでは、下記のような ESLint extends 設定を手動で追加してやります。 ESLint 推奨 (eslint:recommended) TypeScript 関連 (plugin:@typescript-eslint/recommended*) Prettier 関連 (prettier) eslint:recommeded 以外は外部パッケージとして提供されているので、先にインストールしておきます。 必要なパッケージ（Plugin \u0026amp; Config）のインストール $ yarn add --dev @typescript-eslint/eslint-plugin $ yarn add --dev eslint-config-prettier そして、ESLint 設定ファイルを次のように書き換えてやります。 Yaml 形式の方が記述が楽なので、.eslintrc を .eslintrc.yml に置き換えています。 .eslintrc.yml # これがルートの設定ファイル（上位ディレクトリを検索しない）root:trueextends:- eslint:recommended- plugin:@typescript-eslint/recommended- plugin:@typescript-eslint/recommended-requiring-type-checking- next- next/core-web-vitals- prettierparserOptions:# extends で指定している# plugin:@typescript-eslint/recommended-requiring-type-checking# に対して型情報を提供するため tsconfig.json の場所を指定。project:./tsconfig.json あとは、next lint で実行すればよさそうですが、プロジェクト内の TypeScript 型情報に関する警告 (plugin:@typescript-eslint/recommended-requiring-type-checking) を有効にするには、eslint コマンドを直接実行しないといけないみたいです（next lint では全ての警告が出ない…）。 $ npx eslint src --ext .ts,.tsx いずれにしても、最終的には、package.json の中で次のような感じで npm-scripts を定義して、yarn lint (npm run lint) コマンド一発で各種 Lint ツールをまとめて実行できるようにしておくのがよいです。 package.json（抜粋） { \u0026#34;scripts\u0026#34;: { // ... \u0026#34;lint\u0026#34;: \u0026#34;run-p -c -l lint:**\u0026#34;, \u0026#34;lint:prettier\u0026#34;: \u0026#34;prettier --check src\u0026#34;, \u0026#34;lint:eslint\u0026#34;: \u0026#34;eslint src --ext .ts,.tsx\u0026#34;, \u0026#34;lint:tsc\u0026#34;: \u0026#34;tsc\u0026#34;, \u0026#34;fix\u0026#34;: \u0026#34;run-s -l fix:**\u0026#34;, \u0026#34;fix:prettier\u0026#34;: \u0026#34;prettier --write src\u0026#34;, \u0026#34;fix:eslint\u0026#34;: \u0026#34;eslint src --ext .ts,.tsx --fix\u0026#34;, // ... 上記で使用している run-p や run-s は、複数の npm-scripts を並列 or 順次実行するためのコマンドで、npm-run-all パッケージをインストールすると使えるようになります。 $ yarn add npm-run-all --dev"
},
{
url: "/p/dtwckb9/",
title: "LUIS (4) botbuilder-ai ライブラリを使って LUIS の API を利用する",
date: "2019-04-18T00:00:00Z",
body: "LUIS (4) botbuilder-ai ライブラリを使って LUIS の API を利用する こちらの記事（Node.js から LUIS の API を利用する） では、自力で LUIS の REST API を呼び出すための URL を構築していました。 ここでは、botbuilder-ai パッケージを使用して、もっと手軽に LUIS の機能を呼び出してみます。 ☝️ ワンポイント 残念ながら botbuilder-ai が提供している LuisRecognizer などのクラスは、チャットボットの実装に使用する TurnContext オブジェクトに依存した設計になっています。 そのため、単純なコンソールアプリケーションから botbuilder-ai パッケージを使用することは難しく、チャットボットの実装でしか利用できません。 LUIS のエンドポイント情報（接続情報）を確認しておく LUIS API を使用するには、下記のような LUIS アプリの APP ID やエンドポイント情報が必要です。 APP ID: c39eb4df-fbcf-224f-b8b7-a0ee445d11b3 エンドポイント: https://japaneast.api.cognitive.microsoft.com エンドポイントキー（サブスクリプションキー）: c9162c5c0b5edff5270feb6145618acb APP ID とエンドポイントキーは、LUIS ポータル から対象のアプリケーションを開き、下記のように確認できます。 APP ID: MANAGEタブ → Application Information エンドポイント: MANAGEタブ → Keys and Endpoints → Endpoint カラムの URL の前半部分。 エンドポイントキー: MANAGEタブ → Keys and Endpoints → Key 1 カラム LUIS のエンドポイントキーは、Azure ポータル に作成した LUIS リソース の キー の項目に表示されるものと同じです。 念のため、同一のものが表示されているか確認しておくとよいでしょう。 ☝️ ワンポイント LUIS ポータル上の Endpoint Keys で、Starter_Key （管理者用キー）以外のリソースが表示されない場合は、Azure ポータルで作成した LUIS リソース（のキー）と、LUIS ポータルで作成した LUIS アプリの関連付けができていない可能性があります。 先に、LUIS ポータル上の Keys and Endpoints から関連付けを行ってください。 参考: LUIS のオーサリングキー、エンドポイントキーとは botbuilder-ai パッケージのインストール LuisRecognizer クラスは、botbuilder-ai という Node パッケージで提供されています。 botbuilder-ai パッケージは、npm コマンドで簡単にインストールすることができます。 botbuilder-ai のインストール $ npm install botbuilder-ai --save 上記のように --save オプションを付けて実行することで、ついでに package.json に依存情報を追記しておくことができます。 botbuilder-ai を使用する LUIS サービスへの接続情報は、最終的には環境変数（Azure 上では App Service で設定できる）や .bot ファイルで管理することになると思いますが、最初はハードコーディングして動作確認するのがよいでしょう。 まずは、botbuild-ai モジュールの基本的な使い方を学ぶことにフォーカスしましょう。 ベースとする Bot クラス ボット本体は、こちらで作成した Bot クラス (bot.js) をベースに作成することにします。 もともとのコードは下記のようなオウム返し実装になっており、ここに LUIS API の呼び出しを加えていきます。 bot.js （元のコード） const { ActivityTypes } = require(\u0026#39;botbuilder\u0026#39;); class Bot { async onTurn(turnContext) { const type = turnContext.activity.type; if (type === ActivityTypes.Message) { const text = turnContext.activity.text; await turnContext.sendActivity(`You said \u0026#34;${text}\u0026#34;`); } else { await turnContext.sendActivity(`[${type}event detected]`); } } } exports.Bot = Bot; このクラスの onTurn メソッドは、パラメータで TurnContext オブジェクトを受け取るので、これを LuisRecognizer クラスに渡すことで LUIS への問い合わせを行うことができます。 LuisRecognizer クラスをインスタンス化する LUIS の API を利用するには、botbuilder-ai パッケージに含まれている LuisRecognizer クラスを使用します。 このクラスのインスタンスを作成するには、下記のような接続情報オブジェクトが必要です。 const luisEndpoint = { applicationId: \u0026#39;c39eb4df-fbcf-224f-b8b7-a0ee445d11b3\u0026#39;, endpoint: \u0026#39;https://japaneast.api.cognitive.microsoft.com\u0026#39;, endpointKey: \u0026#39;c9162c5c0b5edff5270feb6145618acb\u0026#39; }; こちらの記事で作成した config.js モジュールを使用すると、.bot ファイルに記述した LUIS 接続情報を簡単に取得することができます。 const config = require(\u0026#39;./config.js\u0026#39;); const luisEndpoint = config.loadLuisEndpoint(\u0026#39;your-luis-app-name\u0026#39;); 例えば、Bot クラスのコンストラクタ内で、下記のように LuisRecognizer インスタンスを生成すればよいでしょう。 bot.js const { ActivityTypes } = require(\u0026#39;botbuilder\u0026#39;); const { LuisRecognizer } = require(\u0026#39;botbuilder-ai\u0026#39;); class Bot { /** * Bot コンストラクタ。 * LUIS の接続情報を使って、LuisRecognizer オブジェクトを初期化します。 */ constructor(config) { const luisEndpoint = { applicationId: \u0026#39;c39eb4df-fbcf-224f-b8b7-a0ee445d11b3\u0026#39;, endpoint: \u0026#39;https://japaneast.api.cognitive.microsoft.com\u0026#39;, endpointKey: \u0026#39;c9162c5c0b5edff5270feb6145618acb\u0026#39; }; const luisOptions = {}; this.luisRecognizer = new LuisRecognizer(luisEndpoint, luisOptions, true); } // ... } LuisRecognizer クラスの基本的な使い方 LuisRecognizer#recognize() メソッドに TurnContext オブジェクトを渡すと、LUIS による自然言語解析の結果 RecognizerResult を取得することができます。 RecognizerResult オブジェクトの intents プロパティを参照すると、LUIS によって認識されたユーザーの意図（インテント）の配列データを取得できます。 [ { \u0026quot;intent\u0026quot;: \u0026quot;SearchMeaning\u0026quot;, \u0026quot;score\u0026quot;: 0.8440653 }, { \u0026quot;intent\u0026quot;: \u0026quot;BookConference\u0026quot;, \u0026quot;score\u0026quot;: 0.1042322 }, ... ] 一番スコアの高い（それらしい）トップインテントは、LuisRecognizer.topIntent() ユーティリティ関数を使って取り出すことができます。 まずはトップインテントを取り出し、その意図に応じて各エンティティを取り出すとよいでしょう。 bot.js（応答部分の抜粋） class Bot { /** * Every conversation turn calls this method. * @param {TurnContext} turnContext Contains all the data needed for * processing the conversation turn. */ async onTurn(turnContext) { if (turnContext.activity.type === ActivityTypes.Message) { // LUIS による認識結果を取得 const result = await this.luisRecognizer.recognize(turnContext); const topIntent = LuisRecognizer.topIntent(result); const topIntentName = topIntent.intent; const topIntentScore = topIntent.score; const entities = result.entities; // どんなインテントだと認識したのか表示（デバッグ用） await turnContext.sendActivity(`意図: ${JSON.stringify(topIntent)}`); // インテントの種類に応じてエンティティを取り出す let response = \u0026#39;\u0026#39;; switch (topIntentName) { case \u0026#39;SearchMeaning\u0026#39;: const words = entities[\u0026#39;Word\u0026#39;]; if (words) { response = `${words[0]}の意味は〇〇〇です。`; } else { response = \u0026#39;単語の意味を知りたいのですね。\u0026#39;; } break; case \u0026#39;None\u0026#39;: response = \u0026#39;理解できませんでした。\u0026#39;; break; } await turnContext.sendActivity(response); } else { await turnContext.sendActivity(`[${turnContext.activity.type}event detected]`); } } } 例えば、チャットクライアントから XYZの意味は何ですか？ と入力すると、このボットは下記のように応答します。 意図: {\u0026#34;intent\u0026#34;: \u0026#34;SearchMeaning\u0026#34;, \u0026#34;score\u0026#34;: 0.8440653} xyz の意味は〇〇〇です。 LUIS サービスが行ってくれるのは、上記のような意図の認識（例では SearchMeaning）と、単語の抽出（例では xyz）だけなので、ここから先の「単語の意味を検索する部分」は別の仕組みを使って実装する必要があります。 その仕組みが完成すれば、上記の○○○の部分に実際の意味を表示することができます。 ちなみに、LUIS は意図を認識できないと、デフォルトで None インテントを返します。 例えば、チャットクライアントから いあ！いあ！くとぅるふ ふたぐん！ と入力すると、ボットは下記のような応答を返すことになります。 意図: {\u0026#34;intent\u0026#34;: \u0026#34;None\u0026#34;, \u0026#34;score\u0026#34;: 0.489056647} 理解できませんでした。 ☝️ ワンポイント 「いあ！いあ！くとぅるふ ふたぐん！」は、クトゥルフ神話に登場する詠唱呪文のひとつです。 (応用) デフォルトインテントを置き換える LUIS はインテントを判別できなかった場合、デフォルトインテントとして { intent: \u0026quot;None\u0026quot;, score: 0 } を返します。 LuisRecognizer.topIntent() メソッドで、RecognizerResult オブジェクトから トップインテントを取り出す時に、オプションパラメーターを指定すると、デフォルトのインテントを None 以外の任意のインテントに置き換えることができます。 const result = await this.luisRecognizer.recognize(turnContext); const topIntent = LuisRecognizer.topIntent(result, \u0026#39;Greet\u0026#39;, 0.75);"
},
{
url: "/p/ezq5wy8/",
title: "gnuplot: 軸の目盛り表示を調整する",
date: "2004-01-03T00:00:00Z",
body: "gnuplot: 軸の目盛り表示を調整する 軸の目盛りの間隔、開始座標、終了座標を設定する Syntax set xtics \u0026lt;start\u0026gt;, \u0026lt;incr\u0026gt;, \u0026lt;end\u0026gt; set x2tics \u0026lt;start\u0026gt;, \u0026lt;incr\u0026gt;, \u0026lt;end\u0026gt; set ytics \u0026lt;start\u0026gt;, \u0026lt;incr\u0026gt;, \u0026lt;end\u0026gt; set y2tics \u0026lt;start\u0026gt;, \u0026lt;incr\u0026gt;, \u0026lt;end\u0026gt; set ztics \u0026lt;start\u0026gt;, \u0026lt;incr\u0026gt;, \u0026lt;end\u0026gt; start と end を省略して、incr（ステップ数）だけを指定することもできます。 例: x 軸の目盛りを 1 刻みで 0～5 の間に表示（ついでにグリッドも ON） set xtics 0, 1, 5 set grid plot [-10:10] x あ、こうすると x=0 には目盛りが表示されないみたい。。。 x=0 にも表示したかったら -1, 1, 5 にしないとダメですね。 軸の目盛りを消す Syntax set noxtics set nox2tics set noytics set noy2tics set noztics 図形の形だけを示したい場合などは、軸の目盛りと、凡例を両方とも消してプロットします。 例: 図形の形だけを示す set noxtics set noytics set nokey plot [0:2*pi] sin(x) 任意の位置の目盛りにラベルを表示する Syntax set xtics {align} ({\u0026#34;label\u0026#34;} pos, {\u0026#34;label\u0026#34;} pos ...) 例 set xtics (\u0026#34;Sun\u0026#34; 10, \u0026#34;Mon\u0026#34; 20, \u0026#34;Tue\u0026#34; 30, \u0026#34;Wed\u0026#34; 40, \u0026#34;Thu\u0026#34; 50, \u0026#34;Fri\u0026#34; 60, \u0026#34;Sat\u0026#34; 70)"
},
{
url: "/p/556wrds/",
title: "gnuplot: グラフに補助線を表示する",
date: "2004-01-03T00:00:00Z",
body: "gnuplot: グラフに補助線を表示する X=0, Y=0 の中心線 (axis) を表示する Syntax set [no]zeroaxis # x=0, x2=0, y=0, y2=0 軸の補助線を表示・非表示 set [no]xzeroaxis # x=0 軸の補助線を表示・非表示 set [no]x2zeroaxis # x2=0 軸の補助線を表示・非表示 set [no]yzeroaxis # y=0 軸の補助線を表示・非表示 set [no]y2zeroaxis # y2=0 軸の補助線を表示・非表示 show zeroaxis # 補助線の表示状態を確認する X=0, Y=0 の中心線はデフォルトでは非表示です。 例: x, y の中心線を表示 set zeroaxis plot 1/(1+exp(-x)) - 0.5 目盛りごとに補助線（グリッド）を表示する Syntax set [no]grid # グリッドの表示・非表示 show grid # グリッドの表示状態を確認 例: グリッドを表示 set grid plot log(x)"
},
{
url: "/p/3mgr3db/",
title: "gnuplot: グラフの枠を表示・非表示する",
date: "2004-01-03T00:00:00Z",
body: "gnuplot: グラフの枠を表示・非表示する 枠 (border) の表示・非表示 Syntax set [no]border グラフの枠はデフォルトでは表示されるので、特に枠を消したい場合のみ下記のように実行します。 例: グラフの枠を消す set noborder plot sin(x) 指定した軸だけ表示する Syntax set border \u0026lt;枠番号の論理和\u0026gt; \u0026nbsp;plot bordersplotsplot Sidesplot baseverticalstop bottom (south)116256 left (west)232512 top (north)4641024 right (east)81282048"
},
{
url: "/p/afkbjc6/",
title: "gnuplot: グラフの描画範囲を指定する",
date: "2004-01-03T00:00:00Z",
body: "gnuplot: グラフの描画範囲を指定する 描画する線の範囲を指定する Syntax plot [x_min : x_max] [y_min : y_max] \u0026lt;expression\u0026gt; # 二次元の場合 splot [x_min : x_max] [y_min : y_max] [z_min : z_max] \u0026lt;expression\u0026gt; # 三次元の場合 set xrange [min:max] set yrange [min:max] set zrange [min:max] 例: [-2π, 2π] の sin(x) のグラフを表示 plot [-2*pi:2*pi] sin(x) 開始座標だけを指定したり、終了座標だけを指定したりすることもできます。 例: x軸の範囲を 0 からにする plot [0:] sin(x) # set xrange [0:] ; plot sin(x) と同じ 例: x軸の範囲を π までにする plot [:pi] cos(x) # set xrange [:pi] ; plot cos(x) と同じ 例: y軸の範囲を [-π,π] にする plot [] [-pi:pi] sin(x**2) # set yrange [-pi:pi] ; plot sin(x**2) と同じ プロットのオフセットを設定 Syntax set offset \u0026lt;left\u0026gt;, \u0026lt;right\u0026gt;, \u0026lt;top\u0026gt;, \u0026lt;bottom\u0026gt; # マージン設定 show offset # マージン表示 例: オフセットを設定 set offset 2, 2, 1, 1 set grid plot [-2*pi:2*pi] cos(x) グラフのマージンを設定する Syntax set lmargin left # 左の余白を指定（文字数で指定） set rmargin right # 右の余白を指定（文字数で指定） set tmargin top # 上の余白を指定（文字数で指定） set bmargin bottom # 下の余白を指定（文字数で指定） グラフの外形だけを表示したい場合などは、タイトルやラベルなどを表示するためのマージンは必要ないので、次のようにすると余計な空白をなくすことができます。 例: マージンを 0 にする set lmargin 0 set rmargin 0 set tmargin 0 set bmargin 0 set nokey plot [0:2*pi] sin(x)**2 あれれ、右と上の枠がなくなってしまいました（＞＿＜ こんな場合はしょうがないので、rmargin と tmargin を 1 にして次のようにします。 例: できるだけマージンを小さくする set lmargin 0 set rmargin 1 set tmargin 1 set bmargin 0 set nokey plot [0:2*pi] sin(x)**2 目盛りの表示内容が 2 行以上に渡る場合などは、bmargin を少し広げてやらないと、表示が切れてしまうことがあります。 例: bmargin を少し広げる set xtics ( \\ \u0026#34;5sec\\n10sec\\n15sec\u0026#34; 5, \\ \u0026#34;10sec\\n15sec\\n20sec\u0026#34; 10, \\ \u0026#34;15sec\\n20sec\\n25sec\u0026#34; 15) set bmargin 4 plot \u0026#34;-\u0026#34; with linespoints 5 10 10 12 15 17M E"
},
{
url: "/p/e4vuhjy/",
title: "gnuplot: 線のスタイル、ポイントのスタイルを変更する",
date: "2004-01-03T00:00:00Z",
body: "gnuplot: 線のスタイル、ポイントのスタイルを変更する 線のスタイルを変更する Syntax plot \u0026lt;expression\u0026gt; with \u0026lt;line_style\u0026gt; 線のスタイルを変更するには plot のオプションで with を使います。 with の後ろには次のようなものを指定できます。 括弧は省略形を示しています。 boxes (b) \u0026ndash; 箱（サブスタイル: linesize (ls), linetype (lt)） boxerrorbars \u0026ndash; 箱とエラーバー dots (d) \u0026ndash; 点 errorbars (e) \u0026ndash; エラーバー impulses (i) \u0026ndash; 縦棒 lines (l) \u0026ndash; 線 linespoints \u0026ndash; 線と記号 points (p) \u0026ndash; 記号（サブスタイル: pointtype (pt), pointsize(ps)） steps (s) \u0026ndash; 階段状 線種ごとにさらにサブスタイルを指定することができます。 例えば、記号でプロットする場合（with points (p) を指定した場合）は、オプションとして pointtype (pt) と pointsize (ps) を指定することができます。 例えば、記号のサイズを 3 にする場合は、plot コマンドのオプションとして with p ps 3（省略形での指定）を指定します。 線種や記号の種類にどんなものが指定できるかは、help with コマンドで調べることができます。 ポイント（記号）のスタイルを変更する Syntax plot \u0026#39;test.dat\u0026#39; with linespoints pointtype \u0026lt;pointType\u0026gt; plot \u0026#39;test.dat\u0026#39; with linespoints pt \u0026lt;pointType\u0026gt; 線のスタイルとして、ポイントを伴う linespoints などを指定した場合は、さらに、サブスタイルとして pointtype (pt) を指定できます。 例: ポイントのタイプを 5 に変更 plot \u0026#39;test.dat\u0026#39; with linespoints pointtype 5"
},
{
url: "/p/h3gsjs2/",
title: "AWS CloudFormation で DyanamoDB のリソースを作成する",
date: "2021-04-07T00:00:00Z",
body: "AWS CloudFormation で DyanamoDB のリソースを作成する SAM で簡単な DynamoDB テーブルを生成してみる DynamoDB のテーブルリソースも、Lambda 関数などのリソースと同様に AWS SAM で自動生成＆更新することができます。 CloudFormation のテンプレートをそのまま記述するより、拡張された SAM テンプレートの形式で記述することで、シンプルにリソースを定義することができます。 SAM テンプレート内で DynamoDB のテーブルを定義するときは、リソースタイプとして AWS::Serverless::SimpleTable を指定します（CloudFormation スタック内に実際に生成されるリソースのタイプは AWS::DynamoDB::Table になります）。 DynamoDB テーブルを作成するための最低限の SAM テンプレートはとてもシンプルです。 次の例では、MyTable という 論理 ID (Logical ID) で DynamoDB のテーブルを定義しています。 論理 ID はスタック内でリソースを特定するための名前です。 template.yml AWSTemplateFormatVersion:\u0026#39;2010-09-09\u0026#39;Transform:AWS::Serverless-2016-10-31Description:My sample appResources:MyTable:Type:AWS::Serverless::SimpleTable ひとつもプライマリキーを指定していませんが、その場合はデフォルトで id という名前のプライマリキー（String 型）が定義されます。 AWS CLI で次のように実行すると、CloudFormation のスタックを作成することができます。 $ aws cloudformation deploy --stack-name mystack \\ --template-file template.yml CloudFormation スタック内に、実際にどのような AWS リソースが作成されたかを調べるには以下のようにします。 ここではリソースタイプと、その物理 ID (Pysical ID) を table 形式で出力してみました。 $ aws cloudformation describe-stack-resources --stack-name mystack \\ --query \u0026#39;StackResources[].[ResourceType,PhysicalResourceId]\u0026#39; \\ --output table ---------------------------------------------------------- | DescribeStackResources | +-----------------------+--------------------------------+ | AWS::DynamoDB::Table | mystack-MyTable-ABD467NSG1D3 | +-----------------------+--------------------------------+ SAM テンプレート内では、DynamoDB テーブルの論理 ID (Logical ID) を MyTable と定義しましたが、実際のテーブル名（物理 ID）は mystack-MyTable-ABD467NSG1D3 のように、スタック名と論理 ID、ハッシュ値を組み合わせたものから自動生成されていることが分かります。 この物理 ID が、DynamoDB のマネージメントコンソールなどで表示されるテーブル名になります。 もちろん、テーブル名は SAM テンプレート内で明示的に指定することができます（後述）。 DynamoDB テーブル用のプロパティ設定 SAM の AWS::Serverless::SimpleTable リソースのプロパティ設定には以下のようなものがあります。 TableName \u0026hellip; テーブル名（物理 ID） デフォルトでは、DynamoDB のテーブル名 (Physical ID) は CloudFormation のスタック名と Logical ID から自動生成されますが、TableName プロパティで明示的に設定できます。 Resources:BooksTable:Type:AWS::Serverless::SimpleTableProperties:TableName:myapp-table-books PrimaryKey \u0026hellip; プライマリキー テーブルのプライマリキーは PrimaryKey プロパティで指定します（属性名を Name、属性タイプを Type で指定します）。 属性タイプは String、Number、Binary のいずれかの値を指定します（プライマリキー以外の属性には、他にも Boolean などの属性タイプがありますが、プライマリキーの属性タイプは 3 種類だけです）。 次の例では、プライマリキーとして、Title という名前の String 型属性を定義しています。 Resources:BooksTable:Type:AWS::Serverless::SimpleTableProperties:PrimaryKey:Name:TitleType:String Tags \u0026hellip; タグの配列 DynamoDB テーブルにタグを設定したいときは、Tags プロパティにマップ形式（キー＆バリュー）で指定します。 Resources:BooksTable:Type:AWS::Serverless::SimpleTableProperties:Tags:Project:OnlineShopDepartment:Engineering その他の情報源 参考リンク AWS::Serverless::SimpleTable - AWS Serverless Application Model AWS::DynamoDB::Table - AWS CloudFormation"
},
{
url: "/p/3o3fq3d/",
title: "Next.js のプリレンダリングとルーティング",
date: "2021-05-05T00:00:00Z",
body: "Next.js のプリレンダリングとルーティング"
},
{
url: "/p/ymzbmx9/",
title: "AWS CloudFormation で SNS トピックのリソースを生成する",
date: "2021-04-13T00:00:00Z",
body: "AWS CloudFormation で SNS トピックのリソースを生成する CloudFormation で SNS トピックを作成する CloudFormation スタック内に SNS トピックを生成するには、CloudFormation テンプレートで AWS::SNS::Topic というタイプのリソースを定義します。 このリソースのプロパティはすべてオプショナル（省略可能）なので、最低限のリソース定義は次のようになります。 template.yml AWSTemplateFormatVersion:\u0026#39;2010-09-09\u0026#39;Resources:MyTopic:Type:AWS::SNS::Topic トピック名 (Properties.TopicName) すら指定していませんが、その場合は、CloudFormation のスタック名と、トピックの論理 ID（上記の場合は MyTopic）の組み合わせから、自動的にトピック名が割り当てられるようになっています（例: mystack-MyTopic-WMD9B9WWLEXN）。 上記のテンプレートから CloudFormation スタックを生成するには、AWS CLI を使って次のように実行します。 mystack スタックの生成 $ aws cloudformation deploy --stack-name mystack \\ --template-file template.yml \\ --capabilities CAPABILITY_IAM 無事スタックが生成されたら、次のようにして生成された SNS トピックの物理 ID (ARN) を調べることができます。 SNS トピックの ARN を調べる $ aws cloudformation describe-stack-resources \\ --stack-name mystack \\ --output text \\ --query \u0026#34;StackResources[].PhysicalResourceId\u0026#34; arn:aws:sns:ap-northeast-1:123456789012:mystack-MyTopic-WMD9B9WWLEXN Lambda 関数や S3 バケットから SNS トピックに対して publish するときは、この ARN を指定することになります。 SNS トピックの設定いろいろ トピック名 (TopicName) トピック名の生成を CloudFormation に任せるのではなく、明示的にトピック名を指定する方法です。 Resources:MyTopic:Type:AWS::SNS::TopicProperties:TopicName:topic-hello 上記のように TopicName プロパティを指定すると、SNS トピックの ARN は次のようになります。 arn:aws:sns:ap-northeast-1:123456789012:topic-hello FIFO トピック (FifoTopic) FIFO トピックとして作成するには、FifoTopic プロパティを true に設定します。 Resources:MyTopic:Type:AWS::SNS::TopicProperties:TopicName:topic-hello.fifoFifoTopic:true FIFO トピックを作るときは、TopicName で明示的に .fifo で終わる名前を付けないと、次のようなエラーになるみたいです。 ほんと AWS はこういうところが分かりにくすぎる。。。 Invalid parameter: Topic Name (Service: AmazonSNS; Status Code: 400; ... タグ (Tags) SNS トピックにタグを付けたいときは、Tags プロパティで次のように指定します（他のリソースでタグを設定する場合も同様です）。 Resources:MyTopic:Type:AWS::SNS::TopicProperties:Tags:- Key:key1Value:value1- Key:key2Value:value2"
},
{
url: "/p/qoz8fow/",
title: "React Context で複数のコンポーネント間でデータを共有する",
date: "2020-08-27T00:00:00Z",
body: "React Context で複数のコンポーネント間でデータを共有する Context とは React の Context（コンテクスト） は、いわゆるグローバル変数の格納領域のようなもので、複数のコンポーネント間でのデータ共有に使用できます。 各コンポーネントから Context 情報にダイレクトにアクセスできるため、prop のように上位のコンポーネントから情報を伝搬させていく必要がありません。 Context をむやみに使うと、コンポーネントの再利用性が下がってしまいますが、アプリケーション全体で使用する次のような情報を Context で管理するとコードがすっきりします。 ログイン中のユーザー情報（認証情報） 言語設定 テーマ設定 Context の使い方 Context を作成する (createContext) Context オブジェクトは、React.createContext() で作成することができます。 複数のコンポーネントから参照することになるので、Context オブジェクトは単独のファイルとしてモジュール化しておきます。 React.createContext() の引数に任意のオブジェクトを渡すと、その値を初期値とする Context オブジェクトが生成されます。 次の例では、string 型のデータを保持する Context オブジェクトを生成しています。 MyContext.ts import * as React from \u0026#39;react\u0026#39;; export const MyContext: React.Context\u0026lt;string\u0026gt; = React.createContext\u0026lt;string\u0026gt;(\u0026#39;Default message\u0026#39;); Context を参照する (useContext) 関数コンポーネント内で、Context が保持するデータを参照するには、React.useContext() を使用します。 デフォルトでは、React.createContext() の引数に設定したデフォルト値が返されます。 上記の例では、Default message というデフォルトテキストを設定しているので、その値が返されることになります。 App.tsx import * as React from \u0026#39;react\u0026#39;; import { MyContext } from \u0026#39;./MyContext\u0026#39;; export const App: React.FC = () =\u0026gt; { const message: string = React.useContext(MyContext); //=\u0026gt; \u0026#34;Default message\u0026#34; return ( \u0026lt;div\u0026gt;{message}\u0026lt;/div\u0026gt; ); }; このように、どの階層にあるコンポーネントからも、React.useContext() を使って Context が保持する情報を参照することができます。 しかし、このままだと、Context が保持する値を変更することができません。 Context の値を更新してコンポーネントを再描画する 前述の React.createContext() で作成した MyContext には、MyContext.Provider というコンポーネントが付随しています。 このコンポーネントは、次のように value 属性と一緒に使用します。 \u0026lt;MyContext.Provider value={データ}\u0026gt; 子コンポーネント \u0026lt;/MyContext.Provider\u0026gt; このようにすると、子コンポーネント内で React.useContext() を呼び出したときに返される値が、上記の value 属性で指定した値に変化します。 つまり、この value 属性の値を、ステートオブジェクトを使って設定することで、子コンポーネントを新しい Context データで再描画できるようになります。 次の例では、MyContext.Provider の value 属性に、React.useState() で作成した message ステートオブジェクトを設定しています。 message ステートオブジェクトの初期値は、React.useContext() が返すデフォルト値 (Default message) に設定しています。 この message ステートオブジェクトの値を setMessage 関数で変更することにより、MyContext.Provider 以下のコンポーネントに再描画がかかります。 App.tsx import * as React from \u0026#39;react\u0026#39;; import { MyContext } from \u0026#39;./MyContext\u0026#39;; import { Child } from \u0026#39;./Child\u0026#39;; export const App: React.FC = () =\u0026gt; { const [message, setMessage] = React.useState(React.useContext(MyContext)); return ( \u0026lt;MyContext.Provider value={message}\u0026gt; \u0026lt;Child /\u0026gt;\u0026lt;br /\u0026gt; \u0026lt;button onClick={()=\u0026gt;setMessage(\u0026#39;New message\u0026#39;)}\u0026gt;Change\u0026lt;/button\u0026gt; \u0026lt;/MyContext.Provider\u0026gt; ); }; Child コンポーネントは、次のように MyContext の内容を表示しているだけです。 Child.tsx import * as React from \u0026#39;react\u0026#39;; import { MyContext } from \u0026#39;./MyContext\u0026#39;; export const Child: React.FC = () =\u0026gt; { const message = React.useContext(MyContext); return \u0026lt;b\u0026gt;{message}\u0026lt;/b\u0026gt;; }; Change ボタンを押すと、Child コンポーネントに表示されるメッセージが Default message から New message に変化します。 どのコンポーネントからでも Context の値を更新できるようにする ここまで見てきたように、Context データの変化を子コンポーネントに伝えるには、Context.Provider コンポーネントの value 属性の値をうまく更新してやる必要があります。 このような更新処理は、Context.Provider を配置しているコンポーネント内では容易に行えますが（前述の例）、任意の階層のコンポーネントから Context データを更新できるようにする には少々工夫が必要です。 ここでは、Context データとして、自身のデータを更新するためのセッター関数を持つようにする例を示します。 下記は、作成するアプリの表示例です。 UserInfo コンポーネントは Context データの内容を表示し、UpdateButtons コンポーネントは Context データの内容を変更するボタンを表示します。 例えば、Change username ボタンを押すと、Context が保持する username の値が変化し、画面上の表示も更新されます。 UserInfo と UpdateButtons は prop を介した親子構造により連携しているわけではなく、Context によってのみ連携しています。 AppContext コンポーネントの作成 ここで定義する AppContext は、アプリ全体で共有する 2 つの文字列データ（username と apiToken）を持ち、さらにそれらの値を更新するためのセッター関数 (setUsername と setApiToken) を持ちます。 AppContext.tsx import * as React from \u0026#39;react\u0026#39;; // AppContext が保持する値の型 export interface AppContextType { username: string; apiToken: string; setUsername: (username: string) =\u0026gt; void; setApiToken: (apiToken: string) =\u0026gt; void; } // AppContext の生成 export const AppContext = React.createContext\u0026lt;AppContextType\u0026gt;({ username: \u0026#39;Default username\u0026#39;, // デフォルト値 apiToken: \u0026#39;Default apiToken\u0026#39;, // デフォルト値 setUsername: (username: string) =\u0026gt; {}, // ダミー関数 setApiToken: (apiToken: string) =\u0026gt; {}, // ダミー関数 }); // AppContext にセッター関数を登録するためのコンポーネント export const AppContextProvider: React.FC = ({children}) =\u0026gt; { // デフォルト値の取得用 const context: AppContextType = React.useContext(AppContext); // ステートオブジェクト作成 const [username, setUsername] = React.useState(context.username); const [apiToken, setApiToken] = React.useState(context.apiToken); // 下位コンポーネントへ渡す Context const newContext: AppContextType = { username, setUsername, apiToken, setApiToken }; return ( \u0026lt;AppContext.Provider value={newContext}\u0026gt; {children} \u0026lt;/AppContext.Provider\u0026gt; ); }; ここでのポイントは、任意の子コンポーネントを AppContext.Provider 以下に配置するための AppContextProvider を定義しているところです。 ここで、React.useState() で作成したステートオブジェクトを使って AppContext データを再構成することで、各種セッター関数が正しく初期化されます。 子コンポーネント ({children}) からセッター関数を呼ぶことにより、AppContextProvider コンポーネントの再描画が走るため、結果的に、関連するすべての子コンポーネントが再描画されることになります。 UserInfo コンポーネントの作成 UserInfo コンポーネントは、AppContext が保持するユーザーデータを単純に表示します。 ここでは React.useContext() をそのまま使っていますが、useAppContext() のようなカスタムフックを作成すれば、よりスッキリしたコードになります。 UserInfo.tsx import * as React from \u0026#39;react\u0026#39;; import { AppContext, AppContextType } from \u0026#39;./AppContext\u0026#39;; export const UserInfo: React.FC = () =\u0026gt; { // AppContext.Provider から提供される Context データを参照 const context: AppContextType = React.useContext(AppContext); return \u0026lt;\u0026gt; \u0026lt;h2\u0026gt;UserInfo\u0026lt;/h2\u0026gt; \u0026lt;ul\u0026gt; \u0026lt;li\u0026gt;\u0026lt;b\u0026gt;username:\u0026lt;/b\u0026gt; {context.username}\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;b\u0026gt;apiToken:\u0026lt;/b\u0026gt; {context.apiToken}\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/\u0026gt;; }; UpdateButtons コンポーネントの作成 UpdateButtons コンポーネントは、AppContext が保持するデータを変更するためのボタン（Change username と Change apiToken）を配置します。 AppContext の内容を更新したいときは、AppContext 自身が提供するセッター関数を呼び出すだけで済みます。 UpdateButtons.tsx import * as React from \u0026#39;react\u0026#39;; import { AppContext, AppContextType } from \u0026#39;./AppContext\u0026#39;; export const UpdateButtons: React.FC = () =\u0026gt; { // AppContext.Provider から提供される Context データを参照 const context: AppContextType = React.useContext(AppContext); const handleChangeUsername = () =\u0026gt; { context.setUsername(\u0026#39;New username\u0026#39;); }; const handleChangeApiToken = () =\u0026gt; { context.setApiToken(\u0026#39;New apiToken\u0026#39;); }; return \u0026lt;\u0026gt; \u0026lt;h2\u0026gt;UpdateButtons\u0026lt;/h2\u0026gt; \u0026lt;button onClick={handleChangeUsername}\u0026gt;Change username\u0026lt;/button\u0026gt; \u0026lt;button onClick={handleChangeApiToken}\u0026gt;Change apiToken\u0026lt;/button\u0026gt; \u0026lt;/\u0026gt;; }; App コンポーネントの作成 最後に、最上位のコンポーネントである App コンポーネントです。 AppContextProvider の子コンポーネントとして配置された UserInfo や UpdateButtons からは、AppContext が保持するデータを参照・変更することができます。 App.tsx import * as React from \u0026#39;react\u0026#39;; import { AppContextProvider } from \u0026#39;./AppContext\u0026#39;; import { UserInfo } from \u0026#39;./UserInfo\u0026#39;; import { UpdateButtons } from \u0026#39;./UpdateButtons\u0026#39;; export const App: React.FC = () =\u0026gt; { return ( \u0026lt;AppContextProvider\u0026gt; \u0026lt;UserInfo /\u0026gt; \u0026lt;UpdateButtons /\u0026gt; \u0026lt;/AppContextProvider\u0026gt; ); };"
},
{
url: "/p/bv9kv7h/",
title: "React Context の情報をローカルストレージに保存する",
date: "2020-08-29T00:00:00Z",
body: "React Context の情報をローカルストレージに保存する 何をするか？ ここでは、React の Context オブジェクトにセットした値をローカルストレージに保存し、次回のアプリ起動時にそこから値を復帰させる方法を説明します。 Context の使い方の基本は、次の記事を参照してください。 React Context で複数のコンポーネント間でデータを共有する Context の実装 下記の UserContext.tsx モジュールでは、React.createContext() で UserContext というオブジェクトを作成しています。 このオブジェクトは、gitHubToken という文字列データと、その値を更新するための setGitHubToken 関数を保持しています。 次のように実装することで、UserContext のデータをローカルストレージと同期させることができます。 gitHubToken の初期値に localStorage.getItem() から取得した値を設定する setGitHubToken の呼び出し時に localStorage.setItem() で値を保存する UserContext.tsx import * as React from \u0026#39;react\u0026#39;; // UserContext が保持する値の型 export interface UserContextType { gitHubToken: string; setGitHubToken: (token: string) =\u0026gt; void; } // ローカルストレージ用のキー const KEY_GITHUB_TOKEN = \u0026#39;gitHubToken\u0026#39;; // UserContext の生成 export const UserContext = React.createContext\u0026lt;UserContextType\u0026gt;({ gitHubToken: localStorage.getItem(KEY_GITHUB_TOKEN), // デフォルト値 setGitHubToken: (token: string) =\u0026gt; {} // ダミーセッター }); // UserContext にセッター関数を登録するためのコンポーネント export const UserContextProvider: React.FC = ({children}) =\u0026gt; { const context: UserContextType = React.useContext(UserContext); const [gitHubToken, setGitHubToken] = React.useState(context.gitHubToken); const newContext: UserContextType = { gitHubToken, setGitHubToken: (token: string) =\u0026gt; { localStorage.setItem(KEY_GITHUB_TOKEN, token); setGitHubToken(token); } }; return ( \u0026lt;UserContext.Provider value={newContext}\u0026gt; {children} \u0026lt;/UserContext.Provider\u0026gt; ); }; 使用例 上記で作成した、UserContext を使用するには、上位のコンポーネント (App コンポーネントなど）に UserContextProvider を配置し、その子コンポーネントとして UserContext の Consumer となるコンポーネントを配置します。 ここでは、SignInAndOut コンポーネント（後で実装）を配置しています。 App.tsx import * as React from \u0026#39;react\u0026#39;; import { UserContextProvider } from \u0026#39;./UserContext\u0026#39;; import { SignInAndOut } from \u0026#39;./SignInAndOut\u0026#39;; export const App: React.FC = () =\u0026gt; { return ( \u0026lt;UserContextProvider\u0026gt; \u0026lt;SignInAndOut /\u0026gt; \u0026lt;/UserContextProvider\u0026gt; ); }; SignInAndOut コンポーネントは UserContext を参照し、Sign In あるいは Sign Out のボタンを表示します。 UserContext に gitHubToken が設定されている場合は、サインイン済みと判断しています。 SignInAndOut.tsx import * as React from \u0026#39;react\u0026#39;; import { UserContext, UserContextType } from \u0026#39;./UserContext\u0026#39;; export const SignInAndOut: React.FC = () =\u0026gt; { const ctx: UserContextType = React.useContext(UserContext); if (ctx.gitHubToken) { return \u0026lt;\u0026gt; \u0026lt;button onClick={() =\u0026gt; ctx.setGitHubToken(\u0026#39;\u0026#39;)}\u0026gt;Sign Out\u0026lt;/button\u0026gt; \u0026lt;div\u0026gt;gitHubToken = {ctx.gitHubToken}\u0026lt;/div\u0026gt; \u0026lt;/\u0026gt;; } else { return \u0026lt;\u0026gt; \u0026lt;button onClick={() =\u0026gt; ctx.setGitHubToken(\u0026#39;DUMMY\u0026#39;)}\u0026gt;Sign In\u0026lt;/button\u0026gt; \u0026lt;/\u0026gt;; } }; 表示結果は次のようになります。 サインイン後は、トークンの値も表示するようにしています。 Sign In ボタンを押すと、トークンの値がローカルストレージに保存され、ボタンが Sign Out に変化します。 この状態で Web ブラウザをリロードすると、ローカルストレージからトークンの値が復元されるため、最初からサインインした状態で表示されます（Sign Out ボタンが表示されます）。"
},
{
url: "/p/2t6xrbm/",
title: "QnA Maker (1) QnA Maker とは？",
date: "2019-02-28T00:00:00Z",
body: "QnA Maker (1) QnA Maker とは？ QnA Maker でできること Microsoft が提供している QnA Maker というサービスを使用すると、「質問(Q)と回答(A)」のペアデータを登録するだけで、自然言語での FAQ 検索を行うための API を使用できるようになります。 Microsoft が提供している一連の Cognitive Service のひとつとして位置づけられていて、主に FAQ 系のチャットボット (Bot) を手軽に作成するために使用されています。 QnA Maker QnA Maker Documentation QnA Maker REST API V4.0 QnAMaker class | Microsoft Docs 例えば、下記のような Q\u0026amp;A のペアを登録していくだけで、機械学習によって回答のモデルが自動生成されます。 QnA Maker では、このモデルのことをナレッジベース (Knowledge base) と呼んでいます。 Q. お店の営業時間を教えてください。 A. 営業時間は午前10時から午後6時までです。 実際にユーザが入力する質問文章は、登録した Q\u0026amp;A データの質問文と完全に一致する必要はありません。 QnA Maker がどの質問に近いかを判別して、対応する回答文（と一致度）を返してくれます。 ユーザ入力: 営業時間は？ QnA Makerの回答: 営業時間は午前10時から午後6時までです。 簡単に言ってしまえば、QnA Maker の API が提供する機能はこれだけです（データ管理用の API などもありますが）。 回答文を自動生成してくれるようなこともなく、返される文章は、Q\u0026amp;A データとして登録した回答文そのままです。 とはいえ、サクッと FAQ 系のサービスを作成するときには便利に使用できるサービスです。 QnA Maker のナレッジベースを公開する QnA Maker ポータル上で作成したナレッジベースを、Web API (REST API) の形で使用できるようにするには、下記のようなステップを踏みます。 Azure ポータルの リソースの作成 から QnA Maker のリソースを作成する QnA Maker ポータルで QnA Maker のナレッジベースを作成する（上記で作成した Azure の QnA Maker リソース経由でアクセスできるよう関連付ける） QnA Maker ポータルでナレッジベースを Publish して REST API として呼び出せるようにする 上記のようにしてナレッジベースを公開すれば、Node.js や C# など任意の言語から QnA Maker API を使用できるようになります。"
},
{
url: "/p/idkxws2/",
title: "gnuplot サンプル: ホームページ用の GIF を出力する環境設定ファイル (output_gif.env)",
date: "2002-12-04T00:00:00Z",
body: "gnuplot サンプル: ホームページ用の GIF を出力する環境設定ファイル (output_gif.env) lib/output_gif.env ## 使用例: output.gif というファイル名で出力する設定を行う場合## gnuplot\u0026gt; call \u0026#39;lib/hpgif.gp\u0026#39; \u0026#39;output.gif\u0026#39;#set terminal gif size 320, 240 transparent xffffff #set terminal gif size 320, 240#set samples 200set output \u0026#39;$0\u0026#39; set zeroaxis"
},
{
url: "/p/t6n6jc8/",
title: "QnA Maker (2) QnA Maker のサブスクリプションキー、エンドポイントキーとは",
date: "2019-03-18T00:00:00Z",
body: "QnA Maker (2) QnA Maker のサブスクリプションキー、エンドポイントキーとは サブスクリプションキー (Subscription Key) サブスクリプションキーは、QnA Maker アプリ自体の作成や編集を行うためのキーです。 後述のエンドポイントキーよりも厳重に管理しなければならないキーです。 このキーは、Azure ポータル上で QnA Maker のリソースを作成した際に生成されます。 QnA Maker アプリは、Azure 上にリソースを作ってからでないと作成できないため、QnA Maker アプリがすでに存在するのであれば、サブスクリプションキーも必ず存在することになります。 Azule の QnA Maker リソースに割り当てられたサブスクリプションキーは、Azure ポータルの QnA Maker リソースの Keys のページで確認することができます。 図: Azure ポータル上での QnA Maker のサブスクリプションキーの確認 LUIS の場合は、アプリ管理用のキーはオーサリングキーと呼んでいたりしますが、それの QnA Maker 版だと考えればよいです。 QnA Maker アプリの場合、このキーの管理は Azure ポータル上で管理されることになっており、Azure 上ではこのようなキーのことをサブスクリプションキーと呼んでいるんですね。 このあたりのチグハグ感に関しては こちらを参照。 エンドポイントキー (Endpoint Key) エンドポイントキーは、チャットアプリなどのユーザクライアント（Bot Framework では「チャンネル」と呼びます）が、QnA Maker に対してクエリを行うときに使用するキーです。 エンドポイントキーは、QnA Maker ポータルで対象となるナレッジベースを選択後、PUBLISH タブから Publish 処理を実行したとき、あるいは SETTING タブを選択することで確認することができます。 図: QnA Maker ポータル上での QnA Maker のエンドポイントキーの確認 チャットボットなどから QnA Maker を利用する場合、実運用時に設定する API アクセス用のキーは、こっちのエンドポイントキーです。 （コラム）QnA Maker アプリと Azure リソースの結び付け LUIS アプリの場合は、LUIS ポータル上で LUIS アプリを作成した後に、Azure ポータルで作成したリソースに関連付けるという作業が必要でした。 一方、QnA Maker アプリの場合は、この作業は必要ありません。 なぜなら、QnA Maker ポータル上で QnA Maker アプリ（ナレッジベース）を作成するときに、最初に Azure 上で作成した QnA Maker リソースの結び付けが強制されるからです。 よって、QnA Maker の場合は、ナレッジベースを作成した時点で、その API を Azure リソース経由で呼び出す準備が既に整っていることになります。"
},
{
url: "/p/h2swmzv/",
title: "gnuplot サンプル: グラフの形だけ表示する環境設定 (only_form.env)",
date: "2002-12-05T00:00:00Z",
body: "gnuplot サンプル: グラフの形だけ表示する環境設定 (only_form.env) lib/only_form.env #----------------------------# グラフの形だけ表示する環境#----------------------------# マージンを枠が消えない程度になくすset lmargin 0 set rmargin 1 set tmargin 1 set bmargin 0 # 目盛りを消すset noxtics set noytics # 軸の名前を消すset nokey"
},
{
url: "/p/rgnvp2r/",
title: "QnA Maker (3) Node.js から QnA Maker の API を利用する",
date: "2019-02-28T00:00:00Z",
body: "QnA Maker (3) Node.js から QnA Maker の API を利用する QnA Maker API を呼び出すためのエンドポイント情報を調べる QnA Maker ナレッジベースの Publish REST API を使用して QnA Maker のナレッジベースを使用するためには、QnA Maker ポータル上で対象のナレッジベースを Publish しておく必要があります。 Publish 処理が完了すると、ナレッジベースにアクセスするための Endpoint key が発行されます。 curl での QnA Maker API の呼び出しテスト 任意の質問文に対する回答文を得るには、REST API として下記のような HTTP POST リクエストを送ります。 curl -X POST https://xxx.azurewebsites.net/qnamaker/knowledgebases/＜ナレッジベースID＞/generateAnswer -H \u0026quot;Authorization: EndpointKey ＜上記で発行したキー＞\u0026quot; -H \u0026quot;Content-type: application/json\u0026quot; -d \u0026quot;{'question':'\u0026lt;質問文\u0026gt;'}\u0026quot; Linux の curl コマンドを使用できる環境であれば、上記のように実行するだけで JSON 形式のレスポンスを確認することができます。 Node.js から QnA Maker の REST API を呼び出す Node.js から HTTP POST リクエストを送って JSON レスポンスを取得してみます。 HTTP リクエストを行うためのモジュールとして、ここでは request モジュールを使用します。 JavaScript ファイルを作成するディレクトリと同じディレクトリ内で、下記のようにインストールしておいてください。 $ npm install request QnAMaker の TypeScript (JavaScript) API ドキュメントはこちら。すごい探しにくいです。。。 QnAMaker class | Microsoft Docs 下記のサンプルコードは、コマンドライン引数で入力した「質問文」を QnA Maker REST API のリクエストとして送り、その結果を標準出力へ出力します。 qna.js const HOST_NAME = \u0026#39;https://xxx.azurewebsites.net/qnamaker\u0026#39;; const KNOWLEDGE_BASE_ID = \u0026#39;xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\u0026#39;; const ENDPOINT_KEY = \u0026#39;xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\u0026#39;; // request モジュールの初期化 const request = require(\u0026#39;request\u0026#39;).defaults({ headers: { \u0026#39;Authorization\u0026#39;: `EndpointKey ${ENDPOINT_KEY}`, \u0026#39;Content-type\u0026#39;: \u0026#39;application/json\u0026#39;, }, // HTTP プロキシをハードコードする場合（HTTP_PROXY 環境変数でも設定可） // proxy: \u0026#39;http://proxy.example.com:23400/\u0026#39; }) // POST リクエスト用のデータを作成する function createRequest(question) { return { uri: `${HOST_NAME}/knowledgebases/${KNOWLEDGE_BASE_ID}/generateAnswer`, body: JSON.stringify({question: question}) } } // QnA Maker からのレスポンスを処理する（標準出力に出力するだけ） function onResponse(err, res, body) { if (err) { console.error(\u0026#39;Error: \u0026#39; + err.message); return; } console.log(body); } // エントリポイント（REST API を呼び出す） (function main() { const question = process.argv[2] request.post(createRequest(question), onResponse); })(); 実行例 $ node qna.js \u0026#34;取扱説明書をなくしてしまったのですが\u0026#34; { \u0026#34;answers\u0026#34;: [ { \u0026#34;questions\u0026#34;: [ \u0026#34;取扱説明書をなくしてしまったのですが、新たにもらえませんか。\u0026#34; ], \u0026#34;answer\u0026#34;: \u0026#34;［こちら](#dummy)から最新の取扱説明書（PDF）をダウンロードして...\u0026#34;, \u0026#34;score\u0026#34;: 49.8, \u0026#34;id\u0026#34;: 623, \u0026#34;source\u0026#34;: \u0026#34;https://nestle.jp/brand/ndg/faq/expressly/\u0026#34;, \u0026#34;metadata\u0026#34;: [] } ] }"
},
{
url: "/p/arfdp4b/",
title: "gnuplot サンプル: 関数のある点から x軸、y軸に向かって線を引く (cross_line.gp)",
date: "2002-12-04T00:00:00Z",
body: "gnuplot サンプル: 関数のある点から x軸、y軸に向かって線を引く (cross_line.gp) lib/cross_line.gp ## 関数のある点から x軸、y軸に向かって線を引きます。# f(x) に対象の関数を指定し、x 座標を指定します。## 使用例:# f(x) = sin(x)# call \u0026#39;lib/cross_x.gp\u0026#39; \u0026#39;pi/4\u0026#39;# plot [-pi:pi] f(x)#set arrow from $0, 0 to $0, f($0) nohead lt 3 lw 3 set arrow from 0, f($0) to $0, f($0) nohead lt 3 lw 3 set zeroaxis"
},
{
url: "/p/fwyi2fh/",
title: "QnA Maker (4) Python から QnA Maker の API を利用する",
date: "2019-06-04T00:00:00Z",
body: "QnA Maker (4) Python から QnA Maker の API を利用する QnA Maker は REST API を提供しているので、HTTP リクエストを発行できるプログラミング言語から簡単に制御することができます。 ここでは、Python に標準で付属している urllib.request モジュールを使って HTTP リクエストを発行し、QnA Maker にアクセスしてみます。 事前準備（アクセスキーの準備） REST API を使用するには、HTTP リクエストのヘッダ情報としてアクセスキーを付加する必要があります。 こちらの記事 を参考に、下記のどちらかのアクセスキーを確認しておいてください。 サブスクリプションキー (Subscription Key) \u0026hellip; 管理用 エンドポイントキー (Endpoint Key) \u0026hellip; クエリ用 アクセスキーは 9d16b3e6345489ad4a57a0755eb4f96a のような 16 進数文字列です。 QnA のクエリ実行だけであればエンドポイントキーの方を使えば大丈夫ですが、ナレッジベースの作成や更新などを行う場合は、サブスクリプションキーの方を使う必要があります。 QnA Maker の REST API を呼び出す Python ライブラリ REST API は HTTP リクエストを送るだけで使用できるので、ここでは自力で QnA Maker の API を使用するライブラリを作ってみます。 下記の QnaRequest クラスは、ナレッジベースの一覧を取得する getAllKnowledgeBases メソッドと、指定したナレッジベースの情報を取得する getKnowledgeBase メソッドを提供しています。 戻り値は JSON 形式のテキストです。 mylib/qna.py import urllib.request class QnaRequest: BASE_URL = \u0026#39;https://westus.api.cognitive.microsoft.com/qnamaker/v4.0\u0026#39; def __init__(self, subscriptionKey): self._subscriptionKey = subscriptionKey self._setup_opener() def _setup_opener(self): self._opener = urllib.request.build_opener() self._opener.addheaders = [ (\u0026#39;Ocp-Apim-Subscription-Key\u0026#39;, self._subscriptionKey) ] def _get(self, path): with self._opener.open(QnaRequest.BASE_URL + path) as res: return res.read().decode(\u0026#39;utf-8\u0026#39;) def getAllKnowledgeBases(self): \u0026#34;\u0026#34;\u0026#34;すべてのナレッジベースの情報を取得します。\u0026#34;\u0026#34;\u0026#34; return self._get(\u0026#39;/knowledgebases/\u0026#39;) def getKnowledgeBase(self, id): \u0026#34;\u0026#34;\u0026#34;指定したナレッジベースの情報を取得します。\u0026#34;\u0026#34;\u0026#34; return self._get(\u0026#39;/knowledgebases/{}\u0026#39;.format(id)) HTTP リクエストを送るときには、Ocp-Apim-Subscription-Key ヘッダでアクセス用のキーを付加するようにしています。 QnA Maker には他にもたくさん REST API が用意されています。 下記のサイトを参考にすれば、同じように実装できると思います。 QnA Maker REST API Reference Node.js で QnA Maker REST API を使用する方法 テスト mylib/qna.py ファイルに実装した QnaRequest クラスを使って REST API を呼び出してみます。 ここでは、ナレッジベースの一覧を取得しています。 main.py from mylib.qna import QnaRequest # QnA のサブスクリプションキー（Azure ポータルで確認） subscriptionKey = \u0026#39;9d16b3e6345489ad4a57a0755eb4f96a\u0026#39; # QnA Maker の REST API を呼び出す qna = QnaRequest(subscriptionKey) json = qna.getAllKnowledgeBases() print(json) ナレッジベースがひとつだけ登録されている状態で実行すると、下記のように結果が返ってきます。 実行結果 { \u0026#34;knowledgebases\u0026#34;: [ { \u0026#34;id\u0026#34;: \u0026#34;3700ed24-c581-c146-549b-4129f552e5e8\u0026#34;, \u0026#34;hostName\u0026#34;: \u0026#34;https://sample-qna.azurewebsites.net\u0026#34;, \u0026#34;lastAccessedTimestamp\u0026#34;: \u0026#34;2019-05-29T03:27:15Z\u0026#34;, \u0026#34;lastChangedTimestamp\u0026#34;: \u0026#34;2019-04-17T08:49:06Z\u0026#34;, \u0026#34;lastPublishedTimestamp\u0026#34;: \u0026#34;2019-04-17T06:33:42Z\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;My Sample Knowledge Base\u0026#34;, \u0026#34;userId\u0026#34;: \u0026#34;b931da0aee87aab17af1c3b7c0ec48ef\u0026#34;, \u0026#34;urls\u0026#34;: [ \u0026#34;http://www.jma.go.jp/jma/kishou/know/faq/index.html\u0026#34; ], \u0026#34;sources\u0026#34;: [], \u0026#34;language\u0026#34;: \u0026#34;Japanese\u0026#34;, \u0026#34;enableHierarchicalExtraction\u0026#34;: false, \u0026#34;createdTimestamp\u0026#34;: \u0026#34;2019-04-17T06:27:16Z\u0026#34; } ] }"
},
{
url: "/p/e2h3dg4/",
title: "gnuplot サンプル: いろんなグラフ用の関数 (functions.gp)",
date: "2002-12-06T00:00:00Z",
body: "gnuplot サンプル: いろんなグラフ用の関数 (functions.gp) lib/functions.gp ## Gabor のマザー・ウェーブレット## 使用例:# plot [-20:20] gabor_mother(x, 8)#gabor_mother(x,sigma) = (1/(2*sqrt(pi)*sigma)) * exp(-x**2/sigma**2) * cos(x) ## メキシカン・ハット#mexican_hat(x) = (1-2*x**2)*exp(-x**2) ## 正規分布## 1# f(x) = ----------- e ^(- (x-μ)^2 / 2σ^2)# √(2π)σ## σ … 散らばり具合 -- a# μ … 平均値 -- b### 使用例：# plot normal_distribution(x, 3, 0)#normal_distribution(x, a, b) = exp(-((x-b)**2)/(2*(a**2))) / sqrt(2*pi)*a # シグモイド関数sigm(x) = 1 / (1 + exp(-x))"
},
{
url: "/p/92s2tau/",
title: "gnuplot: スクリプト内での有限ループの書き方",
date: "2004-01-03T00:00:00Z",
body: "gnuplot: スクリプト内での有限ループの書き方 ループ処理の回数を有限にするには、1 つのファイルでループ終了判定用変数を設定し、その中からループ処理を行うファイルを呼び出します。 loop_test.gp i = 0 call \u0026#39;sub.gp\u0026#39; sub.gp i = i + 1 print i if (i \u0026lt; 10) reread 上の 2 つのファイルを用意し、 次のようにすると、1～10 までを表示します。 call \u0026#39;loop_test.gp\u0026#39;"
},
{
url: "/p/yit3cku/",
title: "Next.js の API Routes 機能",
date: "2021-11-01T00:00:00Z",
body: "Next.js の API Routes 機能"
},
{
url: "/p/23a8fgp/",
title: "gnuplot: gnuplot を計算機として使う (print)",
date: "2004-01-03T00:00:00Z",
body: "gnuplot: gnuplot を計算機として使う (print) gnuplot の print コマンドを使えば、簡易電卓として使用できます。 例: e^x の値を表示 print exp(x)"
},
{
url: "/p/sc7r4wm/",
title: "gnuplot: gnuplot のテスト表示を行う (test)",
date: "2004-01-03T00:00:00Z",
body: "gnuplot: gnuplot のテスト表示を行う (test) gnuplot による描画をテストするためのコマンドとして test コマンドが用意されています。 表示サンプル gnuplot\u0026gt; test 図: test コマンドの出力"
},
{
url: "/p/t7gqxyf/",
title: "プロキシ環境から Electron をインストールできない場合の対処方法",
date: "2020-06-24T00:00:00Z",
body: "プロキシ環境から Electron をインストールできない場合の対処方法 問題 プロキシ環境下で、Electron (9.0.5) をインストールしようとしたら、まぁいろいろとエラーになってハマりました。 どうも、node install.js の実行がうまくいっていないようです。 D:\\sandbox\u0026gt; npm install electron --save-dev \u0026gt; core-js@3.6.5 postinstall D:\\sandbox\\node_modules\\core-js \u0026gt; node -e \u0026#34;try{require(\u0026#39;./postinstall\u0026#39;)}catch(e){}\u0026#34; \u0026gt; electron@9.0.5 postinstall D:\\sandbox\\node_modules\\electron \u0026gt; node install.js RequestError: read ECONNRESET at ClientRequest.\u0026lt;anonymous\u0026gt; (D:\\sandbox\\node_modules\\got\\source\\request-as-event-emitter.js:178:14) at Object.onceWrapper (events.js:422:26) at ClientRequest.emit (events.js:327:22) at ClientRequest.origin.emit (D:\\sandbox\\node_modules\\@szmarczak\\http-timer\\source\\index.js:37:11) at TLSSocket.socketErrorListener (_http_client.js:467:9) ... ECONNRESET ってことはプロキシの設定かなぁと思ったけど、プロキシは npm config set proxy ... でちゃんとセットしているし、なんだろう。。。 解決方法 と調べていたら、下記の Electron のチュートリアルに書いてありました。 Installation - Proxies | Electron If you need to use an HTTP proxy, you need to set the ELECTRON_GET_USE_PROXY variable to any value, plus additional environment variables depending on your host system\u0026rsquo;s Node version. なんと、 ELECTRON_GET_USE_PROXY などをセットしないといけないとのこと。 次のような感じでプロキシ設定したら、うまくインストールできました。 Windows の場合 $ set ELECTRON_GET_USE_PROXY=1 $ set GLOBAL_AGENT_HTTPS_PROXY=http://proxy.example.com:8080 $ npm install electron --save-dev わかりにくい。。。 （おまけ）electron-builder の場合 ちなみに、Electron アプリの配布パッケージを作成するための electron-builder は、プロキシ設定として HTTPS_PROXY 環境変数を参照するようです。 プロキシ環境から実行するときは、これをセットして実行しないと必要なモジュールをダウンロードできずにエラーになります。 Windows の場合 $ set HTTPS_PROXY=http://proxy.example.com:8080 $ npx electron-builder --win --x64 --dir"
},
{
url: "/p/yhs2bjs/",
title: "MongoDB 雑多メモ",
date: "2013-10-22T00:00:00Z",
body: "MongoDB 雑多メモ"
},
{
url: "/p/5q4epyb/",
title: "AWS CloudFormation の設定例: SNS トピックを Lambda 関数からサブスクライブする",
date: "2021-04-19T00:00:00Z",
body: "AWS CloudFormation の設定例: SNS トピックを Lambda 関数からサブスクライブする 何をするか？ ここでは、CloudFormation (SAM) のテンプレートを使って、SNS トピックをサブスクライブする Lambda 関数を定義してみます。 サブスクライブ対象とする SNS トピック自体は、あらかじめ何らかの方法で作成済みであり、次のような ARN を取得できているものとします。 SNS トピックの ARN arn:aws:sns:ap-northeast-1:123456789012:mytopic 上記のような CloudFormation スタックが完成すると、マネージメントコンソールや CLI で SNS トピックのメッセージを発行して、Lambda 関数にイベントが届くことを確認できます。 参考リンク CloudFormation で SNS トピックの作成 CloudFormation の設定例: S3 通知を SNS トピックに Publish する テンプレートの記述例 次の SAM テンプレートでは、Lambda 関数を定義しつつ、そのイベントソースとして SNS トピックを設定しています。 イベントソースの指定は、実際には、SNS トピックに Lambda 関数をサブスクライブすることを意味しています。 SNS トピックの ARN は、入力パラメータ TopicArn のデフォルト値として指定しています。 template.yml AWSTemplateFormatVersion:2010-09-09Transform:AWS::Serverless-2016-10-31Parameters:TopicArn:Type:StringDefault:arn:aws:sns:ap-northeast-1:123456789012:mytopicResources:MyFunction:Type:AWS::Serverless::FunctionProperties:Runtime:python3.7Handler:index.handlerInlineCode:|import json def handler(event, context): s = json.dumps(event, indent=2) print(\u0026#39;Message received from SNS:\u0026#39; + s) return {\u0026#39;body\u0026#39;: s, \u0026#39;statusCode\u0026#39;: 200}# Lambda 関数を SNS トピックにサブスクライブするEvents:MySnsEvent:Type:SNSProperties:Topic:!Ref TopicArn Lambda 関数の実装は InlineCode としてテンプレートに埋め込んでいます。 ここでは、単純に第一引数 (event) の内容を出力しています。 デプロイ AWS CLI で次のように実行して、CloudFormation スタックを生成します。 もちろん、CloudFormation のマネージドコンソール（Web サイト）から実行しても構いません。 $ aws cloudformation deploy --stack-name mystack \\ --template-file template.yml \\ --capabilities CAPABILITY_IAM しばらく待つと、SNS トピックにサブスクライブされた Lambda 関数リソースが生成されます。 テスト実行 SNS トピックのマネージメントコンソールから「メッセージを発行」を実行すると、Lambda 関数は次のようなメッセージを受信します。 Message received from SNS: { \u0026#34;Records\u0026#34;: [ { \u0026#34;EventSource\u0026#34;: \u0026#34;aws:sns\u0026#34;, \u0026#34;EventVersion\u0026#34;: \u0026#34;1.0\u0026#34;, \u0026#34;EventSubscriptionArn\u0026#34;: \u0026#34;arn:aws:sns:ap-northeast-1:123456789012:mytopic:0884c0db-5d81-4e13-829f-596f7ea9f8ad\u0026#34;, \u0026#34;Sns\u0026#34;: { \u0026#34;Type\u0026#34; : \u0026#34;Notification\u0026#34;, \u0026#34;MessageId\u0026#34; : \u0026#34;789b67e7-9bd8-5a6e-99d0-3f10e520edf7\u0026#34;, \u0026#34;TopicArn\u0026#34; : \u0026#34;arn:aws:sns:ap-northeast-1:123456789012:mytopic\u0026#34;, \u0026#34;Subject\u0026#34; : \u0026#34;Message Title\u0026#34;, \u0026#34;Message\u0026#34; : \u0026#34;Message Body\u0026#34;, \u0026#34;Timestamp\u0026#34; : \u0026#34;2021-04-19T12:51:04.019Z\u0026#34;, \u0026#34;SignatureVersion\u0026#34; : \u0026#34;1\u0026#34;, \u0026#34;Signature\u0026#34; : \u0026#34;bKXAFppLnPMeajvylkQvjiH/9RNeAlNfxbBC7HJbiOt7SKrw9oVk+CI1ZYsADcNt9aAtAOysdHrFD97J/N4n5o+tV+Dz5hsjxqKskYOCrYDRTTqLyhwa5OBtjAhU74IZy9ByfBSQWfOD1I5AFp0FLUWR8ieop/ZTV5buf4FodNm4scwW18nUJ1D5iTPNy3NinWq0wVP2FT7Ykt9HCdNleaFamMZ+war4OHsRhOgvDqOV4auZ2yvayMf70eJPHLbuQn09E0IlQYsvUArTOSknbFK3lsbeLfJBHmIa2qnuZm+VTknNgJxkCJNyer+7EKTrOABYqXsz55ENYJsn5xvjCA==\u0026#34;, \u0026#34;SigningCertURL\u0026#34; : \u0026#34;https://sns.ap-northeast-1.amazonaws.com/SimpleNotificationService-94bdb98bd93083010a507c1833636cda.pem\u0026#34;, \u0026#34;UnsubscribeURL\u0026#34; : \u0026#34;https://sns.ap-northeast-1.amazonaws.com/?Action=Unsubscribe\u0026amp;SubscriptionArn=arn:aws:sns:ap-northeast-1:123456789012:mytopic:97989c34-955f-49c8-856c-1b8e3e926a6f\u0026#34; } } ] } ちなみに、AWS CLI を使って SNS トピックにメッセージ発行 (publish) することもできます。 $ aws sns publish \\ --subject \u0026#34;Message Title\u0026#34; \\ --message \u0026#34;Message Body\u0026#34; \\ --topic-arn arn:aws:sns:ap-northeast-1:123456789012:mytopic"
},
{
url: "/p/tx6md39/",
title: "TypeScriptの環境/設定について",
date: "2022-04-04T00:00:00Z",
body: "TypeScriptの環境/設定について"
},
{
url: "/p/weow5dm/",
title: "React実装例: クリックで開閉可能なツリービューを作る",
date: "2020-11-11T00:00:00Z",
body: "React実装例: クリックで開閉可能なツリービューを作る ここでは、React コンポーネントとして、開閉可能なツリービューを作ってみます。 コンポーネント名はツリーのノードを示す TreeNode です。 図: TreeNode コンポーネントの表示例 初期の表示内容としては、ルートの TreeNode を 1 つだけ配置し、そのラベルをクリックしたときに、子要素となる TreeNode を 3 つ生成して表示します。 実際のアプリケーションでは、このタイミングで GraphQL サーバーなどからデータを取得してツリー展開していく、といったことができると思います。 下記は TreeNode コンポーネントの実装です。 components/TreeNode.tsx import * as React from \u0026#39;react\u0026#39;; import styles from \u0026#39;./TreeNode.scss\u0026#39;; export const TreeNode: React.FC\u0026lt;{label: string}\u0026gt; = ({label}) =\u0026gt; { const [isOpen, setIsOpen] = React.useState(false); const [childNodes, setChildNodes] = React.useState(null); // チェックボックスのクリックで isOpen ステートを更新 const handleChange = (e: React.ChangeEvent\u0026lt;HTMLInputElement\u0026gt;) =\u0026gt; { setIsOpen(e.target.checked); } // isOpen ステートの変更を監視し、childNodes に子ノードとなる TreeNode をセットする React.useEffect(() =\u0026gt; { setChildNodes(isOpen ? createChildNodes(label) : null); }, [isOpen]) return \u0026lt;\u0026gt; \u0026lt;div className={styles.TreeNode}\u0026gt; \u0026lt;label\u0026gt; \u0026lt;input type=\u0026#34;checkbox\u0026#34; onChange={handleChange} /\u0026gt; \u0026lt;span className={styles.TreeNode_icon} /\u0026gt; {label} \u0026lt;/label\u0026gt; \u0026lt;div className={styles.TreeNode_children}\u0026gt; {childNodes} \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/\u0026gt;; }; // 3つの TreeNode 要素を適当に作る function createChildNodes(labelPrefix: String): React.ReactElement { const labels = [...Array(3)].map((_, i) =\u0026gt; labelPrefix + \u0026#39;-\u0026#39; + (i + 1)); return \u0026lt;\u0026gt; {labels.map(x =\u0026gt; \u0026lt;TreeNode key={x} label={x} /\u0026gt;)} \u0026lt;/\u0026gt;; }; ツリーノードの開閉状態は、HTML のチェックボックス (\u0026lt;input type=\u0026quot;checkbox\u0026quot;\u0026gt;) から取得できる情報をそのまま利用しています（上記の例では e.target.checked で参照しています）。 この状態が true になったとき、動的に子ノードとなる TreeNode を 3 つ作成して表示しています (createChildNodes)。 子ノードも TreeNode なので、クリックすれば無限に掘り進んでいくことができます。 下記は表示をカスタマイズするためのスタイルシートです。 上記コードから CSS Modules の仕組みでインポートしています。 開閉処理自体は TreeNode.tsx 側のコードで完結しているので、スタイル設定がなくても最低限の動作はしますが、このスタイル設定により、 チェックボックスの代わりにフォルダアイコン（open/closed) を表示 子ノードは少しインデントして表示 といったことを行っています。 components/TreeNode.scss .TreeNode { label { display: block; \u0026amp;:hover { background: #eee; } } input[type=checkbox] { display: none; /* チェックボックスの四角は非表示 */ } input[type=checkbox] ~ .TreeNode_icon::before { content: \u0026#39;\\1F4C1\u0026#39;; /* Closed folder icon */ } input[type=checkbox]:checked ~ .TreeNode_icon::before { content: \u0026#39;\\1F4C2\u0026#39;; /* Open folder icon */ } \u0026amp;_children { padding-left: 1em; } } あとは、どこかのコンポーネントから、次のようにルート要素となる TreeNode を配置すれば表示できます。 components/App.tsx import * as React from \u0026#39;react\u0026#39;; import { TreeNode } from \u0026#39;./TreeNode\u0026#39;; export const App: React.FC = () =\u0026gt; { return \u0026lt;div style={{margin: \u0026#39;1rem\u0026#39;}}\u0026gt; \u0026lt;TreeNode label=\u0026#34;項目1\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt;; };"
},
{
url: "/p/8myms6s/",
title: "LUIS と QnA Maker でキーの管理方法が異なるのはなぜか？",
date: "2019-03-18T00:00:00Z",
body: "LUIS と QnA Maker でキーの管理方法が異なるのはなぜか？ LUIS や QnA Maker サービスを利用するためのエンドポイントキーは、下記の 2 種類が提供されます。 実運用のためのキー: チャットクライアントなどからの、一般的な問い合わせを処理するためのキー。 管理用のキー: 各サービスの情報を取得したり、データを編集したりするためのキー。 LUIS も QnA Maker も便利なサービスなのですが、Azure リソースとの結びつけ方法や、キーの管理方法が異なっているため、最初はわけがわからなくなるかもしれません。 例えば、Azure ポータル上の RESOURCE MANAGEMENT / Keys のページで表示されるキー（サブスクリプションキー）が、LUIS の場合は実運用のためのキーであるのに対し、QnA Maker の場合は管理用のキー であったりします。 LUIS/QnA を使用する場合は、それぞれ、エンドポイントキーとしてどちらのキーを使用するかを間違えないようしなければいけません。 LUIS のサブスクリプションキー（実運用のためのキー）: Azure ポータルの LUIS リソースの Keys で表示されるもの LUIS のオーサリングキー（管理用のキー）: LUIS ポータルの Authoring Key で表示されるもの QnA Maker のエンドポイントキー（実運用のためのキー）: QnA Maker ポータルのプロファイル設定で表示されるもの QnA Maker のサブスクリプションキー（管理用のキー）: Azure ポータルの QnA Maker リソースの Keys で表示されるもの この時点で、キーの管理方法が QnA Maker と LUIS では完全に逆になっています。 Azure 上でのインタフェースは LUIS リソースと QnA Maker リソースで見た目が同じなので、混乱に拍車をかけています。 図: LUIS リソースの Keys 管理画面 図: QnA Maker リソースの Keys 管理画面 なぜこのようなことになっているのか、Microsoft のサポートの方に確認してみたところ、下記のような回答をいただきました。 簡単に言うと、各サービスの生い立ちの違いによるものだそうです。 わかりにくいですが、この辺りはそういうものなのだと納得するしかないですね。 各サービスの違いについて LUIS は 当初 Azure と紐づかないサービスとして提供されており、Azure のリソースがなくても新しい LUIS のアプリケーションを作成できるように作られたサービスになっておりました。 そのため、アプリケーションの作成や編集を行うオーサリングキーは LUIS ポータルで作成されるものになっております。 後に LUIS が Azure の Cognitive Service として正式にリリースされた後、Azure のリソースとして関連付けるためにエンドポイントキーを Azure ポータルで取得する LUIS のリソースキーと紐づけております。 それぞれの LUIS のアプリケーションそのものは Azure リソースに紐づいておらず、各ユーザーアカウント (メールアドレス) に紐づいており、エンドポイントへのアクセスキーのみが Azure のリソースとして存在しております。 対しまして QnA Maker は Azure のリソースと紐づくことを当初から想定してリリースされたサービスになっているため、アプリケーションの作成や編集を行うために Azure のサブスクリプションキーが必要になります。 このように LUIS と QnA Maker ではリリースまでの経緯に違いがあることから、各種キーの扱いも異なっております。"
},
{
url: "/p/nujyfsy/",
title: "AWS CDK 入門: cdk コマンドのインストールから Hello World まで",
date: "2021-10-04T00:00:00Z",
body: "AWS CDK 入門: cdk コマンドのインストールから Hello World まで CDK とは AWS CDK (Cloud Development Kit) を使うと、TypeScript や Python を使って AWS リソースの生成を自動化することができます。 大きなプロジェクトでは、CloudFormation や SAM によるスタック生成用のテンプレートが長大になりがちですが、CDK を使うことで CloudFormation テンプレートの生成処理を隠蔽し、効率的にインフラ定義を行うことができます。 CDK の利点 をざっと挙げると以下のような感じです。 TypeScript、Python などのパワフルな言語機能を使ってインフラ定義を行うことができる。 各種リソース間の参照を、オブジェクトのプロパティ参照という自然な形で表現できる。 コンストラクト (Construct Library) という再利用可能なライブラリの提供により、様々なユースケースに対応した AWS リソース群を短いコードで定義できる。 VS Code (TypeScript) 、PyCharm (Python) などで型情報の補完が効くため、AWS リソースに設定可能なプロパティを見つけやすい。明らかに間違った設定はコンパイル時に気付くことができる。 Lambda 関数デプロイ時などに必要になる ZIP パッケージング、および S3 一時バケットの生成を自動で行ってくれる。 一方、CDK の欠点 としては、基本的に AWS に特化したツールであるため、Terraform や Serverless Framework のように様々なクラウド (Azure, AWS, GCP) に対応できないという点が挙げられます。 Terraform などの汎用ツールに比べて、CDK は学習コストも比較的高いです。 Azure なども同じツールで構築したいとか、それほど細かい制御は必要ないということであれば、Terraform などを使った方がいいかもしれません。 ただ、CDK を使っている限り、AWS の最新のリソースにも即対応できることが保証されますし、AWS CloudFormation に関しての知識は身につけやすいでしょう。 CDK Toolkit のインストール CDK によるデプロイには cdk コマンドを使用します。 まずはこのコマンドを使えるようにするため、aws-cdk パッケージをインストールします（CDK 本体の実行には Node.js が必要です）。 $ npm install -g aws-cdk cdk コマンドが実行できるようになっていれば OK です。 $ cdk --version 1.125.0 (build 67b4921) CDK で Hello World まずは、手始めに cdk deploy コマンドで S3 のバケットを含む CloudFormation スタックを作るところまでやってみます。 前提条件として、AWS の認証情報を設定しておく必要があります（aws configure などで情報が表示できれば OK）。 AWS の初期設定: AWS CLI と認証情報の設定 cdk init app ここでは、空の myapp ディレクトリを作成して、そのディレクトリ内に CDK アプリを構成していくことにします。 CDK アプリというのは、CloudFormation スタックを生成する CDK コードと、Lambda 関数などのコードをまとめた概念です。 $ mkdir myapp \u0026amp;\u0026amp; cd myapp cdk init app コマンドを実行すると、カレントディレクトリ以下に、CDK の実行に必要な一連のファイルが生成されます。 今回は、TypeScript で CDK のコードを記述したいので、--language オプションで typescript を指定していますが、python なども指定できます。 $ cdk init app --language typescript Applying project template app for typescript # Welcome to your CDK TypeScript project! ... ✅ All done! ☝️ TypeScript 以外の言語について CDK を使ったコードは、TypeScript 以外にも Python、Java、C#、Go など、色々な言語で記述できるようになっていますが、CDK ライブラリ本体は TypeScript で実装されていて、他の言語用には JSII によるバインディングを行っています。 特にこだわりがなければ TypeScript で記述しておけばよいですが、Python を使っている例もよく見られます。 言語として TypeScript を選んだ場合は、次のようなファイル群が生成されます（これら全体が CDK アプリと呼ばれます）。 CDK によるデプロイを行う場合、このディレクトリ以下で cdk deploy コマンドを実行することになります。 cdk init app で自動生成されるファイル群 myapp/ +-- .gitignore +-- .npmignore +-- bin/ +-- cdk.json +-- jest.config.js +-- lib/ +-- node_modules/ +-- package-lock.json +-- package.json +-- README.md +-- test +-- tsconfig.json cdk deploy でスタックを作成する この時点で、cdk deploy コマンドを実行する準備が整っています。 デフォルトではディレクトリ名（ここでは myapp）に基づいて、MyappStack という名前の CloudFormation スタックが生成されるようになっていますが、スタック名は用途に応じて適切な名前を付けた方がよいでしょう（後述）。 実際にデプロイできるか試してみたければ次のように実行します（ほぼ空っぽのスタックが生成されます）。 cdk deploy コマンドを実行してデプロイ実行（スタックの作成） CloudFormation コンソール を開いて、MyappStack スタックが生成されていることを確認 ☝️ CI/CD 環境上での cdk コマンド cdk init app で作成された package.json には、devDependencies として aws-cdk をインストールするように記述されています。 また、NPM スクリプトとして cdk コマンドが定義されています。 よって、GitHub Actions や AWS CodeBuild などの CI/CD 環境上で cdk コマンドを実行したければ、npm ci で依存モジュールをインスト―ルしてから、npm run cdk ... のように実行すれば OK です。 npx コマンドでダイレクトに aws-cdk を実行する方法もありますが、いずれにしても npm ci による依存モジュールのインストールは必要になります。 S3 バケットを追加してみる cdk init app コマンドで CDK アプリのテンプレートを作成した場合、スタックの定義は lib ディレクトリ以下の .ts ファイルで実装されています。 デフォルトでは、次のような内容の Stack サブクラスが定義されていますが、ここに必要な AWS リソースを追加していくことになります。 ここでは、ファイル名が myapp-stack.ts、クラス名が MyappStack となっていますが、これは親ディレクトリの名前 (myapp) から自動生成されています。 lib/myapp-stack.ts import * as cdk from \u0026#34;@aws-cdk/core\u0026#34;; export class MyappStack extends cdk.Stack { constructor(scope: cdk.Construct, id: string, props?: cdk.StackProps) { super(scope, id, props); // The code that defines your stack goes here } } S3 バケットなど、具体的な AWS リソースを生成するためには、専用のモジュール（コンストラクトライブラリ）をインストールする必要があります。 S3 の場合は @aws-cdk/aws-s3 をインストールします（Stack クラスなどのコアモジュールを提供する @aws-cdk/core は、cdk init を実行したときに自動インストールされています）。 $ npm install @aws-cdk/aws-s3 例えば、カレントスタック (this) に S3 バケットを追加するには、次のように実装します。 my-bucket という名前はこのスタック階層内でのみ一意であればよい論理 ID であり、実際に AWS リソースが生成されるときにはもう少し複雑な物理 ID（例: myappstack-mybucket15d133bf-c3w1q6f0j2xt）が割り当てられるので注意してください。 このあたりの仕組みは CloudFormation と同様です。 lib/cdk-stack.ts import * as cdk from \u0026#39;@aws-cdk/core\u0026#39;; import * as s3 from \u0026#39;@aws-cdk/aws-s3\u0026#39;; export class MyappStack extends cdk.Stack { constructor(scope: cdk.Construct, id: string, props?: cdk.StackProps) { super(scope, id, props); // The code that defines your stack goes here new s3.Bucket(this, \u0026#39;my-bucket\u0026#39;) } } この修正で既存のスタックにどのような変更が行われるかは、cdk diff コマンドで確認できます。 $ cdk diff Stack MyappStack Resources [+] AWS::S3::Bucket my-bucket mybucket15D133BF プレフィックスとして + が付いたリソースが追加されることを示しています。 問題なさそうなので、再度 cdk deploy コマンドを実行して、実際に CloudFormation スタックに反映します。 $ cdk deploy MyappStack: deploying... ☝️ TypeScript のビルドは必要ない？ CDK のコードを TypeScript で記述していますが、CDK CLI のコマンド（cdk diff や cdk deploy）を実行する前にトランスパイルしておく必要はありません。 これは、ts-node によって TypeScript コードを直接実行するようになっているからです。 先にビルドエラーを確認しておきたければ、明示的に npm run build (tsc) することも可能です。 cdk destroy でスタックを削除する CDK の HelloWorld が終了したら、CloudFormation スタックを忘れずに削除しておきましょう。 cdk destory コマンドでスタックごと削除できます。 $ cdk destroy Are you sure you want to delete: MyappStack (y/n)? y MyappStack: destroying... ✅ MyappStack: destroyed （おまけ）確認なしでデプロイ実行する cdk deploy を実行したときにスタックの情報が更新される場合は、y/n の確認プロンプトが表示されます。 GitHub Actions や CodeBuild などでデプロイを自動化したいときは、この確認で止まってしまうと都合が悪いので、--require-approval never オプションを指定してすべて y を選択したように動作させることができます。 $ cdk deploy --require-approval never GitHub にプッシュする CDK アプリを cdk init app コマンドで生成した場合は、Git リポジトリ (.git) も自動生成されて、初期コミットも済んでいる状態になっています。 これをベースに開発を続けていく場合は、GitHub などにプッシュしておきましょう。 すでにコミット内容があるので、GitHub のリポジトリを作成するときは、次のように空のリポジトリとして作成します。 GitHub の New repository を選択して新規リポジトリ作成画面を開く Initialize this repository with: の項目では何もチェックを入れず、Create repository ボタンを押す。 あとは、必要があればローカル編集をコミットし、 $ git add . $ git commit 次のように GitHub にプッシュすれば OK です。 $ git remote add origin https://github.com/\u0026lt;UserName\u0026gt;/\u0026lt;RepoName\u0026gt;.git $ git branch -M main $ git push -u origin main 参考情報 上記の例では必要ありませんでしたが、CDK のデプロイ (cdk deploy) を行うとき、ブートストラップが必要だと表示されることがあります。 その場合は、下記を参考にして cdk bootstrap を実行してください。 AWS CDK メモ: ブートストラップ処理を実行する (cdk bootstrap) CDK アプリを TypeScript 用に生成すると、デフォルトでは NPM が使われるようになっています。 Yarn を使いたい場合は下記を参考にしてください。 AWS CDK メモ: CDK アプリのパッケージ管理に Yarn を使う方法"
},
{
url: "/p/53o7p8p/",
title: "Unityスクリプト: オブジェクトを移動する (Transform.position)",
date: "2020-02-10T00:00:00Z",
body: "Unityスクリプト: オブジェクトを移動する (Transform.position) ゲームオブジェクトに設定された Transform コンポーネントを操作することで、ゲームオブジェクトを移動させることができます。 Transform コンポーネントのオブジェクトは下記のいずれかの方法で取得できます。 Transform tf = gameObject.GetComponent\u0026lt;Transform\u0026gt;(); Transform tf = gameObject.transform; Transform クラス には、ゲームオブジェクトを移動させるためのプロパティやメソッドが定義されています。 ワールド座標での位置 (Transform.position) Transform.position プロパティは、ワールド座標でのオブジェクトの位置を示します。 次の例では、3 つのオブジェクトの X 座標を -2、0、2 に設定しています。 using UnityEngine; public class Sample : MonoBehaviour { private void Start() { GameObject cube = GameObject.CreatePrimitive(PrimitiveType.Cube); GameObject sphere = GameObject.CreatePrimitive(PrimitiveType.Sphere); GameObject capsule = GameObject.CreatePrimitive(PrimitiveType.Capsule); cube.transform.position = new Vector3(-2, 0, 0); sphere.transform.position = new Vector3(0, 0, 0); capsule.transform.position = new Vector3(2, 0, 0); } } += 演算子や -= 演算子を使用すれば、指定した数値分だけワールド座標での位置を移動できます。 cube.transform.position += new Vector3(-2, 0, 0); X、Y、Z 軸方向にだけ動かしたい場合は、Vector3 クラスに用意されている次のような定数を利用できます。 定数 値 Vector3.left Vector3(-1, 0, 0) Vector3.right Vector3(1, 0, 0) Vector3.up Vector3(0, 1, 0) Vector3.down Vector3(0, -1, 0) Vector3.forward Vector3(0, 0, 1) Vector3.back Vector3(0, 0, -1) cube.transform.position += Vector3.left * 2; ローカル座標での位置 (Transform.localPosition) 親オブジェクトからの相対位置（ローカル座標）で位置を指定したい場合は、Transform.position プロパティの代わりに、Transform.localPosition プロパティを指定します。 次の例では、親オブジェクト (Cube) に対して、子オブジェクト (Sphere と Capsule) を、それぞれローカル座標とグローバル座標で位置指定した場合の違いを示しています。 using UnityEngine; public class Sample : MonoBehaviour { private void Start() { GameObject parent = GameObject.CreatePrimitive(PrimitiveType.Cube); GameObject child1 = GameObject.CreatePrimitive(PrimitiveType.Sphere); GameObject child2 = GameObject.CreatePrimitive(PrimitiveType.Capsule); // Set parent-child relation child1.transform.parent = parent.transform; child2.transform.parent = parent.transform; // Move objects parent.transform.position = Vector3.up * 2; child1.transform.localPosition = Vector3.right * 2; child2.transform.position = Vector3.right * 2; } } 子 Sphere (child1) はローカル座標で位置を指定しているので、親 Cube からの相対的な座標で右に表示されています。 一方、子 Capsule (child2) はグローバル座標で位置を指定しているので、親 Cube の位置に関係なく、X = 2 の位置に表示されています。 相対的に移動させる (Transform.Translate) 現在の位置から移動量を指定して移動するには、Transform.Translate() メソッド を使用します。 Transform.Translate メソッド void Translate(Vector3 translation, Space relativeTo=Space.Self); void Translate(Vector3 translation, Transform relativeTo); void Translate(float x, float y, float z, Space relativeTo=Space.Self); void Translate(float x, float y, float z, Transform relativeTo); Space 型の relativeTo パラメータでは、ローカル座標 (Space.Self) かワールド座標 (Space.World) のどちらで移動させるかを指定します。 デフォルトではローカル座標 (Space.Self) になっているので、自分自身のオブジェクトが向いている方向に応じた移動を行います。 次のサンプルコードでは、Cube オブジェクトを左右に行ったり来たりさせています。 using UnityEngine; public class Sample : MonoBehaviour { private GameObject _cube; private Vector3 _direction = Vector3.right; private void Start() { _cube = GameObject.CreatePrimitive(PrimitiveType.Cube); } private void Update() { // 移動方向を切り替える float x = _cube.transform.position.x; if (x \u0026gt; 5) { _direction = Vector3.left; } else if (x \u0026lt; -5) { _direction = Vector3.right; } // 移動方向に従って少しだけ移動する _cube.transform.Translate(_direction * 10 * Time.deltaTime); } }"
},
{
url: "/p/46jrh68/",
title: "WebGL入門 (1) WebGL コンテキストの取得",
date: "2019-08-16T00:00:00Z",
body: "WebGL入門 (1) WebGL コンテキストの取得 このブラウザは canvas タグに対応していません。 上記の canvas 要素は、WebGL により描画しています。 サーフェスをクリアしているだけなので、何も表示されていないのは正しいです。 WebGL のコンテキストを取得する WebGL は、Web ブラウザ上で OpenGL の機能を使用する仕組みです。 HTML の canvas 要素をレンダリング用のサーフェストとして使用します。 canvas 要素から WebGL のコンテキスト WebGLRenderingContext を取得したら、後は OpenGL ES を用いたアプリと同じ感覚で API を呼び出していけます。 下記は、WebGL でサーフェスをクリアするだけの最低限のコードです。 gl.clearColor() でクリア色を設定しています。 HTML \u0026lt;canvas id=\u0026#34;canvas\u0026#34; width=\u0026#34;300\u0026#34; height=\u0026#34;200\u0026#34;\u0026gt;\u0026lt;/canvas\u0026gt; JavaScript function main() { const canvas = document.getElementById(\u0026#39;canvas\u0026#39;); const gl = canvas.getContext(\u0026#39;webgl\u0026#39;); if (!gl) { console.error(\u0026#39;Failed to obtain WebGL context\u0026#39;); return; } gl.clearColor(0, 0, 0.5, 1.0); // RGBA（暗い青） gl.clear(gl.COLOR_BUFFER_BIT); } window.addEventListener(\u0026#39;load\u0026#39;, main); WebGL 2.0 を使用する WebGL 2.0 の API を使用したい場合は、canvas.getContext() のパラメータを webgl から webgl2 に変更し、WebGL2RenderingContext を取得します。 const gl = canvas.getContext(\u0026#39;webgl\u0026#39;); //=\u0026gt; WebGLRenderingContext const gl2 = canvas.getContext(\u0026#39;webgl2\u0026#39;); //=\u0026gt; WebGL2RenderingContext WebGL は OpenGL ES 2.0 をベースにしており、WebGL2 は OpenGL ES 3.0 をベースにしています。 メジャーなブラウザは WebGL 2 に対応しているので、特に理由がなければ WebGL 2 の方を使っていきたいですね。 下記のようにすれば、WebGL 2.0 が使える場合はそちらを、使えない場合は WebGL 1.0 のコンテキストを取得できます。 function createWebGLContext(canvasId) { const canvas = document.getElementById(canvasId); const gl2 = canvas.getContext(\u0026#39;webgl2\u0026#39;); if (gl2) { return gl2; } console.warn(\u0026#39;Failed to obtain WebGL 2.0 context. Use 1.0 instead.\u0026#39;); const gl1 = canvas.getContext(\u0026#39;webgl\u0026#39;); if (!gl1) { throw new Error(\u0026#39;Failed to obtain WebGL 1.0 context\u0026#39;); } return gl1; } function main() { const canvas = document.getElementById('canvas-001'); const gl = canvas.getContext('webgl'); if (!gl) { console.error('Failed to obtain WebGL context'); return; } gl.clearColor(0, 0, 0.5, 1.0); gl.clear(gl.COLOR_BUFFER_BIT); } window.addEventListener('load', main);"
},
{
url: "/p/dx9is3c/",
title: "Unityスクリプト: オブジェクトを回転する (Transform.rotation)",
date: "2020-02-10T00:00:00Z",
body: "Unityスクリプト: オブジェクトを回転する (Transform.rotation) ゲームオブジェクトに設定された Transform コンポーネントを操作することで、ゲームオブジェクトを回転させることができます。 Transform コンポーネントのオブジェクトは下記のいずれかの方法で取得できます。 Transform tf = gameObject.GetComponent\u0026lt;Transform\u0026gt;(); Transform tf = gameObject.transform; Transform クラス には、ゲームオブジェクトを回転させるためのプロパティやメソッドが定義されています。 ワールド座標での回転 (Transform.rotation) Transform.rotation プロパティは、ワールド座標でのオブジェクトの回転角度を示します。 次の例では、Y 軸（上下方向）を中心とした回転角度を 45° に設定しています。 using UnityEngine; public class Sample : MonoBehaviour { private void Start() { GameObject cube = GameObject.CreatePrimitive(PrimitiveType.Cube); cube.transform.rotation = Quaternion.Euler(0, 45, 0); } } Transform.rotation プロパティには Quaternion オブジェクト を設定するのですが、上記のように Quaternion.Euler() 関数 を使用すると、直感的に Quaternion オブジェクトを生成することができます。 ローカル座標での回転 (Transform.localRotation) オブジェクト自身の向きを考慮した軸（ローカル座標）での回転角度を設定するには、Transform.rotation プロパティの代わりに、 Transform.localRotation プロパティを使用します。 次の例では、親 Cube の上下に子 Cube を配置し、それぞれ Y 軸の回転角度として 30° を設定しています。 ただし、上の Cube は localRotation プロパティ、下の Cube は rotation プロパティで回転角度を設定しています。 using UnityEngine; public class Sample : MonoBehaviour { private void Start() { GameObject parent = GameObject.CreatePrimitive(PrimitiveType.Cube); GameObject child1 = GameObject.CreatePrimitive(PrimitiveType.Cube); GameObject child2 = GameObject.CreatePrimitive(PrimitiveType.Cube); child1.transform.position = new Vector3(0, 1.5f, 0); child2.transform.position = new Vector3(0, -1.5f, 0); // Set parent-child relations child1.transform.parent = parent.transform; child2.transform.parent = parent.transform; // Rotate objects parent.transform.rotation = Quaternion.Euler(0, 30, 0); child1.transform.localRotation = Quaternion.Euler(0, 30, 0); child2.transform.rotation = Quaternion.Euler(0, 30, 0); } } 親オブジェクトを回転させると、子オブジェクトもそれに追従して回転します。 上の Cube は親オブジェクトの回転角度 30° をベースとして、自分自身の回転角度 (localRotation) の 30° で回転しているので、合計 60° の回転角度になっています。 一方、下の Cube はグローバル座標の回転角度 (rotation) を 30° に設定しているので、結局、親 Cube と同じ 30° しか回転していません。 相対的に回転させる (Transform.Rotate) 現在の回転角度からの回転量を指定して回転させるには、Transform.Rotate() メソッド を使用します。 Transform.Rotate メソッド void Rotate(Vector3 eulers, Space relativeTo=Space.Self); void Rotate(float xAngle, float yAngle, float zAngle, Space relativeTo=Space.Self); void Rotate(Vector3 axis, float angle, Space relativeTo=Space.Self); relativeTo パラメータに Space.World を指定すると、ワールド座標の軸方向をベースにして回転角度を指定することができます。 デフォルトは Space.Self になっており、自分自身の向き（ローカル座標）を考慮した回転角度を指定します。 次の例では、Cube オブジェクトを Y 軸を中心に 1 秒間に 90° 回転させています。 using UnityEngine; public class Sample : MonoBehaviour { private GameObject _cube; private void Start() { _cube = GameObject.CreatePrimitive(PrimitiveType.Cube); } private void Update() { _cube.transform.Rotate(0, 90 * Time.deltaTime, 0); // 下記のようにも書けます // _cube.transform.Rotate(Vector3.up * 90 * Time.deltaTime); } }"
},
{
url: "/p/8s4uhzv/",
title: "WebGL入門 (2) シェーダーを使用する",
date: "2019-08-17T00:00:00Z",
body: "WebGL入門 (2) シェーダーを使用する このブラウザは canvas タグに対応していません。 上記の canvas 要素は、WebGL により描画しています。 canvas の中央に 1 つの点を表示しています。 シェーダーを使うまでの手順 WebGL は OpenGL ES 2.0、WebGL 2.0 は OpenGL ES 3.0 をベースに策定されているため、プリミティブをレンダリングするには、どちらも GLSL ES 言語で記述したシェーダーコード（頂点シェーダー、フラグメントシェーダー）を用意する必要があります。 シェーダーを使用して描画するまでの流れは下記のようになります。 シェーダーオブジェクトの準備（頂点シェーダーとフラグメントシェーダー） シェーダーオブジェクトを作成する (gl.CreateShader) シェーダーコードを設定する (gl.ShaderSource) シェーダーコードをコンパイルする (gl.CompileShader) 必要があればコンパイル結果のチェック (gl.getShaderParameter) 必要があればコンパイルエラーの内容を出力 (gl.getShaderInfoLog) プログラムオブジェクトの準備 プラグラムオブジェクトを作成する (gl.CreateProgram) 2 つのシェーダーオブジェクトをアタッチする (gl.AttachShader) 2 つのシェーダーオブジェクトをリンクする (gl.LinkProgram) 必要があればリンク結果のチェック (gl.getProgramParameter) 必要があればリンクエラーの内容を出力 (el.getProgramInfoLog) レンダリング前に使用するプログラムオブジェクトを選択する (gl.UseProgram) 頂点情報などを用意して描画 (gl.drawArrays) ユーティリティ関数の作成 シェーダーオブジェクトの準備 (createShader) 指定したシェーダーコードをコンパイルしてシェーダーオブジェクトを作成する createShader 関数を作成します。 /** * シェーダーコードをコンパイルしてシェーダーオブジェクトを作成します。 * 作成に失敗した場合は null を返します。 * * @param gl WebGL コンテキスト * @param type gl.VERTEX_SHADER あるいは gl.FRAGMENT_SHADER * @param source シェーダーのソースコード */ function createShader(gl, type, source) { const shader = gl.createShader(type); if (shader == null) { console.error(\u0026#39;Failed to create a shader\u0026#39;); return null; } gl.shaderSource(shader, source); gl.compileShader(shader); // コンパイル結果を検査する const compiled = gl.getShaderParameter(shader, gl.COMPILE_STATUS); if (!compiled) { var log = gl.getShaderInfoLog(shader); console.error(\u0026#39;Failed to compile a shader\\n\u0026#39; + log); gl.deleteShader(shader); return null; } return shader; } この関数を使って、頂点シェーダーとフラグメントシェーダーをコンパイルします。 const vshader = createShader(gl, gl.VERTEX_SHADER, vshaderCode); const fshader = createShader(gl, gl.FRAGMENT_SHADER, fshaderCode); プログラムオブジェクトの準備 (createProgram) 作成した 2 つのシェーダーを実際に使用するには、プログラムオブジェクトを作成してリンクする必要があります。 シェーダーオブジェクトからプログラムオブジェクトを作成する createProgram 関数を作成します。 /** * シェーダーオブジェクトをリンクしてプログラムオブジェクトを作成します。 * 作成に失敗した場合は null を返します。 * * @param gl WebGL コンテキスト * @param vshader 頂点シェーダーオブジェクト * @param fshader フラグメントシェーダーオブジェクト */ function createProgram(gl, vshader, fshader) { var program = gl.createProgram(); if (!program) { return null; } gl.attachShader(program, vshader); gl.deleteShader(vshader); gl.attachShader(program, fshader); gl.deleteShader(fshader); gl.linkProgram(program); // リンクエラーの確認 var linked = gl.getProgramParameter(program, gl.LINK_STATUS); if (!linked) { var log = gl.getProgramInfoLog(program); console.error(\u0026#39;Failed to link a program\\n\u0026#39; + log); gl.deleteProgram(program); return null; } return program; } 上記コードで gl.attachShader の直後に gl.deleteShader を呼び出していますが、このタイミングでは削除フラグが立つだけです。シェーダーオブジェクトは、プログラムにアタッチされている状態では削除されない仕様なので、これは正しく動作します。 これで、下記のようにしてプログラムオブジェクトを作成することができます。 const vshader = createShader(gl, gl.VERTEX_SHADER, vshaderCode); const fshader = createShader(gl, gl.FRAGMENT_SHADER, fshaderCode); const program = createProgram(gl, vshader, fshader); これは定型処理になるので、直接シェーダーコードを渡してプログラムオブジェクトを作成してしまうユーティリティ関数を用意しておくのもよいですね。 /** * 頂点シェーダーとフラグメントシェーダーのソースコードから * プログラムオブジェクトを作成します。 * 作成に失敗した場合は null を返します。 * * @param gl WebGL コンテキスト * @param vshaderCode 頂点シェーダーのソースコード * @param fshaderCode フラグメントシェーダーのソースコード */ function createProgramFromCode(gl, vshaderCode, fshaderCode) { const vshader = createShader(gl, gl.VERTEX_SHADER, vshaderCode); if (!vshader) { return null; } const fshader = createShader(gl, gl.FRAGMENT_SHADER, fshaderCode); if (!fshader) { gl.deleteShader(vshader); return null; } return createProgram(gl, vshader, fshader); } これで、下記のようにしてシェーダーのコードから直接プログラムオブジェクトを作成できます。 const program = createProgramFromCode(gl, vshaderCode, fshaderCode); main プログラムの作成 シェーダーオブジェクトやプログラムオブジェクトを作成するユーティリティ関数の作成が終わったので、後はメインプログラムを作成します。 頂点シェーダーとフラグメントシェーダーのソースコードは、下記のように、直接 JavaScript でハードコーディングします。 const VSHADER_CODE = ` void main() { gl_Position = vec4(0.0, 0.0, 0.0, 1.0); // 画面中央 gl_PointSize = 10.0; // 頂点サイズ }`; const FSHADER_CODE = ` void main() { gl_FragColor = vec4(0.0, 1.0, 0.0, 1.0); // RGBA（緑色） }`; ここでは、頂点を 1 つだけ表示するために、座標は画面中央 (0, 0, 0) に決め打ち、色も緑色で決め打ちにしています。 後は、gl.drawArrays 関数を使って、頂点を 1 つ描画する命令を発行すれば WebGL によるレンダリングが行われます。 function render(gl) { gl.clearColor(0, 0, 0.5, 1.0); gl.clear(gl.COLOR_BUFFER_BIT); gl.drawArrays(gl.POINTS, 0, 1); } function main() { const canvas = document.getElementById(\u0026#39;canvas\u0026#39;); const gl = canvas.getContext(\u0026#39;webgl2\u0026#39;); if (!gl) { console.error(\u0026#39;Failed to obtain WebGL 2.0 context\u0026#39;); return; } // プログラムオブジェクトの設定 const program = createProgramFromCode(gl, VSHADER_CODE, FSHADER_CODE); gl.useProgram(program); render(gl); } window.addEventListener(\u0026#39;load\u0026#39;, main); /** * シェーダーコードをコンパイルしてシェーダーオブジェクトを作成します。 * 作成に失敗した場合は null を返します。 * * @param gl GLコンテキスト * @param type 作成するシェーダタイプ (gl.VERTEX_SHADER or gl.FRAGMENT_SHADER) * @param source シェーダーのソースコード */ function createShader(gl, type, source) { const shader = gl.createShader(type); if (shader == null) { console.error('Failed to create a shader'); return null; } gl.shaderSource(shader, source); gl.compileShader(shader); // コンパイルエラーの確認 const compiled = gl.getShaderParameter(shader, gl.COMPILE_STATUS); if (!compiled) { const log = gl.getShaderInfoLog(shader); console.error('Failed to compile shader\\n' + log); gl.deleteShader(shader); return null; } return shader; } /** * シェーダーオブジェクトをリンクしてプログラムオブジェクトを作成します。 * 作成に失敗した場合は null を返します。 * * @param gl WebGL コンテキスト * @param vshader 頂点シェーダーオブジェクト * @param fshader フラグメントシェーダーオブジェクト */ function createProgram(gl, vshader, fshader) { var program = gl.createProgram(); if (!program) { return null; } gl.attachShader(program, vshader); gl.deleteShader(vshader); gl.attachShader(program, fshader); gl.deleteShader(fshader); gl.linkProgram(program); // リンクエラーの確認 var linked = gl.getProgramParameter(program, gl.LINK_STATUS); if (!linked) { var log = gl.getProgramInfoLog(program); console.error('Failed to link a program\\n' + log); gl.deleteProgram(program); return null; } return program; } /** * 頂点シェーダーとフラグメントシェーダーのソースコードから * プログラムオブジェクトを作成します。 * 作成に失敗した場合は null を返します。 * * @param gl WebGL コンテキスト * @param vshaderCode 頂点シェーダーのソースコード * @param fshaderCode フラグメントシェーダーのソースコード */ function createProgramFromCode(gl, vshaderCode, fshaderCode) { const vshader = createShader(gl, gl.VERTEX_SHADER, vshaderCode); if (!vshader) { return null; } const fshader = createShader(gl, gl.FRAGMENT_SHADER, fshaderCode); if (!fshader) { gl.deleteShader(vshader); return null; } return createProgram(gl, vshader, fshader); } const VSHADER_CODE = ` void main() { gl_Position = vec4(0.0, 0.0, 0.0, 1.0); gl_PointSize = 10.0; }`; const FSHADER_CODE = ` void main() { gl_FragColor = vec4(0.0, 1.0, 0.0, 1.0); // RGBA（緑色） }`; function render(gl) { gl.clearColor(0, 0, 0.5, 1.0); gl.clear(gl.COLOR_BUFFER_BIT); gl.drawArrays(gl.POINTS, 0, 1); } function main() { const canvas = document.getElementById('canvas-002'); const gl = canvas.getContext('webgl2'); if (!gl) { console.error('Failed to obtain WebGL 2.0 context'); return; } // プログラムオブジェクトの設定 const program = createProgramFromCode(gl, VSHADER_CODE, FSHADER_CODE); gl.useProgram(program); render(gl); } window.addEventListener('load', main);"
},
{
url: "/p/bqodqji/",
title: "Azure 関連のアイコン集",
date: "2019-03-20T00:00:00Z",
body: "Azure 関連のアイコン集 Azure 関連アイコンのダウンロード Microsoft Azure 関連のアイコンは下記のサイトからダウンロードできるようになっています。 PNG 形式や SVG 形式のファイルが入っているので、Azure 関連の構成図を作成するときに便利です。 Download Microsoft Azure, Cloud and Enterprise Symbol / Icon Set 例えばこーゆーアイコンがたくさん入っています。 アイコン 説明 Azure App Service - Web App Azure Cognitive Services Azure Cognitive Services - LUIS 全アイコンのリスト 上記のパッケージに含まれているアイコンを一覧表示できる HTML ファイルを用意しました。 icons.zip アーカイブを展開して、azure-icons/all_icons.html を開くと、下記のように全アイコンを一覧表示することができます。 ここから PowerPoint などにコピペして使うのも簡単です。"
},
{
url: "/p/neuatgr/",
title: "Unityスクリプト: オブジェクトを拡大縮小する (Transform.localScale)",
date: "2020-02-11T00:00:00Z",
body: "Unityスクリプト: オブジェクトを拡大縮小する (Transform.localScale) ゲームオブジェクトに設定された Transform コンポーネントを操作することで、ゲームオブジェクトを拡大縮小することができます。 Transform コンポーネントのオブジェクトは下記のいずれかの方法で取得できます。 Transform tf = gameObject.GetComponent\u0026lt;Transform\u0026gt;(); Transform tf = gameObject.transform; オブジェクトの拡大率を指定する (Transform.localScale) オブジェクトの拡大縮小の設定は Transform.localScale プロパティで行います。 位置の設定 (position) や 回転角度の設定 (rotation) には、ワールド座標とローカル座標の区別がありますが、拡大縮小には、localScale の一種類しかないのでシンプルです。 次の例では、Cube オブジェクトを X 軸方向に 4 倍、Y 軸方向に 0.5 倍、Z 軸方向に 2 倍に拡大縮小しています。 using UnityEngine; public class Sample : MonoBehaviour { private void Start() { GameObject cube = GameObject.CreatePrimitive(PrimitiveType.Cube); cube.transform.localScale = new Vector3(4, 0.5f, 2); } } 全ての軸に同じ比率だけ拡大縮小したいのであれば、Vector3(1, 1, 1) を示す定数 Vector3.one を使って次のように記述できます。 cube.transform.localScale = Vector3.one * 2; 拡大率は親の拡大率を引き継ぐ オブジェクトが親子関係があるとき、Transform.localScale による拡大率は、必ず親オブジェクトの拡大率を継承します。 次の例では、3 つの Cube オブジェクトに cube1 ← cube2 ← cube3 という親子関係を持たせ、それぞれ X 軸の拡大率を 2 倍に設定しています。 using UnityEngine; public class Sample : MonoBehaviour { private void Start() { GameObject cube1 = GameObject.CreatePrimitive(PrimitiveType.Cube); GameObject cube2 = GameObject.CreatePrimitive(PrimitiveType.Cube); GameObject cube3 = GameObject.CreatePrimitive(PrimitiveType.Cube); cube2.transform.position = new Vector3(0, -1, 0); cube3.transform.position = new Vector3(0, -2, 0); // Set parent-child relations cube2.transform.parent = cube1.transform; cube3.transform.parent = cube2.transform; // Scale objects cube1.transform.localScale = new Vector3(2, 1, 1); cube2.transform.localScale = new Vector3(2, 1, 1); cube3.transform.localScale = new Vector3(2, 1, 1); } } 拡大率が親子で引き継がれるため、cube1、cube2、cube3 の表示上の拡大率は、2倍、4倍、8倍となっていることが分かります。 ☝️ ワンポイント X、Y、Z 軸のいずれかの拡大率を 0 にしてしまうと、オブジェクトの大きさが 0 になって見えなくなってしまうことに注意してください。 ワールド座標におけるグローバルスケールを取得する (lossyScale) 上記の例で、cube1、cube2、cube3 の表示上の拡大率は 2倍、4倍、8倍になっていると説明しました。 このような、ワールド座標におけるグローバルな拡大率は、Transform.lossyScale プロパティ で取得することができます。 この lossyScale プロパティは読み取り専用のため、拡大率の指定はあくまで localScale プロパティの方で行う必要があります。 private void Start() { // ...省略... Debug.Log(\u0026#34;cube1 localScale=\u0026#34; + cube1.transform.localScale); Debug.Log(\u0026#34;cube2 localScale=\u0026#34; + cube2.transform.localScale); Debug.Log(\u0026#34;cube3 localScale=\u0026#34; + cube3.transform.localScale); Debug.Log(\u0026#34;cube1 lossyScale=\u0026#34; + cube1.transform.lossyScale); Debug.Log(\u0026#34;cube2 lossyScale=\u0026#34; + cube2.transform.lossyScale); Debug.Log(\u0026#34;cube3 lossyScale=\u0026#34; + cube3.transform.lossyScale); } 実行結果 cube1 localScale=(2.0, 1.0, 1.0) cube2 localScale=(2.0, 1.0, 1.0) cube3 localScale=(2.0, 1.0, 1.0) cube1 lossyScale=(2.0, 1.0, 1.0) cube2 lossyScale=(4.0, 1.0, 1.0) cube1 lossyScale=(8.0, 1.0, 1.0)"
},
{
url: "/p/ogk9ogw/",
title: "WebGL入門 (3) バッファーオブジェクトで頂点座標をシェーダーへ送る (VBO)",
date: "2019-09-11T00:00:00Z",
body: "WebGL入門 (3) バッファーオブジェクトで頂点座標をシェーダーへ送る (VBO) このブラウザは canvas タグに対応していません。 はじめに WebGL (OpenGL) でアプリケーション側 (CPU) のコードから、シェーダー側 (GPU) へ図形の頂点情報を送るには、バッファーオブジェクト (Buffer Object) の仕組みを使用します。 WebGL 側に確保したバッファーオブジェクトに、頂点座標の配列データをまとめて書き込んでおいて、最後に描画開始要求を送ることで、CPU と GPU 間の通信回数を抑えることができます。 頂点座標を格納するために確保したバッファーオブジェクトのことを、特に VBO (Vertext Buffer Object) と呼んだりします。 WebGL でバッファーオブジェクトを使って図形を描画するまでの流れは以下のようになります。 WebGL 側にバッファーオブジェクトを作成する gl.createBuffer() バッファーオブジェクトをターゲットとバインドする gl.bindBuffer() バッファーオブジェクトに頂点情報を転送する gl.bufferData() 頂点シェーダーの attribute 変数でそのデータを1つずつ取り出せるようにする gl.getAttribLocation() gl.vertexAttribPointer() gl.enableVertexAttribArray() 描画要求を送る gl.drawArrays() 以下、単純な三角形を描画するまでの手順を示します。 バッファーオブジェクトを作成する まず、WebGL 側に頂点情報を格納するためのバッファーオブジェクトを生成します。 これは、gl.createBuffer() をパラメータなしで呼ぶだけなので簡単です。 const vertexBuffer = gl.createBuffer(); if (!vertexBuffer) { throw Error(\u0026#39;Failed to create the buffer object.\u0026#39;); } バッファーオブジェクトをターゲットにバインドする バッファーオブジェクトを作成したら、gl.bindBuffer() を使って、そのバッファーオブジェクトをターゲットとバインドします。 ターゲットというのは、そのバッファーオブジェクトをどのような用途で使用するかを示すためのもので、頂点属性のために確保したのであれば、gl.ARRAY_BUFFER というターゲットとバインドします。 頂点属性というのは、「頂点座標」、「頂点カラー」、「テクスチャ座標」などのことで、ここでは頂点座標だけを扱います。 gl.bindBuffer(gl.ARRAY_BUFFER, vertexBuffer); ☝️ ワンポイント バインドのイメージとしては、gl.ARRAY_BUFFER というターゲットを、vertexBuffer が示すバッファーオブジェクトを指すように設定すると考えるのがよいです。 というのも、この次に実行する gl.bufferData() は、gl.ARRAY_BUFFER をパラメータに指定することで、バッファーオブジェクトを操作することになるからです。 ターゲットには他にも gl.ELEMENT_ARRAY_BUFFER などがあり、これは、頂点配列の中のどのインデックスのデータを使うかを示すインデックス配列です。 何らかのオブジェクトを描画する場合、通常は、1 つの頂点が複数の面を構成するために繰り返し使用されます。 そのような場合に、頂点データを使いまわすことでメモリ効率を上げることができます。 gl.ELEMENT_ARRAY_BUFFER を使った描画に関しては、別の記事で説明します。 バッファーオブジェクトに頂点情報を転送する 次に、アプリケーション側 (CPU側）で用意した座標の配列を、gl.bufferData() で GPU 側のバッファーオブジェクトに転送します。 座標配列は、JavaScript の配列として用意するのですが、汎用の Array 型ではなく Typed Array のひとつである Float32Array を使用します。 頂点データ（座標や色）などの配列を扱う場合、すべての要素が同一の型であることを前提にして作成された Typed Array を使用した方が効率がよいからです。 WebGL で使う Typed Array const vertices = new Float32Array([ 0.0, 0.5, // 1つ目の頂点座標 -0.5, -0.5, // 2つ目の頂点座標 0.5, -0.5 // 3つ目の頂点座標 ]); gl.bufferData(gl.ARRAY_BUFFER, vertices, gl.STATIC_DRAW); 第1引数には、バッファーオブジェクトではなく、ターゲット名（ここでは gl.ARRAY_BUFFER）を指定するところがちょっとわかりにくいところですね。 第2引数には転送する頂点データを格納した Typed Array オブジェクトを指定します。 第3引数は、この頂点データをどのように使用するかのパラメータで、WebGL が効率的に描画を行うためのヒント情報として使用されます（実際にどう活用されるかは WebGL の実装によります）。 ヒント情報としては下記のような値を指定できます（WebGL2 ではさらに増えています）。 gl.STATIC_DRAW: バッファーの内容はアプリから一度だけ設定され、描画するためにたくさん参照されます。 gl.STREAM_DRAW: バッファーの内容はアプリから一度だけ設定され、描画するためにいくらか参照されます。 gl.DYNAMIC_DRAW: バッファーの内容はアプリから何度も設定され、描画するためにたくさん参照されます。 頂点シェーダーの attribute 変数でデータを1つずつ取り出せるようにする バッファーオブジェクトに頂点座標の配列をセットしたら、頂点シェーダーからその座標値を1つずつ取り出せるようにする必要があります。 頂点シェーダーは、バッファーオブジェクトに設定した頂点 1 つごとに 1 回呼び出されることになります。 ここでは、頂点シェーダーを下記のように実装し、a_Position という名前の attribute 変数経由で座標値を 1 つずつ取り出すように実装します（a_ プレフィックスは attribute を表します）。 gl_Position に代入した値が、その頂点の最終的な座標になります。 Vertex shader attribute vec4 a_Position; void main() { gl_Position = a_Position; } ピクセル毎に呼び出されるフラグメントシェーダーは、下記のように単色（ここでは緑）で描画するようにしておきます。 Fragment shader void main() { gl_FragColor = vec4(0.0, 1.0, 0.0, 1.0); // RGBA } アプリ側のコードでは、頂点シェーダーが attribute 変数経由でバッファーオブジェクト内の頂点データを取り出せるように設定します。 まず、gl.getAttribLocation() で、attribute 変数にアクセスするためのハンドルを取得します。 const a_Position = gl.getAttribLocation(gl.program, \u0026#39;a_Position\u0026#39;); ここで、第1引数にプログラムオブジェクトが必要になりますが、ここでは、gl.program というプロパティにあらかじめ格納されているとします。 次に、gl.vertexAttribPointer() を使い、現在 gl.ARRAY_BUFFER にバインドされているバッファーオブジェクトに、頂点情報がどのようなレイアウトで格納されているかを設定します。つまり、シェーダー側に、attribute 変数経由でどのような単位でデータを取り出していけばよいかを知らせます。バッファーオブジェクトに設定した頂点情報は、構造化されていない一次元の配列（バイナリ）なので、このような情報が必要になります。 gl.vertexAttribPointer(a_Position, 2, gl.FLOAT, false, 0, 0); 第2引数 (size) では、頂点あたりの次元数（頂点毎に消費する配列要素数）を指定します。 ここでは、X座標とY座標のペアを格納しているので、2 と指定します。 有効な値は 1～4 です。 第3引数 (type) では、各要素の型を指定します。 ここでは、Float32Array で頂点座標をセットしているので、対応する WebGL の型として gl.FLOAT を指定しています。 第4引数 (normalized) では、整数データを浮動小数点数に型変換するときに値の範囲を -1.0～1.0 に正規化するかを指定します。ただし、セットするデータがもともと浮動小数点数の場合は正規化は行われないので、ここは false にしておけば OK です。 第5引数 (stride) は、配列データ内に頂点座標、テクスチャ座標、頂点カラーといった複数種の属性を交互に詰めている（インターリーブされている）場合の、1 頂点あたりの使用バイト数を指定します。 最後の第6引数 (offset) は、最初の要素が、バッファー内のどこから始まるかを示すバイトオフセット値です。 ここでは、頂点座標だけを格納しているので、第5引数と第6引数は両方とも 0 を指定しておけば OK です。 インターリーブされたデータを扱う方法は下記の記事を参考にしてください。 参考: 頂点属性をインターリーブしてバッファオブジェクトに格納する 最後に、gl.enableVertexAttribArray() を呼び出して、attribute 変数に割り当てたバッファーオブジェクトを有効にします。 gl.enableVertexAttribArray(a_Position); ここまで設定が終わると、頂点シェーダーの attribute 変数経由で、バッファオブジェクト内の頂点データを 1 つずつ取り出せるようになります。 ☝️ ワンポイント gl.enableVertexAttribArray() を実行した時点で、その attribute 変数はバッファオブジェクトからの入力専用になるため、gl.vertexAttrib[1234]f() などの関数で個々の頂点データを attribute 変数に直接渡すことはできなくなります。 gl.disableVertexAttribArray() すれば再び渡せるようになります。 描画要求を送る バッファーオブジェクトへの頂点データの格納と、attribute 変数の設定を完了したら、あとは gl.drawArrays() を呼び出すことで、実際に頂点データを使った描画が行われます。 gl.drawArrays(gl.TRIANGLE_STRIP, 0, 3); 第1引数 (mode) では描画するプリミティブのタイプ（ここでは一つの三角形なので、gl.TRIANGLE でも gl.TRIANGLE_STRIP でも OK）を指定します。 第2引数 (first) では、頂点配列の開始インデックスを指定します。 第3引数 (count) では、使用する頂点の数を指定します。 ここでは、3 つの頂点を使うので、3 を指定しています。 頂点シェーダーは、3 回実行されることになります。 全体のソースコード \u0026lt;script id=\u0026#34;vs\u0026#34; type=\u0026#34;x-shader/x-vertex\u0026#34;\u0026gt; attribute vec4 a_Position; void main() { gl_Position = a_Position; } \u0026lt;/script\u0026gt; \u0026lt;script id=\u0026#34;fs\u0026#34; type=\u0026#34;x-shader/x-fragment\u0026#34;\u0026gt; void main() { gl_FragColor = vec4(0.0, 1.0, 0.0, 1.0); // RGBA } \u0026lt;/script\u0026gt; \u0026lt;script type=\u0026#34;module\u0026#34;\u0026gt; import { initGL } from \u0026#39;/assets/js/webgl_util.js\u0026#39;; window.addEventListener(\u0026#39;load\u0026#39;, function () { const gl = initGL(\u0026#39;canvas\u0026#39;, \u0026#39;vs\u0026#39;, \u0026#39;fs\u0026#39;); const vertices = new Float32Array([ 0.0, 0.5, // 1つ目の頂点座標 -0.5, -0.5, // 2つ目の頂点座標 0.5, -0.5 // 3つ目の頂点座標 ]); const vertexBuffer = gl.createBuffer(); if (!vertexBuffer) { throw Error(\u0026#39;Failed to create the buffer object.\u0026#39;); } gl.bindBuffer(gl.ARRAY_BUFFER, vertexBuffer); gl.bufferData(gl.ARRAY_BUFFER, vertices, gl.STATIC_DRAW); const a_Position = gl.getAttribLocation(gl.program, \u0026#39;a_Position\u0026#39;); gl.vertexAttribPointer(a_Position, 2, gl.FLOAT, false, 0, 0); gl.enableVertexAttribArray(a_Position); gl.clearColor(0, 0, 0.5, 1.0); gl.clear(gl.COLOR_BUFFER_BIT); gl.drawArrays(gl.TRIANGLE_STRIP, 0, 3); }); \u0026lt;/script\u0026gt; 上記でインポートしている webgl_util.js は、プログラムオブジェクトを作成するユーティリティ関数 initGL() を定義しています。 プログラムオブジェクトの作成に関しては、こちらを参照してください。 attribute vec4 a_Position; void main() { gl_Position = a_Position; } void main() { gl_FragColor = vec4(0.0, 1.0, 0.0, 1.0); // RGBA } import { initGL } from '/assets/js/webgl_util.js'; window.addEventListener('load', function () { const gl = initGL('canvas-003', 'vs-003', 'fs-003'); const vertices = new Float32Array([ 0.0, 0.5, // 1つ目の頂点座標 -0.5, -0.5, // 2つ目の頂点座標 0.5, -0.5 // 3つ目の頂点座標 ]); const vertexBuffer = gl.createBuffer(); if (!vertexBuffer) { throw Error('Failed to create the buffer object.'); } gl.bindBuffer(gl.ARRAY_BUFFER, vertexBuffer); gl.bufferData(gl.ARRAY_BUFFER, vertices, gl.STATIC_DRAW); const a_Position = gl.getAttribLocation(gl.program, 'a_Position'); gl.vertexAttribPointer(a_Position, 2, gl.FLOAT, false, 0, 0); gl.enableVertexAttribArray(a_Position); gl.clearColor(0, 0, 0.5, 1.0); gl.clear(gl.COLOR_BUFFER_BIT); gl.drawArrays(gl.TRIANGLE_STRIP, 0, 3); });"
},
{
url: "/p/wqjqbpi/",
title: "WebGL入門 (4) 頂点属性をインターリーブしてバッファオブジェクトに格納する",
date: "2019-09-13T00:00:00Z",
body: "WebGL入門 (4) 頂点属性をインターリーブしてバッファオブジェクトに格納する このブラウザは canvas タグに対応していません。 インターリーブとは インターリーブ (interleave) とは、一般的なコンピュータ用語で、データを交互に配置していくことを示します。 例えば、3D モデルの各頂点の「XY座標」「RGBカラー」をインターリーブして配列に詰めると、3 つの頂点の情報は、 X Y R G B X Y Z G B X Y R G B ... のようにレイアウトされることになります。 WebGL (OpenGL) では、このようにインターリーブされた頂点属性データを扱えるようになっています。 インターリーブする主な頂点属性は、頂点座標 (XYZ)、テクスチャ座標 (UV)、頂点カラー (RGBA) などです。 ここでは、頂点座標 (XY) と頂点カラー (RGB) をインターリーブした配列を JavaScript 側の Float32Array として作成し、それを WebGL 側のバッファオブジェクトに詰める方法を示します。 シェーダー側の実装 まずは、頂点シェーダーとフラグメントシェーダーを用意します。 頂点シェーダー attribute vec4 a_Position; // 入力（XY座標） attribute vec4 a_Color; // 入力（RGAカラー） varying vec4 v_Color; // 出力（RGAカラー） void main() { gl_Position = a_Position; v_Color = a_Color; } 頂点シェーダーでは、バッファオブジェクトから XY 座標を取り出すための attribute 変数 a_Position と、RGB カラーを取り出すための a_Color を定義します。 カラー値は最終的にはフラグメントシェーダー側で必要になるので、varying 変数の v_Color を介して値をフラグメントシェーダーへ渡します。 フラグメントシェーダー precision mediump float; // float のデフォルト精度（中） varying vec4 v_Color; // 頂点シェーダーからの入力 void main() { gl_FragColor = v_Color; } フラグメントシェーダー側では、まず float の精度を設定しておかなければならないので、ここでは中精度 (mediump) に設定しています。 実際に使用している変数の型は vec4 ですが、これは float を 4 つセットにしたものなので、float の精度だけ設定しておけば OK です。 頂点シェーダー側と同じ名前で定義した varying 変数 v_Color からは、頂点シェーダー側で代入されたカラー値を受け取ることができます。 実際には、各頂点の中間に位置するフラグメントでは、補間されたカラー値が取り出されます（なのでこのサンプルではグラデーションになって見えます）。 あとは、この値を gl_FragColor に代入すれば、それぞれのフラグメントに異なる色の付いた図形が描画されます。 ☝️ ワンポイント varying 変数は、頂点シェーダーで設定した値と、フラグメントシェーダー側で取り出される値が変わってくるので varying「変わる」という名前が付けられたそうですが、新しいシェーダー言語仕様では in/out に名前が変わっています。確かに最初に varying というキーワードを見た人にはほとんど意味が伝わらないと思いますので、不評だったんでしょうね。 アプリ側の実装 アプリ (CPU) 側では、まず、インターリーブされた配列データを用意します（ここではハードコーディングしていますが、複雑なモデルの場合は glTF 形式などの外部ファイルを使用します）。 const vertices = new Float32Array([ 0.0, 0.5, 1.0, 0.0, 0.0, // 1つ目の頂点座標 + RGB -0.5, -0.5, 0.0, 1.0, 0.0, // 2つ目の頂点座標 + RGB 0.5, -0.5, 0.0, 0.0, 1.0 // 3つ目の頂点座標 + RGB ]); const ELEM_BYTES = vertices.BYTES_PER_ELEMENT; // 4 ELEM_BYTES は、配列の 1 要素当たりのバイト数で、ここでは float 型の値なので 4 になります。 この値は後ほど、WebGL の API を呼び出すときに使います。 次に、頂点情報を格納するためのバッファオブジェクトを WebGL 側に生成し、上記の配列データを転送します。 座標値とカラー値をインターリーブしているので、バッファオブジェクトは 1 つだけで済みます。 const vertexBuffer = gl.createBuffer(); gl.bindBuffer(gl.ARRAY_BUFFER, vertexBuffer); gl.bufferData(gl.ARRAY_BUFFER, vertices, gl.STATIC_DRAW); 次の処理が重要で、インターリーブされた座標値とカラー値を、異なる attribute 変数（a_Position と a_Color）で取り出せるように設定します。 // 座標値 (XY) を取り出すための attribute 変数を設定 const a_Position = gl.getAttribLocation(gl.program, \u0026#39;a_Position\u0026#39;); gl.vertexAttribPointer(a_Position, 2, gl.FLOAT, false, ELEM_BYTES * 5, 0); gl.enableVertexAttribArray(a_Position); // カラー値 (RGB) を取り出すための attribute 変数を設定 const a_Color = gl.getAttribLocation(gl.program, \u0026#39;a_Color\u0026#39;); gl.vertexAttribPointer(a_Color, 3, gl.FLOAT, false, ELEM_BYTES * 5, ELEM_BYTES * 2); gl.enableVertexAttribArray(a_Color); インターリーブされた情報を扱うには、gl.vertexAttributePointer() の第5引数 (stride) と第6引数 (offset) をうまく設定する必要があります。 第5引数 (stride) では、1 頂点あたりの使用バイト数を指定します。 ここでは、1 頂点につき 5 要素 (X,Y,R,G,B) があり、それぞれ float の 4 バイト (= ELEM_BYTES) を使用するので、20 (ELEM_BYTES * 5) を指定しています。 配列の要素数 (5) ではなく、バイト数で指定しないといけないことに注意してください。 最後の第6引数 (offset) は、取り出すべき最初の要素が、バッファー内のどこから始まるかを示すバイトオフセット値です。 座標値の場合は先頭から始まっているので 0 を指定し、カラー値の場合は、その前に配置された 2 つの座標値分だけオフセットして取り出したいので、ELEM_BYTES * 2 を指定しています。 ここで指定されたオフセット位置から、stride パラメータのバイト数ずつずらしながら情報が取り出されていくことになります。 ☝️ ワンポイント 座標値は 2 要素 (XY)、カラー値は 3 要素 (RGB) で格納しているのに、シェーダー側では共に vec4 型で取り出していることに気が付いたかもしれません。 4 要素に満たないデータを vec4 で取り出そうとすると、3 要素目に 0.0、4 要素目に 1.0 というデフォルト値が格納されます。 このデフォルト値は、vec4 変数を座標値として扱う場合も、RGBA 値として扱う場合も都合がよい値になっています。 最後に、gl.drawArrays() で描画命令を WebGL に送ってやれば、バッファーオブジェクトに渡した頂点情報を元に描画が行われます。 gl.clearColor(0, 0, 0.5, 1.0); gl.clear(gl.COLOR_BUFFER_BIT); gl.drawArrays(gl.TRIANGLE_STRIP, 0, 3); attribute vec4 a_Position; // 入力（XY座標） attribute vec4 a_Color; // 入力（RGAカラー） varying vec4 v_Color; // 出力（RGAカラー） void main() { gl_Position = a_Position; v_Color = a_Color; } precision mediump float; varying vec4 v_Color; void main() { gl_FragColor = v_Color; } import { initGL } from '/assets/js/webgl_util.js'; window.addEventListener('load', function() { const gl = initGL('canvas-004', 'vs-004', 'fs-004'); const vertices = new Float32Array([ 0.0, 0.5, 1.0, 0.0, 0.0, // 1つ目の頂点座標 + RGB -0.5, -0.5, 0.0, 1.0, 0.0, // 2つ目の頂点座標 + RGB 0.5, -0.5, 0.0, 0.0, 1.0 // 3つ目の頂点座標 + RGB ]); const ELEM_BYTES = vertices.BYTES_PER_ELEMENT; // = 4 const vertexBuffer = gl.createBuffer(); if (!vertexBuffer) { throw Error('Failed to create the buffer object.'); } gl.bindBuffer(gl.ARRAY_BUFFER, vertexBuffer); gl.bufferData(gl.ARRAY_BUFFER, vertices, gl.STATIC_DRAW); // 頂点座標の attribute 変数を設定 const a_Position = gl.getAttribLocation(gl.program, 'a_Position'); gl.vertexAttribPointer(a_Position, 2, gl.FLOAT, false, ELEM_BYTES * 5, 0); gl.enableVertexAttribArray(a_Position); // 頂点カラーの attribute 変数を設定 const a_Color = gl.getAttribLocation(gl.program, 'a_Color'); gl.vertexAttribPointer(a_Color, 3, gl.FLOAT, false, ELEM_BYTES * 5, ELEM_BYTES * 2); gl.enableVertexAttribArray(a_Color); gl.clearColor(0, 0, 0.5, 1.0); gl.clear(gl.COLOR_BUFFER_BIT); gl.drawArrays(gl.TRIANGLE_STRIP, 0, 3); });"
},
{
url: "/p/9sxkmma/",
title: "WebGL入門 (5) 三角形の 3 つの描画モード",
date: "2019-09-13T00:00:00Z",
body: "WebGL入門 (5) 三角形の 3 つの描画モード gl.drawArrays() や gl.drawElements で図形を描画するとき、第1引数で頂点をどのように使用するかの描画モードを指定します。 OpenGL ES では、四角形を描画することはできないので、面を表現するときには、三角形の組み合わせで描画することになります。 三角形の描画モードには、下記の 3 種類があります。 gl.TRIANGLE - 各三角形は頂点を共有しない gl.TRIANGLE_STRIP - ジグザグに頂点が配置されていると想定 gl.TRIANGLE_FAN - 扇形に頂点が配置されていると想定 gl.TRIANGLE は、隣接する面の描画においても、独立した頂点データが必要です。 よって、基本的には gl.TRIANGLE_STRIP か gl.TRIANGLE_FAN を使うのがよいのですが、多くの環境では gl.TRIANGLE_STRIP の描画効率がよいようです。 下記は、gl.drawArrays() に gl.TRIANGLE_STRIP を指定して 4 つの三角形を描画した例です。 このブラウザは canvas タグに対応していません。 コードでは、下記のように頂点座標と頂点カラーを定義しています。 const vertices = new Float32Array([ -1.0, 0.5, 1.0, 0.0, 0.0, // v0 (XYRGB) 赤 -0.6, -0.5, 0.0, 1.0, 0.0, // v1 (XYRGB) 緑 0.2, 0.5, 0.0, 0.0, 1.0, // v2 (XYRGB) 青 0.2, -0.5, 1.0, 0.0, 0.0, // v3 (XYRGB) 赤 0.6, 0.5, 0.0, 1.0, 0.0, // v4 (XYRGB) 緑 1.0, -0.5, 0.0, 0.0, 1.0 // v5 (XYRGB) 青 ]); // ... gl.drawArrays(gl.TRIANGLE_STRIP, 0, 6); // 頂点を 6 つ使用する attribute vec4 a_Position; // 入力（XY座標） attribute vec4 a_Color; // 入力（RGAカラー） varying vec4 v_Color; // 出力（RGAカラー） void main() { gl_Position = a_Position; v_Color = a_Color; } precision mediump float; varying vec4 v_Color; void main() { gl_FragColor = v_Color; } import { initGL } from '/assets/js/webgl_util.js'; window.addEventListener('load', function() { const gl = initGL('canvas-005', 'vs-005', 'fs-005'); const vertices = new Float32Array([ -1.0, 0.5, 1.0, 0.0, 0.0, // v0 (XYRGB) 赤 -0.6, -0.5, 0.0, 1.0, 0.0, // v1 (XYRGB) 緑 0.2, 0.5, 0.0, 0.0, 1.0, // v2 (XYRGB) 青 0.2, -0.5, 1.0, 0.0, 0.0, // v3 (XYRGB) 赤 0.6, 0.5, 0.0, 1.0, 0.0, // v4 (XYRGB) 緑 1.0, -0.5, 0.0, 0.0, 1.0 // v5 (XYRGB) 青 ]); const ELEM_BYTES = vertices.BYTES_PER_ELEMENT; // = 4 const vertexBuffer = gl.createBuffer(); if (!vertexBuffer) { throw Error('Failed to create the buffer object.'); } gl.bindBuffer(gl.ARRAY_BUFFER, vertexBuffer); gl.bufferData(gl.ARRAY_BUFFER, vertices, gl.STATIC_DRAW); // 頂点座標の attribute 変数を設定 const a_Position = gl.getAttribLocation(gl.program, 'a_Position'); gl.vertexAttribPointer(a_Position, 2, gl.FLOAT, false, ELEM_BYTES * 5, 0); gl.enableVertexAttribArray(a_Position); // 頂点カラーの attribute 変数を設定 const a_Color = gl.getAttribLocation(gl.program, 'a_Color'); gl.vertexAttribPointer(a_Color, 3, gl.FLOAT, false, ELEM_BYTES * 5, ELEM_BYTES * 2); gl.enableVertexAttribArray(a_Color); gl.clearColor(0, 0, 0.5, 1.0); gl.clear(gl.COLOR_BUFFER_BIT); gl.drawArrays(gl.TRIANGLE_STRIP, 0, 6); });"
},
{
url: "/p/wbvv3ha/",
title: "WebGL入門 (6) インデックスバッファを使って頂点を使い回す (drawElements)",
date: "2019-09-19T00:00:00Z",
body: "WebGL入門 (6) インデックスバッファを使って頂点を使い回す (drawElements) インデックスバッファを用いた描画の概要 gl.drawArrays() による描画には、3 つの三角形の描画モードがあり、連なった三角形を描画するときには、gl.TRIANGLE_STRIP あるいは gl.TRIANGLE_FAN の描画モードを使用すると、頂点情報を使い回しながら効率的に描画することができます。 ただし、図形が少し複雑になってくると、一度の gl.drawArrays() 呼び出しではうまく描画できなくなってきます。 例えば次のような 3 つの三角形（トライフォース）を描画することを考えてみます。 面 A、B、C は独立した三角形に見えるので、それぞれに 3 つの頂点（合計 9 頂点）を用意して gl.drawArrays() の gl.TRIANGLES モードでレンダリングすればよさそうですが、頂点 1、2、4 に関しては座標が同じなので、本来であれば上記のように 6 つの頂点情報を用意するだけで足りそうです。 このような場合は、インデックスバッファと gl.drawElements() を使用すると、効率的な描画を行えます。 頂点バッファオブジェクト (VBO) に座標情報を入れておくのは gl.drawArrays() を使った場合と同様ですが、もう一つ別のバッファオブジェクトとして、インデックスバッファオブジェクト (IBO: Index Buffer Object) を作成します。 IBO には、VBO 内のどの頂点情報を使って図形描画を行うかを示す、頂点インデックスの情報を格納します。 頂点バッファオブジェクト (VBO) 頂点情報（座標、色など）を重複しないように格納する。 上記の例では、頂点 0～5 の 6 つの頂点情報を格納する。 インデックスバッファオブジェクト (IBO) 図形描画に VBO 内のどの頂点情報を使うかを示すインデックス配列。 上記の例では、面Aは 0,1,2、面Bは 1,3,4、面Cは 2,4,5 の頂点を使用するという情報。一次元で、0,1,2,1,3,4,2,4,5 と格納すればよい。 実装 このブラウザは canvas タグに対応していません。 ここでは、各頂点に異なる色をつけたトライフォースを描画してみます。 頂点バッファオブジェクト (VBO) を作成する const vertices = new Float32Array([ 0.0 , 0.5, 1.0, 1.0, 0.0, // v0 (XYRGB) 黄 -0.25, 0.0, 0.0, 1.0, 0.0, // v1 (XYRGB) 緑 0.25, 0.0, 1.0, 0.0, 0.0, // v2 (XYRGB) 赤 -0.5, -0.5, 1.0, 0.0, 1.0, // v3 (XYRGB) 紫 0.0, -0.5, 0.0, 1.0, 1.0, // v4 (XYRGB) シアン 0.5, -0.5, 1.0, 1.0, 1.0 // v5 (XYRGB) 白 ]); const ELEM_BYTES = vertices.BYTES_PER_ELEMENT; // = 4 // 頂点バッファオブジェクト (VBO) の作成 const vertexBuffer = gl.createBuffer(); gl.bindBuffer(gl.ARRAY_BUFFER, vertexBuffer); gl.bufferData(gl.ARRAY_BUFFER, vertices, gl.STATIC_DRAW); // 頂点座標の attribute 変数を設定 const a_Position = gl.getAttribLocation(gl.program, \u0026#39;a_Position\u0026#39;); gl.vertexAttribPointer(a_Position, 2, gl.FLOAT, false, ELEM_BYTES * 5, 0); gl.enableVertexAttribArray(a_Position); // 頂点カラーの attribute 変数を設定 const a_Color = gl.getAttribLocation(gl.program, \u0026#39;a_Color\u0026#39;); gl.vertexAttribPointer(a_Color, 3, gl.FLOAT, false, ELEM_BYTES * 5, ELEM_BYTES * 2); gl.enableVertexAttribArray(a_Color); 頂点バッファオブジェクトの作成方法は、gl.drawArrays() で描画する場合と同様です。 ここでは、ひとつのバッファオブジェクト内にインターリーブする形で頂点座標と頂点カラーを格納し、それぞれ a_Position、a_Color という attribute 変数で 1 つずつ取り出せるように設定しています。 インデックスバッファオブジェクト (IBO) を作成する const indices = new Uint8Array([ 0, 1, 2, // 面 A を構成する頂点のインデックス 1, 3, 4, // 面 B を構成する頂点のインデックス 2, 4, 5 // 面 C を構成する頂点のインデックス ]); // インデックスバッファオブジェクト (IBO) の作成 const indexBuffer = gl.createBuffer(); gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, indexBuffer); gl.bufferData(gl.ELEMENT_ARRAY_BUFFER, indices, gl.STATIC_DRAW); インデックス情報を格納するためのバッファオブジェクトも、VBO と同様に gl.createBuffer() で作成します。 ただし、gl.bindBuffer() と gl.bufferData() のターゲットには gl.ELEMENT_ARRAY_BUFFER を指定します（gl.ARRAY_BUFFER ではない）。 OpenGL ES の仕様では、インデックスバッファの各要素は、gl.UNSIGNED_BYTE 型、あるいは gl.UNSIGNED_SHORT 型の値でなければいけないため、JavaScript 側の頂点インデックス配列も Uint8Array 型（gl.UNSIGNED_BYTE に対応）で作成しています。 gl.drawElements() で描画する // キャンバスのクリア gl.clearColor(0, 0, 0.5, 1.0); gl.clear(gl.COLOR_BUFFER_BIT); // インデックスバッファオブジェクト (IBO) のインデックスに従って描画 gl.drawElements(gl.TRIANGLES, indices.length, gl.UNSIGNED_BYTE, 0); VBO と IBO の作成が終わったら、後は gl.drawElements を使って描画を行います。 それぞれの面（三角形）には独立した頂点インデックスが 3 つずつ与えられているため、第１引数 (mode) の描画モードとしては gl.TRIANGLES を指定すれば OK です。 第2引数 (count) には頂点インデックスの数（IBO の要素数）、第3引数 (type) には頂点インデックスの型（ここでは gl.UNSIGNED_BYTE）、第4引数 (offset) には使用するデータのバイトオフセット（IBO の先頭から参照するなら 0 でよい）を指定します。 全体のコード \u0026lt;script id=\u0026#34;vs-006\u0026#34; type=\u0026#34;x-shader/x-vertex\u0026#34;\u0026gt; attribute vec4 a_Position; // 入力（XY座標） attribute vec4 a_Color; // 入力（RGBAカラー） varying vec4 v_Color; // 出力（RGBAカラー） void main() { gl_Position = a_Position; v_Color = a_Color; } \u0026lt;/script\u0026gt; \u0026lt;script id=\u0026#34;fs-006\u0026#34; type=\u0026#34;x-shader/x-fragment\u0026#34;\u0026gt; precision mediump float; varying vec4 v_Color; void main() { gl_FragColor = v_Color; } \u0026lt;/script\u0026gt; \u0026lt;script type=\u0026#34;module\u0026#34;\u0026gt; import { initGL } from \u0026#39;/assets/js/webgl_util.js\u0026#39;; window.addEventListener(\u0026#39;load\u0026#39;, function() { const gl = initGL(\u0026#39;canvas-006\u0026#39;, \u0026#39;vs-006\u0026#39;, \u0026#39;fs-006\u0026#39;); const vertices = new Float32Array([ 0.0 , 0.5, 1.0, 1.0, 0.0, // v0 (XYRGB) 黄 -0.25, 0.0, 0.0, 1.0, 0.0, // v1 (XYRGB) 緑 0.25, 0.0, 1.0, 0.0, 0.0, // v2 (XYRGB) 赤 -0.5, -0.5, 1.0, 0.0, 1.0, // v3 (XYRGB) 紫 0.0, -0.5, 0.0, 1.0, 1.0, // v4 (XYRGB) シアン 0.5, -0.5, 1.0, 1.0, 1.0 // v5 (XYRGB) 白 ]); const ELEM_BYTES = vertices.BYTES_PER_ELEMENT; // = 4 const indices = new Uint8Array([ 0, 1, 2, // 面 A を構成する頂点のインデックス 1, 3, 4, // 面 B を構成する頂点のインデックス 2, 4, 5 // 面 C を構成する頂点のインデックス ]); // 頂点バッファオブジェクト (VBO) の作成 const vertexBuffer = gl.createBuffer(); gl.bindBuffer(gl.ARRAY_BUFFER, vertexBuffer); gl.bufferData(gl.ARRAY_BUFFER, vertices, gl.STATIC_DRAW); // 頂点座標の attribute 変数を設定 const a_Position = gl.getAttribLocation(gl.program, \u0026#39;a_Position\u0026#39;); gl.vertexAttribPointer(a_Position, 2, gl.FLOAT, false, ELEM_BYTES * 5, 0); gl.enableVertexAttribArray(a_Position); // 頂点カラーの attribute 変数を設定 const a_Color = gl.getAttribLocation(gl.program, \u0026#39;a_Color\u0026#39;); gl.vertexAttribPointer(a_Color, 3, gl.FLOAT, false, ELEM_BYTES * 5, ELEM_BYTES * 2); gl.enableVertexAttribArray(a_Color); // インデックスバッファオブジェクト (IBO) の作成 const indexBuffer = gl.createBuffer(); gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, indexBuffer); gl.bufferData(gl.ELEMENT_ARRAY_BUFFER, indices, gl.STATIC_DRAW); // キャンバスのクリア gl.clearColor(0, 0, 0.5, 1.0); gl.clear(gl.COLOR_BUFFER_BIT); // インデックスバッファオブジェクト (IBO) のインデックスに従って描画 gl.drawElements(gl.TRIANGLES, indices.length, gl.UNSIGNED_BYTE, 0); }); \u0026lt;/script\u0026gt; attribute vec4 a_Position; // 入力（XY座標） attribute vec4 a_Color; // 入力（RGAカラー） varying vec4 v_Color; // 出力（RGAカラー） void main() { gl_Position = a_Position; v_Color = a_Color; } precision mediump float; varying vec4 v_Color; void main() { gl_FragColor = v_Color; } import { initGL } from '/assets/js/webgl_util.js'; window.addEventListener('load', function() { const gl = initGL('canvas-006', 'vs-006', 'fs-006'); const vertices = new Float32Array([ 0.0 , 0.5, 1.0, 1.0, 0.0, // v0 (XYRGB) 黄 -0.25, 0.0, 0.0, 1.0, 0.0, // v1 (XYRGB) 緑 0.25, 0.0, 1.0, 0.0, 0.0, // v2 (XYRGB) 赤 -0.5, -0.5, 1.0, 0.0, 1.0, // v3 (XYRGB) 紫 0.0, -0.5, 0.0, 1.0, 1.0, // v4 (XYRGB) シアン 0.5, -0.5, 1.0, 1.0, 1.0 // v5 (XYRGB) 白 ]); const ELEM_BYTES = vertices.BYTES_PER_ELEMENT; // = 4 const indices = new Uint8Array([ 0, 1, 2, // 面 A を構成する頂点のインデックス 1, 3, 4, // 面 B を構成する頂点のインデックス 2, 4, 5 // 面 C を構成する頂点のインデックス ]); // 頂点バッファオブジェクト (VBO) の作成 const vertexBuffer = gl.createBuffer(); gl.bindBuffer(gl.ARRAY_BUFFER, vertexBuffer); gl.bufferData(gl.ARRAY_BUFFER, vertices, gl.STATIC_DRAW); // 頂点座標の attribute 変数を設定 const a_Position = gl.getAttribLocation(gl.program, 'a_Position'); gl.vertexAttribPointer(a_Position, 2, gl.FLOAT, false, ELEM_BYTES * 5, 0); gl.enableVertexAttribArray(a_Position); // 頂点カラーの attribute 変数を設定 const a_Color = gl.getAttribLocation(gl.program, 'a_Color'); gl.vertexAttribPointer(a_Color, 3, gl.FLOAT, false, ELEM_BYTES * 5, ELEM_BYTES * 2); gl.enableVertexAttribArray(a_Color); // インデックスバッファオブジェクト (IBO) の作成 const indexBuffer = gl.createBuffer(); gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, indexBuffer); gl.bufferData(gl.ELEMENT_ARRAY_BUFFER, indices, gl.STATIC_DRAW); // キャンバスのクリア gl.clearColor(0, 0, 0.5, 1.0); gl.clear(gl.COLOR_BUFFER_BIT); // インデックスバッファオブジェクト (IBO) のインデックスに従って描画 gl.drawElements(gl.TRIANGLES, indices.length, gl.UNSIGNED_BYTE, 0); });"
},
{
url: "/p/q7q8p6m/",
title: "AWS CDK メモ: ブートストラップ処理を実行する (cdk bootstrap)",
date: "2022-04-17T00:00:00Z",
body: "AWS CDK メモ: ブートストラップ処理を実行する (cdk bootstrap) CloudFormation のスタックを生成するときに、一時的なファイル置き場として S3 バケットが必要になることがあります。 例えば、Lambda 関数をデプロイするときに、ZIP パッケージを置くためのステージングバケットが必要になります。 このステージングバケットへの実際のアップロード処理は CDK が自動でやってくれるのですが、バケットの準備だけはあらかじめ手動で行っておく必要があります。 このためのコマンドが cdk bootstrap コマンドです。 AWS アカウント（およびリージョン）内で一度だけ実行しておけばよいので、このタイミングで実行しておきます。 実行時には次のように「アカウント番号」と「リージョン名」を指定する必要があります。 cdk bootstrap aws://\u0026lt;アカウント番号\u0026gt;/\u0026lt;リージョン名\u0026gt; 実際の実行例 $ cdk bootstrap aws://123456789012/ap-northeast-1 ⏳ Bootstrapping environment aws://123456789012/ap-northeast-1... CDKToolkit: creating CloudFormation changeset... ... ✅ Environment aws://123456789012/ap-northeast-1 bootstrapped. これにより、ステージング用のバケットを含む CDKToolkit という名前のブートストラップ・スタックが生成されます。 ちなみに、現在使用している「アカウント番号」と「リージョン名」は、AWS CLI を使って次のように確認できます。 アカウント番号の確認 $ aws sts get-caller-identity --output text --query Account [--profile xxxx] 123456789012 リージョン名の確認 $ aws configure get region [--profile xxxx] ap-northeast-1"
},
{
url: "/p/nqkav2m/",
title: "AWS CDK メモ: コンストラクトの概念を理解する",
date: "2021-10-04T00:00:00Z",
body: "AWS CDK メモ: コンストラクトの概念を理解する コンストラクト・ツリー (Construct Tree) AWS CDK を使って CloudFormation スタックを作成するとき、そのリソース構成は、論理的な コンストラクト (construct) のツリー構造によって表現します。 下記は、典型的な CDK アプリケーションにおけるコンストラクト・ツリー構造です。 App +-- Stack | +-- Construct | +-- Construct | +-- ... +-- Stack +-- Construct | +-- Construct | +-- Construct +-- Construct +-- ... App、Stack、Construct はそれぞれ抽象度の異なるオブジェクトですが、すべて IConstruct インタフェース を実装したコンストラクトの一種です。 CDK アプリ―ケーションには、構成のエントリポイントとなる App コンストラクト が 1 つあり、複数の Stack コンストラクトを含むことができます。 Stack コンストラクト は、その名の通り CloudFormation スタックを表現するコンストラクトです。 App が複数の Stack から構成されている場合、cdk deploy コマンドでデプロイを実行したときに複数の CloudFormation スタックが生成されることになります。 cdk deploy \u0026lt;Stack名\u0026gt; とすれば、特定のスタックのみをデプロイすることも可能です。 指定可能な Stack 名の一覧を確認したいときは、cdk ls コマンドを使います。 Stack コンストラクトはスタックを構成する入れ物であり、実際に AWS リソースを配置するには、Stack 内に具体的な AWS リソースを生成するための Construct コンストラクト を配置します。 末端に配置する Construct としては、CDK が提供する L1/L2/L3 コンストラクト（後述）や、cdk.Construct を継承して作った独自のコンストラクトなどを指定します。 Construct には、ほとんど CloudFormation のリソースそのままの低レベルなもの（例: CfnBucket）もあれば、高度に抽象化されたもの（例: LambdaRestApi）もあります。 Construct クラスには、複数の CDN アプリで使えるように汎用化されたものもあり、それらをコンストラクト・ライブラリ (Construct Library) と呼びます。 CDN 自体が提供している s3.Bucket もコンストラクト・ライブラリの一種です。 ☝️ 入れ子構造の制約 上の例のような階層構造はとても直感的ですが、実際には App 直下に独自の Construct を配置して、その下に複数の Stack を置くということもできます。 Construct は柔軟な構成が可能ですが、Construct を入れ子にするたびに、生成される AWS リソースの物理名も長くなっていくことに注意してください。 Stack を入れ子構造にしたいときは、Stack 以下に NestedStack を配置します。 L1/L2/L3 コンストラクト CDK はコンストラクト・ライブラリとして、L1 ～ L3 までの異なる抽象度レベルの Construct クラスを提供しています。 最初は、L2 あたりの Construct をよく使うことになると思います。 L1 コンストラクト (CloudFormation-only) CfnBucket のように、名前が Cfn で始まるもっとも低レベルなコンストラクトで、Cfn リソース とも呼ばれます。CloudFormation の仕様から自動生成されており、最新の AWS リソースであっても必ずこの L1 コンストラクトは提供されています。CloudFormation でリソースを定義するのと同様に詳細なプロパティ設定する必要があり、AWS リソースおよび CloudFormation に関する知識が必要です。 L2 コンストラクト (Curated) 1 つ以上の L1 コンストラクトをカプセル化し、デフォルトの設定やポリシーを提供したコンストラクトです。例えば、S3 バケットを生成するために s3.Bucket コンストラクトが提供されており、その実装内部では L1 コンストラクトの CfnBucket が使われています。L1 コンストラクトの CfnBucket で S3 バケットを作ろうとすると、bucketName prop で世界で一意な物理バケット名を指定する必要がありますが、L2 コンストラクトの s3.Bucket を使うと、コンストラクトにシンプルな論理名を指定するだけで済みます。また、L2 コンストラクトは便利メソッドを提供していることもあります（s3.Bucket の addLifeCycleRule() など）。 L3 コンストラクト (Patterns) 複数の L1、L2 コンストラクトを組み合わせて作られた、特定のユースケースを実現するためのコンストラクトです。例えば、API Gateway と Lambda 関数の組み合わせを簡単に定義する aws-apigateway.LambdaRestApi コンストラクトなどがあります。 コンストラクトの階層を作る コンストラクトの入れ子構造を作るには、各種コンストラクトのコンストラクタ（ややこしい＾＾;）の 第1引数 で親となるコンストラクトを指定します。 lib/my-app-stack.ts import * as cdk from \u0026#39;@aws-cdk/core\u0026#39; import * as s3 from \u0026#39;@aws-cdk/aws-s3\u0026#39; export class MyAppStack extends cdk.Stack { constructor(scope: cdk.Construct, id: string, props?: cdk.StackProps) { super(scope, id, props) new s3.Bucket(this, \u0026#39;MyBucket\u0026#39;) } } この例では、s3.Bucket コンストラクトの第1引数で this、つまり、MyAppStack コンストラクトを指定しています。 さらに、この MyAppStack をインスタンス化するときは、その親コンストラクトとして、CDK アプリのエントリポイントである App コンストラクトを指定します。 bin/my-app.ts import * as cdk from \u0026#39;@aws-cdk/core\u0026#39; import { MyAppStack } from \u0026#39;../lib/my-app-stack\u0026#39; const app = new cdk.App(); new MyAppStack(app, \u0026#39;MyAppStack\u0026#39;, {}) これらによって、次のようなコンストラクト・ツリーが作られたことになります。 App +-- MyAppStack +-- s3.Bucket ちなみに、App はトップレベルのコンストラクトなので、そのコンストラクタには親コンストラクトを指定するパラメーターはありません（参考: class App）。 通常、コンストラクトのコンストラクタの 第2引数 では、そのコンストラクトの論理 ID を指定します。 この ID はそのコンストラクト階層の中で一意であれば十分なので、CDK アプリ内で意味が通じる程度にシンプルな名前を付けるようにします。 第3引数 は、コンストラクトごとの設定情報である props オブジェクトを指定します。 例えば、s3.Bucket コンストラクトの場合は、s3.BucketProps オブジェクトを渡すことで、S3 バケットの設定を行うことができます（例: { versioned: true }）。 多くの場合、props オブジェクトの多くのプロパティは省略可能であり、第3引数の指定自体を省略できるコンストラクトもあります（s3.Bucket もそのひとつです）。"
},
{
url: "/p/4h3jygw/",
title: "AWS CDK メモ: CDK アプリのパッケージ管理に Yarn を使う方法",
date: "2022-04-17T00:00:00Z",
body: "AWS CDK メモ: CDK アプリのパッケージ管理に Yarn を使う方法 cdk init app --language typescript で CDK アプリのひな型を生成すると、デフォルトではパッケージマネージャーとして NPM を使う想定になっています（package-lock.json などが作成されます）。 NPM の代わりに Yarn を使いたい場合は、次のように package-lock.json を削除して、yarn.lock ファイルを生成します。 $ git rm package-lock.json $ yarn install 生成された yarn.lock は忘れずに Git へコミットしてください。 ちなみに、package-lock.json が残っている状態で yarn install しようとすると、次のような感じの Warning が表示されます。 warning package-lock.json found. Your project contains lock files generated by tools other than Yarn. It is advised not to mix package managers in order to avoid resolution inconsistencies caused by unsynchronized lock files. To clear this warning, remove package-lock.json."
},
{
url: "/p/2asq4k4/",
title: "AWS CDK メモ: 謎の CDKMetadata を生成しないようにする",
date: "2021-10-04T00:00:00Z",
body: "AWS CDK メモ: 謎の CDKMetadata を生成しないようにする AWS CDK で CloudFormation スタックを生成すると、デフォルトで CDKMetadata というリソースが生成されます（cdk synth コマンドで CloudFormation テンプレートを出力してみると確認できます）。 Resources:CDKMetadata:Type:AWS::CDK::MetadataProperties:Analytics:v2:deflate64:IsH4AAAAAAAA/L9ZNTs....9mAAAAMetadata:aws:cdk:path:CdkStack/CDKMetadata/DefaultCondition:CDKMetadataAvailableConditions:CDKMetadataAvailable:Fn::Or:- Fn::Or:- Fn::Equals:- Ref:AWS::Region- af-south-1- Fn::Equals:- Ref:AWS::Region- ap-east-1... 自分で何もリソース生成していないのにテンプレートが汚されて邪魔だなぁと思っていたら、この情報は、CDK を開発しているチームが利用状況などを把握して今後の改善のために使うようです。 下記、CDK のドキュメント より抜粋。 Every generated template contains a AWS::CDK::Metadata resource by default. (We haven\u0026rsquo;t shown it here.) The AWS CDK team uses this metadata to gain insight into how the AWS CDK is used, so we can continue to improve it. For details, including how to opt out of version reporting, see Version reporting. 気にならなければこのまま協力すればよいし、このデータが邪魔な場合は Opt-out でオフにすることができます。 CDK アプリのトップディレクトリにある cdk.json で次のように versionReporting を設定すれば、CDKMetadata は生成されなくなります。 cdk.json { \u0026#34;app\u0026#34;: \u0026#34;npx ts-node --prefer-ts-exts bin/my-app.ts\u0026#34;, \u0026#34;versionReporting\u0026#34;: false, \u0026#34;context\u0026#34;: { // ... } } $ cdk synth {} スッキリ！カラッポ！ というか、デフォルトはこっちにしておいて欲しいですね。 CloudFormation ってただでさえ読みにくいのに、デフォルトでデータを突っ込んでくる AWS 開発者たちよ。。。"
},
{
url: "/p/cj9i4m3/",
title: "AWS CDK で TypeScript で実装した Lambda 関数をデプロイする (NodejsFunction)",
date: "2021-10-06T00:00:00Z",
body: "AWS CDK で TypeScript で実装した Lambda 関数をデプロイする (NodejsFunction) 何をするか？ ここでは、CDK アプリとして作成した CloudFormation スタック内に、TypeScript で実装した Lambda 関数 を追加してみます。 Lambda 関数のビルドもデプロイ時に自動で行われるようにします。 以降の説明では、CDK プロジェクトの作成自体は済んでいるものとします。 参考: AWS CDK 入門: cdk コマンドのインストールから Hello World まで TypeScript で Lambda 関数を実装する Lambda 関数のコードは、プロジェクトのルートに lambda ディレクトリを作成して、そこに配置していくことにします。 myapp/ +-- bin/ ... CDK の App コンストラクト (.ts) +-- lambda/ ... ラムダ関数の実装コード (.ts) ★これを追加 | +-- index.ts +-- lib/ ... CDK の Stack コンストラクトなど (.ts) ... Lambda 関数実装用の TypeScript 型情報をインストールします。 $ npm install @types/aws-lambda --save-dev # npm の場合 $ yarn add @types/aws-lambda --dev # yarn の場合 最低限の Hello World 的なラムダ関数を作成します。 lambda/index.ts import { Handler } from \u0026#34;aws-lambda\u0026#34; // Lambda エントリーポイント export const handler: Handler = async () =\u0026gt; { console.log(\u0026#34;Hello Lambda!\u0026#34;) } Lambda 関数を含むスタックの定義とデプロイ NodejsFunction コンストラクト AWS CDK の ml) が提供する NodejsFunction コンストラクトを使用すると、TypeScript 言語で実装した Lambda 関数を簡単にビルド＆デプロイできます。 CDK V2 用の NodejsFunction コンストラクト (aws-cdk-lib/aws_lambda_nodejs) CDK V1 用の NodejsFunction コンストラクト (@aws-cdk/aws-lambda-nodejs) Lambda 関数用の汎用的なコンストラクトとしては、aws-cdk-lib/aws_lambda が提供する Function コンストラクトがあるのですが、これの代わりに、Node.js (TypeScript) に特化した NodejsFunction の方を使うと、次のような恩恵を得られます。 esbuild による Lambda 関数関連アセットの高速なパッケージング（バンドル）。 Lambda 関数の TypeScript コードをいちいちコンパイルしなくてよい。 ちょっとややこしいのですが、CDK コード（TypeScript で書いた場合）の実行は ts-code で実行され、Lambda 関数のビルドとパッケージングは esbuild で行われます。 CDK V1 のコンストラクトパッケージは次のようにインストールします。 CDK V2 の場合は、aws-cdk-lib に含まれているので、追加でパッケージをインストールする必要はありません。 CDK V1 の場合 $ npm install @aws-cdk/aws-lambda-nodejs # npm の場合 $ yarn add @aws-cdk/aws-lambda-nodejs # yarn の場合 スタックの定義 CDK アプリのひな型として、CloudFormation スタックを構築するためのコンストラクト (lib/myapp-stack.ts) が生成されているはずなので、そのスタック内に、NodejsFunction コンストラクトを生成するよう記述します。 lib/myapp-stack.ts // CDK V1 の場合 // import { Construct, Stack, StackProps } from \u0026#34;@aws-cdk/core\u0026#34; // import * as lambda from \u0026#34;@aws-cdk/aws-lambda-nodejs\u0026#34; // CDK V2 の場合 import { Stack, StackProps, aws_lambda_nodejs as lambda } from \u0026#34;aws-cdk-lib\u0026#34; import { Construct } from \u0026#34;constructs\u0026#34; export class MyappStack extends Stack { constructor(scope: Construct, id: string, props?: StackProps) { super(scope, id, props) new lambda.NodejsFunction(this, \u0026#34;MyLambda\u0026#34;, { entry: \u0026#34;lambda/index.ts\u0026#34;, // handler: \u0026#34;handler\u0026#34;, // デフォルトのハンドラ関数名は \u0026#34;handler\u0026#34; // runtime: Runtime.NODEJS_14_X, // デフォルトは Node.js 14.x // timeout: Duration.minutes(15), // デフォルトは 3 秒 }) } } 最小構成では、上記のように props オブジェクトの entry プロパティで Lambda 関数の index.ts ファイルパスを指定するだけで OK です。 デプロイ スタックの定義が済んだら、cdk deploy を実行して Lambda 関数をデプロイすることができます。 $ npm run cdk -- deploy デプロイが完了したら、CloudFormation コンソール を開いて、実際にスタックと Lambda 関数が生成されているか確認しましょう。 TypeScript コードのトランスパイルも esbuild で自動でやってくれるし、ZIP パッケージ化とアップロードも自動でやってくれる（これは CDK の機能ですが）ので、とっても楽ですね！ 参考: AWS CDK メモ: Lambda 関数コードだけ高速デプロイする (cdk deploy \u0026ndash;hotswap) トラブルシューティング デプロイ時に spawnSync docker ENOENT が出る場合 Windows や macOS で cdk diff や cdk deploy を実行したときに、spawnSync docker ENOENT というエラーが発生する場合は、esbuild をインストール するとうまくいくようです。 $ yarn add --dev esbuild@0 あるいは $ npm install --save-dev esbuild@0 NodejsFunction の第1引数の this でエラーになるとき CDK V1 の NodejsFunction のコンストラクタの this を渡している部分で、次のような型情報エラーが発生するときは、aws-cdk 本体と、コンストラクトライブラリ（@aws-cdk/aws-lambda-nodejs など）のバージョンが合っていない可能性があります。 Argument of type \u0026lsquo;this\u0026rsquo; is not assignable to parameter of type \u0026lsquo;Construct\u0026rsquo;. Type \u0026lsquo;MyappStack\u0026rsquo; is not assignable to type \u0026lsquo;Construct\u0026rsquo;. package.json を開いて、両者のバージョンを新しい方に揃えて、yarn install で更新すれば直ります。"
},
{
url: "/p/38jt3cm/",
title: "AWS CDK で Go 言語で実装した Lambda 関数をデプロイする (GoFunction)",
date: "2022-04-17T00:00:00Z",
body: "AWS CDK で Go 言語で実装した Lambda 関数をデプロイする (GoFunction) 何をするか？ ここでは、CDK アプリとして作成した CloudFormation スタック内に、Go 言語で実装した Lambda 関数 を追加してみます。 Lambda 関数のビルドもデプロイ時に自動で行われるようにします。 CDK のプロジェクト自体（スタックを定義する CDK コード）は TypeScript で作成します。 以降の説明では、CDK プロジェクトの作成自体は済んでいるものとします。 参考: AWS CDK 入門: cdk コマンドのインストールから Hello World まで Go 言語で Lambda 関数を実装する Lambda 関数のコードは、プロジェクトのルートに lambda ディレクトリを作成して、そこに配置していくことにします。 myapp/ +-- bin/ ... CDK の App コンストラクト (.ts) +-- lambda/ ... ラムダ関数用のディレクトリ (.go) | +-- go.mod | +-- go.sum | +-- main.go +-- lib/ ... CDK の Stack コンストラクトなど (.ts) ... lambda ディレクトリの下で、Go パッケージの依存情報 (go.mod、go.sum) を追加します。 $ mkdir lambda $ cd lambda $ go mod init lambda $ go get github.com/aws/aws-lambda-go/lambda Hello World 的な Lambda 関数を実装します。 次の Lambda 関数は、name 情報をイベントとして受け取り、挨拶テキストをレスポンスとして返します。 lambda/main.go package main import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;github.com/aws/aws-lambda-go/lambda\u0026#34; ) // Lambda 関数への入力イベントの型 type MyEvent struct { Name string `json:\u0026#34;name\u0026#34;` } // Lambda 関数からのレスポンスの型 type MyResponse struct { Message string `json:\u0026#34;message\u0026#34;` StatusCode int `json:\u0026#34;statusCode\u0026#34;` } // Lambda 関数のエントリポイント func handle(ctx context.Context, evt MyEvent) (MyResponse, error) { res := MyResponse{ Message: fmt.Sprintf(\u0026#34;Hello %s!\u0026#34;, evt.Name), StatusCode: 200, } return res, nil } // Go 言語での Lambda 関数実装にはこれが必要 func main() { lambda.Start(handle) } この時点で次のようにフォーマットやビルドを行えますが、後述の cdk deploy でビルドは自動で行われるようになるため、ここでビルドしておく必要はありません。 $ go fmt # Go コードのフォーマット $ go build -o main # Go コードのビルド Lambda 関数を含むスタックの定義とデプロイ @aws-cdk/aws-lambda-go パッケージ AWS CDK が提供する GoFunction コンストラクト クラスを使用すると、Go 言語で実装した Lambda 関数を簡単にデプロイできます。 CDK V2 用の @aws-cdk/aws-lambda-go-alpha いずれ aws-cdk-lib/aws_lambda_go として aws-cdk-lib に組み込まれるはず。 CDK V1 用の @aws-cdk/aws-lambda-go コンストラクトパッケージは次のようにインストールしますが、使用している CDK 本体のバージョン（V2 あるいは V1）に合わせたパッケージをインストールしてください。 $ npm install @aws-cdk/aws-lambda-go-alpha # npm の場合 $ yarn add @aws-cdk/aws-lambda-go-alpha # yarn の場合 ☝️ V2 と V1 CDK V1 用のパッケージは @aws-cdk、CDK V2 用のパッケージは aws-cdk-lib としてリリースされていますが、V2 の GoFunction コンストラクトに関しては、まだ@aws-cdk/aws-lambda-go-alpha としてリリースされているようです（2022 年 4 月現在）。 いずれ、aws-cdk-lib/aws_lambda_go としてリリースされると思われます（aws-cdk-lib 本体に組み込まれて、個別インストールの必要がなくなる）。 Lambda 関数用の汎用的なコンストラクトとしては、aws-cdk-lib/aws_lambda が提供する Function コンストラクトもあるのですが、GoFunction コンストラクトは Go 言語に特化しており、デプロイ時に Lambda 関数のビルド (go build) を自動で行ってくれます。 スタックの定義 CDK アプリのひな型として、CloudFormation スタックを構築するためのコンストラクト (lib/myapp-stack.ts) が生成されているはずなので、そのスタック内に、GoFunction コンストラクトを生成するよう記述します。 lib/myapp-stack.ts import { Stack, StackProps } from \u0026#34;aws-cdk-lib\u0026#34; import { Construct } from \u0026#34;constructs\u0026#34; import * as lambda from \u0026#34;@aws-cdk/aws-lambda-go-alpha\u0026#34; export class GoLambdaAppStack extends Stack { constructor(scope: Construct, id: string, props?: StackProps) { super(scope, id, props) // このスタックに Lambda 関数を追加する new lambda.GoFunction(this, \u0026#34;MyLambda\u0026#34;, { entry: \u0026#34;lambda\u0026#34;, }) } } 最小構成では、上記のように entry プロパティに Lambda 関数のディレクトリ名を指定するだけで OK です。 このディレクトリで go build によるビルドが行われるようになります。 デプロイとテスト スタックの定義が済んだら、cdk deploy を実行して Lambda 関数をデプロイすることができます。 Lambda 関数のビルド (go build) も自動で行われます。 $ npm run cdk -- deploy デプロイが完了したら、CloudFormation コンソール を開いて、実際にスタックと Lambda 関数が生成されているか確認してください。 次のように AWS CLI を使って関数を呼び出すことができます。 $ FUNC_NAME=MyappStack-MyLambdaCCE802FB-SRU9ijhbiKZ1 $ echo \u0026#39;{ \u0026#34;name\u0026#34;: \u0026#34;Maku\u0026#34; }\u0026#39; \u0026gt; event.json $ aws lambda invoke --function-name $FUNC_NAME --payload fileb://event.json output.txt ExecutedVersion: $LATEST StatusCode: 200 $ cat output.txt {\u0026#34;message\u0026#34;:\u0026#34;Hello Maku!\u0026#34;,\u0026#34;statusCode\u0026#34;:200} 参考: AWS CDK メモ: Lambda 関数コードだけ高速デプロイする (cdk deploy \u0026ndash;hotswap)"
},
{
url: "/p/gzkzbny/",
title: "AWS CDK のサンプルコード集（TypeScript 版）",
date: "2021-10-04T00:00:00Z",
body: "AWS CDK のサンプルコード集（TypeScript 版） AWS CDK を使った TypeScript サンプルコードいろいろです。 リソースにタグを付ける import * as cdk from \u0026#39;@aws-cdk/core\u0026#39; import { MyappStack } from \u0026#39;../lib/myapp-stack\u0026#39; const app = new cdk.App() new MyappStack(app, \u0026#39;MyappStack\u0026#39;, { tags: { Owner: \u0026#39;TeamA\u0026#39;, Purpose: \u0026#39;Project1\u0026#39;, }, }) AWS リソース用のコンストラクトの props パラメーターで、tags プロパティを指定することで、そのリソースにタグを設定できます。 タグの設定方法は、どの AWS リソース用のコンストラクトでも同様です。 上記のように Stack コンストラクトに対してタグを設定すると、その中に配置した AWS リソースにもそのタグが設定されます。 S3 バケットや DynamoDB テーブルをスタック削除時に自動削除する バケットが空のときだけ自動削除する import * as cdk from \u0026#39;@aws-cdk/core\u0026#39; import * as s3 from \u0026#39;@aws-cdk/aws-s3\u0026#39; new s3.Bucket(this, \u0026#39;MyBucket\u0026#39;, { removalPolicy: cdk.RemovalPolicy.DESTROY, }) CDK で作成した S3 バケットや DynamoDB テーブルは、デフォルトでは、（内容が空であっても）スタック削除時にそのまま残るようになっています。 つまり、スタックから独立したリソースとして S3 バケットだけが残ります。 これは、CloudFormation の DeletionPolicy のデフォルトの挙動とは逆なので注意してください。 スタックの削除 (cdk destroy) と同時に S3 バケットや DynamoDB テーブルを削除したいときは、上記のように removalPolicy を設定します。 バケットが空じゃなくても自動削除する import * as cdk from \u0026#39;@aws-cdk/core\u0026#39; import * as s3 from \u0026#39;@aws-cdk/aws-s3\u0026#39; new s3.Bucket(this, \u0026#39;MyBucket\u0026#39;, { removalPolicy: cdk.RemovalPolicy.DESTROY, autoDeleteObjects: true, }) removalPolicy を RemovalPolicy.DESTROY に設定しても、S3 バケットにオブジェクト含まれているときは、スタック削除時に連動して自動削除してくれません。 スタック削除時に、バケット内のオブジェクトを自動削除してバケットの削除までやってしまいたいときは、removalPolicy に加えて、autoDeleteObjects プロパティを設定します。 この設定を行うと、たとえ S3 バケットのバージョニングが有効 (versioned: true) になっていても、問答無用で削除されるので注意してください。 autoDeleteObjects の機能を実現するために、内部的に Lambda 関数が自動生成されるので、CDK のブートストラッピング (cdk bootstrap) をあらかじめ実行しておく必要があります。 S3 バケットの物理名 (Physical ID) を指定する import * as s3 from \u0026#39;@aws-cdk/aws-s3\u0026#39; const bucket = new s3.Bucket(this, \u0026#39;MyBucket\u0026#39;, { bucketName: \u0026#39;bucket-123456789012-user-data\u0026#39;, }) L2 コンストラクトの s3.Bucket は、物理バケット名（物理 ID）を自動生成してくれますが、何らかの理由で固定の物理名を指定したいときは、上記のように bucketName プロパティで明示的に指定することができます。 逆に、L1 コンストラクトの CfnBucket を使ってバケットを作成するときは、必ず bucketName の指定が必要です。 S3 バケットを作成して Lambda 関数から参照できるようにする import * as lambda from \u0026#39;@aws-cdk/aws-lambda\u0026#39; import * as s3 from \u0026#39;@aws-cdk/aws-s3\u0026#39; const bucket = new s3.Bucket(this, \u0026#39;my-bucket\u0026#39;) new lambda.Function(this, \u0026#39;my-lambda\u0026#39;, { // ... environment: { BUCKET_NAME: bucket.bucketName } }) // バケットポリシーで Lambda 関数から読み書きできるようにする bucket.grantReadWrite(lambda) Function コンストラクトをインスタンス化するときに、上記のように environment props を指定することで、Lambda 関数の実装の中で、環境変数 BUCKET_NAME としてバケット名を参照できるようになります。 実際に Lambda 関数から S3 バケットにアクセスできるようにするには、Bucket コンストラクト側の grantRead / grantWrite / grantReadWrite 関数を呼び出して、Lambda 関数にアクセス権限を付けておく必要があります（バケットポリシーが生成されます）。 これを忘れると、Lambda 関数の実行時に Access Denied エラーになります。 既存の S3 バケットを参照する import * as s3 from \u0026#39;@aws-cdk/aws-s3\u0026#39; // (A) Construct a resource (bucket) just by its name (must be same account) const myBucket = s3.Bucket.fromBucketName( this, \u0026#39;MyBucket\u0026#39;, \u0026#39;bucket-123456789012-user-data\u0026#39; ) // (B) Construct a resource (bucket) by its full ARN (can be cross account) const myBucket = s3.Bucket.fromBucketArn( this, \u0026#39;MyBucket\u0026#39;, \u0026#39;arn:aws:s3:::bucket-123456789012-user-data\u0026#39; ) // あとは Lambda 関数などに読み書き権限を与える myBucket.grantReadWrite(lambdaFunc) すでに別の CloudFormation スタック内に作成済みの S3 バケットなどを参照する必要がある場合は、上記のようにバケット名や ARN をもとに s3.Bucket インスタンスを生成できます。 既存の DynamoDB テーブルを参照する import * as dynamodb from \u0026#39;@aws-cdk/aws-dynamodb\u0026#39; // (A) 既存の DynamoDB テーブルをテーブル名で参照する（同一アカウント内） const configTable = dynamodb.Table.fromTableName( this, \u0026#39;ConfigTable\u0026#39;, \u0026#39;myapp-dev-config\u0026#39; ) // (B) 既存の DynamoDB テーブルを ARN で参照する（クロスアカウント） const configTable = dynamodb.Table.fromTableArn( this, \u0026#39;ConfigTable\u0026#39;, \u0026#39;arn:aws:dynamodb:\u0026lt;Region\u0026gt;:\u0026lt;Account\u0026gt;:table/myapp-dev-config\u0026#39; ) // あとは Lambda 関数などに読み書き権限を与える configTable.grantReadWriteData(lambdaFunc) S3 バケットにオブジェクトを追加したときに SNS トピック通知を発行する import * as s3 from \u0026#39;@aws-cdk/aws-s3\u0026#39; import * as s3notify from \u0026#39;@aws-cdk/aws-s3-notifications\u0026#39; import * as sns from \u0026#39;@aws-cdk/aws-sns\u0026#39; const bucket = new s3.Bucket(this, \u0026#39;bucket\u0026#39;) const topic = new sns.Topic(this, \u0026#39;topic\u0026#39;) bucket.addObjectCreatedNotification(new s3notify.SnsDestination(topic)) 上記のように S3 バケットと SNS トピックを生成して、addObjectCreatedNotification で関連付けると、S3 バケットへのオブジェクト追加（および更新）時に SNS トピックからの通知を発行できるようになります。 CloudFormation を直書きすると、S3 との連携用にポリシー設定 (AWS::SNS::TopicPolicy) まで記述しないといけなくて非常に面倒ですが、CDK であれば、上記のように記述だけで済みます（トピックポリシーは内部で自動生成してくれます）。 SNS Topic に自動設定されるアクセスポリシーの例 { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;0\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;s3.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;sns:Publish\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:sns:\u0026lt;リージョン\u0026gt;:\u0026lt;アカウント\u0026gt;:\u0026lt;トピック名\u0026gt;\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;ArnLike\u0026#34;: { \u0026#34;aws:SourceArn\u0026#34;: \u0026#34;arn:aws:s3:::\u0026lt;バケット名\u0026gt;\u0026#34; } } } ] } 応用として、NotifyingBucket をインスタンス化するときの props 引数で、prefix: '/images' と指定すれば、監視対象となるオブジェクトをフィルタすることができます。 次の独自コンストラクト (NotifyingBucket) の実装例では、オプションで prefix を指定できるようにしています。 import * as cdk from \u0026#39;@aws-cdk/core\u0026#39; import * as s3 from \u0026#39;@aws-cdk/aws-s3\u0026#39; import * as s3notify from \u0026#39;@aws-cdk/aws-s3-notifications\u0026#39; import * as sns from \u0026#39;@aws-cdk/aws-sns\u0026#39; export interface NotifyingBucketProps { prefix?: string } export class NotifyingBucket extends cdk.Construct { constructor(scope: cdk.Construct, id: string, props: NotifyingBucketProps = {}) { super(scope, id) const bucket = new s3.Bucket(this, \u0026#39;bucket\u0026#39;) const topic = new sns.Topic(this, \u0026#39;topic\u0026#39;) bucket.addObjectCreatedNotification(new s3notify.SnsDestination(topic), { prefix: props.prefix }) } } 参考: Constructs - AWS Cloud Development Kit (CDK) S3 バケットにオブジェクトが追加されたときに Lambda 関数を呼び出す import * as lambda from \u0026#39;@aws-cdk/aws-lambda\u0026#39; import * as s3 from \u0026#39;@aws-cdk/aws-s3\u0026#39; import * as s3notify from \u0026#39;@aws-cdk/aws-s3-notifications\u0026#39; const handler = new lambda.Function(this, \u0026#39;Handler\u0026#39;, {/* ... */}) const bucket = new s3.Bucket(this, \u0026#39;Bucket\u0026#39;) bucket.addObjectCreatedNotification(new s3notify.LambdaDestination(handler)) S3 バケットにオブジェクトが追加されたときに Lambda 関数を呼び出すには、Bucket#addObjectCreatedNotification() に LambdaDestination オブジェクトを渡します。 呼び出す関数は SNS トピック通知を発行する場合と同様ですが、引数で渡すオブジェクトが異なります。 SNS トピックの通知で Lambda 関数を呼び出す import * as sns from \u0026#39;@aws-cdk/aws-sns\u0026#39; import * as snsSub from \u0026#39;@aws-cdk/aws-sns-subscriptions\u0026#39; // 既存の SNS Topic からの通知で Lambda 関数を起動する const myTopic = sns.Topic.fromTopicArn( this, \u0026#39;MyTopic\u0026#39;, \u0026#39;arn:aws:sns:\u0026lt;Region\u0026gt;:\u0026lt;Account\u0026gt;:myapp-dev-xxx-topic\u0026#39; ) myTopic.addSubscription(new snsSub.LambdaSubscription(handler)) S3 バケットを Read 可能な IAM グループを作成する import * as s3 from \u0026#39;@aws-cdk/aws-s3\u0026#39; import * as iam from \u0026#39;@aws-cdk/aws-iam\u0026#39; const rawData = new s3.Bucket(this, \u0026#39;raw-data\u0026#39;) const dataScience = new iam.Group(this, \u0026#39;data-science\u0026#39;) rawData.grantRead(dataScience) S3 バケットへの CORS アクセスを許可する import * as s3 from \u0026#39;@aws-cdk/aws-s3\u0026#39; const myBucket = new s3.Bucket(this, \u0026#39;MyBucket\u0026#39;, { cors: [ { allowedHeaders: [\u0026#39;*\u0026#39;], allowedMethods: [s3.HttpMethods.GET, s3.HttpMethods.POST], allowedOrigins: [ \u0026#39;http://localhost:*\u0026#39;, \u0026#39;https://example.com/\u0026#39;, \u0026#39;https://*.example.com/\u0026#39;, ], }, ], }) Web サイトのクライアントサイド JavaScript から、S3 バケット内のファイルを取得する場合は、S3 バケットの CORS 設定でクロスオリジンのアクセスを許可しておく必要があります。 Web ブラウザのコンソール出力で、次のようなエラーが出たら、この CORS 設定ができていない証拠です。 Access to fetch at \u0026lsquo;\u0026hellip;\u0026rsquo; from origin \u0026lsquo;http://localhost:3000\u0026rsquo; has been blocked by CORS policy: No \u0026lsquo;Access-Control-Allow-Origin\u0026rsquo; header is present on the requested resource. allowedOrigins の指定方法ですが、http://localhost:3000 からアクセスするのであれば、http://localhost:3000 や http://localhost:* と記述する必要があり、スキーマを省略したり (localhost:3000)、ポート番号を省略したり (http://localhost) するのは NG です。 ワイルドカードのアスタリスクは、アドレスの一か所でのみ使用可能です。 参考: CORS configuration - Amazon S3 SQS キューと Lambda 関数を結びつける import * as lambda from \u0026#39;@aws-cdk/aws-lambda\u0026#39; import * as sqs from \u0026#39;@aws-cdk/aws-sqs\u0026#39; const jobsQueue = new sqs.Queue(this, \u0026#39;jobs\u0026#39;) const createJobLambda = new lambda.Function(this, \u0026#39;create-job\u0026#39;, { runtime: lambda.Runtime.NODEJS_14_X, handler: \u0026#39;index.handler\u0026#39;, code: lambda.Code.fromAsset(\u0026#39;./create-job-lambda-code\u0026#39;), environment: { QUEUE_URL: jobsQueue.queueUrl } }) このように、lambda.Function の props で environment を設定しておくと、Lambda 関数の実装の中から、QUEUE_URL 環境変数の形で SQS キューの URL を参照できるようになります。 参考: Constructs - AWS Cloud Development Kit (CDK) ECS クラスターを作って EC2 サービスから参照する import * as ecs from \u0026#39;@aws-cdk/aws-ecs\u0026#39; const cluster = new ecs.Cluster(this, \u0026#39;Cluster\u0026#39;, {/* ... */}) const service = new ecs.Ec2Service(this, \u0026#39;Service\u0026#39;, { cluster: cluster }) 別のスタック内の S3 バケットを参照する const prod = { account: \u0026#39;123456789012\u0026#39;, region: \u0026#39;ap-northeast-1\u0026#39; } const stack1 = new Stack1(app, \u0026#39;Stack1\u0026#39;, { env: prod }) const stack2 = new Stack2(app, \u0026#39;Stack2\u0026#39;, { env: prod, bucket: stack1.bucket }) Stack2 のコンストラクタの bucket props として、Stack1 オブジェクトの公開プロパティ bukcket を渡しています。 同じアカウント＆リージョンのスタックであることが条件です。 EventBridge で定期的に Lambda 関数を実行する import * as cdk from \u0026#39;@aws-cdk/core\u0026#39; import * as events from \u0026#39;@aws-cdk/aws-events\u0026#39; import * as eventsTargets from \u0026#39;@aws-cdk/aws-events-targets\u0026#39; import * as lambdaNodejs from \u0026#39;@aws-cdk/aws-lambda-nodejs\u0026#39; // Lambda 関数を作成する const myLambda = new lambdaNodejs.NodejsFunction(this, \u0026#39;MyLambda\u0026#39;, { entry: \u0026#39;lambda/index.ts\u0026#39;, }) // EventBridge ルールで 10 分おきに Lambda 関数呼び出し new events.Rule(this, \u0026#39;MyRule\u0026#39;, { schedule: events.Schedule.rate(cdk.Duration.minutes(10)), // 10分おき // schedule: events.Schedule.cron({ ... }), // cron 形式で指定する場合 targets: [ new eventsTargets.LambdaFunction(myLambda, { retryAttempts: 3 }), ], }) 上記の例では、10 分ごとに Lambda 関数を呼び出すように EventBridge のスケジュール設定（ルール設定）を行っています。 参考: ルールのスケジュール式 - Amazon CloudWatch Events CDK コードの中で SSM パラメーターストアのパラメーター値を取得する import * as ssm from \u0026#39;@aws-cdk/aws-ssm\u0026#39; const bucketName = ssm.StringParameter.valueForStringParameter(this, \u0026#39;/myapp/dev/ImageBucketName\u0026#39; ) 上記の例では、SSM パラメーターストアの /myapp/dev/ImageBucketName というパラメーターに格納された値を取得しています。 他のアプリが生成した S3 バケットの名前をこのパラメーターストアに格納してくれていれば、その値を介して連携させることができます。 パラメーターの種類が SecureString の場合は、次のように別の関数を使います（バージョン情報の指定が必要です）。 const gitHubToken = ssm.StringParameter.valueForSecureStringParameter(this, \u0026#39;/myapp/dev/GitHubToken\u0026#39;, 1 ) Lambda 関数から SSM パラメーターストアにアクセスできるようにする import * as lambdaNodejs from \u0026#39;@aws-cdk/aws-lambda-nodejs\u0026#39; import * as ssm from \u0026#39;@aws-cdk/aws-ssm\u0026#39; // Lambda 関数を作成する const myLambda = new lambdaNodejs.NodejsFunction(this, \u0026#39;MyLambda\u0026#39;, { runtime: lambda.Runtime.NODEJS_14_X, entry: \u0026#39;lambda/index.ts\u0026#39;, environment: { GITHUB_TOKEN_SSM_PARAM: \u0026#39;/myapp/dev/GitHubToken\u0026#39;, }, }) // 既存の SSM パラメーターの読み取り権限を Lambda 関数に与える const mySsmParam = ssm.StringParameter.fromStringParameterName( this, \u0026#39;MySsmParam\u0026#39;, \u0026#39;/myapp/dev/GitHubToken\u0026#39; ) mySsmParam.grantRead(myLambda) // エラーが出るときは、下記でやってみる // const mySsmParam = ssm.StringParameter.fromSecureStringParameterAttributes( // this, \u0026#39;MySsmParam\u0026#39;, { // parameterName: \u0026#39;/myapp/dev/GitHubToken\u0026#39;, // version: 1, // } // ) ここでは、パラメーターストア上のパラメーター (/myapp/dev/GitHubToken) として GitHub のアクセストークンを格納して、Lambda 関数内からその値を取得することを想定しています。 既存のパラメーターのコンストラクト参照を取得するには、上記のように ssm.StringParameter.fromStringParameterName 関数を使用します。 あとは、grantRead で Lambda 関数からの読み込みを許可してやると、次のようなアクションがまとめて許可されます。 ssm:DescribeParameters ssm:GetParameter ssm:GetParameterHistory ssm:GetParameters StringParameter の grantRead 関数を使わずに、次のように Lambda 関数に Policy ステートメントを直接追加してしまう方法もありますが、パラメーターの ARN 指定などが面倒ですね。 grantRead を使った方がシンプルでよいと思います。 myLambda.addToRolePolicy(new iam.PolicyStatement({ effect: iam.Effect.ALLOW, actions: [\u0026#39;ssm:GetParameter*\u0026#39;], resources: [\u0026#39;arn:aws:ssm:\u0026lt;Region\u0026gt;:\u0026lt;Account\u0026gt;:parameter/myapp/dev/GitHubToken\u0026#39;], })) ちなみに、Lambda 関数 (AWS SDK) の方では、次のような感じでパラメーターの値を取得できます。 Lambda 関数内で SSM パラメーター値を取得 import * as AWS from \u0026#39;aws-sdk\u0026#39; const ssm = new AWS.SSM({ region: \u0026#39;ap-northeast-1\u0026#39; }) export async function getGitHubToken(): Promise\u0026lt;string | undefined\u0026gt; { const result = await ssm.getParameter({ Name: process.env.GITHUB_TOKEN_SSM_PARAM as string, WithDecryption: true, }).promise() return result.Parameter?.Value } ApiGateway + Lambda 関数で REST API を作成する lib/myapi-stack.ts // CDK V1 の場合 // import { Construct, Stack, StackProps } from \u0026#39;@aws-cdk/core\u0026#39; // import * as apigateway from \u0026#39;@aws-cdk/aws-apigateway\u0026#39; // import * as lambdaNodejs from \u0026#39;@aws-cdk/aws-lambda-nodejs\u0026#39; // CDK V2 の場合 import { Stack, StackProps, aws_apigateway as apigateway, aws_lambda_nodejs as lambda, } from \u0026#34;aws-cdk-lib\u0026#34; import { Construct } from \u0026#34;constructs\u0026#34; export class MyappStack extends Stack { constructor(scope: Construct, id: string, props?: StackProps) { super(scope, id, props) // Lambda 関数（GET books/ のハンドル用） const getBooksHandler = new lambda.NodejsFunction(this, \u0026#34;getBooksHandler\u0026#34;, { entry: \u0026#34;lambda/index.ts\u0026#34;, handler: \u0026#34;getBooksHandler\u0026#34;, }) // Lambda 関数（GET books/{id} のハンドル用） const getSingleBookHandler = new lambda.NodejsFunction( this, \u0026#34;getSingleBookHandler\u0026#34;, { entry: \u0026#34;lambda/index.ts\u0026#34;, handler: \u0026#34;getSingleBookHandler\u0026#34;, } ) // ApiGateway (RestApi) の作成 const api = new apigateway.RestApi(this, \u0026#34;api\u0026#34;) // リソースを定義して Lambda プロキシ統合する (GET books/) const books = api.root.addResource(\u0026#34;books\u0026#34;) books.addMethod(\u0026#34;GET\u0026#34;, new apigateway.LambdaIntegration(getBooksHandler)) // リソースを定義して Lambda プロキシ統合する (GET books/{id}) const singleBook = books.addResource(\u0026#34;{id}\u0026#34;) singleBook.addMethod( \u0026#34;GET\u0026#34;, new apigateway.LambdaIntegration(getSingleBookHandler) ) } } 下記はバックエンドとして動く Lambda 関数の適当な実装です。 実際には、DynamoDB などから情報を取得して JSON データとして返すように実装します。 lambda/index.ts // npm install --save-dev @types/aws-lambda import { Handler } from \u0026#39;aws-lambda\u0026#39; const BOOKS = [ { id: \u0026#39;1\u0026#39;, title: \u0026#39;Title 1\u0026#39; }, { id: \u0026#39;2\u0026#39;, title: \u0026#39;Title 2\u0026#39; }, { id: \u0026#39;3\u0026#39;, title: \u0026#39;Title 3\u0026#39; }, ] /** 全ての本情報を取得する。 */ export const getBooksHandler: Handler = async () =\u0026gt; { return { statusCode: 200, body: JSON.stringify(BOOKS), } } /** 指定された ID の本情報を取得する。 */ export const getSingleBookHandler: Handler = async (event: any = {}) =\u0026gt; { const id = event.pathParameters.id return { statusCode: 200, body: JSON.stringify(BOOKS.find((b) =\u0026gt; b.id === id)), } } cdk deploy 後に発行された次のような API エンドポイントにアクセスできれば成功です。 https://xxxxxxxxxx.execute-api.ap-northeast-1.amazonaws.com/prod/books/"
},
{
url: "/p/u53q2qi/",
title: "TypeScriptのモジュールの仕組みについて",
date: "2020-02-04T00:00:00Z",
body: "TypeScriptのモジュールの仕組みについて"
},
{
url: "/p/hrgu4dk/",
title: "TypeScript の型／タイプアノテーション",
date: "2022-02-08T00:00:00Z",
body: "TypeScript の型／タイプアノテーション"
},
{
url: "/p/7wnt5qf/",
title: "TypeScriptのサンプルコード",
date: "2020-05-08T00:00:00Z",
body: "TypeScriptのサンプルコード"
},
{
url: "/p/n5emu3a/",
title: "ConoHa VPS を借りて独自ドメインでアクセスできるようにする",
date: "2022-06-27T00:00:00Z",
body: "ConoHa VPS を借りて独自ドメインでアクセスできるようにする 何をするか？ ConoHa の VPS を借りたので、そのときの設定手順をメモしておきます。 大体こんな感じのことをしています。 ConoHa VPS を契約 して Ubuntu 22.04 を起動 お名前.com で独自ドメインを取得 独自ドメインで ConoHa VPS にアクセスできるようにする（IPv6 も有効化） ConoHa VPS はリーズナブルかつ API でのサーバー管理ができたりして、徐々に人気が高まってきてるみたいです。 安いプランであれば月額数百円で借りることができます。 Docker コンテナやデータベース (RDB) をホストするサーバーが欲しかったのですが、AWS や Azure はプライベートで使うには高すぎるので、今回は ConoHa VPS を採用しました。 VPS にはグローバル IP アドレスが割り当てられるので独自ドメインは必須ではないですが、やはりドメイン名でアクセスできた方がよいので、いつも通り お名前.com でドメイン取得しました。 ここでは、example.com というドメインを取得したものとして説明しています。 ConoHa のアカウントを作って VPS を契約 何はともあれ、まずは ConoHa のアカウントを作って ConoHa VPS を借ります。 ポチポチやってけば終わります。 図: ConoHa VPS での OS の選択 VPS の初期 OS として、Ubuntu 22.04 を選択しました。 上記は選択できる OS の一例ですが、他にもいろいろあります。 独自ドメインを取得する ConoHa VPS に割り当てる独自ドメインを取得しておきます。 ドメインはどこで取得してもいいんですが、あまりいろいろな会社に散らばると面倒なので、わたしの場合はお名前.com に統一しています。 ConoHa でもドメイン取得できるので、そちらで取得しても大丈夫です。 ドメイン取るなら - お名前.com ここでは、example.com というドメインを取得したとして説明していきます。 毎度のことなんですが、ドメイン名を考えるのが一番時間がかかりますねｗ ドメインの更新料金は 1 年ごとに数千円程度ですが、1 年目は数百円だったりします。 DNS サーバーを設定する 独自ドメインを取得したら、そのドメイン名で ConoHa VPS のサーバーにアクセスできるようにします。 つまり、example.com から 160.xxx.xxx.xxx のような IP アドレスを引けるようにします。 参考: ドメイン管理と DNS 管理の違いを理解する ネームサーバーを変更する お名前.com でドメインを取得すると、そのドメインの IP アドレスは次のような DNS サーバーで管理するよう初期設定されています。 dns1.onamae.com / dns2.onamae.com この状態で、Web ブラウザから独自ドメインにアクセス (http://example.com) すると、お名前.com の「ようこそ」的な Web ページが表示されるようになっています。 このままではダメなので、DNS サーバーを変更して、その DNS サーバーで正しい IP アドレスを関連づけてやります。 お名前.com が用意している次のような DNS サーバーを使うこともできますが、 01.dnsv.jp / 02.dnsv.jp 今回はせっかくなので、ConoHa が提供している DNS サーバーを使ってみます。 お名前.com Navi にログインして、次のように使用する DNS サーバーを変更します。 図: お名前.com のネームサーバー変更 ネームサーバーの設定 → ネームサーバーの設定 と選択する 取得したドメイン名 (example.com) を選択する 他のネームサーバーを利用 を選択して、次のような ConoHa 側の DNS サーバーを登録する ns-a1.conoha.io ns-a2.conoha.io ns-a3.conoha.io DNS に IP アドレス情報を設定する 次に、ConoHa 側のコントールパネル で DNS サーバーの設定をします。 ここで、ドメイン名と IP アドレスを関連付けます。 まず、コントロールパネルから VPS サーバー情報を開いて、割り当てられた IPv4 アドレス（160.xxx.xxx.xxx など）を確認しておきます。 ConoHa コントロールパネル - サーバーリスト また、そこで IPv6 として割り当て可能なアドレスのリストも確認できるので、一番上のアドレス（2400:8500:1801:XXX:XXX:XXX:XX:XX など）とゲートウェイのアドレスを控えておきます。 VPS に最初から 17 個の IPv6 アドレスが割り当てられているように見えますが、それは罠で、自分で VPS に設定しないといけません（後述）。 IP アドレスがわかったら、DNS の設定画面を開いて、A レコード（IPv4 アドレス）と AAAA レコード（IPv6 アドレス）として登録します。 ConoHa コントロールパネル - サーバーリスト 図: DNS レコードの追加 取得したドメイン (example.com) を追加 編集ボタンを押して、A レコードとして IPv4 アドレスを追加します。 例: 名称: @, TTL: 3600, VALUE: 160.xxx.xxx.xxx IPv6 アドレスも割り当てたい場合は、AAAA レコードも追加します。 例: 名称: @, TTL: 3600, VALUE: 2400:8500:1801:XXX:XXX:XXX:XX:XX 以上の設定を終えて 10 分くらい待つと、ping examle.com が通るようになります。 ただし、デフォルトでは VPS に IPv6 のアドレスは割り当てられていないので、VPS の設定を変更して IPv6 を有効化します。 VPS に IPv6 アドレスを設定する ConoHa VPS に IPv6 のアドレスを割り当てる方法として、下記のマニュアルが用意されていますが、これは CentOS 用のものみたいです（2022年6月現在）。 Ubuntu では Netplan でネットワーク設定するので、そのやり方をメモっておきます。 参考: ConoHa - ご利用ガイド IPv6 を VPS へ設定する 参考: Linuxメモ: Netplan で Ubuntu のネットワーク設定を行う 以下のファイル編集作業は、次のように SSH 接続するか、ConoHa コントロールパネルからコンソールを開いて行います。 $ ssh root@example.com ConoHa VPS の Ubuntu 22.04 の初期設定では、Netplan の設定ファイルとして下記のファイルだけが入っています。 IPv4 は DHCP が有効になっていますが、うまく固定のアドレスが割り当てられているようです。 vi /etc/netplan/10-gmovps.yaml network:ethernets:eth0:addresses:[]dhcp4:truedhcp6:falseaccept-ra:falseoptional:trueversion:2 このファイルを書き換えてもよいのですが、IPv6 設定用のファイルを別に用意することにします。 vi /etc/netplan/99-custom.yaml network:ethernets:eth0:addresses:- \u0026#34;2400:8500:XXXX:XXX:XXX:XXX:XX:XX/64\u0026#34;# IPv6 アドレスを設定dhcp6:falseaccept-ra:falseoptional:trueroutes:- to:defaultvia:\u0026#34;2400:8500:XXXX:XXX::1\u0026#34;# デフォルトゲートウェイを設定version:2 あとは、次のように Netplan の設定を反映すれば、IPv6 の設定完了です。 # netplan apply ip コマンド で IPv6 アドレスやデフォルトゲートウェイが正しく割り当てられているか確認しておきます。 IPv6 アドレスの確認 $ ip a show dev eth0 2: eth0: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000 link/ether 02:02:a0:fb:XX:XX brd ff:ff:ff:ff:ff:ff altname enp0s3 altname ens3 inet 160.XXX.XXX.XXX/23 metric 100 brd 160.XXX.XXX.255 scope global dynamic eth0 valid_lft 5183492sec preferred_lft 5183492sec inet6 2400:8500:XXXX:XXX:XXX:XXX:XX:XX/64 scope global valid_lft forever preferred_lft forever inet6 fe80::2:a0ff:fefb:330a/64 scope link valid_lft forever preferred_lft forever デフォルトゲートウェイの確認 $ ip -6 route ::1 dev lo proto kernel metric 256 pref medium 2400:8500:XXXX:XXX::/64 dev eth0 proto kernel metric 256 pref medium fe80::/64 dev eth0 proto kernel metric 256 pref medium default via 2400:8500:XXXX:XXX::1 dev eth0 proto static metric 1024 pref medium IPv6 で外部サーバー (google.com) に ping6 できることも確認しておきます。 $ ping6 -c 3 -I eth0 google.com PING google.com(nrt12s30-in-x0e.1e100.net (2404:6800:4004:812::200e)) from 2400:8500:XXXX:XXX:XXX:XXX:XX:XX eth0: 56 data bytes 64 bytes from nrt12s30-in-x0e.1e100.net (2404:6800:4004:812::200e): icmp_seq=1 ttl=56 time=1.03 ms 64 bytes from nrt12s30-in-x0e.1e100.net (2404:6800:4004:812::200e): icmp_seq=2 ttl=56 time=0.838 ms 64 bytes from nrt12s30-in-x0e.1e100.net (2404:6800:4004:812::200e): icmp_seq=3 ttl=56 time=0.833 ms 逆に、手元の PC から ConoHa VPS に ping6 できることも確認しておきます。 $ ping6 example.com ...（省略）... これで、独自ドメインで ConoHa VPS にアクセスできるようになりました！ ConoHa VPS 広告 最後に、お得な広告を貼っておきます（＾＾ ConoHa VPS の申し込みはこちらから → お名前.com での ドメイン取得 はこちらから →"
},
{
url: "/",
title: "まくろぐ",
date: "2022-06-27T00:00:00Z",
body: "まくろぐ"
},
{
url: "/p/nd3cmt3/",
title: "ネットワーク関連技術メモ",
date: "2022-06-27T00:00:00Z",
body: "ネットワーク関連技術メモ"
},
{
url: "/p/3ftx6b2/",
title: "技術系のメモ",
date: "2022-06-27T00:00:00Z",
body: "技術系のメモ"
},
{
url: "/p/opyajt3/",
title: "Let's Encrypt 関連記事",
date: "2022-06-26T00:00:00Z",
body: "Let's Encrypt 関連記事"
},
{
url: "/p/fn7m2gu/",
title: "JavaScript / Node.js 関連メモ",
date: "2022-06-22T00:00:00Z",
body: "JavaScript / Node.js 関連メモ"
},
{
url: "/p/oj9nzgt/",
title: "Node.js で URL のパスを結合する (url-join)",
date: "2022-06-22T00:00:00Z",
body: "Node.js で URL のパスを結合する (url-join) José F. Romaniello 氏 (jfromaniello) が公開している NPM パッケージの url-join を使うと、バラバラになった URL のパスをうまいこと結合してくれます。 url-join のインストール $ npm install url-join 使用例 import urlJoin from \u0026#39;url-join\u0026#39; urlJoin(\u0026#39;https://example.com\u0026#39;, \u0026#39;a\u0026#39;, \u0026#39;/b/c\u0026#39;)) //=\u0026gt; https://example.com/a/b/c urlJoin(\u0026#39;https://example.com/\u0026#39;, \u0026#39;/a\u0026#39;, \u0026#39;/b/c/\u0026#39;)) //=\u0026gt; https://example.com/a/b/c/ urlJoin(\u0026#39;https://example.com\u0026#39;, \u0026#39;/foo\u0026#39;, \u0026#39;?q=123\u0026#39;)) //=\u0026gt; https://example.com/foo?q=123 urlJoin(\u0026#39;https://example.com\u0026#39;, \u0026#39;foo/\u0026#39;, \u0026#39;/?q=123\u0026#39;)) //=\u0026gt; https://example.com/foo?q=123 URL の末尾にクエリ文字列 (?q=123) があるときは、パス部分の末尾の / は消されちゃうみたいですね。 ☝️ path.join は URL 結合には使えない path モジュールの path.join は、ローカルファイルシステム用のパス結合関数なので、URL の結合には使ってはいけません。 例えば、Windows 環境ではバックスラッシュが使われてしまったりします。"
},
{
url: "/p/ruk3gu9/",
title: "Linux メモ",
date: "2022-06-16T00:00:00Z",
body: "Linux メモ"
},
{
url: "/p/p7q7n4i/",
title: "Linuxコマンド: ip コマンドの使い方",
date: "2022-06-16T00:00:00Z",
body: "Linuxコマンド: ip コマンドの使い方 apt で ip コマンドをインストールする ip コマンドは APT の iproute2 パッケージに含まれています。 Docker の Ubuntu コンテナなどで ip コマンドが見つからない場合は、次のようにインストールできます。 $ apt update # パッケージリストの更新 $ apt install -y iproute2 iproute2 パッケージには、ip コマンド以外にもいろいろなコマンドが含まれています（参考: iproute2 に含まれるファイルのリスト ─ Debian / archlinux）。 arpd - userspace arp daemon bridge - show / manipulate bridge addresses and devices devlink - Devlink tool ip - show / manipulate routing, devices, policy routing and tunnels lnstat - unified linux network statistics nstat - network statistics tools routef - flush routes routel - list routes with pretty output format rtacct - network statistics tools rtmon - listens to and monitors RTnetlink rtstat - unified linux network statistics ss - another utility to investigate sockets tc - show / manipulate traffic control settings tipc - a TIPC configuration and management tool サブコマンドのヘルプを表示する ip \u0026lt;サブコマンド名\u0026gt; help で各サブコマンドのヘルプを表示できます。 例: ip address コマンドのヘルプを表示する $ ip address help 例: ip link コマンドのヘルプを表示する $ ip link help ip address コマンド（IP アドレスの確認・設定） ip address コマンドは、ホストの（ネットワークインタフェース）に割り当てられている IP アドレスの情報を表示します。 サブコマンドの address は 1 文字まで省略できるので、ip a で実行することができます。 すべてのアドレスを表示 $ ip addr 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever 2: tunl0@NONE: \u0026lt;NOARP\u0026gt; mtu 1480 qdisc noop state DOWN group default qlen 1000 link/ipip 0.0.0.0 brd 0.0.0.0 3: ip6tnl0@NONE: \u0026lt;NOARP\u0026gt; mtu 1452 qdisc noop state DOWN group default qlen 1000 link/tunnel6 :: brd :: permaddr e28e:402f:dcf2:: 81: eth0@if82: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc noqueue state UP group default link/ether 02:42:ac:11:00:03 brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet 172.17.0.3/16 brd 172.17.255.255 scope global eth0 valid_lft forever preferred_lft forever 指定したデバイス (eth0) のアドレスを表示 $ ip addr show dev eth0 81: eth0@if82: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc noqueue state UP group default link/ether 02:42:ac:11:00:03 brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet 172.17.0.3/16 brd 172.17.255.255 scope global eth0 valid_lft forever preferred_lft forever IPv6 アドレスが割り当てられているか確認する 次のように fe80:: で始まるアドレスしか表示されない場合は、IPv6 アドレスは割り当てられていません。 $ ip -6 a 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 state UNKNOWN qlen 1000 inet6 ::1/128 scope host valid_lft forever preferred_lft forever 2: eth0: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 state UP qlen 1000 inet6 fe80::2:a0ff:fefb:330a/64 scope link valid_lft forever preferred_lft forever fe80:: で始まるアドレスは、IPv6 におけるリンクローカルアドレスです。 ちなみに、IPv4 のリンクローカルアドレスは 169.254.0.0 〜 169.254.255.255 です。 DHCP などでアドレスが割り当てられない場合に、IP アドレス自己割り当て機能 (APIPA: Automatic Private IP Addressing) を使って、これらの IP アドレスが割り当てられます。"
},
{
url: "/p/aseqzau/",
title: "Apollo Server 関連記事",
date: "2022-06-08T00:00:00Z",
body: "Apollo Server 関連記事"
},
{
url: "/p/q7q4ahp/",
title: "Apollo Server で GraphQL サーバーを作成する (Hello World)",
date: "2022-06-08T00:00:00Z",
body: "Apollo Server で GraphQL サーバーを作成する (Hello World) 何をするか？ apollo-server NPM パッケージは、Node.js で GraphQL サーバーを実装するためのライブラリです。 Apollo Graph 社が OSS として公開しており、2022 年時点で最も使用されている JavaScript 用の GraphQL ライブラリです。 ここでは、簡単な GraphQL スキーマとリゾルバーを定義して、GraphQL サーバーを立ち上げてみます。 apollo-server は標準で TypeScript の型情報に対応しているため、ここでは TypeScript を使って実装しますが、JavaScript でもほぼ同様に実装できます。 TypeScript 用プロジェクトの準備 TypeScript の実行環境自体は、下記の記事などを参考にしてセットアップします。 参考: TypeScriptの環境: Visual Studio Code で TypeScript の開発環境を構築する でもここでは、.ts ファイルをそのまま実行できる ts-node を使って楽をしちゃいます。 プロジェクトの作成 $ mkdir myserver \u0026amp;\u0026amp; cd myserver $ npm init -y $ npm install --save-dev typescript ts-node package.json を少し修正して、npm run dev で main.ts を起動できるようにしておきます。 package.json // ... \u0026#34;scripts\u0026#34;: { \u0026#34;dev\u0026#34;: \u0026#34;ts-node main\u0026#34; } これで準備完了です。 apollo-server と graphql のインストール GraphQL サーバーインスタンスを立ち上げるための apollo-server パッケージと、GraphQL スキーマを扱うための graphql パッケージをインストールします。 $ npm install --save-dev apollo-server graphql GraphQL サーバーを実装する Apollo Server ライブラリを使って GraphQL サーバーを実装していきます。 ここでは、Query のルートフィールドとして hello フィールドを定義して、そのリゾルバー関数で world を返すように実装します。 main.ts import { ApolloServer, gql } from \u0026#39;apollo-server\u0026#39; // GraphQL スキーマの定義 const typeDefs = gql` type Query { hello: String! } ` // リゾルバーの定義 const resolvers = { Query: { hello: () =\u0026gt; \u0026#39;world\u0026#39;, }, } // GraphQL サーバーを起動する const server = new ApolloServer({ typeDefs, resolvers }) server.listen().then(({ url }) =\u0026gt; { console.log(`🚀 Server ready at ${url}`) }) Hello World なのでとてもシンプル！ 次のように実行すれば GraphQL サーバーが立ち上がります。 $ npm -s run dev 🚀 Server ready at http://localhost:4000/ デフォルトで 4000 番ポートで起動しますが、server.listen({ port: 5000 }) のように変更できます。 GraphQL クエリを実行してみる 立ち上げた GraphQL サーバーに対してクエリ実行してみます。 どんな GraphQL クライアントを使ってもよいのですが、Apollo Studio Explorer というサイトから、簡単に localhost:4000 に対して GraphQL クエリを投げられます。 図: Apollo Studio Explorer からのクエリ実行 hello フィールドを参照すると、正しく world という値が返ってきていることを確認できます。 curl コマンドで直接 GraphQL API を呼び出して確認することもできます。 $ curl --request POST \\ --header \u0026#39;content-type: application/json\u0026#39; \\ --url http://localhost:4000/ \\ --data \u0026#39;{\u0026#34;query\u0026#34;:\u0026#34;query { hello }\u0026#34;}\u0026#39; {\u0026#34;data\u0026#34;:{\u0026#34;hello\u0026#34;:\u0026#34;world\u0026#34;}}"
},
{
url: "/p/cm9nyco/",
title: "GraphQL 関連記事",
date: "2022-06-08T00:00:00Z",
body: "GraphQL 関連記事"
},
{
url: "/p/6p3dox9/",
title: "Firebase 関連メモ",
date: "2022-06-05T00:00:00Z",
body: "Firebase 関連メモ"
},
{
url: "/p/dtdtbr8/",
title: "Firestore のデータバンドルを作成してドキュメントの読み込み回数を削減する",
date: "2022-06-05T00:00:00Z",
body: "Firestore のデータバンドルを作成してドキュメントの読み込み回数を削減する 何をするか？ Firestore はクライアントアプリから直接アクセスできることが利点ですが、多数のクライアントから複数のドキュメントを読み込んでいると、あっという間に無料枠を超えて高額な請求が発生してしまいます。 図: 同じデータなのに何度もドキュメントの Read が発生する Firebase 8.2.0 でリリースされた Cloud Firestore Data Bundles という仕組みを使用すると、Firestore から取得したデータ（クエリ結果）をバンドルというデータにまとめておいて、それを使いまわすことができます。 データバンドルを CDN でキャッシュ、あるいはクライアントサイドでキャッシュすることにより、Firestore へのアクセスを発生させずに、あたかも Firestore からデータフェッチしたかのように動作させることが可能です。 ユーザー数の多いアプリに導入すれば、大きなコスト削減につながります。 データバンドルは Cloud Functions を使って作成してしまうのが簡単です。 下記のような構成にすれば、クライアントアプリは Firestore にアクセスする代わりにデータバンドルを取得して動作するようになります。 図: Cloud Functions でバンドルを生成する しかし、これだけでは複数のクライアントから Cloud Functions へのアクセスが発生してしまうので、結局はその都度 Firestore へのアクセスが発生してしまいます。 各クライアントアプリではキャッシュが有効ですが、そのキャッシュでさえ、Ctrl(Cmd) + R によるスーパーリロードで無視されてしまいます。 そこで、次のようにさらに CDN (Firebase Hosting) を挟んでデータバンドルをキャッシュすることで、各クライアントからのアクセスで Cloud Functions が起動されてしまうのを防ぎます。 図: CDN でバンドルをキャッシュする この構成になっていれば、クライアントがいくら強制リロードしようが、CDN (Firebase Hosting) にキャッシュされたデータバンドルのみが参照されるようになります。 Firestore へのアクセスが発生するのは、CDN 上のキャッシュが無効になったときのみです。 クライアント側のキャッシュ時間や、CDN のキャッシュ時間は、Cloud Functions の関数が返すレスポンスヘッダ (Cache-Control) で制御できます。 Cloud Functions でデータバンドルを作成する 下記のコードでは、Cloud Functions に登録する createBundle 関数を定義しています。 処理の流れは次のようになっています。 Firestore のコレクションからドキュメントを取得（ここでは最新の 50 件の books データ） データバンドルを作成し、上記 books データを名前付きクエリ結果として格納 関数のレスポンスとしてデータバンドルを返す Firestore には既に books コレクションが登録されているものとします。 functions/index.ts import * as admin from \u0026#39;firebase-admin\u0026#39; import * as functions from \u0026#39;firebase-functions\u0026#39; const COLLECTION_NAME = \u0026#39;books\u0026#39; // Firestore のコレクション名 const QUERY_NAME = \u0026#39;latest-books-query\u0026#39; // バンドルに作成する名前付きクエリの名前 const MAX_AGE = 300 // ブラウザにキャッシュさせる秒数 const S_MAXAGE = 600 // CDN にキャッシュさせる秒数 admin.initializeApp({ projectId: \u0026#39;myapp-12345\u0026#39; }) const db = admin.firestore() /** Cloud Functions に登録する関数 */ export const createBundle = functions .region(\u0026#39;us-central1\u0026#39;) // asia-northeast1 にしたいけど Firebase Hosting が対応してない .https.onRequest(async (req, res) =\u0026gt; { // Firestore からデータを取得する（これは頻繁には呼ばれないようにしたい） console.log(`Fetch from Firestore [collection=${COLLECTION_NAME}]...`) const books = await db .collection(COLLECTION_NAME) .orderBy(\u0026#39;date\u0026#39;, \u0026#39;desc\u0026#39;) // 新しい順 .limit(50) .get() // 取得したデータからデータバンドルと名前付きクエリを作成する console.log(`Create a named query [queryName=${QUERY_NAME}]`) const builder = db.bundle() // バンドル ID は省略可能 const bundleBuffer = builder.add(QUERY_NAME, books).build() // 何度もこの関数が呼ばれないようにブラウザと CDN にキャッシュ時間を指示する res.set(\u0026#39;Cache-Control\u0026#39;, `public, max-age=${MAX_AGE}, s-maxage=${S_MAXAGE}`) // テストで Client JS から直接呼び出す場合は CORS 対応しておく res.set(\u0026#39;Access-Control-Allow-Origin\u0026#39;, \u0026#39;*\u0026#39;) res.set(\u0026#39;Access-Control-Allow-Methods\u0026#39;, \u0026#39;GET, HEAD, OPTIONS, POST\u0026#39;) res.set(\u0026#39;Access-Control-Allow-Headers\u0026#39;, \u0026#39;Content-Type, Authorization\u0026#39;) // データバンドルを返す res.end(bundleBuffer) }) ポイントは、CDN とクライアントアプリにデータバンドルをキャッシュさせるために Cache-Control レスポンスヘッダを付加するところでしょうか（参考: Manage cache behavior | Firebase）。 response.set(\u0026#39;Cache-Control\u0026#39;, \u0026#39;public, max-age=300, s-maxage=600\u0026#39;) Cache-Control の各値は次のような意味を持っています。 public \u0026hellip; CDN (Firebase Hosting) でもデータバンドルをキャッシュさせます。これを指定しなかった場合のデフォルト値は private で、クライアントアプリ（ブラウザ）のみがデータバンドルをキャッシュ可能になります。 max-age=300 \u0026hellip; キャッシュ有効時間（秒）を指示します。クライアントアプリ、および CDN がこの指示に従います。 s-maxage=600 \u0026hellip; CDN のキャッシュの有効時間（秒）を別途指示します。これを省略した場合は、CDN のキャッシュ有効時間にも max-age が使用されます。 つまり、クライアントアプリでデータバンドルを 300 秒間キャッシュに保持、CDN で 600 秒間キャッシュに保持することになります。 ☝️ なぜ us-central1 を使う？ ホスティング動作を構成する | Firebase Documentation のドキュメントで、CDN (Firebase Hosting) をプロキシさせて Cloud Functions を呼び出す場合は、us-central1 のみサポートされているとの記載があります（2022-06 現在）。 重要: Firebase Hosting は、us-central1 でのみ Cloud Functions をサポートします。 たしかに、asia-northeast1 に Cloud Functions 関数をデプロイしてしまうと、CDN との連携がうまくいかない（問答無用で us-central1 の Cloud Functions に転送されてしまう）ので、今はあきらめて us-central1 にデプロイしておくしかなさそうです。 Google さん、対応してね！ CDN (Firebase Hosting) でデータバンドルをキャッシュする Firestore のデータバンドルをキャッシュするための CDN (Firebase Hosting) は簡単に作成することができます。 firebase init functions コマンドなどで Firebase プロジェクトを作成 している場合、プロジェクトのルートディレクトリに firebase.json ファイルが生成されているはずです。 このファイルに次のように追記することで、Cloud Functions へのプロキシとなる CDN を配置できます。 firebase.json { \u0026#34;hosting\u0026#34;: { \u0026#34;rewrites\u0026#34;: [{ \u0026#34;source\u0026#34;: \u0026#34;/createBundle\u0026#34;, \u0026#34;function\u0026#34;: \u0026#34;createBundle\u0026#34; }], \u0026#34;headers\u0026#34;: [ { \u0026#34;source\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;headers\u0026#34;: [{ \u0026#34;key\u0026#34;: \u0026#34;Access-Control-Allow-Origin\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;*\u0026#34; }] } ] }, // ... } 設定内容はシンプルで、/createBundle という URL へのアクセスを、Cloud Functions の createBundle 関数の呼び出しに接続しています。 さらに、別ドメインに配置した Web アプリから CDN へのアクセスを許可するために、CORS 用のレスポンスヘッダ定義を追加しておく必要があります。 参考: Configure hosting behavior | Firebase。 Cloud Functions 関数の実装と、CDN の設定が済んだら、プロジェクトルートで下記コマンドを実行してデプロイします。 $ firebase deploy デプロイに成功すると、Cloud Functions と CDN の次のようなエンドポイントが有効になります。 Cloud Functions: https://us-central1-myapp-12345.cloudfunctions.net/createBundle CDN (Firestore Hosting): https://myapp-12345.web.app/createBundle どちらも同じデータバンドルを返しますが、CDN の方はキャッシュ生成後は一瞬でデータを返してくれるはずです。 クライアントアプリからデータバンドルを取得する 最後に、CDN から Firestore データバンドルを取得するクライアントアプリ側の実装です。 Firebase SDK の基本的な扱い方は省略します（参考: Next.js で Firebase: Cloud Firestore データベースを使う）。 utils/firebase/firestore.ts（抜粋） import { getDocsFromCache, getFirestore, loadBundle, namedQuery } from \u0026#39;firebase/firestore\u0026#39; import { Book } from \u0026#39;@/utils/types\u0026#39; const QUERY_NAME = \u0026#39;latest-books-query\u0026#39; export async function getLatestBooksFromBundle(): Promise\u0026lt;Book[]\u0026gt; { console.log(\u0026#39;Get latest books from Bundle...\u0026#39;) const db = getFirestore() // CDN からデータバンドルを取得 const bundle = await fetch(\u0026#39;https://myapp-12345.web.app/createBundle\u0026#39;) if (bundle.body == null) { console.warn(\u0026#39;Bundle has no data\u0026#39;) return [] } // フェッチしたバンドルから SDK 内にクライアントキャッシュを生成 await loadBundle(db, bundle.body) // クライアントキャッシュから名前付きクエリの Query オブジェクトを生成 const query = await namedQuery(db, QUERY_NAME) if (query == null) { console.warn(`Bundle does not have namedQuery: ${QUERY_NAME}`) return [] } // 名前付きクエリからデータを取り出す（必要に応じてコンバーターを適用するのはいつも通り） const booksQuery = query.withConverter(bookConverter) const snapshot = await getDocsFromCache(booksQuery) return snapshot.docs.map((doc) =\u0026gt; doc.data()) } 例えば、React のカスタムフックなどから上記の関数を呼び出すことで、データバンドルをもとに生成された Book 配列を取得できます。 CDN のキャッシュデータだけを参照するので、直接 Firestore にアクセスするも高速に動作し、かつ安価に運用できます。 もちろん、データ取得の柔軟性は減りますし、キャッシュ期間中は最新データを取得できないといった制約がありますが、多数のユーザーがアクセスするトップページの情報などは、この仕組みを導入する価値がありそうです。"
},
{
url: "/p/fvevcs8/",
title: "Firebase の Cloud Functions で Hello World",
date: "2022-06-04T00:00:00Z",
body: "Firebase の Cloud Functions で Hello World 何をするか？ Cloud Functions に関数をデプロイすると、Google Cloud Platform 上でサーバーレス関数として実行できるようになります（Amazon の AWS Lambda や、Microsoft の Azure Functions に相当するものです）。 この関数は、次のように、様々なイベントをトリガーにして呼び出されます。 HTTP でのアクセス スケジュールされたタイミング Firestore データベースの更新時 ここでは、HTTP によるアクセス時に Hello from Firebase! というレスポンスを返すだけの関数を Cloud Functions に追加してみます。 また、Firebase にデプロイする前に、エミュレーターでのローカルテストを行います。 ☝️ Firebase なのか GCP なのか Cloud Functions は Firebase プロジェクトからも使用できますが、実体は GCP で提供されているサービスです。 このようなサービスは他にもあり、Firebase のサービスのうち、頭に Cloud と付いてるものは実際には GCP が提供しています（例:「Cloud Firestore」「Cloud Functions」「Cloud Storage」）。 事前準備 最初に Firebase プロジェクトを作成し、Firebase CLI をインストールしておきます。 既存の Firebase プロジェクトに Cloud Functions を追加する場合は、プロジェクトの作成は必要ありません。 Firebase のアカウントを作成します Firebase コンソール から新規プロジェクトを作成します firebase コマンドでもプロジェクトを作成できますが、上記サイトから作成してしまった方が楽です（名前の重複チェックなどをしてくれます） Firebase CLI をインストール して、firebase コマンドを実行できるようにします Firebase CLI をインストールしたら、次のように Firebase アカウントでサインインしておきます。 $ firebase login Firebase プロジェクト用のディレクトリを作成する (firebase init) 任意のディレクトリ内で firebase init コマンドを実行すると、firebase.json ファイル（および .firebaserc）が作成されて、Firebase プロジェクト用のディレクトリと認識されるようになります。 すでに GitHub などで管理しているプロジェクトディレクトリに対しても実行することができます。 例えば、次のようにして、Cloud Functions for Firebase のテンプレートコード を作成することができます。 Functions のテンプレートを生成する $ mkdir myapp （このディレクトリを Git 管理する想定） $ cd myapp $ firebase init functions firebase init を実行すると、対話形式で「どのプロジェクトを対象とするか？」「JavaScript と TypeScript のどちらを使用するか？」などを聞かれるので、順番に答えていくと、次のようなファイルおよびディレクトリが生成されます（選択によって微妙に変わってきます）。 myapp/ +-- .firebaserc （デプロイ対象とするプロジェクトの情報） +-- .gitignore （Git 管理外にするファイルの情報） +-- firebase.json （Firebase へのデプロイ情報など） +-- functions/ +-- .eslintrc.js （ESLint の設定） +-- package.json （Functions 用のプロジェクト設定） +-- src/ （Functions のテンプレートコード） +-- tsconfig.json （TypeScript を選択した場合はその設定ファイル） エミュレーターで Functions の動作を確認してみる 簡単な Hello World 関数を実装して、エミュレーターで動作確認してみます。 functions ディレクトリを Visual Studio Code などで開いて、src/index.ts ファイルを次のように修正してください。 functions/src/index.ts import * as functions from \u0026#34;firebase-functions\u0026#34;; export const helloWorld = functions .region(\u0026#34;asia-northeast1\u0026#34;) .https.onRequest((request, response) =\u0026gt; { functions.logger.info(\u0026#34;Hello logs!\u0026#34;, { structuredData: true }); response.send(\u0026#34;Hello from Firebase!\u0026#34;); }); リージョンの指定方法は若干わかりにくいので要注意です。 上記では asia-northeast1 を指定していますが、省略すると us-central1 にデプロイされます。 上記のように helloWorld という名前のオブジェクトを export することで、Cloud Functions に helloWorld 関数を登録することになります。 Firebase にデプロイする前にエミュレーターで動作確認をしておきます。 次のようにして、エミュレーターを起動してください。 関数コードのビルドも自動的に行われます。 $ cd functions $ npm run serve ... ✔ functions[asia-northeast1-helloWorld]: http function initialized (http://localhost:5001/myapp1-12345/asia-northeast1/helloWorld). ... 無事エミュレーターが起動すると、上記のような感じで、関数を呼び出すための URL が表示されるので、Web ブラウザで開くか curl コマンドでアクセスします。 次のように Hello レスポンスが返って来れば成功です。 $ curl http://localhost:5001/myapp1-12345/us-central1/helloWorld Hello from Firebase! Firebase にデプロイしてみる エミュレーターでの動作確認が済んだら、Firebase にデプロイしてみます。 firebase deploy コマンドを実行すると、firebase.json の情報に基づいてデプロイが実行されます（--only functions オプションで、Functions のみをデプロイ対象とすることもできます）。 $ firebase deploy === Deploying to \u0026#39;myapp1-12345\u0026#39;... : i functions: creating Node.js 16 function helloWorld(us-central1)... ✔ functions[helloWorld(us-central1)] Successful create operation. Function URL (helloWorld(us-central1)): https://us-central1-myapp1-12345.cloudfunctions.net/helloWorld : ✔ Deploy complete! デプロイが成功すると、上記のようにアクセス用の URL が表示されるので、Web ブラウザや curl コマンドで動作確認することができます。 ちなみに、URL は次のような構成になっています。 https://\u0026lt;LocationID\u0026gt;-\u0026lt;ProjectID\u0026gt;.cloudfunctions.net/\u0026lt;FunctionName\u0026gt; デプロイした関数を削除する Cloud Functions にデプロイした関数が必要なくなったら、次のようにして削除します。 $ firebase functions:delete helloWorld"
},
{
url: "/p/ij4jv9k/",
title: "Go 言語で gRPC 通信してみる（Echo サーバー＆クライアント）",
date: "2022-05-18T00:00:00Z",
body: "Go 言語で gRPC 通信してみる（Echo サーバー＆クライアント） 何をするか？ ここでは、Go 言語用の gRPC ライブラリである gRPC-Go (google.golang.org/grpc) を使って、簡単な gRPC サーバーとクライアントを作ってみます。 通信用のスタブコードなどは、protoc コマンド (Protocl Buffers Compiler) で .proto ファイルから自動生成するので、あらかじめ protoc コマンドをインストールしておいてください。 参考: protoc コマンドで .proto ファイルをコンパイルする (Protocol Buffers Compiler) protoc コマンドで Go 言語用のコードを生成するには、protoc-gen-go プラグインと protoc-gen-go-grpc プラグインをインストールしておく必要があります。 前者がシリアライズ用のコード、後者が gRPC 用のスタブコードを生成するための protoc プラグインです。 # バージョンを指定してインストールする方法（推奨） $ go install google.golang.org/protobuf/cmd/protoc-gen-go@v1.28 $ go install google.golang.org/grpc/cmd/protoc-gen-go-grpc@v1.2 # 最新バージョンをインストールする方法 $ go install google.golang.org/protobuf/cmd/protoc-gen-go@latest $ go install google.golang.org/grpc/cmd/protoc-gen-go-grpc@latest プロジェクトの作成と gRPC-Go のインストール まずは Go 言語用のプロジェクトを作成します。 モジュール名は com.example/grpc-sample としていますが、GitHub で管理する予定であれば、リポジトリ名に合わせて github.com/\u0026lt;USER\u0026gt;/grpc-sample のような名前にしてください。 これが、プロジェクト内で作成する Go パッケージをインポートするときのプレフィックスになります。 $ mkdir grpc-sample \u0026amp;\u0026amp; cd grpc-sample $ go mod init com.example/grpc-sample あとは、gRPC サーバーとクライアントの実装に使用する gRPC-Go パッケージの依存関係を追加しておきます。 $ go get google.golang.org/grpc .proto ファイルを作成する echo/echo.proto ファイルを作成して、次のように記述します。 Go 言語用のオプション option go_package で、出力する .go ファイルを echo パッケージに配置するように指定しています。 echo/echo.proto syntax = \u0026#34;proto3\u0026#34;;package echo;option go_package = \u0026#34;example.com/grpc-sample/echo\u0026#34;;// Echo メソッドを持つ EchoService の定義 service EchoService { rpc Echo (EchoRequest) returns (EchoResponse);}// Echo に送るリクエストメッセージの定義 message EchoRequest { string message = 1;}// Echo が返すレスポンスメッセージの定義 message EchoResponse { string message = 1;} ここでは、EchoService というサービスが、Echo というメソッドを提供するよう定義しています。 .proto ファイルをコンパイルする protoc コマンドを実行して、.proto ファイルからシリアライズ用のコードと、gRPC 関連のスタブコードを生成します。 $ protoc --go_out=. --go_opt=paths=source_relative \\ --go-grpc_out=. --go-grpc_opt=paths=source_relative \\ echo/echo.proto それぞれのオプションは次のような意味があります。 --go_out \u0026hellip; protoc-gen-go プラグインによる生成コードの出力先ディレクトリ --go_opt \u0026hellip; protoc-gen-go プラグインに渡すオプション --go-grpc_out \u0026hellip; protoc-gen-go-grpc プラグインによる生成コードの出力先ディレクトリ --go-grpc_opt \u0026hellip; protoc-gen-go-grpc プラグインに渡すオプション --go_out オプションを指定することでシリアライズ用のコード (echo.pb.go)、--go-grpc_out オプションを指定することで gRPC 用のスタブコード (echo_grpc.pb.go) を生成してくれます。 追加のオプションで、paths=source_relative を指定することにより、入力ファイル (.proto) と同じディレクトリ構成で .go ファイルを出力するようにしています。 今回はカレントディレクトリ (.) を出力のルートに指定しているので、結果的に入力ファイルと同じディレクトリに次のように .go ファイルが生成されることになります。 入力ファイル 使う protoc プラグイン 生成されるファイル echo/echo.proto protoc-gen-go echo/echo.pb.go echo/echo.proto protoc-gen-go-grpc echo/echo_grpc.pb.go 生成された echo.pb.go ファイルや echo_grpc.pb.go ファイルを覗いてみると、次のようなパッケージ名で定義されていることがわかります。 echo/echo.pb.go（抜粋） package echo このパッケージ名は、.proto ファイル内の options go_package で指定したパスに従って自動生成されています（パスの最後の /echo という部分が採用されています）。 また、今回はモジュール名を example.com/grpc-sample と定義したので（go.mod ファイルに書かれているので）、自動生成されたこれらのパッケージをインポートするときは、次のような感じで記述することになります。 import \u0026#34;example.com/grpc-sample/echo\u0026#34; gRPC サーバーとクライアントの実装 gRPC を使って通信するサーバーとクライアントは、それぞれ独立したコマンドとして cmd/echo-server ディレクトリ、cmd/echo-client ディレクトリ以下に作成することにします（それぞれ main 関数を作成します）。 Go 言語のプロジェクトで生成する実行ファイルのコードを cmd ディレクトリ以下に配置するのはよくあるプラクティスです。 gRPC サーバーの実装 まずは、EchoService を実装します。 protoc によって自動生成された echo/echo_grpc.pb.go の関数シグネチャを参考に、次のような感じで Echo メソッドを実装します。 クライアントから受信したテキストの先頭に * を付加したレスポンスを返しているだけなので実装は簡単です。 cmd/echo-server/server.go package main import ( \u0026#34;context\u0026#34; \u0026#34;log\u0026#34; \u0026#34;example.com/grpc-sample/echo\u0026#34; ) // EchoService を実装するサーバーの構造体 type server struct{ echo.UnimplementedEchoServiceServer } // EchoService の Echo メソッドの実装 func (s *server) Echo(ctx context.Context, in *echo.EchoRequest) (*echo.EchoResponse, error) { log.Printf(\u0026#34;Received from client: %v\u0026#34;, in.GetMessage()) return \u0026amp;echo.EchoResponse{Message: \u0026#34;*\u0026#34; + in.GetMessage()}, nil } あとは、main 関数で gRPC サーバーのインスタンスを生成して、上記の実装を登録すれば OK です。 cmd/echo-server/main.go package main import ( \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net\u0026#34; \u0026#34;google.golang.org/grpc\u0026#34; \u0026#34;example.com/grpc-sample/echo\u0026#34; ) const port = 52000 func main() { // TCP ポートをオープンできるか確認 \tlis, err := net.Listen(\u0026#34;tcp\u0026#34;, fmt.Sprintf(\u0026#34;:%d\u0026#34;, port)) if err != nil { log.Fatalf(\u0026#34;Failed to listen: %v\u0026#34;, err) } // gRPC サーバーを生成し、EchoService サーバーの実装を登録する \ts := grpc.NewServer() echo.RegisterEchoServiceServer(s, \u0026amp;server{}) // gRPC サーバーを稼働開始 \tlog.Printf(\u0026#34;Server listening at %v\u0026#34;, lis.Addr()) if err := s.Serve(lis); err != nil { log.Fatalf(\u0026#34;Failed to serve: %v\u0026#34;, err) } } gRPC クライアントの実装 gRPC サーバー側が実装できたら、次はクライアント側の実装です。 下記の gRPC クライアントでは、Echo メソッドを呼び出して AAAAA というメッセージを送り、その応答を単純に出力しています。 cmd/echo-client/main.go package main import ( \u0026#34;context\u0026#34; \u0026#34;log\u0026#34; \u0026#34;time\u0026#34; \u0026#34;google.golang.org/grpc\u0026#34; \u0026#34;google.golang.org/grpc/credentials/insecure\u0026#34; \u0026#34;example.com/grpc-sample/echo\u0026#34; ) const addr = \u0026#34;localhost:52000\u0026#34; func main() { // EchoService サーバーへ接続する \tconn, err := grpc.Dial(addr, grpc.WithTransportCredentials(insecure.NewCredentials())) if err != nil { log.Fatalf(\u0026#34;Did not connect: %v\u0026#34;, err) } defer conn.Close() c := echo.NewEchoServiceClient(conn) // Echo メソッドを呼び出す \tctx, cancel := context.WithTimeout(context.Background(), time.Second) defer cancel() r, err := c.Echo(ctx, \u0026amp;echo.EchoRequest{Message: \u0026#34;AAAAA\u0026#34;}) if err != nil { log.Fatalf(\u0026#34;Could not echo: %v\u0026#34;, err) } log.Printf(\u0026#34;Received from server: %s\u0026#34;, r.GetMessage()) } 実行してみる まず、gRPC のサーバー側を起動します。 $ go run ./cmd/echo-server 2022/05/17 22:00:47 Server listening at [::]:52000 次に、gRPC のクライアント側を起動すると、サーバーと通信してメッセージを受信できていることを確認できます。 $ go run ./cmd/echo-client 2022/05/17 22:01:32 Received from server: *AAAAA やったー！"
},
{
url: "/p/88gow5c/",
title: "gRPC 関連メモ",
date: "2022-05-18T00:00:00Z",
body: "gRPC 関連メモ"
},
{
url: "/p/saku4ck/",
title: "Next.js 関連記事",
date: "2022-05-09T00:00:00Z",
body: "Next.js 関連記事"
},
{
url: "/p/3vbr2bm/",
title: "Next.js でローカル開発時 (next dev) のみ有効なデバッグページを作成する (getStaticProps)",
date: "2022-05-09T00:00:00Z",
body: "Next.js でローカル開発時 (next dev) のみ有効なデバッグページを作成する (getStaticProps) 何をするか？ Next.js アプリを作っていると、開発中にだけ表示したいデバッグ用のページを作りたくなることがよくあります。 ここでは、ローカルサーバー (next dev) での開発中のみ有効になるデバッグページの作り方を説明します。 デバッグページの作成 Next.js の各ページのビルド時には、必要に応じてデータフェッチなどを行うための getStaticProps 関数が呼び出されます（参考: Next.js のプリレンダリング機能を使用する (getStaticProps)）。 この関数の戻り値として、notFound プロパティ を true にしたオブジェクトを返すと、そのページがないものとして扱うことができます（404 Not Found になる）。 export const getStaticProps: GetStaticProps = () =\u0026gt; { // ... return { // Return the default 404 page with a status code of 404. notFound: true } } この仕組みを利用して次のように実装すれば、ローカルサーバーでの開発中のみ表示可能なデバッグページを作ることができます。 ローカルサーバー (next dev) で実行されているかどうかは、環境変数 process.env.NODE_ENV の値で判断できます（参考: Next.js で環境変数を扱う (.env, NEXT_PUBLIC, NODE_ENV)）。 pages/debug/info.tsx import { GetStaticProps, NextPage } from \u0026#39;next\u0026#39; type EmptyProps = { [key: string]: never } /** * ページビルド時の前処理。 * 開発サーバー (next dev) での実行時のみこのページが存在するようにします。 */ export const getStaticProps: GetStaticProps\u0026lt;EmptyProps\u0026gt; = () =\u0026gt; { const isLocalDev = process.env.NODE_ENV !== \u0026#39;production\u0026#39; return { notFound: !isLocalDev, props: {} } } const DebugInfoPage: NextPage = () =\u0026gt; { // ... return ( \u0026lt;\u0026gt; \u0026lt;h1\u0026gt;Debug page\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;This page is displayed only during development.\u0026lt;/p\u0026gt; \u0026lt;/\u0026gt; ) } export default DebugInfoPage"
},
{
url: "/p/d7p5jye/",
title: "React 関連記事",
date: "2022-05-09T00:00:00Z",
body: "React 関連記事"
},
{
url: "/p/ufpqqno/",
title: "HTTP/1.1 の認証スキームに関するメモ",
date: "2022-05-01T00:00:00Z",
body: "HTTP/1.1 の認証スキームに関するメモ 認証スキーム とは、HTTP のリクエストヘッダに指定する Authentication ヘッダーの先頭部分に指定する文字列のこと。 Basic \u0026hellip; RFC2617 Web ブラウザが標準でサポートしている。 Bearer \u0026hellip; RFC6750 OAuth 2.0 で使われている認証スキームのひとつ。 署名を行う必要はなく、受け取った値をそのまま使える。 Digest \u0026hellip; RFC2617 Web ブラウザが標準でサポートしている。 Negotiate \u0026hellip; RFC4559 OAuth \u0026hellip; RFC5849 OAuth 1.0 で使われていた認証スキーム。 署名のルールが複雑すぎて廃れた。 参考リンク RFC7235 - Hypertext Transfer Protocol (HTTP/1.1): Authentication RFC7236 - Initial Hypertext Transfer Protocol (HTTP): Authentication Scheme Registrations"
},
{
url: "/p/s7q8o5k/",
title: "ウェブサイトのリンク切れを自動でチェックする (muffet)",
date: "2022-04-23T00:00:00Z",
body: "ウェブサイトのリンク切れを自動でチェックする (muffet) muffet のインストール muffet はウェブサイトのリンク切れをチェックしてくれるコマンドラインツールです。 Go 言語で実装されており、いろいろな OS (Linux、macOS、Windows) で利用することができます。 raviqqe/muffet: Fast website link checker in Go インストール方法は、上記サイトに記述されていますが、例えば macOS であれば、homebrew を使って次のように簡単にインストールできます。 macOS の場合 % brew install muffet 各 OS 用の実行バイナリが欲しければ、Release ページ からダウンロードできます。 muffet の使い方 基本的な使い方は、次のように調べたいウェブページのアドレスを入力するだけです。 % muffet http://localhost:51000 リンク元のサイトアドレスと、アクセスできなかったサイトアドレスの組み合わせが一覧表示されます。 http://localhost:51000/p/eu7djpv/ 404\thttp://localhost:51000/assets/favicon/180x180.png 404\thttp://localhost:51000/assets/favicon/192x192.png http://localhost:51000/p/ckahx6k/ 404\thttp://localhost:51000/assets/favicon/180x180.png 404\thttp://localhost:51000/assets/favicon/192x192.png 404\thttp://video.google.com/videoplay?docid=973149761529535925 404 (following redirect https://www.example.com/p/44327.html) http://www.example.com/44327/2005/04/tipsinbox.html muffet は複数スレッドで高速にリンクチェックを行いますが、ひとつのドメインに対する同時接続数を制限したいときは、--max-connections-per-host オプションを指定します。 Web サーバーへの負荷を考慮したいときに使えます。 同時接続数を制限する % muffet --max-connections-per-host=5 http://localhost:51000 --exclude オプションを使うと、チェック対象外とするアドレスを正規表現で指定できます。 例えば、次のようにすれば、https:// で始まるリンクをチェック対象外にできます。 ローカル Web サーバーで開発している場合、このオプション指定によって外部サイトのリンクだけをチェック対象外にできます。 外部リンクを対象外にする % muffet --exclude=\u0026#34;https://.*\u0026#34; http://localhost:51000 その他のオプションは、muffet --help で確認できます。 muffet のヘルプ (v2.4.9) % muffet --help Usage: muffet [options] \u0026lt;url\u0026gt; Application Options: -b, --buffer-size=\u0026lt;size\u0026gt; HTTP response buffer size in bytes (default: 4096) -c, --max-connections=\u0026lt;count\u0026gt; Maximum number of HTTP connections (default: 512) --max-connections-per-host=\u0026lt;count\u0026gt; Maximum number of HTTP connections per host (default: 512) -e, --exclude=\u0026lt;pattern\u0026gt;... Exclude URLs matched with given regular expressions --follow-robots-txt Follow robots.txt when scraping pages --follow-sitemap-xml Scrape only pages listed in sitemap.xml --header=\u0026lt;header\u0026gt;... Custom headers -f, --ignore-fragments Ignore URL fragments --json Output results in JSON -r, --max-redirections=\u0026lt;count\u0026gt; Maximum number of redirections (default: 64) --rate-limit=\u0026lt;rate\u0026gt; Max requests per second -t, --timeout=\u0026lt;seconds\u0026gt; Timeout for HTTP requests in seconds (default: 10) -v, --verbose Show successful results too --proxy=\u0026lt;host\u0026gt; HTTP proxy host --skip-tls-verification Skip TLS certificate verification --one-page-only Only check links found in the given URL --color=[auto|always|never] Color output (default: auto) -h, --help Show this help --version Show version 現状そこまで凝ったことはできないようですね。 オプションの使い方もよくわからない点が多いので、公式サイトのドキュメントが拡充されることを期待します。"
},
{
url: "/p/zb9ocav/",
title: "ツール",
date: "2022-04-23T00:00:00Z",
body: "ツール"
},
{
url: "/p/37e6uck/",
title: "protoc コマンドで .proto ファイルをコンパイルする (Protocol Buffers Compiler)",
date: "2022-04-20T00:00:00Z",
body: "protoc コマンドで .proto ファイルをコンパイルする (Protocol Buffers Compiler) Protcol Buffers とは プロトコルバッファー (Protocol Buffers、protobuf) は、Google が開発した、構造化したデータをシリアライズするためのフォーマットです。 同じく Google が開発した gRPC 通信プラットフォームで採用されており、XML や JSON などのテキストベースの API より効率的な通信を行うことができるという特徴を持っています。 データをコンパクトに表現できるため、通信やパース処理が高速 強い型付けを行うことでき、サーバー、クライアントの安全なコーディングが可能 定義変更時の互換性を考慮したフォーマット OS やプログラミング言語などに非依存 データ構造やサービス形式の定義は、.proto 拡張子を持つ プロトコル定義ファイル (Proto Definition file) で行います。 この .proto ファイルを protoc コマンド（プロトコルバッファーコンパイラ）でコンパイルすると、各言語用のソースコードを生成することができます。 hello.proto ──[protoc]──\u0026gt; hello_pb.rb protoc コマンドは各種プログラミング言語用のコードを生成するわけですが、そのためには、protoc コマンド本体 と 各言語用のプラグイン（protoc-gen-go など）がインストールされている必要があります。 C++ や C#、Kotlin、Python、Ruby などのコード生成は組み込みで対応していますが、Go 言語用のプラグインなどは別途インストールする必要があります。 protoc 本体のインストール protoc コマンド (Protocol Buffers Compiler) は、Linux（Ubuntu 系）や macOS ではパッケージマネージャーを使ってインストールしてしまうのが簡単です。 インストールするパッケージの名前は protobuf や protobuf-compiler であることに注意してください。 macOS (Homebrew) の場合 $ brew install protobuf # インストール $ brew upgrade protobuf # バージョン更新 Linux (apt) の場合 $ apt install -y protobuf-compiler プリビルド版を使う場合 あるいは、各 OS 用のバイナリを GitHub のリリースページ からダウンロードし、protoc コマンドにパスを通します。 例えば、Windows であれば protoc-3.20.0-win64.zip などをダウンロードします。 次のように protoc コマンドを実行できるようになれば OK です。 $ protoc --version libprotoc 3.20.0 参考: Protocol Buffer Compiler Installation | gRPC .proto ファイルをコンパイルしてみる .proto ファイル 次のような簡単な .proto ファイルを入力ファイルとして用意します。 protos/person.proto syntax = \u0026#34;proto3\u0026#34;;message Person { optional string name = 1; optional int32 id = 2; optional string email = 3;} C# のコードを生成 例えば、次のように実行すると、C# 用のソースコードを生成することができます。 --csharp_out=\u0026lt;OUT_DIR\u0026gt; というオプションで、C# ソースコードの出力先ディレクトリを指定しています。 $ mkdir gen $ protoc --csharp_out=gen protos/person.proto $ ls gen Person.cs Python のコードを生成 Python 用のソースコードを生成したければ、同様に次のようにします。 出力ディレクトリは --python_out=\u0026lt;OUT_DIR\u0026gt; オプションで指定します。 $ protoc --python_out=gen protos/person.proto その他の言語のコードを生成 他にも各言語用のソースコードを生成するオプションが用意されており、次のようにヘルプ表示すると標準でサポートしている言語を確認できます。 protoc の言語別出力オプション $ protoc --help | grep OUT_DIR --cpp_out=OUT_DIR Generate C++ header and source. --csharp_out=OUT_DIR Generate C# source file. --java_out=OUT_DIR Generate Java source file. --js_out=OUT_DIR Generate JavaScript source. --kotlin_out=OUT_DIR Generate Kotlin file. --objc_out=OUT_DIR Generate Objective-C header and source. --php_out=OUT_DIR Generate PHP source file. --python_out=OUT_DIR Generate Python source file. --ruby_out=OUT_DIR Generate Ruby source file. 言語拡張用のプラグイン (protoc-gen-xxx) protoc が標準でサポートしてない言語のコードを生成するには、追加のプラグイン（実際はただのコマンド）をインストールする必要があります。 追加でインストールするコマンドは protoc-gen-\u0026lt;言語名\u0026gt; という名前であり、そのコマンドがシステムに存在していると、protoc コマンドの --\u0026lt;言語名\u0026gt;_out というオプションが有効になります。 Go 言語用プラグイン (protoc-gen-go) 例えば、Go 言語用のプラグインである protoc-gen-go をインストールすると、--go_out オプションが使えるようになります。 protoc-gen-go のインストール # バージョン指定でインストールする場合（推奨） $ go install google.golang.org/protobuf/cmd/protoc-gen-go@v1.28.0 # 最新版をインストールする場合 $ go install google.golang.org/protobuf/cmd/protoc-gen-go@latest # 確認 $ protoc-gen-go --version protoc-gen-go v1.28.0 Go 言語用のコードを出力する場合は、.proto ファイル内の option go_package でパッケージ名を設定しておく必要があります。 protos/person.proto syntax = \u0026#34;proto3\u0026#34;;option go_package = \u0026#34;example.com/myapp\u0026#34;;message Person { optional string name = 1; optional int32 id = 2; optional string email = 3;} 次のようにすると、gen ディレクトリ以下に Go コードが生成されます。 $ protoc --go_out=gen protos/person.proto .proto ファイルで指定したパッケージ名に従ってディレクトリ階層ができます。 gen/example.com/myapp/person.pb.go .proto ファイル内でパッケージ名を指定するのではなく、protoc コマンドの --go_opt=M... オプションで次のように指定することもできます。 $ protoc --go_out=gen \\ --go_opt=Mprotos/person.proto=example.com/myapp \\ protos/person.proto = が 2 回出てくるのでちょっと分かりにくいですが、protos/person.proto ファイルのパッケージ名を example.com/myapp に設定しています。"
},
{
url: "/p/7s7hs4e/",
title: "AWS 関連メモ",
date: "2022-04-18T00:00:00Z",
body: "AWS 関連メモ"
},
{
url: "/p/vujw9jv/",
title: "AWS CDK で API Gateway に Cognito 認証によるアクセス制御を追加する",
date: "2022-04-18T00:00:00Z",
body: "AWS CDK で API Gateway に Cognito 認証によるアクセス制御を追加する 何をするか？ ここでは、API Gateway で提供している REST API にアクセス制御を追加するため、既存の Cognito ユーザープールによるオーソライザーを API Gateway に設定してみます。 これにより、Cognito のユーザープールで認証済みのユーザーのみが REST API を呼び出せるようになります。 後述の CDK コードでは、API Gateway と Lambda 関数、オーソライザーを生成していますが、Cognito ユーザープールは既存のものを参照しています（こういったユースケースは多いと思います）。 なお、CDK による API Gateway の作成方法（Lambda プロキシ統合）については下記の記事を参考にしてください。 ここでは、Cognito ユーザープールによるオーソライザーの作成方法にフォーカスします。 AWS CDK で API Gateway の REST API を作成する Lambda 関数を作成する REST API のバックエンドである Lambda 関数は最低限の実装で用意します。 ユーザー認証後に、API Gateway 経由で正しくこのハンドラを呼び出せるかの確認用です。 lambda/info.ts import { APIGatewayProxyHandler } from \u0026#34;aws-lambda\u0026#34; /** GET /info */ export const handler: APIGatewayProxyHandler = async (event) =\u0026gt; { console.log(\u0026#34;headers: \u0026#34; + JSON.stringify(event.headers, undefined, 2)) return { statusCode: 200, body: JSON.stringify({ message: \u0026#34;Hello, API Gateway!\u0026#34; }), headers: { \u0026#34;Access-Control-Allow-Origin\u0026#34;: \u0026#34;*\u0026#34;, }, } } Cognito ユーザープールによるオーソライザーの追加 下記は、cdk init app で作成した CDK アプリのスタック生成コードに手を入れたものです。 lib/myapi-sample-stack.ts import { Stack, StackProps, aws_apigateway as apigateway, aws_cognito as cognito, aws_lambda_nodejs as lambda, } from \u0026#34;aws-cdk-lib\u0026#34; import { Construct } from \u0026#34;constructs\u0026#34; // 既存の Cognito ユーザープール const USER_POOL_ID = \u0026#34;ap-northeast-1_xxxxxxxxx\u0026#34; // const USER_POOL_ARN = // \u0026#34;arn:aws:cognito-idp:ap-northeast-1:123456789012:userpool/ap-northeast-1_xxxxxxxxx\u0026#34; export class MyapiSampleStack extends Stack { constructor(scope: Construct, id: string, props?: StackProps) { super(scope, id, props) // Lambda 関数（GET /info 用） const getInfoHandler = new lambda.NodejsFunction(this, \u0026#34;GetInfoHandler\u0026#34;, { entry: \u0026#34;lambda/info.ts\u0026#34;, handler: \u0026#34;handler\u0026#34;, }) // 既存のユーザープールを参照する（fromUserPoolId か fromUserPoolArn を使う） const userPool = cognito.UserPool.fromUserPoolId( this, \u0026#34;MyUserPool\u0026#34;, USER_POOL_ID ) // ユーザープールを使うオーソライザーを作成 const authorizer = new apigateway.CognitoUserPoolsAuthorizer( this, \u0026#34;MyAuthorizor\u0026#34;, { cognitoUserPools: [userPool] } ) // API Gateway (REST API) を作成して Lambda プロキシ統合 const api = new apigateway.RestApi(this, \u0026#34;MyApi\u0026#34;, { // デフォルトで Cognito 認証を必須とする defaultMethodOptions: { authorizer }, // プリフライトリクエスト時の CORS アクセスを許可 defaultCorsPreflightOptions: { allowOrigins: apigateway.Cors.ALL_ORIGINS, allowMethods: apigateway.Cors.ALL_METHODS, allowHeaders: apigateway.Cors.DEFAULT_HEADERS, statusCode: 200, }, }) const books = api.root.addResource(\u0026#34;info\u0026#34;) books.addMethod(\u0026#34;GET\u0026#34;, new apigateway.LambdaIntegration(getInfoHandler)) } } ポイントは、UserPool.fromUserPoolId() で既存の Cognito ユーザープールを参照し、それを使って CognitoUserPoolsAuthorizer オブジェクトを生成する部分です。 作成したオーソライザーは、RestApi インスタンス生成時に defaultMethodOptions で設定することができます。 リソース（URL パス）ごとにアクセス制限をかけたいときは、各リソースの addMethod 時にオーソライザーを設定すれば OK です。 これで、REST API へのアクセス時に、Cognito 認証によるアクセス制限がかかるようになります。 defaultCorsPreflightOptions の設定はちょっと事情が複雑ですが、Web ブラウザ上の JavaScript から認証付き API の呼び出しを行う際に必要になります。 クライアントサイド JS から API を呼び出すときに HTTP リクエストヘッダーに Authorization 情報を付加することになるのですが、この場合は GET 要求の前にプリフライトリクエストという OPTIONS 要求を行うことが HTTP の仕様で決められています。 このプリフライトリクエストはブラウザが自動的に行ってくれるのですが、このリクエストにもクロスドメインでのアクセスを許可しておかないといけません。 この設定を行わないと、CORS エラーが発生して API 呼び出しが失敗します。 デプロイ Lambda 関数とスタック定義の実装が済んだら、CDK でデプロイします。 $ cdk deploy 最後の方に、次のようにエンドポイント URL が表示されるのでコピーしておきます。 Outputs: MyapiSampleStack.BookApiEndpointXXXXXXXX = https://xxxxxxxxxx.execute-api.ap-northeast-1.amazonaws.com/prod/ REST API アクセスのテスト curl コマンドで REST API の /info リソースを参照すると、うまくアクセス制限がかかっていることが分かります。 HTTP レスポンスコードは 401 Unauthorized です。 $ curl https://xxxxxxxxxx.execute-api.ap-northeast-1.amazonaws.com/prod/info {\u0026#34;message\u0026#34;:\u0026#34;Unauthorized\u0026#34;} 情報を取得するには、Cognito ユーザープールで認証して取得した ID トークンを、REST API リクエスト時の Authorization ヘッダーで指定する必要があります。 $ curl https://xxxxxxxxxx.execute-api.ap-northeast-1.amazonaws.com/prod/info -H \u0026#34;Authorization:XXXX...XXXX\u0026#34; {\u0026#34;message\u0026#34;:\u0026#34;Hello, API Gateway!\u0026#34;} ID トークンの取得方法 ID トークンは、実際に Web サイト上の UI からサインインしてしまうか、AWS CLI (aws cognito-idp) などで認証処理を行うことで取得することができます。 参考: Amazon Cognito でサインイン可能な Web サイトを作る (Amplify) 参考: Amazon Cognito をコマンドライン (CLI) から操作する 下記は、コマンドラインで認証処理を行って ID トークンを取得する例です。 実際には、この前にチャレンジレスポンスに返答する必要があったりしてとても面倒ですが、まぁがんばれば取得できます。 $ aws cognito-idp admin-initiate-auth --user-pool-id ap-northeast-1_XXXXXXXXX --client-id XXXXXXXXXXXXXXXXXXXXXXXXX --auth-flow ADMIN_USER_PASSWORD_AUTH --auth-parameters USERNAME=username,PASSWORD=password AuthenticationResult: AccessToken: eyJraWQiOiJ2aldabmd1meejRSauF5Z43Ez_9LWAxfBP...（省略） ExpiresIn: 3600 IdToken: eyJraWQiOiJvVU9NU1QyZHhvQVArcnsmwD0WbYqhZppSDVNg...（省略） RefreshToken: eyJjdHkiOiJKV1QiLC3YjEmAndRqakoOhw4O9al0z1V...（省略） TokenType: Bearer ChallengeParameters: {} 上記レスポンスにある、IdToken の値を、Authorization ヘッダーでそのまま送れば、REST API は正しいレスポンスを返してくれます。 $ curl https://xxxxxxxxxx.execute-api.ap-northeast-1.amazonaws.com/prod/info -H \u0026#34;Authorization:eyJraWQiOiJv...\u0026#34; {\u0026#34;message\u0026#34;:\u0026#34;Hello, API Gateway!\u0026#34;} 送った ID トークンが妥当なものかは、API Gateway が内部で自動で調べてくれるので、Lambda 関数でチェックしたりする必要はありません。 （応用）Web アプリからの REST API 呼び出し Web アプリからオーソライザー設定された API Gateway を呼び出すには、HTTP リクエスト（fetch 関数呼び出し）時に、Authorization ヘッダーで Cognito ユーザープールから取得した ID トークンを付加する必要があります。 Web アプリからの Cognito 認証に Amplify ライブラリを使用している場合は、次のような感じで簡単に認証情報付き HTTP リクエストを発行できます。 import { Auth } from \u0026#39;aws-amplify\u0026#39; export const fetchWithAuth = async (url: string) =\u0026gt; { const token = (await Auth.currentSession()).getIdToken().getJwtToken() return fetch(url, { headers: { Authorization: token } }).then((r) =\u0026gt; r.json()) } 参考: API (REST) - Define authorization rules - JavaScript - AWS Amplify Docs あとは、このフェッチ関数を通常の fetch 関数の代わりに React カスタムフックなどから呼び出すだけで OK です。 下記は、今回作成した REST API を呼び出す useInfo カスタムフックの実装例です。 \u0026lt;Next.jsアプリ\u0026gt;/src/hooks/useInfo.ts（抜粋） /** useInfo フックの戻り値の型 */ type UseInfoOutput = { error?: Error message?: string } /** REST API の戻り値の型 */ type DataType = { message: string } export const useInfo = (): UseInfoOutput =\u0026gt; { const { data, error } = useSWR\u0026lt;DataType, Error\u0026gt;(GET_INFO_URL, fetchWithAuth) return { error, message: data?.message } } 参考: Amazon Cognito (1) サインイン可能な Web サイトを作る (Cognito User Pool)"
},
{
url: "/p/k7eoer5/",
title: "AWS CDK で API Gateway の REST API を作成する",
date: "2022-04-18T00:00:00Z",
body: "AWS CDK で API Gateway の REST API を作成する 概要 API Gateway は HTTPS で Lambda 関数を呼び出す API Gateway で REST API のエンドポイントを定義すると、HTTPS リクエストで Lambda 関数を呼び出せるようになります。 クライアント ─(HTTPS)─\u0026gt; API Gateway ─(AWS API)─\u0026gt; Lambda 関数 API Gateway には Cognito のユーザープールと連携する機能を備えており、認証済みのユーザーにのみ API 呼び出しを許可するといったことが可能です（具体的に言うと、API Gateway が見えないところで ID トークンの正当性を確認してくれたりします）。 ☝️ 新しい Lambda 関数 URL 2022 年 4 月に公開された Lambda 関数 URL の仕組みを使うと、直接 Lambda 関数にエンドポイント URL を割り当てて呼び出すことができます。 Cognito 連携などを使わないシンプルな Web API であれば、Lambda 関数 URL の仕組みで作ってしまうのが手っ取り早いかもしれません。 Lambda プロキシ統合 Lambda 関数は様々な AWS サービスからのイベント通知によって起動する仕組みになっており、API Gateway からの HTTPS リクエストもそのうちのひとつです。 Lambda 関数のハンドラが呼び出されるとき、そのパラメーターとして「イベントオブジェクト」を受け取ることができるのですが、このイベントオブジェクトの中身は発生源によって異なります。 exports.handler = async function(event) { // event の中身は呼び出し元によってバラバラ } つまり、Lambda 関数は呼び出し側が想定しているリクエストとレスポンスの型を意識した実装をしなければいけません。 とはいえ、REST API の呼び出し方は大体決まっており、Lambda 関数側が欲しい情報も、URL パスやクエリ文字列、HTTP メソッドなど決まっています。 そこで、API Gateway はこういった REST API の実装に都合のよい情報をイベントオブジェクトに詰めてくれる「Lambda プロキシ統合」という仕組みを提供しています。 Lambda プロキシ統合を有効にすると、ハンドラ関数に渡されたイベントオブジェクトから、クエリ文字列などを簡単に取り出すことができます。 レスポンスも決まった型で返さないといけないことに注意してください（間違った形式で返すと、クライアントに 502 エラーが通知されます）。 Lambda プロキシ統合を有効にしたハンドラ関数のシグネチャ (TypeScript) export const handler: APIGatewayProxyHandler = async (event) =\u0026gt; { // event.pathParameters でアクセス時の URL パス情報を参照可能 // event.queryStringParameters でクエリ文字列を参照可能 return { statusCode: 200, body: JSON.stringify(data), headers: { \u0026#34;Access-Control-Allow-Origin\u0026#34;: \u0026#34;*\u0026#34;, }, // isBase64Encoded: true, // body が Base64 エンコードされている場合 } } 以下の説明では、この Lambda プロキシ統合を有効にして API Gateway (REST API) の実装を行っています。 CDK プロジェクトを作成する CDK プロジェクトの作成 は次のような感じで完了しているものとします。 $ mkdir myapi-sample $ cd myapi-sample $ cdk init app --language typescript ここでは、Lambda 関数の実装にも TypeScript を使います。 Lambda 関数を実装する API Gateway (REST API) 経由で呼び出される Lambda 関数を実装します。 最初に Lambda 関数用の TypeScript 型情報をインストールしておきます。 $ npm install --save-dev @types/aws-lambda # npm の場合 $ yarn add --dev @types/aws-lambda # yarn の場合 Lambda 関数の実装ファイル (.ts) は、プロジェクトルートに lambda ディレクトリを作ってそこに入れることにします。 ここでは、REST API として書籍情報を返す /books と /books/{id} というエンドポイントを作成します。 それぞれのハンドラとして getBooksHandler 関数と getBookHandler 関数を定義します。 lambda/books.ts import { APIGatewayProxyHandler, APIGatewayProxyResult } from \u0026#34;aws-lambda\u0026#34; const BOOKS = [ { id: \u0026#34;1\u0026#34;, title: \u0026#34;Title-1\u0026#34; }, { id: \u0026#34;2\u0026#34;, title: \u0026#34;Title-2\u0026#34; }, { id: \u0026#34;3\u0026#34;, title: \u0026#34;Title-3\u0026#34; }, ] /** GET /books */ export const getBooksHandler: APIGatewayProxyHandler = async (event) =\u0026gt; { console.log( \u0026#34;pathParameters = \u0026#34; + JSON.stringify(event.pathParameters, undefined, 2) ) return createResponse(BOOKS) } /** GET /books/{id} */ export const getBookHandler: APIGatewayProxyHandler = async (event) =\u0026gt; { console.log( \u0026#34;pathParameters = \u0026#34; + JSON.stringify(event.pathParameters, undefined, 2) ) const id = event.pathParameters?.[\u0026#34;id\u0026#34;] return createResponse(BOOKS.find((b) =\u0026gt; b.id === id)) } /** レスポンスデータを生成する */ function createResponse(body: any): APIGatewayProxyResult { return { statusCode: 200, body: JSON.stringify(body), headers: { \u0026#34;Access-Control-Allow-Origin\u0026#34;: \u0026#34;*\u0026#34;, }, } } Lambda プロキシ統合を前提とする場合、Lambda 関数の型は、AWS SDK によってあらかじめ定義された型（APIGatewayProxyHandler や APIGatewayProxyResult）を使う必要があります。 また、Web ブラウザ上の JavaScript からの CORS アクセスを許可するために、レスポンスオブジェクトの headers プロパティで、Access-Control-Allow-Origin を指定しています。 参考: Enabling CORS for a REST API resource - Amazon API Gateway スタックを定義する cdk init app による CDK プロジェクトの初期化時に、lib/myapi-sample-stack.ts といった感じの CloudFormation スタック定義用のコードが生成されているので、これを修正して、Lambda 関数と API Gateway の定義 を行い、両者を Lambda プロキシ統合します。 TypeScript で実装した Lambda 関数を CDK で扱う方法の詳細は下記を参考にしてください。 参考: AWS CDK で TypeScript で実装した Lambda 関数をデプロイする (NodejsFunction) lib/myapi-sample-stack.ts // CDK V2 系のインポート（追加インストールの必要なし） import { Stack, StackProps, aws_apigateway as apigateway, aws_lambda_nodejs as lambda, } from \u0026#34;aws-cdk-lib\u0026#34; import { Construct } from \u0026#34;constructs\u0026#34; export class MyapiSampleStack extends Stack { constructor(scope: Construct, id: string, props?: StackProps) { super(scope, id, props) // Lambda 関数（GET books/ 用） const getBooksHandler = new lambda.NodejsFunction(this, \u0026#34;getBooksHandler\u0026#34;, { entry: \u0026#34;lambda/books.ts\u0026#34;, handler: \u0026#34;getBooksHandler\u0026#34;, }) // Lambda 関数（GET books/{id} 用） const getBookHandler = new lambda.NodejsFunction(this, \u0026#34;getBookHandler\u0026#34;, { entry: \u0026#34;lambda/books.ts\u0026#34;, handler: \u0026#34;getBookHandler\u0026#34;, }) // API Gateway (REST API) の作成 const api = new apigateway.RestApi(this, \u0026#34;BookApi\u0026#34;) // リソースを定義して Lambda プロキシ統合 (GET books/) const books = api.root.addResource(\u0026#34;books\u0026#34;) books.addMethod(\u0026#34;GET\u0026#34;, new apigateway.LambdaIntegration(getBooksHandler)) // リソースを定義して Lambda プロキシ統合 (GET book/) const singleBook = books.addResource(\u0026#34;{id}\u0026#34;) singleBook.addMethod(\u0026#34;GET\u0026#34;, new apigateway.LambdaIntegration(getBookHandler)) } } コードの末尾あたりの、apigateway.LambdaIntegration() の部分が、API Gateway の Lambda プロキシ統合を行っている部分になります。 指定したリソース（URL パス）と HTTP メソッドを、特定のハンドラ関数に結びつけています。 こうすることで、その URL (REST API) にアクセスしたときに、扱いやすいイベントオブジェクトをハンドラ関数に渡してくれるようになります。 デプロイ Lambda 関数の実装とスタックの定義が完了したら、CDK でデプロイを行います。 デプロイが完了すると、標準出力に API のエンドポイント (URL) を表示してくれます。 $ cdk deploy ... Outputs: MyapiSampleStack.BookApiEndpointCA1C03A3 = https://a4chxhlkod.execute-api.ap-northeast-1.amazonaws.com/prod/ 上記 URL の末尾に /books を付けて Web ブラウザからアクセスすれば REST API を呼び出せます。 次のような書籍一覧情報の JSON データが返ってくれば成功です。 /books のレスポンス [{\u0026#34;id\u0026#34;:\u0026#34;1\u0026#34;,\u0026#34;title\u0026#34;:\u0026#34;Title-1\u0026#34;},{\u0026#34;id\u0026#34;:\u0026#34;2\u0026#34;,\u0026#34;title\u0026#34;:\u0026#34;Title-2\u0026#34;},{\u0026#34;id\u0026#34;:\u0026#34;3\u0026#34;,\u0026#34;title\u0026#34;:\u0026#34;Title-3\u0026#34;}] 単一の書籍情報を取得する場合は、/books/1 のように、書籍 ID まで指定してアクセスします。 /books/1 のレスポンス {\u0026#34;id\u0026#34;:\u0026#34;1\u0026#34;,\u0026#34;title\u0026#34;:\u0026#34;Title-1\u0026#34;} （応用）プロキシリソースで複数階層の URL をまとめてハンドルする プロキシリソースとは 前述の例では、ひとつの書籍情報を返す REST API のパスとして/books/{id} を設定し、パスパラメーター {id} で書籍 ID を受け取るようにしていました。 API Gateway の プロキシリソース の仕組みを利用すると、複数階層の URL（例: /aaa/bbb/ccc）を 1 つのパスパラメーター（{proxy+}）で受け取ることができます。 プロキシリソースは、前述の Lambda プロキシ統合とは別物 なので注意してください。 Lambda プロキシ統合の方は、単に REST API 呼び出しを Lambda 関数の呼び出しに変換する機能です。 プロキシリソースを使うと、1 つのハンドラー関数実装で様々な URL での API 呼び出しを処理することができます。 例えば、/aaa 、/aaa/bbb/ccc 、/foo/bar といった URL でのアクセスを、1 つのハンドラー関数でまとめて処理できます。 さらに、ハンドルする HTTP メソッドとして ANY を指定することで、複数の HTTP メソッド（GET や POST など）もまとめて 1 つの関数で処理できます。 プロキシリソースの {proxy+} の部分のことを greedy パスパラメーター (greedy path parameter) とか、greedy パス変数 と呼びます。 greedy とは「貪欲な」とか「食いしん坊な」という意味で、いろんな URL を飲み込んじゃうことを示しています。 個人的には「食いしん坊パス」と呼びたいところです。 CDK でプロキシリソースを定義する 先に CloudFormation のスタックを作る CDK コードを見ていきます。 ここでは、API Gateway の REST API を作成し、プロキシリソース (/greedy/{proxy+}) を追加し、そこにハンドラー関数 (greedyHandler) を Lambda プロキシ統合します（ハンドラーは後ほど実装）。 lib/myapi-sample-stack.ts（抜粋） // CDK V2 系のインポート import { Stack, StackProps, aws_apigateway as apigateway, aws_lambda_nodejs as lambda, } from \u0026#34;aws-cdk-lib\u0026#34; import { Construct } from \u0026#34;constructs\u0026#34; export class MyapiSampleStack extends Stack { constructor(scope: Construct, id: string, props?: StackProps) { super(scope, id, props) // API Gateway (REST API) を作成 const api = new apigateway.RestApi(this, \u0026#34;SampleApi\u0026#34;) // プロキシリソース (/greedy/{proxy+}) を扱うハンドラー関数を作成 const greedyHandler = new lambda.NodejsFunction(this, \u0026#39;GreedyHandler\u0026#39;, { entry: \u0026#39;lambda/api.ts\u0026#39;, handler: \u0026#39;greedyHandler\u0026#39;, }) // `/greedy/{proxy+}` というプロキシリソースを Lambda プロキシ統合して追加 api.root.addResource(\u0026#39;greedy\u0026#39;).addProxy({ anyMethod: true, // すべての HTTP メソッド (ANY) をハンドル defaultIntegration: new apigateway.LambdaIntegration(greedyHandler), }) } } プロキシリソースを定義している部分は最後の api.root.addResource('greedy').addProxy(...) という部分ですが、greedy パス名としては {proxy+} が自動的に割り当てられるようです。 ちなみに、API に Cognito ユーザープール認可などの Authorizer を設定するときは、OPTIONS メソッドに Authorizer が設定されないようにしなければいけません。 上記コードの addProxy 部分に単純に Authorizer を設定してしまうと、OPTIONS メソッドにまで Authorizer が設定されてしまい、HTTP のプリフライトリクエスト（OPTIONS リクエスト）が弾かれてしまいます。 簡単に言うと、API Gateway で定義した API が Web ブラウザ上の JavaScript から呼び出せなくなります。 ダメな Authorizer 設定方法 api.root.addResource(\u0026#39;greedy\u0026#39;).addProxy({ anyMethod: true, // OPTIONS メソッドまで Authorizer が設定されてしまう defaultIntegration: new apigateway.LambdaIntegration(greedyHandler), defaultMethodOptions: { authorizer }, }) なので、Authorizer は何とかして OPTIONS メソッド以外に設定してやる必要があります。 例えばこうすれば動く const greedyResource = api.root.addResource(\u0026#39;greedy\u0026#39;).addProxy({ anyMethod: false, // ここでは HTTP メソッドを追加しない defaultIntegration: new apigateway.LambdaIntegration(greedyHandler), }) // OPTIONS 以外の各メソッドに個別に Authorizer を設定する greedyResource.addMethod(\u0026#39;GET\u0026#39;, undefined, { authorizer }) greedyResource.addMethod(\u0026#39;POST\u0026#39;, undefined, { authorizer }) greedyResource.addMethod(\u0026#39;PUT\u0026#39;, undefined, { authorizer }) greedyResource.addMethod(\u0026#39;DELETE\u0026#39;, undefined, { authorizer }) API Gateway に Cognito 認証をかける方法の詳細は こちらを参照 してください。 プロキシリソース用のハンドラー（Lambda 関数）を実装する 上記で定義したプロキシリソース URL (/greedy/{proxy+}) にアクセスしたときに呼び出される Lambda 関数（ハンドラー）を実装します。 lambda/api.ts import { APIGatewayProxyHandler } from \u0026#39;aws-lambda\u0026#39; export const greedyHandler: APIGatewayProxyHandler = async (event) =\u0026gt; { // レスポンス本文用の JSON テキストを作る const responseBody = JSON.stringify({ message: \u0026#39;I am greedyHandler!\u0026#39;, httpMethod: event.httpMethod, path: event.path, pathParameters: event.pathParameters, queryStringParameters: event.queryStringParameters, }) // APIGatewayProxyResult 型のレスポンスを返す return { statusCode: 200, body: responseBody, headers: { \u0026#39;Access-Control-Allow-Origin\u0026#39;: \u0026#39;*\u0026#39;, }, } } 実際にどのような URL で REST API が呼び出されたかは、ハンドラー関数に渡されるイベントオブジェクト (APIGatewayProxyEvent) を参照すると分かります。 例えば、/greedy/aaa/bbb/ccc/?foo=100\u0026amp;bar という URL でアクセスした場合、イベントオブジェクトの値は次のようになります。 プロパティ 値 event.httpMethod GET event.path /greedy/aaa/bbb/ccc/ event.pathParameters { proxy: \u0026quot;aaa/bbb/ccc\u0026quot; } event.queryStringParameters { bar: \u0026quot;\u0026quot;, foo: \u0026quot;100\u0026quot; } つまり、event.pathParameters.proxy の値を見ることで、パスに応じた処理を行えるということですね。"
},
{
url: "/p/54s6es8/",
title: "Go 言語で AWS CDK V2 を使う (1) 導入編",
date: "2022-04-13T00:00:00Z",
body: "Go 言語で AWS CDK V2 を使う (1) 導入編 何をするか？ CDK プロジェクトでは多くのケースでは TypeScript を使ってコード記述されていると思いますが、Go 言語の勢いが出てきていることもあり、ここでは Go 言語を使った CDK プロジェクトを作成してみます。 CDK 自体の概要については下記に簡単にまとまっています。 参考: AWS CDK 入門 (1) インストールから Hello World まで 以下、Go 言語のインストールや、AWS の認証情報の設定 (~/.aws/credentials, ~/.aws/config) はできているものとします。 参考: Go 言語で AWS SDK を使う開発環境を整える AWS CDK のインストール Go 言語で CDK のコードを記述する場合でも、AWS CDK のコマンドラインツール (cdk) 自体は、Node.js の NPM パッケージで提供されているものを使います。 $ npm install -g aws-cdk ... $ cdk --version 2.20.0 (build 738ef49) CDK プロジェクトを作成する (cdk init) CDK の Scaffold 機能を使って、Go 言語用の CDK プロジェクトを生成します。 $ mkdir cdk-with-go $ cd cdk-with-go $ cdk init --language=go cdk init すると、次のようなファイルが生成されます。 TypeScript 用のプロジェクトと比べてとってもシンプルです！ - README.md # GitHub リポジトリのトップページ - .gitignore # CDK と Go 言語用の .gitignore - cdk-with-go.go # スタック生成コードのエントリポイント - cdk-with-go_test.go # 上記のテストコード - cdk.json # CDK 用の設定 - go.mod # Go モジュールの定義（CDK パッケージの依存情報など） 依存モジュールをダウンロードして、不要な依存関係を削除しておきます。 $ go mod tidy CloudFormation にスタックを生成する、削除する (cdk deploy, cdk destroy) 自動生成されたスタック定義用の Go コードを見ると、次のような感じになっています。 初期状態では、空っぽの CdkWithGoStack スタックを作るようになっています。 cdk-with-go.go （自動生成されたコード） package main import ( \u0026#34;github.com/aws/aws-cdk-go/awscdk/v2\u0026#34; // \u0026#34;github.com/aws/aws-cdk-go/awscdk/v2/awssqs\u0026#34; \t\u0026#34;github.com/aws/constructs-go/constructs/v10\u0026#34; // \u0026#34;github.com/aws/jsii-runtime-go\u0026#34; ) type CdkWithGoStackProps struct { awscdk.StackProps } func NewCdkWithGoStack(scope constructs.Construct, id string, props *CdkWithGoStackProps) awscdk.Stack { var sprops awscdk.StackProps if props != nil { sprops = props.StackProps } stack := awscdk.NewStack(scope, \u0026amp;id, \u0026amp;sprops) // The code that defines your stack goes here // example resource \t// queue := awssqs.NewQueue(stack, jsii.String(\u0026#34;CdkWithGoQueue\u0026#34;), \u0026amp;awssqs.QueueProps{ \t// VisibilityTimeout: awscdk.Duration_Seconds(jsii.Number(300)), \t// }) return stack } func main() { app := awscdk.NewApp(nil) NewCdkWithGoStack(app, \u0026#34;CdkWithGoStack\u0026#34;, \u0026amp;CdkWithGoStackProps{ awscdk.StackProps{ Env: env(), }, }) app.Synth(nil) } // env determines the AWS environment (account+region) in which our stack is to // be deployed. For more information see: https://docs.aws.amazon.com/cdk/latest/guide/environments.html func env() *awscdk.Environment { // If unspecified, this stack will be \u0026#34;environment-agnostic\u0026#34;. \t// Account/Region-dependent features and context lookups will not work, but a \t// single synthesized template can be deployed anywhere. \t//--------------------------------------------------------------------------- \treturn nil // Uncomment if you know exactly what account and region you want to deploy \t// the stack to. This is the recommendation for production stacks. \t//--------------------------------------------------------------------------- \t// return \u0026amp;awscdk.Environment{ \t// Account: jsii.String(\u0026#34;123456789012\u0026#34;), \t// Region: jsii.String(\u0026#34;us-east-1\u0026#34;), \t// } // Uncomment to specialize this stack for the AWS Account and Region that are \t// implied by the current CLI configuration. This is recommended for dev \t// stacks. \t//--------------------------------------------------------------------------- \t// return \u0026amp;awscdk.Environment{ \t// Account: jsii.String(os.Getenv(\u0026#34;CDK_DEFAULT_ACCOUNT\u0026#34;)), \t// Region: jsii.String(os.Getenv(\u0026#34;CDK_DEFAULT_REGION\u0026#34;)), \t// } } ここでは、このコードはそのまま使わずに、次のような最小限のコードを最初のステップとして使います。 cdk-with-go.go package main import ( \u0026#34;github.com/aws/aws-cdk-go/awscdk/v2\u0026#34; \u0026#34;github.com/aws/jsii-runtime-go\u0026#34; ) func main() { app := awscdk.NewApp(nil) awscdk.NewStack(app, jsii.String(\u0026#34;CdkWithGoStack\u0026#34;), \u0026amp;awscdk.StackProps{}) app.Synth(nil) } やっていることは単純で、空っぽのスタック (CdkWithGoStack) を作成しているだけです。 jsii.String というのは、文字列リテラルを String* 型の引数にそのまま渡すためのユーティリティです（これがないと文字列変数をいちいち作らないといけない\u0026hellip;）。 この定義に従って CloudFormation へデプロイを行うには、cdk deploy コマンドを実行します。 $ go mod tidy # 必要に応じて Go モジュールの依存解決 $ cdk deploy CloudFormation スタックの生成処理に 1 分くらいかかるのでしばらく待ちます。 コマンドの実行が完了してから AWS コンソールを覗いてみると、実際に CdkWithGoStack というスタックが生成されていることを確認できます。 図: AWS コンソール上の表示 このお試し作業が終わったら、cdk destory で作成したスタックを削除しておきます。 $ cdk destroy Are you sure you want to delete: CdkWithGoStack (y/n)? y スタックに AWS リソースを追加する ここでは、例としてスタック上に S3 バケットを作成してみます。 S3 を扱うパッケージを go get で追加します。 最後に go mod tidy でまとめて依存解決する方法もありますが、コーディング時に入力補完するためには先に go get しておく必要があります。 $ go get github.com/aws/aws-cdk-go/awscdk/v2/awss3 参考: AWS CDK V2 の API ドキュメント 参考: Go 言語用の awss3.NewBucket 関数 スタック生成用のコードを書き換えて、スタック上に S3 バケット (MyBucket) を追加します。 cdk-with-go.go package main import ( \u0026#34;github.com/aws/aws-cdk-go/awscdk/v2\u0026#34; \u0026#34;github.com/aws/aws-cdk-go/awscdk/v2/awss3\u0026#34; \u0026#34;github.com/aws/jsii-runtime-go\u0026#34; ) func main() { app := awscdk.NewApp(nil) stack := awscdk.NewStack(app, jsii.String(\u0026#34;CdkWithGoStack\u0026#34;), \u0026amp;awscdk.StackProps{}) // スタック内に S3 バケットを生成 \tawss3.NewBucket(stack, jsii.String(\u0026#34;MyBucket\u0026#34;), \u0026amp;awss3.BucketProps{}) app.Synth(nil) } あとは、次のようにデプロイすれば S3 バケットを持つ CloudFormation スタックが生成されます。 $ cdk deploy 他の AWS リソースに関しても、同様にスタックに追加していくことができます。"
},
{
url: "/p/qwb6v89/",
title: "Amazon API Gateway をコマンドライン (CLI) から操作する",
date: "2022-04-11T00:00:00Z",
body: "Amazon API Gateway をコマンドライン (CLI) から操作する AWS CLI（コマンドラインkツール）で Amazon API Gateway を操作するには、aws apigatewayv2 コマンドを使用します。 API Gateway の作成や更新を行うためには、IAM ユーザーに適切な権限が必要ですが、AmazonAPIGatewayAdministrator 管理ポリシーを付けるとほとんどの操作が可能になります。 通常、REST API を作成する場合は、バックエンドの Lambda 関数も合わせて必要になるので、AWSLambdaFullAccess などの管理ポリシーも必要になります。 REST API を作成する (apigateway create-rest-api) リファレンス: apigateway create-rest-api $ aws apigateway create-rest-api --name \u0026#34;My First API\u0026#34; \\ --description \u0026#34;This is my first API\u0026#34; \\ --region ap-northeast-1 apiKeySource: HEADER createdDate: \u0026#39;2022-04-18T15:46:00+09:00\u0026#39; description: This is my first API disableExecuteApiEndpoint: false endpointConfiguration: types: - EDGE id: mk6mj65po6 name: My First API --name オプションのみが必須です。 API の作成に成功すると、上記のように ID (mk6mj65po6) が返されます。 REST API を削除する (apigateway delete-rest-api) リファレンス: apigateway delete-rest-api $ aws apigateway delete-rest-api --rest-api-id mk6mj65po6 REST API の名前ではなく、ID を指定することに注意してください。 ID が分からない場合は、get-rest-apis で列挙して調べることができます。 REST API の一覧を取得する (apigateway get-rest-apis) リファレンス: apigateway get-rest-apis $ aws apigateway get-rest-apis"
},
{
url: "/p/wqamv5d/",
title: "Amazon API Gateway のメモ",
date: "2022-04-11T00:00:00Z",
body: "Amazon API Gateway のメモ"
},
{
url: "/p/yz2h95y/",
title: "Amazon Cognito 関連記事",
date: "2022-04-11T00:00:00Z",
body: "Amazon Cognito 関連記事"
},
{
url: "/p/xnogqgm/",
title: "Go 言語で AWS SDK を使う開発環境を整える",
date: "2022-04-11T00:00:00Z",
body: "Go 言語で AWS SDK を使う開発環境を整える 何をするか？ ここでは、Go 言語用の AWS SDK V2 をセットアップして、各種 AWS サービス用の API を呼び出す準備をします。 Go 言語は Google が開発したプログラミング言語で、ライブラリインポートの手軽さや、生成された実行バイナリの実行速度に定評があるため、今後も利用ユーザーは増えていきそうです。 参考: Go 言語とは？／Go をインストールする | まくまくHugo/Goノート Go の実行環境は Go のインストーラー で簡単にインストールできます。 これ以降の説明では、Go の実行環境はインストール済みであると想定しています。 テスト用の Go プロジェクトを作成する Go プロジェクト用に適当なディレクトリを作成し、その中で go mod init コマンドを実行して go.mod （依存関係などが保存されるファイル）を作成しておきます。 このファイルが存在するディレクトリを、Go はモジュールとして認識します。 $ mkdir aws-study $ cd aws-study $ go mod init aws-study 上記の例では、go mod init の引数（モジュールパス）を aws-study としましたが、GitHub リポジトリで管理する前提であれば、github.com/\u0026lt;user\u0026gt;/aws-study のようなモジュールパスを指定するようにしてください。 これで、Go 言語プロジェクトの準備完了です。 AWS SDK でコンフィグ情報を参照してみる AWS SDK を使って AWS のサービスにアクセスするには、認証情報として IAM ユーザーの「アクセスキー ID」や「シークレットアクセスキー」などが必要になります。 これらは、一般的には AWS CLI の aws configure コマンドによって、~/.aws/credentials や ~/.aws/config に保存された情報です。 参考: AWS の初期設定: AWS CLI と認証情報の設定 AWS SDK にはこれらの設定ファイルから認証情報（クレデンシャル情報）を読み取る API が用意されています。 まず、go get コマンドを実行して、設定情報を読み込むための github.com/aws/aws-sdk-go-v2/config パッケージ の依存情報を追加します。 $ go get github.com/aws/aws-sdk-go-v2/config go get コマンドを実行すると、パッケージの依存情報が記載された go.mod と go.sum ファイルが更新されるので、これらは忘れずに Git などにコミットするようにしてください。 下記のサンプルコードでは、AWS のコンフィグ情報を取得して、画面上に出力しています。 main.go package main import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;github.com/aws/aws-sdk-go-v2/config\u0026#34; ) func main() { // 外部リソース（~/.aws/config など）からコンフィグ情報 (aws.Config) を生成 \tcfg, err := config.LoadDefaultConfig(context.TODO()) if err != nil { panic(fmt.Sprintf(\u0026#34;failed loading config, %v\u0026#34;, err)) } // コンフィグ情報を表示 \tfmt.Printf(\u0026#34;Region = %s\\n\u0026#34;, cfg.Region) cred, err := cfg.Credentials.Retrieve(context.TODO()) if err != nil { panic(fmt.Sprintf(\u0026#34;failed retrieving credentials, %v\u0026#34;, err)) } fmt.Printf(\u0026#34;AccessKeyID = %s\\n\u0026#34;, cred.AccessKeyID) fmt.Printf(\u0026#34;SecretAccessKey = %s\\n\u0026#34;, cred.SecretAccessKey) fmt.Printf(\u0026#34;SessionToken = %s\\n\u0026#34;, cred.SessionToken) } 次のように実行してアクセスキーの情報が表示されれば、各種 AWS サービスの API を呼び出す準備は整っています。 実行例 $ go run main.go Region = ap-northeast-1 AccessKeyID = TAZASBDCD4ASIAVTXAP4 SecretAccessKey = S2VmkhmfeN8n9TXe7G2L1XAOVhK80jui/eNcdgna SessionToken = Ub7oU0AhI0k4NIGo3J（省略）D9f3YiTZ2xyyqi44w= config.LoadDefaultConfig 関数 は、次のような外部リソースを情報源として AWS のコンフィグ情報 (aws.Config) を構築しています。 コンフィグ情報がうまく表示されないときは、これらの設定を確認すると原因が分かるかもしれません。 環境変数 export AWS_REGION=ap-northeast-1 export AWS_ACCESS_KEY_ID=TAZASBDCD4ASIAVTXAP4 export AWS_SECRET_ACCESS_KEY=S2VmkhmfeN8n9TXe7G2L1XAOVhK80jui/eNcdgna export AWS_SESSION_TOKEN=Ub7oU0AhI0k4NIGo3J（省略）D9f3YiTZ2xyyqi44w= export AWS_PROFILE=default Shared Credentials ファイル (~/.aws/credentials) Shared Configuration ファイル (~/.aws/config) AWS サービスの API を呼び出してみる コンフィグ情報 (aws.Config) を取得できるようになったら、あとは各 AWS サービス（S3、API Gateway、DynamoDB など）の API を呼び出すだけです。 例としては何でもよいのですが、ここでは、S3 バケットの情報を取得してみます。 各 AWS サービス用のパッケージは github.com/aws/aws-sdk-go-v2/service/サービス名 という名前で提供されているので、これを go get しておきます。 $ go get github.com/aws/aws-sdk-go-v2/service/s3 下記のサンプルコードを実行すると、S3 バケットの一覧（作成日とバケット名）を出力します。 main.go package main import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;github.com/aws/aws-sdk-go-v2/aws\u0026#34; \u0026#34;github.com/aws/aws-sdk-go-v2/config\u0026#34; \u0026#34;github.com/aws/aws-sdk-go-v2/service/s3\u0026#34; ) func main() { cfg := loadAwsConfig() output := listS3Buckets(cfg) for _, bucket := range output.Buckets { created := bucket.CreationDate.Format(\u0026#34;2006-01-02 15:04:05 Mon\u0026#34;) fmt.Println(created + \u0026#34;: \u0026#34; + *bucket.Name) } fmt.Printf(\u0026#34;Found %d buckets\\n\u0026#34;, len(output.Buckets)) } // 外部リソース（~/.aws/config など）からコンフィグ情報 (aws.Config) を生成します。 func loadAwsConfig() aws.Config { cfg, err := config.LoadDefaultConfig(context.TODO()) if err != nil { panic(fmt.Sprintf(\u0026#34;failed loading config, %v\u0026#34;, err)) } return cfg } // S3 バケットの一覧を取得します。 func listS3Buckets(cfg aws.Config) *s3.ListBucketsOutput { client := s3.NewFromConfig(cfg) input := \u0026amp;s3.ListBucketsInput{} output, err := client.ListBuckets(context.TODO(), input) if err != nil { panic(fmt.Sprintf(\u0026#34;failed listing S3 buckets, %v\u0026#34;, err)) } return output } 実行例 $ go run main.go 2021-12-24 00:59:06 Fri: my-sample-bucket-name-1 2022-04-08 05:15:52 Fri: my-sample-bucket-name-2 2022-04-04 08:47:23 Mon: my-sample-bucket-name-3 2020-07-10 06:54:33 Fri: my-sample-bucket-name-4 Found 4 buckets このサンプルコードでは S3 サービスの API を使用しましたが、他の AWS サービスに関しても同様に操作することができます。"
},
{
url: "/p/nej9wjb/",
title: "Go 言語と AWS SDK V2 で Amazon Cognito を操作する",
date: "2022-04-11T00:00:00Z",
body: "Go 言語と AWS SDK V2 で Amazon Cognito を操作する ここでは、AWS SDK for Go V2 を使って、Go 言語から Amazon Cognito を操作するサンプルコードを示します。 Go 言語で AWS SDK を使うための開発環境 は構築済みとします。 指定したユーザープール内のユーザーリストを取得する (ListUsers) list_users.go package main import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;github.com/aws/aws-sdk-go-v2/aws\u0026#34; \u0026#34;github.com/aws/aws-sdk-go-v2/config\u0026#34; \u0026#34;github.com/aws/aws-sdk-go-v2/service/cognitoidentityprovider\u0026#34; ) var userPoolId = \u0026#34;ap-northeast-1_XXXXXXXXX\u0026#34; // ユーザープールの ID func main() { listUsers() } func listUsers() { client := cognitoidentityprovider.NewFromConfig(loadAwsConfig()) input := \u0026amp;cognitoidentityprovider.ListUsersInput { UserPoolId: \u0026amp;userPoolId, } output, err := client.ListUsers(context.TODO(), input) if err != nil { panic(err) } for _, user := range output.Users { fmt.Printf(\u0026#34;%s, %s\\n\u0026#34;, user.UserCreateDate, *user.Username) } fmt.Printf(\u0026#34;Found %d users\\n\u0026#34;, len(output.Users)) } // 外部リソース（~/.aws/config など）からコンフィグ情報 (aws.Config) を生成します。 func loadAwsConfig() aws.Config { cfg, err := config.LoadDefaultConfig(context.TODO()) if err != nil { panic(err) } return cfg } 実行例 $ go run list_users.go 2021-11-25 06:37:28.751 +0000 UTC, user-name-1 2021-10-28 02:34:29.485 +0000 UTC, user-name-2 2021-11-30 13:49:28.566 +0000 UTC, user-name-3 Found 3 users ユーザーのパスワードを変更する (AdminSetUserPassword) package main import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;github.com/aws/aws-sdk-go-v2/aws\u0026#34; \u0026#34;github.com/aws/aws-sdk-go-v2/config\u0026#34; \u0026#34;github.com/aws/aws-sdk-go-v2/service/cognitoidentityprovider\u0026#34; ) var userPoolId = \u0026#34;ap-northeast-1_XXXXXXXXX\u0026#34; // ユーザープールの ID func main() { adminSetUserPassword() } func adminSetUserPassword() { client := cognitoidentityprovider.NewFromConfig(loadAwsConfig()) user := \u0026#34;user1\u0026#34; pass := \u0026#34;Password#123\u0026#34; input := \u0026amp;cognitoidentityprovider.AdminSetUserPasswordInput{ UserPoolId: \u0026amp;userPoolId, Username: \u0026amp;user, Password: \u0026amp;pass, } _, err := client.AdminSetUserPassword(context.TODO(), input) if err != nil { panic(err) } fmt.Println(\u0026#34;Password changed\u0026#34;) } ユーザー名とパスワードで認証して ID トークンとアクセストークンを取得する (AdminInitiateAuth) 下記のように AdminInitiateAuth API でユーザー認証を行うには、Cognito ユーザープールの設定で対象のクライアントを選択し、ALLOW_ADMIN_USER_PASSWORD_AUTH にチェックを入れておく必要があります。 package main import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;github.com/aws/aws-sdk-go-v2/aws\u0026#34; \u0026#34;github.com/aws/aws-sdk-go-v2/config\u0026#34; \u0026#34;github.com/aws/aws-sdk-go-v2/service/cognitoidentityprovider\u0026#34; \u0026#34;github.com/aws/aws-sdk-go-v2/service/cognitoidentityprovider/types\u0026#34; ) var userPoolId = \u0026#34;ap-northeast-1_XXXXXXXXX\u0026#34; // ユーザープールの ID var clientId = \u0026#34;XXXXXXXXXXXXXXXXXXXXXXXXX\u0026#34; func main() { adminInitiateAuth() } func adminInitiateAuth() { client := cognitoidentityprovider.NewFromConfig(loadAwsConfig()) input := \u0026amp;cognitoidentityprovider.AdminInitiateAuthInput{ UserPoolId: \u0026amp;userPoolId, ClientId: \u0026amp;clientId, AuthFlow: types.AuthFlowTypeAdminUserPasswordAuth, AuthParameters: map[string]string{\u0026#34;USERNAME\u0026#34;: \u0026#34;user1\u0026#34;, \u0026#34;PASSWORD\u0026#34;: \u0026#34;Password#123\u0026#34;}, } output, err := client.AdminInitiateAuth(context.TODO(), input) if err != nil { panic(err) } // レスポンスの出力 \tfmt.Printf(\u0026#34;ChallengeName = %s\\n\u0026#34;, output.ChallengeName) fmt.Printf(\u0026#34;ChallengeParameters = %v\\n\u0026#34;, output.ChallengeParameters) if output.Session != nil { fmt.Printf(\u0026#34;Session:\\n%s\\n\u0026#34;, *output.Session) } if output.AuthenticationResult != nil { fmt.Println(\u0026#34;AuthenticationResult:\u0026#34;) fmt.Printf(\u0026#34; IdToken = %s\\n\u0026#34;, *output.AuthenticationResult.IdToken) fmt.Printf(\u0026#34; AccessToken = %s\\n\u0026#34;, *output.AuthenticationResult.AccessToken) fmt.Printf(\u0026#34; RefreshToken = %s\\n\u0026#34;, *output.AuthenticationResult.RefreshToken) fmt.Printf(\u0026#34; TokenType = %s\\n\u0026#34;, *output.AuthenticationResult.TokenType) fmt.Printf(\u0026#34; ExpiresIn = %d(sec)\\n\u0026#34;, output.AuthenticationResult.ExpiresIn) } } 認証に成功すると、API の戻り値の AuthenticationResult に各種トークン情報が格納されます。 ChallengeName = ChallengeParameters = map[] AuthenticationResult: IdToken = eyJraWQiOiJvVU-UYPb...長いので省略...QlbXNjaDF4cHBRWWU AccessToken = eyJraWQiOiJ2a1W...長いので省略...MeaGq7Q-ecVo7UrQA RefreshToken = eyJjdHkiOiJKV1...長いので省略...FmbPUE4M-CFXNp9aA TokenType = Bearer ExpiresIn = 3600(sec) 場合によっては、次のように追加のチャレンジリクエストが返されることがあります。 ChallengeName = NEW_PASSWORD_REQUIRED ChallengeParameters = map[USER_ID_FOR_SRP:user1 requiredAttributes:[\u0026quot;userAttributes.email\u0026quot;] userAttributes:{\u0026quot;email\u0026quot;:\u0026quot;\u0026quot;}] Session: AYABeGUOL0khu9R69cL1oW5AlDMAHQABAAdTZXJ2aWNlABBDb2duaXRvVXN lclBvVsigrdMZ2QLwOwDNyG485jP45wBAn19cJKXxHhAGETrvfQjHMSOIyz ...長いので省略... Uk9oosogIT_QEIXF5OrGGtWq7ELm56gXiW1hc06rp3cBYFbOlI5pjp36Jfd SfWaFjq0yyWYVAwEA4NG0DgtW3xZjto4NpHVCIVdxBmmolAKDtbkvVsWNFQ その場合は、続けて AdminRespondToAuthChallenge API を呼び出し、ChallengeName で指定されたチャレンジ（上記の場合は NEW_PASSWORD_REQURED）に答える必要があります。 このとき、チャレンジ要求時に提示された Session 情報が必要になります。 下記は、AdminRespondToAuthChallenge の呼び出し方の例です（ここでは全部ハードコーディングしちゃってます）。 func adminRespondToAuthChallenge() { client := cognitoidentityprovider.NewFromConfig(loadAwsConfig()) session := \u0026#34;AYABeJDb9BhR5D...長いので省略...fZAPW2Ynnslwww\u0026#34; input := \u0026amp;cognitoidentityprovider.AdminRespondToAuthChallengeInput{ UserPoolId: \u0026amp;userPoolId, ClientId: \u0026amp;clientId, ChallengeName: \u0026#34;NEW_PASSWORD_REQUIRED\u0026#34;, ChallengeResponses: map[string]string{ \u0026#34;USERNAME\u0026#34;: \u0026#34;user1\u0026#34;, \u0026#34;NEW_PASSWORD\u0026#34;: \u0026#34;Password#123\u0026#34;, \u0026#34;userAttributes.email\u0026#34;: \u0026#34;user1@example.com\u0026#34;, }, Session: \u0026amp;session, } _, err := client.AdminRespondToAuthChallenge(context.TODO(), input) if err != nil { panic(err) } fmt.Println(\u0026#34;Auth challenge succeeded\u0026#34;) } チャレンジに正しく応答できると、AdminRespondToAuthChannelgeInput API の戻り値の AuthenticationResult フィールドに、ID トークンやアクセストークンが格納されます。 これは、AdminInitiateAuth API の戻り値と同様です。 チャレンジに応答した後に、再度 AdminInitiateAuth を呼び出して各トークンを取得することもできます。"
},
{
url: "/p/9xxpe4t/",
title: "Jest で TypeScript コードのユニットテストを記述する",
date: "2022-04-04T00:00:00Z",
body: "Jest で TypeScript コードのユニットテストを記述する Jest とは Jest は Facebook が公開した JavaScript 用のシンプルなテストフレームワークで、Node.js 環境で実行することができます。 Jest · 🃏 Delightful JavaScript Testing Jest は下記のような特徴を持っています。 ゼロコンフィグで使い始められる（設定ファイルなしで実行可能） テストを並列実行するので高速 コードカバレッジレポートの出力を標準搭載 わかりやすいマッチャー表現 (expect ～ toBe、toContain など、自然な文章として読める） TypeScript に対応（ts-jest を利用） Jest 用のテストコードは、次のようなコードジェネレーターでも採用されており、利用者は増え続けています（2022 年現在）。 create-react-app \u0026hellip; React アプリのジェネレーター cdk init app \u0026hellip; AWS のインフラ生成コードのジェネレーター Jest のインストール Jest 本体の jest モジュールをインストールします。 TypeScript を使用する場合は、Jest ライブラリの型情報である @types/jest と、Jest 用の TypeScript プロセッサ (ts-jest) もインストールする必要があります。 これらはすべてテスト時のみ使用する NPM モジュールなので、devDependencies としてインストールします。 Jest 本体と TypeScript 関連モジュールをインストール ### npm の場合 $ npm install --save-dev jest @types/jest ts-jest ### yarn の場合 $ yarn add --dev jest @types/jest ts-jest package.json の修正 Jest によるテストを簡単に起動できるように、package.json に NPM スクリプト (test) を定義しておきます。 あと、Jest が TypeScript のコードを理解できるように、jest.preset に ts-jest を設定しておきます。 これを設定しておかないと、import 構文などを理解できなくてエラーになります。 package.json { // ... \u0026#34;scripts\u0026#34;: { // ... \u0026#34;test\u0026#34;: \u0026#34;jest\u0026#34; }, \u0026#34;jest\u0026#34;: { \u0026#34;preset\u0026#34;: \u0026#34;ts-jest\u0026#34; } } 上記の jest プロパティの値は、jest.config.js という別ファイルとして定義することもできます。 jest.config.js（これがあればこちらが優先される） module.exports = { preset: \u0026#39;ts-jest\u0026#39;, } これで、次のようにユニットテストを起動できます。 $ yarn test # yarn の場合 $ npm test # npm の場合 最初は何もテストコードがないので、実行しても次のようなエラーで終了するはずです（終了コード 1 はコマンドが失敗したことを表します）。 $ yarn -s test No tests found, exiting with code 1 テストがないときにエラーにならないようにするには、--passWithNoTests オプションを付けて実行します。 自動ビルド環境などで、常に yarn test は実行しておきたい場合にお世話になるかもしれません。 $ yarn -s jest --passWithNoTests No tests found, exiting with code 0 テストの記述 ここでは、次のような計算ライブラリをテスト対象のコードとして使うことにします。 src/math.ts（テスト対象） export function add(a: number, b: number): number { return a + b } Jest はデフォルトで次のようなファイルを検索してテストコードとして実行します。 拡張子が .test.ts (.test.js) のファイル 拡張子が .spec.ts (.spec.js) のファイル __test__ ディレクトリ以下に配置した .ts (.js) ファイル 前述の計算ライブラリ (math.ts) をテストするためのテストコードを、math.test.ts というファイル名で作成します。 ファイル名のベース部分 (math) はテスト対象のファイル名と合わせておくと分かりやすいでしょう。 src/math.test.ts（テストコード） import { add } from \u0026#39;./math\u0026#39; test(\u0026#39;add - positives\u0026#39;, () =\u0026gt; { const result = add(1, 2) expect(result).toBe(3) }) test(\u0026#39;add - negatives\u0026#39;, () =\u0026gt; { const result = add(-1, -2) expect(result).toBe(-3) }) テストコード内では、上記のように test(テスト名, テスト内容) という形で各テストを定義します（test の代わりに it も使えます）。 計算結果の検証は、expect(実行結果).toBe(期待結果) のように記述します。 次のようにテストを起動できます（yarn の出力をシンプルにするために -s オプションを指定しています）。 $ yarn -s test PASS src/math.test.ts √ add - positives (1 ms) √ add - negatives Test Suites: 1 passed, 1 total Tests: 2 passed, 2 total Snapshots: 0 total Time: 2.316 s, estimated 3 s Ran all test suites. すべてのテストが通りました！ さらに、--coverage オプションを付けて実行することで、テストカバレッジのレポートを出力することができます。 テスト対象となったソースコードのうち何％がテストでカバーされているかを表示してくれます。 $ yarn -s test --coverage PASS src/math.test.ts √ add - positives (2 ms) √ add - negatives (1 ms) ----------|---------|----------|---------|---------|------------------- File | % Stmts | % Branch | % Funcs | % Lines | Uncovered Line #s ----------|---------|----------|---------|---------|------------------- All files | 100 | 100 | 100 | 100 | math.ts | 100 | 100 | 100 | 100 | ----------|---------|----------|---------|---------|------------------- Test Suites: 1 passed, 1 total Tests: 2 passed, 2 total Snapshots: 0 total Time: 3.201 s Ran all test suites. Jest のマッチャー expect(add(1, 2)).toBe(3) 上記の検証コードの toBe の部分は マッチャー と呼ばれており、toBe 以外にも次のようなマッチャーが用意されています。 真偽値や null との比較 toBeTruthy() \u0026hellip; 値が true であることを確認する toBeFalthy() \u0026hellip; 値が false であることを確認する toBeNull() \u0026hellip; 値が null であることを確認する toBeUndefined() \u0026hellip; 値が undefined であることを確認する toBeDefined() \u0026hellip; 値が undefined でないことを確認する test(\u0026#39;null\u0026#39;, () =\u0026gt; { const n = null expect(n).toBeNull() }) 否定 (not) not を使うと、条件を反転できます。 expect(1).not.toBeNull() 数値の比較 数値の同値比較には toBe あるいは toEqual が使えますが、大小比較用のマッチャーも用意されています。 test(\u0026#39;two plus two\u0026#39;, () =\u0026gt; { const value = 2 + 2 expect(value).toBe(4) expect(value).toBeGreaterThan(3) expect(value).toBeGreaterThanOrEqual(3.5) expect(value).toBeLessThan(5) expect(value).toBeLessThanOrEqual(4.5) }) 浮動小数点数の同値比較には、toBe ではなく toBeCloseTo を使うようにします。 test(\u0026#39;add floating point numbers\u0026#39;, () =\u0026gt; { const value = 0.1 + 0.2 expect(value).toBeCloseTo(0.3) // Do not use \u0026#39;toBe\u0026#39; }) 正規表現 文字列が正規表現に一致するかを調べるには、toMatch を使用します。 次の例では、チーム名が team- プレフィックスで始まっているかを調べています。 test(\u0026#39;starts with \u0026#34;team-\u0026#34; prefix\u0026#39;, () =\u0026gt; { const teamName = \u0026#39;team-xxx\u0026#39; expect(teamName).toMatch(/^team-/); }) 配列、セットのテスト 配列やセットの内容が等しいことを確認するには、toEqual を使います。 toBe を使うと参照の比較になってしまうので、toEqual で実際の値を比較するようにします。 // 配列の比較 const arr = [1, 2, 3] expect(arr).toEqual([1, 2, 3]) // セットの比較 const set = new Set([1, 2, 3]) expect(set).toEqual(new Set([1, 2, 3])) 配列やセットに特定の値が含まれているかどうかを調べるには、toContain を使います。 test(`contain 200`, () =\u0026gt; { const arr = [100, 200, 300] expect(arr).toContain(200) }) 指定した複数の値がすべて含まれているかどうかを調べるには、ちょっと複雑ですが、expect.arrayContaining を組み合わせて次のようにします。 const arr = [1, 2, 3, 4, 5] expect(arr).toEqual(expect.arrayContaining([3, 5, 1])) 例外のスロー ある関数が例外を投げるかどうかを調べるには、toThrow を使用します。 テスト対象の関数が expect 内で呼び出されるように、ラムダ式の形で渡すことに注意してください。 function foo() { throw new Error() } test(`foo throws exeception`, () =\u0026gt; { expect(() =\u0026gt; foo()).toThrow() // 何らかの例外をスローすることを確認 expect(() =\u0026gt; foo()).toThrow(Error) // Error をスローすることを確認 }) その他のマッチャー マッチャーの詳細は、expect API のページで確認することができます。"
},
{
url: "/p/gqo9yoo/",
title: "TypeScript メモ",
date: "2022-04-04T00:00:00Z",
body: "TypeScript メモ"
},
{
url: "/p/ryq6it6/",
title: "NPM パッケージを作るときの package.json ファイルの書き方に関してのメモ",
date: "2022-03-16T00:00:00Z",
body: "NPM パッケージを作るときの package.json ファイルの書き方に関してのメモ name, version フィールド name と version フィールドは、パッケージを公開するつもりがないなら指定する必要はありません。 description フィールド description プロパティは、ユーザーがこのパッケージを探しやすくするための説明文で、npm search を実行したときに表示されます。 パッケージ対象外にするファイル (.npmignore / .gitignore) NPM パッケージを作るときに、.npmignore に書かれたファイルはパッケージングされなくなります。 .npmignore ファイルがない場合は、.gitignore ファイルが代わりに参照されます。 これらの設定にかかわらず、下記のファイルは必ずパッケージングされます。 package.json README（大文字小文字と拡張子は問わない） CHANGES / CHANGELOG / HISTORY（大文字小文字と拡張子は問わない） LICENSE / LICENCE（大文字小文字と拡張子は問わない） NOTICE（大文字小文字と拡張子は問わない） main フィールドで指定されたファイル bin フィールド NPM パッケージで何らかの実行コマンドを提供したいときは、bin フィールドを使用します。 例えば、mycommand コマンドを提供するときは次のように記述します。 { // ... \u0026#34;bin\u0026#34;: { \u0026#34;mycommand\u0026#34;: \u0026#34;./cli.js\u0026#34; } } 単独のコマンドをインストールするための NPM パッケージを作る場合は、bin フィールドのコマンド名を省略して次のように記述できます。 { \u0026#34;name\u0026#34;: \u0026#34;mycommand\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1.2.5\u0026#34;, \u0026#34;bin\u0026#34;: \u0026#34;./path/to/program.js\u0026#34; } 上記の bin フィールドは次のように記述するのと同様に振舞います。 { // ... \u0026#34;bin\u0026#34;: { \u0026#34;mycommand\u0026#34;: \u0026#34;./path/to/program.js\u0026#34; } } repository repository フィールドでは、ソースコードの場所を示すことができます。 例えば、GitHub のリポジトリで管理している場合は次のような感じ。 { // ... \u0026#34;repository\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;git\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;https://github.com/maku77/myapp.git\u0026#34; } } npm 1.1.65 移行は、url 部分は省略して次のように書くことができます。 { // ... \u0026#34;repository\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;git\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;maku77/myapp\u0026#34; } }"
},
{
url: "/p/vgs4dox/",
title: "Firebase の Cloud Functions で定期的に Firestore の集計処理を行う",
date: "2022-03-13T00:00:00Z",
body: "Firebase の Cloud Functions で定期的に Firestore の集計処理を行う 何をするか？ Firestore データベースは、コレクションデータを手軽に格納していくのにはとても便利ですが、全データを集計するような処理は苦手です。 例えば、各ドキュメントに付けられた「タグ」情報をすべて回収して、タグの一覧を生成したい場合、全てのドキュメントを read する必要があるため、ドキュメント数が Firebase の使用料金にダイレクトに効いてきます。 もし、Firestore にドキュメントが追加されるたびに Cloud Functions を起動してこのような集計処理を行うと、凄まじい勢いで課金されてしまいます。 ここでは、Cloud Functions による 集計処理を定期的なスケジュールで起動する ことで、Firestore ドキュメントの read 処理を削減してみます。 もちろん、リアルタイムな更新が必要なデータには使えませんが、カタログ的なデータであれば、定期的なデータ更新で間に合うケースは多いはずです。 事前準備 Firebase コンソール からテスト用のプロジェクトを作成してください。ここでは、自動生成されたアプリ ID を myapp-58138 とします。 Firestore データベースに books コレクションを追加し、次のようなサンプルドキュメントを追加してください。tag フィールドは本来は配列 (tags) であるべきですが、ここではシンプル化のために文字列型のスカラデータとしています。 id: 001 (title: Title1, author: Author1, tag: Tag1) id: 002 (title: Title2, author: Author2, tag: Tag2) id: 003 (title: Title3, author: Author3, tag: Tag3) Firebase CLI をインストール して、firebase コマンドを使用できるようにしてください。作成した関数を Cloud Functions にデプロイするために使います。 プロジェクトの雛形の生成 プロジェクト用のディレクトリを作成します。 $ mkdir myapp $ cd myapp firebase init コマンドを実行して、Cloud Functions をデプロイするための firebase.json ファイルと、関数実装のテンプレート (functions/*) を作成します。 $ firebase init functions 次のような感じで質問に回答していけば OK です。 ESLint のスタイルはプロジェクトによって異なるので、ここでは自動設定しないようにしています。 ? Please select an option: Use an existing project ? Select a default Firebase project for this directory: myapp-58138 (MyApp) ? What language would you like to use to write Cloud Functions? TypeScript ? Do you want to use ESLint to catch probable bugs and enforce style? n ? Do you want to install dependencies with npm now? y 集計用 Cloud Functions の作成 Cloud Functions のテンプレートコードとして、functions/src/index.ts というファイルが生成されているので、このファイルを修正することにします。 ここでは、次のような処理を 60 分おきに実行 するように実装しています。 books コレクション内のすべてのドキュメントからタグ情報を回収（collectTags 関数） タグの配列を meta/booksMeta ドキュメントの tags フィールドに保存（updateMeta 関数） functions/src/index.ts import * as admin from \u0026#39;firebase-admin\u0026#39; import * as functions from \u0026#39;firebase-functions\u0026#39; admin.initializeApp() const booksCollRef = admin.firestore().collection(\u0026#39;books\u0026#39;) const booksMetaRef = admin.firestore().doc(\u0026#39;meta/booksMeta\u0026#39;) /** 定期的にメタ情報を更新する関数。 */ exports.updateMetaFunction = functions .region(\u0026#39;asia-northeast1\u0026#39;) .pubsub.schedule(\u0026#39;every 60 minutes\u0026#39;) .onRun(async (context) =\u0026gt; { console.log(\u0026#39;Start updating tags information of books\u0026#39;) const tags = await collectTags() await updateMeta(tags) console.log(`tags = ${tags.join(\u0026#39;, \u0026#39;)}`) return null }) /** books コレクション内のドキュメントからタグ情報を抽出します。 */ async function collectTags(): Promise\u0026lt;string[]\u0026gt; { const tags = new Set\u0026lt;string\u0026gt;() const snapshot = await booksCollRef.get() snapshot.docs.forEach((doc) =\u0026gt; { const book = doc.data() tags.add(book[\u0026#39;tag\u0026#39;]) }) return [...tags].sort() // Set からソート済み文字列配列に変換 } /** meta コレクションのタグ一覧情報を更新します。 */ async function updateMeta(tags: string[]): Promise\u0026lt;void\u0026gt; { await booksMetaRef.set({ tags }, { merge: true }) } functions ディレクトリ以下で次のようにしてビルド＆デプロイします。 $ npm run deploy （下記と同様です） $ firebase deploy --only functions デプロイが完了するまで数分間待ちます。 参考: 関数のスケジュール設定 | Firebase Documentation 実行結果の確認 Firebase コンソールからプロジェクトを開き、Functions のページを開きます。 今回作成した関数は「60 分おき」に実行されるようにスケジューリングしましたが、関数のオプションメニューから Cloud Scheduler で表示 を選択し、関数を手動で 今すぐ実行 することができます。 ☝️ Cloud Scheduler とは Cloud Functions の スケジュール実行は、GCP (Google Cloud Platform) の Pub/Sub API と Cloud Scheduler API によって実現されています。 Firebase CLI で関数をデプロイすると、これらのリソースは自動的に生成されるので、特に意識して操作する必要はありません。 ただし、上記の例のように、Cloud Scheduler を手動トリガで起動する場合は、GCP 側の画面に遷移して操作する必要があります。 関数が実行されると、Firestore の books コレクションのタグ情報が回収されて、meta/booksMeta ドキュメントに書き込まれます。 Firestore Database のページを開き、データタブを選択すると、tags フィールドにすべてのタグ情報が格納されていることを確認できます。 さらにドキュメントの read 回数を減らすには 今回、Firestore ドキュメントの集計用関数の呼び出し頻度を 1 時間に 1 回としましたが、ドキュメント数が数万件規模になってくると、これでもドキュメントの read 回数が膨大になってしまいます（Firestore の無料枠は、1 日あたり 50,000 read しかありません）。 データ集計用の read 回数をさらに減らすには、次のような方法が考えられます。 Cloud Functions の定期実行時に books コレクションが更新されているかをチェックして、更新されていない場合は 集計処理をスキップする books コレクションの更新時に 集計情報を差分更新する 以下、それぞれの方法を見ていきます。 集計処理をスキップする スケジューリングされた Cloud Functions は定期的に呼び出されますが、このとき books コレクションのデータが何も更新されていないのであれば、全データをスキャンして集計するのは無駄です。 各ドキュメントを更新したときに、updatedAt のようなフィールドを付加しておけば、前回の集計関数が実行されたあとにデータ更新があったかどうかをチェックすることができます（集計データの方にも updatedAt フィールドが必要です）。 ちなみに、クライアントアプリから Firestore のドキュメントを更新するときは、serverTimestamp 関数 の戻り値をフィールド値として設定することで、サーバー側のタイムスタンプを格納することができます。 クライアント PC のシステム時刻は狂っている可能性があるので、このように更新時刻をセットした方が安全です。 import { serverTimestamp, setDoc } from \u0026#34;firebase/firestore\u0026#34;; // ... const bookDoc = { title: \u0026#39;New Title\u0026#39;, author: \u0026#39;New Author\u0026#39;, tag: \u0026#39;New Tag\u0026#39;, updatedAt: serverTimestamp() // サーバー側で更新時刻を詰める } Cloud Functions でメタ情報を更新するときも、メタ情報側に updatedAt フィールドを格納するようにします。 // import { FieldValue } from \u0026#39;firebase-admin/firestore\u0026#39; /** meta コレクションのタグ一覧情報を更新します。 */ async function updateMeta(tags: string[]): Promise\u0026lt;void\u0026gt; { await booksMetaRef.set( { tags, updatedAt: FieldValue.serverTimestamp() }, { merge: true } ) } あとは、定期実行される Cloud Functions の集計関数の中で、上記タイムスタンプを比較して、メタ情報の更新時刻の方が古い場合のみメタ情報を更新するようにします。 更新が必要ない場合は、books コレクション内のドキュメントは 1 つだけ read するだけで済む（最新の updatedAt を持つドキュメントを 1 つだけ read する）ので、Firestore の課金を最小限に抑えられます。 以下にこの対応を入れた Cloud Functions の関数実装を載せておきます。 functions/src/index.ts import * as admin from \u0026#39;firebase-admin\u0026#39; import * as functions from \u0026#39;firebase-functions\u0026#39; import { FieldValue, Timestamp } from \u0026#39;firebase-admin/firestore\u0026#39; admin.initializeApp() const booksCollRef = admin.firestore().collection(\u0026#39;books\u0026#39;) const booksMetaRef = admin.firestore().doc(\u0026#39;meta/booksMeta\u0026#39;) /** 定期的に実行する関数。 */ exports.updateMetaFunction = functions .region(\u0026#39;asia-northeast1\u0026#39;) .pubsub.schedule(\u0026#39;every 60 minutes\u0026#39;) .onRun(async (context) =\u0026gt; { console.log(\u0026#39;Checks if the books are updated\u0026#39;) const needToUpdate = await needToUpdateMeta() if (!needToUpdate) { console.log(\u0026#39;Books are not updated\u0026#39;) return null } console.log(\u0026#39;Start updating meta information of books\u0026#39;) const tags = await collectTags() // console.log(`tags = ${tags.join(\u0026#39;, \u0026#39;)}`) await updateMeta(tags) return null }) /** books コレクション内のドキュメントからタグ情報を抽出します。 */ async function collectTags(): Promise\u0026lt;string[]\u0026gt; { const tags = new Set\u0026lt;string\u0026gt;() const snapshot = await booksCollRef.get() snapshot.docs.forEach((doc) =\u0026gt; { const book = doc.data() tags.add(book[\u0026#39;tag\u0026#39;]) }) return [...tags].sort() // Set からソート済み文字列配列に変換 } /** meta コレクションのタグ一覧情報を更新します。 */ async function updateMeta(tags: string[]): Promise\u0026lt;void\u0026gt; { await booksMetaRef.set( { tags, updatedAt: FieldValue.serverTimestamp() }, { merge: true } ) } /** books コレクションの最終更新日時を取得します。 */ async function lastUpdatedTimeOfBook(): Promise\u0026lt;Timestamp | undefined\u0026gt; { const booksSnap = await booksCollRef .orderBy(\u0026#39;updatedAt\u0026#39;, \u0026#39;desc\u0026#39;) .limit(1) .get() if (booksSnap.empty) { console.error(\u0026#39;updatedAt を持つドキュメントが見つかりません！\u0026#39;) return undefined } const latestBook = booksSnap.docs[0].data() return latestBook[\u0026#39;updatedAt\u0026#39;] } /** メタ情報の最終更新日時を取得します。 */ async function lastUpdatedTimeOfMeta(): Promise\u0026lt;Timestamp | undefined\u0026gt; { const metaSnap = await booksMetaRef.get() return metaSnap.data()?.[\u0026#39;updatedAt\u0026#39;] } /** * メタ情報の更新が必要かどうかを確認します。 * （メタ情報の最終更新後に、books コレクションが更新されていれば true） */ async function needToUpdateMeta(): Promise\u0026lt;boolean\u0026gt; { const bookUpdated = await lastUpdatedTimeOfBook() if (bookUpdated == undefined) { // books コレクションのドキュメントに updatedAt フィールドがなければ何もしない return false } const metaUpdated = await lastUpdatedTimeOfMeta() // メタ情報が books コレクションより古ければ更新する必要がある return metaUpdated == undefined || bookUpdated \u0026gt; metaUpdated } 集計情報を差分更新する Cloud Functions の Cloud Firestore トリガー を使うと、Firestore データベースの任意のドキュメントが更新されたときに関数を呼び出すことができます。 exports.bookUpdated = functions.firestore .document(\u0026#39;books/{bookId}\u0026#39;) .onWrite((change, context) =\u0026gt; { // context.params.bookId == \u0026#34;001\u0026#34;; // ... and ... // change.before.data() == {tag: \u0026#34;Old Tag\u0026#34;, ...} // change.after.data() == {tag: \u0026#34;New Tag\u0026#34;, ...} }); これを利用すると、更新されたドキュメントの内容（更新前と更新後の値）を随時取得できるので、その差分情報を使ってメタ情報をリアルタイムに更新することができます。 ただし、積み上げの形でメタ情報を更新していくことになるので、整合性が保たれるように注意しなければいけません。 タグが完全に削除されたことを検出するためには、メタ情報としてタグの参照カウンタを保存しておくといった変更も必要になるでしょう。 メタ情報としてタグの参照カウンタを持つ tags:\u0026#34;Tag1\u0026#34;: 7\u0026#34;Tag2\u0026#34;: 10\u0026#34;Tag3\u0026#34;: 0 上記の Tag3 のように、そのタグの参照数カウンタが 0 になったらそのタグはもう存在しないとみなします。 このように、差分更新は複雑で慎重に扱う必要があるので、定期的な集計で済むのであればそちらの手法を使った方が簡単です。 ある程度の整合性を保ちながら、メタ情報をリアルタイムに更新していく必要がある場合は、両者の手法を組み合わせて使う方法も考えられます。 例えば、ドキュメントの更新時にメタ情報を差分更新しつつ、1 日 1 回程度の定期的な集計処理で整合性を担保します。"
},
{
url: "/p/5q4fr3d/",
title: "GitHubメモ",
date: "2022-02-27T00:00:00Z",
body: "GitHubメモ"
},
{
url: "/p/un3gu8m/",
title: "GitHub Actions で Hugo サイトをビルドして VPS サーバーに rsync デプロイする",
date: "2022-02-27T00:00:00Z",
body: "GitHub Actions で Hugo サイトをビルドして VPS サーバーに rsync デプロイする 何をするか？ Web サイトのコンテンツを GitHub で管理し、さくらの VPS や、お名前.com の VPS で Web サーバーを運用している場合、GitHub Actions でビルドとデプロイを自動化すると便利です。 ここでは、Web サイトのビルドに Hugo、VPS サーバーへのデプロイに rsync を使う前提で、次のような手順で自動化を進めていきます。 SSH 鍵を作成する（自動デプロイのためパスワードは設定しない） VPS 側に SSH 公開鍵を登録する GitHub Actions のシークレットとして SSH 秘密鍵を登録する GitHub Actions のワークフローを作成し、ビルド (Hugo) とデプロイ (rsync) を自動化する Web サイトのビルドには何を使ってもよいのですが、現時点でおそらく最速の静的サイトジェネレーターである Hugo を例にして説明しています。 GitHub Actions による自動化が完了すると、GitHub の main ブランチに Web サイトコンテンツを push するだけで、Hugo によるビルドと rsync による VPS へのデプロイが自動で行われるようになります。 SSH キーペアを作成して VPS へ公開鍵を登録する rsync コマンドで使用する SSH 鍵を ssh-keygen コマンドで作成しておきます。 GitHub Actions から rsync コマンドを実行するので、SSH 秘密鍵にはパスワードを設定しないようにします。 次の例では、github-actions / github-actions.pub という名前のキーペアを作成しています。 ファイル名は何でも構いません。 $ ssh-keygen Generating public/private rsa key pair. Enter file in which to save the key (/Users/maku/.ssh/id_rsa): github-actions Enter passphrase (empty for no passphrase): ★そのままEnter Enter same passphrase again: ★そのままEnter SSH キーぺアが用意できたら、VPS（Web サーバー）へ公開鍵を登録します。 ssh-id-copy コマンドを使うと、簡単に ~/.ssh/authorized_keys にエントリを追加できます。 $ ssh-copy-id -i github-actions.pub user@example.com ... user@example.com\u0026#39;s password: （リモートホスト側のユーザーのパスワードを入力） ... 参考: ssh-id-copy で SSH の公開鍵をリモートホストに登録する ssh コマンドで接続できるようになっているか確認しておきます。 $ ssh -i github-actions user@example.com ここまでできたら、作成した SSH キーペアを安全な場所に退避しておきます。 特に秘密鍵 (github-actions) の方は厳重に管理してください。 GitHub のシークレットとして SSH 秘密鍵を登録する GitHub Actions から SSH 秘密鍵を参照する必要があるので、先に Repository secret 情報として SSH 秘密鍵の値を登録しておきます。 GitHub の対象リポジトリを開き、Settings タブ → Secrets → Actions と選択します。 New repository secret ボタンを押します。 Name に SSH_PRIVATE_KEY と入力し、Value に秘密鍵ファイル（今回は github-actions ファイル）の内容を貼り付けます。 -----BEGIN OPENSSH PRIVATE KEY----- b3BlbnNzaC1rZXktdjEAAAAABG5vbmUAAAAEbm9uZQAAAAAAAAABAAABlwAAAAdzc2gtcn NhAAAAAwEAAQAAAYEAqBOVBdo3ZL41PXEqvDY7malbuWPur0grpHLlh/sLqY4Wqm64b4W6 ...（省略）... hLY0Rl3sWcrLswb6/j5tu713d0wL+jyXwTJ2G00nVXOE86wmDEsUEQWazZ166sxGP5U7Co RyRi5y7Tx50Z0AAAASbWFrdUBtYWt1bWFjLmxvY2FsAQ== -----END OPENSSH PRIVATE KEY----- VPS の「ユーザー名」や「接続先アドレス」、「コピー先ディレクトリ」も念のため隠しておきたいので、次のようなシークレットも追加で登録しておきます。 Name: SSH_USER、Value: VPSのユーザ名 （例: maku） Name: SSH_HOST、Value: VPSのアドレス （例: www9999xx.sakura.ne.jp） Name: DST_PATH、Value: デプロイ先のホームディレクトリからの相対パス （例: webroot） シークレットを 3 つ登録するのが煩わしい場合は、次のように 1 つのシークレットにまとめてしまってもいいかもしれません。 Name: RSYNC_TARGET、Value: maku@www9999xx.sakura.ne.jp:webroot（例） GitHub Actions のワークフローを作成する Web サイトのコンテンツが格納されている GitHub リポジトリに、GitHub Actions のワークフローを作成します。 ワークフローでは、特定のイベントが発生したときに実行する一連のジョブを定義します。 Actions タブを開き、set up a workflow yourself を選択します。 後述のような内容のワークフローファイルをコミットします。デフォルトのファイル名は main.yml ですが、.github/workflows ディレクトリ以下であれば、ファイル名は何でもかまいません。 これで、main ブランチに Web サイトのコンテンツを push（あるいはトピックブランチからのマージ）するだけで、Hugo によるビルドと rsync によるデプロイが自動で行われるようになります。 \u0026lt;Repo\u0026gt;/.github/workflows/main.yml on:push:branches:[main ]jobs:build-and-deploy:runs-on:ubuntu-lateststeps:- uses:actions/checkout@v2with:submodules:true# Fetch Hugo themes (true OR recursive)fetch-depth:0# Fetch all history for .GitInfo and .Lastmod- name:Setup Hugouses:peaceiris/actions-hugo@v2with:hugo-version:\u0026#39;0.92.1\u0026#39;extended:true# Enable scss- name:Buildrun:hugo --minify- name:Generate ssh keyrun:echo \u0026#34;$SSH_PRIVATE_KEY\u0026#34; \u0026gt; ${{ runner.temp }}/key \u0026amp;\u0026amp; chmod 600 ${{ runner.temp }}/keyenv:SSH_PRIVATE_KEY:${{ secrets.SSH_PRIVATE_KEY }}- name:Deploy with rsyncrun:\u0026gt;rsync -e \u0026#39;ssh -i ${{ runner.temp }}/key -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null\u0026#39; -av --delete public/ ${SSH_USER}@${SSH_HOST}:${DST_PATH}env:SSH_USER:${{ secrets.SSH_USER }}SSH_HOST:${{ secrets.SSH_HOST }}DST_PATH:${{ secrets.DST_PATH }} 以下、このワークフローファイルの内容について細かく見ていきます。 on:push:branches:[main ]まず、この on プロパティで、main ブランチへの push が行われたときに、このワークフローが実行されるように設定しています。 残りは、build-and-deploy ジョブの各ステップの説明になります（今回定義しているジョブは 1 つだけです）。 ジョブ内の各ステップは上から順番に実行されていき、どこかでエラーが発生すると、そこでジョブの実行は停止します。 なので、ビルドに失敗したら、後続のデプロイ処理は実行されません。 - uses:actions/checkout@v2with:submodules:true# Fetch Hugo themes (true OR recursive)fetch-depth:0# Fetch all history for .GitInfo and .Lastmod最初のステップでは、定番の actions/checkout アクションを使って、リポジトリ内のコードをワークスペースにチェックアウトします。 Hugo プロジェクトでは、通常 Git submodules で外部テーマを取り込んで使用するので、submodules: true オプションを指定して、サブモジュールを一緒に取得するようにしています。 - name:Setup Hugouses:peaceiris/actions-hugo@v2with:hugo-version:\u0026#39;0.92.1\u0026#39;extended:true# Enable scsspeaceiris/actions-hugo で Hugo をインストールしています。 Web サイトのスタイル定義に SCSS などのプリプロセッサを使っている場合は、extended バージョンの Hugo が必要になるので、extended: true オプションを指定しています。 - name:Buildrun:hugo --minifyHugo による Web サイトのビルドを行います。 オプションは適宜修正します。 例えば、-F オプションを追加すれば、将来の日付が設定されたコンテンツをビルド対象にできます。 - name:Generate ssh keyrun:echo \u0026#34;$SSH_PRIVATE_KEY\u0026#34; \u0026gt; ${{ runner.temp }}/key \u0026amp;\u0026amp; chmod 600 ${{ runner.temp }}/keyenv:SSH_PRIVATE_KEY:${{ secrets.SSH_PRIVATE_KEY }}この後の rsync コマンド実行時に、SSH 秘密鍵の「ファイル」が必要になるので、ここで作成しています。 前述の手順で SSH_PRIVATE_KEY というシークレットに、SSH 秘密鍵の「値」を格納しておいたので、この値を key という名前の「ファイル」として出力します。 ${{ runner.temp }} は、ビルド時にテンポラリディレクトリ名に置換されます。 - name:Deploy with rsyncrun:\u0026gt;rsync -e \u0026#39;ssh -i ${{ runner.temp }}/key -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null\u0026#39; -r -h --delete public/ ${SSH_USER}@${SSH_HOST}:${DST_PATH}env:SSH_USER:${{ secrets.SSH_USER }}SSH_HOST:${{ secrets.SSH_HOST }}DST_PATH:${{ secrets.DST_PATH }}最後は rsync によるデプロイ処理ですが、ここは若干複雑です。 rsync の -e オプションでは、SSH 秘密鍵ファイルの指定と、known_hosts 関連のエラー対策を行っています。 rsync -e 'ssh -i ${{ runner.temp }}/key -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null' SSH で新しいホストに接続しようとすると、known_hosts への接続先ホスト情報の書き込みが行われるのですが、この処理はデフォルトでユーザーに確認を求めるという挙動になっているので、-o StrictHostKeyChecking=no というオプションで、ユーザー確認なしで書き込むようにします。 さらに、-o UserKnownHostsFile=/dev/null という指定で、実際には known_hosts ファイルには出力せずに、出力を破棄するという振る舞いにしています。 これらを指定しておかないと、rsync コマンド実行時に、Host key verification failed. というエラーが出て、ジョブが停止してしまいます。 このあたりは、おまじないのように入れておけばよいと思います。 rsync の残りの部分では、具体的なファイルのコピー方法などを指定しています。 -av --delete public/ ${SSH_USER}@${SSH_HOST}:${DST_PATH} env: SSH_USER: ${{ secrets.SSH_USER }} SSH_HOST: ${{ secrets.SSH_HOST }} DST_PATH: ${{ secrets.DST_PATH }} ここも用途によって要調整ですが、大体次のような指定を行っています。 -a \u0026hellip; アーカイブモードでコピーする（ディレクトリを再帰的に処理し、タイムスタンプやパーミッション情報を維持する） -v \u0026hellip; ログを詳細に表示する --delete \u0026hellip; コピー元にないファイルをコピー先から削除する public/ \u0026hellip; コピー元のディレクトリパス Hugo のデフォルトの出力ディレクトリは public です。public ディレクトリそのものではなく、ディレクトリ内のファイルだけをコピーしたい場合は、public/ のように末尾にスラッシュが必要なことに注意してください。 ${SSH_USER}@${SSH_HOST}:${DST_PATH} \u0026hellip; VPN のユーザー名、ホスト名、ディレクトリ名 それぞれのプレースホルダーには、GitHub の Repository secret で設定した値が入ります。コピー先のディレクトリ名は、VPN ユーザーのホームディレクトリからの相対パスで指定します。 rsync コマンドの詳細に関しては、下記の記事を参考にしてください。 参考: rsync コマンドで2つのディレクトリを同期する さいごに広告（＾＾ さくらの VPS はこちらから → お名前.com の VPS はこちらから →"
},
{
url: "/p/m4dmu4c/",
title: "Next.js でブラウザ履歴で戻るボタンを表示する (router.back)",
date: "2022-02-22T00:00:00Z",
body: "Next.js でブラウザ履歴で戻るボタンを表示する (router.back) Next.js の next/router モジュールが提供する NextRouter オブジェクトの back メソッド を呼び出すと、ブラウザの履歴に従って 1 つ前のページに遷移することができます。 つまり、ブラウザの「戻る」ボタンを押した場合と同じ振る舞いをします。 NextRouter オブジェクトは、useRouter フックで取得することができます。 次の BackButton コンポーネントはシンプルな「戻る」ボタンを表示し、クリック時に NextRouter#back() を呼び出します。 図: 戻るボタン（標準の button 版） components/BackButton.tsx import { FC } from \u0026#39;react\u0026#39; import { useRouter } from \u0026#39;next/router\u0026#39; export const BackButton: FC = () =\u0026gt; { const router = useRouter() return ( \u0026lt;button alia-label=\u0026#34;戻る\u0026#34; type=\u0026#34;button\u0026#34; onClick={() =\u0026gt; router.back()}\u0026gt; 戻る \u0026lt;/button\u0026gt; ) } 上の例では、素の button コンポーネントを使っていますが、mui (Material-UI) などの UI ライブラリを使えばリッチなボタンを表示できます。 図: 戻るボタン（mui 版） components/BackButton.tsx import { FC } from \u0026#39;react\u0026#39; import { useRouter } from \u0026#39;next/router\u0026#39; import BackIcon from \u0026#39;@mui/icons-material/ArrowBackIosNew\u0026#39; import Button from \u0026#39;@mui/material/Button\u0026#39; export const BackButton: FC = () =\u0026gt; { const router = useRouter() return ( \u0026lt;Button aria-label=\u0026#34;戻る\u0026#34; variant=\u0026#34;contained\u0026#34; onClick={() =\u0026gt; router.back()}\u0026gt; \u0026lt;BackIcon /\u0026gt; \u0026lt;/Button\u0026gt; ) }"
},
{
url: "/p/ter3doz/",
title: "Linuxメモ: Bluetooth 関連コマンドのメモ (hciconfig, bluetoothctl)",
date: "2022-02-20T00:00:00Z",
body: "Linuxメモ: Bluetooth 関連コマンドのメモ (hciconfig, bluetoothctl) Bluetooth デバイスの情報を表示する (hciconfig) hciconfig は、Bluetooth デバイスの情報表示や設定を行うためのコマンドです。 HCI プロトコルで Bluetooth コントローラーと通信します。 hciconfig コマンドが見つからない場合は、bluez パッケージをインストールします。 Ubuntu への bluez パッケージのインストール $ apt update \u0026amp;\u0026amp; apt install -y bluez Bluetooth のデバイス名には hci0 や hci1 といった名前が付けられ、hciconfig コマンドでそれらの一覧を表示することができます。 次の実行例は、Raspberry Pi 4 に USB Bluetooth ドングルを接続した状態で hciconfig コマンドを実行したときの結果です（アドレスは一部伏せてます）。 $ hciconfig hci1: Type: Primary Bus: USB BD Address: 00:E0:4C:XX:XX:XX ACL MTU: 1021:6 SCO MTU: 255:12 UP RUNNING RX bytes:2186 acl:0 sco:0 events:105 errors:0 TX bytes:12322 acl:0 sco:0 commands:105 errors:0 hci0: Type: Primary Bus: UART BD Address: DC:A6:32:XX:XX:XX ACL MTU: 1021:8 SCO MTU: 64:1 UP RUNNING RX bytes:1514 acl:0 sco:0 events:90 errors:0 TX bytes:2061 acl:0 sco:0 commands:90 errors:0 USB ドングルの Bluetooth デバイスが hci1 (Bus: USB)、Raspberry Pi 4 組み込みの Bluetooth デバイスが hci0 (Bus: UART) として認識されているのが分かります。 hciconfig コマンドに -a (--all) オプションをつけて実行すると、詳細情報を表示できます。 $ hciconfig -a hci1: Type: Primary Bus: USB BD Address: 00:E0:4C:XX:XX:XX ACL MTU: 1021:6 SCO MTU: 255:12 UP RUNNING RX bytes:1909 acl:0 sco:0 events:102 errors:0 TX bytes:12313 acl:0 sco:0 commands:102 errors:0 Features: 0xff 0xff 0xff 0xfe 0xdb 0xfd 0x7b 0x87 Packet type: DM1 DM3 DM5 DH1 DH3 DH5 HV1 HV2 HV3 Link policy: RSWITCH HOLD SNIFF PARK Link mode: SLAVE ACCEPT Name: \u0026#39;RTK_BT_5.0\u0026#39; Class: 0x000000 Service Classes: Unspecified Device Class: Miscellaneous, HCI Version: 5.1 (0xa) Revision: 0x97b LMP Version: 5.1 (0xa) Subversion: 0xec43 Manufacturer: Realtek Semiconductor Corporation (93) hci0: Type: Primary Bus: UART BD Address: DC:A6:32:XX:XX:XX ACL MTU: 1021:8 SCO MTU: 64:1 UP RUNNING RX bytes:1514 acl:0 sco:0 events:90 errors:0 TX bytes:2061 acl:0 sco:0 commands:90 errors:0 Features: 0xbf 0xfe 0xcf 0xfe 0xdb 0xff 0x7b 0x87 Packet type: DM1 DM3 DM5 DH1 DH3 DH5 HV1 HV2 HV3 Link policy: RSWITCH SNIFF Link mode: SLAVE ACCEPT Name: \u0026#39;ubuntu\u0026#39; Class: 0x000000 Service Classes: Unspecified Device Class: Miscellaneous, HCI Version: 5.0 (0x9) Revision: 0x156 LMP Version: 5.0 (0x9) Subversion: 0x6119 Manufacturer: Cypress Semiconductor Corporation (305) Bluetooth デバイスをスキャンする (bluetoothctl) bluetoothctl コマンドを使うと、Bluetooth デバイスの検出やペアリングを行うことができます。 bluetoothctl を起動して、その中で scan on サブコマンドを実行すると、周辺の Bluetooth デバイスを検出できます。 exit コマンドで終了できます。 $ bluetoothctl Agent registered [CHG] Controller DC:A6:32:XX:XX:XX Pairable: yes [bluetooth]# scan on Discovery started [CHG] Controller DC:A6:32:XX:XX:XX Discovering: yes [NEW] Device 7B:D4:F8:XX:XX:XX iPhone [NEW] Device A4:83:E7:XX:XX:XX BRAVIA [NEW] Device 27:7D:7C:XX:XX:XX 27-7D-7C-XX-XX-XX [NEW] Device 52:9A:7B:XX:XX:XX 52-9A-7B-XX-XX-XX ... [bluetooth]# exit 次のように直接サブコマンド (scan on) を指定することも可能です。 $ bluetoothctl scan on discoverable on サブコマンドを実行すると、他のデバイスから Bluetooth デバイスを発見できるようになります。 discoverable-timeout \u0026lt;SECONDS\u0026gt; で指定した秒数（デフォルトは 180 秒）が経過すると、自動的に discoverable off されるので注意してください。 $ bluetoothctl discoverable on Changing discoverable on succeeded USB Bluetooth 5.0 ドングル (Realtek RTL8761B) を認識させる Ubuntu Server 20.04 に Bluetooth 5.0 対応の USB ドングル (Realtek RTL8761B) を接続してもうまく認識されませんでした。 hciconfig コマンドを実行すると、下記のように hci1 というデバイス名は出てくるけど、BD Address は認識されておらず、ステータスも DOWN 状態。 $ hciconfig -a hci1: Type: Primary Bus: USB BD Address: 00:00:00:00:00:00 ACL MTU: 0:0 SCO MTU: 0:0 DOWN RX bytes:42 acl:0 sco:0 events:4 errors:0 TX bytes:12 acl:0 sco:0 commands:4 errors:0 Features: 0x00 0x00 0x00 0x00 0x00 0x00 0x00 0x00 Packet type: DM1 DH1 HV1 Link policy: Link mode: SLAVE ACCEPT hciconfig up しようとすると、ファイルが見つからないというエラー。 $ sudo hciconfig hci1 up Can\u0026#39;t init device hci1: No such file or directory (2) dmesg でカーネルログを参照すると、どうも Realtek のファームウェアファイルが足りていないみたいです。 $ dmesg | grep hci1 ... [ 5013.848992] Bluetooth: hci1: RTL: firmware file rtl_bt/rtl8761b_fw.bin not found rtl8761b_fw.bin ファイルの取得方法は、下記に記述されていました。 参考: Realtek RTL8761B - LinuxReviews ダウンロードするファイル \u0026hellip; rtl8761b_config / rtl8761b_fw まず、上記のファイルをカレントディレクトリにダウンロードします。 $ curl -O https://raw.githubusercontent.com/Realtek-OpenSource/android_hardware_realtek/rtk1395/bt/rtkbt/Firmware/BT/rtl8761b_config $ curl -O https://raw.githubusercontent.com/Realtek-OpenSource/android_hardware_realtek/rtk1395/bt/rtkbt/Firmware/BT/rtl8761b_fw ファイル名の末尾に .bin という拡張子がついていないので、リネームしてから /lib/firmware/rtl_bt ディレクトリにコピーします。 $ mv rtl8761b_config rtl8761b_config.bin $ mv rtl8761b_fw rtl8761b_fw.bin $ sudo cp rtl8761b_config.bin /lib/firmware/rtl_bt $ sudo cp rtl8761b_fw.bin /lib/firmware/rtl_bt これで、hciconfig up できるようになります。 $ sudo hciconfig hci1 up BD Address もちゃんと認識されて、UP RUNNING 状態になりました。めでたしめでたし。 $ hciconfig -a hci1 hci1: Type: Primary Bus: USB BD Address: 00:E0:4C:XX:XX:XX ACL MTU: 1021:6 SCO MTU: 255:12 UP RUNNING RX bytes:1909 acl:0 sco:0 events:102 errors:0 TX bytes:12313 acl:0 sco:0 commands:102 errors:0 Features: 0xff 0xff 0xff 0xfe 0xdb 0xfd 0x7b 0x87 Packet type: DM1 DM3 DM5 DH1 DH3 DH5 HV1 HV2 HV3 Link policy: RSWITCH HOLD SNIFF PARK Link mode: SLAVE ACCEPT Name: \u0026#39;RTK_BT_5.0\u0026#39; Class: 0x000000 Service Classes: Unspecified Device Class: Miscellaneous, HCI Version: 5.1 (0xa) Revision: 0x97b LMP Version: 5.1 (0xa) Subversion: 0xec43 Manufacturer: Realtek Semiconductor Corporation (93)"
},
{
url: "/p/8t6hr3d/",
title: "Ansible のメモ",
date: "2022-02-17T00:00:00Z",
body: "Ansible のメモ"
},
{
url: "/p/2mzbmw8/",
title: "Linuxコマンド: ssh-id-copy で SSH の公開鍵をリモートホストに登録する",
date: "2022-02-17T00:00:00Z",
body: "Linuxコマンド: ssh-id-copy で SSH の公開鍵をリモートホストに登録する ssh-id-copy とは SSH で公開鍵認証方式を使ってリモートホストに接続するには、リモートホスト側の ~/.ssh/authorized_keys ファイルに公開鍵を書き込んでおく必要がありますが、ssh-copy-id コマンドを使うと、この作業を一撃で済ますことができます。 ssh-copy-id コマンドは Linux 環境であれば標準でインストールされているはずです。 前提条件として、パスワード認証で SSH 接続できる状態にはしておく必要があります。 （必要があれば）鍵ファイルの作成 (ssh-keygen) 接続元のマシンに次のような秘密鍵＆公開鍵のペアが存在しないときは、ssh-keygen コマンドなどで作成しておきます。 ~/.ssh/id_rsa \u0026hellip; 秘密鍵 ~/.ssh/id_rsa.pub \u0026hellip; 公開鍵（これをリモートホストに登録します） 秘密鍵と公開鍵を生成する $ ssh-keygen Generating public/private rsa key pair. Enter file in which to save the key (/Users/maku/.ssh/id_rsa): （このパスでよければ Enter） Enter passphrase (empty for no passphrase): （鍵のパスワードを入力） Enter same passphrase again: （パスワードを再入力） Your identification has been saved in /Users/maku/.ssh/id_rsa. Your public key has been saved in /Users/maku/.ssh/id_rsa.pub. The key fingerprint is: SHA256:hmOfShQhPstmuGyB3qj0wpdosKXD82ibJs+7Jsb+wSl maku@makumac.local The key\u0026#39;s randomart image is: +---[RSA 3072]----+ | | | | |o.* * . | |O O O = S | |o . . . | |.@ o * . . | |oB * B o | | *E+o+ | |++oOOo | +----[SHA256]-----+ リモートホストに公開鍵を登録する (ssh-copy-id) 公開鍵の準備ができたら、ssh-copy-id コマンドでリモートホストの ~/.ssh/authorized_keys に書き込みます。 最初は、-n オプションをつけて dry-run 実行してみるのがよいです。 実際には実行されませんが、どの公開鍵が登録されるかを確認できます。 dry-run 実行 $ ssh-copy-id -n user@192.168.1.20 /usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: \u0026#34;/Users/maku/.ssh/id_rsa.pub\u0026#34; /usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed /usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys =-=-=-=-=-=-=-= Would have added the following key(s): ssh-rsa AAAAB3NzaCn21Bq...(省略)...Qu4cIuQFG92hxMqU= maku@makumac.local =-=-=-=-=-=-=-= 公開鍵ファイルは、デフォルトで ~/.ssh/id*.pub というファイルが検索されて使用されますが、-i オプションで明示することもできます。 $ ssh-copy-id -n -i ~/.ssh/id_rsa_XXX.pub user@192.168.1.20 登録内容に問題なさそうであれば、今度は -n オプションを外して実際に実行します。 ここでは、まだパスワード認証が使われるので、リモートホスト側のユーザーのパスワードを入力する必要があります。 $ ssh-copy-id user@192.168.1.20 /usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: \u0026#34;/Users/maku/.ssh/id_rsa.pub\u0026#34; /usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed /usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys user@192.168.1.20\u0026#39;s password: （リモートホストのユーザーのパスワードを入力） Number of key(s) added: 1 Now try logging into the machine, with: \u0026#34;ssh \u0026#39;user@192.168.1.20\u0026#39;\u0026#34; and check to make sure that only the key(s) you wanted were added. これで、ssh コマンド実行時に SSH 鍵を使って（公開鍵認証方式で） 接続するようになります。 $ ssh user@192.168.1.20 Enter passphrase for key \u0026#39;/Users/maku/.ssh/id_rsa\u0026#39;: （SSH鍵のパスワードを入力） ssh-copy-id で -i オプションを使って標準と異なる名前の公開鍵を登録した場合は、ssh で接続するときも -i オプションを使って対となる秘密鍵を指定します。 $ ssh -i ~/.ssh/id_rsa_XXX user@192.168.1.20 SSH 鍵のパスワード入力に失敗すると、従来のリモートホストのパスワード認証が実行されますが、この振る舞いは後述のように無効化することができます。 パスワード認証を無効にする SSH 鍵でリモートホストに接続できるようになったら、パスワード認証による接続は無効にしておくと安全です。 次のように vim や nano エディタで SSH デーモンの設定ファイルを開き、 $ sudo vim /etc/ssh/sshd_config 下記の行を修正して保存します。 PasswordAuthentication yes ↓ PasswordAuthentication no あとは、SSH デーモンを再起動して反映します。 $ sudo systemctl restart ssh （おまけ）ssh-copy-id を使わずに authorized_keys に登録する場合 何らかの理由で ssh-copy-id コマンドが使えない場合は、次のようにして ssh コマンド経由で公開鍵を登録することができます。 $ cat ~/.ssh/id_rsa.pub | ssh user@192.168.1.20 \u0026#34;cat \u0026gt;\u0026gt; ~/.ssh/authorized_keys\u0026#34; こちらでも簡単に登録できますが、~/.ssh ディレクトリが存在しない場合は先に作成しておくなどの対応が必要になってくるので、できれば ssh-copy-id コマンドを使った方がよいです。"
},
{
url: "/p/dw9jt4e/",
title: "Firebase Auth で admin ユーザーのみ Firestore に書き込みできるようにする",
date: "2022-02-13T00:00:00Z",
body: "Firebase Auth で admin ユーザーのみ Firestore に書き込みできるようにする 何をするか？ ユーザーデータの管理に Firestore を使うと、Web アプリやモバイルアプリから手軽にデータを読み書きできるので非常に便利です。 一方で、データの書き込み (write) を誰にでもできるようにしていると、大切なデータを勝手に書き換えられてしまいます。 Firestore の危険なセキュリティルールの例 rules_version = \u0026#39;2\u0026#39;; service cloud.firestore { match /databases/{db}/documents { match /{doc=**} { allow read, write: if true; // 危険！ } } } ここでは、Firestore へのデータ書き込みを admin ユーザー（自分）だけに制限してみます。 なお、FirebaseApp インスタンスの初期化 (initializeApp) や、Firebase Auth の導入 自体は完了しているものとします。 ユーザーごとにアクセス制御をしたいので、Firebase Auth による認証処理はほぼ必須になります。 とはいえ、Firebase アプリの認証まわりの実装はとても簡単で、最初に FirebaseApp インスタンスを初期化して、UI ライブラリ（react-firebaseui など）を使ってサインイン画面を出してユーザーにサインインさせるさせるだけです。 サインイン状態は Firebase が内部で管理してくれるので、Firestore API の呼び出し時には特に意識する必要はありません。 Firestore サービス側のセキュリティルールで、認証状態を意識した制限をかければよいだけです。 何をもって admin ユーザーとするか？ Firestore のデータ書き込み (write) を admin ユーザーだけに制限するといっても、そもそも何をもって admin ユーザーとみなすのかという問題があります。 このあたりは、ひとことで言うと「自由」です。 例えば、次のようなやり方が考えられます。 特定のユーザー ID (UID) を持つユーザーを admin とみなす Firestore の users コレクション以下にユーザー情報（ドキュメント）を格納しておいて、そのドキュメントに admin: true というデータが含まれていたら admin ユーザーとみなす 1 つ目の方法はちょっと横着なやり方ですが (^^；、とりあえず自分にだけ write 権限を与えておきたい、というときに手っ取り早いかもしれません。 よくサンプルコードなどで見かけるのは、後者のように各ユーザーの情報を保持する Firestore コレクションを用意する方法です。 Web サイトにサインイン機能を付けると、詳細なユーザー情報を Firestore で管理したくなります。 そのユーザー情報の中に、admin フラグを持たせるということですね。 admin ユーザーにのみ Firestore の write 権限を付ける 特定の UID をもつユーザーを admin とする方法 まず、Firebase Auth のページで、対象とするユーザーの UID を確認しておきます。 あとは、Firestore のセキュリティルールで、そのユーザーがアクセスしてきたときのみ、write アクセスを許可するように設定してやります。 下記の例では、アクセスしてきたユーザーが admin ユーザーかどうかを判断するための isAdmin() ユーザー関数を定義しています。 isAdmin() が true を返した場合に、/books コレクション内のドキュメントへの書き込み (write) を許可しています。 rules_version = \u0026#39;2\u0026#39;; service cloud.firestore { function isAdmin() { return request.auth != null \u0026amp;\u0026amp; request.auth.uid == \u0026#39;E9pvOlKxcHUd7RuekoGFiEj4XIW2\u0026#39; } match /databases/{db}/documents { match /books/{doc=**} { allow read; allow write: if isAdmin(); } } } Firestore の users コレクションで admin フラグを管理する方法 Firestore に users コレクションを作成して、次のような UID をドキュメント ID としたデータを入れておき、その中の admin フラグを使って admin ユーザーかどうかを管理する方法です。 セキュリティルールの中では、isAdmin 関数をちょっと書き換えて、users コレクションのデータを参照するようにします。 あと、データベース名の変数 (db) を参照するために、isAdmin 関数の階層をひとつ下に移動していることに注意してください。 rules_version = \u0026#39;2\u0026#39;; service cloud.firestore { match /databases/{db}/documents { function isAdmin() { return request.auth != null \u0026amp;\u0026amp; exists(/databases/$(db)/documents/users/$(request.auth.uid)) \u0026amp;\u0026amp; get(/databases/$(db)/documents/users/$(request.auth.uid)).data.admin == true; } match /books/{doc=**} { allow read; allow write: if isAdmin(); } } } もう少しシンプルな方法としては、users の代わりに admins コレクションを用意して、そこに対象ユーザーのドキュメントが存在するときは admin ユーザーとみなすというやり方も考えられます。 rules_version = \u0026#39;2\u0026#39;; service cloud.firestore { match /databases/{db}/documents { function isAdmin() { return request.auth != null \u0026amp;\u0026amp; exists(/databases/$(db)/documents/admins/$(request.auth.uid)) } match /books/{document=**} { allow read; allow write: if isAdmin(); } } } この場合は、アクセスしてきたユーザーの UID が E9pv... だとしたら、Firestore に /admins/E9pv... というドキュメントが存在すれば admin ユーザーだとみなします。 ドキュメントの中身は空っぽで構いません。 以上、認証済みユーザーによるアクセス制御方法をいくつか見てきましたが、いずれの方法も簡単かつ柔軟に設定できることがわかると思います。 この手軽さに慣れてしまうと、なにかと複雑な AWS には近づきたくなくなっちゃいます(^^;"
},
{
url: "/p/bw9kv6g/",
title: "Firestore ドキュメントを TypeScript のユーザー定義型オブジェクトに変換する (withConverter)",
date: "2022-02-12T00:00:00Z",
body: "Firestore ドキュメントを TypeScript のユーザー定義型オブジェクトに変換する (withConverter) Firestore の JavaScript SDK でドキュメントを参照するときに、withConverter 関数を組み合わせて使用すると、ドキュメントの読み書きを行うときに、TypeScript のユーザーデータ型との変換処理を自動的に呼び出すことができます。 例えば、次のような Book 型のデータを、Firestore の books コレクションに保存するとします。 export type Book = { id: string title: string price?: number } Firestore ドキュメントとユーザーデータ型の変換処理は、次のように FirestoreDataConverter インタフェースを実装する形で定義します。 今回は Book 型に id プロパティを含めましたが、Firestore はドキュメントの ID をパス情報として表現するので、そのあたりの変換処理に注意する必要があります。 // import { // DocumentData, FirestoreDataConverter, QueryDocumentSnapshot, // SnapshotOptions, serverTimestamp } from \u0026#39;firebase/firestore\u0026#39; /** * Firestore のドキュメントと Book オブジェクトの型変換を行います。 */ const bookConverter: FirestoreDataConverter\u0026lt;Book\u0026gt; = { /** * Book オブジェクトを Firestore ドキュメントデータへ変換します。 */ toFirestore(book: Book): DocumentData { // id は Firestore のパスで表現されるのでドキュメントデータには含めない。 // 下記の updatedAt のように、自動で更新時刻のフィールドを追加することも可能。 return { title: book.title, price: book.price, updatedAt: serverTimestamp(), } }, /** * Firestore ドキュメントデータを Book オブジェクトへ変換します。 */ fromFirestore(snapshot: QueryDocumentSnapshot, options: SnapshotOptions): Book { const data = snapshot.data(options) // Book オブジェクトの id プロパティには Firestore ドキュメントの id を入れる。 return { id: snapshot.id, title: data.title, price: data.price, } }, } あとは、次のように、doc や collection で Firestore のデータを参照するときに、withConverter で上記のコンバーターオブジェクトを渡してやります。 /** Firestore の books コレクションにドキュメントを追加する。 */ export async function addBook(book: Book) { const db = getFirestore() const docRef = doc(db, \u0026#39;books\u0026#39;, book.id).withConverter(bookConverter) await setDoc(docRef, book) } /** Firestore から books コレクションを読み込む。 */ export async function getBooks(): Promise\u0026lt;Book[]\u0026gt; { const db = getFirestore() const collRef = collection(db, \u0026#39;/books\u0026#39;).withConverter(bookConverter) const snapshot = await getDocs(collRef) return snapshot.docs.map((doc) =\u0026gt; doc.data()) } これで、実際に setDoc や getDocs でデータアクセスするときに、自動的にデータ変換処理が行われるようになります。"
},
{
url: "/p/9t6gr3c/",
title: "TypeScriptの型: 既存の型をちょっと変えた型を作る（ユーティリティ型）",
date: "2022-02-08T00:00:00Z",
body: "TypeScriptの型: 既存の型をちょっと変えた型を作る（ユーティリティ型） ユーリティティ型とは？ TypeScript には、既存の型を加工して新しい型を生み出す ユーティリティ型 (Utility Types) というものが用意されています。 例えば、Partial を使用すると、ある型のプロパティをすべてオプショナルにした型を簡単に作ことができます。 以下、使いやすそうなユーティリティ型を紹介しておきます。 ユーティリティ型 概要 Omit 指定したプロパティを取り除く Pick 指定したプロパティだけ抽出する Partial 全プロパティをオプショナルにする Required 全プロパティを必須にする Readonly 全プロパティを readonly にする ユーティリティ関数の使用例 Omit / Pick \u0026hellip; プロパティを削除・抽出する Omit を使用すると、既存の型から指定したプロパティを取り除いた型を作成できます。 次の例では、Book 型から id プロパティを取り除いて、新しい NewBook 型を定義しています。 type Book = { id: string title: string price: number } type NewBook = Omit\u0026lt;Book, \u0026#39;id\u0026#39;\u0026gt; // 上記は以下と同様 // type NewBook = { // title: string // price: number // } // 使用例: 新しい書籍を登録する関数（id は自動生成する想定） function addBook(book: NewBook): Book { // ... } Pick は逆に、指定したプロパティのみを持つ型を作りたいときに使用します。 次の例では、title と price プロパティのみを持つ新しい NewBook 型を定義しています。 type NewBook = Pick\u0026lt;Book, \u0026#39;title\u0026#39; | \u0026#39;price\u0026#39;\u0026gt; Partial / Required \u0026hellip; プロパティをオプショナル・必須にする Partial を使うと、既存の型のすべてのプロパティをオプショナルにした新しい型を生成できます。 type Game = { title: string genre: string price?: number } type GamePartial = Partial\u0026lt;Game\u0026gt; // type GamePartial = { // title?: string // genre?: string // price?: number // } // 使用例: 指定したフィールドで検索する関数 async function findGames(condition: Partial\u0026lt;Game\u0026gt;): Promise\u0026lt;Game[]\u0026gt; { // ... } Required は逆に、すべてのプロパティを必須にした型を生成します。 type GameRequired = Required\u0026lt;Game\u0026gt; // type GameRequired = { // title: string // genre: string // price: number // } Readonly \u0026hellip; プロパティを readonly にする Readonly を使うと、既存の型のすべてのプロパティを読み取り専用にした新しい型を生成できます。 type Game = { title: string genre: string price?: number } type ReadonlyGame = Readonly\u0026lt;Game\u0026gt; // type Game = { // readonly title: string // readonly genre: string // readonly price?: number // }"
},
{
url: "/p/7q3dnx8/",
title: "Linuxメモ: Netplan で Ubuntu のネットワーク設定を行う",
date: "2022-01-20T00:00:00Z",
body: "Linuxメモ: Netplan で Ubuntu のネットワーク設定を行う Netplan とは Netplan は Linux のネットワーク設定を簡潔な YAML ファイルで行う仕組みで、Ubuntu 18.04 以降（正確には 17 以降）で採用されています。 昔の Ubuntu/Debian で使用されていた /etc/network/interfaces という設定ファイルはもう使われていません。 実際のネットワーク管理は、バックエンドで動作する NetworkManager や systemd-networkd といったネットワークデーモンが行うのですが、Netplan は YAML 設定ファイルの内容を適切な形に変換して、これらのネットワークデーモンに渡してくれます。 つまり、バックエンドでどのようなネットワークデーモンが動いているかを意識せずに、統一されたわかりやすい YAML ファイルでネットワーク設定を行うことができます。 Netplan は次のように振る舞います。 システム起動時に Netplan が設定ファイル (/etc/netplan/*.yaml) を読み込んで、各ネットワークデーモン用の設定値を /run 以下へ書き出す 各ネットワークデーモンが渡された情報に基づいてネットワーク設定を行う 図: netplan.io のサイトより バックエンドのネットワークデーモンとして何を使うかは、設定ファイルの renderer 部分で指定できるようになっていますが、デフォルトでは次のように動作します。 Wifi や 無線 WAN/LTE の設定 \u0026hellip; NetworkManager に渡される それ以外のネットワーク（有線LANなど）の設定 \u0026hellip; networkd に渡される よって、通常はどのネットワークデーモンを使うかを明示する必要はありません。 設定ファイルの読み込まれる順序 Netplan はすべての /etc/netplan/*.yaml ファイルを読み込みます。 複数のファイルが存在する場合は、ファイル名のアルファベット順に読み込まれ、後に読み込まれたファイルの設定値が優先的に使用されます。 例えば、 /etc/netplan/50-cloud-init.yaml /etc/netplan/99-custom.yaml というファイルがある場合、50-cloud-init.yaml で設定された値は 99-custom.yaml の設定値によって上書きされます。 ちなみに、Linux のインストール方法によって、最初から 50-cloud-init.yaml といった設定ファイルが存在することがありますが、これらのファイルを編集してはいけません。 50-cloud-init.yaml は別のモジュール（この場合は cloud-init）が生成しているファイルであり、このファイルを編集しても、将来的に上書きされてしまう可能性があります。 そのため、ネットワーク設定をカスタマイズするときは、それらのファイルよりも後に読み込まれる 99-custom.yaml といった別名の設定ファイルを作成します（名前は何でも OK です）。 設定例 Netplan の公式サイトで設定例や、各項目の意味を参照できます。 https://netplan.io/examples/ \u0026hellip; 設定例 https://netplan.io/reference/ \u0026hellip; 各項目の意味 例えば、次のような感じで設定します。 有線 LAN の eth0 に DHCP でアドレス割り当て /etc/netplan/99-custom.yaml network:version:2ethernets:eth0:dhcp4:trueoptional:true ルートプロパティの network と、その直下の version の指定はお決まりです。 有線 LAN などの設定は ethernets の下に記述していきます。 Wi-Fi 接続の wlan0 に固定 IP アドレスを割り当て /etc/netplan/99-custom.yaml network:version:2wifis:wlan0:dhcp4:falseaccess-points:\u0026#34;YOUR-SSID\u0026#34;:password:\u0026#34;********\u0026#34;addresses:[192.168.1.20/24]nameservers:addresses:[192.168.1.1,8.8.8.8]routes:- to:defaultvia:192.168.1.1 この例では、無線 LAN で 192.168.1.20 という固定 IP アドレスを使用するよう設定しています。 DNS サーバーと、デフォルトゲートウェイには 192.168.1.1 を指定しています。 設定を反映する YAML ファイルを編集したら、次のように実行してネットワーク設定を反映できます。 $ sudo netplan apply NetworkManager や networkd に設定が反映されるまで数秒かかります。"
},
{
url: "/p/n9kv7gq/",
title: "Raspberry Pi に Ubuntu 20.04 を入れて WiFi 接続できるようにする",
date: "2022-01-20T00:00:00Z",
body: "Raspberry Pi に Ubuntu 20.04 を入れて WiFi 接続できるようにする ひょんなことから、Ubuntu Server の入った Raspberry Pi 4 が必要になったので、セットアップ手順をメモしておきます。 なんか昔より簡単にインストールできるようになっててビックリしました。 何をするか？ ここでは、Raspberry Pi 4 Model B に Ubuntu 20.04 をインストールして、Wi-Fi 経由の SSH ログインができるところまでセットアップします。 なお、有線 LAN では一度も接続せずに Wi-Fi 接続できるようにします。 ただし、初期設定のために HDMI でのディスプレイ出力は必要になります。 準備するもの Raspberry Pi 4 （たぶん別のバージョンでもOK） SD カードに OS をインストールするための PC HDMI ケーブルとディスプレイと USB キーボード SD カードに OS をインストール 公式の Raspberry Pi Imager というソフトウェアを使うと、ものすごく簡単に SD カードに各種 OS をインストールできます。 Raspberry Pi Imager を起動したら、次のようにポチポチやっていくだけでインストール完了です。 Operating System の項目で、Other general purpose OS → Ubuntu → Ubuntu Server 20.04 LTS (64-bit server OS) のように選択 Storage の項目で、書き込み対象の SD カードを選択 WRITE ボタンを押してしばらく待つ あとは、この SD カードを Raspberry Pi に挿入して電源を入れれば Ubuntu OS が起動します。 お手軽すぎる。。。 Wi-Fi（無線LAN）に接続する Raspberry Pi を HDMI ケーブルでディスプレイに接続して電源を入れます。 Ubuntu が起動するので、初期ユーザー ubuntu、初期パスワード ubuntu でログインします。 ubuntu login: ubuntu Password: ****** 初回ログイン時にパスワードの変更を促されるので、適当なパスワードを設定します。 Ubuntu のネットワーク設定は Netplan の仕組み で行われるため、そのための YAML ファイルを作成します。 $ sudo vim /etc/netplan/99-custom.yaml /etc/netplan/99-custom.yaml network:version:2wifis:wlan0:dhcp4:trueaccess-points:\u0026#34;\u0026lt;SSID\u0026gt;\u0026#34;:password:\u0026#34;********\u0026#34; 設定ファイル中の SSID とパスワードの部分は、実際に使用している Wi-Fi アクセスポイントのものに置き換えてください。 YAML ファイルを作成したら、次のようにしてネットワーク設定を反映します。 $ sudo netplan apply 数秒待てば Wi-Fi 接続できるようになっているはずなので、apt で各種パッケージを更新しておきます。 $ sudo apt update $ sudo apt upgrade ...しばらく待つ... 大量のパッケージが更新されるので、ここでいったん再起動しておくとよいかもです。 $ sudo shutdown -r now SSH 接続できるようにする Raspberry Pi 上で SSH サーバーを起動しておけば、ノート PC などからリモート接続できるようになります。 次のようにして、apt で SSH サーバー (openssh-server) をインストールして起動します。 ついでに IP アドレス確認用の ifconfig コマンドなどを使えるように、net-tools パッケージもインストールしておきます。 $ sudo apt install openssh-server $ sudo apt install net-tools $ sudo systemctl start ssh # SSHサーバーを起動 SSH サーバーが起動したら、ifconfig コマンドあるいは ip a コマンドで IP アドレスを確認します。 $ ifconfig あとは、この IP アドレスに対して、ノート PC などから SSH 接続できれば成功です。 macOS などであれば、ssh コマンドは最初からインストールされています。 $ ssh ubuntu@192.168.1.14 この時点で Raspberry Pi をリモート操作できるようになったので、ディスプレイは必要なくなります。 デフォルトではパスワード認証で SSH 接続するようになっていますが、できれば SSH 鍵を使った公開鍵認証方式で接続できるようにしましょう。 参考: ssh-id-copy で SSH の公開鍵をリモートホストに登録する 固定 IP アドレスにしておく 前述のネットワーク設定では DHCP で IP アドレスを割り当てるようにしましたが、SSH 接続での使用を前提とするなら、固定の IP アドレスを割り当てておいた方がよさそうです。 Netplan の設定ファイルで固定 IP アドレスを指定する場合、DHCP を無効 (dhcp4: false) にし、代わりに次のような項目を設定します。 IP アドレス (addresses) DNS サーバー (nameservers) デフォルトゲートウェイ (routes) 次の例では、固定 IP アドレスとして 192.168.1.20、DNS サーバーとデフォルトゲートウェイとして 192.168.1.1 を指定しています。 念の為、セカンダリ DNS に Google Public DNS (8.8.8.8) を指定してあります。 /etc/netplan/99-custom.yaml network:version:2wifis:wlan0:dhcp4:noaccess-points:\u0026#34;\u0026lt;SSID\u0026gt;\u0026#34;:password:\u0026#34;********\u0026#34;addresses:[192.168.1.20/24]nameservers:addresses:[192.168.1.1,8.8.8.8]routes:- to:defaultvia:192.168.1.1 次のようにネットワーク設定を反映して完了です。 $ sudo netplan apply IP アドレスを変更した場合は、ここで SSH 接続が切れるので、新しい IP アドレスで接続しなおします。 $ ssh ubuntu@192.168.1.20"
},
{
url: "/p/2kw8is3/",
title: "読書メモ『やっぱりおまえはバカじゃない』吉野敬介",
date: "2022-01-11T00:00:00Z",
body: "読書メモ『やっぱりおまえはバカじゃない』吉野敬介 やっぱりおまえはバカじゃない 吉野敬介 小学館 受験生が「やる気」を出すための本。アツい、アツすぎる。 著者の吉野敬介氏の経歴が素敵で、中学と高校で、ずっと不良、暴走族のリーダー をやってきたんだけど高校の終わりに急に大学に行きたくなって、文字通り本当に死ぬ気で勉強してみごと志望大学に合格したという人です（実話）。 ずっと予備校の講師をしてきて、2020年にはYouTuberになったみたいです。 そういえば私が高校生だったころ、吉野氏の詳細は知らなかったけど、『吉野のピタリとでる古文単語』略してピコタンという本は確かにまわりに存在してた記憶があります。 その本自体はたぶん買ってないのですけど、ピコタンって響きが面白かったので、別の単語集の表紙をすげかえて、自分でピカチュウとかピコピコリナちゃんの絵を描いて、「ピカタン」とか「ピコタン」と呼んでいました（どうでもいいですね^^;） 著者の経験の中で、試験の終わりでぶっ倒れたというのは、ちょっとやりすぎな気もしましたが、人間やればできるんだという気持ちにさせてくれる本です。 基本的にモチベーションを上げるための本だと思いますが、妙に実践的な内容もチラホラ。 形容詞や形容動詞は、どんなことがあっても辞書を引かない。これがわからないということは、ぜんぜん文章が読めていないということだからだ。 \u0026hellip; いっぽう、動詞と名詞は完全に頭に叩き込んでおこうと思い、辞書を引に引きまくった。 \u0026hellip; 訳を紙に書いてみる。かならず紙に書かなければだめだ。頭で思っていることと実際思っていることとは違うからだ。なんとなくわかるというのは、わかっていないのと同じこと。 ところどころ挟まる不良時代のエピソードで、「バカだなぁ」と思わせつつ、物事への打ち込み方の核心をついてきたり。 オレには東大の大学院へ行くなどという芸当はできないが、オレがやったのと同じことを「やれるもんならやってみろ」という自信はある。 \u0026hellip; スタート地点がちがうからといって、劣等感に陥ってもしかたがないじゃないか、ということだ。客観的に見たら、競争するだけムダに見えるかもしれないが、受験をするときの最大の敵は自分だということを忘れちゃいけない。やる気と集中力があればなんとかなるんだ。 世の中には自分よりすごい人、環境にめぐまれた人なんてたくさんいます。 そんな中で達成感を味わうには、著者のように「オレほどがんばれるならやってみろ！」というくらい物事に打ち込む姿勢が大切ですね。 仕事でも遊びでも、とにかくがんばろうという気持ちにさせてくれる本です。"
},
{
url: "/p/35odek9/",
title: "読書",
date: "2022-01-11T00:00:00Z",
body: "読書"
},
{
url: "/p/pamw7hr/",
title: "Firebase CLI でコマンドラインから Firebase を操作する",
date: "2022-01-08T00:00:00Z",
body: "Firebase CLI でコマンドラインから Firebase を操作する Firebase CLI のインストール Firebase CLI をインストールすると、firebase というコマンドで Firebase の各種サービスを操作できるようになります。 インストール用に各 OS 用のバイナリが用意されていますが、どの OS でも共通で使える Node.js の npm でインストールすることをお勧めします。 $ npm install -g firebase-tools Firebase CLI をバージョンアップしたいときも同じコマンドでいけます。 インストールが終わったら、firebase コマンドを実行できるか確認しておきます。 $ firebase --version 10.0.1 firebase コマンドの使い方 firebase コマンドは、firebase \u0026lt;サブコマンド\u0026gt; という形で使用します。 firebase コマンドを引数なしで実行するとヘルプを表示できますが、公式サイトのコマンドリファレンス の方がわかりやすいです。 以下に、いくつかのサブコマンドを紹介しておきます。 サインイン (firebase login) Firebase プロジェクトの情報を取得するには、まずは Firebase アカウントにサインインしておく必要があります。 次のように実行すると、Web ブラウザが開き、Firebase にサインインできます。 $ firebase login サインインとアクセス権限が終わったら、Web ブラウザは閉じて大丈夫です。 Firebase プロジェクトの一覧を取得する (projects:list) $ firebase projects:list ✔ Preparing the list of your Firebase projects ┌──────────────────────┬──────────────┬────────────────┬──────────────────────┐ │ Project Display Name │ Project ID │ Project Number │ Resource Location ID │ ├──────────────────────┼──────────────┼────────────────┼──────────────────────┤ │ MyApp1 │ myapp1-12345 │ 123456789001 │ asia-northeast1 │ ├──────────────────────┼──────────────┼────────────────┼──────────────────────┤ │ MyApp2 │ myapp2-12345 │ 123456789002 │ asia-northeast1 │ └──────────────────────┴──────────────┴────────────────┴──────────────────────┘ 2 project(s) total. firebase コマンドで操作対象のプロジェクトを指定するときは、--project オプションで上記の Project ID の欄に表示されている ID を指定します。 ただし、firebase init で初期化したディレクトリ内でコマンド実行する場合は、通常は --project オプションは省略できます（デフォルトで操作対象とする Firebase プロジェクトが .firebaserc に保存されるため）。 参考: Firebase の Cloud Functions で Hello World Firestore のインデックス情報を取得する (firestore:indexes) $ firebase --project myapp1-12345 firestore:indexes Firebase Auth のユーザーリストを取得する (auth:export) $ firebase --project myapp1-12345 auth:export users.json Exporting accounts to users.json ✔ Exported 3 account(s) successfully. 出力ファイル名の拡張子によって、JSON 形式あるいは CSV 形式で出力されます。 --format json のように、明示的にフォーマットを指定することもできます。 Functions の一覧を取得する (functions:list) $ firebase --project myapp1-12345 functions:list ┌────────────┬─────────┬─────────────┬────────┬──────────┐ │ Function │ Trigger │ Location │ Memory │ Runtime │ ├────────────┼─────────┼─────────────┼────────┼──────────┤ │ helloWorld │ https │ us-central1 │ 256 │ nodejs16 │ └────────────┴─────────┴─────────────┴────────┴──────────┘"
},
{
url: "/p/yfov4bi/",
title: "Firebase Admin SDK で Firebase の各種サービスを操作する",
date: "2021-12-31T00:00:00Z",
body: "Firebase Admin SDK で Firebase の各種サービスを操作する Firebase Admin SDK とは Firebase Admin SDK を使うと、Firebase の管理者（おそらくあなた）用に提供された API キーを使って、Firebase 上のデータを管理することができます。 例えば、ローカル PC にある JSON データを解析して Firestore データベースのドキュメントとして登録するといったことができます。 Firebase Admin SDK がサポートしている言語としては、Node.js、Java、Python、Go、C# などがありますが、Node.js から順番に機能提供されていくようです。 ここでは Node.js (TypeScript) で Firestore の API を呼び出してみます。 ☝️ サーバーライブラリとクライアントライブラリ Firebase Admin SDK はしばしば サーバーライブラリ とも呼ばれます。 一方で、Web アプリやモバイルアプリなどで使う SDK は クライアントライブラリ と呼ばれ、Firebase が提供するセキュリティルールという仕組みでアクセス制御を行います。 具体的には、Firebase Auth などでユーザー認証を行うことで、各クライアントに対してアクセス権限を付与します。 これに対して、Firebase Admin SDK はあらかじめローカルに保持しているアクセスキーを使って API を呼び出すので、セキュリティルールを無視した特権アクセスが可能です。 秘密鍵のダウンロード Firebase Admin SDK を使って API 呼び出しを行うには、秘密鍵（API キー）を取得する必要があります。 Firebase コンソール にサインインして、対象のプロジェクトを選択する。 プロジェクトの設定 を開き、サービスアカウント タブを選択する。 新しい秘密鍵の生成 をクリックして、秘密鍵ファイル (.json) をダウンロード。 ダウンロードされる .json ファイルは、次のような感じの内容になっています。 このファイルは、Credential ファイル や Configuration ファイル と呼ばれます。 myapp-12345-firebase-adminsdk-xxxxx.json { \u0026#34;type\u0026#34;: \u0026#34;service_account\u0026#34;, \u0026#34;project_id\u0026#34;: \u0026#34;myapp-12345\u0026#34;, \u0026#34;private_key_id\u0026#34;: \u0026#34;14b01f11bc7f484d42fab494dd0bdb7818c93f3b\u0026#34;, \u0026#34;private_key\u0026#34;: \u0026#34;-----BEGIN PRIVATE KEY-----\\n ... \\n-----END PRIVATE KEY-----\\n\u0026#34;, \u0026#34;client_email\u0026#34;: \u0026#34;firebase-adminsdk-xxxxx@myapp-12345.iam.gserviceaccount.com\u0026#34;, \u0026#34;client_id\u0026#34;: \u0026#34;123456789012345678901\u0026#34;, \u0026#34;auth_uri\u0026#34;: \u0026#34;https://accounts.google.com/o/oauth2/auth\u0026#34;, \u0026#34;token_uri\u0026#34;: \u0026#34;https://oauth2.googleapis.com/token\u0026#34;, \u0026#34;auth_provider_x509_cert_url\u0026#34;: \u0026#34;https://www.googleapis.com/oauth2/v1/certs\u0026#34;, \u0026#34;client_x509_cert_url\u0026#34;: \u0026#34;https://www.googleapis.com/robot/v1/metadata/x509/firebase-adminsdk-xxxxx%40myapp-12345.iam.gserviceaccount.com\u0026#34; } このファイルには、管理者権限で Firebase を操作するための秘密鍵が含まれているので、外部に公開されないように保管してください。 間違って Git コミットしないように、ホームディレクトリなどに配置しておくのがいいです。 ここでは、次のように Dropbox に保存してみました。 ~/Dropbox/firebase/myapp-12345-firebase-adminsdk-xxxx-abcde12345.json Node.js (TypeScript) プロジェクトの作成 Firebase Admin SDK を使うための Node.js プロジェクトを作成していきます。 まずは、プロジェクト用のディレクトリを作成して、必要な NPM パッケージをインストールします。 ここでは、TypeScript コードをビルドなしで手軽に実行するために、ts-node を使います。 Firebase Admin SDK は、firebase-admin という NPM パッケージとして提供されています。 $ mkdir myapp \u0026amp;\u0026amp; cd myapp ### npm の場合 $ npm init -y $ npm install -D typescript ts-node $ npm install firebase-admin ### yarn の場合 $ yarn init -y $ yarn add -D typescript ts-node $ yarn add firebase-admin ついでに NPM スクリプトを追加して、yarn start (npm start) コマンドで main.ts を起動できるようにしておきます。 package.json { // ... \u0026#34;scripts\u0026#34;: { \u0026#34;start\u0026#34;: \u0026#34;ts-node main\u0026#34; }, Firebase Admin SDK の初期化 Firebase Admin SDK の各種サービスにアクセスするには、最初に initializeApp 関数を呼び出して、Firebase の App インスタンスを初期化しておく必要があります。 initializeApp 関数は、デフォルトで GOOGLE_APPLICATION_CREDENTIALS 環境変数に設定したパスから、Credential ファイルをロードしようとするので、先にこの環境変数を設定しておきます。 export GOOGLE_APPLICATION_CREDENTIALS=~/Dropbox/firebase/myapp-12345-firebase-adminsdk-xxxx-abcde12345.json 次の TypeScript コードは、この Credential ファイルを使って Firebase の App インスタンスを初期化し、その設定内容を表示します。 main.ts import { initializeApp, App } from \u0026#39;firebase-admin/app\u0026#39; const app: App = initializeApp() console.log(app.options) 次のように実行して、秘密鍵の情報などが表示されればうまく設定できています。 実行例 $ yarn -s start { credential: ServiceAccountCredential { httpAgent: undefined, implicit: true, projectId: \u0026#39;myapp-12345\u0026#39;, privateKey: \u0026#39;-----BEGIN PRIVATE KEY-----\\n\u0026#39; + \u0026#39;MIIEvgIBADANBgkqhkiG9w0BAQEFAASCBKgwggSkAgEAAoIBAQC4PB8Dwzy7J0tg\\n\u0026#39; + \u0026#39;................................................................\\n\u0026#39; + \u0026#39;I/cr9iy94UUMtXq5Y18aDe2aKg7//GDdtCGrQ4OicOojvv/BqujDZ3ZL0b3dD/yP\\n\u0026#39; + \u0026#39;AzWyaB/GnfIEPKIyWM7LOPl2\\n\u0026#39; + \u0026#39;-----END PRIVATE KEY-----\\n\u0026#39;, clientEmail: \u0026#39;firebase-adminsdk-xxxxx@myapp-12345.iam.gserviceaccount.com\u0026#39;, httpClient: HttpClient { retry: [Object] } } } 複数の Firebase プロジェクトを運用している場合は、GOOGLE_APPLICATION_CREDENTIALS という 1 つの環境変数を使いまわすのは都合が悪いかもしれません。 そのような場合は、次のようにすれば、任意の環境変数に Credential ファイルのパスを設定しておくことができます。 この例ではまず FIREBASE_MYAPP_CREDENTIALS 環境変数を参照し、見つからなかった場合はフォールバックとして GOOGLE_APPLICATION_CREDENTIALS 環境変数を参照するようにしています。 initFirebase.ts import { cert, initializeApp } from \u0026#39;firebase-admin/app\u0026#39; const credPath = process.env[\u0026#39;FIREBASE_MYAPP_CREDENTIALS\u0026#39;] || process.env[\u0026#39;GOOGLE_APPLICATION_CREDENTIALS\u0026#39;] if (!credPath) { console.error(\u0026#39;Error: FIREBASE_MYAPP_CREDENTIALS env is not set\u0026#39;) process.exit(1) } initializeApp({ credential: cert(credPath) }) これで、Firebase の各種 API を呼び出す準備ができました。 Admin SDK で Firestore データベースにアクセスしてみる 上記で作成した initFirebase.ts モジュールを読み込めば、Firebase の各種サービスにアクセスできるようになります。 例えば、firebase-admin/firestore モジュール が提供する getFirestore 関数を使って、Firestore インスタンスを取得すれば、Firestore データベースを操作することができます。 次の例では、addSampleBooks 関数で books コレクションにサンプルデータを登録し、dumpSampleBooks 関数でその情報を取得しています。 main.ts import { getFirestore } from \u0026#39;firebase-admin/firestore\u0026#39; import \u0026#39;./initFirebase\u0026#39; // Initialize Firebase App const db = getFirestore() const booksCollection = db.collection(\u0026#39;/books\u0026#39;) /** books コレクションに 1 つのドキュメントを追加 */ async function addBook(id: string, title: string) { await booksCollection.doc(id).set({ title }) } /** books コレクションにサンプルデータを追加 */ async function addSampleBooks() { await Promise.all([ addBook(\u0026#39;id-001\u0026#39;, \u0026#39;Title-001\u0026#39;), addBook(\u0026#39;id-002\u0026#39;, \u0026#39;Title-002\u0026#39;), addBook(\u0026#39;id-003\u0026#39;, \u0026#39;Title-003\u0026#39;), ]) } /** books コレクションの全てのドキュメントを取得して表示する */ async function dumpSampleBooks() { const snapshot = await booksCollection.get() snapshot.docs.forEach((doc) =\u0026gt; { const book = doc.data() console.dir(book) }) } /** エントリーポイント */ void (async function main() { await addSampleBooks() await dumpSampleBooks() })() 実行結果 $ yarn -s start { title: \u0026#39;Title-001\u0026#39; } { title: \u0026#39;Title-002\u0026#39; } { title: \u0026#39;Title-003\u0026#39; }"
},
{
url: "/p/m3bjrz7/",
title: "Next.js で Firebase: Cloud Firestore データベースを使う",
date: "2021-12-30T00:00:00Z",
body: "Next.js で Firebase: Cloud Firestore データベースを使う 何をするか Cloud Firestore は、Firebase サービス（あるいは GCP）が提供するサーバーレスな NoSQL データベースです。 Firestore データベースには様々な環境からアクセスできますが、ここでは Web サイトからアクセスすることを想定して、Firebase が提供する JavaScript SDK（クライアントサイド SDK）を使って Firestore データベースを操作してみます。 ☝️ Firebase と GCP の使い分け Firebase と GCP (Google Cloud Platform) の両方に Firestore の記載があるので混乱しますが、どちらのプロジェクトで作った Firestore データベースも内部的には共有されているようです。 Firebase プロジェクトも、GCP プロジェクトとして参照できるようになっています。 一方で、SDK は共通化されておらず、主に Firebase はクライアントサイド用の SDK を提供し、GCP はサーバーサイド用の SDK を提供しています。 前提条件として、Firebase プロジェクトの作成は完了し、FirebaseApp インスタンスの初期化コードは準備できているものとします。 参考: Next.js で Firebase: プロジェクトの作成と接続準備 Firestore データベースの作成 クライアントアプリの実装を始める前に、Firebase プロジェクトに Firestore データベースを作成します。 Firebase コンソール にサインインして、対象のプロジェクトを開く。 サイドバーから Firestore Database を選択し、データベースの作成 をクリックする。 保護ルールは 本番環境モード を選んでおけば OK ロケーションは asia-northeast1（東京）を選んでおけば OK 次のように空っぽのデータベースが作成されれば準備 OK です。 テスト用コレクション (books) の作成 Web アプリからのデータ取得を試したいので、まずは Firebase コンソール上で Firestore データベースのテスト用コレクション (books) を作成することにします。 Firestore Database のデータタブから コレクションを開始 を押して、books という名前でコレクションを追加します。 最初のドキュメント（データ）の情報追加画面になるので、こんな感じでデータを追加します。 ドキュメントID: id-1 フィールド title: (string) Title-1 フィールド author: (string) Author-1 フィールド price: (number) 1000 ☝️ コレクション作成と同時にドキュメント追加が必要なのはなぜ？ Firestore のコレクションはドキュメント（個々のデータ）の集まりです。 あるコレクション ID の下に 1 つ目のドキュメントを作成しようとすると、コレクションが自動的に作成されます。 逆に、コレクションから最後のドキュメントを削除すると、コレクションは自動的に削除されます。 つまり、ドキュメントなしではコレクションは存在することができないので、Firebase コンソール上で Firestore のコレクションを作成しようとすると、1 つ目のドキュメント入力が同時に求められます。 無事に books コレクションを作成できたら、ドキュメントを追加 を押して、適当に 3 つくらいデータを登録しておきます。 例えば、こんな感じでドキュメントを追加しておきます。 ドキュメントID title author price id-1 Title-1 Author-1 1000 id-2 Title-2 Author-2 2000 id-3 Title-3 Author-3 3000 セキュリティルールの設定 クライアントアプリ（Web アプリやモバイルアプリ）からの Firestore データベースへのアクセス制御は、セキュリティルール で設定します。 例えば、「サインイン済みのユーザーにのみコレクションの読み書き許可する」といった設定が可能です。 ここではとりあえず、books コレクションは誰でも読み取り可能で、書き込みは不可というルールに設定してみます。 Firestore Database の ルール タブを選択すると、セキュリティルールを編集できます。 デフォルトでは、おそらく次のようになっています。 rules_version = '2'; service cloud.firestore { match /databases/{database}/documents { match /{document=**} { allow read, write: if false; } } } これは、「いかなるドキュメントに対しても読み書きを許可しない」という設定なので、次のように編集して保存します。 rules_version = '2'; service cloud.firestore { match /databases/{database}/documents { match /books/{document=**} { allow read: if true; allow write: if false; } } } 上記のルール設定は、次のような意味を持っています。 books コレクション以下の全てのドキュメントが対象 (match /books/{document=**}) 読み込みは許可 (allow read: if true;) 書き込みは不可 (allow write: if false;) これで、Firestore 側の books コレクションの準備は完了です。 クライアントコードの作成 Firestore の準備ができたので、Web アプリ (Next.js/React) のコードからデータ取得してみます。 カスタムフック (useBooks) を作って、Firestore の books コレクション内のすべてのドキュメントを取得します。 firebase パッケージのインストールや、FirebaseApp インスタンスの初期化用コード init.ts の作成は終わっているものとします（参考: FirebaseApp の初期化）。 Firestore アクセス部分 まずは、Firestore から books コレクション内のドキュメントを取得してくるコードを作成します。 Book データ型もここで定義しておきます。 utils/firebase/books.ts import { collection, getDocs, getFirestore } from \u0026#39;firebase/firestore\u0026#39; // import \u0026#39;../utils/firebase/init\u0026#39; // Initialize FirebaseApp export type Book = { id: string title: string author: string price: number } export async function getBooks(): Promise\u0026lt;Book[]\u0026gt; { const books = new Array\u0026lt;Book\u0026gt;() const db = getFirestore() const booksSnapshot = await getDocs(collection(db, \u0026#39;/books\u0026#39;)) booksSnapshot.forEach((doc) =\u0026gt; { const book = doc.data() as Book books.push({ ...book, id: doc.id }) }) return books } データ取得用のカスタムフック React コンポーネントからデータ取得したいので、上記で作ったコードを useBooks カスタムフックの形にラップします。 ここでは、直接 getBooks() を呼び出していますが、最終的には useSWR フックを使ってデータフェッチ することをお勧めします。 hooks/useBooks.ts import { useEffect, useState } from \u0026#39;react\u0026#39; import { Book, getBooks } from \u0026#39;../utils/firebase/books\u0026#39; export type UseBooksOutput = { isLoading: boolean books: Book[] } const DEFAULT_OUTPUT: UseBooksOutput = { isLoading: true, books: [], } export function useBooks(): UseBooksOutput { const [output, setOutput] = useState(DEFAULT_OUTPUT) useEffect(() =\u0026gt; { void (async () =\u0026gt; { const books = await getBooks() setOutput({ isLoading: false, books }) })() }, []) return output } React コンポーネント あとは、適当なコンポーネントから、useBooks フックを使って取得した情報を表示すれば OK です。 components/BookTable.tsx import { FC } from \u0026#39;react\u0026#39; import { useBooks } from \u0026#39;../hooks/useBooks\u0026#39; export const BookTable: FC = () =\u0026gt; { const { isLoading, books } = useBooks() if (isLoading) return \u0026lt;p\u0026gt;Loading...\u0026lt;/p\u0026gt; return ( \u0026lt;ul\u0026gt; {books.map((book) =\u0026gt; ( \u0026lt;li key={book.id}\u0026gt; {book.title} / {book.author} / {book.price} \u0026lt;/li\u0026gt; ))} \u0026lt;/ul\u0026gt; ) } 上記のコンポーネントをレンダリングして、次のように表示されれば成功です。 Title-1 / Author-1 / 1000 Title-2 / Author-2 / 2000 Title-3 / Author-3 / 3000 おまけ: Firestore にドキュメントを追加するコード 上記の例では、Firestore からのドキュメントの読み込みを試しましたが、ドキュメントの追加も似たようなコードで実現できます。 下記の addBook 関数は、渡された Book オブジェクトの情報を Firestore の books コレクションに追加します。 utils/firebase/books.ts import { collection, doc, getDocs, getFirestore, setDoc } from \u0026#39;firebase/firestore\u0026#39; // ... // export async function getBooks(): Promise\u0026lt;Book[]\u0026gt; { ... } // ... export async function addBook(book: Book): Promise\u0026lt;void\u0026gt; { const db = getFirestore() const docRef = doc(db, \u0026#39;books\u0026#39;, book.id) await setDoc(docRef, { title: book.title, author: book.author, price: book.price }, { merge: true /* ドキュメントが存在する場合はフィールドを追記 */ } ) } 実際にこのコードを呼び出すときは、Firestore のセキュリティルールで write 許可しておく必要があります。 次のステップ Firebase Auth で admin ユーザーのみ Firestore に書き込みできるようにする Firestore ドキュメントを TypeScript のユーザー定義型オブジェクトに変換する (withConverter)"
},
{
url: "/p/8t6gq2b/",
title: "Next.js で Firebase: Authentication 機能でユーザー認証できるようにする",
date: "2021-12-26T00:00:00Z",
body: "Next.js で Firebase: Authentication 機能でユーザー認証できるようにする 何をするか？ Firebase の Authentication 機能 を使用すると、ウェブアプリ（やモバイルアプリ）にユーザー認証機能を付けて、各種リソースへのアクセスを制御できるようになります。 例えば、「Firestore に格納されているユーザー情報の編集は、そのユーザーにのみ許可する」といったことができます。 Firebase のクライアントアプリでユーザーデータを扱う場合は、Firebase Authentication はほぼ必須の機能だといえます。 ここでは、Next.js (React) アプリで Firebase Authentication を使い、ユーザー認証を行えるようにしてみます。 ユーザー認証に使う UI は、Firebase が用意している FirebaseUI を使って表示します。 事前準備として、Firebase プロジェクトの作成は済んでおり、Next.js アプリから各種 Firestore 関連インスタンスを取得できるようになっていると想定します。 参考: Next.js で Firebase: プロジェクトの作成と接続準備 ログインプロバイダの設定 Firebase Authentication では、サインイン方法として、新規に登録するメールアドレスや電話番号を使う方法（ネイティブプロバイダ）と、既存の Google アカウントや Facebook アカウントなどを使う方法（追加のプロバイダ）が準備されています。 まずは、シンプルに「メールアドレス」でユーザー登録できるようにしてみます。 Firebase コンソール の Authentication タブを選択して機能を有効化する。 ログインプロバイダ (Sign-in method) で メール／パスワード を選択する。 有効にする にチェックを入れて 保存 をクリック。 これで、Firebase Authentication で「メールアドレス」による認証を行えるようになります。 サインイン状態を扱う React フックを作成する Next.js (React) アプリから Firebase Authentication を使う場合は、サインイン状態を扱うためのカスタムフックを作成しておくと便利です。 サインインボタンなどの UI を先に作りたいところですが、ボタンを表示すべきかどうかの判断のために結局このカスタムフックが必要になるので、先にカスタムフックを作成します。 認証状態の変化は onAuthStateChanged コールバックでハンドルすることができるので、これを利用して useAuthState カスタムフックを実装します。 hooks/useAuthState.ts import { useEffect, useState } from \u0026#39;react\u0026#39; import { getAuth, onAuthStateChanged } from \u0026#39;firebase/auth\u0026#39; import \u0026#39;../utils/firebase/init\u0026#39; // Initialize FirebaseApp /** * useAuthState フックの戻り値の型。 */ export type AuthState = { isSignedIn: boolean isLoading: boolean userId: string | undefined userName: string | undefined avatarUrl: string | undefined } /** * useAuthState が返す初期値。 * Next.js のサーバーサイドレンダリング時もこの値になる。 */ const INITIAL_AUTH_STATE: AuthState = { isSignedIn: false, isLoading: true, userId: undefined, userName: undefined, avatarUrl: undefined, } /** * ユーザーのサインイン状態を取得するためのカスタムフック。 */ export function useAuthState(): AuthState { const [authState, setAuthState] = useState(INITIAL_AUTH_STATE) // サインイン状態の変化を監視する useEffect(() =\u0026gt; { const unsubscribe = onAuthStateChanged(getAuth(), (user) =\u0026gt; { if (user) { setAuthState({ isSignedIn: true, isLoading: false, userId: user.uid, userName: user.displayName || undefined, avatarUrl: user.photoURL || undefined, }) } else { setAuthState({ ...INITIAL_AUTH_STATE, isLoading: false }) } }) // ページ遷移時にサインイン状態の監視を解除 return () =\u0026gt; unsubscribe() }, []) return authState } サインイン画面用のコンポーネントを作成する Firebase はサインイン画面やユーザー登録画面を提供するライブラリとして、firebaseui パッケージを提供しています。 Next.js (React) を使っている場合は、このパッケージを React コンポーネント化した reactfirebaseui パッケージを使うと便利です。 ### npm の場合 $ npm install react-firebaseui ### yarn の場合 $ yarn add react-firebaseui react-firebaseui パッケージは、FirebaseAuth コンポーネントと StyledFirebaseAuth コンポーネントを提供していますが、後者を使った方が表示スタイルを直接設定できて便利です。 下記は、メールアドレスによるサインイン画面を表示するコンポーネントの実装例です。 components/SignInForm.tsx import { FC } from \u0026#39;react\u0026#39; import { getAuth, EmailAuthProvider, // FacebookAuthProvider, // GoogleAuthProvider, // TwitterAuthProvider, } from \u0026#39;firebase/auth\u0026#39; import { auth } from \u0026#39;firebaseui\u0026#39; import StyledFirebaseAuth from \u0026#39;react-firebaseui/StyledFirebaseAuth\u0026#39; import \u0026#39;../utils/firebase/init\u0026#39; // Initialize FirebaseApp const uiConfig: auth.Config = { signInFlow: \u0026#39;popup\u0026#39;, signInOptions: [ EmailAuthProvider.PROVIDER_ID, // FacebookAuthProvider.PROVIDER_ID, // GoogleAuthProvider.PROVIDER_ID, // TwitterAuthProvider.PROVIDER_ID, ], signInSuccessUrl: \u0026#39;/\u0026#39;, } export const SignInForm: FC = () =\u0026gt; { return ( \u0026lt;StyledFirebaseAuth firebaseAuth={getAuth()} uiConfig={uiConfig} /\u0026gt; ) } どのような認証方法を有効にするかは、signInOptions プロパティで指定します。 この例では、認証プロバイダーとしてメールアドレス用の EmailAuthProvider しか指定していないため、このコンポーネントを表示すると、次のようなメールアドレスの入力フォームだけが表示されます。 2 つ以上の認証プロバイダーを有効にした場合は、次のように認証方法を選択する画面が最初に表示されます（あらかじめ Firebase コンソール上で、各プロバイダーの設定をしておく必要があります）。 Sign in with email の画面で、ユーザー登録されていないメールアドレスを入力すると、自動的に新規ユーザーの登録フォームが表示されます。 つまり、これだけで「サインイン画面」と「ユーザー登録画面」の完成です。 表示内容のカスタマイズ方法（上記の uiConfig 部分）は、FirebaseUI のページの Configuration を参照してください。 実際にここで作成した SignInForm を表示するには、次のような感じで Next.js のページコンポーネントから使用します。 pages/signin.tsx import type { NextPage } from \u0026#39;next\u0026#39; import { SignInForm } from \u0026#39;../components/SignInForm\u0026#39; const SignInPage: NextPage = () =\u0026gt; { return ( \u0026lt;div style={{ margin: \u0026#39;1rem\u0026#39; }}\u0026gt; \u0026lt;h2\u0026gt;サインイン\u0026lt;/h2\u0026gt; \u0026lt;SignInForm /\u0026gt; \u0026lt;/div\u0026gt; ) } export default SignInPage こうしておけば、/signin という URL でアクセスしたときにサインイン画面を表示できます。 Sign-in ボタンと Sign-out ボタンを表示する 最後に、現在のサインイン状態によって「サインイン」あるいは「サインアウト」のボタンを表示するコンポーネントを作成します。 サインインボタンが押されたときは、Router.push('/signin') でサインイン画面に遷移し、サインアウトボタンが押されたときは、Firebase が提供する signOut 関数を呼び出すようにしています。 components/SignInOrOutButton.tsx import { FC } from \u0026#39;react\u0026#39; import Router from \u0026#39;next/router\u0026#39; import { getAuth, signOut } from \u0026#39;firebase/auth\u0026#39; import \u0026#39;../utils/firebase/init\u0026#39; // Initialize FirebaseApp import { useAuthState } from \u0026#39;../hooks/useAuthState\u0026#39; export const SignInOrOutButton: FC = () =\u0026gt; { const { isSignedIn } = useAuthState() if (isSignedIn) { return \u0026lt;button onClick={() =\u0026gt; signOut(getAuth())}\u0026gt;Sign-out\u0026lt;/button\u0026gt; } else { return \u0026lt;button onClick={() =\u0026gt; Router.push(\u0026#39;/signin\u0026#39;)}\u0026gt;Sign-in\u0026lt;/button\u0026gt; } } あとはこのコンポーネントを各ページのヘッダ部分などに配置してやれば、どのページからでもサインイン／アウトのできる Web サイトの完成です。 ここではロジックを簡単に示すために、ネイティブな button コンポーネントを使用しましたが、かっこいい UI を表示したければ、MUI (Material-UI) などを導入する のが簡単です。"
},
{
url: "/p/73eq2cm/",
title: "Next.js で Firebase: プロジェクトの作成と接続準備",
date: "2021-12-26T00:00:00Z",
body: "Next.js で Firebase: プロジェクトの作成と接続準備 何をするか？ ここでは、Firebase を Next.js (React) ウェブアプリから使用するための準備 として、「Firebase プロジェクトの作成」「Next.js アプリの作成」「FirebaseApp インスタンスの初期化」までを行います。 なお、ここでは Firebase JS SDK ver.9 以降を対象とします（ver.8 以前は初期化方法が若干異なります）。 Firebase サービスを使うと、Web アプリやモバイルアプリに必要なバックエンド環境を簡単に整えることができます。 例えば、Firebase は次のような機能を提供しており、小規模のアプリであれば無料の Spark プランで動かすことができます（参考: Firebase の料金プラン）。 Firebase Authentication \u0026hellip; ユーザー管理と認証（ログイン UI もある） Firebase Hosting \u0026hellip; Web アプリのホスティング（独自ドメインにも対応） Cloud Firestore \u0026hellip; NoSQL データベース Cloud Function \u0026hellip; サーバレス関数 Cloud Storage for Firebase \u0026hellip; ファイル管理 Web アプリから上記のような機能にアクセスするには、まずは FirebaseApp インスタンスの設定（初期化）が必要になります。 以下では、Next.js アプリから各種 Firebase インスタンスにアクセスするところまでの準備を行います。 Firebase プロジェクトの作成 Firebase コンソールにサインイン して、Firebase のプロジェクトを作成します。 プロジェクト名は、自分の Google アカウント内で一意の名前になっていれば OK です。 例えば、MyApp のような名前を付けて作成してください。 Google アナリティクスは有効にしなくても OK です。 Firebase にウェブアプリを追加する Firebase プロジェクトを作成したら、そのプロジェクトにクライアントアプリを登録します。 クライアントアプリというのは、ウェブアプリやモバイルアプリ、Unity アプリといった、ユーザーが使うアプリのことで、各アプリごとに情報を登録しておく必要があります。 ここでは、Next.js を使ったクライアントアプリから Firebase を使うことを想定しているので、「ウェブアプリ」として登録します。 Firebase コンソール から対象のプロジェクトを選択します。 プロジェクトの概要 ページで アプリを追加 ボタンを押して、ウェブアプリ を選択します。 アプリ名を適当に入力して アプリを登録 ボタンを押します。 ウェブアプリを作成すると、次のような接続用の JavaScript コードが表示されます。 これが Next.js アプリ内で FirebaseApp インスタンスを生成するためのコードになります。 import { initializeApp } from \u0026#34;firebase/app\u0026#34;; const firebaseConfig = { apiKey: \u0026#34;AIzaSyCt1.....................VjbRJAicg\u0026#34;, authDomain: \u0026#34;myapp-99999.firebaseapp.com\u0026#34;, projectId: \u0026#34;myapp-99999\u0026#34;, storageBucket: \u0026#34;myapp-99999.appspot.com\u0026#34;, messagingSenderId: \u0026#34;123456789012\u0026#34;, appId: \u0026#34;1:123456789012:web:ab47d539998fdf2c427784\u0026#34; }; // Initialize Firebase const app = initializeApp(firebaseConfig); このコードはいつでも参照できるので、このタイミングで保存しておく必要はありません。 Next.js プロジェクトの作成と firebase パッケージのインストール まだ Next.js プロジェクトを作成していなければ、create-next-app コマンドを使ってサクッとプロジェクトの雛形を生成してしまいましょう。 次のように実行すると、カレントディレクトリに myapp というディレクトリ（Next.js プロジェクト）が生成されます。 $ npx create-next-app myapp --typescript 次に、Next.js プロジェクトに firebase パッケージをインストールします。 $ cd myapp ### npm の場合 $ npm install firebase ### yarn の場合 $ yarn add firebase あとは、必要に応じて Prettier（コード整形ツール）の設定や、ESLint（静的解析）の設定などをしておきましょう。 Firebase 初期化コードの作成 Next.js アプリから Firebase にアクセスできるようにするため、FirebaseApp インスタンスを初期化するモジュールを作成します。 下記コードはほぼ、Firebase プロジェクトにウェブアプリを追加したときに自動生成されたコードのままです。 utils/firebase/init.ts import { initializeApp } from \u0026#39;firebase/app\u0026#39; // FirebaseApp インスタンスを初期化する initializeApp({ apiKey: \u0026#39;AIzaSyCt1.....................VjbRJAicg\u0026#39;, authDomain: \u0026#39;myapp-99999.firebaseapp.com\u0026#39;, projectId: \u0026#39;myapp-99999\u0026#39;, storageBucket: \u0026#39;myapp-99999.appspot.com\u0026#39;, messagingSenderId: \u0026#39;123456789012\u0026#39;, appId: \u0026#39;1:123456789012:web:ab47d539998fdf2c427784\u0026#39; }) ☝️ Firebase の apiKey は Git にコミットして OK 上記のコード内には apiKey プロパティの値がハードコードされていますが、これはいわゆる 秘密鍵ではない ので、GitHub などにそのままコミットして公開しても大丈夫です。 Firebase のクライアントアプリにおけるアクセス権限は、Firestore などのセキュリティルール の仕組みを使って、ユーザーの認証状態などに基づいて制御します。 一方で、管理用のアプリを作るための Firebase Admin SDK を使用する場合は、Firebase コンソール上で生成した秘密鍵を使って接続することになります。 こちらはもちろん Git にはコミットしてはいけないものなので混同しないようにしてください。 この初期化コードは、次のような感じでインポートすることで実行します。 初期化された FirebaseApp インスタンスは Firebase ライブラリ内で保持されているため、いつでも getApp() 関数で参照できるようになります。 pages/index.tsx import type { NextPage } from \u0026#39;next\u0026#39; import { getApp, FirebaseApp } from \u0026#39;firebase/app\u0026#39; import \u0026#39;../utils/firebase/init\u0026#39; // Initialize FirebaseApp const Home: NextPage = () =\u0026gt; { const app: FirebaseApp = getApp() return ( \u0026lt;ul\u0026gt; \u0026lt;li\u0026gt;name = {app.name}\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;appId = {app.options.appId}\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;apiKey = {app.options.apiKey}\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; ) } export default Home あとは、yarn dev (npm run dev) で Next.js 開発サーバーを起動して、http://localhost:3000/ にアクセスすれば、次のように FirebaseApp インスタンスの情報が表示されるはずです。 * name = [DEFAULT] * appId = 1:123456789012:web:ab47d539998fdf2c427784 * apiKey = AIzaSyCt1.....................VjbRJAicg 各種 Firebase サービスにアクセスする方法 Firebase の各種サービス用のインスタンスを取得するためには、専用のモジュールをインポートして、getXxx() 系のメソッドを呼び出します。 例えば、次のコードでは、Firebase Authentication を使うための Auth インスタンスと、Cloud Firestore を使うための Firestore インスタンスを取得しています。 import { getAuth, Auth } from \u0026#39;firebase/auth\u0026#39; import { getFirestore, Firestore } from \u0026#39;firebase/firestore\u0026#39; import \u0026#39;../utils/firebase/init\u0026#39; // Initialize FirebaseApp // Firebase Authentication を使うコード const auth: Auth = getAuth() // Cloud Firestore を使うコード const firestore: Firestore = getFirestore() これらの getXxx() 系関数を呼び出す前に、utils/firebase/init.ts をインポートして、FirebaseApp インスタンスを初期化しておくことを忘れないでください。 initializeApp() を実行する前に getXxx() 系関数を呼び出すと、次のようなエラーが発生します。 FirebaseError: Firebase: No Firebase App '[DEFAULT]' has been created - call Firebase App.initializeApp() (app/no-app). Next.js アプリで全面的に Firebase を使うのであれば、pages/_app.tsx あたりで初期化してしまうのがよいかもしれません。 pages/_app.tsx import type { AppProps } from \u0026#39;next/app\u0026#39; import \u0026#39;../styles/globals.css\u0026#39; import \u0026#39;../utils/firebase/init\u0026#39; // Initialize FirebaseApp function MyApp({ Component, pageProps }: AppProps) { return \u0026lt;Component {...pageProps} /\u0026gt; } export default MyApp ☝️ init.ts の中に Auth や Firestore 関連のコードを記述しない アプリのコードを簡潔にするために、init.ts の中で getFirestore() などを呼び出して Firestore インスタンスを export したくなるかもしれませんが、そのようにすると、init.ts をインポートする全てのページのバンドルサイズが大きくなってしまいます。 init.ts 内の処理は FirebaseApp インスタンスの初期化にとどめておき、必要に応じて getAuth() や getFirestore() を呼び出すことをお勧めします。 参考リンク Next.js で Firebase: Authentication 機能でユーザー認証できるようにする"
},
{
url: "/p/cwdyhec/",
title: "Next.js で useState とローカルストレージ (localStorage) を連動させる",
date: "2021-12-01T00:00:00Z",
body: "Next.js で useState とローカルストレージ (localStorage) を連動させる 何をするか？ React (Next.js) の useState フックは、Web ページの状態を保持するものですが、ページのリロードや、ブラウザの再起動を行うと、その状態はリセットされてしまいます。 一方、Web ブラウザに搭載されている localStorage や sessionStorage を使用すると、キー＆バリュー（両方とも文字列のみ）の形でデータを保存することができます。 ここでは、これらを一緒に使うことで、useState で管理している状態をローカルストレージに保存・復帰できるようにしてみます。 使い方のイメージ 例えば、Web サイト上でダークモードの On/Off を行うスイッチがあるとして、その状態をローカルストレージに保存できるようにしたいとします。 図: ダークモード切り替えのイメージ ダークモードの状態は useDarkMode のようなカスタムフックを作成して、次のように扱えると便利です。 src/pages/sample.tsx import { NextPage } from \u0026#39;next\u0026#39; import { useDarkMode } from \u0026#39;../hooks/useDarkMode\u0026#39; const SamplePage: NextPage = () =\u0026gt; { // 一見 useState と同様だが localStorage と連動している const [isDark, setDark] = useDarkMode(false) return ( \u0026lt;div style={{ width: \u0026#39;100vw\u0026#39;, height: \u0026#39;100vh\u0026#39;, color: isDark ? \u0026#39;white\u0026#39; : \u0026#39;black\u0026#39;, background: isDark ? \u0026#39;black\u0026#39; : \u0026#39;white\u0026#39;, }} \u0026gt; \u0026lt;label\u0026gt; \u0026lt;input type=\u0026#34;checkbox\u0026#34; checked={isDark} onChange={(e) =\u0026gt; setDark(e.target.checked)} /\u0026gt; {isDark ? \u0026#39;DARKモードです\u0026#39; : \u0026#39;LIGHTモードです\u0026#39;} \u0026lt;/label\u0026gt; \u0026lt;/div\u0026gt; ) } export default SamplePage useDarkMode の実装 useState による状態をローカルストレージと連動させるには、状態の初期化時に localStorage.getItem で値をロード、状態の変更時に localStorage.setItem で値をセーブ、とすればよさそうです。 ただし、localStorage オブジェクトは、クライアントサイド JS でしか参照できないため、Next.js などのサーバーサイドレンダリング時に値を参照しようとするとエラーになってしまいます。 localStorage の参照タイミングをうまく制御しながら、useState フックと連携させなければいけません。 useEffect を使う方法 useEffect（副作用フック）で設定したコールバック関数は、クライアントサイドでのレンダリング時にしか呼び出されないことが保証されているので、次のように localStorage.getItem を呼び出してやれば、状態の初期化はうまくいきます。 src/hooks/useDarkMode.ts import { useCallback, useEffect, useState } from \u0026#39;react\u0026#39; /** * ダークモード設定を保存するローカルストレージのキー名。 * ダークモードなら `true` という文字列を格納する。 */ const STORAGE_KEY_DARK_MODE = \u0026#39;myapp.example.com/darkMode\u0026#39; /** * ダークモード設定状態を扱うためのフック。 */ export function useDarkMode( defaultValue: boolean ): [isDark: boolean, setDark: (dark: boolean) =\u0026gt; void] { const [isDarkInternal, setDarkInternal] = useState(defaultValue) // クライアントでの初期レンダリング直後にローカルストレージの設定を反映 useEffect(() =\u0026gt; { const dark = localStorage.getItem(STORAGE_KEY_DARK_MODE) === \u0026#39;true\u0026#39; if (dark !== defaultValue) { setDarkInternal(dark) } }, [setDarkInternal]) // 外部からのセッター呼び出し時にローカルストレージに値を保存する const setDark = useCallback( (isDark: boolean) =\u0026gt; { localStorage.setItem(STORAGE_KEY_DARK_MODE, isDark ? \u0026#39;true\u0026#39; : \u0026#39;false\u0026#39;) setDarkInternal(isDark) }, [setDarkInternal] ) return [isDarkInternal, setDark] } 初期表示時のフラッシュ問題 useEffect は初回レンダリング後に呼び出されるので、Web ブラウザをリロードしたときに、デフォルトの状態（上記の例の場合は isDark = false）で描画されてしまうことを防ぐことができません。 ユーザーがダークモードに設定していたとしても、ブラウザのリロードを行うと、瞬間的にライトモードの（SSR 生成された）ページが見えてしまいます。 この問題の解決方法はいろいろ考えられますが、いずれも若干トリッキーな実装が必要になるみたいです。 参考になりそうなサイトから、ポイントだけ抜粋しておきます。 Adding dark mode with Next.js, styled-components, and useDarkMode SSR 時には全体を visibility: 'hidden' で描画しておき、初回レンダリング後（useEffect コールバック後）に通常表示に切り替える方法。実はデフォルトモードで描画してるんだけど、見えないようにしてるということ。 const [mounted, setMounted] = React.useState(false) React.useEffect(() =\u0026gt; { setMounted(true) }, []) // prevents ssr flash for mismatched dark mode const body = \u0026lt;ThemeProvider theme={theme}\u0026gt;{children}\u0026lt;/ThemeProvider\u0026gt; if (!mounted) return \u0026lt;div style={{ visibility: \u0026#39;hidden\u0026#39; }}\u0026gt;{body}\u0026lt;/div\u0026gt; return body donavon/use-dark-mode: A custom React Hook to help you implement a \u0026ldquo;dark mode\u0026rdquo; component. _document.tsx で特殊な noflash.jsをロードするようにしておき、その中で次のように全体に反映される CSS クラスを設定する方法。この JS ファイルはクライアントサイドでの初期レンダリング時に必ず実行されるので、確実にlocalStorage の値を CSS クラスに反映できる。 (function() { // ... document.body.classList.add(darkMode ? classNameDark : classNameLight) // ... })() いやぁ。なかなか大変ですね。。。 とはいえ、現在のテーマ設定値に関しては、少なくとも React のコンテキスト として保持するようにしておけば、ページ遷移時に画面がフラッシュするようなことは防げます。 というわけで、ここでサンプルコードとして使ったuseDarkMode の例はあまりよくなかったかもです。。。"
},
{
url: "/p/s5m7cbh/",
title: "Next.js のその他の記事",
date: "2021-12-01T00:00:00Z",
body: "Next.js のその他の記事"
},
{
url: "/p/ys8myer/",
title: "エミュレーター: FCEUX で TAS 動画を作る",
date: "2021-11-22T00:00:00Z",
body: "エミュレーター: FCEUX で TAS 動画を作る ファミコンのプレイ動画を作る機会があったので、その操作手順をメモメモ。 いわゆる TAS (Tool-Assisted Superplay) と呼ばれているもので、うまくプレイできたものだけを繋げた動画を作ります。 今回使うのはファミコンのエミュレーター FCEUX で、ムービーの保存機能がついています（実際には各フレームの操作内容を記録しているだけ）。 これとセーブ機能を組み合わせて、何度もプレイをやり直すことで、ノーミスプレイの動画を作ることができます。 録画手順 ゲームの ROM をロードした状態で、メニューから Movie → Movie Record と選択すると録画（操作内容の記録）を開始できます。 このとき、Record の項目で Start を選択しておくと、ゲームがリセットされたところから操作の記録が開始されるので、普通にゲームを進めていきます。 録画を終了したいときは、メニューから Movie Stop を選択します。 FCEUX の場合、プレイ内容は .fm2 という拡張子の Movie ファイルとして保存されます。 プレイのやり直し（録画内容の上書き） スロット（0〜9）を使ったステートのセーブ＆ロード機能を使うと、任意の地点からプレイをやり直すことができます。 Shift + F1〜F10 \u0026hellip; スロット 0〜9 へのセーブ F1〜F10 \u0026hellip; スロット 0〜9 からロード このロード機能は Movie Record による録画にも反映されるため、適宜 Shift+F1 でセーブしつつ、F1 でロードすることによって、うまくいったプレイだけの Movie ファイルを作ることができます。 次のようにすると、既存の Movie ファイル (.fm2) を再生して、途中から操作をやり直し（記録内容を上書き）することができます。 Movie ファイルを上書きするときは、ファイルをバックアップしておくと安心です。 メニューから Movie → Movie Play を選択 Open Read-Only のチェックを外す Play ボタンで Movie ファイルを再生開始 早送りキー（後述）などでやり直したいところまで進めて、Shift+F1 などでステートセーブ F1 キーでステートロードすると、その地点からの録画が開始される あとは、納得のいくプレイができるまでステートセーブ＆ロードを繰り返すだけです。 動画ファイルに出力する 上記手順で作成した .fm2 ファイルは、あくまでエミュレーター上で再生できる操作データであって、YouTube で見れるような動画ファイルではありません。 安心してください。FCEUX には、動画ファイルを作成する機能もついています。 メニューから Movie → AVI Record As を選択 ファイル名を入力して Save ボタンを押す これで、現在のプレイ内容が動画ファイルへの出力されていきます。 このとき、描画スピードを上げても動画ファイルの内容は正しいスピードのもので作成されるので大丈夫です。 デフォルトのエンコーダー設定だと、若干映像が荒かったりするので、Options → Movie Options で設定を変えると綺麗になったりします（例えば、AVI Backend driver というところを libgwavi に変えて、エンコーダーに H.264 を選ぶという方法があります）。 （おまけ）キーコンフィグ FCEUX のメニューから、Options → HotKey Config を選択すると、キーボードで各種操作を行うためのホットキーを設定できます。 フレームのポーズ機能や、再生速度を制御するためのホットキーを、自分が押しやすいキーに変更しておくと便利です。 Emulation / Pause \u0026hellip; フレームのポーズ機能（デフォルトが Pause キーなので、Space などにしておくと押しやすい） Speed / DecreaseSpeed \u0026hellip; フレームの再生速度を下げる（デフォルトの - でも OK） Speed / IncreaseSpeed \u0026hellip; フレームの再生速度を上げる（デフォルトの = でも OK）"
},
{
url: "/p/ajj5753/",
title: "遊び",
date: "2021-11-22T00:00:00Z",
body: "遊び"
},
{
url: "/p/inh3k2j/",
title: "Visual Studio Code のメモ",
date: "2021-11-13T00:00:00Z",
body: "Visual Studio Code のメモ"
},
{
url: "/p/4oybku6/",
title: "VS Code で Python 用のフォーマッター (Black) を使う",
date: "2021-11-13T00:00:00Z",
body: "VS Code で Python 用のフォーマッター (Black) を使う 何をするか？ Visual Studio Code に Python 拡張 を入れることで、Python コードの編集（自動補完など）ができるようになりますが、コードの自動フォーマットを行うには、フォーマッターを別途インストールしておく必要があります（いろんなフォーマッターがあるため）。 Python のフォーマッターとしては、autopep8 や yapf などもありますが、ここでは、最近人気がある Black をインストールして VS Code の自動フォーマッターとして設定します。 Facebook や Dropbox、Mozilla などでも導入されており、採用実績としては申し分なさそうです。 ☝️ 頑固なフォーマッター Black は自分自身を The uncompromising code formatter と説明しています。 ようするに、「私が定義する設定に従いなさい」という意味で、ユーザーにほとんど設定の余地を残していません（行の長さ程度は設定できます）。 このようにすることで、チーム内でのフォーマット論争を防ぐ効果があります。 TypeScript (JavaScript) でよく使われている Prettier フォーマッターも同様の思想で作られており、ほとんど設定ができないようになっています（こちらは opinionated という単語を使っています）。 参考: TypeScript コードを Prettier で自動整形する Black ではどのようなスタイルになるか？ インデントは スペース 4 文字 PEP 8 通り。 トップレベルのクラス定義や関数定義の間には 2 行の空白行 を入れる（クラス内のメソッド間は 1 行） PEP 8 通り。 1 行あたり最大 88 文字 まで PEP 8 は 79 文字と言っているが、それだと改行がたくさん入りすぎる傾向があるので、Black では 1 割増しの 88 文字にした。Raymond Hettinger の講演 Beyond PEP 8 でも 90 文字くらいがよいと指摘している。 文字列リテラルは ダブルクォートで囲む（Issue #51 などの議論を経てダブルクォートに落ち着いた。理由をまとめると以下のような感じ） PEP 257 で docstring はダブルクォートで囲むべしとされており、それに合わせるのが一貫性があってよい。PEP 8 では docstring 以外の文字列リテラルにシングルクォートを使っているが、バラバラにする理由がない。 空白文字列をシングルクォートで表現すると '' となって、フォントによっては判別しにくくなる。ダブルクォートであれば一目瞭然 (\u0026quot;\u0026quot;)。 ダブルクォートの中でシングルクォートを使うことはよくあるが（例: \u0026quot;don't\u0026quot;）、その逆は少ない。 UK レイアウトや German レイアウトのキーボードでは、\u0026quot; の入力は苦じゃないよ。シングルクォートの方が入力しやすければ、それで入力しておいて Black に \u0026quot; に変換させればよい。 文字列リテラルをシングルクォートで囲っている Python プロジェクトは多いので、Black が一貫してダブルクォートを採用しているところは要注意かもしれません。 ただ、上記のような理由を読むと、ダブルクォートを使う方が理にかなっているような気がします。 Black のインストール Black は pip で簡単にインストールできます。 $ python3 -m pip install black VS Code の自動フォーマット設定 Cmd(Ctrl) + Shift + P → Preferences: Open Settings (JSON) で settings.json フィアルを開き、次のように設定します。 ここでは、Python 用のフォーマッターとして black を使用することと、ファイルの保存時に自動でフォーマットを実行することを指定しています。 settings.json { // Python コードを black でフォーマットする設定 // （Python 拡張をインストールして pip install black しておく） \u0026#34;python.formatting.provider\u0026#34;: \u0026#34;black\u0026#34;, \u0026#34;[python]\u0026#34;: { \u0026#34;editor.defaultFormatter\u0026#34;: null, // Prettier を使わないようにする \u0026#34;editor.formatOnSave\u0026#34;: true // ファイル保存時に自動フォーマット }, // ... } ちなみに、\u0026quot;editor.defaultFormatter\u0026quot;: null という設定は、デフォルトのフォーマッターとして次のように Prettier などを設定している場合に必要になります （Prettier は Python コードのフォーマットには対応していません）。 settins.json { \u0026#34;editor.defaultFormatter\u0026#34;: \u0026#34;esbenp.prettier-vscode\u0026#34;, // Prettier を使う // ... } 参考: Editing Python Code in Visual Studio Code - Formatting Black によるフォーマットを無効化する 配列で行列データを表現する場合など、Black によるフォーマットを抑制したいことがあります。 そのような場合は、# fmt: off と # fmt: on で囲みます（同じインデントレベルに記述してください）。 # fmt: off matrix = { 0, 1, 2, 3, 4, 5, 6, 7, 8, } # fmt: on 1 行だけに適用したいときは、行末コメントで # fmt: skip と指定できます。 GitHub の README.md に Black バッジを表示する Python プロジェクトに Black を適用したら、GitHub リポジトリの README.md の先頭に下記のコードを入れて、Black バッジを表示しておきましょう。 [![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)"
},
{
url: "/p/d7fhhhg/",
title: "読書メモ『シンプルリスト』ドミニック・ローホー",
date: "2021-11-12T00:00:00Z",
body: "読書メモ『シンプルリスト』ドミニック・ローホー シンプルリスト ドミニック・ローホー 講談社 いろいろなリストを作ることによって、たくさんの小さな幸せに気付くためのヒント集のようなものです。 そのようなリストを集めていくことで、自分の本質が見えてきます。 物事を豊かにとらえることができるようになります。 リストとは リストは、人生を前に進めるための貴重な道具となる。 リストは、、、 記憶を助けるものである。ささやかな望み、大事な決意、一時的な情熱、心に誓った人生の信条など。 セラピーのようなものである。あなたが道を見失い、心にぽっかりと穴があいてしまったときに、忘れてしまった人生の意味を取り戻してくれる。 私たちの鏡である。人生そのものであり、本質を映し出してくれる。 リストを書くコツ 最初のページは、リストのリスト（目次）にする リストは作ってみたいものから始めればよい できるだけ的確で簡潔な文章を書く 日付や見出しの欄を設けて、見た目にも気を配る 分類や書き方は試行錯誤していけばいい 同じテーマのことを複数のノートに分散させない 思い出や夢のリストはこの瞬間から少しずつ育てていく（さかのぼって書く必要はない） 本当の自分 これが私と言えるものが見つかるリスト。自らの価値観をはっきりさせることが大切。 それをすることで生き生きとできること 好きな話題と嫌いな話題 似合う衣服やアクセサリ 嫌いなもののリスト。自分が好きではないものを知ることは、自分を知ることである。 好きではないこと・もの いらいらすること・もの 2度としたくないこと 嫌なことで変えたいこと 時間を費やしてしまった大切じゃないこと ある人の長所と短所のリスト。自分自身のありたい姿が見えてくる。 親友（好きなところ） 思春期の友達（一緒にしたこと） 恋人（どこに惹かれたか） 先生（教えられたこと） 家族（長所、短所） 強い印象を受けた人（何を感じたか） 小説や映画で印象に残った登場人物 シンプルに生きる 習慣をシンプルにするリスト。 1日に1つだけ美のお手入れをする 掃除は1度に1か所だけにする 取引銀行は1行だけにする 1週間のうち1日は何もしない日を作る 美術館では1枚の絵をじっくりと見る 持ち物をシンプルにするため、ひとつだけあればいいものをまとめる。 デビッド・アレンの GTD のコツは、具体的な行動を書き出すということ。タイヤを交換しなければいけないならば、「タイヤを替える」ではなく、「自動車整備工場の予約をする」と書く。 モチベーションを上げる特効薬は、「デスクの整理」や「請求書の選別」といった、簡単にできることのリスト。 行動のポリシー、モットー、ルールを決めておく。 自然と接する時間を持つ。少なくとも1日に1回は自然を見るなど。 人と話して不快に感じたら、「腹が立つなぁやり返してやる！」ではなく、「自分も同じようなことをしたことがないか？反対の行動をとろう」と考える。 哲学者アリストテレスの言葉「注意深く観察をする能力が発達すればするほど、幸せになる能力が発達する」 時間がないという焦燥感にかられるのは、段取りが悪いからではない。うまく集中できていないことに原因がある。 幸せを再生産する 小さな幸せの瞬間のリストは、幸せな人生そのものである。本当の幸せは、人に自慢するものでも、人に見せるものでもない。五感を意識するのがコツ。 遠くから聞こえるピアノの音 公園の子供たちのはじける笑顔 夕暮れの空を行く渡り鳥 降りしきる雨を眺めながらバッハを聞く ふかふかの絨毯の上をはだしで歩く 起きがけに漂う焼き立てのパンとコーヒーの香り 冬に上質な暖かいコートに身を包み散歩に出かける 雪降る露天風呂につかる 年月を経て味わいの出る皮、家具、ジーンズ 小さな幸せを見つけるヒント。 季節、一日の流れを感じる 食（おいしくて幸せになったもの） 大切な人といるとき、ひとりのときの幸せ 待ちですれ違った印象的だった人 美しいと思った言葉、表現 場所（お気に入りの場所） これまでに見た美しい自然の景色 体験した魔法のようなひととき 自分の理想的な環境 音楽リストはシチュエーションごとに聞くものをまとめる。 悩みから解放される 「ネガティブ思考」は人生の質を悪化させる。くだらない考えはそれを意識すること捨てられる。 ルイーズ・L・ヘイ 『すべてがうまくいく「やすらぎ」の言葉』 「しなければならない」「できない」といったネガティブな言葉を使わずに、「したい」「できる」といったポジティブな言葉を意識して使うこと。 ネガティブ思考を追い払うリスト ポジティブな文章 夢中になれる楽しいこと5つ 気分転換になること 生まれつき陽気な人 にぎやかで楽しい場所 悩み・心配事のリストを書き出すと、客観的になれる。それほど恐ろしいものではないことに気付くことができる。そして不要な感情（不安）は捨てる。 仕事の悩み・心配 交友関係の悩み・心配 体のこと そのトラブルによって引き起こされる感情 理想的な解決法、代替案 不安に耐えられないのは、不安の対象が何かわからないときである。 病気は病名が分かれば治療ができるのと一緒で、自分が苦しい理由を意識できれば、窮地を脱することができる。 不安や不満は一度紙の上に書き出してしまえば、あなたのもとを離れてあなたに影響を与えることはない。不満は紙の中に閉じ込められたのだから。 誰かがいないから寂しいのではなく、自分をしっかり持っていないから寂しいと感じる。そういうときは独り言を書きとめてみる。 魔法 なりたい姿を決めて、それを書きとめる。 見たいこと、感じたいこと、考えたいこと、望ましいことだけを選ぶ。そうでないものはくどくど書かない。 人生の挫折とは、新しい日々よりも過ぎ去ったことを大切にし、現状維持と安定を望むこと。そうではなく、これからの人生の可能性を考える。 困難に直面したとき、まずは逃げないことから始めてみる。苦しみから逃れようとすると、ますます苦しみを意識することになる。これまで耐えてきたことをリストにすると、人生の苦しみや過ち、忍耐、挑戦、経験から拾い集めた知恵を自分のものにできる。 人生で成功するために必要なのは、ほんの少しのユーモアのセンスと想像力である。── チャーリー・チャップリン 人は年をとればとるほど、笑いが減っていく。笑いは若さの証拠でもある。笑いのリストを作る。 笑うための話 笑った映画 笑ったシチュエーション 笑わせてくれる人たち まわりを笑顔にするアイデア 「願望リスト」は想像以上の力を秘めている。日付と願望を記入して手元に置いておくだけでいい。矛盾点を気にする必要はなく、人知を超えた神秘と奇跡を信じること。 いつかしたいこと いつかなりたい自分 いつか実現したいこと 神秘を信じなくなったとき、人は死ぬのだ。── アルベルト・アインシュタイン 自分がどうしたいかを知っている人は、ほかの人よりもずっと早く目的を達成できる。それは、自分がどこへ向かっているかを知っているから。まず何から始めればよいかをわかっているから。"
},
{
url: "/p/3jt3bjr/",
title: "AWS DynamoDB 関連記事",
date: "2021-11-02T00:00:00Z",
body: "AWS DynamoDB 関連記事"
},
{
url: "/p/wht5epz/",
title: "DynamoDB を Python で操作する (boto3)",
date: "2021-11-02T00:00:00Z",
body: "DynamoDB を Python で操作する (boto3) （AWS SDK を使うときは、aws configure によるアクセスキーの設定は完了しているものと想定します） Boto3 のインストール Python 用の AWS SDK として Boto3 が用意されているので、これをインストールして使います。 PC のグローバル環境を汚さないように、venv による仮想環境を作って作業する ことをオススメします。 まず、仮想環境を作ってそこに入ります。 $ mkdir myapp \u0026amp;\u0026amp; cd myapp # アプリ用のディレクトリを作成 $ python3 -m venv .venv # 仮想環境の作成 $ source .venv/bin/activate # 仮想環境に入る 仮想環境 (.venv) 内に boto3 パッケージをインストールします。 (.venv) $ python3 -m pip install boto3 これで準備完了です。簡単！ 高レベル API と低レベル API Boto3 の API は、抽象度の高い API と、低い API の二種類が用意されています。 高レベル API（リソース API） 各 AWS リソースを、オブジェクト指向なコードで扱うことができる。boto3.resource(リソース名) でインスタンスを取得できる。（参考: Resources） 低レベル API（クライアント API） AWS のサービス API と 1:1 で対応する構成になっており、各種 API の戻り値は単純な dict オブジェクト。boto3.client(リソース名) でインスタンスを取得できる。（参考: Low-level clients、client 関数） import boto3 # 高レベル API を使うとき dynamodb = boto3.resource(\u0026#39;dynamodb\u0026#39;) # 低レベル API を使うとき dynamodb_client = boto3.client(\u0026#39;dynamodb\u0026#39;) リソース API は、内部でクライアント API を使って実装されています。 DynamoDB Local サーバーに接続する # 高レベル API を使うとき dynamodb = boto3.resource(\u0026#39;dynamodb\u0026#39;, endpoint_url=\u0026#39;http://localhost:8000\u0026#39;) # 低レベル API を使うとき dynamodb_client = boto3.client(\u0026#39;dynamodb\u0026#39;, endpoint_url=\u0026#39;http://localhost:8000\u0026#39;) dynamodb のリソースインスタンス、あるいはクライアントインスタンスを生成するときに、上記のように endpoint_url を指定することで、ローカルで実行している DynamoDB Local サーバーに接続することができます。 DynamoDB テーブルのリストを取得する 高レベル API dynamodb_resource.tables.all() で全ての DynamoDB テーブルを取得できます。 戻り値は Dynamodb.Table のリストです。 import boto3 dynamodb = boto3.resource(\u0026#39;dynamodb\u0026#39;) # dynamodb = boto3.resource(\u0026#39;dynamodb\u0026#39;, endpoint_url=\u0026#39;http://localhost:8000\u0026#39;) # すべてのテーブルの名前を列挙する for tbl in dynamodb.tables.all(): print(tbl.name) 低レベル API DynamoDB.Client.list_tables メソッドでテーブルの一覧を取得できます。 戻り値は辞書オブジェクトで、TableNames プロパティにテーブル名の文字列リストが入っています。 import boto3 dynamodb_client = boto3.client(\u0026#39;dynamodb\u0026#39;) res = dynamodb_client.list_tables() print(res[\u0026#39;TableNames\u0026#39;]) 実行結果 [\u0026#39;Books\u0026#39;, \u0026#39;Games\u0026#39;, \u0026#39;Movies\u0026#39;] DynamoDB テーブルを作成する (create_table リソース API) DynamoDB テーブルを作成するには、create_table リソース API を使用します。 テーブルのプライマリキーの定義方法は相変わらず古くてわかりにくい方法でしか記述できません。 次の例では、Books テーブルを作成して、テーブルが生成されるまで待機しています。 プライマリキーとしては、パーティションキーの BookId、ソートキーの Title を設定しています。 Books テーブルを作成する import boto3 dynamodb = boto3.resource(\u0026#39;dynamodb\u0026#39;) # dynamodb = boto3.resource(\u0026#39;dynamodb\u0026#39;, endpoint_url=\u0026#39;http://localhost:8000\u0026#39;) def create_books_table(): table = dynamodb.create_table( TableName=\u0026#39;Books\u0026#39;, KeySchema=[ { \u0026#39;AttributeName\u0026#39;: \u0026#39;BookId\u0026#39;, \u0026#39;KeyType\u0026#39;: \u0026#39;HASH\u0026#39; }, { \u0026#39;AttributeName\u0026#39;: \u0026#39;Title\u0026#39;, \u0026#39;KeyType\u0026#39;: \u0026#39;RANGE\u0026#39; } ], AttributeDefinitions=[ { \u0026#39;AttributeName\u0026#39;: \u0026#39;BookId\u0026#39;, \u0026#39;AttributeType\u0026#39;: \u0026#39;S\u0026#39; }, { \u0026#39;AttributeName\u0026#39;: \u0026#39;Title\u0026#39;, \u0026#39;AttributeType\u0026#39;: \u0026#39;S\u0026#39; }, ], # オンデマンドにする場合 BillingMode=\u0026#39;PAY_PER_REQUEST\u0026#39; # プロビジョンドにする場合 # ProvisionedThroughput={ # \u0026#39;ReadCapacityUnits\u0026#39;: 1, # \u0026#39;WriteCapacityUnits\u0026#39;: 1 #} ) return table if __name__ == \u0026#39;__main__\u0026#39;: print(\u0026#39;Creat table...\u0026#39;) table = create_games_table() table.wait_until_exists() print(\u0026#39;Created!\u0026#39;) print(\u0026#39;Table status:\u0026#39;, table.table_status) print(\u0026#39;Item count:\u0026#39;, table.item_count) テーブルがすでに存在する場合は、ResourceInUseException 例外が発生します。 create_table 引数には、他にも次のようなものを指定できます。 # タグ Tags=[ { \u0026#39;Key\u0026#39;: \u0026#39;key-1\u0026#39;, \u0026#39;Value\u0026#39;: \u0026#39;value-1\u0026#39; }, { \u0026#39;Key\u0026#39;: \u0026#39;key-2\u0026#39;, \u0026#39;Value\u0026#39;: \u0026#39;value-2\u0026#39; }, ] # GSI（グローバル・セカンダリー・インデックス） GlobalSecondaryIndexes=[ { \u0026#39;IndexName\u0026#39;: \u0026#39;string\u0026#39;, \u0026#39;KeySchema\u0026#39;: [ { \u0026#39;AttributeName\u0026#39;: \u0026#39;string\u0026#39;, \u0026#39;KeyType\u0026#39;: \u0026#39;HASH\u0026#39;|\u0026#39;RANGE\u0026#39; }, ], \u0026#39;Projection\u0026#39;: { \u0026#39;ProjectionType\u0026#39;: \u0026#39;ALL\u0026#39;|\u0026#39;KEYS_ONLY\u0026#39;|\u0026#39;INCLUDE\u0026#39;, \u0026#39;NonKeyAttributes\u0026#39;: [ \u0026#39;string\u0026#39;, ] }, \u0026#39;ProvisionedThroughput\u0026#39;: { \u0026#39;ReadCapacityUnits\u0026#39;: 10, \u0026#39;WriteCapacityUnits\u0026#39;: 10 } }, ] テーブルが必要なくなったら、次の AWS CLI コマンドで削除できます。 $ aws dynamodb delete-table --table-name Books DynamoDB テーブルを削除する（table.delete / client.delete_table） DynamoDB 内の既存のテーブル削除するには、下記のような API を使用します。 テーブル名を指定するだけなので、どちらも使い方はほぼ同じです。 リソース API（高レベル）: DynamoDB.Table.delete メソッド クライアント API（低レベル）: DynamoDB.ServiceResource.delete_table メソッド テーブル内のアイテムがすべて削除されるので、注意して実行してください。 リソース API の場合 (Table.delete) import boto3 # Books テーブルを参照する dynamodb = boto3.resource(\u0026#39;dynamodb\u0026#39;).Table(\u0026#39;Books\u0026#39;) # Books テーブルを削除する table.delete() クライアント API の場合 (delete_table) import boto3 dynamodb_client = boto3.client(\u0026#39;dynamodb\u0026#39;) dynamodb_client.delete_table(TableName=\u0026#39;Books\u0026#39;) 存在しないテーブルを削除しようとすると、ResourceNotFoundException が発生します。 テーブルを削除すると、そこに設定されている DynamoDB Stream も 24 時間以内に削除されます。 DynamoDB テーブルにアイテムを追加する（put_item リソース API） DynamoDB テーブルにアイテムを追加するには、DynamoDB.Table.put_item メソッドを使用します。 次の例では、既存の Books テーブルに、3 つのアイテムを追加しています。 import boto3 # Books テーブルを参照する table = boto3.resource(\u0026#39;dynamodb\u0026#39;).Table(\u0026#39;Books\u0026#39;) # Books テーブルにアイテムを追加する table.put_item(Item={\u0026#39;BookId\u0026#39;: \u0026#39;001\u0026#39;, \u0026#39;Title\u0026#39;: \u0026#39;Title-1\u0026#39;}) table.put_item(Item={\u0026#39;BookId\u0026#39;: \u0026#39;002\u0026#39;, \u0026#39;Title\u0026#39;: \u0026#39;Title-2\u0026#39;}) table.put_item(Item={\u0026#39;BookId\u0026#39;: \u0026#39;003\u0026#39;, \u0026#39;Title\u0026#39;: \u0026#39;Title-3\u0026#39;}) 次の AWS CLI コマンドで、ちゃんとアイテムが追加できているかを確認できます。 $ aws dynamodb scan --table-name Books DynamoDB テーブルに効率的に書き込む（batch_writer リソース API） 何度も put_item や delete_item をしたいときは、DynamoDB.Table オブジェクトのメソッドを直接呼び出すのではなく、batch_writer メソッドで取得したバッチライターオブジェクト経由で実行すると、まとまった単位で効率的に書き込みを行うことができます（通信回数が減ります）。 import boto3 # Books テーブルを参照する table = boto3.resource(\u0026#39;dynamodb\u0026#39;).Table(\u0026#39;Books\u0026#39;) # Books テーブルに複数のアイテムを追加する with table.batch_writer() as batch: for i in range(10): book_id = \u0026#39;%03d\u0026#39; % i title = \u0026#39;Title-%d\u0026#39; % i batch.put_item(Item={\u0026#39;BookId\u0026#39;: book_id, \u0026#39;Title\u0026#39;: title}) DynamoDB テーブルをスキャンする（全てのアイテムを取得する） (scan) DynamoDB.Table.scan メソッドで、テーブル内の全てのアイテムを取得（スキャン）することができます。 スキャン結果のアイテムのリストは、scan() の戻り値の Items プロパティに格納されています。 多数のアイテムが格納されているテーブルに対してスキャンすると、RCU の消費量が大きくなるので注意してください。 Limit 引数で取得件数を制限すれば、消費 RCU も減ります。 基本的なスキャン import boto3 # Games テーブルから 5 件のアイテムを取得 table = boto3.resource(\u0026#39;dynamodb\u0026#39;).Table(\u0026#39;Games\u0026#39;) response = table.scan(Limit=5, ReturnConsumedCapacity=\u0026#39;TOTAL\u0026#39;) # スキャン結果の表示 items = response[\u0026#39;Items\u0026#39;] rcu = response[\u0026#39;ConsumedCapacity\u0026#39;][\u0026#39;CapacityUnits\u0026#39;] print(\u0026#39;Scanned items: %d\u0026#39; % len(items)) print(\u0026#39;Consumed capacity: %.2fRCU\u0026#39; % rcu) for item in items: print(item[\u0026#39;Date\u0026#39;], item[\u0026#39;Title\u0026#39;]) 実行結果 Scanned items: 5 Consumed capacity: 0.50 RCU 1993-07-30 バリ・アーム 1994-03-25 ダンジョンマスターII スカルキープ 1994-09-22 スター・ウォーズ レベル・アサルト 1993-11-19 ナイトトラップ 1992-09-11 ブライ 八玉の勇士伝説 合計 1MB 以上のアイテムをスキャンする DynamoDB の制約として、一度に 1MB までのデータしかスキャンできないという制約があります（クエリの場合も同様です）。 大量のアイテムを一気に取得したいときは、戻り値オブジェクトに含まれる LastEvaluatedKey プロパティを使って、繰り返しスキャンを行う必要があります。 次の scan() の ExclusiveStartKey 引数にその値を渡すことで、続きのアイテムを取得することができます。 import boto3 table = boto3.resource(\u0026#34;dynamodb\u0026#34;).Table(\u0026#34;Games\u0026#34;) # 繰り返しスキャンして全てのアイテムを取得 def scan_all_games(): games = [] response = table.scan() while True: games.extend(response[\u0026#34;Items\u0026#34;]) if \u0026#34;LastEvaluatedKey\u0026#34; not in response: break response = table.scan(ExclusiveStartKey=response[\u0026#34;LastEvaluatedKey\u0026#34;]) return games # 全スキャンの実行と結果の表示 games = scan_all_games() print(\u0026#34;%ditems\u0026#34; % len(games)) for game in games: print(game[\u0026#34;Date\u0026#34;], game[\u0026#34;Title\u0026#34;]) DynamoDB テーブルから 1 つのアイテムを取得する (get_item) DynamoDB.Table.get_item メソッドで、指定したプライマリキーに一致するアイテムを 1 件取得することができます。 取得結果は、戻り値の Item プロパティに格納されています。 アイテムが見つからなかった場合は、Item プロパティ自体が存在しなくなります。 import boto3 # Games テーブルから指定したプライマリキーに一致するアイテムを取得 table = boto3.resource(\u0026#34;dynamodb\u0026#34;).Table(\u0026#34;Games\u0026#34;) response = table.get_item(Key={\u0026#34;GameId\u0026#34;: \u0026#34;zjorzdp\u0026#34;}) # 取得結果を表示 if \u0026#34;Item\u0026#34; in response: item = response[\u0026#34;Item\u0026#34;] print(item[\u0026#34;Date\u0026#34;], item[\u0026#34;Title\u0026#34;]) else: print(\u0026#34;Not found\u0026#34;) （おまけ）DynamoDB から取得した結果を JSON 文字列に変換する Python 標準モジュールの json.dumps 関数を使うと、任意のオブジェクトを JSON 形式の文字列に変換することができますが、DynamoDB のデータを変換するときは注意が必要です。 DynamoDB の数値 (number) カラムの値を取得すると、Python では Decimal 型として保持されるのですが、JSON では数値は float 型しか表現できません。 そのため、DynamoDB から取得したデータをそのまま JSON 文字列に変換しようとすると、次のようなエラーが発生します。 TypeError: Object of type Decimal is not JSON serializable json.dumps 関数の default 引数でフック関数を渡すと、JSON 形式に変換できない値（今回の場合は Decimal）が見つかったときに、どのように変換すべきかを定義することができます。 import boto3 import decimal import json # json.dumps() のシリアライズ用フック（Decimal → float） def decimal_serializer(obj): if isinstance(obj, decimal.Decimal): return float(obj) raise TypeError if __name__ == \u0026#34;__main__\u0026#34;: # DynamoDB の Games テーブルをスキャンして JSON 文字列で出力 response = boto3.resource(\u0026#34;dynamodb\u0026#34;).Table(\u0026#34;Games\u0026#34;).scan() json_text = json.dumps( response, indent=2, ensure_ascii=False, default=decimal_serializer ) print(json_text)"
},
{
url: "/p/d4p4fr4/",
title: "Next.js で開発環境で実行しているときに Web サイト上に dev 表示する (TargetEnvIndicator)",
date: "2021-10-29T00:00:00Z",
body: "Next.js で開発環境で実行しているときに Web サイト上に dev 表示する (TargetEnvIndicator) 何をするか？ Next.js (React) などで Web サイトの開発を行うとき、その開発フェーズに応じて、開発環境 (dev)、ステージング環境 (stg)、本番環境 (prod) などを分けてリリースしていくことが多いと思います。 このとき、ブラウザ上でどのフェーズのサイトを表示しているのかが分かるように、画面上に dev 環境 のようなインジケーターを表示すると便利です（上図）。 ここでは、環境変数 NEXT_PUBLIC_TARGET_ENV の値が prod 以外のときに、上記のような表示をすることにします。 参考: Next.js で環境変数を扱う (.env, NEXT_PUBLIC, NODE_ENV) 実装例 次のコンポーネント TargetEnvIndicator は、画面右下に環境名（例: dev 環境）を表示します。 components/common/TargetEnvIndicator.tsx import { FC } from \u0026#39;react\u0026#39; /** * ビルド時のターゲット環境が `prod` 以外のときに、画面右下に環境名を表示します。 */ export const TargetEnvIndicator: FC = () =\u0026gt; { const target = process.env.NEXT_PUBLIC_TARGET_ENV ?? \u0026#39;dev\u0026#39; // 本番環境 (prod) の場合は何も表示しない if (target === \u0026#39;prod\u0026#39;) return null return ( \u0026lt;div style={{ position: \u0026#39;fixed\u0026#39;, right: 10, bottom: 10, padding: \u0026#39;0.2em 0.6em\u0026#39;, borderRadius: \u0026#39;0.2em\u0026#39;, fontSize: \u0026#39;16pt\u0026#39;, background: \u0026#39;#f008\u0026#39;, color: \u0026#39;#fffd\u0026#39;, zIndex: 1000, }} \u0026gt; {target} 環境 \u0026lt;/div\u0026gt; ) } ターゲット環境は環境変数 NEXT_PUBLIC_TARGET_ENV で指定しますが、この環境変数が設定されていない場合は、デフォルトで「dev 環境」と表示します。 NEXT_PUBLIC_TARGET_ENV の値 表示内容 prod 何も表示しない prod 以外 \u0026lt;その値\u0026gt; 環境 未設定 dev 環境 上記のコンポーネントは、アプリ全体に適用されるように、例えば、カスタム App コンポーネントの中で次のように記述しておきます。 pages/_app.tsx // ... import { TargetEnvIndicator } from \u0026#39;../components/common/TargetEnvIndicator\u0026#39; export default function MyApp({ Component, pageProps }: AppProps): JSX.Element { // ... return ( \u0026lt;\u0026gt; \u0026lt;Head\u0026gt; \u0026lt;title\u0026gt;My App\u0026lt;/title\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;minimum-scale=1, initial-scale=1, width=device-width\u0026#34; /\u0026gt; \u0026lt;/Head\u0026gt; \u0026lt;ThemeProvider theme={theme}\u0026gt; \u0026lt;CssBaseline /\u0026gt; \u0026lt;Component {...pageProps} /\u0026gt; \u0026lt;TargetEnvIndicator /\u0026gt; \u0026lt;/ThemeProvider\u0026gt; \u0026lt;/\u0026gt; ) } あとは、ビルド時 (next build) や開発時 (next dev) に、環境変数 NEXT_PUBLIC_TARGET_ENV を設定しておけば、その名前がブラウザ画面右下に表示されるようになります（prod の場合は何も表示しません）。"
},
{
url: "/p/raz82p6/",
title: "読書メモ『HEALTH HACKS!』川田浩志",
date: "2021-10-25T00:00:00Z",
body: "読書メモ『HEALTH HACKS!』川田浩志 HEALTH HACKS! 川田浩志 ディスカヴァー・トゥエンティワン 健康は何よりも重要！ 本書には、健康に効果があって（エビデンスがあって）、かつ続けられる方法がいろいろと示されています。 著者は、「年収が上がると健康度が上がる」のではなくて、「健康度が上がると年収が上がる」と考えています。 だから、健康への自己投資は若いときから続けるのがよいと。 ごもっとも。 以下、参考になったことをメモメモ。 メモ 考え方 健康度は主観的なものだが、自分の健康度が高いと思っているほど寿命が長いという結果がある。 健康度を挙げるには、正しい知識を付けて、自信をもって健康に良いことをする 必要がある。 ジムや健康食品、健康法などの問題は、続けられないこと（▽RIZAPとかはこのあたりに目を付けてますね^^）。だから、効果があって続けられそうなこと から少しずつ自分の生活に取り込んでいくのがよい。 周りの人たちの健康も考えてあげることで、Win-Win で健康になっていく。 明るい、楽天的、活動的 → 長寿 運動 『家庭用トレッドミル』 はおすすめ。テレビを見ながらでもできるので時間の節約になるし、雨の日でも、真夏で外に出られなくても、毎日続けられる。外出用に着替える必要もない。折り畳み式のものであれば、場所もとらない。音楽を聴きながら、目をつぶって歩くととても気持ちがよい。 運動にはがん予防の効果がある（大腸がん、乳がん）。 筋トレは何歳で始めても必ず効果が出る。 食事 白パン、マーガリン、ハム、ソーセージみたいない朝食を続けるくらいなら、朝食は抜いたほうがまし。 現在では、カロリーの接種を控えめにすることが一番 健康保持と長寿に有力。お腹いっぱい食べるのではなく、腹七分ないし八分目を意識すべし。 寿命を延ばすには、インスリンの濃度を低く保つ こと。GI 値が高い商品（炭水化物）は、血糖値を上げるのでインスリンが出て細胞の寿命がどんどん縮む。野菜から食べ始める のがやはり効果的。 リスベラトロール を摂ると、インスリンの分泌を低く保つことができる。 皮ごと食べられるブドウ、赤ワイン、グレープジュース カリフォルニア・レーズン アーモンドの皮 年を取ると、のどの渇きを感じにくくなるので、水は決めた量を飲むようにする。これは血液の流れをよくするため。男性2ℓ、女性1.5ℓ くらい（食事に含まれる水分を含む）。 水の取りすぎで「むくむ」ことはなく、むくみの原因は塩分の取りすぎにある（血液の浸透圧が高くなるから）。 飲酒は少量であっても様々ながんの発症リスク を高めてしまう。乳がん、食道がん、大腸がん、肝臓がんなどのリスクが上がる。顔が赤くなる人は特に注意。飲酒がメリットになる日本人は少ない。 ミネラルウォーターの含有ヒ素濃度は、水道水の 5 倍まで認可されている。▽日本の水道水は安全度が高いということ。 善玉コレステロールを増やすには、よい油を摂る。グレープシードオイル や エゴマ油 をドレッシングにするとよい。 サプリメント サプリメントでおすすめなのは、ビタミン A の代わりに ベータカロテン を使っている マルチビタミン・ミネラル サプリメント。ベータカロテンは体内で必要なだけビタミン A に変換してくれる。 マルチビタミン・ミネラルのサプリメントは毎日飲み続ける必要はなく、食生活が不規則だなと感じたときに数日間飲むといい。ただし、肉やワインをよく接種する人は鉄の取りすぎになるので、鉄抜きのものを選ぶとよい。 見た目 歯が白いだけで印象はだいぶよくなる。リンゴ酸入りの歯磨き粉 などを使うとよい。見た目を先に改善 することで、健康を維持しようというモチベーションが上がる。 人と会う前には目薬をしておくとよい。 顔を若く保つには UV ケアが何より大切。現在では、シワの原因のほとんどは日光からの紫外線 であることが分かっている。昔は日光に当たることがよいなどと言われていたことがあったが、日光に直接当たるのは百害あって一利なし。木陰に 10 分いるだけでビタミン D の活性化にも十分。 普段の日焼け止めの SPF は 10 程度 で十分。SPF が高くなると皮膚に有害 だが、日本ではほとんど規制されておらず、高いものが出回っている。"
},
{
url: "/p/s3o57jv/",
title: "AWS SSM のポリシーステートメントの記述例",
date: "2021-10-15T00:00:00Z",
body: "AWS SSM のポリシーステートメントの記述例 参考: AppSync / Lambda パラメーターの説明情報の取得 すべてのパラメーターの説明情報を取得できるようにする { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;ssm:DescribeParameters\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } ssm:DescribeParameters は、SSM パラメーターストアに格納されたパラメーターの説明情報を取得する権限です。 この権限だけでは、パラメーターの「値」自体は取得できないことに注意してください。 パラメーターの値の取得 prod- で始まるパラメーターの値を取得できるようにする { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;ssm:GetParameter*\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:ssm:\u0026lt;Region\u0026gt;:\u0026lt;Account\u0026gt;:parameter/prod-*\u0026#34; } ] } パラメーターの Get 系アクションには、GetParameter/GetParameters/GetParameterHistory/GetParametersByPath など いろいろある ため、上記のように ssm:GetParameter* とワイルドカード指定しておくと確実に取得できるようになります。 GetParameter だけだと、パラメーターの一覧取得などが許可されません。 パラメーターの追加・削除 prod- で始まるパラメーターの追加と削除を許可する { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;ssm:PutParameter\u0026#34;, \u0026#34;ssm:DeleteParameter\u0026#34;, \u0026#34;ssm:DeleteParameters\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:ssm:\u0026lt;Region\u0026gt;:\u0026lt;Account\u0026gt;:parameter/prod-*\u0026#34; } ] } 暗号化されたパラメーター (SecureString) の取得 暗号化された prod- で始まるパラメーターを読み込む { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;ssm:GetParameter*\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:ssm:\u0026lt;Region\u0026gt;:\u0026lt;Account\u0026gt;:parameter/prod-*\u0026#34; ] }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;kms:Decrypt\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:kms:\u0026lt;Region\u0026gt;:\u0026lt;Account\u0026gt;:key/\u0026lt;KmsKey\u0026gt;\u0026#34; ] } ] } SSM パラメーターストアに SecureString タイプとして格納されたパラメーターは、KMS キーによって暗号化されています。 このパラメーターの値を取得するには、ssm:GetParameter* によるパラメーター読み取り権限と、kms:Decrypt による複合化の権限が必要です。 暗号化されたパラメーター (SecureString) の作成 { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;ssm:PutParameter\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:ssm:\u0026lt;Region\u0026gt;:\u0026lt;Account\u0026gt;:parameter/prod-*\u0026#34; ] }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;kms:Encrypt\u0026#34;, \u0026#34;kms:GenerateDataKey\u0026#34; // 暗号化された詳細パラメータの作成に必要 ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:kms:\u0026lt;Region\u0026gt;:\u0026lt;Account\u0026gt;:key/\u0026lt;KmsKey\u0026gt;\u0026#34; ] } ] } Principal で特定のユーザーに権限を絞る { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;Allow SSM parameter access for maku\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: {\u0026#34;AWS\u0026#34;: \u0026#34;arn:aws:iam::111122223333:user/maku\u0026#34;}, \u0026#34;Action\u0026#34;: [ \u0026#34;ssm:PutParameter\u0026#34;, \u0026#34;ssm:DeleteParameter\u0026#34;, \u0026#34;ssm:DeleteParameters\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:ssm:\u0026lt;Region\u0026gt;:\u0026lt;Account\u0026gt;:parameter/prod-*\u0026#34; ] } ] }"
},
{
url: "/p/5o2cnw8/",
title: "AWS SSM (Systems Manager) 関連メモ",
date: "2021-10-15T00:00:00Z",
body: "AWS SSM (Systems Manager) 関連メモ"
},
{
url: "/p/3nybkv6/",
title: "AWS KMS 関連メモ",
date: "2021-10-14T00:00:00Z",
body: "AWS KMS 関連メモ"
},
{
url: "/p/m8jv7hr/",
title: "AWS KMS をコマンドライン (CLI) で操作する",
date: "2021-10-14T00:00:00Z",
body: "AWS KMS をコマンドライン (CLI) で操作する SSM パラメーターストア用の AWS マネージドキーを確認する $ aws kms describe-key --key-id alias/aws/ssm 実行結果 KeyMetadata: AWSAccountId: \u0026#39;123456789012\u0026#39; Arn: arn:aws:kms:ap-northeast-1:123456789012:key/d7ce1afa-a7d4-fe43-2da2-4ddd769480d7 CreationDate: \u0026#39;2021-10-14T03:34:31.467000+09:00\u0026#39; CustomerMasterKeySpec: SYMMETRIC_DEFAULT Description: Default key that protects my SSM parameters when no other key is defined Enabled: true EncryptionAlgorithms: - SYMMETRIC_DEFAULT KeyId: d7ce1afa-a7d4-fe43-2da2-4ddd769480d7 KeyManager: AWS KeyState: Enabled KeyUsage: ENCRYPT_DECRYPT Origin: AWS_KMS KMS キーを作成する (kms create-key) aws kms create-key KMS キー (CMK: Customer Master Key) は作成は一瞬でできますが、削除は最低 7 日かかるので注意してください。 KMS キーを削除する (kms schedule-key-deletion / cancel-key-deletion) KMS キーの削除にはリスクを伴うので、削除するまでの猶予期間として 7～30 日を指定する必要があります（kms delete-key のような即削除のコマンドは用意されていません）。 7 日後に KMS キーを削除する $ aws kms schedule-key-deletion \\ --key-id 9a6dff25-5ba8-364e-5e92-4123d37d43a1 \\ --pending-window-in-days 7 削除スケジュールをキャンセルするには次のように実行します。 $ aws kms cancel-key-deletion \\ --key-id 9a6dff25-5ba8-364e-5e92-4123d37d43a1 \\ 上記の操作を行うには、それぞれ、kms:ScheduleKeyDeletion 権限と kms:CancelKeyDeletion 権限が必要です。"
},
{
url: "/p/aug76s5/",
title: "AWS SSM をコマンドライン (CLI) で操作する",
date: "2021-10-13T00:00:00Z",
body: "AWS SSM をコマンドライン (CLI) で操作する パラメーターストアにパラメーターを格納する (ssm put-parameter) String（文字列） /myapp/param1 という名前のパラメーターとして value1 を格納 $ aws ssm put-parameter --name /myapp/param1 \\ --value \u0026#34;value1\u0026#34; --type String \\ --tags \u0026#34;Key=key1,Value=value1\u0026#34; 既存のパラメーターの値を更新する場合は、--overwrite オプションが必要です（Version 情報がインクリメントされます）。 /myapp/param1 の値を value2 に書き換え $ aws ssm put-parameter --name /myapp/param1 \\ --value \u0026#34;value2\u0026#34; --type String --overwrite Tier: Standard Version: 2 SecureString（暗号化された文字列） デフォルトの AWS マネージドキーを使って暗号化 $ aws ssm put-parameter --name /myapp/param1 \\ --value \u0026#34;secret_value\u0026#34; --type SecureString デフォルトのキーは、アカウントで共通のものになります。 作成した KMS キーを使って暗号化 $ aws ssm put-parameter --name /myapp/param1 \\ --value \u0026#34;secret_value\u0026#34; --type SecureString \\ --key-id \u0026#34;\u0026lt;KeyId\u0026gt;\u0026#34; \\ KeyId は次のいずれかの形式で指定できます。 ARN (Amazon Resource Name) arn:aws:kms:us-east-2:123456789012:key/12345678-1234-1234-1234-123456789012 エイリアス ARN arn:aws:kms:us-east-2:123456789012:alias/MyAliasName キー ID 12345678-1234-1234-1234-123456789012 エイリアス alias/MyAliasName 独自の KMS キーを使ってパラメーターを暗号化する場合は、KMS キーの kms:Encrypt 権限が必要です。 StringList（文字列のリスト） value1、value2、value3 という 3 つの値を格納 $ aws ssm put-parameter --name /myapp/param1 \\ --value \u0026#34;value1,value2,value3\u0026#34; --type StringList パラメーターストアからパラメーターを取得する (ssm get-parameter(s)) パラメーターの値を取得する $ aws ssm get-parameter --name /myapp/param1 --output yaml 実行結果 Parameter: ARN: arn:aws:ssm:ap-northeast-1:123456789012:parameter/myapp/param1 DataType: text LastModifiedDate: \u0026#39;2021-10-13T17:37:25.108000+09:00\u0026#39; Name: /myapp/param1 Type: SecureString Value: AQICAHhLiblDAUFGpE...(省略)...1T9iD+1QpcEWcerOhvQ== Version: 1 SecureString の値を復号化する パラメーターの Type が SecureString の場合、デフォルトでは上記のように Value は暗号化された値で返されます。 Value の値を複合化するときは with-decryption オプションを指定します。 パラメーターを複合化には、ユーザーに kms:Decrypt 権限が必要です。 パラメータ値を復号化する場合 $ aws ssm get-parameter --name /myapp/param1 --output yaml 実行結果 Parameter: ARN: arn:aws:ssm:ap-northeast-1:123456789012:parameter/myapp/param1 DataType: text LastModifiedDate: \u0026#39;2021-10-13T17:37:25.108000+09:00\u0026#39; Name: /myapp/param1 Type: SecureString Value: \u0026#34;my secret value\u0026#34; Version: 1 パラメーターの値だけを取得する $ aws ssm get-parameter --name /myapp/param1 --query Parameter.Value \u0026#34;Hello World\u0026#34; 複数のパラメーターを同時に取得する $ aws ssm get-parameters --names /myapp/param1 /myapp/param2 コマンド名とオプション名に、複数形の s が付くことに注意してください。 値だけ取得したいとき $ aws ssm get-parameters --names /myapp/param1 /myapp/param2 \\ --query \u0026#34;Parameters[*].Value\u0026#34; パラメーターストアからパラメーターを削除する (ssm delete-parameter) パラメーター /myapp/param1 を削除する $ aws ssm delete-parameter --name /myapp/param1 参考: ssm delete-parameter パラメーターストア内のパラメーターの変更履歴を取得する (ssm get-parameter-history) aws ssm put-parameter でパラメーターの値を変更した場合に、その変更履歴を確認したいときは、ssm get-parameter-history コマンドを使用します。 $ aws ssm get-parameter-history --name /myapp/param1 パラメーターを検索する (ssm describe-parameters) パラメーター名が /myapp/dev/ で始まるものを検索する $ aws ssm describe-parameters \\ --parameter-filters \u0026#34;Key=Name,Option=BeginsWith,Values=/myapp/dev/\u0026#34; Option=BeginsWith, の部分を省略すると、デフォルトの Option=Equals 扱いになり、完全一致での検索になります。 パラメーター名の一部に GitHub を含むものを検索する $ aws ssm describe-parameters \\ --parameter-filters \u0026#34;Key=Name,Option=Contains,Values=GitHub\u0026#34; 出力結果に、パラメータの「値」自体は含まれません。 参考: describe-parameters — AWS CLI Command Reference 参考: Systems Manager のパラメータを検索する - AWS Systems Manager"
},
{
url: "/p/vx5ta85/",
title: "AWS CDK で外部パラメーターを扱う（コンテキスト・バリューと環境変数）",
date: "2021-10-11T00:00:00Z",
body: "AWS CDK で外部パラメーターを扱う（コンテキスト・バリューと環境変数） CDK コードに外部パラメーターを与える方法 AWS CDK による CloudFormation スタックの構築時に、外部からキー＆バリューの形でパラメーターを設定したいときは、主に次の 3 つの方法があります（クラウド上に値を保存するパラメーターストアなどは対象外とします）。 Context values （コンテキスト・バリュー） Environment variables （環境変数） CloudFormation parameters （CloudFormation パラメーター） S3 バケットの名前をパラメーター化したり、デプロイターゲットを staging と production の間で切り替えたりするときに使えます。 Context values（コンテキスト・バリュー） コンテキスト・バリューは、CDK 特有の仕組みで、cdk deploy 実行時のコマンドライン引数や、cdk.json ファイルの中で、キー＆バリューのペアを設定することができます。 キーの型は string で、バリューの型は JSON がサポートするデータ型のいずれかです（string、number、オブジェクト、およびそれらの配列）。 コンテキスト・バリューは CDK の仕組みなので、CDK コードの中からしか参照できません。 Lambda 関数の中から値を参照したい場合は、Lambda 関数のコンストラクトを生成するときに、environment props などで間接的に渡す必要があります。 コマンドライン引数で指定する方法 cdk deploy コマンド（あるいは diff、synth）を実行するときに、--context (-c) オプションで、コンテキスト・バリューを設定できます。 $ cdk deploy --context key=value 複数のキー＆バリューペアを設定したいときは、単純にオプション指定を繰り返します。 $ cdk deploy -c key1=value1 -c key2=value2 コンテキスト・バリューは CDK アプリ内の全スタックに渡されますが、特定のスタックにのみ反映させることもできます。 $ cdk deploy -c Stack1:key1=value1 -c Stack2:key2=value2 cdk.json で指定する方法 cdk init app コマンドで CDK アプリを生成すると、cdk.json というファイルがプロジェクトのルートに配置されます。 このファイルの中の、context プロパティで、コンテキスト・バリュー用のキー＆バリューを記述しておくことができます。 ホームディレクトリの ~/cdk.json に記述しておくこともできます。 cdk.json { \u0026#34;app\u0026#34;: \u0026#34;npx ts-node --prefer-ts-exts bin/myapp.ts\u0026#34;, \u0026#34;context\u0026#34;: { \u0026#34;@aws-cdk/aws-apigateway:usagePlanKeyOrderInsensitiveId\u0026#34;: true, \u0026#34;@aws-cdk/core:enableStackNameDuplicates\u0026#34;: \u0026#34;true\u0026#34;, // ★このあたりに追加 \u0026#34;target\u0026#34;: \u0026#34;dev\u0026#34;, \u0026#34;bucket\u0026#34;: { \u0026#34;region\u0026#34;: \u0026#34;ap-northeast-1\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;my-bucket\u0026#34; } } } ちなみに、context プロパティには最初からいくつか値が設定されていますが、これらは各モジュール用の機能を有効化するための設定です（@aws-cdk/aws-lambda: のようなモジュール名のプレフィックスが付いています）。 これらは各機能を Off/On するためのものなので、Feature flags と呼ばれています（省略した場合のデフォルトは Off です）。 cdk.json ファイルの context プロパティの値よりも、cdk コマンドの --context 引数で指定した値が優先されるので、cdk.json ファイルの方にデフォルト設定を書いておき、cdk コマンド実行時に上書きするという運用が可能です。 $ cdk deploy # 省略時は cdk.json に記述した target=dev が使われる $ cdk deploy -c target=prod # 本番環境は明示的に target を上書き cdk.App コンストラクト生成時に指定する方法 コンストラクト生成時の context オプションで、明示的にコンテキスト・バリューを設定することもできます。 この値は、そのコンストラクタ以下のノード全体に反映されます。 bin/myapp.ts import * as cdk from \u0026#39;@aws-cdk/core\u0026#39; const app = new cdk.App({ context: { bucketName: \u0026#39;bucket-123456789012\u0026#39;, }, }) このように、トップレベルの cdk.App コンストラクトに設定すれば、すべての Stack コンストラクトから、this.node.tryGetContext() でそのコンテキスト・バリューを参照できるようになります。 コンテキスト・バリューの参照方法 CDK のコード内から、construct.node.tryGetContext 関数 を呼び出すことで、コンテキスト・バリューを参照できます。 次の例では、キー名 bucketName のコンテキスト・バリューを参照しています。 bin/myapp.ts import * as cdk from \u0026#39;@aws-cdk/core\u0026#39; const app = new cdk.App() const bucketName = app.node.tryGetContext(\u0026#39;bucketName\u0026#39;) as string if (bucketName == undefined) { throw new Error(\u0026#39;Context value [bucketName] is not set\u0026#39;) } console.log(`bucketName = ${bucketName}`) // ... 各スタックの定義 ... tryGetContext 関数の戻り値は any 型で、指定したキーに対応する値がセットされていないときは、undefined を返します（TypeScript の場合）。 デプロイのために必須の値であれば、戻り値が undefined のときに Error をスローすることで cdk コマンドの実行を終了させることができます。 （おまけ）cdk.context.json ファイル cdk コマンド実行時にキャッシュファイル (cdk.context.json) が生成されることがあります。 CDK のコードから Stack の availabilityZones を参照したり、パラメーターストアを参照したりすると、cdk synth のタイミングで生成されるようです。 これは、cdk コマンドの実行を効率化するためのものであり、2 回目以降の実行では、このファイルに保存されたコンテキスト・バリューが参照されるようになります。 このキャッシュは自動的に削除されることはないので、例えば、パラメーターストア側の設定値を変更してすぐに反映したいときは、cdk context --clear コマンドなどで cdk.context.json の内容をクリアする必要があります。 （おまけ）cdk context コマンド cdk context コマンドを引数なしで実行すると、cdk.json ファイルや cdk.context.json ファイルで設定されているコンテキスト・バリューの一覧を確認することができます。 $ cdk context # テーブル形式で表示 $ cdk context -j # JSON形式で表示 cdk context --clear コマンドを実行すると、cdk.context.json ファイルに保存された情報（キャッシュ）をクリアできます。 cdk.json ファイルの context プロパティの値はクリアされません。 $ cdk context --clear # 全クリア $ cdk context --reset \u0026lt;Name\u0026gt; # キー名を指定してクリア（インデックス指定も可） Environment variables（環境変数） CDK コードの中から、process.env.環境変数名 で環境変数の値を取得することができます（設定されていない場合は undefined になります）。 new MyappStack(app, \u0026#39;MyappStack\u0026#39;, { env: { account: process.env.CDK_DEFAULT_ACCOUNT, region: process.env.CDK_DEFAULT_REGION }, }) 環境変数は CDK の仕組みではないので、CDK のコードと Lambda 関数のコードで同じように参照することができますが、環境変数の値は実行時の環境によって変わってくることに注意してください。 あと、環境変数は文字列値しか保持できないので、オブジェクトを持てるコンテキスト・バリューの方が柔軟性があります。 コンストラクト・ツリーの子ノードのみに設定値を伝搬させるという仕組みも、コンテキスト・バリューにしかありません。 これらを考慮すると、基本的には、CDK によるデプロイ用のパラメーターとしては、コンテキスト・バリューの仕組みを使うのがよさそうです。 CDK Developers Guide の Best practices でも、コンストラクトの中での環境変数の参照はアンチパターン であると述べられています（トップレベル、つまり App コンストラクトでの参照はこの限りではないけれど、それ以下の階層へは props で伝搬させていくべき）。 一方、Lambda 関数からは CDK のコンテキスト・バリューを参照することはできないので、間接的にコンテキスト・バリューの値を使いたいときは、次のような感じで Lambda 関数コンストラクトの environment オプションで値を渡してやる必要があります（Lambda 関数の実行環境の環境変数として設定されます）。 const myLambda = new lambdaNodejs.NodejsFunction(this, \u0026#39;MyLambda\u0026#39;, { runtime: lambda.Runtime.NODEJS_14_X, entry: \u0026#39;lambda/index.ts\u0026#39;, environment: { S3_BUCKET_NAME: this.tryGetContext(\u0026#39;s3BucketName\u0026#39;) as string, S3_OBJECT_KEY: this.tryGetContext(\u0026#39;s3ObjectKey\u0026#39;) as string, }, }) CloudFormation parameters（CloudFormation パラメーター） この仕組みは CDK では非推奨とされています。 cdk deploy 時に、--parameters オプションを指定することで、CloudFormation パラメーターに相当するキー＆バリューを設定することができます。 $ cdk deploy --parameters uploadBucketName=UploadBucket 上記のように指定した CloudFormation パラメーターは、CDK コードの中から次のように参照することができます。 const uploadBucketName = new cdk.CfnParameter(this, \u0026#39;uploadBucketName\u0026#39;, { type: \u0026#39;string\u0026#39;, description: \u0026#39;Name of the bucket to store image files\u0026#39; }) const myBucket = new s3.Bucket(this, \u0026#39;uploadBucket\u0026#39;, { bucketName: uploadBucketName.valueAsString }) ただし、CloudFormation パラメーターはデプロイ時 (cdk deploy) にしか参照できず、Synthesize (cdk synth) のタイミングでは有効ではないという制約があります。 なぜなら、CloudFormation テンプレートは Synthesize 時に生成されるものであり、その時点では CloudFormation パラメーターはプレースホルダーとして残しておかなければいけないからです（コンテキスト・バリューのように Synthesize 時に値を展開できない）。 CDK アプリの他の部分とうまく連携がとれないため、コンテキスト・バリューの方を使うことが推奨されています。 応用： コンテキスト・バリューを使って実行環境 (staging/production) を切り替える アプリの実行環境は、次のような感じで、用途ごとに作成することが多いと思います。 本番環境 (production, prod) ステージング環境 (staging, stg) 開発環境 (develop, dev) 例えば、本番環境用の CloudFormation スタックと、ステージング環境用の CloudFormation スタックは分けて作成することになります。 CDK のコンテキスト・バリューの仕組みを使って、次のように cdk deploy 時にターゲットとする環境を切り替えることができます（targetEnv というキー名は勝手に決めた名前です）。 $ cdk deploy --context targetEnv=production # 本番環境用スタックの生成 $ cdk deploy --context targetEnv=staging # ステージング用スタックの生成 $ cdk deploy --context targetEnv=development # 開発環境用スタックの生成 あとは、App コンストラクトの CDK コードなどで、targetEnv の値を使って、各種コンフィグ値を切り替えることができます。 次の例では、config.ts というファイルに各環境用のコンフィグ情報を記述し、targetEnv の値で切り替えるようにしています。 lib/config.ts（各環境の設定情報） export type Config = { stackName: string stackDesc: string imageBucketName: string tags: { team: string targetEnv: string } } export function getConfig(targetEnv: string): Config { const stackName = `myapp-stack-${targetEnv}` const stackDesc = `MyApp stack for ${targetEnv}` switch (targetEnv) { case \u0026#39;production\u0026#39;: return { stackName, stackDesc, imageBucketName: \u0026#39;image-bucket-prod\u0026#39;, tags: { team: \u0026#39;ProdTeam\u0026#39;, targetEnv: \u0026#39;production\u0026#39;, }, } case \u0026#39;development\u0026#39;: return { stackName, stackDesc, imageBucketName: \u0026#39;image-bucket-dev\u0026#39;, tags: { team: \u0026#39;DevTeam\u0026#39;, targetEnv: \u0026#39;development\u0026#39;, }, } default: throw new Error( \u0026#39;Context value [targetEnv] is invalid (use production or development).\u0026#39; ) } } bin/myapp.ts（App コンストラクト） import * as cdk from \u0026#39;@aws-cdk/core\u0026#39; import { getConfig } from \u0026#39;../lib/config\u0026#39; import { MyappStack } from \u0026#39;../lib/myapp-stack\u0026#39; const app = new cdk.App() // ここでコンテキスト・バリューに基づいて Config 値を決定する const targetEnv = app.node.tryGetContext(\u0026#39;targetEnv\u0026#39;) as string const config = getConfig(targetEnv) // デフォルトを development とする場合 // const config = getConfig(targetEnv ?? \u0026#39;development\u0026#39;) // スタックの props として渡したりする new MyappStack(app, config.stackName, { env: { account: \u0026#39;123456789012\u0026#39;, region: \u0026#39;ap-northeast-1\u0026#39; }, description: config.stackDesc, tags: config.tags, config, }) lib/myapp-stack.ts（Stack コンストラクト） import * as cdk from \u0026#39;@aws-cdk/core\u0026#39; import { Config } from \u0026#39;./config\u0026#39; interface MyappStackProps extends cdk.StackProps { config: Config } export class MyappStack extends cdk.Stack { constructor(scope: cdk.Construct, id: string, props: MyappProps) { super(scope, id, props) // あとは props.config の値を使って煮るなり焼くなり }"
},
{
url: "/p/ap8p7n4/",
title: "AWS CDK メモ: Lambda 関数コードだけ高速デプロイする (cdk deploy --hotswap)",
date: "2021-10-06T00:00:00Z",
body: "AWS CDK メモ: Lambda 関数コードだけ高速デプロイする (cdk deploy --hotswap) AWS CDK によるデプロイ (cdk deploy) の実行には結構時間がかかりますが、Lambda 関数のコードだけ更新したいときは、hotswap オプションを付けて実行することで高速にデプロイできます。 Lambda 関数だけ高速更新 $ cdk deploy --hotswap ただし、これは開発時のみ使うべき機能として提供されており、Production 環境においては、通常通り CDK アプリ全体のデプロイを行うことが推奨されています。"
},
{
url: "/p/u9oenzf/",
title: "AWS CDK 関連メモ",
date: "2021-10-04T00:00:00Z",
body: "AWS CDK 関連メモ"
},
{
url: "/p/m9o2dyj/",
title: "読書メモ『夏への扉』ロバート・A・ハインライン",
date: "2021-09-20T00:00:00Z",
body: "読書メモ『夏への扉』ロバート・A・ハインライン 夏への扉 [新版] ロバート・A・ハインライン（訳：福島正実） 早川書房 タイムトラベルものの小説のひとつ、というかそのジャンルを確立させたとも言われているのがこの『夏への扉』です。 ロバート・A・ハインラインがはるか昔の1956年に書いたものですが、今読んでもまったく色褪せておらず、夏になると読み直したくなるという人が多いというのも納得です（別に夏に読む必要はないけどね）。 日本で SF ランキングを取ると今でも上位に出てくるので、日本人の感性に合っているのかもしれません。 そして、長い年を経て（65年！）、今年ついに映画化 されました。 なんと舞台は日本です。 原作では1970年と2000年の間を時間旅行する設定になっており、ハインラインが1950年代に想像した2000年の世界が描かれているのですが、さすがにインターネットの登場までは予想できなかったらしく、情報のやりとりが手紙だったり、新聞が配達チューブで届くところなんかは時代を感じさせます。 それでもリアリティが損なわれていないのはさすがです。 ちなみに、物語に登場する牡猫のピートは、ハインラインが実際に飼っていた猫のピクシーがモデルみたいです。 ピートは決しておとなしい猫ではないけれど、その振る舞いの描写から、著者の猫への愛が伝わってきます。 しかし、この傑作をハインラインはわずか13日間で書き上げてしまったというのは本当でしょうか？ ストーリーまとめ 以下、あらすじ、まとめ、ネタバレ注意です。 章のタイトルは私が勝手につけました。 第1章 逃亡 主人公（ダン・デイビス）は、コールドスリープして未来にいきたい理由をつらつらと語り出す。 ベル・ダーキンと、マイルズ・ジェントリーのいなくなった世界に行きたい。 もうあの2人と関わりたくない。 目標は30年後の西暦2000年だ。 猫のピートも連れていきたい。 コールドスリープに入る前の身体検査で医者に言われた。 「きみはどのくらいの期間このどんちゃん騒ぎを続けている？」 ▼デイビスは黙って「2週間あまりです」と答えるが、まだ読者には何のことなのか分からない。 デイビスは手続きを済ませ、翌日コールドスリープに入ることが決まった。 第2章 裏切り 人間の新陳代謝を止める方法は、1930年代から理論的には実現可能であることが知られていた。 しかし、実際に何に使われていたかというと、戦争だった。 人間を兵器のように保存しておいて、必要なときに蘇生させるのだ。 戦争が終わると、この技術がコールドスリープとして保険会社の商品として扱われるようになった。 デイビスはドライブインで食事を済ませて落ち着くと、本当にコールドスリープに入っていいのか自問自答を始める。 この状況から逃げ出すことが正しい答えなのか？ ベルとマイルズの問題は片付けなくていいのか？ いや、今からマイルズのところに行ってぶん殴ってやる！ マイルズ・ジェントリー は、徴兵時代の親友だった。 その娘の リッキー（フレデリカ）が、猫のピートの世話をしてくれていた。 デイビスとマイルズは、一緒に事業を始めた。 ハイヤーガールの制作だ。 賢い掃除ロボットしてヒットし、その後、ベル・ダーキン という女性が仲間に加わった。 株式会社の登録も済ませ、開発のほとんどを担当していたデイビスは51％の株式を保有することになった。 デイビスは容姿端麗なベルに惚れて、事業の拡大が落ち着き次第結婚しようという約束をした。 だから、持株の一部も彼女に譲渡した。 一方、マイルズの娘のリッキーは激しく嫉妬していた。 小さい頃、デイビスと恋人ごっこをして将来結婚しようと約束していたからだ（年は大分離れているが）。 ベルは猫のピートのことも好きだった（かのように見せかけていた）。 それはデイビスが好きなものを自分も好きなのだと思わせるためだった。 ある日、マイルズの提案で緊急の株主総会が開かれることになる（3人だけだが）。 マイルズからのとんでもない株主提案は2対1で可決されることになり、デイビスはベルから「相当なおバカさんね」と捨てゼリフを吐かれる。 デイビスの知らないうちに、マイルズとベルは結婚していた。 2人に裏切られたデイビスは解雇され、いつの間にかベルによって強制的にサインさせられていた書類によって、5年間は同業種に就くことさえ許されない状態になっていた。 最後に発明した「万能フランク」も消え去っていた。 第3章 口論 デイビスがマイルズの家に到着すると、ベルもそこにいて、3人の壮絶な口論が始まる。 デイビス vs マイルズ＆ベルという構図だったが、最後に「どうしてベルは2人に近づいたのか？」という核心に迫りそうになると、ベルの態度が豹変する。 そのとき、デイビスはうかつにもベルに背中を見せてしまった。 第4章 冷凍睡眠 ベルが本性を表し、デイビスは薬で催眠状態にされてしまう。 デイビスの荷物の中からコールドスリープの書類を見つけたベルは策略を練り始める。 ベルは書類を偽造するために、マイルズに会社のタイプライターを取りに行かせようとするが、そのとき、デイビスが乗ってきたはずの車がなくなっていることに気づく。 翌朝、まだ催眠状態のデイビスは2人に連れられてコールドスリープのための冷凍場（サンクチュアリ）までやってきた。 デイビスはなされるがままにコールドスリープに入ってしまう。 第5章 目覚め コールドスリープから目覚めたデイビスは、色々な感情が混ざり合っていたが、意識や記憶ははっきりしていた。 まずは何よりも西暦2000年の様子を見たかった。 そういえば、猫のピートは入れてもらえなかったが、30年後のこの世界でもまだどこかで生きているだろうか。 ドクターの話を聞く限り、2000年の世界に来ていることは間違いなさそうだ。 新聞のレイアウトはそれほど変わっていないが、印刷された写真が立体に見える。 よく見ると、冷凍場から発表される「入場者」と「退場者」のリストが載っている。 デイビスはリッキーの所在を確かめることを何より先にしようと考えた。 冷凍場を後にすると、保険会社のオフィスで「シュルツ夫人」なる人物から電話があったと知らされる。 第6章 西暦2000年 サンクチュアリ（冷凍場）を出るとき、いろいろな事情で結局全財産は 400 ドルしか残っていなかった。 滑走道路のステーションで一晩過ごそうとしただけで30日の禁固刑を言い渡されてしまったが、2日目にはなんとかグレート・ロサンゼルスで職に就くことができた。 それは失業対策のための水増し雇用だったが、デイビスは新世界のロサンゼルスを気に入った。 風邪というものは一掃され、重力制御法が発見されて物体の移動が楽になっていた。 デイビスは技術職に戻りたかったので、（30年前に自分が作った）ハイヤーガール株式会社に就職した。 憎きベルとマイルズはそこにはおらず、金銭的な問題もあって、デイビスは2人を探すことを諦めてしまう。 ただし、たった1人の肉親であるリッキーの行方だけはつきとめたかった。 コールドスリープに入る前に、ハイヤーガールの株をリッキーに譲渡するように手配していたのだが、信託先のバンク・オブ・アメリカの記録にはリッキーの名前はなかった。 デイビスの技術知識はもはや時代遅れのものになっていたので、ハイヤーガールは主に宣伝効果を目的としてデイビスを雇うことにした。 いくつかの雑誌に創業者デイビスの広告が載った頃、再びミセス・シュルツなる人物から電話がかかってきた。 会社で電話に応じると、それはあのベルだった。 第7章 シュルツ夫人 デイビスはベルに会うことにした。 正直なところ、ベルのことに関して興味はなくなっていたが、リッキーの居場所を知っているに違いなかったからだ。 ベルはデイビスを見ると喜びをあらわにした。 1970年のことはデイビスのためにやったことで、マイルズはその2年後に死んだと言う。 死んだ理由はわからない。 最後に発明した「万能フランク」はコールドスリープ前に消え去ってしまったが、デイビスが盗んだのだと言う。 結局ベルからは、リッキーのお祖母さんの名前がヘイニカーとかなんとかいう名であることを聞いて、その場を後にする（どうやら H で始まる名前のようだ）。 第8章 手がかり デイビスはリッキーを本格的に探し始めた。 リッキーに譲渡されるように手配していた株券は ハイニック という人間に渡っていた。 ベルの仕業に違いない。 ベルは何もかも根こそぎ奪おうとしているのか！ 「アラジン工業」という会社が所有しているロボットの特許について調べてみると、なんと自分（デイビス）が発明者になっている。 次に「製図機ダン」の特許についても調べてみると、それも自分が発明したことになっている。 確かに自分と同じような発想の発明品だが、こんなものを作った覚えはない。 コールドスリープで記憶喪失になってしまったのだろうか？ よき同僚である チャック に相談してみると、コールドスリープではなく、すでに時間旅行（タイムトラベル）ができるようになっているのだという。 ただし、それは軍の機密事項になっており、一般には知られていない。 そのマシンには欠点があり、2つのものを同時に転送しなければならず、どちらか一方が過去へ、もう一方が未来へ行ってしまうという。 そして、行ったが最後で元の時間には戻って来られない。 しかもどの年代に飛ぶかもうまく制御できないらしい。 デイビスは初めのうちは30年前に戻って事実を明らかにすればいいと思っていたが、チャックの話を聞いているうちに、それがとても馬鹿げた考えだと気がついた。 デイビスは新聞の蘇生者リストの中から F・V・ハイニック という名前を見つけた。 デイビスにはそれがリッキーの祖母の名前だということが直感的にわかった。 ハイニックというのは、リッキーに渡すはずだった株券の所有者の名前だ。 慌てて冷凍場に電話をすると、ハイニックはすでに出て行ったという。 何が起きているんだ？ 第9章 時間旅行 冷凍場に行くと、リッキーの写真を見せてもらうことができた。 彼女は20くらいの歳になっていたが、デイビスにはすぐにそれがリッキーだということがわかった。 どうやらリッキーは、祖母が死んだ直後にコールドスリープに入り、今はブローリーにいるらしい。 調べてみると、ユマですでに誰かと結婚していた。 崩れ落ちるデイビス。 デイビスはリッキーを探すことを諦め、トウィッチェル博士 と会うことにした。 同僚のチャックが、タイムマシンを作ったと言っていた人物で、一週間後には研究室を見学させてもらえることになった。 なんとか時間旅行の話に持ち込み、「時間転移の射程は正確に測定できないでしょう」と煽ると、博士はそんなことはないと言う。 そして、2枚の貨幣をマシンにかけて目の前から消してみせた。 今から一週間プラスマイナス6秒の誤差で転送したのだという。 一枚は一週間後にここにいれば現れるのを見ることができる。 もう一枚は博士のポケットに入っていた。 一週間前に博士はその貨幣をすでに手にしていたのだ。 博士は過去の苦い経験から二度と人間をこのマシンで転送しないと決めていた。 だがデイビスは博士をわざと怒らせて、その流れで自分を過去に転送させようとした。 自分が以前コールドスリープに入った日の6ヶ月前だ。 博士は憤り、デイビスをコールドスリープにかけた。 第10章 準備 デイビスの身体は転落し、どこかに叩きつけられた。 目を開けると、素っ裸の2人の男女が立っている。 全く恥ずかしがる気配がなく、どうやら過去ではなく未来に来てしまったようだ。 と思ったら、そこは単なるヌーディストクラブで、実際には1970年らしい。 うまくいった！ その男 ジョン・サットン は弁護士で、とても協力的であったおかげで、デイビスは数週間後には事務室を一室借りることができた。 まずはそこで「製図機ダン」の制作に取り掛かった。 ▼ここで、これらの発明品の特許にデイビスの名前があったことが明らかになる。 デイビスは偶然にも若い頃のトウィッチェル博士に出会った。 30年後の世界で、博士が「どこかで会ったことがある」と言っていたのは正しかった。 また、私立探偵を雇ってベル（元婚約者）のことを調べさせると、想像した通り結婚詐欺の常習犯だった。 デイビスとジョンは、「製図機ダン」や「護民官ピート」を売るための会社を作ることにした。 会社の名前はもちろん「アラジン自動工業商会」で、場所はロサンゼルスだ。 あの忌まわしい1970年12月2日まで時間がない。急がなければ。 第11章 約束 1970年12月3日の夕刻、デイビスはロサンゼルスのマイルズ家の近くまでタクシーでやってきた。 あの壮絶な口論が繰り広げられる（た）ところだ。 しばらくすると、一台の車がやってきて停車した。 近づいてみると、まさしく自分の車だ。 デイビスはいつも車のトランクにスペアキーを入れていたので、その鍵を取り出して車に乗り込んだ。 マイルズの家のガレージに回ると、そこには（過去に）会社を乗っ取られたときに姿を消した発明品「万能フランク」があった。 デイビスはフランクをバラバラに分解して車に詰め込んだ。 ▼最終的にフランクが消えたのはデイビスのせいだったということが明らかになる。 騒動の中で家から飛び出してきた猫のピートと車に乗り込み、ビッグベアのガールスカウトのキャンプへ向かった。 リッキーがいるところだ。 そこへ向かう道中で、フランクの部品を片っ端から投げ捨てていった。 リッキーはすでにマイルズとベルの結婚のことを知っていた。 ベルのことが嫌なので、お祖母さん（ハイニック）のところで暮らすつもりだという。 デイビスはリッキーに30年間のお別れになることを説明し、ハイヤーガールの株券の裏書きとしてリッキーの名前を書いた。 本名は フレデリカ・ヴァージニア・ハイニック。 ▼ここで、株券がハイニックという人物に渡っていた理由や、蘇生者リストにあった F・V・ハイニックというのがリッキー自身であったことが明らかになる。 どうしてもデイビスとピートと別れたくないというリッキーに、デイビスは将来コールドスリープに入ればいいという提案をする。 それは、リッキーが21歳になったとき、つまり、お祖母さんが亡くなって、株によるお金も溜まっている頃だ。 リッキーが未来に来たときに結婚するという約束をして2人は別れた。 デイビッドは町の冷凍場（サンクチュアリ）へ向かい、今度は猫のピートとともに再び30年の眠りについた。蘇生日程は2001年4月27日。 リッキーのいるあの暖かい夏の扉を開くんだ。。。 第12章 夏への扉 デイビスは何事もなく目を覚ました。 そして、リッキーの蘇生予定日の5月1日に冷凍場へ行き、無事2人（と1匹）は再開を果たした。 2人はユマの群役場へ行き、正式に籍を入れた。 ▼リッキーが結婚した相手はデイビスだった。 デイビスはトウィッチェル博士にこれまでの経緯や謝罪の手紙を送り、博士に関する本を書くことにした。 タイトルは『埋もれた天才』だ。 リッキーとこれまでのことをいろいろと話した。 ある時点で自分は2人いたことになる。 そういえば、もうひとりの自分がサンクチュアリを出たという記事を見なかった。 でもそんなタイムパラドックスに関して心配などしない。 僕の夏への扉は見つかったんだ。"
},
{
url: "/p/w7igunc/",
title: "Apollo Client の fetchMore を自動で呼び出して GitHub GraphQL の100件制限を乗り越える (useAutoFetchMore)",
date: "2021-09-16T00:00:00Z",
body: "Apollo Client の fetchMore を自動で呼び出して GitHub GraphQL の100件制限を乗り越える (useAutoFetchMore) 何をするか？ GitHub の GraphQL API で Issue 情報などを取得しようとすると、リソース制限 のため一度に 100 件までの情報しか取得できません。 Apollo Client が提供する useQuery や useLazyQuery などの React フック関数を使用すると、戻り値で返される fetchMore 関数を使って追加読み込み（ページネーション処理）を行うことができますが、この関数の使用例として提示されているものは、ユーザーによるボタンクリックなどを必要とするものばかりです。 ここでは、useQuery 実行後に自動で fetchMore を繰り返し呼び出して、100 件を超える情報を取得する方法の例を示します。 fetchMore のための設定 前提として、Apollo Client の fetchMore 関数の基本的な使い方は理解しているものとします（下記記事などを参考にしてください）。 Apollo Client の Pagenation 機能を使って GraphQL API を呼び出す 今回サンプルコードで使う GraphQL クエリには、次のような search コネクションが含まれていることを想定しています。 ページネーションの対象となるのは、この search コネクション部分です。 queryQueryIssues($cursor:String){search(type:ISSUE,first:100,after:$cursor,query:\u0026#34;...\u0026#34;){...}} そのため、ApolloClient に設定するキャッシュのフィールドポリシーとして、search フィールドの値が fetchMore 時にマージされるように設定しておきます。 cache オブジェクトの生成時に呼び出している relayStylePagination 関数あたりがポイントです。 GitHubApolloProvider.tsx import * as React from \u0026#39;react\u0026#39; import { ApolloClient, ApolloLink, ApolloProvider, createHttpLink, InMemoryCache, } from \u0026#39;@apollo/client\u0026#39; import { relayStylePagination } from \u0026#39;@apollo/client/utilities\u0026#39; import { setContext } from \u0026#39;@apollo/client/link/context\u0026#39; import { Auth } from \u0026#39;@/utils/auth\u0026#39; const httpLink = createHttpLink({ uri: \u0026#39;https://api.github.com/graphql\u0026#39;, }) const authLink = setContext((_, { headers }) =\u0026gt; { // Get the authentication token from local storage if it exists const token = Auth.getToken() // Return the headers to the context so httpLink can read them return { headers: { ...headers, authorization: token ? `Bearer ${token}` : \u0026#39;\u0026#39;, } as ApolloLink, } }) // GraphQL cache with field policies const cache = new InMemoryCache({ typePolicies: { Query: { fields: { search: relayStylePagination([\u0026#39;type\u0026#39;, \u0026#39;query\u0026#39;]), // ★ }, }, }, }) // Create a GraphQL client const apolloClient = new ApolloClient({ link: authLink.concat(httpLink), cache, }) export const GitHubApolloProvider: React.FC = (prop) =\u0026gt; { return \u0026lt;ApolloProvider client={apolloClient}\u0026gt;{prop.children}\u0026lt;/ApolloProvider\u0026gt; } あとは、上記ファイルで export されている GitHubApolloProvider コンポーネントをトップレベルのコンポーネントとして配置すれば、それ以下の階層で useQuery フックが適切に動作するようになります。 例えば、Next.js を使っている場合なら、カスタム App コンポーネントで次のような感じで配置すればよいでしょう。 pages/_app.tsx function MyApp({ Component, pageProps }: AppProps): JSX.Element { return ( \u0026lt;\u0026gt; \u0026lt;Head\u0026gt; \u0026lt;title\u0026gt;My App\u0026lt;/title\u0026gt; \u0026lt;meta name=\u0026#34;description\u0026#34; content=\u0026#34;すんごいアプリ\u0026#34; /\u0026gt; \u0026lt;/Head\u0026gt; \u0026lt;GitHubApolloProvider\u0026gt; \u0026lt;Component {...pageProps}\u0026gt;\u0026lt;/Component\u0026gt; \u0026lt;/GitHubApolloProvider\u0026gt; \u0026lt;/\u0026gt; ) } export default MyApp fetchMore を自動呼出しするためのフック関数 (useAutoFetchMore) を作る fetchMore を自動で繰り返し呼び出す仕組みですが、ここでは useEffect を使って、pageInfo.hasNextPage の値などが変化したときに fetchMore を呼び出すようにしてみます。 この実装をコンポーネントのコードに入れてもいいのですが、ある程度汎用的に使える処理なので、useAutoFetchMore フック関数として定義します。 src/hooks/useAutoFetchMore.ts import { useEffect, useRef } from \u0026#39;react\u0026#39; import { ApolloError } from \u0026#39;@apollo/client\u0026#39; /** * ApolloClient (useQuery) の fetchMore を自動で繰り返し呼び出すためのフック関数です。 * * 各パラメーターには、useQuery() の戻り値をそのまま設定します。 * ページネーションは Relay スタイル（pageInfo や edges）で提供されていることを前提とし、 * fetchMore の呼び出しごとにクエリ変数 (variables) の cursor の値が更新されていきます。 * 手違いによる大量呼び出しを防ぐため、最大呼び出し回数 (maxAutoFetch) を設定できます。 */ export function useAutoFetchMore( loading: boolean, error: ApolloError | undefined, pageInfo: { hasNextPage: boolean; endCursor: string | null } | undefined, fetchMore: any, // eslint-disable-line maxAutoFetch = 2 ): void { const hasNextPage = pageInfo?.hasNextPage ?? false const endCursor = pageInfo?.endCursor // fetchMore を自動で呼び出した回数を保持しておく（呼び出しすぎ防止） const count = useRef(0) // しかるべきタイミングで fetchMore を自動呼出しする useEffect(() =\u0026gt; { if (error || loading || count.current \u0026gt;= maxAutoFetch) return if (hasNextPage) { count.current += 1 // eslint-disable-next-line @typescript-eslint/no-unsafe-call fetchMore({ variables: { cursor: endCursor } }) } }, [loading, error, hasNextPage, endCursor, fetchMore, maxAutoFetch]) } useAutoFetchMore フックの使用例 次のサンプルコンポーネントは、上記で作成した useAutoFetchMore フックを使用して、GitHub の apollographql/apollo-client リポジトリの Issue 情報を連続取得します。 一度に取得する件数は first: 100 のように最大 100 件に設定することができますが、ここでは連続して取得していることが分かるように first: 5 として 5 件ずつ取得するようにしています。 src/pages/sample.tsx import { gql, useQuery } from \u0026#39;@apollo/client\u0026#39; import { FC } from \u0026#39;react\u0026#39; import { useAutoFetchMore } from \u0026#39;@/hooks/useAutoFetchMore\u0026#39; const QUERY_ISSUES = gql` query QueryIssues($cursor: String) { search( type: ISSUE query: \u0026#34;repo:apollographql/apollo-client is:issue is:open\u0026#34; first: 5 after: $cursor ) { edges { node { ... on Issue { id number title } } } pageInfo { endCursor hasNextPage } } } ` // 本来は useQuery の型パラメーターをちゃんと指定して ESLint 警告を取り除くべき /* eslint-disable */ const SamplePage: FC = () =\u0026gt; { const { loading, error, data, fetchMore } = useQuery(QUERY_ISSUES) useAutoFetchMore(loading, error, data?.search.pageInfo, fetchMore) if (error) return \u0026lt;p\u0026gt;{error.message}\u0026lt;/p\u0026gt; if (loading) return \u0026lt;p\u0026gt;Loading ...\u0026lt;/p\u0026gt; const { search } = data return ( \u0026lt;ol\u0026gt; {search.edges.map(({ node: issue }) =\u0026gt; ( \u0026lt;li key={issue.id}\u0026gt; \u0026lt;b\u0026gt;#{issue.number}\u0026lt;/b\u0026gt; {issue.title} \u0026lt;/li\u0026gt; ))} \u0026lt;/ol\u0026gt; ) } /* eslint-enable */ export default SamplePage ポイントは、下記のフック呼び出し部分です。 useQuery フックに続けて useAutoFetchMore フックを呼び出しておくことで、内部で fetchMore が自動的に繰り返し呼ばれるようになります。 const { loading, error, data, fetchMore } = useQuery(QUERY_ISSUES) useAutoFetchMore(loading, error, data?.search.pageInfo, fetchMore) 内部で fetchMore が呼び出されるごとにコンポーネントの再描画が行われるため、段階的に表示量が増えていく振る舞いになります。 応用（useLazyQuery) Apollo Client において、任意のタイミング（ボタンクリックなど）で GraphQL クエリを発行したいときは、useQuery の代わりに useLazyQuery フックを使用します。 参考: Apollo Client でクリック時に GraphQL クエリを実行する 今回実装した useAutoFetchMore フックは、そのまま useLazyQuery にも適用することができます（クエリが実行されるまでは、内部的に hasNextPage == false と同じ振る舞いになるようにしているので）。 次のサンプルコードでは、ユーザーが Get Issues ボタンをクリックしたときに fetchMore の自動実行を開始するようにしています。 src/pages/test.tsx（抜粋） /* eslint-disable */ const TestPage: FC = () =\u0026gt; { const [doQuery, { called, loading, error, data, fetchMore }] = useLazyQuery(QUERY_ISSUES) useAutoFetchMore(loading, error, data?.search.pageInfo, fetchMore) if (error) return \u0026lt;p\u0026gt;{error.message}\u0026lt;/p\u0026gt; if (loading) return \u0026lt;p\u0026gt;Loading ...\u0026lt;/p\u0026gt; const searchEdges = called ? data.search.edges : [] return ( \u0026lt;\u0026gt; \u0026lt;button onClick={() =\u0026gt; doQuery()}\u0026gt;Get Issues\u0026lt;/button\u0026gt; \u0026lt;ol\u0026gt; {searchEdges.map(({ node: issue }) =\u0026gt; ( \u0026lt;li key={issue.id}\u0026gt; \u0026lt;b\u0026gt;#{issue.number}\u0026lt;/b\u0026gt; {issue.title} \u0026lt;/li\u0026gt; ))} \u0026lt;/ol\u0026gt; \u0026lt;/\u0026gt; ) } /* eslint-enable */"
},
{
url: "/p/wht6fq2/",
title: "読書メモ『うつヌケ』田中圭一",
date: "2021-08-31T00:00:00Z",
body: "読書メモ『うつヌケ』田中圭一 うつヌケ 田中圭一 KADOKAWA コロナで引きこもり生活が多くなって、鬱（ウツ）な気分になっている人も多いかと思います。 そこで、前から気になっていた田中圭一氏の『うつヌケ』を読んでみました。 マンガです。 内容は、ウツを経験したことのある人たちの経験談（どうしてウツになったのか、どうやって抜け出したのか）です。 ウツな気分なときは、活字は読む気さえ起こらないと思うので、マンガになっているのはいいですね。 まとめ。 自分をキライになるとウツになる。朝起きたときに、まず自分を褒めるといい「ボクは自分が大好き！」。寝起きはボーッとしていて、ウツな気分を受け入れてしまいやすいので、強制的に自分を肯定するのがいい。 不安な日は、天気と同じようにやってくる。時間が立てば去っていったりする。 気温差の変動が激しいとウツになる、みたいな簡単な原因だったりする（著者の場合）。気温と精神状態を毎日記録することで気付けた。 つらいのは自分だけじゃない。克服の仕方の本を参考にする（ネットじゃなくて書籍）。 自分を否定するものからは遠ざかり、肯定してくれるものに近づけばいい。小さなことでもいい。模型を買い込んで熱中してみるとか、山に登って綺麗な景色をみるとか。ペットと遊ぶとか。 心の故障を直すくらい気楽に「心療内科」に行けばいい。医者から処方される薬や治療法を信じよう。 ウツの渦中にある人は、周囲のものに気づく余裕がない。見えていなかった物に気づけたらウツトンネルから抜けられた証拠「ここにピアノが置いてあったんだ！」 ウツなときは思考に歪みがあるので、物事を客観視するための日記を書くとよい。「客観的に何が起きたか」「主観的にどう感じたか」を両方を 1:1 の比率で書いておく。後から見直して、なんでこんなことで悩んでいたんだと実感できる。 実際に重度の鬱になったら、上記のようなアドバイスを受け入れる余裕すらないかもしれません。 そう考えると、ウツを予防するための知識としてこういったことを知っておくのがよさそうです。"
},
{
url: "/p/qgvamzc/",
title: "Next.js で src からの相対パスで import できるようにする (tsconfig.json)",
date: "2021-08-26T00:00:00Z",
body: "Next.js で src からの相対パスで import できるようにする (tsconfig.json) 何をするか？ Next.js (TypeScript) のプロジェクトで、src ディレクトリ以下の階層構造が深くなってくると、別のディレクトリのモジュールをインポートするときの相対パスがわかりにくくなってきます。 import { sleep } from \u0026#39;../../../../../utils/timeUtil\u0026#39; このような場合は、次に説明するような tsconfig.json の設定をしておくと、シンプルなパスでインポートできるようになります。 compilerOptions.paths プロパティ (module alias) tsconfig.json の compilerOptions.paths プロパティ（と baseUrl プロパティ）を設定すると、特定のパスに配置されたモジュール（.ts ファイル）を、エイリアス名（ここでは @）を使って参照できるようになります。 tsconfig.json { \u0026#34;compilerOptions\u0026#34;: { // ... \u0026#34;baseUrl\u0026#34;: \u0026#34;.\u0026#34;, \u0026#34;paths\u0026#34;: { \u0026#34;@/*\u0026#34;: [\u0026#34;./src/*\u0026#34;] } } } 上記のように設定すると、プロジェクトルートの src ディレクトリ以下のモジュールを、どの階層にあるコードからでも、@/moduleName という名前で参照できるようになります。 例えば、src/utils/timeUtil.ts というモジュールをインポートするとき、これまでは、次のようにカレントディレクトリからの相対パスで指定しなければいけなかったところを、 import { sleep } from \u0026#39;../../../../../utils/timeUtil\u0026#39; 次のように src ディレクトリを示すエイリアス名 @ を使って指定できるようになります。 import { sleep } from \u0026#39;@/utils/timeUtil\u0026#39; ☝️ ワンポイント 上記のようなエイリアス名を使った場合でも正しくモジュールを参照できるのは、Next.js のビルドシステムが JavaScript へのトランスパイル時に本来のモジュールのパスに変換してくれるおかげです（おそらく webpack などによるバンドル時に処理されています）。 このあたりにも、Next.js のゼロコンフィグ思想が垣間見えます。 ちなみに、一緒に設定している \u0026quot;baseUrl\u0026quot;: \u0026quot;.\u0026quot; というオプションは、本来は次のように ./ プレフィックスを付けない名前でインポートしたときに、プロジェクトルートからの相対パスでモジュールを検索してくれるようにするためのオプションです。 import { sleep } from \u0026#39;src/utils/timeUtil\u0026#39; この baseUrl の設定は paths の設定とは関係なさそうに見えますが、一緒に設定しておかないとビルド時のパス解決に失敗するので、必ず baseUrl と paths の両方の設定が必要です。 baseUrl を設定すると、3rd パーティ製の npm モジュールとの見分けがつきにくくなるという弊害があるため、このあたりは将来的に改善されそうな気がします。"
},
{
url: "/p/weow6dm/",
title: "『世界樹の迷宮』やってる",
date: "2021-08-22T00:00:00Z",
body: "『世界樹の迷宮』やってる ウィザードリィ風だけどライトな感じの 3D ダンジョンゲームの 『世界樹の迷宮 (DS) 』 をやってました。 シリーズものはできるだけ 1 からクリアしたい派なので、ニンテンドー DS の 1 から始めてやっとクリアしました。 ちなみに、上記のレンジャーはこのタイトルで最強と呼ばれている職業で、最大レベルにしたもの。スキル配分も多分こんな感じが最強。 3D ダンジョンゲームは明らかに人を選ぶジャンルですけど、だんだん深くまで潜っていけるようになる 中毒性 達成感 があってやめられません。 古代祐三氏の BGM はやっぱり素晴らしいです。 日向悠二氏のキャラクター はかわいすぎです。 第五階層に到達したときに広がる世界は神秘的でグッときました。 というわけで 『世界樹の迷宮 2 (DS)』 も続けてやることに決定しました。 ラスボスを倒すと上のようなパスワードが発行されて、2 を始めるときに「エトリアの勲章」を持った状態でスタートできます（HP:+10、TP:+10、全能力:+1）。 実質引き継げるのはこのアイテムくらいなのに、なんて長いパスワードなんでしょう（笑）。 まぁタッチペンなので数分あれば入力できますけど。 あと全体の印象としては、 序盤のカマキリみたいなやつが倒せなくて 一度詰む（みんな漏れなく一度詰んでいるみたい） 苦労して見つけた 宝箱の中身が全部ゴミ（ほんと最後の最後までゴミしか入ってない） セーブポイント少なすぎ 裏ボスとか竜を倒すときはパラディン入れて毎回ガードするのが必須の パターンゲームと化す（一度でもガードをミスると即死） 最終フロアとか雷属性使わないと倒せない敵が出てきて詰む（レベル上げしたいだけなのに ザコが倒せない） 最後はほぼ Max レベル 70 にしないと勝てない（比較的早く Max レベルになるので、ボスをあっさり倒すという爽快感は味わえない） な感じですね（不満しか書いてないw）。 中でもラスボス前のレベル上げ修行は大変でした。 「一日中、わたしは何をやっているのだろう\u0026hellip;」という気持ちになることもしばしば。 でもこれがキャラクターを育てるという愛なのですね。 ちなみに、『世界樹の迷宮 2』では、キャラのレベルを最大の 70 まで上げて引退させてレベル 30 に戻すと、引退ボーナスで最大レベルが 1 上がって 71 になるらしいです。 そしてもう一度最大レベル 71 にして引退させてレベル 30 に戻すと、次はレベル 72 まで上がると\u0026hellip;（嫌な予感しかしない\u0026hellip;）。 修行するぞ〜！"
},
{
url: "/p/qb73pxx/",
title: "日記・コラム",
date: "2021-08-22T00:00:00Z",
body: "日記・コラム"
},
{
url: "/p/m7is4dn/",
title: "Next.js のページコンポーネントが Client と Server どちらで実行されているか調べる (isServer, isClient, NoSsr)",
date: "2021-08-13T00:00:00Z",
body: "Next.js のページコンポーネントが Client と Server どちらで実行されているか調べる (isServer, isClient, NoSsr) Next.js のページコンポネント (src/pages/*.tsx) の関数は、静的な HTML ファイルを生成するためにビルド時にも実行されます（参考: Next.js のプリレンダリング機能を使用する）。 従来の React による SPA アプリはクライアントサイド JavaScript でしか実行されないので、同じような感覚で実装していると振る舞いの違いでハマることがあります。 例えば、ページコンポーネントから次のように window オブジェクトを参照しようとすると、Next.js によるプリレンダリング時にエラーになります。 これは、window オブジェクトは、Web ブラウザ上で JavaScript を実行しているときにしか存在しないからです。 src/pages/hello.tsx import { FC } from \u0026#39;react\u0026#39; const HelloPage: FC = () =\u0026gt; { console.log(window.location) // ReferenceError: window is not defined return \u0026lt;h1\u0026gt;Hello\u0026lt;/h1\u0026gt; } 逆に言うと、実行時に window オブジェクトが存在しているかどうかを調べることによって、ページコンポーネント内のコードが、どのタイミングで実行されているかを判別できます。 const isClient = () =\u0026gt; typeof window !== \u0026#39;undefined\u0026#39; // const isServer = () =\u0026gt; typeof window === \u0026#39;undefined\u0026#39; const HelloPage: FC = () =\u0026gt; { if (isClient()) { console.log(\u0026#39;これはクライアントサイド JS として実行されているよ！\u0026#39;) console.log(window.location) alert(\u0026#39;だから alert も使えるよ！\u0026#39;) } return \u0026lt;h1\u0026gt;Hello\u0026lt;/h1\u0026gt; } ちなみに、React フックの useEffect で設定したコールバック関数は、DOM 要素のレンダリング後に実行されるものなので、クライアントサイドでのみ実行されることが保証されています。 const HelloPage: FC = () =\u0026gt; { useEffect(() =\u0026gt; { // ここであれば window オブジェクトは確実に参照できる console.log(window.location) }, []) return \u0026lt;h1\u0026gt;Hello\u0026lt;/h1\u0026gt; } JSX コードで記述した部分も、Next.js のサーバーサイドビルド時と、クライアントサイド JS の両方で実行されます。 クライアントサイドでのみレンダリングしたい部分は、上記で定義した isClient 関数を使って次のように記述します。 const HelloPage: FC = () =\u0026gt; { return ( \u0026lt;\u0026gt; \u0026lt;p\u0026gt;Rendered in server and client\u0026lt;/p\u0026gt; {isClient() \u0026amp;\u0026amp; \u0026lt;p\u0026gt;Rendered in client\u0026lt;/p\u0026gt;} \u0026lt;/\u0026gt; ) } 例えば、URL のハッシュフラグメント (window.location.hash) の情報を利用してデータ生成を行うような場合は、クライアントサイド JS でしか処理できない（基本的にユーザーインタラクションによってクライアントサイドでのみ変化する）ので、上記のような判定が必要になったりします。 UI ライブラリとして Material-UI を使用している場合は、同様のことを実現する NoSsr というコンポーネントが用意されているので、こちらを使用すると簡単です。 import { FC } from \u0026#39;react\u0026#39; import { NoSsr } from \u0026#39;@material-ui/core\u0026#39; const HelloPage: FC = () =\u0026gt; { return ( \u0026lt;\u0026gt; \u0026lt;p\u0026gt;Rendered in server and client\u0026lt;/p\u0026gt; \u0026lt;NoSsr\u0026gt;\u0026lt;p\u0026gt;Rendered in client\u0026lt;/p\u0026gt;\u0026lt;/NoSsr\u0026gt; \u0026lt;/\u0026gt; ) } NoSsr コンポーネントの実装 も単純で、初回の DOM 要素レンダリング後にのみ子要素 (children) を return するようになっています。 useEffect を使えば、同様のコンポーネントを実装するのは簡単だと思います。"
},
{
url: "/p/bnrrqpn/",
title: "Apollo CLI の codegen で GraphQL クエリレスポンスの TypeScript 型を自動生成する",
date: "2021-08-11T00:00:00Z",
body: "Apollo CLI の codegen で GraphQL クエリレスポンスの TypeScript 型を自動生成する 何をするか TypeScript プロジェクトにおいて、Apollo Client の useQuery フックで GraphQL クエリ呼び出しを行っていると、レスポンスの型情報が any になってしまうことに悩むことになります。 例えば、GitHub の GraphQL クエリで、次のようにログイン中のユーザー情報を取得するとします。 import { gql, useQuery } from \u0026#39;@apollo/client\u0026#39; export const QUERY_VIEWER = gql` query QueryViewer { viewer { login url avatarUrl } } ` const Viewer: FC = () =\u0026gt; { const { error, loading, data } = useQuery(QUERY_VIEWER) // ... } useQuery 関数の戻り値の data はデフォルトで any 型なので、そのままだと ESLint などに怒られることになります。 Unsafe array destructuring of a tuple element with an any value @typescript-eslint/no-unsafe-assignment これを解消するために、useQuery 関数の型パラメーターで data の型をセットできるのですが、 const { error, loading, data } = useQuery\u0026lt;ViewerData\u0026gt;(QUERY_VIEWER) 各クエリごとにこういった型情報を定義するのは面倒ですし、戻り値のオブジェクトが複雑だったりすると、型定義そのものが複雑で大変です。 そこで、このような GraphQL クエリの戻り値の型を自動生成してくれるのが Apollo CLI が提供する apollo client:codegen コマンドです。 ここでは、GitHub の GraphQL スキーマ定義ファイルを使って、クエリレスポンスの型情報を自動生成してみます。 Apollo CLI で型情報を生成するための準備 apollo client:codegen コマンドを利用するには、apollo コマンド自体のインストールに加え、下記のような入力ファイルを用意してやる必要があります。 スキーマ定義ファイル (*.graphql) クエリリテラルを含む TypeScript コード（デフォルトで gql を検索します） Apollo CLI のインストール まず、Apollo CLI（apollo コマンド）自体をインストールします。 基本的にはプロジェクトごとに devDependencies インストールするのがよいと思いますが、型情報の生成はそこまで頻繁に行わないので、グローバルインストールでもよいかもしれません（node_modules が肥大化するのは嫌ですし）。 apollo コマンドのインストール ### yarn の場合 $ yarn add apollo --dev $ yarn global add apollo（グローバルインストールする場合） ### npm の場合 $ npm install apollo --save-dev $ npm install apollo -g（グローバルインストールする場合） GitHub の GraphQL スキーマ定義をダウンロード Apollo CLI への入力ファイルとして、GraphQL のスキーマ定義を用意します。 GitHub の GraphQL API の場合は、下記のサイトから schema.docs.graphql というファイルをダウンロードすれば OK です（サイズは 1MB 弱です）。 パブリックスキーマ - GitHub Docs curl コマンドや、apollo client:download-schema コマンドを使ってエンドポイントから直接ダウンロードする方法もありますが、GitHub アクセストークンの設定が必要だったりして面倒なので、まずは上記サイトからファイルをダウンロードしてしまうのが手っ取り早いです。 ダウンロードしたファイルは、プロジェクト内のどこかに配置しておきます。 ここでは、graphql ディレクトリに入れることにします。 \u0026lt;project\u0026gt; +-- graphql/ +-- schema.docs.graphql クエリ文字列の含まれた TypeScript コード Apollo Client (useQuery) を使ったプロジェクトであれば、すでに gql を使ったクエリ文字列の定義は TypeScript コード内に含まれていると思います。 例えば、src ディレクトリ以下に、次のようなコードを含む .ts ファイルが存在すれば準備 OK です。 src/useViewer.ts import { gql } from \u0026#39;@apollo/client\u0026#39; export const QUERY_VIEWER = gql` query QueryViewer { viewer { login url avatarUrl } } ` // ... apollo client:codegen で型情報を生成する 上記の準備が済んだら、次のようなコマンドで GraphQL クエリレスポンス用の型情報を生成できます。 $ apollo client:codegen --target=typescript --localSchemaFile=graphql/schema.docs.graphql √ Loading Apollo Project √ Generating query files with \u0026#39;typescript\u0026#39; target - wrote 12 files 言語として TypeScript を指定して、スキーマ定義としてダウンロードした schema.docs.graphql を指定しています。 デフォルトで、src ディレクトリ以下の *.ts ファイルが検索されますが、--includes=foo/**/*.ts オプションなどで調整できます。 その他のオプションは、apollo client:codegen --help や、公式ページのヘルプ で調べられます。 型情報ファイルの生成に無事成功すると、デフォルトで入力ファイル (*.ts) と同じディレクトリに、__generated__ というディレクトリが生成され、その中にクエリ単位で .ts ファイルが生成されます。 今回の例では、src/userViewer.ts 内に query QueryViewer {...} という記述があるので、このクエリ名称をもとに次のようなファイルが自動生成されます。 src/__generated__/QueryViewer.ts（自動生成） /* tslint:disable */ /* eslint-disable */ // @generated // This file was automatically generated and should not be edited. // ==================================================== // GraphQL query operation: QueryViewer // ==================================================== export interface QueryViewer_viewer { __typename: \u0026#34;User\u0026#34;; /** * The username used to login. */ login: string; /** * The HTTP URL for this user */ url: any; /** * A URL pointing to the user\u0026#39;s public avatar. */ avatarUrl: any; } export interface QueryViewer { /** * The currently authenticated user. */ viewer: QueryViewer_viewer; } ドキュメンテーションコメントなども、入力したスキーマ定義ファイル (schema.docs.graphql) から自動で適用されていていい感じです（VS Code などで編集中にこれらのドキュメントを参照できます）。 url や avatarUrl の型が any になってしまっている部分の対応に関しては後述します。 あとは、次のようにこのファイルをインポートして useQuery の型パラメーターとして使うだけです。 src/useViewer.ts import { gql, useQuery } from \u0026#39;@apollo/client\u0026#39; import { QueryViewer, QueryViewer_viewer } from \u0026#39;./__generated__/QueryViewer\u0026#39; export const QUERY_VIEWER = gql` query QueryViewer { viewer { login url avatarUrl } } ` /** * サインイン中の GitHub ユーザー情報を取得します。 * ロード中やエラー時は undefined を返します。 */ export function useViewer(): QueryViewer_viewer | undefined { const { data } = useQuery\u0026lt;QueryViewer\u0026gt;(QUERY_VIEWER) return data?.viewer } ☝️ さらにアプリドメインの独自型へ変換すべきか？ 上記のカスタムフック useViewer では、戻り値の型として、Apollo CLI で生成したクエリレスポンス型をそのまま使っています。 実際のプロジェクトでは、アプリドメインで定義した独自型に変換した方が都合がよいかもしれません。 いずれにしても、そういった変換処理はカスタムフックのコード内に閉じて、UI コンポーネント側に染み出さないようにするのが保守性を高めるコツです。 クエリに引数がある場合は、XxxVariables という型も生成されるので、次のような感じで第2型パラメーターに指定してやります。 const { data } = useQuery\u0026lt;QueryIssues, QueryIssuesVariables\u0026gt;( QUERY_ISSUES, { variables: { milestoneNumber: milestoneNumber } } ) （応用）Prettier の設定 Prettier を使ってコードを自動フォーマット している場合は、__generated__ ディレクトリを無視設定しておきましょう。 .prettierignore __generated__/ .next/ build/ *.html *.md ESLint の無視設定に関しては、自動生成されるファイル内に /* eslint-disable */ というコメントが入っているので気にしなくても大丈夫です。 （応用）npm scripts で簡単に codegen 実行できるようにしておく apollo client:codegen コマンドは、NPM scripts として定義して簡単に実行できるようにしておきましょう。 package.json { // ... \u0026#34;scripts\u0026#34;: { // ... \u0026#34;codegen\u0026#34;: \u0026#34;apollo client:codegen --target typescript --localSchemaFile=./graphql/schema.docs.graphql\u0026#34; }, // ... } これで、次のように型情報を生成できるようになります。 ### yarn の場合 $ yarn codegen ### npm の場合 $ npm run codegen （応用）独自のタイプが any にならないようにする GraphQL のスキーマ定義ファイル (.graphql) の中で、次のような独自スカラー型 (custom scalar) が定義されていると、 schema.docs.graphql（抜粋） scalar URI そのような型が使われている部分の型情報がデフォルトで any になってしまいます。 src/__generated__/QueryViewer.ts（抜粋） export interface QueryViewer_viewer { __typename: \u0026#34;User\u0026#34;; /** * The username used to login. */ login: string; /** * The HTTP URL for this user */ url: any; /** * A URL pointing to the user\u0026#39;s public avatar. */ avatarUrl: any; } これでは意味がないので、なんとか他の TypeScript 型にマッピングしてやる必要があります。 上記のカスタムスカラー型の URI は、少なくとも TypeScript の string にマッピングしてやりたいところです。 これを実現するには、例えば次のようにします。 apollo client:codegen のオプションで --passthroughCustomScalars を指定することで、any ではなくカスタムスカラー型のまま出力するようにする（上記の場合は URL 型で出力）。 apollo client:codegen のオプションで --customScalarsPrefix=CustomScalar を指定することで、出力する型にプレフィックスを追加してやる（上記の場合は URL → CustomScalarURL 型になる）。これは、既存の TypeScript 型とのコンフリクトを防ぐため。 出力された型 (CustomScalarURL) に対応する型のマッピングを globals.d.ts などに記述する。 今回の例の場合は、カスタムスカラー型の URL が CustomScalarURL 型として出力されることになるので、グローバルな型情報としてプロジェクトルートの globals.d.ts に、次のような感じでマッピングを定義してやります（この例では DateTime 用のマッピングも追加しています）。 globals.d.ts // apollo client:codegen が生成するカスタムスカラー型用のマッピング type CustomScalarURI = string type CustomScalarDateTime = string あとは、次のように型情報をジェネレートしてやります。 $ apollo client:codegen --target=typescript \\ --localSchemaFile=./graphql/schema.docs.graphql \\ --passthroughCustomScalars \\ --customScalarsPrefix=CustomScalar \\ 生成される型情報ファイルは次のように変化するので、無事 url プロパティと avatarUrl プロパティは CustomScalarURI 型（=string 型）として参照できるようになります。 src/__generated__/QueryViewer.ts（抜粋） export interface QueryViewer_viewer { __typename: \u0026#34;User\u0026#34;; /** * The username used to login. */ login: string; /** * The HTTP URL for this user */ url: CustomScalarURI; /** * A URL pointing to the user\u0026#39;s public avatar. */ avatarUrl: CustomScalarURI; } 本当はダイレクトにカスタムスカラー型の URI を、TypeScript の string にマッピングしたいところですけど、これはこれでまぁ分かりやすいのかもです。 （応用）Apollo の設定ファイル (apollo.config.js) 前述の実行例では、apollo client:codegen のコマンドライン引数でスキーマ定義ファイルなどを指定していました。 $ apollo client:codegen --target=typescript --localSchemaFile=graphql/schema.docs.graphql プロジェクトのルートディレクトリに、apollo.config.js というコンフィグファイルを作成しておくと、その設定を apollo client:codegen が読み込んでくれるようになります。 複雑な設定が必要になってきたら、このファイルを作成してしまうとよいです。 apollo.config.js module.exports = { client: { // includes: [\u0026#39;app/**/*.ts\u0026#39;, \u0026#39;app/**/*.tsx\u0026#39;], // src 以外のディレクトリを検索したいとき // tagName: \u0026#39;graphql\u0026#39;, // ts コード内のクエリリテラルで `gql` 以外を使う場合 service: { name: \u0026#39;github\u0026#39;, localSchemaFile: \u0026#39;./graphql/schema.docs.graphql\u0026#39; }, } }; ここでは、client.service.localSchemaFile プロパティでスキーマ定義ファイルの場所を設定しているので、コマンド実行時のオプション指定を次のように省略できます。 $ apollo client:codegen --target=typescript apollo.config.js の詳しい設定方法は下記の公式ドキュメントを参照してください。 Configuring Apollo projects - Apollo Basics - Apollo GraphQL Docs トラブルシューティング Apollo does not support anonymous operations apollo client:codegen コマンドを実行したときに、次のようなエラーになったら、 $ apollo client:codegen --target=typescript √ Loading Apollo Project × Generating query files with \u0026#39;typescript\u0026#39; target → Apollo does not support anonymous operations GraphQLError: Apollo does not support anonymous operations TypeScript コードの中で gql を使って定義したクエリに名前が付いていないものがあります。 次のように、名前を付けてやれば解決します。 const QUERY_TEAMS = gql` query { ... } ` （↑のコードを↓のように変更する） const QUERY_TEAMS = gql` query QueryTeams { ... } ` これで、うまく実行できるようになります。 $ apollo client:codegen --target=typescript √ Loading Apollo Project √ Generating query files with \u0026#39;typescript\u0026#39; target - wrote 12 files"
},
{
url: "/p/vgs4dnw/",
title: "Next.js アプリでのリンク方法まとめ（Material-UI との連携なども） (next/link, next/router)",
date: "2021-08-10T00:00:00Z",
body: "Next.js アプリでのリンク方法まとめ（Material-UI との連携なども） (next/link, next/router) アプリ内ページへのリンク（基本） // import Link from \u0026#39;next/link\u0026#39; \u0026lt;Link href=\u0026#34;/about\u0026#34;\u0026gt; \u0026lt;a\u0026gt;About us\u0026lt;/a\u0026gt; \u0026lt;/Link\u0026gt; pages/about.tsx ページコンポーネントが生成するページへのリンクになります。 リンクを \u0026lt;a\u0026gt; コンポーネントとして出力するために、上記のように子要素として明示的に \u0026lt;a\u0026gt; タグの記載が必要です。 \u0026lt;a\u0026gt; を省略しても、リンククリック時は JavaScript でハンドルされるので動作しますが、HTML 的には正しく \u0026lt;a\u0026gt; 要素を出力しておくべきです（SEO 的にも）。 replace オプション \u0026lt;Link href=\u0026#34;/about\u0026#34; replace\u0026gt; 上記のように replace オプションを指定すると、ページ遷移前の URL がブラウザの履歴に残りません（戻るキーで戻らなくなります）。 外部リンク https:// で始まる外部リンクを出力したい場合は、\u0026lt;a\u0026gt; コンポーネントをそのまま使用します。 next/link（や react-router) が提供する Link コンポーネントは、アプリ内のルーティング用なので使えません。 外部リンクを開く場合は、安全性のために一律で rel=\u0026quot;noopener noreferrer\u0026quot; を付けましょう。 リンククリック時に必ず別タブで開きたいときは、target=\u0026quot;_blank\u0026quot; を指定してください。 \u0026lt;a href=\u0026#34;https://example.com/\u0026#34; target=\u0026#34;_blank\u0026#34; rel=\u0026#34;noopener noreferrer\u0026#34;\u0026gt; サイト名 \u0026lt;/a\u0026gt; Material-UI を採用したサイトの場合は、a の代わりに @material-ui/core/Link コンポーネントを使用することで、サイト内のデザインを統一することができます。 Link という名前のコンポーネントはいろいろなライブラリが提供しているので、下記のように別名 (MuiLink) を付けて使用すると混乱を防ぐことができます。 // import { Link as MuiLink } from \u0026#39;@material-ui/core\u0026#39; \u0026lt;MuiLink href=\u0026#34;https://example.com/\u0026#34; target=\u0026#34;_blank\u0026#34; rel=\u0026#34;noopener noreferrer\u0026#34;\u0026gt; サイト名 \u0026lt;/MuiLink\u0026gt; 外部リンクを出力するときに、毎回上記のような長ったらしいコードを書くのは大変なので、次のような独自コンポーネント (ExternalLink) などを定義しておくと便利です。 ここでは、外部リンクを示すアイコン (@material-ui/icons/Launch) を末尾に表示するようにしています。 src/components/ExternalLink.tsx import { FC } from \u0026#39;react\u0026#39; import LaunchIcon from \u0026#39;@material-ui/icons/Launch\u0026#39; import { Link as MuiLink } from \u0026#39;@material-ui/core\u0026#39; type Props = { url: string title: string } export const ExternalLink: FC\u0026lt;Props\u0026gt; = ({ url, title }: Props) =\u0026gt; { return ( \u0026lt;MuiLink href={url} target=\u0026#34;_blank\u0026#34; rel=\u0026#34;noopener noreferrer\u0026#34; style={{ display: \u0026#39;inline-flex\u0026#39;, alignItems: \u0026#39;center\u0026#39; }} \u0026gt; {title} \u0026lt;LaunchIcon fontSize=\u0026#34;inherit\u0026#34; /\u0026gt; \u0026lt;/MuiLink\u0026gt; ) } MuiLink コンポーネントの style プロパティは、LaunchIcon の上下位置をリンク名のテキストに合わせるためのものです。 使用例 \u0026lt;ExternalLink url=\u0026#34;https://example.com/\u0026#34; title=\u0026#34;サイト名\u0026#34; /\u0026gt; 図: 表示結果 Next.js の Link コンポーネント以下に Material-UI の UI コンポーネントを配置する Next.js の Link コンポーネント (next/link) で独自のコンポーネントをリンクとして動作させるためには、ちょっとしたポイントがあります。 Material-UI は独自のコンポーネントとして、Link や Button を持っており、これらに href プロパティを指定することによって、a 要素としてレンダリングするようになっています（Material-UI の Link と Next.js の Link は別物なので注意）。 ダイレクトに a 要素を使わないのは、Material-UI が提供する UI 表現を使用するためですね。 Material-UI のリンク系コンポーネント import Link from \u0026#39;@material-ui/core/Link\u0026#39; import Button from \u0026#39;@material-ui/core/Button\u0026#39; \u0026lt;Link href=\u0026#34;/about\u0026#34; underline=\u0026#34;none\u0026#34;\u0026gt;About us\u0026lt;/Link\u0026gt; \u0026lt;Button href=\u0026#34;/about\u0026#34; variant=\u0026#34;contained\u0026#34;\u0026gt;About us\u0026lt;/Button\u0026gt; これはこれで便利なのですが、Next.js アプリ内での遷移には next/link を使ったルーティングを行う必要があるため、上記のようには記述できません（クライアントサイド JS でのルーティングが動作しません）。 next/link モジュールの Link 要素を使って、Material-UI の UI コンポーネントをリンクとして機能させるには、次のように記述します。 Link という名前がコンフリクトするため、ここでは、それぞれ NextLink、MuiLink という名前でインポートしています（片方だけリネームすれば十分ですが分かりやすくするため両方リネームしています）。 next/link と Material-UI を組み合わせて使う import NextLink from \u0026#39;next/link\u0026#39; import { Button, Link as MuiLink } from \u0026#39;@material-ui/core\u0026#39; \u0026lt;NextLink href=\u0026#34;/about\u0026#34; passHref\u0026gt; \u0026lt;MuiLink underline=\u0026#34;none\u0026#34;\u0026gt;About us\u0026lt;/MuiLink\u0026gt; \u0026lt;/NextLink\u0026gt; \u0026lt;NextLink href=\u0026#34;/about\u0026#34; passHref\u0026gt; \u0026lt;Button variant=\u0026#34;contained\u0026#34;\u0026gt;About us\u0026lt;/Button\u0026gt; \u0026lt;/NextLink\u0026gt; Next.js の Link コンポーネント (next/link) の href プロパティで指定した値を子要素に伝搬させるために、passHref プロパティを指定するのがポイントです。 passHref を指定しなくても、Next.js のクライアントサイド JS でリンク機能が動作するため、一見正しく動いているかのように見えますが、a 要素の href 属性がされないため、SEO 的に不利な Web サイトになってしまいます（さらに、Material-UI の Button コンポーネントの場合は、href が渡されないと、a 要素ではなく button 要素として出力されてしまいます）。 プログラム内部でリダイレクト // import Router from \u0026#39;next/router\u0026#39; Router.replace(\u0026#39;/list/users\u0026#39;) Router.replace を使うと、リダイレクト前の URL がブラウザの履歴に残りません（最初からこの URL でアクセスしたかのように振る舞います）。 アプリ内のルーティングではなく、外部 URL へ移動する場合は、next/router ではなく window.location を使用します。 これは、外部リンク用のコンポーネントとして next/link ではなく \u0026lt;a\u0026gt; を使用するのと同じ理由です。"
},
{
url: "/p/xjjbwes/",
title: "Next.js の public 以下のファイルのパスを正しく扱う",
date: "2021-07-30T00:00:00Z",
body: "Next.js の public 以下のファイルのパスを正しく扱う Next.js アプリでは、/public ディレクトリ以下に配置した静的リソースファイル（画像ファイルなど）は、次のような感じで URL のドメイン直下に配置されたファイルとして参照できるようになります。 // import Image from \u0026#39;next/image\u0026#39; \u0026lt;Image src=\u0026#34;/me.png\u0026#34; alt=\u0026#34;Picture of the author\u0026#34; width={500} height={500} /\u0026gt; 仮に、作成した Web サイトを GitHub Pages の「プロジェクトサイト」として公開する場合は、https://username.github.io/reponame/ のように一階層深い URL パスがアプリのルートになりますが、next.config.js で次のようにベースパスを設定しておけば、Next.js の Image コンポーネントは正しいパス (/reponame/me.png) に補正して画像ファイルを参照してくれます。 next.config.js const urlPrefix = \u0026#39;/reponame\u0026#39; module.exports = { // ... assetPrefix: urlPrefix, basePath: urlPrefix, trailingSlash: true, } 参考: Next.js アプリを GitHub Actions でビルドして GitHub Pages で公開する 一方で、Next.js が提供する Image コンポーネントなどを使わず、img 要素をそのまま使った場合、このような URL プレフィックスの付加は自動では行われず、画像が参照できなくなるという問題が発生します。 画像が参照できなくなる \u0026lt;img src=\u0026#34;/me.png\u0026#34; alt=\u0026#34;Picture of the author\u0026#34; /\u0026gt; Vercel 以外のサーバーで Web サイトをホスティングする場合、Image コンポーネント (next/image) は使えないことが多いので、この問題には意外とよく遭遇します。 次のユーティリティ関数 url() は、public ディレクトリ以下のファイルを参照するときに、正しい URL に補正するための関数です。 src/utils/config.ts import getConfig from \u0026#39;next/config\u0026#39; /** * public ディレクトリ以下に配置したファイルを参照するための URL を取得します。 * * 例: url(\u0026#39;/img/sample.png\u0026#39;) =\u0026gt; /reponame/img/sample.png * * next.config.js の publicRuntimeConfig.urlPrefix プロパティで指定した文字列が、 * filename 引数で指定された文字列のプレフィックスとして付加されます。 * 例えば Web サイトを GitHub Pages のプロジェクトページなどで公開する場合、 * * https://username.github.io/reponame/ * * のように、URL のドメイン直下がアプリのルートにならないため、 * この URL 補正のために必要です。 * * @see https://maku.blog/p/xjjbwes */ export function url(filename: string): string { const { publicRuntimeConfig } = getConfig() as { publicRuntimeConfig: { urlPrefix: string } } return publicRuntimeConfig.urlPrefix + filename } 上記のコードでは、next.config.js ファイルの publicRuntimeConfig.urlPrefix プロパティで設定した URL プレフィックスを参照しているので、next.config.js ファイルに正しい値を設定しておく必要があります。 参考: next.config.js: Runtime Configuration | Next.js 例えば次のように記述しておくと、next build によるビルド時に URL_PREFIX 環境変数で指定されていた値が、URL プレフィックスとして使用されるようになります。 next.config.js const urlPrefix = process.env.URL_PREFIX ? \u0026#39;/\u0026#39; + process.env.URL_PREFIX : \u0026#39;\u0026#39; module.exports = { assetPrefix: urlPrefix, basePath: urlPrefix, trailingSlash: true, publicRuntimeConfig: { urlPrefix }, // ★コレ } これで、コンポーネント内では次のように記述しておくだけで、public リソースファイルの参照が壊れてしまう心配がなくなります。 // import { url } from \u0026#39;../utils/config\u0026#39; \u0026lt;link rel=\u0026#34;icon\u0026#34; href={url(\u0026#39;/favicon.ico\u0026#39;)} sizes=\u0026#34;any\u0026#34; /\u0026gt; \u0026lt;img src={url(\u0026#39;/img/sample.png\u0026#39;)} alt=\u0026#34;Sample image\u0026#34; /\u0026gt;"
},
{
url: "/p/jz78nmk/",
title: "GraphQL の仕様メモ",
date: "2021-07-26T00:00:00Z",
body: "GraphQL の仕様メモ GraphQL 関連用語 クエリ文字列 (query string) query {...} という文字列全体のこと。 操作タイプ (operation type, root type) query {...} などの query というキーワード部分のこと。操作の種類を表しており、query の他には mutation と subscription があります。 操作名 (operation name) query HogeHoge {...} などの HogeHoge の部分のこと。特に query 操作の場合は query name、mutation 操作の場合は mutation name と呼ぶことがあります。操作名の指定は multi-operation documents じゃない限りオプショナルですが、ログ解析やデバッグをしやすくするために、名前を付けることが推奨されています。 クエリ変数 (query variables) query User($name: String!) {...} などの $name の部分のこと。 クエリ引数 (query arguments) book(id: \u0026quot;xyz\u0026quot;) {...} など、フィールド参照時に指定する id: \u0026quot;xyz\u0026quot; の部分のこと。クエリに変数が渡されている場合は、ここで book(id: $bookId) のような感じで参照できます。 選択セット、セレクションセット (selection sets) query HogeHoge {...} などの {...} の部分のこと。どのフィールドを取得したいかを選択するので、選択セットと呼びます。 フィールド (field) GraphQL オブジェクトの各プロパティ部分のこと。例えば、book { id title } というクエリで Book オブジェクトを取得するときの id とか title の部分。大きく分けて 2 種類あり、Scalar types（末端ノードそれ自体が値）と、Object types（ネストされたフィールドから構成される）があります。 入力オブジェクト型 (input object type, input types) 引数専用のオブジェクト型のこと。文字列 (String) や数値 (Int) などのスカラー値と比べて、複雑なデータを渡せます。例えば、新規データの作成要求 (mutation) を行うときに、新規データの内容を表現するために使われます。定義方法自体は普通のオブジェクト型 (type) と同様ですが、入力型 (input) はそれ自身のデータを取得する用途には使えないところが異なります（つまり、クエリ内のフィールドとしては指定できないということです）。 5 つの組み込みスカラー型 (Scalar types) 組み込みのスカラー型 型名 意味 Int 符号付き 32 ビット整数 Float 符号付き倍精度浮動小数点数 String 文字列（UTF-8 エンコーディング） Boolean true か false ID 一意の識別子。データ形式としては String と同様だが、ID はリーダブル（意味のある単語）にはなっていないことを示唆します。 その他はオブジェクト型、あるいはユーザー定義のスカラー型です。 ユーザー定義の型 ユーザーが自由に定義できる型は、オブジェクト型、スカラー型 (scalar)、列挙型 (enums) の 3 種類です。 スキーマ内での独自型の定義 # オブジェクト型typeCharacter{name:String!appearsIn:[Episode]!}# スカラー型scalarDate# 列挙型enumEpisode{NEWHOPEEMPIREJEDI} フラグメント (Fragments) フラグメント は複数のオペレーションから再利用可能なセレクションセットです。 例えば、 fragmentbasicUserInfoonUser{nameage}と定義すると、クエリのセレクションセットの User オブジェクトの中で、...basicUserInfo のように参照できるようになります。 query{user(name:\u0026#34;maku\u0026#34;){...basicUserInfo}}上記のクエリは、次のように記述するのと同様に振舞います。 query{user(name:\u0026#34;maku\u0026#34;){nameage}} レスポンス { \u0026#34;data\u0026#34;: { \u0026#34;user\u0026#34; { \u0026#34;name\u0026#34;: \u0026#34;maku\u0026#34;, \u0026#34;age\u0026#34;: 14 } } } フラグメントが役に立つのは、そのセレクションセットを使いまわすときです。 query{maku:user(name:\u0026#34;maku\u0026#34;){...basicUserInfo}chiko:user(name:\u0026#34;chiko\u0026#34;){...basicUserInfo}}上記のように単一クエリの中で同種のデータ（ここでは user）を要求する場合は、エイリアス（ここでは maku と chiko）を付けることで、レスポンス内のプロパティ名がコンフリクトしないようにします。 レスポンス { \u0026#34;data\u0026#34;: { \u0026#34;maku\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;maku\u0026#34;, \u0026#34;age\u0026#34;: 14 }, \u0026#34;hemu\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;chiko\u0026#34;, \u0026#34;age\u0026#34;: 5 }, } } イントロスぺクション GraphQL サーバーに対して次のようなクエリを投げると、どんなフィールドを指定できるかを調べることができます。 __schema{...}__type(name:\u0026#34;User\u0026#34;){...}"
},
{
url: "/p/raku5dn/",
title: "VS Code の Explorer で特定のファイルやディレクトリを非表示にする (files.exclude)",
date: "2021-07-24T00:00:00Z",
body: "VS Code の Explorer で特定のファイルやディレクトリを非表示にする (files.exclude) VS Code のエクスプローラービューは、サイドバー上にプロジェクト内のファイル一覧を表示してくれる便利な機能ですが、編集対象ではないファイルまで表示されていると地味に邪魔だったりします。 例えば、Node.js アプリの node_modules ディレクトリなどは常に表示されていてもあまり役に立たないかもしれません。 図: 不要なディレクトリが表示されている このような場合は、設定ファイル (settings.json) の files.exclude プロパティで非表示にしたいファイルやディレクトリのパターンを指定します。 settings.json { // Explorer で非表示にするもの \u0026#34;files.exclude\u0026#34;: { \u0026#34;**/.next\u0026#34;: true, // Next.js サーバーのキャッシュ \u0026#34;**/node_modules\u0026#34;: true, \u0026#34;out\u0026#34;: true // Next.js の export 先 }, // その他の設定... } 上記のようにパターンに out と指定すると、トップディレクトリの out という名前のファイルおよびディレクトリが非表示になります。 **/node_modules と指定すると、任意の階層の node_modules という名前のファイルおよびディレクトリが非表示になります。 末尾にスラッシュ (/) を付けるのは何も効果がないようです。 グロブパターン（** など）の詳細な指定方法は、Advanced search options のドキュメントが参考になります。 図: 指定したディレクトリが非表示になった ちなみに、デフォルト設定では次のようなファイルとディレクトリが非表示になります。 { // Configure glob patterns for excluding files and folders. // For example, the file Explorer decides which files and folders // to show or hide based on this setting. // Refer to the `search.exclude` setting to define search specific excludes. \u0026#34;files.exclude\u0026#34;: { \u0026#34;**/.git\u0026#34;: true, \u0026#34;**/.svn\u0026#34;: true, \u0026#34;**/.hg\u0026#34;: true, \u0026#34;**/CVS\u0026#34;: true, \u0026#34;**/.DS_Store\u0026#34;: true }, // ... }"
},
{
url: "/p/xenv4bh/",
title: "React の props.children の型定義には ReactNode を使う",
date: "2021-07-18T00:00:00Z",
body: "React の props.children の型定義には ReactNode を使う children の型定義 TypeScript で React の関数コンポーネントを定義するときには、下記のような React.FC (React.FunctionComponent) を使用します。 type FC\u0026lt;P = {}\u0026gt; = FunctionComponent\u0026lt;P\u0026gt;; interface FunctionComponent\u0026lt;P = {}\u0026gt; { (props: PropsWithChildren\u0026lt;P\u0026gt;, context?: any): ReactElement\u0026lt;any, any\u0026gt; | null; propTypes?: WeakValidationMap\u0026lt;P\u0026gt; | undefined; contextTypes?: ValidationMap\u0026lt;any\u0026gt; | undefined; defaultProps?: Partial\u0026lt;P\u0026gt; | undefined; displayName?: string | undefined; } // ... type PropsWithChildren\u0026lt;P\u0026gt; = P \u0026amp; { children?: ReactNode | undefined }; FC の型パラメータ P は、上記のような PropsWithChildren 型にラップされるので、props の型定義をするときに明示的に children を含める必要はありません。 下記の ColorBox コンポーネントは、指定した背景色で子要素 (children) を表示します。 ColorBox.tsx import { FC } from \u0026#39;react\u0026#39; type Props = { color: string } export const ColorBox: FC\u0026lt;Props\u0026gt; = ({ color, children }) =\u0026gt; { return \u0026lt;div style={{ background: color }}\u0026gt;{children}\u0026lt;/div\u0026gt; } ただ、これだと、ColorBox コンポーネントの型情報を見ただけでは、子要素 (children) が必要なのかどうかを判別することができません。 props の型定義で、明示的に children の型情報を指定するには、次のように React.ReactNode を使います。 import { FC, ReactNode } from \u0026#39;react\u0026#39; type Props = { color: string children: ReactNode } export const ColorBox: FC\u0026lt;Props\u0026gt; = ({ color, children }) =\u0026gt; { return \u0026lt;div style={{ background: color }}\u0026gt;{children}\u0026lt;/div\u0026gt; } これで、子要素を指定せずに ColorBox コンポーネントを使おうとしたときにエラー表示してくれるようになります。 \u0026lt;ColorBox color=\u0026#34;red\u0026#34; /\u0026gt; // 子要素がないのでエラー！ ちなみに、子要素の指定がオプショナルであることを明示するには、次のように children? と定義すれば OK です。 これであれば何も定義しないのと同じでは？と思うかもしれませんが、この定義があることで、子要素を指定したときに確実に何らかの描画が行われるということを示すことができます。 type Props = { color: string children?: ReactNode } （おまけ） React.ReactElement や JSX.Element との違い 上記で children の型定義に使った React.ReactNode 以外にも、次のような似たような型があるのでまとめて起きます。 ReactElement / JSX.Element React コンポーネントが生成する描画要素（\u0026lt;MyComponent\u0026gt; など）を表す型です。 関数コンポーネント (FC) の戻り値は、この ReactElement です。 （参考: DefinitelyTyped の定義） interface ReactElement\u0026lt; P = any, T extends string | JSXElementConstructor\u0026lt;any\u0026gt; = string | JSXElementConstructor\u0026lt;any\u0026gt; \u0026gt; { type: T props: P key: Key | null } type Key = string | number; React.FC インタフェースの定義を見ると、関数の戻り値として ReactElement が使われていることを確認できます。 TypeScript の型定義に慣れないと最初は理解しにくいかもしれませんが、下記の interface 定義の 1 つ目のプロパティが、関数コンポーネントのコールシグネチャを表しています。 type FC\u0026lt;P = {}\u0026gt; = FunctionComponent\u0026lt;P\u0026gt; interface FunctionComponent\u0026lt;P = {}\u0026gt; { (props: PropsWithChildren\u0026lt;P\u0026gt;, context?: any): ReactElement\u0026lt;any, any\u0026gt; | null propTypes?: WeakValidationMap\u0026lt;P\u0026gt; contextTypes?: ValidationMap\u0026lt;any\u0026gt; defaultProps?: Partial\u0026lt;P\u0026gt; displayName?: string } JSX.Element もほぼ同じもので、次のようなエイリアスなので、関数コンポーネントの戻り値の型として使用できます。 コンポーネントの実装において、部分的な要素を生成するユーティリティ関数の戻り値としても使用できます。 namespace JSX { interface Element extends React.ReactElement\u0026lt;any, any\u0026gt; { } // ... } ReactChild ReactChild は、ReactElement、文字列、数値のいずれかを表現する型です。 （参考: DefinitelyTyped の定義） type ReactChild = ReactElement | ReactText type ReactText = string | number 一見これを children の型として使用できそうですが、ReactChild はあくまで 1 つの要素を表すものなので、複数の要素を指定できる children の型としては使用できません。 ReactNode ReactNode は次のように定義されており、1 つ以上のコンポーネントやプリミティブ値を表します。 簡単にいうと、JSX コードの中の一部分はこの ReactNode で表現できます。 つまり、children の型としてはこの ReactNode を使うことができます。 type ReactNode = | ReactChild | ReactFragment | ReactPortal | boolean | null | undefined type ReactFragment = {} | ReactNodeArray interface ReactNodeArray extends Array\u0026lt;ReactNode\u0026gt; {} interface ReactPortal extends ReactElement { key: Key | null children: ReactNode } まとめ 各タイプを粒度の観点で整理すると次のような感じです。 ReactNode （1 つ以上の React コンポーネント or 文字列 or 数値） ReactChild （1 つの React コンポーネント or 文字列 or 数値） ReactElement / JSX.Element （1 つの React コンポーネント） ReactText （文字列 or 数値）"
},
{
url: "/p/pfdpybm/",
title: "React フック関連の記事",
date: "2021-07-18T00:00:00Z",
body: "React フック関連の記事"
},
{
url: "/p/m7it4do/",
title: "React 雑多記事",
date: "2021-07-18T00:00:00Z",
body: "React 雑多記事"
},
{
url: "/p/qcoz9ju/",
title: "VS Code のフォーマッターで自動整形する (editor.formatOnSave)",
date: "2021-07-14T00:00:00Z",
body: "VS Code のフォーマッターで自動整形する (editor.formatOnSave) VS Code には、標準で各種言語用のフォーマッターが搭載されており、JavaScript、TypeScript、JSON、HTML などのコードを自動整形することができます。 手動でフォーマッターを起動する ファイル全体をフォーマット (editor.action.formatDocument) コマンドパレット1 を使う場合: Format Document を選択 ショートカットキーを使う場合: (Windows) Shift + Alt + F (macOS) Shift + Option + F 選択中の行をフォーマット (editor.action.formatSelection) コマンドパレット1 を使う場合: Format Selection を選択 ショートカットキーを使う場合: (Windows) Ctrl + K → Ctrl + F (macOS) Cmd + K → Cmd + F ファイル保存時などに自動でフォーマットする 下記の設定をしておくと、ファイル保存時や、コードの編集中に自動的にフォーマッターを起動することができます。 設定ファイル (settings.json) の場所に関しては、こちらの記事 を参考にしてください。 全ての種類のファイルで自動フォーマットする場合 settings.json { // 自動フォーマット設定 \u0026#34;editor.formatOnSave\u0026#34;: true, // 保存時にフォーマット \u0026#34;editor.formatOnType\u0026#34;: true, // 入力中（改行時）にフォーマット \u0026#34;editor.formatOnPaste\u0026#34;: true, // ペースト時にフォーマット // その他... } フォーマッターによっては、保存時のフォーマット (editor.formatOnSave) にしか対応していません。 特定の種類のファイルで自動フォーマットする場合 下記は、TypeScript ファイル (.ts, .tsx) の編集中のみオートフォーマットを有効にする例です（参考: per-language configuration）。 settings.json { // .ts ファイル用の設定 \u0026#34;[typescript]\u0026#34;: { \u0026#34;editor.formatOnSave\u0026#34;: true, \u0026#34;editor.formatOnType\u0026#34;: true, \u0026#34;editor.formatOnPaste\u0026#34;: true, }, // .tsx ファイル用の設定 \u0026#34;[typescriptreact]\u0026#34;: { \u0026#34;editor.formatOnSave\u0026#34;: true, \u0026#34;editor.formatOnType\u0026#34;: true, \u0026#34;editor.formatOnPaste\u0026#34;: true, }, // ... } おすすめは、デフォルトで自動フォーマットを有効にしておいて、フォーマットしたくない種類のファイルだけ OFF にする設定です。 { // デフォルトで自動フォーマットを ON \u0026#34;editor.formatOnSave\u0026#34;: true, // Markdown ファイルは自動フォーマットしない \u0026#34;[markdown]\u0026#34;: { \u0026#34;editor.formatOnSave\u0026#34;: false, \u0026#34;editor.wordWrap\u0026#34;: \u0026#34;on\u0026#34;, \u0026#34;editor.renderWhitespace\u0026#34;: \u0026#34;all\u0026#34;, \u0026#34;editor.acceptSuggestionOnEnter\u0026#34;: \u0026#34;off\u0026#34;, \u0026#34;files.trimTrailingWhitespace\u0026#34;: false }, // ... } Prettier などの拡張フォーマッターを使用する VS Code に標準搭載されているフォーマッターの代わりに、拡張機能が提供するフォーマッターを使用するには、editor.defaultFormatter にその拡張機能の ID を設定します。 ここでは、下記の Prettier 拡張を使ってみます。 Prettier 自体のインストールや設定 は終わっているものとします。 Prettier - Code formatter - Visual Studio Marketplace この拡張機能の ID は esbenp.prettier-vscode なので、設定ファイルの中で次のように指定します。 settings.json { // 自動フォーマット設定 \u0026#34;typescript.format.enable\u0026#34;: false, // 組み込みのフォーマッターは無効にする \u0026#34;editor.defaultFormatter\u0026#34;: \u0026#34;esbenp.prettier-vscode\u0026#34;, // Prettier を使う \u0026#34;editor.formatOnSave\u0026#34;: true, \u0026#34;editor.formatOnType\u0026#34;: true, \u0026#34;editor.formatOnPaste\u0026#34;: true, // ... } 上記では、ファイル保存時 (formatOnSave) などに自動でフォーマットをかけるように設定していますが、コマンドパレット1 から Format Document などを選んだ場合も同様に Prettier 拡張のフォーマッターが使われるようになります。 Cmd/Ctrl + Shift + P\u0026#160;\u0026#x21a9;\u0026#xfe0e;"
},
{
url: "/p/4is2ahp/",
title: "Next.js アプリのディレクトリ構成を考える（Atomic Design と Presentational and Container Components）",
date: "2021-07-13T00:00:00Z",
body: "Next.js アプリのディレクトリ構成を考える（Atomic Design と Presentational and Container Components） Web サイトを構築するにあたって、よく参照されるコンポーネントの分類手法として、Atomic Design と Presetational and Container Components があります。 Atomic Design \u0026hellip; UI の粒度と具体性によって 5 レベルに分類する Presentational and Container Components \u0026hellip; 「表示」と「振る舞い」の役割で分類する ここでは、それぞれに関して概要をざっと眺めた上で、Next.js プロジェクトにどんな形で適用していけばいいかを考えてみます。 Atomic Design とは Web デザインにおける UI コンポーネントの分割粒度の考え方として、Brad Frost 氏の Atomic Design があります。 Atomic Design - Brad Frost 氏のブログ記事 Atomic Design - 書籍版（Webで読めます） Atomic Design では、UI コンポーネントを粒度の小さい順に次のように分類します。 図: Atomic Design の 5 つのレベル（Brad Frost 氏のブログより） Atoms（原子） \u0026hellip; これ以上分割できない単位（例: ラベル、入力、ボタン） Molecules（分子） \u0026hellip; 意味のある UI パーツ単位 （例: 検索フォーム (ラベル + 入力 + ボタン)） Organisms（有機体、生物） \u0026hellip; ページの一部分を構成する。Molecules をどう組み合わせるべきかという、アプリドメインの知識が入ってくる。 Templates（テンプレート） \u0026hellip; ページ全体のレイアウト。最初はプレースホルダーだらけかもしれないが、徐々に具体的な Organisms が配置されて最終形態に近づいていく。 Pages（ページ） \u0026hellip; Templates に具体的なデータを入れたもの（特定のページ）。 よく Organisms の扱いで迷うようですが、汎用性の側面から次のような感じで分類すると、プロジェクト内でコンポーネントを整理しやすくなります。 Pages に関しては、Templates に対してデータを流し込んだものなので、ここでは省略しています。 汎用性 考え方 Atoms ◯ 純粋な UI パーツ。通常、アプリドメインの知識を持たず、渡されたデータをそのまま描画するだけ。React であれば、渡された props を表示する。表示幅やマージンなどは、より上位のモジュールから自由に設定できるようになっているのが望ましい。 Molecules ◯ Organisms △ アプリドメインの知識を持って、表示内容を構成する。例えば、アプリヘッダーなど、そのアプリ特有のパーツを構成する。Atoms/Molecules は渡されたデータをただ表示する役割しか持たないので、おそらくデータフェッチ処理などのロジックは、この Organisms より上位のコンポーネントで行うことになる。 Templates × 正確には、Atomic Design では「振る舞い」をどのレベルで導入するかに関しては言及されていないのですが、少なくとも Atoms/Molecules は「表示」のみを責務とするコンポーネントとして定義するのがよいでしょう。 Presentational and Container Components とは Dan Abramov 氏の Presentational and Container Components は、コンポーネントを「見た目」と「振る舞い」の観点で分類します。 Presentational components \u0026hellip; 「見た目」だけを提供するコンポーネント。上位のコンポーネントから渡された props を単純に表示する。 Container components \u0026hellip; 「振る舞い」を提供するコンポーネント。データフェッチや状態の保持、変更などの責務を負い、表示すべきデータを Presentational components に渡す。 「見た目」と「振る舞い」を分離することによって、それぞれの観点からテストしやすくなったり、コンポーネントとしての再利用性が上がるといった利点があります。 多くの場合は、「見た目」と「振る舞い」の定義は一対一になりますが、一対多の関係になることもあります。 例えば、1 つの UI コンポーネントに流し込むデータの取得先が 2 種類あるようなケースです。 このようなケースでは、Presentational and Container Components パターンでコンポーネント分離できていれば対応が簡単です。 下記は、簡単な Presentational components と Container components の実装例です。 Presentational components（見た目）の例 export const AvatarCard: FC\u0026lt;{ name: string }\u0026gt; = ({ name }) =\u0026gt; { const classes = useStyles() return \u0026lt;div className={classes.avatar}\u0026gt;I am {name}\u0026lt;/div\u0026gt; } 表示するデータ自体は props パラメーターで受け取っていて、それをそのまま表示しているだけなので、これは「見た目」の実装です。 ここではフック関数 (useStyles) を呼んじゃってますが、これは装飾のためのスタイル設定なので OK。 Container components（振る舞い）の例 export const AvatarCardContainer: FC = () =\u0026gt; { const name = useAvatar() return \u0026lt;AvatarCard name={name} /\u0026gt; } Container components の方で呼び出している useAvatar フックは、データフェッチを行って情報を取得します。 こちらは「振る舞い」の実装です。 「表示」の処理に関しては、Presentational components に委譲しています。 React にフックの仕組みが導入されたことにより、「振る舞い」の大部分はフック関数に切り出すことが可能になりました。 そのため、Container componets へ「振る舞い」を切り出すという方法は、以前ほど採用されなくなっているかもしれません。 それでも、完全に「見た目」と「振る舞い」を確実に分離したいときは、Presentational and Container Components の考え方が必要になってきます。 フックだけでは、useXxx という関数呼び出し部分が、どうしても UI コンポーネント内に残ってしまうからです。 Next.js アプリのディレクトリ構成を考える 上記を考慮した、Next.js アプリの（src 以下の）ディレクトリ構成をいくつか考えてみます。 実際のプロジェクトでは、次のようなディレクトリも作ることになると思いますが、ここではコンポーネント用のディレクトリだけ考えます。 hooks/ \u0026hellip; React のカスタムフック types/ or interfaces/ \u0026hellip; TypeScript 型定義 utils/ or libs/ \u0026hellip; その他のユーティリティ（データフェッチ関数など） まず、Next.js アプリでは、ページコンポーネントは pages ディレクトリに格納することが決まっているので、Atomic Design の Templates (Pages) に相当するコンポーネントは自然にここに入れることになります。 パターン(1) components ディレクトリ 1 つだけ 一番シンプルなディレクトリ構成だとこんな感じでしょうか。 components/ \u0026hellip; ページコンポーネント以外のコンポーネント pages/ \u0026hellip; ページコンポーネント この方法では、Atomic Design も Presentational and Container Componets も特に意識せずに、全てのコンポーネントを conpoments に入れちゃいます。 最初はここからスタートしてもよいかもしれません。 components ディレクトリ以下は、コンポーネントのカテゴリごとに、さらに階層化されることがあります。 components/ button/ card/ ここで Atomic Design による階層化を行うこともあります（このやり方は割とよく見受けられます）。 components/ atoms/ molecules/ organisms/ 各ディレクトリ以下のコンポーネントの依存関係は、基本的には atoms \u0026lt;- molecules \u0026lt;- organisms となります。 ディレクトリ名でソートしたときに、この順番に並ぶところがいいですね。 components 以下に全てのコンポーネントを入れてしまう場合、「見た目」と「振る舞い」の実装は、特に意識して分離しないと保守性が下がってしまいます。 アプリケーションのロジック（振る舞い）に関しては、必ず hooks ディレクトリ内にカスタムフックとして実装する、といったルールを決めておくとよいでしょう。 パターン(2) Presentational/Container components のディレクトリを分ける components/ \u0026hellip; 「見た目」を定義するコンポーネント (Presentational Components) containers/ \u0026hellip; 「振る舞い」を定義するコンポーネント (Container Components) pages/ \u0026hellip; ページコンポーネント 「振る舞い」を定義する Container Components 用に、containers というディレクトリを別に用意する方法です。 例えば、BookList というコンポーネントを作る場合、「見た目」を定義するコンポーネントとして components/BookList.tsx を作成し、そこにデータを詰める「振る舞い」を定義するコンポーネントとして container/BookList.tsx を作成します。 別のコンポーネントからこの BookList を使用するときは、通常 container/BookList の方を参照することになります。 コンポーネントが増えてきたときは、components や containers の下を、Atomic Design で階層化するのもいいでしょう。 components/ atoms/ molecules/ organisms/ containers/ atoms/ molecules/ organisms/ アプリ特有のカテゴリとして、button や card といったディレクトリを作るのもいいと思います。 アプリの規模が小さいうちは、こちらの方が直感的でわかりやすいかもしれません。 components/ button/ card/ containers/ button/ card/ これらのやり方の利点は、表示だけを担う UI パーツが全て components に集まるところです。 UI カタログみたいなものを作りたいときは、components 以下のコンポーネントだけを意識すれば済みます。 欠点としては、「見た目」と「振る舞い」の定義が異なるディレクトリに散らばってしまうので、若干対応付けがしにくくなるところでしょうか。 ちなみに、このディレクトリ名（components と containers）はすごく分かりにくいと感じるのは私だけでしょうか・・・？ どちらもコンポーネントなので、どっちがどっち？ってなる (^^; もっと明確に、次のような階層にしてしまうことも考えられますが、これはちょっとネストしすぎかな。。。 components presentation container パターン(3) Presentational/Container components をセットで置く 「見た目」を定義するコンポーネントと、「振る舞い」を定義するコンポーネントを、同じディレクトリに入れてしまう方法です。 例えば、BookList コンポーネントであれば次のような感じ。 components/ BookList.tsx （Presentaional components) BookListContainer.tsx (Container components) 上記のようなファイル名にすると、実際にこのコンポーネントを参照するときに BookListContainer の方を使うことになるので、次のように Container components の方をシンプルな名前にした方がいいかもしれません。 components/ BookList.tsx (Container components) BookListPresenter.tsx (Presentational components) 特殊なやり方として、BookList コンポーネント用にディレクトリを掘ってしまう方法もあります。 components/ BookList/ index.tsx (Container components) Presenter.tsx (Presentational components) Presenter.tsx は、もっと具体的に BookListPresenter.tsx にしてもいいかもしれません。 他のコンポーネントから参照するときは、これまで通り components/BookList というパスでインポートできます（index.tsx を読み込んでくれます）。 もちろん、「振る舞い」の定義が必要ないコンポーネントの場合は、わざわざディレクトリを掘らずに、components ディレクトリに直接 Presentation components を配置してしまえば大丈夫です。 これらのやり方においても、コンポーネントが増えてきたときに components/ 以下を Atomic Desigin などで階層化するのは自由です。 README.md にディレクトリ構成を書いておく どのようなディレクトリ構成を採用するにせよ、プロジェクトの README.md に、src ディレクトリ以下の構成 と、そこにどのようなファイルを置くべきかの指針を書いておきましょう。 チーム内で何らかのルールが守られてさえいれば、後から配置ルールを変更することになっても、それほど苦労せずに対応できるはずです。 README.md の記述例（抜粋） ### src ディレクトリ以下の構成 components/ \u0026ndash; Presentational components 「見た目」を定義する UI コンポーネント (.tsx) を配置します。 ロジックを持たず、渡された props を純粋に描画するコンポーネントです。 何らかのロジック（フックによるデータフェッチや状態管理）を持つコンポーネントは、ここではなく containers ディレクトリに配置してください。 このディレクトリ以下は、さらにカテゴリ別に階層化することができます。 containers/ \u0026ndash; Container components 「振る舞い」を定義するコンポーネント (.tsx) を配置します。 フック関数などによるデータフェッチ、状態の保存・変更などのロジックを含み、最終的に表示すべきデータを別のコンポーネントの props オブジェクトとして渡します。 このディレクトリ以下は、さらにカテゴリ別に階層化することができます。 hooks/ \u0026ndash; Custom hooks React のカスタムフックを配置します（例: useAuth.ts）。 アプリケーションのロジックはコンポーネント内には記述せず、できるだけフック関数として実装します。 基本的に、フック関数は comtainers ディレクトリ以下のコンポーネントや、別のフック関数から呼び出されます。 pages/ \u0026ndash; Page components Next.js のページコンポーネント (.tsx)、および、_app.tsx と _document.tsx を配置します。 Web サイトアクセス時の URL パスに応じたファイル (xxx.tsx) が読み込まれます。 Atomic Design における Templates (Pages) に相当します。 types/ \u0026ndash; Type definitions 複数ファイルで共有する TypeScript 型定義を配置します。 index.ts から export した型は、import { UserInfo } from '../types' のようにインポートできます。 utils/ \u0026ndash; Other utilities 上記いずれにも当てはまらないユーティリティ（コンフィグ、データフェッチ関数など）を配置します。 コンポーネントを作るときに components に入れるか containers に入れるかで迷ったら、とりあえず containers の方に入れておいて、後ほど「見た目」の定義だけを切り出して components に入れるとよいです。 「振る舞い」の定義をフックに切り出すだけにとどめる場合（Container components を作らない）場合は、components ディレクトリ以下のコンポーネントで「振る舞い」を実装しないように記述しておくとよいです。 上記の説明のうち、containers の項目を削除して、次のように書き換えます。 components/ \u0026ndash; UI components 「見た目」を定義する UI コンポーネント (.tsx) を配置します。 アプリケーションのロジック（データフェッチや状態管理）は、ここではなく hooks ディレクトリ内にカスタムフックとして実装してください。 このディレクトリ以下は、さらにカテゴリ別に階層化することができます。 hooks/ \u0026ndash; Custom hooks React のカスタムフックを配置します（例: useAuth.ts）。 アプリケーションのロジックはコンポーネント内には記述せず、できるだけフック関数として実装します。 基本的に、フック関数は components ディレクトリ以下のコンポーネントや、別のフック関数から呼び出されます。"
},
{
url: "/p/gk6jx9k/",
title: "DynamoDB 用のポリシー設定例",
date: "2021-06-28T00:00:00Z",
body: "DynamoDB 用のポリシー設定例 あるテーブルに対するすべての操作を可能にする { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;AllAPIActionsOnBooks\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;dynamodb:*\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:dynamodb:us-west-2:123456789012:table/Books\u0026#34; } ] } Action に dynamodb:* というワイルド―カードを指定することで、DynamoDB のすべての API を使った操作を可能にしています。 通常は、特定のアクションのみを許可すべきです。 あるテーブルの読み取りを行えるようにする { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;DescribeQueryScanBooksTable\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;dynamodb:DescribeTable\u0026#34;, \u0026#34;dynamodb:Query\u0026#34;, \u0026#34;dynamodb:Scan\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:dynamodb:us-west-2:123456789012:table/Books\u0026#34; } ] } このポリシーステートメントは、アカウント 123456789012 が所有する Books テーブルの読み取り（Query や Scan）が可能であることを示します。 下記は、もう少し可能な操作を増やしたバージョンです。 { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;ReadOnlyAPIActionsOnBooks\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;dynamodb:GetItem\u0026#34;, \u0026#34;dynamodb:BatchGetItem\u0026#34;, \u0026#34;dynamodb:DescribeTable\u0026#34;, \u0026#34;dynamodb:Query\u0026#34;, \u0026#34;dynamodb:Scan\u0026#34;, \u0026#34;dynamodb:ConditionCheckItem\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:dynamodb:us-west-2:123456789012:table/Books\u0026#34; } ] }"
},
{
url: "/p/k2ahpw5/",
title: "Next.js でハッシュフラグメントを扱う（useHash カスタムフック）",
date: "2021-06-28T00:00:00Z",
body: "Next.js でハッシュフラグメントを扱う（useHash カスタムフック） ハッシュフラグメントとは URL のハッシュフラグメントというのは、下記のような URL の末尾の # 以降の部分を指します。 https://examle.com/sample#AAA 似たようなものにクエリパラメーター（?key=val のみたいなの）もありますが、ハッシュフラグメントは HTTP リクエスト時に、その文字列（上記の例では AAA）がサーバーに送られないという違いがあります。 つまり、ハッシュフラグメントの値は、クライアントサイドで使用することが意図されています。 useHash フックの実装 下記の useHash 関数は、Next.js でハッシュフラグメントを簡単に扱えるようにするカスタムフックの例です。 useState フックと同じ感覚で使えるように、ハッシュフラグメントの現在値と、設定用の関数をペアで返します。 src/libs/useHash.ts import { useCallback } from \u0026#39;react\u0026#39; import { useRouter } from \u0026#39;next/router\u0026#39; /** * URL のハッシュフラグメント部分を扱うためのフックです。 * * 次のようにすると、`hash` 変数に URL の `#` 以降の値が格納されます。 * URL の `#` 以降の値を変更したいときは、`setHash` 関数を使用します。 * * ``` * const [hash, setHash] = useHash() * ``` */ export function useHash(): [string, (newHash: string) =\u0026gt; void] { const router = useRouter() const hash = extractHash(router.asPath) const setHash = useCallback((newHash: string) =\u0026gt; { // ブラウザの履歴に残すなら、ここを router.push に変えれば OK router.replace({ hash: newHash }, undefined, { shallow: true }) }, []) return [hash, setHash] } // URL の # 以降の文字列を取り出すユーティリティ function extractHash(url: string): string { return url.split(\u0026#39;#\u0026#39;)[1] ?? \u0026#39;\u0026#39; } やっていることは簡単で、router.asPath から抽出したハッシュフラグメントの値を返しているだけです。 レンダリングのたびに値を抽出して返そうとしますが、まぁこれくらいはよいかなと(^^; useHash フックの使用例 下記は useHash フックの使用例です。 テキストボックスに何か入力すると、Web ブラウザの URL のハッシュフラグメント部分がそれに合わせて変化し、さらにページ内の表示（Current hash の値）も連動して変化します。 src/pages/sample.tsx import { FC } from \u0026#39;react\u0026#39; import { useHash } from \u0026#39;../libs/useHash\u0026#39; const SamplePage: FC = () =\u0026gt; { const [hash, setHash] = useHash() return ( \u0026lt;\u0026gt; \u0026lt;p\u0026gt;Current hash = {hash}\u0026lt;/p\u0026gt; \u0026lt;input onChange={(e) =\u0026gt; setHash(e.target.value)} /\u0026gt; \u0026lt;/\u0026gt; ) } export default SamplePage と、ここまでやってみて気付きましたが、Next.js アプリとハッシュフラグメントは相性がよくない ですね (^^; Next.js はプリレンダリングの仕組みがあり、当然そのタイミングではハッシュフラグメントの値は取得できないので、上記のコードではプリレンダリング時には hash の値は必ず空っぽになってしまいます（もちろん、初回のクライアントサイドでの描画時にはすぐにハッシュフラグメントの値を取得できるようになりますが）。 なので、初期表示では hash の値が空っぽの状態のページがロードされるということを意識してコーディングをしておく必要があります。 このあたりの事情は router.query で URL のクエリパラメーターを扱う ときも同様です。 （おまけ）ハッシュフラグメントの変更と React コンポーネントの再レンダリングの関係 URL 末尾のハッシュフラグメントを変更する方法はいくつもあるので、それぞれの方法で変更した場合に、React コンポーネントが再レンダリングされるのかについてまとめておきます。 再レンダリングされないケース ユーザーが Web ブラウザのアドレスバーで、直接ハッシュフラグメントだけ変更した場合（例: https://example.com/#1 → https://example.com/#2） コンポーネントのコードで location.hash = 'Hello' とした場合 \u0026lt;a href=\u0026quot;#1\u0026quot;\u0026gt;Hello\u0026lt;/a\u0026gt; のようなリンクをクリックした場合 このように、URL のハッシュフラグメント部分が直接的に変更された場合は、現在表示されているページコンポーネントの再レンダリングは実行されません。 このケースでは、ハッシュフラグメントの変化は、window.addEventListener('hashchange', handler) で監視できます。 一方で、next/router の router.event.on(\u0026lsquo;hashChangeComplete\u0026rsquo;, handler) では変更監視できません。 再レンダリングされるケース next/router で Router.push({ hash: 'Hello' }) した場合 next/link の \u0026lt;Link href=\u0026quot;#Hello\u0026quot;\u0026gt;Hello\u0026lt;/Link\u0026gt; のようなリンクをクリックした場合 これらのケースでは、現在表示されているページコンポーネントに再レンダリングのトリガーがかかります。 ハッシュフラグメントの変化は、next/router の router.event.on('hashChangeComplete', handler) で監視できます。 一方で、window.addEventListener('hashchange', handler) では変更監視できません。 ようするに、URL 末尾のハッシュフラグメント部分の変更と React コンポーネントのレンダリングを同期させたいときは、Next.js のアプリ内ルーティングを扱うための next/router や next/link を使ってハッシュフラグメント部分を変更しなければいけないということです。 その際に hashchange イベントが発生しないのは、Next.js のルーティングで内部的に pushState が使われていることが原因のようです。 仮に、Web ブラウザーのアドレスバーでハッシュフラグメント部分を直接変更した場合にも再レンダリングを発火させたいときは、例えば次のような感じで実装すれば全て連動させることができると思います。 ハッシュフラグメントだけ変更するときは、location.hash を変更するか \u0026lt;a href=\u0026quot;#xxx\u0026quot;\u0026gt; のリンクをクリックさせる。 変更監視は window.addEventListener('hashchange') で行う。 変更を検出したら、useState() フックで生成したセッター setXxx を呼び出して、React コンポーネントの再レンダリングをかける。 ちょっと面倒だし、わかりにくいですね。。。 URL のクエリパラメーター (router.query) による処理 で間に合うのであれば、素直にそちらを使った方がよさそうです。"
},
{
url: "/p/gbpeyov/",
title: "Next.js で環境変数を扱う (.env, NEXT_PUBLIC, NODE_ENV)",
date: "2021-06-28T00:00:00Z",
body: "Next.js で環境変数を扱う (.env, NEXT_PUBLIC, NODE_ENV) Next.js アプリ内での環境変数の振る舞い process.env の振る舞い Node.js の process.env による環境変数の参照が有効なのは、基本的には次のようなサーバーサイドで実行されるコード内のみです。 ビルド時あるいはアクセス時に呼び出される getStaticPaths や getStaticProps 必ずアクセス時に呼び出される getServerSideProps 必ずアクセス時に呼び出される API ルートのハンドラ関数 (handler) src/pages/sample.tsx export const getStaticProps: GetStaticProps\u0026lt;PageProps\u0026gt; = async context =\u0026gt; { // このコードはビルド時に実行されるので環境変数を参照できる console.log(process.env.VAR_NAME) return { props: {} } } NEXT_PUBLIC プレフィックス ただし、例外として、NEXT_PUBLIC_ で始まる環境変数を process.env.NEXT_PUBLIC_XXX のように参照すると、next build によるビルド時に変数値がインライン展開されるので、クライアントサイドで実行されるコード（コンポーネントの実装内）から参照できます。 src/pages/sample.tsx const SamplePage: FC = () =\u0026gt; { return \u0026lt;\u0026gt; \u0026lt;p\u0026gt;Public env: {process.env.NEXT_PUBLIC_ANALYTICS_ID}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;Private env: {process.env.API_SECRET_KEY} （必ず空っぽ）\u0026lt;/p\u0026gt; \u0026lt;/\u0026gt; } 上記のようにすると、process.env.NEXT_PUBLIC_ANALYTICS_ID の部分には、ビルド時の環境変数 NEXT_PUBLIC_ANALYTICS_ID の値がそこに埋め込まれ、process.env.API_SECRET_KEY の方は必ず undefined になります（何も表示されない）。 サーバーサイドでしか参照しない環境変数（シークレットキーなど）には、NEXT_PUBLIC_ プレフィックスを付けないように注意してください。 .env (.env.local) ファイル Next.js サーバーは、デフォルトでプロジェクトルートに配置した .env や .env.local といった名前のファイルを読み込んで、process.env.XXX で参照可能な状態にしてくれます。 ローカル開発中に、一時的にテスト用のリソースサーバーに繋ぎたいときなどに便利です。 .env.local DB_HOST=localhost DB_USER=myuser DB_PASS=mypassword これらの設定ファイルの中では、次のように $VAR という形の変数展開を行えるようになっています。 HOSTNAME=localhost PORT=8080 HOST=http://$HOSTNAME:$PORT .local サフィックスが付いている方のファイルは、「Git などにコミットしないファイルですよ」という Next.js での取り決めですね。 Next.js は他にも実行環境に応じて色々な名前の環境設定ファイルを読み込むようになっています。 下記は、どのファイルがどの環境で読み込まれるかの一覧です。 ファイル 本番環境 (next start) 開発環境 (next dev) テスト環境 （jest など） Git コミット するか？ .env \u0026#x2714;(4) \u0026#x2714;(4) \u0026#x2714;(4) \u0026#x2714;する .env.local \u0026#x2714;(2) \u0026#x2714;(2) \u0026#x2714;(2) しない .env.production \u0026#x2714;(3) \u0026#x2714;する .env.production.local \u0026#x2714;(1) しない .env.development \u0026#x2714;(3) \u0026#x2714;する .env.development.local \u0026#x2714;(1) しない .env.test \u0026#x2714;(3) \u0026#x2714;する .env.test.local \u0026#x2714;(1) しない 括弧の中の数値は、優先度を示しています（1が最大）。 複数のファイルに同じ環境変数が定義されている場合は、.local が付いたものが優先的に使われます。 例えば、本番環境 (next start) では、.env.production.local ＞ .env.local ＞ .env.production ＞ .env という優先度になります。 末尾に .local が付いたファイルには秘密鍵などの情報を記述することを想定しているので、間違えて Git にコミットしないように .gitignore ファイルに登録しておきましょう。 .gitignore # local env files .env.local .env.production.local .env.development.local .env.test.local config.ts に環境変数の値を反映させる アプリ全体のコンフィグ用に config.ts のようなファイルを作成しているケースは多いと思います。 この中で環境変数を参照するようにしておくと、環境 (production or development) に応じてリソースを使い分けるといったことが簡単にできます。 これは、Next.js が前述のように複数のファイルを読み分けてくれるおかげです。 src/libs/config.ts export const config = { userPoolId: process.env.NEXT_PUBLIC_USER_POOL_ID ?? \u0026#39;default-user-pool\u0026#39;, identityPoolId: process.env.NEXT_PUBLIC_IDENTITY_POOL_ID ?? \u0026#39;default-id-pool\u0026#39;, } ちなみに、?? という演算子は Nullish coalescing という仕組みで、左側が undefined だったときに右側の値が使われるようになります。 つまり、上記のように記述しておくと、環境変数が設定されていればその値を使い、設定されていなければ後ろに書いたデフォルト値を使う、という振る舞いになります。 参考: TypeScript で undefined/null をうまく扱う (nullish coalescing (??), optional chaining (?.)) 例えば、本番環境で接続先の情報を変えたいときは、次のような環境変数ファイルを作成するだけで済みます。 next start で Next.js サーバーを起動したときや、Vercel でホスティングするときはこの設定が使われるようになります。 .env.production NEXT_PUBLIC_USER_POOL_ID=xxxxxxxxxxxxx NEXT_PUBLIC_IDENTITY_POOL_ID=yyyyyyyyyyyyy NODE_ENV 環境変数で開発環境と本番環境の動作を切り替える Next.js サーバー実行時の NODE_ENV 環境変数の値は、サーバーの起動方法によって次のように設定されるようになっています。 Next.js サーバーの起動方法 process.env.NODE_ENV の値 next dev development next start production これを利用すると、現在の実行環境に応じて振る舞いを変更できます。 次の例では、開発環境 (next dev) ではローカルのリソースファイルを使い、本番環境 (next start) ではインターネット上のリソースファイルを使うようにしています。 function getImageUrl(filename: string) { if (process.env.NODE_ENV === \u0026#39;production\u0026#39;) { // 本番環境ではインターネット上のファイルを参照 return `https://example.com/img/${filename}` } else { // 開発環境では public ディレクトリ以下のファイルを参照 return `/img/${filename}` } } ほとんどのユースケースは上記のような切り替えでカバーできるのですが、時々 next build によるビルド後のサイト確認 (next start) でも、ローカルリソースを参照したいことがあります（ファイル転送による従量課金が気になる場合など）。 このようなケースで、next start コマンド実行時に強引に NODE_ENV 環境変数の値を development に変えようとしても、内部で production に上書きされてしまってうまくいきません。 これは無意味 (\u0026gt;_\u0026lt;) $ NODE_ENV=development next start こういったケースでは、next.config.js の env コンフィグ 機能を使って、ビルド時に独自の環境変数を設定してやるとうまくいきます。 next.config.js const isProd = process.env.NODE_ENV === \u0026#39;production\u0026#39; module.exports = { env: { isProd: isProd, } } next.config.js ファイルはビルド時に処理されるので、上記のように記述しておくと、process.env.isProd の値が、next build 実行時の NODE_ENV 変数の値によって確定します（正確には、コード内部の process.env.isProd という部分が具体的な値に置換されます）。 プログラム内で process.env.NODE_ENV を参照していた部分は、次のように process.env.isProd を参照するように書き換えます。 function getImageUrl(filename: string) { if (!!process.env.isProd) { return `https://example.com/img/${filename}` } else { return `/img/${filename}` } } あとは、ビルド方法や実行方法により、process.env.NODE_ENV や process.env.isProd の値を次のように変化させることができます（コンポーネント内のコードで参照したときの値を示していることに注意してください）。 ビルド／実行方法 NODE_ENV の値 isProd の値 $ next build $ next start 'production' true $ NODE_ENV=development next build $ next start 'production' false $ next dev 'development' false 実際には、NODE_ENV 環境変数を isProd の値の制御のために使うのは混乱を招くので避けた方がいいかもしれません。 上記の結果を見るとわかるように、ビルド時に NODE_ENV=development と指定しても、ランタイムでは NODE_ENV の値は production になってしまいます。 リソースの参照先を柔軟に切り替えたいときは、次のように独自の環境変数 (IS_LOCAL) を用意するようにした方がよいでしょう。 next.config.js const isProd = process.env.NODE_ENV === \u0026#39;production\u0026#39; const isLocal = process.env.IS_LOCAL != undefined || !isProd module.exports = { env: { isLocal, imageUrlPrefix: isLocal ? \u0026#39;/img/\u0026#39; : \u0026#39;https://example.com/img/\u0026#39; }, } ローカルファイルを参照したいときのビルド方法 $ IS_LOCAL=1 next build $ next start 上記の next.config.js の例では、環境によってリソースファイルのプレフィックス情報 (process.env.imageUrlPrefix) を切り替えているので、getImageUrl 関数は次のように簡潔に記述できます。 使用例 function getImageUrl(filename: string) { return (process.env.imageUrlPrefix ?? \u0026#39;\u0026#39;) + filename }"
},
{
url: "/p/r7fou3a/",
title: "Next.js のコンポーネント内でクエリ文字列を取得する (next/router, useRouter)",
date: "2021-06-27T00:00:00Z",
body: "Next.js のコンポーネント内でクエリ文字列を取得する (next/router, useRouter) クエリ文字列とは https://example.com/todos?sortby=title\u0026amp;order=asc URL のクエリ文字列（クエリパラメーター）というのは、上記のような URL の末尾の ? 以降の、sortby=title\u0026amp;order=asc の部分のことを指します。 この部分を参照する方法としては、主に次の 2 種類の方法があります。 クライアントサイド JS \u0026hellip; useRouter フックを使う サーバーサイド JS \u0026hellip; getServerSideProps に渡されるパラメーターを使う クライアントサイド JS からクエリパラメーターを参照する (router.query) Next.js の useRouter フック を使うと、上記のようなクエリパラメーター部分を簡単に抽出することができます。 次の例では、クエリパラメーターとして渡された sortby と order の値を取得しています。 値が省略された場合は、それぞれの値は undefined になります。 src/pages/todos.tsx import { FC } from \u0026#39;react\u0026#39; import { useRouter } from \u0026#39;next/router\u0026#39; const TodosPage: FC = () =\u0026gt; { const router = useRouter() const { sortby, order } = router.query return ( \u0026lt;p\u0026gt;{ sortby } で { order === \u0026#39;asc\u0026#39; ? \u0026#39;昇順\u0026#39; : \u0026#39;降順\u0026#39; } ソートします\u0026lt;/p\u0026gt; ) } export default TodosPage ☝️ プリレンダリングと hydrate 処理の考慮 Next.js にはページコンポーネントのプリレンダリングの仕組み（あらかじめ JS 部分まで実行して静的な HTML を生成しておく仕組み）があり、その時点では URL のクエリ文字列は参照できないので、router.query オブジェクトも空っぽになっています。 上記の例で言えば、プリレンダリング時の sortby や order の値は undefined になっているということです。 もちろん、実際にクエリパラメーター付きの URL で Web サイトにアクセスするタイミングでは、クライアントサイドで実行される JavaScript で router.query の値を参照できるようになっていますが、ページコンポーネントの実装では、クエリ文字列が指定されていない場合のことを考えておくべきです。 このように、Next.js アプリにおいて、ページコンポーネントに記述した JS コードが、プリレンダリング時とアクセス時に行われる仕組みは hydration (hydrate) と呼ばれています。 サーバーサイド JS からクエリパラメーターを参照する (context.query) Web サイトへのアクセス時に必ずサーバーサイドで呼び出される getServerSideProps 関数では、関数のパラメーターとしてクエリパラメーターを受け取ることができます。 serverSideProps 内でのクエリパラメーターの参照 import { GetServerSideProps } from \u0026#39;next\u0026#39; export const getServerSideProps: GetServerSideProps\u0026lt;PageProps\u0026gt; = async (context) =\u0026gt; { const { id } = context.params as PathParams // /books/[id] の id 部分など const { sortby, order } = context.query // URL の ? 以降のクエリパラメーター console.log(id) console.log(sortby) console.log(order) return { props: { // PageProps 型の情報を詰める } } } ちなみに、ビルド時に呼び出される getStaticProps 関数の中では、クエリパラメーターを取得することはできません。 クエリパラメーターは、あくまで実際にユーザーが Web サイトにアクセスするときに指定されるものという扱いであり、ビルド時にはクエリパラメーターまで含んだページを出力できないからです。 もっと具体的にいうと、001?sortby=title\u0026amp;order=asc.html のようなクエリまで含んだファイルを事前生成することはできないということです。"
},
{
url: "/p/2hr3eqx/",
title: "TypeScript で JSON オブジェクトに型情報を付加する",
date: "2021-06-26T00:00:00Z",
body: "TypeScript で JSON オブジェクトに型情報を付加する 何が問題か？ JSON テキストファイルの内容を JSON.parse した結果や、fetch API のレスポンスを json() 関数にかけた結果は、型情報のない any 型のオブジェクトになります。 TypeScript コードから、このオブジェクトのプロパティを参照しようとすると、「定義されていないプロパティを参照している」という感じの ESLint エラーになってしまいます。 何より、型情報がないデータをそのまま扱おうとすると、VS Code などでプロパティ名の入力補完機能が働きません。 ここでは、サンプルデータとして次のような JSON 形式の文字列を使うことにします。 const jsonText = `{ \u0026#34;games\u0026#34;: [ { \u0026#34;title\u0026#34;: \u0026#34;Title1\u0026#34;, \u0026#34;genres\u0026#34;: [\u0026#34;ACT\u0026#34;] }, { \u0026#34;title\u0026#34;: \u0026#34;Title2\u0026#34;, \u0026#34;genres\u0026#34;: [\u0026#34;ACT\u0026#34;, \u0026#34;RPG\u0026#34;] }, { \u0026#34;title\u0026#34;: \u0026#34;Title3\u0026#34;, \u0026#34;genres\u0026#34;: [\u0026#34;STG\u0026#34;], \u0026#34;note\u0026#34;: \u0026#34;Fantastic shooting game\u0026#34; } ] } ` この JSON 文字列を JSON.parse 関数でオブジェクトに変換して、そのプロパティを参照しようとすると、ESLint がエラーを出します。 // Unsafe assignment of an `any` value (@typescript-eslint/no-unsafe-assignment) const jsonObj = JSON.parse(jsonText) // Unsafe member access .games on an `any` value (@typescript-eslint/no-unsafe-member-access) console.log(jsonObj.games[0].title) 解決方法 このような any 型オブジェクトを TypeScript コードから扱うには、JSON データに一致する型情報（あるいはそのサブセット）を定義し、型アサーション (as) でその型を指定します。 下記のコードは、完全な型情報が付加された TypeScript コードです。 type Game = { title: string genres: string[] } type GameInfo = { games: Game[] } // JSON.parse() の結果を型アサーションして受け取る const gameInfo = JSON.parse(jsonText) as GameInfo gameInfo.games.forEach((game) =\u0026gt; { console.log(game.title) console.log(game.genres) }) なお、JSON 側での記述をオプショナルにしているプロパティ（上記のサンプルデータでは note プロパティ）を扱いたい場合も、同じように型定義してしまえば OK です。 type Game = { title: string genres: string[] note?: string // note フィールドも参照する場合 } 型定義 (type や interface）は、あくまで TypeScript 側でどのようなプロパティ名での参照を許すかという付加情報であり、JSON テキストに含まれているデータは、メモリ上に全て保持されていることに注意してください。 fetch で Web API を呼び出す場合も同様 ここまでの例では JSON.parse 関数を使っていましたが、fetch 関数で Web API を叩いて JSON データを取得する場合も同様です。 次の例では、GitHub の REST API でユーザー情報を取得しています。 プログラム内で参照するフィールドは、IGitHubUser 型として定義しています。 type IGitHubUser = { name: string login: string location: string } async function showGitHubUser(name: string = \u0026#39;octocat\u0026#39;) { const url = `https://api.github.com/users/${name}` const res: Response = await fetch(url) if (res.ok) { const user = await res.json() as IGitHubUser console.log(user.name) console.log(user.login) console.log(user.location) } else { console.error(\u0026#39;Could not obtain user info\u0026#39;) } }"
},
{
url: "/p/xjv6gqy/",
title: "React の JSX 記述のコツ",
date: "2021-06-17T00:00:00Z",
body: "React の JSX 記述のコツ JSX の最上位要素はひとつ JSX 要素を作成するとき、トップレベルの要素は 1 つだけにする必要があります。 次のコードでは、トップレベルに 2 つの p 要素が並んでいるのでエラーになります。 ダメな例 const MyComponent: React.FC = () =\u0026gt; { return ( \u0026lt;p\u0026gt;Hello\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;World\u0026lt;/p\u0026gt; ) } これを解決するには、例えば次のようにルート要素として div を配置します。 return ( \u0026lt;div\u0026gt; \u0026lt;p\u0026gt;Hello\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;World\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; ) もちろん、これはこれで動作するのですが、ルートに余計な div 要素が作られてしまうのを防ぎたいときは、次のように \u0026lt;\u0026gt;...\u0026lt;/\u0026gt; で囲います（これは \u0026lt;React.Fragment\u0026gt; の省略記法です）。 return ( \u0026lt;\u0026gt; \u0026lt;p\u0026gt;Hello\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;World\u0026lt;/p\u0026gt; \u0026lt;/\u0026gt; ) 条件を満たすときのみ出力する 次のコードは、n \u0026gt; 0 を満たしたときに、後半の p 要素を表示します。 return \u0026lt;\u0026gt; {n \u0026gt; 0 \u0026amp;\u0026amp; \u0026lt;p\u0026gt;条件を満たしたよ\u0026lt;/p\u0026gt;} \u0026lt;/\u0026gt; JSX コードの中では、if や for といった値を返さない文 (statement) を記述することができません。 なので、出力を条件分岐させたいときは、この例のように、\u0026amp;\u0026amp; や || のような演算子を駆使する必要があります。 JSX の {} 内に記述した式の評価結果が undefined、null、true、false のいずれかになった場合、{} 全体は 何も出力しない ことを表します。 true の場合に何も表示されないのは直感的ではないと思うかもしれませんが、画面上に true と表示されても困るし、まぁそんなものだと受け入れるしかないですね。 上記コードの例でいうと、n \u0026gt; 0 の部分が「偽」になった瞬間に {} 全体が false として評価されるため、結果的に何も出力されないということになります。 if-else 出力 ある条件を満たしたときは A、満たさなかったときは B、と表示分けしたいときは、JavaScript の 三項演算子（? と :） を使います。 次のコードは、n が偶数のときに Even、奇数のときに Odd と出力します。 {n % 2 == 0 ? \u0026#39;Even\u0026#39; : \u0026#39;Odd\u0026#39;} オブジェクトのあるプロパティが未設定 (undefined) のときに代替値を表示したいときは、ES2020 の Nullish Coalescing (??) を使うとシンプルに記述できます。 次の例では、movie オブジェクトの genre プロパティが設定されているときはその値を表示し、設定されていないときは 不明 と表示します。 {movie.genre ?? \u0026#39;不明\u0026#39;} 配列要素のループ出力 配列要素を forEach 風に繰り返し出力するには、map メソッドを使用します。 初めて見るとウッとなりますが、React/JSX の世界ではこの書き方は一般教養。 慣れるしかありません。 const foods = [ { id: 1, name: \u0026#39;apples\u0026#39; }, { id: 2, name: \u0026#39;bananas\u0026#39; }, { id: 3, name: \u0026#39;lemons\u0026#39; }, ] const FoodList: React.FC = () =\u0026gt; { return ( \u0026lt;ul\u0026gt; {foods.map((f) =\u0026gt; ( \u0026lt;li key={f.id}\u0026gt;I like {f.name}\u0026lt;/li\u0026gt; ))} \u0026lt;/ul\u0026gt; ) } このように要素を繰り返し出力する場合は、React が効率的な差分出力を行えるように、各要素に一意な key プロパティ値を指定しなければいけないことに注意してください（参考: リストと key）。 これを忘れると、Each child in a list should have a unique \u0026quot;key\u0026quot; prop. といった警告が出ます。 n 回のループ出力 ちょっとハック的ですが、n 回の繰り返しは次のように記述できます。 {[...Array(3)].map((_, i) =\u0026gt; ( \u0026lt;p key={i}\u0026gt;{i}: Hello\u0026lt;/p\u0026gt; ))} [...Array(3)] という部分で、[undefined, undefined, undefined] というサイズ 3 の配列を作っておいて、各要素を map でループ処理してます。 こんな書き方しかできないの？そうですか・・・ コメントを記述する JSX コードの中では、JavaScript と同様のコメント記法が使えます。 \u0026lt;\u0026gt; \u0026lt;div\u0026gt; { // 一行コメント n \u0026gt; 0 \u0026amp;\u0026amp; \u0026lt;p\u0026gt;Hello\u0026lt;/p\u0026gt; } \u0026lt;/div\u0026gt; \u0026lt;div\u0026gt; {/* 複数行にわたるコメントは、 こんな感じで記述できます。 */} \u0026lt;/div\u0026gt; \u0026lt;/\u0026gt; ユーザーコンポーネント名は大文字で始める JSX コード内で使うユーザー定義コンポーネントの名前は、大文字で始めなければいけません。 小文字で始まる名前 (p や div）は、組み込みのコンポーネントとして予約されているので使えません。 なお、JSX 組み込みのコンポーネントは JSX.IntrinsicElements として定義されており、200 近くのコンポーネントが定義されています。"
},
{
url: "/p/5oyaju5/",
title: "TypeScript で undefined/null をうまく扱う (nullish coalescing (??), optional chaining (?.))",
date: "2021-06-17T00:00:00Z",
body: "TypeScript で undefined/null をうまく扱う (nullish coalescing (??), optional chaining (?.)) Null 合体演算子 (??) ES2020 で Null 合体演算子 (Nullish Coalescing Operator) の ?? が導入されました。 ☝️ nullish とは？ JavaScript において nullish とは、「undefined あるいは null」を示します。 coalescing には、「癒合、合体」という意味があります。 よって、nullish coalescing は、「null っぽかったら合体させるよ」という意味になります。 ?? 演算子を使うと、ある変数の値が undefined（あるいは null）だったときの代替となる値を指定することができます。 つまり、 A ?? B は、次のように記述するのと同等です。 A != undefined ? A : B 下記は、?? 演算子の振る舞いの一覧です。 ?? 演算子はあくまで undefined と null だけを判別するものであって、左側に偽となる値（false や空文字）をおいた場合は、その値がそのまま使われることに注意してください。 // 右側の値が（代わりに）使われるパターン const a = undefined ?? \u0026#39;default\u0026#39; //=\u0026gt; \u0026#39;default\u0026#39; const b = null ?? \u0026#39;default\u0026#39; //=\u0026gt; \u0026#39;default\u0026#39; // 左側の値が（そのまま）使われるパターン const c = \u0026#39;\u0026#39; ?? \u0026#39;default\u0026#39; //=\u0026gt; \u0026#39;\u0026#39; const d = \u0026#39;aaa\u0026#39; ?? \u0026#39;default\u0026#39; //=\u0026gt; \u0026#39;aaa\u0026#39; const e = 1 ?? 100 //=\u0026gt; 1 const f = 0 ?? 200 //=\u0026gt; 0 const g = true ?? \u0026#39;default\u0026#39; //=\u0026gt; true const h = false ?? \u0026#39;default\u0026#39; //=\u0026gt; false const i = [] ?? [1, 2, 3] //=\u0026gt; [] Nullish Coaescing Operator は、省略可能なプロパティを持つオブジェクトを参照するときに便利です。 次の dumpPoint 関数は、渡された Enemy オブジェクトの point プロパティの値をしますが、この値が未設定の場合はデフォルト値の 100 を表示します。 type Enemy = { name: string point?: number // このプロパティ値は省略可能 } function dumpPoint(enemy: Enemy) { console.log(enemy.point ?? 100) } dumpPoint({ name: \u0026#39;Enemy1\u0026#39;, point: 0 }) //=\u0026gt; 0 dumpPoint({ name: \u0026#39;Enemy2\u0026#39;, point: 50 }) //=\u0026gt; 50 dumpPoint({ name: \u0026#39;Enemy3\u0026#39; }) //=\u0026gt; 100 従来はこのような処理のために短絡演算子 (||) がよく使われていましたが、下記のように偽値となる値（0 や false）がうまく扱えないという問題がありました。 今後は、?? を使えば OK です。 よくない例 console.log(enemy.point || 100) // point=0 の時に 100 になってしまう デフォルト値に関しては、次のように分割代入時に設定する方法も健在です。 用途によって使い分けましょう。 function dumpPoint(enemy: Enemy) { const { name, point = 100 } = enemy console.log(name) console.log(point) } オプショナルチェイニング演算子 (?:) ES2020 では、オプショナルチェイニング演算子 (Optional Chaining Operator) の ?. も導入されています。 これは、undefined（あるいは null）であるかもしれないオブジェクトのプロパティを参照するときに使用します。 A?.foo() とすると、オブジェクト A が undefined（あるいは null）の場合に undefined になり、それ以外の場合に A のプロパティ foo が参照されます。 つまり、上記は下記と同様です。 A != undefined ? A.foo() : undefined 下記は Optional Chaining の具体的な使用例です。 User オブジェクトは入れ子の形で Address オブジェクトを保持することができますが、そのための address プロパティは省略可能なものとして定義されています。 このように、入れ子になったオブジェクトのプロパティを参照するケースで、Optional Chaining は威力を発揮します。 type Address = { country: string city: string } type User = { name: string address?: Address } function dumpCity(user: User) { // ここでオプショナルチェイニングを使用 (｀•ω•´) const city = user.address?.city ?? \u0026#39;UNKNOWN_CITY\u0026#39; console.log(city) } dumpCity({ name: \u0026#39;User1\u0026#39;, address: { country: \u0026#39;Japan\u0026#39;, city: \u0026#39;Tokyo\u0026#39; } }) dumpCity({ name: \u0026#39;User2\u0026#39; }) 実行結果 Tokyo UNKNOWN_CITY ポイントは次の部分で、Optional Chaining (?.) と、前述の Nullish Coalescing (??) を組み合わせて使っています。 const city = user.address?.city ?? \u0026#39;UNKNOWN_CITY\u0026#39; user.address に Address オブジェクトが設定されている場合は city プロパティを参照し、user.address が設定されていない場合（undefined のとき）は、代わりに UNKNOWN_CITY という値を使うようにしています。 単純に user.address.city と繋げて書くと、user.address が undefined のときに不正な参照になってしまいます。 このイディオムは、オブジェクトの入れ子構造がもっと深い場合でもうまく機能します。 // いずれかのプロパティが undefined になった時点で NO_NAME になる const name = obj.aaa?.bbb?.ccc?.name ?? \u0026#39;NO_NAME\u0026#39; また、ある関数型プロパティが設定されている場合だけ呼び出したいときは次のように記述できます。 // fix プロパティに関数がセットされている場合のみ呼び出す sentence.fix?.()"
},
{
url: "/p/8cygv9k/",
title: "Amazon S3: 未整理・雑多メモ",
date: "2021-06-16T00:00:00Z",
body: "Amazon S3: 未整理・雑多メモ S3 のストレージクラスの例 汎用ストレージ \u0026hellip; S3 STANDARD アクセス頻度小 \u0026hellip; S3 STANDARD_IA 長期アーカイブ \u0026hellip; S3 Glacier S3 のバケットポリシーでは、プレフィックスとか拡張子などを指定してアクセスコントロールが可能。 S3 へのアクセスは ACL（アクセスコントロールリスト）でもコントロールできるが、古い仕組みなので非推奨。今は IAM を使う。 S3 のバージョニング設定を有効にすると、オブジェクトの複数バージョンを管理できるようになる。 S3 のバケット名は世界で一意になるように命名する。 3～63 文字で、大文字は使えない。 先頭文字は小文字の英数字。 _ 2文字目以降は、小文字の英数字、ハイフン、ドットのいずれかで構成する。ただし、ドットは通常は使わない方がよい（ドメインの区切り文字と混ざるので、HTTPS の証明書検証などに影響が出る）。"
},
{
url: "/p/38bpqjp/",
title: "DynamoDB の未整理・雑多メモ",
date: "2021-06-16T00:00:00Z",
body: "DynamoDB の未整理・雑多メモ DynamoDB のテーブルは リージョンごとに独立 して存在する。例えば、us-east-2 リージョンの People テーブルと、us-west-2 リージョンの People テーブルは別物として扱われる。 DyanmoDB のテーブル名、属性名は CamelCase にするのが公式っぽい（-、_、. といった記号も使える） プライマリキー DynamoDB の プライマリキーの型 は、文字列／数値／バイナリ、といったスカラ値のみが使える。 DynamoDB のプライマリキーは 1 つ or 2 つ 1 つの場合 \u0026hellip; パーティションキーのみ（一意な ID） 2 つの場合 \u0026hellip; パーティションキー + ソートキー（パーティションが同じであれば、同じ物理ストレージ内にソートキー値でソートされた形で項目が保持される） DynamoDB のテーブルは、プライマリキーとなる属性以外はスキーマレスなので、テーブル作成時はプライマリーキー属性のみ定義すればよい。それ以外の部分には入れ子構造のデータも自由に入れられる。 DynamoDB に項目を追加するときに バイナリ型属性 の値を渡すときは、Base64 エンコードして渡す必要がある。 RCU の消費 基本的にクエリ (Query) は合計サイズ 4KB ごとに 1RCU 消費する。 GetItem の場合は、1 件ごとに 1RCU 消費する。 100 件以上とか大量に PutItem するときは、BatchWrite の仕組みを使うとめっちゃ速くなる。複数の要求をバッファリングして通信回数を減らしてくれるぽい。具体的な使い方は、各 SDK の API ドキュメントを参照。"
},
{
url: "/p/rcoz9o9/",
title: "Azure リソースのプレフィックス名（省略名）",
date: "2021-06-12T00:00:00Z",
body: "Azure リソースのプレフィックス名（省略名） Azure で何らかのリソースを作成するときは、リソース名のプレフィックス として、リソースの種類に応じた略称（cosmos- など）をつけることが多いのですが、この略称の指針が Microsoft Docs のサイトに書かれています。 リソース名をどうするかは意外と迷うところなので、こういった情報は地味に助かります。 Azure リソースの種類に推奨される省略形 - Cloud Adoption Framework | Microsoft Docs 例えば次のような感じで定義されています。 リソースの種類 プレフィックス リソースグループ rg- Cosmos DB アカウント cosmos- ストレージアカウント st- 静的 Web アプリ stapp- 関数アプリ func- また、リソース名全体の構成も次のような例で示されています。 図: Azure リソース名の構成（Microsoft Docs より） この辺りは開発チームによってルールが決められているかもしれませんが、まずはこの構成で間に合うか考えてみるとよいと思います。"
},
{
url: "/p/xjwakv8/",
title: "Azure Cosmos DB 関連記事",
date: "2021-06-12T00:00:00Z",
body: "Azure Cosmos DB 関連記事"
},
{
url: "/p/dt3ahpw/",
title: "MongoDB for VS Code で Azure Cosmos DB を操作する",
date: "2021-06-12T00:00:00Z",
body: "MongoDB for VS Code で Azure Cosmos DB を操作する Cosmos DB インスタンスを MongoDB API アクセス用に作成 しておくと、さまざまな MongoDB 用のツールでデータベースにアクセスできるようになります。 ここでは、VS Code 用の拡張「MongoDB for VS Code」を使って、Cosmos DB を操作できるようにしてみます。 TypeScript を使って Web アプリを作成しているときは、エディタとして VS Code を使っていることが多いでしょうから、同じ環境上で Cosmos DB を操作できると開発が捗ります。 MongoDB for VS Code のインストール 図: MongoDB for VS Code のインストール MongoDB for VS Code は、VS Code の Extesions バー (Cmd/Ctrl + Shift + X) で MongoDB で検索すれば簡単にインストールできます。 VS Code から Cosmos DB (MongoDB) に接続する 接続文字列で簡単接続 MongoDB for VS Code をインストールすると、サイドバーに 葉っぱのアイコン が出てくるので、ここから MongoDB サーバーに接続することができます。 ちなみに、MongoDB が葉っぱアイコンを使うのは、それを使うことが「シンプルで自然であるから」らしいです（じゃあ水でもいいじゃん、とは言いますまい）。 図: MongoDB サーバーへ接続する Connext ボタンを押して、mongodb:// で始まる接続文字列を指定するだけで簡単に MongoDB サーバーへ接続できます（接続文字列は Azure Portal の Cosmos DB リソースのページで確認してください）。 Playgrounds 機能でスクリプト実行 接続に完了すると、Playgrounds 機能でデータベースを操作できるようになります。 これは次のような .mongodb 拡張子を持つファイルのエディタ機能で、右上の実行ボタンを押すと、接続先の MongoDB データベース（今回の例では Cosmos DB データベース）を操作できます。 図: Playgrounds 機能 MongoDB for VS Code がインストール済みの環境であれば、以降はこの .mongodb ファイルを開くだけで Playgrounds 機能が起動します。 このファイルをプロジェクトのリポジトリにコミットしておけば、データベース操作のサンプルコードとして使用できます。"
},
{
url: "/p/f4ugxri/",
title: "Android Studio の IdeaVim プラグインで快適コーディング",
date: "2021-06-08T00:00:00Z",
body: "Android Studio の IdeaVim プラグインで快適コーディング IdeaVim プラグインのインストール Android Studio (IntelliJ IDEA) に IdeaVim プラグインを入れると、Vim 系のキーマッピングが有効になり、高速にコーディングできるようになります（もちろん Vim の操作に精通しておく必要がありますが）。 IdeaVim プラグインは Android Studio から下記のように辿って簡単にインストールできます。 File → Settings → Plugins IdeaVim で検索してインストール IdeaVim の設定 (.ideavimrc) 通常の Vim エディタの設定ファイルは ~/.vimrm ですが、IdeaVim の設定ファイルは ~/.ideavimrc です。 Windows の場合は、%USERPROFILE%\\.ideavimrc です（or _ideavimrc）。 ~/.ideavimrc set clipboard=unnamed nnoremap gd :action GotoDeclaration\u0026lt;CR\u0026gt; nnoremap gi :action GotoImplementation\u0026lt;CR\u0026gt; nnoremap gs :action GotoSuperMethod\u0026lt;CR\u0026gt; nnoremap gb :action Back\u0026lt;CR\u0026gt; nnoremap gf :action Forward\u0026lt;CR\u0026gt; nnoremap \u0026lt;C-Left\u0026gt; :action Back\u0026lt;CR\u0026gt; nnoremap \u0026lt;C-Right\u0026gt; :action Forward\u0026lt;CR\u0026gt; .ideavimrc ファイルを変更したときは、次のようにして反映できます。 :source ~/.ideavimrc OS のクリップボードと連携 set clipboard=unnamed x キーによる切り取りや、yy での行ヤンク（コピー）されたレジスタ内容を、Windows などの OS クリップボードと連携させることができます。 キーマッピング nnoremap gd :action GotoDeclaration\u0026lt;CR\u0026gt; nnoremap gi :action GotoImplementation\u0026lt;CR\u0026gt; nnoremap gs :action GotoSuperMethod\u0026lt;CR\u0026gt; nnoremap gb :action Back\u0026lt;CR\u0026gt; nnoremap gf :action Forward\u0026lt;CR\u0026gt; nnoremap \u0026lt;C-Left\u0026gt; :action Back\u0026lt;CR\u0026gt; nnoremap \u0026lt;C-Right\u0026gt; :action Forward\u0026lt;CR\u0026gt; IdeaVim も Vim と同様に map、noremap 系コマンドでキーマップを定義することができます。 参考: キーマップの基本 (map, noremap) | まくまくVimノート このとき、:action コマンドを組み合わせて使うと、Android Studio (IntelliJ IDEA) 特有の機能を呼び出すことができます。 例えば、:action Back で「戻る (Navigate Back)」操作を行うことができるし、:action GotoDeclaration で「定義位置、参照箇所へのジャンプ」を行えます。 参考: IdeaVim - Executing actions どんなコマンドがあるか？ IdeaVim の :action XXX で実行できるコマンドにどのようなものがあるかは、:actionlist コマンドで検索することができます。 :actionlist \u0026lt;キーワード\u0026gt; 例えば、:actionlist Goto と実行すると、GotoDeclaration や GotoImplementation といったコマンドがあることが分かります。"
},
{
url: "/p/syy4ryp/",
title: "設定",
date: "2021-06-08T00:00:00Z",
body: "設定"
},
{
url: "/p/dxhs2bk/",
title: "AWS AppSync 関連記事",
date: "2021-06-06T00:00:00Z",
body: "AWS AppSync 関連記事"
},
{
url: "/p/cexcpyc/",
title: "AWS AppSync のポリシーステートメントの記述例",
date: "2021-06-06T00:00:00Z",
body: "AWS AppSync のポリシーステートメントの記述例 参考: Lambda / SSM 特定アカウントからのアクセスのみ許可する アカウント 123456789012 からのアクセスのみ許可 { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;appsync.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;sts:AssumeRole\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;aws:SourceAccount\u0026#34;: \u0026#34;123456789012\u0026#34; } } } ] } 特定の API へのアクセスのみ許可する abcdefg API のみ許可 { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;appsync.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;sts:AssumeRole\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;ArnEquals\u0026#34;: { \u0026#34;aws:SourceArn\u0026#34;: \u0026#34;arn:aws:appsync:us-west-2:123456789012:apis/abcdefg\u0026#34; } } } ] } 特定 のリージョンからのアクセスのみ許可する us-east-1 のみ許可 { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;appsync.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;sts:AssumeRole\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;ArnEquals\u0026#34;: { \u0026#34;aws:SourceArn\u0026#34;: \u0026#34;arn:aws:appsync:us-east-1:123456789012:apis/*\u0026#34; } } } ] }"
},
{
url: "/p/yn7hqx8/",
title: "AWS Lambda のポリシーステートメントの記述例",
date: "2021-06-06T00:00:00Z",
body: "AWS Lambda のポリシーステートメントの記述例 参考: AppSync / SSM Lambda 関数の呼び出しを許可する { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;lambda:invokeFunction\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:lambda:us-west-2:123456789012:function:my-function\u0026#34;, \u0026#34;arn:aws:lambda:us-west-2:123456789012:function:my-function:*\u0026#34; ] } ] }"
},
{
url: "/p/somcgdw/",
title: "macOS 関連メモ",
date: "2021-05-30T00:00:00Z",
body: "macOS 関連メモ"
},
{
url: "/p/ygpw6dk/",
title: "macOS で不要なファイルを削除してストレージ容量を確保する",
date: "2021-05-30T00:00:00Z",
body: "macOS で不要なファイルを削除してストレージ容量を確保する macOS のストレージ容量が足りなくなってきたときのために、各種キャッシュの削除方法などをまとめておきます。 Homebrew (brew) 関連 古いバージョンの削除 brew コマンドでいろいろコマンドをインストールしていると、古いバージョンのモジュールが /usr/local/Cellar ディレクトリの中にどんどん増えていきます。 brea cleanup コマンドで、古いモジュールを削除できます。 # ドライラン（何が削除されて、何MBくらい減らせるか確認） $ brew cleanup -n # 実際に削除 $ brew cleanup 各モジュールでどのようなバージョンがインストールされているかは、次のように確認することができます。 $ brea ls-versions ... libxext 1.3.4 libxrender 0.9.10 libyaml 0.1.6_1 0.2.5 0.1.7 ... ダウンロードキャッシュの削除 Homebrew のダウンロードキャッシュが格納されているディレクトリは次のコマンドで確認できます。 $ brew --cache /Users/maku/Library/Caches/Homebrew 次のようにしてキャッシュディレクトリごとまとめて削除できます。 $ rm -rf `brew --cache` ライブラリフォルダ内のキャッシュを削除 $ rm -rf ~/Library/Caches/* Ruby 関連 gem # インストールされている Gem のバージョン一覧 $ gem list # 古いバージョンの削除（ドライラン） $ gem cleanup --dryrun # 古いバージョンの削除（実行） $ gem cleanup"
},
{
url: "/p/j5gr3dn/",
title: "macOS のスポットライトのインデックス処理を停止・開始する",
date: "2021-05-30T00:00:00Z",
body: "macOS のスポットライトのインデックス処理を停止・開始する macOS の mdutil コマンドを使用すると、スポットライトのインデックス設定を変更することができます。 インデックス処理の現在の設定を調べる $ sudo mdutil -a -s /: Indexing enabled. /System/Volumes/Data: Indexing enabled. /Volumes/SD_card: Indexing and searching disabled. インデックス処理を無効化する $ sudo mdutil -a -i off インデックス処理を有効化する $ sudo mdutil -a -i on インデックスを削除して再生成 $ sudo mdutil -a -E"
},
{
url: "/p/au8iu6u/",
title: "TypeScript コードを Prettier で自動整形する",
date: "2021-05-26T00:00:00Z",
body: "TypeScript コードを Prettier で自動整形する Prettier とは？ Prettier は、TypeScript や JavaScript などのソースコードを自動フォーマットするためのツールです。 HTML や CSS など様々なファイルに対応していますが、主に TypeScript や JavaScript のフォーマッターとして使用されています。 実際にどのようにフォーマットされるかは、Playground のページ で試すことができます。 特徴と思想 Prettier の一番の特徴は、Opinionated（独断的な） コードフォーマッターであることを標榜していることです。 これは、ユーザーに自由なカスタマイズを許さず、「Prettier 自身が定義しているスタイルに強制的にフォーマットするよ」ということです（セミコロンの有無など最低限の設定はできます）。 これにより、コーディングスタイルに関する 不毛な議論を避ける ことができ、プロジェクト内のコーディングスタイルを簡単に統一することができます。 もちろん、自分がベストだと思っているスタイルでフォーマットすることはできなくなるかもしれませんが、そんな些細なことよりも、アプリケーション（成果物）を作り上げることに集中すべきだという考え方です。 Prettier がやらないこと Prettier はあくまでコードのフォーマットのみを行います。 コードの意味を解析して危険な部分（潜在的バグ）を検出してくれたりはしないので、そういったことを行いたい場合は、他の静的解析ツール（ESLint など）を使う必要があります。 ESLint にもコードフォーマット機能がありますが、フォーマッターとしては Prettier が優れており、「Prettier による整形 ＋ ESLint による静的解析」という形で組み合わせて使うのが一般的です。 あと、import 文のソートなど、一見やってくれてもよさそうなフォーマットもしてくれなかったりします。 これは、その import 順序がロジック的に意味を持っていたりする場合に、Prettier が判断できないからです。 このように、いろいろと想像と異なるフォーマット結果になることがありますが、そこにはちゃんと理由があります（参考: Rationale）。 あまり気にせずにそんなものだと考えるのがよいです。 ちなみに、ESLint の方には import 文のソートを行うプラグイン (eslint-plugin-import) があります。 Prettier をインストールする Prettier は npm で簡単にインストールすることができます。 TypeScript のプロジェクトは作成済み で、package.json がすでに存在すると想定します。 ### yarn の場合 $ yarn add prettier --dev --exact ### npm の場合 $ npm install prettier --save-dev --save-exact Prettier は、パッチバージョンが上がるだけで、出力結果に微妙な差分が生まれる可能性があります。 そのため、インストール時のオプションとして --save-exact を指定することで、明確なバージョンを package.json の依存情報として保存することが推奨されています。 これにより、チームメンバー全員のフォーマット結果を確実に一致させることができます。 package.json（抜粋） \u0026#34;devDependencies\u0026#34;: { \u0026#34;prettier\u0026#34;: \u0026#34;^2.3.0\u0026#34; // こうではなく、 \u0026#34;prettier\u0026#34;: \u0026#34;2.3.0\u0026#34; // こう書き込まれます。 } あと、他のツール（VS Code など）に、このプロジェクトが Prettier を使用していることを知らせるために、設定ファイル（.prettierrc.json や .prettierrc.yml）を作成しておきます。 拡張子を省略して .prettierrc というファイル名にすると、JSON 形式と YAML 形式のどちらでも記述できますが、エディタの補完機能などを有効にするために、.prettierrc.yml のように拡張子は明示しておいた方がよいでしょう。 特別な設定をしないのであれば、設定内容は空っぽで構いません（JSON 形式であれば {}、YAML 形式であれば本当に何も書かないでで OK）。 .prettierrc（JSON形式）の作成 $ echo {}\u0026gt; .prettierrc 行末セミコロンの省略や、引用符をシングルクォートにする、といった設定はしたいかもしれません。 カスタマイズに関しては後述しますが、こんな感じで設定できます（コメントを入れるために YAML 形式で記述しています）。 .prettierrc.yml（YAML形式） semi:false# 行末のセミコロンは省略するsingleQuote:true# 引用符にはシングルクォートを使う 次に、Prettier に無視させたいファイル群を .prettierignore ファイルで指定しておきます。 フォーマットは、.gitignore と同様です。 Markdown ファイル (md) なども自動整形したいところですけど、Prettier は日本語の処理が弱いようなので無視無視。 .prettierignore .next/ build/ *.html *.md 正しく .prettierignore ファイルを記述できていれば、prettier --write . コマンド（後述）で、プロジェクト内のファイルをすべて整形できます。 作成した .prettierrc と .prettierignore は、忘れずに Git リポジトリにコミットしてください。 Prettier を実行する prettier コマンドの使い方 prettier コマンドにソースコードを食わせると、Perttier のスタイルに従ってフォーマットし直した結果を標準出力に出力してくれます。 $ npx prettier main.ts -w (--write) オプションを付けて実行すると、フォーマット結果をそのファイルに書き戻します。 ディレクトリ名や グロブパターン で複数ファイルをまとめて処理できます。 # カレントディレクトリ以下のファイルを整形 $ npx prettier --write . # src ディレクトリ以下のファイルを整形 $ npx prettier --write src # src ディレクトリ以下の .ts、.tsx ファイルを整形 $ npx prettier --write src/**/*.{ts,tsx} カレントディレクトリ以下のファイルをまとめて整形する場合は、先にどのファイルが整形対象になっているかを調べておくと安心です。 -l (--list-different) オプション、あるいは -c (--check) オプションを付けて実行すると、Prettier のフォーマットに従っていないファイルを一覧表示できます。 # カレントディレクトリ以下のファイルで整形対象になるものを確認 $ npx prettier -l . npm スクリプト化 毎回 npx prettier ... と入力するのは面倒なので、npm スクリプト化しておきます。 package.json（抜粋） { // ... \u0026#34;scripts\u0026#34;: { \u0026#34;lint:prettier\u0026#34;: \u0026#34;prettier --check src\u0026#34;, \u0026#34;fix:prettier\u0026#34;: \u0026#34;prettier --write src\u0026#34;, // ... これで、次のように簡単に Prettier によるフォーマットをかけられるようになります。 $ npm run lint:prettier # 違反のチェックだけしたいとき $ npm run fix:prettier # 自動で fix 実行 npm スクリプト名は lint、fix のようなシンプルな名前にしてもよいのですが、ここでは ESLint も導入することを考えて、詳細な名前を付けるようにしています（ESLint 側のスクリプトには lint:eslint、fix:eslint という名前を付ける想定）。 参考リンク TypeScript プロジェクトに ESLint を導入する ESLint + Prettier の設定方法まとめ Prettier と一緒に ESLint を使う場合 プロジェクトに ESLint を導入 している場合、Prettier によるフォーマットと ESLint による解析ルールが競合するので、その部分を無効にしておく必要があります。 これを簡単に行ってくれるのが、eslint-config-prettier パッケージ（ESLint プラグイン）です。 このパッケージは Prettier チームが正式に提供している ものなので、誰かが適当に作ったパッケージではなく、これを使うことをお勧めします。 ### yarn の場合 $ yarn add eslint-config-prettier --dev ### npm の場合 $ npm install eslint-config-prettier --save-dev あとは、ESLint の設定ファイルの extends プロパティの最後に prettier というコンフィグを追加するだけで OK です。 .eslintrc.yml（抜粋） extends:- eslint:recommended- plugin:react/recommended- plugin:react-hooks/recommended- plugin:@typescript-eslint/recommended- plugin:@typescript-eslint/recommended-requiring-type-checking- prettier ☝️ ワンポイント 古い情報では、prettier/react コンフィグも必要と記載されてものがありますが、現在のバージョン（v8.x.x 以降）では prettier の指定だけで大丈夫です。 Prettier のカスタマイズ Prettier のフォーマット方法は、.prettier.{json,yml,js} ファイルである程度カスタマイズできますが、Prettier はフォーマット関連のオプションをほとんど用意しておらず、可能な限りデフォルト設定のまま使うべきとされています。 なぜなら、スタイル設定による不毛な議論を防ぐことを一番の目的としているからです（参考: Prettier のオプションに対する思想）。 過去の経緯で追加されてしまったオプションは、今さら消すことができないという理由で残っているものがあり、これらも通常使うべきではありません。 使わない方がよいオプションの例 arrowParens jsxSingleQuote jsxBracketSameLine noBracketSpacing そして、Prettier のデフォルトスタイルは十分に成熟したとし、今後はフォーマット関連のオプションは追加しない としています。 そんな中でもいくつかのオプションは使われることがあるので、下記にいくつか紹介しておきます。 printWidth (default: 80) 一行あたりの文字数がどれくらいであるべきかを指定します。ESLint の max-len（最大文字数）とは若干概念が異なり、実際にはこの値よりも長い行が出力されることはあります。各種フォーマッターで、最大文字数の設定を 100 や 120 にしているプロジェクトは多くありますが、Prettier は printWidth はあくまでデフォルトの 80 を使うことを推奨しています。80 文字を超える文字列リテラルや、深いネストによって 80 文字を超える場合は、Prettier はそのまま出力します。 semi (default: true) 行末のセミコロンの有無を指定します。デフォルトではセミコロンが付加されますが、JavaScript Standard Style ではセミコロンを省略する提案がされていますし、Next.js の create-next-app コマンドで出力される雛形コードもセミコロンなしのコードになっていたりします。将来的にセミコロンなしが主流になる可能性は十分にあります。 singleQuote (default: false) 文字列リテラルはデフォルトでダブルクォートで囲まれます。シングルクォートで囲みたいときは singleQuote オプションを true に設定します。多くのスタイルではシングルクォートが優先されているので、この設定だけは true にして使う人が多いかもしれません。ちなみに、この設定を true にしても、JSX コード内の文字列リテラルはダブルクォートで囲まれます（jsxSingleQuote という別オプションになっています）。 tralingComma (default: \u0026ldquo;es5\u0026rdquo;) デフォルトでは、配列などの末尾要素の後にカンマ (,) を付加されます。\u0026quot;none\u0026quot; にするとカンマが付かなくなります。 .prettierrc の記述例（YAML形式） printWidth: 100 semi: false singleQuote: true trailingComma: none Prettier フォーマットを無効にするコメント ソースコードの中で、部分的に Prettier フォーマットを無効にしたいときは、対象オブジェクトの前に prettier-ignore コメントを入れます。 // prettier-ignore matrix( 1, 0, 0, 0, 1, 0, 0, 0, 1 ) 参考 ESLint の設定方法のまとめと注意点 VS Code のフォーマッターで自動整形する (formatOnSave)"
},
{
url: "/p/k8mxakw/",
title: "Next.js で Bootstrap と React Bootstrap を使う",
date: "2021-05-10T00:00:00Z",
body: "Next.js で Bootstrap と React Bootstrap を使う 何をするか？ Next.js アプリから、CSS フレームワークの Bootstrap を使えるようにする方法を説明します。 Bootstrap を導入 各コンポーネントの実装で、Bootstrap の CSS クラスを参照できるようにします React Bootstrap を導入 Bootstrap を React コンポーネントの形で使えるようにします Bootstrap を導入する bootstrap モジュールをインストールする方法 Bootstrap は npm install で簡単にインストールできます。 $ npm install bootstrap@next --save あとは、次のような pages/_app.tsx ファイルを作成して、グローバル CSS としてインポートすれば OK です。 pages/_app.tsx import type { AppProps } from \u0026#39;next/app\u0026#39; import \u0026#39;bootstrap/dist/css/bootstrap.min.css\u0026#39; export default function MyApp({ Component, pageProps }: AppProps) { return \u0026lt;Component {...pageProps} /\u0026gt; } これで、各ページコンポーネントから Bootstrap の CSS クラスを参照できるようになります。 CDN 上のファイルを参照する方法 CDN 上で公開されている Bootstrap ファイルを参照することもできます。 pages/_app.tsx ファイルを作成して、次のように Bootstrap の CSS ファイルを読み込みます。 これで、各ページの head 要素内に link 要素が追加されます。 pages/_app.tsx import type { AppProps } from \u0026#39;next/app\u0026#39; import Head from \u0026#39;next/head\u0026#39; export default function MyApp({ Component, pageProps }: AppProps) { return \u0026lt;\u0026gt; \u0026lt;Head\u0026gt; \u0026lt;!-- Bootstrap CSS --\u0026gt; \u0026lt;link href=\u0026#34;https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta1/dist/css/bootstrap.min.css\u0026#34; rel=\u0026#34;stylesheet\u0026#34; integrity=\u0026#34;sha384-giJF6kkoqNQ00vy+HMDP7azOuL0xtbfIcaT9wjKHr8RbDVddVHyTfAAsrekwKmP1\u0026#34; crossOrigin=\u0026#34;anonymous\u0026#34;\u0026gt; \u0026lt;/link\u0026gt; \u0026lt;/Head\u0026gt; \u0026lt;Component {...pageProps} /\u0026gt; \u0026lt;/\u0026gt; } 最新の CDN アドレスは、Bootstrap のサイト で確認してください。 一点注意なのは、JSX では crossorigin 属性は crossOrigin のように O を大文字にしないといけないというところです。 Bootstrap の高度なコンポーネントを使うときは、JavaScript ファイルも必要なことがあります。 その場合は、Component 要素の後ろあたりに script 要素を追加すれば OK です。 動作確認 適当なページコンポーネントで、Bootstrap の CSS クラスを参照できれば成功です。 例えば、以下のように btn クラスを適用したボタン を表示すれば、うまく適用できているか分かります。 pages/index.tsx const Home: React.FC = () =\u0026gt; { return \u0026lt;\u0026gt; \u0026lt;button type=\u0026#34;button\u0026#34; className=\u0026#34;btn btn-primary\u0026#34;\u0026gt;Primary\u0026lt;/button\u0026gt;{\u0026#39; \u0026#39;} \u0026lt;button type=\u0026#34;button\u0026#34; className=\u0026#34;btn btn-secondary\u0026#34;\u0026gt;Secondary\u0026lt;/button\u0026gt;{\u0026#39; \u0026#39;} \u0026lt;button type=\u0026#34;button\u0026#34; className=\u0026#34;btn btn-danger\u0026#34;\u0026gt;Danger\u0026lt;/button\u0026gt; \u0026lt;/\u0026gt; } export default Home React Bootstrap を導入する react-bootstrap のインストール React Bootstrap を導入すると、Bootstrap の CSS が適用された React コンポーネントを使えるようになります。 Bootstrap 本体の方は、前述の方法で導入しておく必要があります。 React Bootstrap のインストール $ npm install react-bootstrap --save 動作確認 次の例では、React Bootstrap の Button コンポーネント を使用しています。 Bootstrap の CSS クラスをそのまま使うよりは、若干シンプルに記述できるようになっています。 pages/index.tsx import Button from \u0026#39;react-bootstrap/Button\u0026#39;; const Home: React.FC = () =\u0026gt; { return \u0026lt;\u0026gt; \u0026lt;Button variant=\u0026#34;primary\u0026#34;\u0026gt;Primary\u0026lt;/Button\u0026gt;{\u0026#39; \u0026#39;} \u0026lt;Button variant=\u0026#34;secondary\u0026#34;\u0026gt;Secondary\u0026lt;/Button\u0026gt;{\u0026#39; \u0026#39;} \u0026lt;Button variant=\u0026#34;danger\u0026#34;\u0026gt;Danger\u0026lt;/Button\u0026gt; \u0026lt;/\u0026gt; } export default Home"
},
{
url: "/p/iz8fnu3/",
title: "Next.js でサーバーサイドで JSON や YAML ファイルを読み込む (fs.readFileSync)",
date: "2021-05-09T00:00:00Z",
body: "Next.js でサーバーサイドで JSON や YAML ファイルを読み込む (fs.readFileSync) 何をするか？ Next.js アプリのページコンポーネントの getStaticProps / getServerSideProps 関数や、API ルート (pages/api/*.ts) の handler 関数は、クライアントからのアクセス時やビルド時に、サーバーサイドで呼び出されます。 つまり、これらの関数の中では、Node.js の fs モジュールを使った（サーバー上の）ローカルファイルの読み込みが可能です。 ここでは、例として、 ページコンポーネントの getStaticProps 関数から JSON ファイルを読み込む方法 API ルートの handler 関数から YAML ファイルを読み込む方法 を紹介します。 JSON ファイルを読み込む（in getStaticProps 関数） 使用する JSON ファイル サンプルデータとして次のような JSON ファイルをプロジェクト内に配置します。 src/data/games.json [ { \u0026#34;id\u0026#34;: \u0026#34;dq1\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;ドラゴンクエスト\u0026#34; }, { \u0026#34;id\u0026#34;: \u0026#34;dq2\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;ドラゴンクエスト2\u0026#34; }, { \u0026#34;id\u0026#34;: \u0026#34;dq3\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;ドラゴンクエスト3\u0026#34; } ] JSON ファイルを読み込む 次のコードでは、getStaticProps 関数の中で src/data/games.json ファイルを読み込んで、ページコンポーネントに渡す props データを作成しています。 src/pages/games.tsx import * as fs from \u0026#39;fs\u0026#39; import * as path from \u0026#39;path\u0026#39; types Game = { id: string, title: string } types PageProps = { games: Game[] } export const getStaticProps: GetStaticProps\u0026lt;PageProps\u0026gt; = async (context) =\u0026gt; { // JSON ファイルを読み込む const jsonPath = path.join(process.cwd(), \u0026#39;src\u0026#39;, \u0026#39;data\u0026#39;, \u0026#39;games.json\u0026#39;) const jsonText = fs.readFileSync(jsonPath, \u0026#39;utf-8\u0026#39;) const games = JSON.parse(jsonText) as Game[] // ページコンポーネントに渡す props オブジェクトを設定する return { props: { games } } } const GamesPage: React.FC\u0026lt;PageProps\u0026gt; = ({ games }: PageProps) =\u0026gt; { // ... } JSON 形式のテキストは、JavaScript 標準の JSON.parse 関数でオブジェクトに変換することができるので、プログラム内での扱いはお手軽です。 ポイントは、JSON ファイルの絶対パスを構築している部分です。 const jsonPath = path.join(process.cwd(), \u0026#39;src\u0026#39;, \u0026#39;data\u0026#39;, \u0026#39;games.json\u0026#39;) 一般的な Node.js プログラムで相対パスを扱うときは __dirname を使用することがあると思いますが、Next.js サーバー上で __dirname を参照すると、自動生成された .next ディレクトリ以下のパスが返されてしまってうまくいきまん。 代わりに、process.cwd() でカレントディレクトリ（通常はプロジェクトのルートディレクトリ）のパスを取得して YAML ファイルのパスを構築するようにします 参考リンク Reading files: Use process.cwd() - Next.js YAML ファイルを読み込む（in API ルート） 次に、YAML ファイルを API ルートの handler 関数から読み込んでみます。 基本的に JSON ファイルを扱うのと同様に、fs.readFileSync 関数を使うだけですが、Node.js は標準では YAML テキストをパースできないので、js-yaml パッケージをインストールしておきます。 js-yaml のインストール js-yaml パッケージと、TypeScript 用の型情報 (@types/js-yaml) をインストールします。 $ npm install js-yaml $ npm install @types/js-yaml --save-dev 使用する YAML ファイル サンプルデータとして次のような YAML ファイルをプロジェクト内に配置します。 src/data/books.yaml -title:Title 1author:Author 1-title:Title 2author:Author 2-title:Title 3author:Author 3 YAML ファイルを読み込む この YAML ファイルを、API ルートの実装 (pages/api/books.ts) から読み込むには次のようにします。 src/pages/api/books.ts import * as fs from \u0026#39;fs\u0026#39; import * as path from \u0026#39;path\u0026#39; import * as yaml from \u0026#39;js-yaml\u0026#39; import type { NextApiRequest, NextApiResponse } from \u0026#39;next\u0026#39; export default (req: NextApiRequest, res: NextApiResponse) =\u0026gt; { // プロジェクトルートからの相対パスで YAML ファイルのパスを解決する const yamlPath = path.join(process.cwd(), \u0026#39;src\u0026#39;, \u0026#39;data\u0026#39;, \u0026#39;books.yml\u0026#39;) // YAML ファイルの内容を読み込んでそのまま JSON データとして返す const obj = yaml.load(fs.readFileSync(yamlPath, \u0026#39;utf-8\u0026#39;)) res.status(200).json(obj) } 動作確認 Next.js サーバーを起動 (npm run dev) して、localhost:3000/api/books にアクセスすると、次のような JSON テキストが得られるはずです。 実際は一行 [ {\u0026#34;title\u0026#34;:\u0026#34;Title 1\u0026#34;,\u0026#34;author\u0026#34;:\u0026#34;Author 1\u0026#34;}, {\u0026#34;title\u0026#34;:\u0026#34;Title 2\u0026#34;,\u0026#34;author\u0026#34;:\u0026#34;Author 2\u0026#34;}, {\u0026#34;title\u0026#34;:\u0026#34;Title 3\u0026#34;,\u0026#34;author\u0026#34;:\u0026#34;Author 3\u0026#34;} ]"
},
{
url: "/p/fw7gpx7/",
title: "Next.js の Image コンポーネントで画像を表示する (next/image)",
date: "2021-05-06T00:00:00Z",
body: "Next.js の Image コンポーネントで画像を表示する (next/image) Image コンポーネントの特徴 Next.js が提供している Image コンポーネント (next/image) を使用すると、image 要素をそのまま配置するのに比べて次のような恩恵を受けられます。 遅延ロード (Lazy loading) Web ブラウザでその画像がビューポート内（画面内）に入って来たときに初めてダウンロードされるようになります。大きなページの末尾部分に配置された画像が、無駄にダウンロードされてしまうのを防ぐことができます。 画像の最適化 アクセスしてきたクライアントに応じて画像ファイルを最適化して配信します。例えば、圧縮効率のよい WebP フォーマットなどに変換してくれます。リクエスト時にサーバーサイドでオンデマンドで最適化するため、Image コンポーネントを使うことでビルド時間が伸びてしまうことはありません。外部サーバーの画像を間接的に表示する場合も最適化できます。 レスポンシブ 画面サイズに応じたレスポンシブ表示 (CSS) がデフォルトで行われます。 画像最適化に関しては、Next.js サーバー上でホスティングしているときしか動作しないといった制約がありますが、遅延ローディングがデフォルトで有効になるのは便利です。 Image コンポーネントの基本的な使い方 次のサンプルコンポーネントでは、Image コンポーネントを使って /public/images/avatar.png ファイルを表示しています。 components/Avatar.tsx import Image from \u0026#39;next/image\u0026#39; export const Avatar: React.FC = () =\u0026gt; ( \u0026lt;Image src=\u0026#34;/images/avatar.png\u0026#34; width={64} height={64} alt=\u0026#34;My avatar\u0026#34; /\u0026gt; ) ☝️ public ディレクトリ public ディレクトリ以下に配置したファイルは、Web サイトへのアクセス時には、ルートパス (/) からの相対パスで参照できるようになります。 public ディレクトリは、必ず Next.js プロジェクトのルートディレクトリに配置する必要があります。 .ts、.tsx ファイルは src ディレクトリ以下にも配置できますが、public ディレクトリは必ずルートに置かなければいけません。 width や height プロパティを明示しておくと、画像のロード前にそのサイズの枠が確保されることになります。 これは、CLS (Cumulative Layout Shift) を発生させないために重要です。 表示サイズがあらかじめ決まっていないと、画像ロード後にレイアウトがガクッとずれたりして UX が低下します。 Google によるサイト評価でも CLS スコアは重要視されています。 Image コンポーネントによる画像の拡大・縮小 指定したサイズに拡大・縮小 (width, height) \u0026lt;Image src=\u0026#34;/images/sample.png\u0026#34; width={300} height={150} /\u0026gt; 一番基本的な使い方です。 Image コンポーネント内に表示される画像は、デフォルトで Image コンポーネント自体のサイズ、つまり、width、height プロパティで指定したサイズに拡大・縮小されて表示されます。 画像ファイルのアスペクト比を考慮して指定しないと、上の例のように変形して表示されてしまうので注意してください。 ちなみに、Image コンポーネントが出力する img 要素には、max-width: 100% という CSS スタイルが設定されているため、width プロパティで指定する数値が親コンポーネントの横幅を超えていてもうまく収まるように表示してくれます。 アスペクト比を保って大きく表示 (objectFit=contain) Image コンポーネントの objectFit プロパティ に contain を指定すると、画像のアスペクト比を保ちながら、縦か横にできるだけ大きく表示してくれます。 \u0026lt;Image src=\u0026#34;/images/sample.png\u0026#34; width={300} height={150} objectFit=\u0026#34;contain\u0026#34; /\u0026gt; この objectFit プロパティは、HTML の img 要素用の CSS プロパティである、object-fit プロパティ そのものです。 このプロパティのデフォルト値は fill なので、これを指定しない場合は、画像が width、height プロパティで指定された通りに引き伸ばして表示されるというわけです。 親コンポーネントのサイズに連動させる (layout=fill) \u0026lt;div style={{ position: \u0026#39;relative\u0026#39;, width: \u0026#39;100%\u0026#39;, height: 150 }}\u0026gt; \u0026lt;Image src=\u0026#34;/images/sample.png\u0026#34; layout=\u0026#34;fill\u0026#34; objectFit=\u0026#34;contain\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; Image コンポーネントの width、height プロパティを指定する代わりに、layout プロパティ を fill に設定すると、親要素のサイズが Image コンポーネントのサイズとして使われます。 上記の例でいうと、上の階層に配置した div 要素のサイズが、Image 要素のサイズになります。 ここでは、div 要素自体の横幅も、さらにその親の要素の横幅に合わせるように 100% 指定しています。 Image コンポーネントのサイズを layout=\u0026quot;fill\u0026quot; で親要素のサイズに合わせるときは、objectFit=\u0026quot;contain\u0026quot; も一緒に指定して、アスペクト比を保って拡縮表示するとよいです。 これを指定しないと、デフォルトの objectFit=\u0026quot;fill\u0026quot; が使われて、画像が親要素の形に変形して表示されてしまいます。 （応用）環境によって画像ファイルのダウンロード先を変える (NODE_ENV) 開発環境では /public ディレクトリ以下の画像リソースを参照し、本番環境では別のサーバー上の画像リソースを参照する、といったことをやりたい場合は、例えば NODE_ENV 環境変数の値で条件分岐させます。 process.env.NODE_ENV の値は、実行環境によって次のように変化します。 NODE_ENV の値 実行環境の例 production 本番サーバー (next start) development 開発サーバー (next dev) test テスト (jest) 次の関数は、実行環境に応じて画像ファイルの URL を作り分けます。 export function getImageSrc(filename: string): string { if (process.env.NODE_ENV === \u0026#39;production\u0026#39;) { return `http://img.example.com/img/${filename}` } else { return `/img/${filename}` } } あとは、次のように Image コンポーネントなどで使います。 // import Image from \u0026#39;next/image\u0026#39; \u0026lt;Image src={getImageSrc(\u0026#39;avatar.png\u0026#39;)} width={64} height={64} /\u0026gt; ちなみに、Next.js の Image コンポーネントの src プロパティで、外部サーバー上の画像ファイルを指定する場合は、next.config.js でドメイン名を指定しておく必要があります。 next.config.js module.exports = { images: { domains: [\u0026#39;img.example.com\u0026#39;], }, } 他にも、next.config.js ファイル内で assetPrefix の値を切り替えることで、画像ファイルの取得先を切り替える方法もあります。 参考: next.config.js: CDN Support with Asset Prefix | Next.js next.config.js const isProd = process.env.NODE_ENV === \u0026#39;production\u0026#39; module.exports = { // Use the CDN in production and localhost for development. assetPrefix: isProd ? \u0026#39;https://img.example.com\u0026#39; : \u0026#39;\u0026#39;, images: { domains: [\u0026#39;img.example.com\u0026#39;], }, } これであれば、Image コンポーネントの src プロパティは次のようにシンプルに記述できます。 \u0026lt;Image src=\u0026#39;/avatar.png\u0026#39; width={64} height={64} /\u0026gt; 単純に URL のプレフィックス部分だけ切り替えられればよいのであれば、こちらの方法を使った方が簡単かもしれません。 ただし、assetPrefix の設定は、next/image が提供する Image コンポーネントを使った場合にしか効果がないことに注意してください（生の img コンポーネントをそのまま使った場合はプレフィックスが反映されません）。 また、assetPrefix は全てのリソースの参照パスを切り替えてしまうので、特定のリソースのみ別のサーバーにおきたい場合などは、前述の getImageSrc 関数のような独自の関数を用意したり、Image や img をラップするコンポーネントを作成する必要があります。 （応用）src で指定した画像が見つからなかったときにプレースホルダー画像を表示する Next.js の Image コンポーネントに限らず、通常の HTML の img 要素でも同じなのですが、src 属性で指定した画像ファイルが見つからなかったときは、 のようなアイコンが表示されます（どう表示されるかは Web ブラウザによって異なります）。 このようなケースでは、Image コンポーネントの onError prop に設定したコールバック関数が呼ばれるようになっているので（img の場合は onerror）、この中で代わりの画像の URL をセットするということができます。 次の例では、指定した URL の画像が存在しなかったときに、プレースホルダー画像を表示するように src の URL を変更しています。 function renderImage(title: string, url: string): JSX.Element { return ( \u0026lt;Image src={url} unoptimized={true} layout=\u0026#34;fixed\u0026#34; width={300} height={200} title={title} alt={title} onError={(e) =\u0026gt; { e.currentTarget.src = `https://placehold.jp/32/003060/e0e0e0/300x200.png?text=${title}` }} /\u0026gt; ) } const MyPage: NextPage= () =\u0026gt; { return ( \u0026lt;\u0026gt; {renderImage(\u0026#39;画像タイトル\u0026#39;, \u0026#39;https://example.com/404.png\u0026#39;)} \u0026lt;/\u0026gt; ) } export default MyPage 図: 表示されるプレースホルダー画像 ここでは、プレースホルダー画像を自動生成するために、Placehold.jp を使わせてもらっています。 プレースホルダー生成サービスとしては、他にも Placeholder.com などがありますが、こちらは日本語テキストの表示に対応していないようです。 次のような URL でアクセスするだけで、指定したサイズ、カラー、テキストのプレースホルダー画像を返してくれます。 https://placehold.jp/32/003060/e0e0e0/300x200.png?text=Title https://via.placeholder.com/300x200/003060/e0e0e0.png?text=Title こういうサービスはとってもありがたいです。感謝 ٩(๑❛ᴗ❛๑)۶ 外部サービスに頼りたくないのであれば、次のようにクライアントサイド JavaScript でプレースホルダー画像を生成してしまう方法もあります。 /** * プレースホルダー画像を動的に生成して、img 要素の src にセットするための URL を返します。 * `document` オブジェクトを参照するため、クライアントサイド JS でのみ実行可能です。 */ function createPlaceHolderImage( width: number, height: number, text: string ): string { // Canvas 要素を動的に生成 const canvasElem = document.createElement(\u0026#39;canvas\u0026#39;) canvasElem.width = width canvasElem.height = height const ctx = canvasElem.getContext(\u0026#39;2d\u0026#39;) as CanvasRenderingContext2D // 背景を描画 ctx.fillStyle = \u0026#39;#003060\u0026#39; ctx.fillRect(0, 0, width, height) // テキストを描画（中央寄せ） ctx.fillStyle = \u0026#39;white\u0026#39; ctx.font = `bold 24px Arial, meiryo, sans-serif` const textWidth = ctx.measureText(text).width // 左右の中央寄せ用 ctx.textBaseline = \u0026#39;middle\u0026#39; // 上下の中央寄せ用 ctx.fillText(text, (width - textWidth) / 2, height / 2, width) // 描画内容をデータ化して URL にして返す return canvasElem.toDataURL() } 関数内で document オブジェクトを参照しているため、ビルド時に実行されないように注意してください。 次のように、クライアントサイド JS でしか実行されないようになっていれば大丈夫です（useEffect の中で呼び出すのも大丈夫です）。 \u0026lt;Image ... onError={(e) =\u0026gt; { e.currentTarget.src = createPlaceHolderImage(300, 200, \u0026#39;画像タイトル\u0026#39;) }} /\u0026gt;"
},
{
url: "/p/eu7djpv/",
title: "Undertale やってみた",
date: "2021-05-03T00:00:00Z",
body: "Undertale やってみた インディーズゲームの世界で話題になった『Undertale』をやってみました。 斬新なシステムや、ストーリー、音楽などに定評があるゲームです。 プレイヤーによって好き嫌いがハッキリと分かれそうなゲームですが、ゲームとして非常に練りこまれていて、プレイしておいて損はないゲームだと思いました。 最初クリアしたときは、ただのパズル要素の入ったドット絵の同人 RPG みたいだなという感じでしたが、Web で情報を探してみると、下記のように特殊な進め方をする 2 回目以降のプレイからが本当のストーリーの始まりでした。 P ルート (True Pacifist Route) \u0026hellip; 誰も殺さない G ルート (Genocide Route) \u0026hellip; 皆殺し この両極端な進め方でもクリアできるようになっているところが面白く、そのプレイ方法がプレイヤーを感情移入させます。 そして登場キャラクターは、プレイヤーが何度も繰り返しプレイしていることを認識しています。 何度もクリアしなければいけないのは面倒だと思うかもしれませんが、2 回目以降は途中のパズルなどを飛ばせるようになっていて、サクサクと進められるよう工夫されています。 ただし、集団虐殺ルート（通称 G ルート）のラスボス的存在である骸骨姿の「サンズ (Sans)」は凶悪なほど強く、鬼畜ゲー と言われる理由がわかりました。 なんと、プレイヤーのコマンド入力エリアにまで攻撃を仕掛けてきて、ミリ秒単位の操作が要求されます。 ほんと寿命が縮まります。 何十回も挑戦してぎりぎりでクリアできましたが、もう少し歳を取ったら、このゲームはたぶんクリアできなくなると思います。 というかプレイ中に死ぬ と思います。 今のうちにクリアしておいてよかったです。 UNDERTALE - Switch (【永久封入特典】ストーリーブックレット 同梱) Toby Fox Nintendo Switch UNDERTALE - PS4 (【永久封入特典】ストーリーブックレット 同梱) Toby Fox PlayStation 4 UNDERTALE - PSVita (【永久封入特典】ストーリーブックレット 同梱) Toby Fox PlayStation Vita ちなみに、普通の RPG と同様に、最初にプレイヤーに名前を付けるのですが、この名前は実は、"
},
{
url: "/p/anu28ek/",
title: "async は「アシンク」じゃなくて「エイシンク」だよ",
date: "2021-04-30T00:00:00Z",
body: "async は「アシンク」じゃなくて「エイシンク」だよ こんなことを記事にしたくもなかったのですが、ほんとうに間違った読み方をしている人が多いので書きます。 多くのモダンなプログラミング言語が async/await という非同期処理用の構文（あるいはそれに似た構文）を採用しているのですが、この「async」を「アシンク」と読んでいる日本人がすごく多いです。 感覚的には、半分くらいの人が「アシンク」って発音しているのではないかと思うくらい。。。しかし、 「async」の発音は「エイシンク」です！ もちろんこのキーワードは英語の asynchronous から来ているのですが、 アメリカ発音は eɪsíŋkrənəs イギリス発音は eɪˈsɪŋkrʌnʌs で、どちらも「エイシンクロナス」です。 英語の解説動画を見たらすぐ分かることですが、「アシンク」なんて発音している人はいません。 ちなみにちょっと古い技術ですが、「ajax」も「アジャックス」ではなく「エイジャックス」です。 「アシンクロナス」なんて発音したら、「a synchronous ~」になって全く逆の意味になってしまいます。 おそらく独学で async/await イディオムを学んだ人は最初からちゃんと正しく発音できています。 周りの人が「アシンク」って連呼しているところから学び始めた人は、間違えて覚えちゃってる人が多いのだと思います。 「アシンク」でもいいんじゃないかと言う人すらいそうですが、こんな基本的な発音すら間違っていると、この人はプログラミングをちゃんと理解しているのか？と無駄に疑われてしまいます。 こんなことでも海外のデベロッパーになめられます。 絶対にちゃんと発音した方がいいです。 この記事を読んだ人は、これ以上被害者を出さないためにも、「エイシンク」と正しく発音するようにしてください。 Youtube などで間違った読み方で解説動画を作っている人はすぐに直してください。 お願いいたします。"
},
{
url: "/p/7tds7bw/",
title: "AWS CLI でアクセスできるのに AWS SDK で Access Denied (403) になるとき",
date: "2021-04-26T00:00:00Z",
body: "AWS CLI でアクセスできるのに AWS SDK で Access Denied (403) になるとき 認証情報の食い違いを調べる 例えば、ローカルで AWS CLI を使って S3 の情報にアクセスできているのに、AWS SDK 使った Node.js プログラムで S3 にアクセスしたときに Access Denied (403) になるときは、異なる認証情報 (credentials) を使ってアクセスしている可能性 があります。 AWS CLI が、どのようなユーザーでアクセスしているかは、下記のようにして確認できます。 $ aws sts get-caller-identity Account: \u0026#39;123456789012\u0026#39; Arn: arn:aws:sts::123456789012:assumed-role/MyDeveloperRole/botocore-session-9876543210 UserId: A6B3EVWX58AR9AVTXAP5T:botocore-session-9876543210 次に、Node.js のプログラムなどで、AWS SDK を使って上記と同様の情報を取得します。 Node.js 用の SDK ver.2 では、AWS.STS.getCallerIdentity()、SDK ver.3 では STSClient.send() を使います。 参考: AWS.STS.getCallerIdentity() - AWS SDK v2 参考: GetCallerIdentityCommand() - AWS SDK v3 printCallerIdentity.ts（SDK ver.2 の場合） import { STS } from \u0026#39;aws-sdk\u0026#39;; async function printCallerIdentity() { try { const sts = new STS(); const result = await sts.getCallerIdentity().promise() console.log(result) } catch (e) { console.error(e); } } printCallerIdentity(); SDK ver.3 の場合 import { STSClient, GetCallerIdentityCommand, GetCallerIdentityCommandInput, GetCallerIdentityCommandOutput, } from \u0026#34;@aws-sdk/client-sts\u0026#34;; async function printCallerIdentity() { const client = new STSClient({ region: \u0026#34;ap-northeast-1\u0026#34; }); const input: GetCallerIdentityCommandInput = {}; const command = new GetCallerIdentityCommand(input); try { const output: GetCallerIdentityCommandOutput = await client.send(command); console.log(output); } catch (e) { console.error(e); } } printCallerIdentity(); 実行結果 $ ts-node printCallerIdentity.ts { ResponseMetadata: { RequestId: \u0026#39;2ce10620-9158-4e5e-8bca-8258bfd02927\u0026#39; }, UserId: \u0026#39;MWUCVBID75KAC5PB68LSP\u0026#39;, Account: \u0026#39;777888999000\u0026#39;, Arn: \u0026#39;arn:aws:iam::777888999000:user/your-user-name\u0026#39; } 上記の結果と aws sts get-caller-identity の結果を比べると、別のユーザー (credential) でアクセスしていることが分かります。 つまり、AWS SDK 対して、正しく認証情報 (credentails) を設定してやれば問題は解決するはずです。 AWS CLI に設定されている認証情報は、aws configure list コマンドなどで確認できます。 参考リンク AWS SDK の使用中に発生する S3 アクセス拒否エラーの解決 （おまけ）今回の原因 ちなみに、今回の Access Denied (403) の原因は、AWS CLI では Assume Role したユーザーでアクセスできていたけれど、AWS SDK の方は直接アクセスしていたので弾かれていたというオチでした。 AWS SDK で Assume Role したいときは、AWS.SMS オブジェクトの assumeRole メソッドを使います。 例えば、下記のような感じで Assume Role して取得した認証情報をセットしてから、S3 などの API を呼び出せば、うまくアクセスできるようになります。 import * as AWS from \u0026#39;aws-sdk\u0026#39;; async function assumeRole() { const roleToAssume = { RoleArn: \u0026#39;arn:aws:iam::123456789012:role/MyDeveloperRole\u0026#39;, RoleSessionName: \u0026#39;session1\u0026#39;, DurationSeconds: 900, }; try { const sts = new AWS.STS(); const data = await sts.assumeRole(roleToAssume).promise(); AWS.config.update({ credentials: { accessKeyId: data.Credentials?.AccessKeyId!, secretAccessKey: data.Credentials?.SecretAccessKey!, sessionToken: data.Credentials?.SessionToken! } }); } catch (err) { console.error(err); } } 複雑すぎでしょ・・・（´へ｀; 参考リンク sts_assumerole.js - AWS Code Sample （おまけ）Access Key Id の情報を調べる 次のようにすれば、AWS SDK が使用しようとしているアクセスキーの ID を調べることができます。 この情報もトラブル発生時のヒントになるかもしれません。 import * as AWS from \u0026#39;aws-sdk\u0026#39;; function printAccessKey() { AWS.config.getCredentials(err =\u0026gt; { if (err) console.error(err.message); else console.log(\u0026#39;Access Key: \u0026#39; + AWS.config.credentials?.accessKeyId); }); } printAccessKey(); 参考リンク SDK v2 開発者ガイド ─ グローバル設定オブジェクトの使用"
},
{
url: "/p/szcbzgt/",
title: "AWS のトラブルシューティング",
date: "2021-04-26T00:00:00Z",
body: "AWS のトラブルシューティング"
},
{
url: "/p/bwamwgp/",
title: "ドメイン管理と DNS 管理の違いを理解する",
date: "2021-04-25T00:00:00Z",
body: "ドメイン管理と DNS 管理の違いを理解する ドメイン管理と DNS サーバー 「独自ドメイン＋レンタルサーバー」を契約してブログサイトなどを立ち上げようとすると、どうしてもドメイン管理や DNS 設定を行う必要が出てきます。 同じ会社で一括契約すると、まとめて設定できたりしますが、これらは本来別々のサービスなので、ここで簡単に整理しておきます。 ドメイン取得・管理は、レジストラ（およびその委託先会社）が行っており、世界で一意なドメインを運用します。 日本では、お名前.com (by GMO) などが有名ですね。 一方で、DNS サービスは、このドメイン名を具体的な IP アドレスに関連づける機能を提供します。 レジストラ（ドメイン管理会社）が提供するドメイン管理サービスは、あくまでドメイン名を管理しているだけであり、DNS の機能を提供しているわけではありません。 なので、ドメイン管理会社でドメインを取得したら、そのドメインの名前解決に使用する DNS サーバーのアドレスを教えてあげる必要があります。 上の図では、お名前.com のドメイン管理設定で、さくらインターネットの DNS サーバー (ns1/2.dns.ne.jp) のアドレスを設定する例を示しています。 この設定により、ユーザーが example.com にアクセスしようとすると、DNS サーバー (ns1.dns.ne.jp) によって IP アドレス (12.34.56.78) に変換され、そのアドレスの Web サーバーにアクセスできるという仕組みになっています。 組み合わせの例 ドメイン取得・管理 DNS サーバー Web サーバー お名前.com お名前.com お名前.com お名前.com さくらインターネット さくらインターネット お名前.com AWS (R53) AWS (EC2) 多くの場合、こんな感じで DNS サーバーと Web サーバーは同じ会社のものを使います。 レンタルサーバーのアドレスなどを自動で設定できたりして便利だからです。 DNS サーバーの使用料金はレンタルサーバーの使用料金に含まれていることが多いですが、AWS の R53 などは個別に使用料金がかかります。 一方、ドメイン取得・管理会社の方は、年ごとの更新費用などが安い「お名前.com」などを選ぶことが多いです。 Amazon (AWS) などのクラウドサービスでもドメイン取得できたりしますが、ちょっとお値段高めです。 お名前.com でのドメイン取得はこちらから → お名前.com のレンタルサーバーはこちらから → さくらの VPS はこちらから → お名前.com の VPS はこちらから →"
},
{
url: "/p/f2fq2cn/",
title: "Lambda 実装例: S3 へのアップロードを SNS で通知して Lambda から読み込む",
date: "2021-04-19T00:00:00Z",
body: "Lambda 実装例: S3 へのアップロードを SNS で通知して Lambda から読み込む 何をするか？ ここでは Lambda 関数の実装例として、SNS トピックから S3 バケットの PutObject イベント通知を受けて、アップロードされたファイルを読み込む例を示します。 S3 バケット、および SNS トピックの作成と、S3 → SNS の通知設定は完了していると想定します。 参考リンク CloudFormation の設定例: S3 通知を SNS トピックに Publish する CloudFormation の設定例: SNS トピックを Lambda 関数からサブスクライブする Lambda 関数の実装 AWS SDK のインストール ここでは、Node.js 用の AWS SDK ver.2 を使っているので、先にインストールしておく必要があります。 AWS 側の Lambda 実行環境には標準でインストールされているので、--save-dev（開発用）でインストールしておけば OK です。 ついでに TypeScript 用の型定義もインストールしておくと、Lambda ハンドラのパラメータを any 型ではなく、SNSEvent 型などで参照できて便利です。 $ npm install aws-sdk --save-dev $ npm install @types/aws-lambda --save-dev Lambda ハンドラの実装 先に、S3 バケット内のオブジェクトの内容を取得するユーティリティ関数を用意しておきます（AWS SDK ver.2 を使用しています）。 エクスポートされた getS3Object 関数を使う想定ですが、このコードを直接実行したときには末尾のテスト関数を実行するようにしてあります。 src/s3util.ts import { S3 } from \u0026#39;aws-sdk\u0026#39;; const s3 = new S3(); /** S3 バケット内のオブジェクト（テキスト）を読み込んでその内容を返します。 */ export async function getS3Object( bucketName: string, objectKey: string ): Promise\u0026lt;string | undefined\u0026gt; { const output: S3.GetObjectOutput = await s3.getObject({ Bucket: bucketName, Key: objectKey, }).promise(); return output.Body?.toString(); } // テスト用 main 関数 if (require.main === module) (async () =\u0026gt; { try { const bucket = \u0026#39;bucket-123456789012-sample\u0026#39;; const key = \u0026#39;sample.txt\u0026#39;; const body = await getS3Object(bucket, key); console.log(body); } catch (e) { console.err(e); } })(); 次の Lambda 関数実装では、第一引数で受け取った SNSEvent オブジェクトから S3 バケット名とオブジェクト名を取り出して、そのオブジェクトの内容を S3 API（上記で定義したユーティリティ関数）を使って取得しています。 src/index.ts import { SNSEvent, Context, Callback } from \u0026#39;aws-lambda\u0026#39;; import * as s3util from \u0026#39;./s3util\u0026#39;; /** SNS トピックの通知から抽出する S3 メタ情報 */ type BucketMeta = { /** S3 のイベント名 (例: `ObjectCreated:Put`) */ eventName: string, /** S3 バケット名 */ bucketName: string, /** S3 バケット内のオブジェクトキー */ objectKey: string, }; /** Lambda 関数に渡されるイベントデータから S3 のメタ情報を取得します。 */ function parseSnsEvent(snsEvent: SNSEvent): BucketMeta { const msg = JSON.parse(snsEvent.Records[0].Sns.Message) as any; return { eventName: msg.Records[0].eventName, bucketName: msg.Records[0].s3.bucket.name, objectKey: msg.Records[0].s3.object.key, } as BucketMeta; } /** Lambda 関数のエントリポイントです。 */ export async function handler(event: SNSEvent, ctx: Context, callback: Callback) { try { const meta: BucketMeta = parseSnsEvent(event); const body = await s3util.getS3Object(meta.bucketName, meta.objectKey) console.log(meta); console.log(body); callback(null, body); } catch (e) { console.error(e); callback(e); } } 解説 Lambda 関数の第一引数 (event) で渡されるオブジェクト (このケースでは SNSEvent 型) の Records[0].Sns.Message プロパティを参照すると、次のような JSON テキストを取得できます（オブジェクトではなく JSON 形式のテキストです）。 SNSEvent.Records[0].Sns.Message の内容 { \u0026#34;Records\u0026#34;: [ { \u0026#34;eventVersion\u0026#34;: \u0026#34;2.1\u0026#34;, \u0026#34;eventSource\u0026#34;: \u0026#34;aws:s3\u0026#34; \u0026#34;awsRegion\u0026#34;: \u0026#34;ap-northeast-1\u0026#34;, \u0026#34;eventTime\u0026#34;: \u0026#34;2021-04-19T15:30:59.084Z\u0026#34;, \u0026#34;eventName\u0026#34;: \u0026#34;ObjectCreated:Put\u0026#34;, \u0026#34;userIdentity\u0026#34;: { \u0026#34;principalId\u0026#34;: \u0026#34;AWS:AIDMAQAKLZ6V3HXINMCQG\u0026#34; }, \u0026#34;requestParameters\u0026#34;: { \u0026#34;sourceIPAddress\u0026#34;: \u0026#34;110.76.125.97\u0026#34; }, \u0026#34;responseElements\u0026#34;: { \u0026#34;x-amz-request-id\u0026#34;: \u0026#34;PR9N0NY46J4B4YM9\u0026#34;, \u0026#34;x-amz-id-2\u0026#34;: \u0026#34;IyRPxwo5CHEv4eB8Vd2JjL6kkxdJ0fm0S3qfkB1oKh3gBudpIomjSBvN77749yBgqxKtws7l+FbUhjgMATBf/1VnblothZ6v7DXmjCj5s8Y=\u0026#34; }, \u0026#34;s3\u0026#34;: { \u0026#34;s3SchemaVersion\u0026#34;: \u0026#34;1.0\u0026#34;, \u0026#34;configurationId\u0026#34;: \u0026#34;497e6001-fbc4-40df-939e-c09289477696\u0026#34;, \u0026#34;bucket\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;bucket-123456789012-sample\u0026#34;, \u0026#34;ownerIdentity\u0026#34;: { \u0026#34;principalId\u0026#34;: \u0026#34;A2H51MMFJF0VI7\u0026#34; }, \u0026#34;arn\u0026#34;: \u0026#34;arn:aws:s3:::bucket-123456789012-sample\u0026#34; }, \u0026#34;object\u0026#34;: { \u0026#34;key\u0026#34;: \u0026#34;sample.txt\u0026#34;, \u0026#34;size\u0026#34;: 5, \u0026#34;eTag\u0026#34;: \u0026#34;dcd0cda10b5681c4a9e9ff6fe9e95990\u0026#34;, \u0026#34;sequencer\u0026#34;: \u0026#34;5500C45300607DA237\u0026#34; } } } ] } この JSON テキストをオブジェクト化すれば、次のような情報を参照できます。 Records[0].eventName → S3 のイベント名 (ObjectCreated:Put) Records[0].s3.bucket.name → S3 バケット名 (bucket-123456789012-sample) Records[0].s3.object.key → S3 バケットに格納されたオブジェクト名 (sample.txt) あとは、この情報を使って、S3 バケットに格納されたオブジェクト（ファイル）の内容を取得すれば OK です。 必要な情報は Lambda 関数の引数で受け取れるので、環境変数などで S3 バケットの情報を渡さずに済みます。 デプロイ用の情報 CloudFormation テンプレート ここでは CloudFormation (SAM) テンプレートを使って、Lambda 関数のリソースを生成します。 Lambda 関数リソースを生成するときに、S3 バケットへのアクセス権限と、SNS トピックへのサブスクリプション設定を行う必要があるので、これらの情報を入力パラメーター (Parameters) として定義しています。 S3 バケット名: bucket-123456789012-sample SNS トピックの ARN: arn:aws:sns:ap-northeast-1:123456789012:mytopic template.yaml AWSTemplateFormatVersion:2010-09-09Transform:AWS::Serverless-2016-10-31Parameters:TopicArn:Type:StringDefault:arn:aws:sns:ap-northeast-1:123456789012:mytopicBucketName:Type:StringDefault:bucket-123456789012-sampleResources:MyFunction:Type:AWS::Serverless::FunctionProperties:Runtime:nodejs14.xHandler:build/index.handlerCodeUri:function.zip# S3 にアクセスするための権限（ポリシー）をロールに追加Policies:- S3CrudPolicy:BucketName:!Ref BucketName# この Lambda 関数を SNS トピックにサブスクライブするEvents:MySnsEvent:Type:SNSProperties:Topic:!Ref TopicArn このテンプレートを使って実際に CloudFormation スタックを生成する方法をここで説明すると長くなってしまうので、そのあたりは下記の記事を参照してください。 参考リンク AWS CloudFormation で Lambda 関数のリソースを生成する package.json 参考までに package.json の一例を載せておきます。 { \u0026#34;name\u0026#34;: \u0026#34;function\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;0.0.1\u0026#34;, \u0026#34;scripts\u0026#34;: { \u0026#34;start\u0026#34;: \u0026#34;node build/index.js\u0026#34;, \u0026#34;build\u0026#34;: \u0026#34;tsc\u0026#34;, \u0026#34;build:watch\u0026#34;: \u0026#34;tsc --watch\u0026#34;, \u0026#34;zip\u0026#34;: \u0026#34;npm-pack-zip\u0026#34;, \u0026#34;cf:package\u0026#34;: \u0026#34;aws cloudformation package --template-file template.yml --output-template-file template.packaged.yml --s3-bucket bucket-123456789012-functions\u0026#34;, \u0026#34;cf:deploy\u0026#34;: \u0026#34;aws cloudformation deploy --stack-name mystack --template-file template.packaged.yml --capabilities CAPABILITY_IAM\u0026#34; }, \u0026#34;files\u0026#34;: [ \u0026#34;build\u0026#34; ], \u0026#34;bundledDependencies\u0026#34;: [], \u0026#34;devDependencies\u0026#34;: { \u0026#34;@types/aws-lambda\u0026#34;: \u0026#34;^8.10.75\u0026#34;, \u0026#34;@types/node\u0026#34;: \u0026#34;^14.14.35\u0026#34;, \u0026#34;npm-pack-zip\u0026#34;: \u0026#34;^1.2.9\u0026#34;, \u0026#34;typescript\u0026#34;: \u0026#34;^4.2.3\u0026#34; }, \u0026#34;dependencies\u0026#34;: { \u0026#34;aws-sdk\u0026#34;: \u0026#34;^2.884.0\u0026#34; } } 使用例 $ npm run install # 依存パッケージのインストール $ npm run build # ビルド（トランスパイル） $ npm run zip # ビルド結果を ZIP 化 $ npm run cf:package # ZIP をアップロード $ npm run cf:deploy # デプロイ（CloudFormation スタックを生成） TypeScript で実装した Lambda 関数を ZIP 化する方法に関しては、以下の記事を参考にしてください。 参考リンク AWS Lambda にデプロイするための ZIP パッケージを npm で作成する (npm-pack-zip)"
},
{
url: "/p/qcpybnx/",
title: "AWS SNS トピックから通知されるイベントデータの例",
date: "2021-04-19T00:00:00Z",
body: "AWS SNS トピックから通知されるイベントデータの例 AWS SNS トピックからメッセージが発行されたときに、サブスクライバー（Lambda 関数など）にどのようなイベントデータが配信されるかの例です。 基本的なメッセージの構造 Lambda 関数で受け取る場合 SNS トピックに対して Lambda 関数をサブスクライブしておくと、Lambda 関数の第一引数 (event) で、次のようなオブジェクトを受信できます。 重要な情報は、Records[0].Sns の下に格納されています。 { \u0026#34;Records\u0026#34;: [ { \u0026#34;EventSource\u0026#34;: \u0026#34;aws:sns\u0026#34;, \u0026#34;EventVersion\u0026#34;: \u0026#34;1.0\u0026#34;, \u0026#34;EventSubscriptionArn\u0026#34;: \u0026#34;arn:aws:sns:ap-northeast-1:123456789012:mytopic:0884-5d81c0db-4e13-829f-596f7ea9f8ad\u0026#34;, \u0026#34;Sns\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Notification\u0026#34;, ... \u0026#34;Subject\u0026#34;: \u0026#34;Message Title\u0026#34;, \u0026#34;Message\u0026#34;: \u0026#34;Message Body\u0026#34;, ... } } ] } メールで受け取る場合 SNS トピックに「JSON 形式のメール」をサブスクライブしておくと、SNS のメッセージが発行されたときに、次のような内容のメールが届きます。 { \u0026#34;Type\u0026#34;: \u0026#34;Notification\u0026#34;, ... \u0026#34;Subject\u0026#34;: \u0026#34;Message Title\u0026#34;, \u0026#34;Message\u0026#34;: \u0026#34;Message Body\u0026#34;, ... } Lambda 関数の第一引数で渡される event オブジェクトで表現すると、event.Records[0].Sns に相当する部分の情報がメールで送られてきます。 具体的な SNS メッセージの例 下記の例では、Records[0].Sns 以下の情報のみを示しています（JSON 形式のメールで送られる内容です）。 SNS のマネージメントコンソールからメッセージ発行したとき 件名に Message Title、本文に Message Body を設定してメッセージ発行したときに送られるイベントデータの例です。 { \u0026#34;Type\u0026#34; : \u0026#34;Notification\u0026#34;, \u0026#34;MessageId\u0026#34; : \u0026#34;789b67e7-9bd8-5a6e-99d0-3f10e520edf7\u0026#34;, \u0026#34;TopicArn\u0026#34; : \u0026#34;arn:aws:sns:ap-northeast-1:123456789012:mytopic\u0026#34;, \u0026#34;Subject\u0026#34; : \u0026#34;Message Title\u0026#34;, \u0026#34;Message\u0026#34; : \u0026#34;Message Body\u0026#34;, \u0026#34;Timestamp\u0026#34; : \u0026#34;2021-04-19T12:51:04.019Z\u0026#34;, \u0026#34;SignatureVersion\u0026#34; : \u0026#34;1\u0026#34;, \u0026#34;Signature\u0026#34; : \u0026#34;bKXAFppLnPMeajvylkQvjiH/9RNeAlNfxbBC7HJbiOt7SKrw9oVk+CI1ZYsADcNt9aAtAOysdHrFD97J/N4n5o+tV+Dz5hsjxqKskYOCrYDRTTqLyhwa5OBtjAhU74IZy9ByfBSQWfOD1I5AFp0FLUWR8ieop/ZTV5buf4FodNm4scwW18nUJ1D5iTPNy3NinWq0wVP2FT7Ykt9HCdNleaFamMZ+war4OHsRhOgvDqOV4auZ2yvayMf70eJPHLbuQn09E0IlQYsvUArTOSknbFK3lsbeLfJBHmIa2qnuZm+VTknNgJxkCJNyer+7EKTrOABYqXsz55ENYJsn5xvjCA==\u0026#34;, \u0026#34;SigningCertURL\u0026#34; : \u0026#34;https://sns.ap-northeast-1.amazonaws.com/SimpleNotificationService-94bdb98bd93083010a507c1833636cda.pem\u0026#34;, \u0026#34;UnsubscribeURL\u0026#34; : \u0026#34;https://sns.ap-northeast-1.amazonaws.com/?Action=Unsubscribe\u0026amp;SubscriptionArn=arn:aws:sns:ap-northeast-1:123456789012:mytopic:97989c34-955f-49c8-856c-1b8e3e926a6f\u0026#34; } S3 の PutObject イベントを SNS から通知したとき S3 バケットに対して sample.txt をアップロードしたときの SNS 通知の例です。 Message プロパティの中に JSON 形式の情報が格納されていて、この中身を見ると、アップロードされたファイルの名前（S3 オブジェクトのキー）などが分かります。 { \u0026#34;Type\u0026#34; : \u0026#34;Notification\u0026#34;, \u0026#34;MessageId\u0026#34; : \u0026#34;da5edc2e-1ccf-51d9-8601-2ada4b82a998\u0026#34;, \u0026#34;TopicArn\u0026#34; : \u0026#34;arn:aws:sns:ap-northeast-1:123456789012:mytopic\u0026#34;, \u0026#34;Subject\u0026#34; : \u0026#34;Amazon S3 Notification\u0026#34;, \u0026#34;Message\u0026#34; : \u0026#34;{\\\u0026#34;Records\\\u0026#34;:[{\\\u0026#34;eventVersion\\\u0026#34;:\\\u0026#34;2.1\\\u0026#34;,\\\u0026#34;eventSource\\\u0026#34;:\\\u0026#34;aws:s3\\\u0026#34;,\\\u0026#34;awsRegion\\\u0026#34;:\\\u0026#34;ap-northeast-1\\\u0026#34;,\\\u0026#34;eventTime\\\u0026#34;:\\\u0026#34;2021-04-19T13:16:16.834Z\\\u0026#34;,\\\u0026#34;eventName\\\u0026#34;:\\\u0026#34;ObjectCreated:Put\\\u0026#34;,\\\u0026#34;userIdentity\\\u0026#34;:{\\\u0026#34;principalId\\\u0026#34;:\\\u0026#34;AWS:AIDAQXINMCQAMKLZ6V3HG\\\u0026#34;},\\\u0026#34;requestParameters\\\u0026#34;:{\\\u0026#34;sourceIPAddress\\\u0026#34;:\\\u0026#34;110.76.125.97\\\u0026#34;},\\\u0026#34;responseElements\\\u0026#34;:{\\\u0026#34;x-amz-request-id\\\u0026#34;:\\\u0026#34;JWTTJDZ40Y077BRS\\\u0026#34;,\\\u0026#34;x-amz-id-2\\\u0026#34;:\\\u0026#34;TNX1leb/NXvnS3fN/slo373HsAi6Wy0OUXK0LLlxLTfWHr+HhyxMckvUvkN91A7BDx2/UEFM0EFiCRJw0mGxlZBAy68j43vt\\\u0026#34;},\\\u0026#34;s3\\\u0026#34;:{\\\u0026#34;s3SchemaVersion\\\u0026#34;:\\\u0026#34;1.0\\\u0026#34;,\\\u0026#34;configurationId\\\u0026#34;:\\\u0026#34;497e6001-fbc4-40df-939e-c09289477696\\\u0026#34;,\\\u0026#34;bucket\\\u0026#34;:{\\\u0026#34;name\\\u0026#34;:\\\u0026#34;myapp-sample-bucket-123456789012\\\u0026#34;,\\\u0026#34;ownerIdentity\\\u0026#34;:{\\\u0026#34;principalId\\\u0026#34;:\\\u0026#34;FJF0VI7A2H51MM\\\u0026#34;},\\\u0026#34;arn\\\u0026#34;:\\\u0026#34;arn:aws:s3:::myapp-sample-bucket-123456789012\\\u0026#34;},\\\u0026#34;object\\\u0026#34;:{\\\u0026#34;key\\\u0026#34;:\\\u0026#34;sample.txt\\\u0026#34;,\\\u0026#34;size\\\u0026#34;:5,\\\u0026#34;eTag\\\u0026#34;:\\\u0026#34;cda10b5681c9e9ff6fe9e95990dcd04a\\\u0026#34;,\\\u0026#34;sequencer\\\u0026#34;:\\\u0026#34;48084D47F00607D82A\\\u0026#34;}}}]}\u0026#34;, \u0026#34;Timestamp\u0026#34; : \u0026#34;2021-04-19T13:16:21.315Z\u0026#34;, \u0026#34;SignatureVersion\u0026#34; : \u0026#34;1\u0026#34;, \u0026#34;Signature\u0026#34; : \u0026#34;EDu9KfAsGc4ajlurH+R+fALKFBGLbQEvm+DPMfI6GWyWk0e1tfg3VxpsSwRaE7+QTKeqjCwCXXLhsALo3eIZbFh7xL4mTX+4tDyPtw3zV4OpSlEfWJr0F3g9lP1ZbO0DbSqKqrLnthw3CPsG3yNDGgyEVTPR8BGIL0tTsmpNDDcHfOsEIwoxUCpR4HZfImLWKua4lZd8U1Yib/8r9p033T9kp5VoQlaK0lMRJI0WuI3Rbn7YC2Qvh2G3Lp8mszoqkUjmftmk7wCfgguB88dCLn5FU7ylHNanOao0do1BbV12rTcBMqZH3vbcezaqa9KVRcetDEHB5BJHQRGeG6t0og==\u0026#34;, \u0026#34;SigningCertURL\u0026#34; : \u0026#34;https://sns.ap-northeast-1.amazonaws.com/SimpleNotificationService-94bdb98bd93083a010a507c1833636cd.pem\u0026#34;, \u0026#34;UnsubscribeURL\u0026#34; : \u0026#34;https://sns.ap-northeast-1.amazonaws.com/?Action=Unsubscribe\u0026amp;SubscriptionArn=arn:aws:sns:ap-northeast-1:123456789012:mytopic:97989c34-955f-49c8-856c-1b8e3e926a6f\u0026#34; }"
},
{
url: "/p/3o2dpyb/",
title: "AWS CloudFormation の設定例: S3 通知を SNS トピックに Publish する",
date: "2021-04-13T00:00:00Z",
body: "AWS CloudFormation の設定例: S3 通知を SNS トピックに Publish する 何をするか？ ここでは、CloudFormation のテンプレートを使って、次のような AWS リソースを定義してみます。 S3 バケット（Logical ID: MyBucket) SNS トピック (Logical ID: MyTopic) 上記の S3 バケットへの書き込み時に、SNS トピックへ publish 動作のイメージとしてはこんな感じです。 このような構成でリソースを作っておくと、S3 バケット上のデータ更新を、SNS トピックのサブスクライブによって監視できるようになります。 例えば、Lambda 関数を SNS トピックのサブスクライバーとして登録すれば、S3 バケットへの書き込みを Lambda 関数でハンドルできます。 参考情報 CloudFormation テンプレートで S3 バケットや SNS トピックを定義する方法は、下記の記事を参考にしてください。 CloudFormation で S3 バケットの作成 CloudFormation で SNS トピックの作成 テンプレートの記述例 次の CloudFormation テンプレートでは、S3 バケットと SNS トピックのリソースを定義しています。 デフォルトの名前はそれぞれ次のようになっています。 S3 バケット名: myapp-sample-bucket-\u0026lt;AccountId\u0026gt; SNS トピック名: myapp-sample-topic S3 バケット名は世界で一意でなければいけないため、末尾に使用中のアカウント ID を付加するようにしています。 template.yml AWSTemplateFormatVersion:\u0026#39;2010-09-09\u0026#39;Parameters:BucketPrefix:Type:StringDefault:myapp-sample-bucketTopicName:Type:StringDefault:myapp-sample-topicResources:MyTopic:Type:AWS::SNS::TopicProperties:TopicName:!Sub ${TopicName}MyTopicPolicy:Type:AWS::SNS::TopicPolicyProperties:PolicyDocument:Id:!Ref MyTopicVersion:2012-10-17Statement:- Effect:AllowPrincipal:Service:s3.amazonaws.comAction:sns:PublishResource:!Ref MyTopicCondition:ArnLike:aws:SourceArn:!Sub arn:aws:s3:::${BucketPrefix}-${AWS::AccountId}Topics:- !Ref MyTopicMyBucket:Type:AWS::S3::BucketProperties:BucketName:!Sub ${BucketPrefix}-${AWS::AccountId}NotificationConfiguration:TopicConfigurations:- Event:s3:ObjectCreated:PutTopic:!Ref MyTopic このテンプレートを使って CloudFormation スタックを生成するには、例えば AWS CLI を使って次のように実行します。 mystack スタックの生成 $ aws cloudformation deploy --stack-name mystack \\ --template-file template.yml \\ --capabilities CAPABILITY_IAM 1 分ほど待つと、スタックの生成が完了します。 あとは、SNS トピックのコンソールから E メールなどをサブスクリプション登録して、S3 バケットに適当にファイルをアップロードすれば、JSON 形式のイベント通知が届くはずです。 その通知には S3 バケット名などが含まれているので、例えば、Lambda 関数から S3 バケットの情報を取り出すといったことが簡単に行えます。 サブスクライバーに通知される JSON の例 { \u0026#34;Records\u0026#34;: [ { \u0026#34;eventVersion\u0026#34;: \u0026#34;2.1\u0026#34;, \u0026#34;eventSource\u0026#34;: \u0026#34;aws:s3\u0026#34;, \u0026#34;awsRegion\u0026#34;: \u0026#34;ap-northeast-1\u0026#34;, \u0026#34;eventTime\u0026#34;: \u0026#34;2021-04-13T18:30:34.201Z\u0026#34;, \u0026#34;eventName\u0026#34;: \u0026#34;ObjectCreated:Put\u0026#34;, \u0026#34;userIdentity\u0026#34;: { \u0026#34;principalId\u0026#34;: \u0026#34;AWS:AMKLZ6V3HGAIDAQXINMCQ\u0026#34; }, \u0026#34;requestParameters\u0026#34;: { \u0026#34;sourceIPAddress\u0026#34;: \u0026#34;110.76.125.97\u0026#34; }, \u0026#34;responseElements\u0026#34;: { \u0026#34;x-amz-request-id\u0026#34;: \u0026#34;7ACH2WP7F8SCVTP8\u0026#34;, \u0026#34;x-amz-id-2\u0026#34;: \u0026#34;tpjlZo9kIjD9kgHA6WjiEh/XW3eh7NyByw3jxho8pVTZnEUG0NixkAMO00zfwD4IRxyOJIk8WRziEIZR24bXxXr37fruczEB\u0026#34; }, \u0026#34;s3\u0026#34;: { \u0026#34;s3SchemaVersion\u0026#34;: \u0026#34;1.0\u0026#34;, \u0026#34;configurationId\u0026#34;: \u0026#34;497e6001-c4fb-df40-9e93-c09289477696\u0026#34;, \u0026#34;bucket\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;myapp-sample-bucket-123456789012\u0026#34;, \u0026#34;ownerIdentity\u0026#34;: { \u0026#34;principalId\u0026#34;: \u0026#34;FJF0VI7A2H51MM\u0026#34; }, \u0026#34;arn\u0026#34;: \u0026#34;arn:aws:s3:::myapp-sample-bucket-123456789012\u0026#34; }, \u0026#34;object\u0026#34;: { \u0026#34;key\u0026#34;: \u0026#34;Key1\u0026#34;, \u0026#34;size\u0026#34;: 5, \u0026#34;eTag\u0026#34;: \u0026#34;dcd0cda10b5681c4a9e9ff6fe9e95990\u0026#34;, \u0026#34;sequencer\u0026#34;: \u0026#34;F2B20061006075E34D\u0026#34; } } } ] } テンプレートの解説 まず、SNS トピックは次のような感じで簡単に定義できます。 Resources:MyTopic:Type:AWS::SNS::TopicProperties:... S3 バケットから SNS トピックに対して public できるようにする権限を設定するには、S3 バケットを作成する前に、次のような AWS::SNS::TopicPolicy リソースを作成しておく必要があります。 形としては、Topics プロパティで指定した SNS トピックに対して、PolicyDocument プロパティで定義したポリシーが割り当てられるという意味になります。 Resources:MyTopicPolicy:Type:AWS::SNS::TopicPolicyProperties:PolicyDocument:Id:\u0026lt;任意のID\u0026gt;Version:2012-10-17Statement:- Effect:AllowPrincipal:Service:s3.amazonaws.comAction:sns:PublishResource:\u0026lt;SNSトピックのARN\u0026gt;Condition:ArnLike:aws:SourceArn:\u0026lt;S3バケットのARN\u0026gt;Topics:- \u0026lt;SNSトピックのARN\u0026gt; S3 バケットの定義では、何らかの操作時（例えばオブジェクトの追加時）に、SNS トピックに対して publish を行うという指定を NotificationConfiguration プロパティで設定します。 この設定を行った状態で CloudFormation スタックを生成しようとすると、S3 バケットリソースの生成時に、SNS トピックポリシーが正しく設定されているかの確認が行われます。 そのため CloudFormation は、依存する SNS トピックポリシー（ここでは前述の MyTopicPolicy）を先に生成しようとします。 Resources:MyBucket:Type:AWS::S3::BucketProperties:NotificationConfiguration:TopicConfigurations:- Event:s3:ObjectCreated:PutTopic:\u0026lt;通知先のSNSトピックのARN\u0026gt; まとめると、次のような順序でリソースが生成されることになります（生成順序は CloudFormation が依存関係に基づいて判断するので、特に意識して記述する必要はありません）。 SNS トピック SNS トピックポリシー 定義内で「SNS トピック」と「S3 バケット」を指定する S3 バケット 適切な「SNS トピックポリシー」が先に定義されている必要がある ここで問題になるのは、2 番目のトピックポリシーの定義内で S3 バケットを指定するときに、まだ S3 バケットの生成が完了していないということです。 これは、CloudFormation によって 自動で割り当てられる S3 バケット名 (Physical ID) を使用できない ということを意味します。 例えば、トピックポリシーの定義で !Ref MyBucket のように S3 バケット名を参照しようとすると、そんなバケットはまだ定義されていないというエラーになります。 ResourceStatus: CREATE_FAILED ResourceStatusReason: \u0026#39;Unable to validate the following destination configurations (Service: Amazon S3; Status Code: 400; Error Code: InvalidArgument; Request ID: ... CloudFormation はできる限り依存関係を解決するような順序でリソースを構築していきますが、S3 バケットに TopicConfigurations を設定するときは、その振る舞いを許可するための SNS トピックポリシーが事前に生成されている必要があります。 そのため、S3 バケットを SNS トピックポリシーより先に構築することはできません。 これにより、鶏と卵の関係のような「循環参照エラー」が発生します。 この問題の解決方法は こちらの記事 に、以下の 2 種類が紹介されています。 入力パラメータなどを使って、S3 バケット名を事前に決めておく（管理する名前が増える・・・） S3 バケットの NotificationConfiguration を無効にした状態でスタックを生成してから、もう一度今度は有効にした状態でスタックを更新する（手作業すぎるでしょ・・・） いやいやこれは CloudFormation の設計ミスでしょと言いたくなるのをグッとこらえて、 とにかく何らかの方法で S3 バケット名を参照できるようにしなければいけないので、上記のテンプレート例では、S3 バケットの名前を入力パラメータ (BucketPrefix) で指定できるようにしています。 あと、ついでに SNS トピック名も入力パラメータ (TopicName) で指定できるようにしています。"
},
{
url: "/p/2it3bjs/",
title: "macOS のコマンドラインで ZIP ファイルを作成する",
date: "2021-04-06T00:00:00Z",
body: "macOS のコマンドラインで ZIP ファイルを作成する ZIP ファイルを作成する（zip コマンド） macOS に標準で付属している zip コマンドを使って、ファイル群を ZIP ファイルとしてアーカイブ（圧縮）できます。 ファイルを 1 つずつ指定する $ zip sample.zip 1.txt 2.txt 3.txt 作成される ZIP ファイル sample.zip +-- 1.txt +-- 2.txt +-- 3.txt ディレクトリごとまとめて ZIP 化する $ zip -r sample.zip dir1 dir2 作成される ZIP ファイル sample.zip +-- dir1/ | +-- 1.txt | +-- 2.txt | +-- 3.txt +-- dir2/ +-- 4.txt +-- 5.txt +-- 6.txt トップディレクトリを含めずに ZIP 化する 例: src ディレクトリ以下のファイルだけ圧縮 $ (cd src \u0026amp;\u0026amp; zip -r ../src.zip ./*) コマンド全体を括弧 () で囲んでいるのは、コマンド実行後にもとのディレクトリに戻るためです。 作成される ZIP ファイル src.zip +-- 1.txt +-- 2.txt +-- 3.txt 除外するファイルを指定する 例: ドットで始まるファイルを含めない $ zip -r sample.zip src -x \u0026#34;.*\u0026#34; -x オプションは複数指定することができます。"
},
{
url: "/p/6vs27aa/",
title: "AWS SDK for Node.js でプロキシ環境変数 (https_proxy) を反映させる",
date: "2021-03-29T00:00:00Z",
body: "AWS SDK for Node.js でプロキシ環境変数 (https_proxy) を反映させる AWS SDK for Node.js のプロキシ設定 社内のプロキシ環境下などから AWS SDK (for Node.js) を使って API 呼び出しを行うには、次のようにプロキシエージェント設定を行います。 ここでは、AWS SDK version 2 の設定例を示しています。 プロキシ設定の例 (AWS SDK v2) import * as AWS from \u0026#39;aws-sdk\u0026#39;; import { HttpsProxyAgent } from \u0026#39;https-proxy-agent\u0026#39;; AWS.config.update({ httpOptions: { agent: new HttpsProxyAgent(\u0026#39;http://proxy.example.com:8080\u0026#39;) } }); これで、それ以降の AWS サービス (AWS.S3 など）の API 呼び出しがプロキシ経由で行われるようになります。 環境変数 https_proxy の設定を使用する 次のようにすれば、環境変数 https_proxy に設定されたプロキシアドレスを、AWS SDK にも反映させることができます（といっても、process.env.https_proxy を参照しているだけです）。 import * as AWS from \u0026#39;aws-sdk\u0026#39;; import { HttpsProxyAgent } from \u0026#39;https-proxy-agent\u0026#39;; // プロキシ設定を反映 function setupAwsProxy() { const proxy = process.env.https_proxy; if (proxy) { AWS.config.update({ httpOptions: { agent: new HttpsProxyAgent(proxy) }, }); } } あとは、AWS の各種サービス用の API を使用するだけです。 async function putObjectToBucket() { setupAwsProxy(); // 環境変数のプロキシ設定を反映 const s3 = new AWS.S3(); try { const output = await s3.putObject({ Bucket: \u0026#39;my-s3-bucket-name\u0026#39;, Key: \u0026#39;key-1\u0026#39;, Body: \u0026#39;body-1\u0026#39; }).promise(); console.log(\u0026#39;SUCCESS - Object added:\u0026#39;, output); } catch (err) { console.error(\u0026#39;ERROR:\u0026#39;, err); } } putObjectToBucket();"
},
{
url: "/p/r9kv6gq/",
title: "Amazon S3 バケット用のポリシー設定例",
date: "2021-03-21T00:00:00Z",
body: "Amazon S3 バケット用のポリシー設定例 S3 用のポリシー設定例 指定したバケット内のオブジェクト一覧を取得できるようにする { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:ListBucket\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::\u0026lt;バケット名\u0026gt;\u0026#34; ] } ] } 指定したバケット内のオブジェクトの内容を取得できるようにする { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:GetObject\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::\u0026lt;バケット名\u0026gt;/*\u0026#34; ] } ] } 指定したバケットに対していろいろできるようにする { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:DeleteObject\u0026#34;, \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:ListBucket\u0026#34;, \u0026#34;s3:PutObject\u0026#34;, \u0026#34;s3:PutObjectAcl\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::\u0026lt;バケット名\u0026gt;\u0026#34;, \u0026#34;arn:aws:s3:::\u0026lt;バケット名\u0026gt;/*\u0026#34; ] } ] } すべての S3 リソースに対して何でもできるようにする { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:*\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } S3 で静的 Web サイトをホストするときは、バケットポリシーで s3:GetObject アクションのみを指定すればよい。ListObject や PutObject アクセス許可しなくても OK。 （おまけ）CORS 設定（JSON 形式） Web サイトの JavaScript などから S3 バケットにアクセスする場合は、バケットの設定で CORS アクセスを有効にしておく必要があります。 設定は次のように JSON 形式で行います。 [ { \u0026#34;AllowedHeaders\u0026#34;: [ \u0026#34;*\u0026#34; ], \u0026#34;AllowedMethods\u0026#34;: [ \u0026#34;HEAD\u0026#34;, \u0026#34;GET\u0026#34;, \u0026#34;PUT\u0026#34;, \u0026#34;POST\u0026#34;, \u0026#34;DELETE\u0026#34; ], \u0026#34;AllowedOrigins\u0026#34;: [ \u0026#34;*\u0026#34; ], \u0026#34;ExposeHeaders\u0026#34;: [ \u0026#34;ETag\u0026#34; ] } ]"
},
{
url: "/p/zmydq3f/",
title: "AWS Lambda にデプロイするための ZIP パッケージを npm で作成する (npm-pack-zip)",
date: "2021-03-20T00:00:00Z",
body: "AWS Lambda にデプロイするための ZIP パッケージを npm で作成する (npm-pack-zip) 何をするか？ AWS Lambda で実行する関数は、ZIP ファイルの形でデプロイすることになります。 ここでは、Node.js で関数を実装しているという前提で、npm スクリプトで簡単にデプロイ用の ZIP パッケージを作成する方法を説明します。 Lambda 関数用の ZIP パッケージを作成するときは、次のようなことを考慮する必要があります。 実行時に必要な node_modules 以下のモジュールを含める（逆に devDependencies で指定したモジュールは含めない。例えば typescript とか eslint とかは含めない） AWS SDK (aws-sdk) は含めない（Lambda の実行環境にインストールされている） TypeScript を使っているのであれば、ビルド後の .js ファイルのみを含める（例えば、src/*.ts は含めず、build/*.js を含める） ☝️ AWS Lambda レイヤー Lambda の「レイヤー」という機能を使うと、関数の実行に必要な node_modules を ZIP パッケージとは別に管理して、Lambda 関数から参照するということができます。 でも設定にひと手間かかります。AWS のこういうところは嫌いです。 ここでは、レイヤーの機能は使わずに、ZIP パッケージに全部入れちゃう方法を説明しています。 npm-pack-zip で ZIP ファイルを作成する npm-pack-zip とは ここでは、npm-pack-zip パッケージを使って、Lambda 関数のデプロイ用 ZIP パッケージを作ってみます。 npm-pack-zip - npm NPM には、もともと標準で npm pack というデプロイ用の NPM パッケージを作成する仕組みが搭載されています。 Lambda 用にもこれが使えると楽なのですが、残念ながら npm pack は .tgz 形式のパッケージしか作成できません。 npm-pack-zip をインストールすると、npm pack の仕組みをそのまま使い、.zip 形式のパッケージを作成することができます。 npm-pack-zip のインストール $ npm install npm-pack-zip --save-dev パッケージング設定 (package.json) npm-pack-zip のパッケージング設定は、npm pack と同様の仕組みで行います。 package.json の files が指定されている場合は、そこに指定されたファイル／ディレクトリのみをパッケージングする（node_modules は指定しなくて OK） package.json の bundledDependencies に指定された依存モジュールをパッケージングする（dependencies に記述した依存モジュールのうち、パッケージングしたいものの名前を列挙する） この仕組みは、npm-packlist モジュールによって提供されており、npm-pack-zip もこのモジュールを使っているので、npm pack と同じ設定方法が使えます。 例えばデプロイ対象として、build ディレクトリ以下のファイルと、js-yaml NPM モジュールを含めたいときは、package.json で次のように指定します。 files プロパティと bundledDependencies プロパティに注目してください。 packages.json { \u0026#34;name\u0026#34;: \u0026#34;hello-lambda\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1.0.0\u0026#34;, \u0026#34;scripts\u0026#34;: { \u0026#34;start\u0026#34;: \u0026#34;node build/index.js\u0026#34;, \u0026#34;build\u0026#34;: \u0026#34;tsc\u0026#34;, \u0026#34;build:watch\u0026#34;: \u0026#34;tsc --watch\u0026#34; }, \u0026#34;files\u0026#34;: [ \u0026#34;build\u0026#34; ], \u0026#34;dependencies\u0026#34;: { \u0026#34;js-yaml\u0026#34;: \u0026#34;^4.0.0\u0026#34; }, \u0026#34;bundledDependencies\u0026#34;: [ \u0026#34;js-yaml\u0026#34; ], \u0026#34;devDependencies\u0026#34;: { \u0026#34;@types/node\u0026#34;: \u0026#34;^14.14.35\u0026#34;, \u0026#34;npm-pack-zip\u0026#34;: \u0026#34;^1.2.9\u0026#34;, \u0026#34;typescript\u0026#34;: \u0026#34;^4.2.3\u0026#34; } } files プロパティも bundledDependencies プロパティも、値として配列 ([]) を指定することに注意してください（{} にするとエラーになります）。 dependencies で指定した NPM モジュールのうち、ZIP パッケージにも含めたいものの名前を bundledDependencies に列挙します（名前だけでバージョンは指定しません）。 ZIP パッケージを作成する 以上の設定が終われば、npm-pack-zip コマンドを実行して ZIP パッケージを作成できます（npx を使えば、npm-pack-zip コマンドは事前インストールなしでも実行できます）。 生成される ZIP ファイル名は、package.json の name プロパティによって自動的に決まります（ここでは hello-lambda.zip）。 ZIP パッケージの作成 $ npx npm-pack-zip ZIP パッケージを作成するコマンドは、次のように npm スクリプトにしておくと便利です。 ここでは、zip というスクリプト名にしました。 package.json { ... \u0026#34;scripts\u0026#34;: { ... \u0026#34;zip\u0026#34;: \u0026#34;npm-pack-zip\u0026#34; }, ... } こうしておけば、次のように ZIP パッケージを生成できます。 $ npm run build # TypeScript を使っているなら先にビルド $ npm run zip # デプロイ用の ZIP パッケージを作成 ちなみに、ここまでの設定通りに ZIP パッケージを作成していれば、その内容は次のようになります。 hello-lambda.zip の内容 hello-lambda.zip +-- build/ | +-- index.js +-- node-modules/ | +-- argparse/ | +-- js_yaml/ +-- package.json npm-packlist の仕様上、package.json がデフォルトで含まれてしまいますが、特に問題はないかと思います。 Lambda に ZIP パッケージをデプロイする デプロイ用の ZIP パッケージを作成できたら、あとは実際に AWS Lambda 上にデプロイするだけです。 ここでは、Lambda コンソール で、hello-lambda という名前の Lambda 関数を作成済みであるとします（ランタイムは Node.js 14.x などを選択）。 ハンドラー名を更新する 関数のエントリポイントとなるファイルを build/index.js などにした場合は、AWS 上の Lambda 関数のハンドラー設定もそれに合わせて変更しておく必要があります（デフォルトは index.handler になっているはず）。 例えば、AWS CLI を使って、次のようにハンドラー関数を指定できます（参考: AWS CLI の設定）。 ハンドラーを build/index.handler にする $ aws lambda update-function-configuration \\ --function-name hello-lambda \\ --handler build/index.handler --handler オプションで指定するハンドラー名は、ファイルのベース名.関数名 であることに注意してください。 ドットの後ろは拡張子の js ではなく、関数名の handler を指定します。 ZIP パッケージをデプロイする Lambda 関数の ZIP パッケージをデプロイするには、Web ブラウザの Lambda コンソールからポチポチやるか、AWS CLI でコマンドラインから次のように実行します。 （必要に応じて --region ap-northeast-1 なども追加） Lambda に ZIP パッケージをデプロイする $ aws lambda update-function-code \\ --function-name hello-lambda \\ --zip-file fileb://hello-lambda.zip 次のように NPM スクリプト化しておくのもいいかもしれません。 package.json { ... \u0026#34;scripts\u0026#34;: { ... \u0026#34;deploy\u0026#34;: \u0026#34;aws lambda update-function-code --function-name hello-lambda --zip-file fileb://hello-lambda.zip\u0026#34; }, ... } これで、次のように実行するだけで ZIP パッケージをデプロイできます。 $ npm run deploy Lambda 関数を実行する デプロイした Lambda 関数は AWS CLI の lambda invoke コマンドで呼び出すことができます。 $ aws lambda invoke --function-name hello-lambda response.json"
},
{
url: "/p/n9nydjc/",
title: "AWS Lambda をコマンドライン (CLI) で操作する",
date: "2021-03-12T00:00:00Z",
body: "AWS Lambda をコマンドライン (CLI) で操作する Lambda 関数の一覧を取得する (lambda list-functions) $ aws lambda list-functions --max-items 10 関数名だけ取り出す $ aws lambda list-functions --max-items 10 --query \u0026#34;Functions[].FunctionName\u0026#34; Node.js 10 を使ってる関数の ARN を調べる $ aws lambda list-functions --function-version ALL --output text --query \u0026#34;Functions[?Runtime==\u0026#39;nodejs10.x\u0026#39;].FunctionArn AWS から来た「Node.js 10 のサポート切れるから乗り換えてね」というメール (2021-06-04) に書かれていたやり方です。 Lambda 関数の情報を取得する (lambda get-function) $ aws lambda get-function --function-name my-function 実行結果 { \u0026#34;Configuration\u0026#34;: { \u0026#34;FunctionName\u0026#34;: \u0026#34;my-function\u0026#34;, \u0026#34;FunctionArn\u0026#34;: \u0026#34;arn:aws:lambda:ap-northeast-1:123456789012:function:my-function\u0026#34;, \u0026#34;Runtime\u0026#34;: \u0026#34;nodejs12.x\u0026#34;, \u0026#34;Role\u0026#34;: \u0026#34;arn:aws:iam::123456789012:role/lambda-ex\u0026#34;, \u0026#34;CodeSha256\u0026#34;: \u0026#34;FpFMvUhayLkOoVBpNuNiIVML/tuGv2iJQ7t0yWVTU8c=\u0026#34;, \u0026#34;Version\u0026#34;: \u0026#34;$LATEST\u0026#34;, \u0026#34;TracingConfig\u0026#34;: { \u0026#34;Mode\u0026#34;: \u0026#34;PassThrough\u0026#34; }, \u0026#34;RevisionId\u0026#34;: \u0026#34;88ebe1e1-bfdf-4dc3-84de-3017268fa1ff\u0026#34;, ... }, \u0026#34;Code\u0026#34;: { \u0026#34;RepositoryType\u0026#34;: \u0026#34;S3\u0026#34;, \u0026#34;Location\u0026#34;: \u0026#34;https://awslambda-ap-northeast-1-tasks.s3.ap-northeast-1.amazonaws.com/snapshots/123456789012/my-function-4203078a-b7c9-4f35-...\u0026#34; } } Lambda 関数のデプロイパッケージをダウンロードするために使用できる、Lambda 関数メタデータと署名付き URL が含まれています。 Lambda 関数を作成する (lambda create-function) $ aws lambda create-function --function-name my-function \\ --runtime nodejs12.x \\ --handler index.handler \\ --zip-file fileb://function.zip \\ --role arn:aws:iam::123456789012:role/lambda-ex 実行結果 { \u0026#34;FunctionName\u0026#34;: \u0026#34;my-function\u0026#34;, \u0026#34;FunctionArn\u0026#34;: \u0026#34;arn:aws:lambda:ap-northeast-1:123456789012:function:my-function\u0026#34;, \u0026#34;Runtime\u0026#34;: \u0026#34;nodejs12.x\u0026#34;, \u0026#34;Role\u0026#34;: \u0026#34;arn:aws:iam::123456789012:role/lambda-ex\u0026#34;, \u0026#34;Handler\u0026#34;: \u0026#34;index.handler\u0026#34;, \u0026#34;CodeSha256\u0026#34;: \u0026#34;FpFMvUhayLkOoVBpNuNiIVML/tuGv2iJQ7t0yWVTU8c=\u0026#34;, \u0026#34;Version\u0026#34;: \u0026#34;$LATEST\u0026#34;, \u0026#34;TracingConfig\u0026#34;: { \u0026#34;Mode\u0026#34;: \u0026#34;PassThrough\u0026#34; }, \u0026#34;RevisionId\u0026#34;: \u0026#34;88ebe1e1-bfdf-4dc3-84de-3017268fa1ff\u0026#34;, ... } タグを付けるときは、関数の作成時に次のようなオプションを追加します。 --tags Department=Marketing,CostCenter=1234ABCD Lambda 関数を削除する (lambda delete-function) $ aws lambda delete-function --function-name my-function Lambda 関数の ZIP パッケージをアップロードする (lambda update-function-code) aws lambda update-function-code \\ --function-name my-function \\ --zip-file fileb://function.zip 実行結果 { \u0026#34;FunctionName\u0026#34;: \u0026#34;my-function\u0026#34;, \u0026#34;FunctionArn\u0026#34;: \u0026#34;arn:aws:lambda:us-west-2:123456789012:function:my-function\u0026#34;, \u0026#34;Runtime\u0026#34;: \u0026#34;nodejs12.x\u0026#34;, \u0026#34;Role\u0026#34;: \u0026#34;arn:aws:iam::123456789012:role/lambda-role\u0026#34;, \u0026#34;Handler\u0026#34;: \u0026#34;index.handler\u0026#34;, \u0026#34;CodeSha256\u0026#34;: \u0026#34;Qf0hMc1I2di6YFMi9aXm3JtGTmcDbjniEuiYonYptAk=\u0026#34;, \u0026#34;Version\u0026#34;: \u0026#34;$LATEST\u0026#34;, \u0026#34;TracingConfig\u0026#34;: { \u0026#34;Mode\u0026#34;: \u0026#34;Active\u0026#34; }, \u0026#34;RevisionId\u0026#34;: \u0026#34;983ed1e3-ca8e-434b-8dc1-7d72ebadd83d\u0026#34;, ... } 参考リンク Windows のコマンドラインから zip ファイルを作成する (Compress-Archive) Lambda 関数を呼び出す (lambda invoke) Lambda 関数のレスポンスをファイルに取得する $ aws lambda invoke --function-name my-function output.yml ExecutedVersion: $LATEST StatusCode: 200 $ cat output.yml {\u0026#34;body\u0026#34;: \u0026#34;Hello World!\u0026#34;, \u0026#34;statusCode\u0026#34;: 200} Lambda 関数のリソースベースポリシー設定 Lambda のリソースベースポリシーは、他のサービスからの Lambda 関数へのアクセス許可設定を保持しています。 Lambda 関数は 1 つの リソースベースポリシー を持ち、その中にアクセス権限を表現する複数の ステートメント が含まれている、という構成になります。 Lambda 関数 ◇── ポリシー x 1 ◇── ステートメント x N ステートメントを追加する (lambda add-permission) 他のサービスに Lambda 関数を呼び出す権限を与えるには、Lambda 関数のリソースベースポリシーに、ステートメントを追加します。 例: すべての SNS トピックからの呼び出しを許可 $ aws lambda add-permission \\ --function-name my-function \\ --action lambda:InvokeFunction \\ --statement-id sns \\ --principal sns.amazonaws.com \\ Statement: \u0026#39;{\u0026#34;Sid\u0026#34;:\u0026#34;sns\u0026#34;,\u0026#34;Effect\u0026#34;:\u0026#34;Allow\u0026#34;,\u0026#34;Principal\u0026#34;:{\u0026#34;Service\u0026#34;:\u0026#34;sns.amazonaws.com\u0026#34;},\u0026#34;Action\u0026#34;:\u0026#34;lambda:InvokeFunction\u0026#34;,\u0026#34;Resource\u0026#34;:\u0026#34;arn:aws:lambda:ap-northeast-1:123456789012:function:my-function\u0026#34;}\u0026#39; この例では、sns という名前のステートメントを Lambda 関数のポリシーに追加しています。 コマンドの実行結果として、追加されたステートメントの内容（JSON 形式）が出力されます。 ここで割り当てたステートメント ID（上記の例では sns）は、ステートメントを削除する場合などに使用します。 上記の例では、すべての SNS トピックからのアクセスを許可していますが、特定の SNS トピックからの Lambda 関数呼び出し (lambda:InvokeFunction) を許可するには、--source-arn パラメータを追加で指定します。 例: 特定の SNS トピックからの呼び出しを許可 $ aws lambda add-permission \\ --function-name my-function \\ --action lambda:InvokeFunction \\ --statement-id sns-my-topic \\ --principal sns.amazonaws.com \\ --source-arn arn:aws:sns:ap-northeast-1:123456789012:my-topic Statement: \u0026#39;{\u0026#34;Sid\u0026#34;:\u0026#34;sns-my-topic\u0026#34;,\u0026#34;Effect\u0026#34;:\u0026#34;Allow\u0026#34;,\u0026#34;Principal\u0026#34;:{\u0026#34;Service\u0026#34;:\u0026#34;sns.amazonaws.com\u0026#34;},\u0026#34;Action\u0026#34;:\u0026#34;lambda:InvokeFunction\u0026#34;,\u0026#34;Resource\u0026#34;:\u0026#34;arn:aws:lambda:ap-northeast-1:123456789012:function:my-function\u0026#34;,\u0026#34;Condition\u0026#34;:{\u0026#34;ArnLike\u0026#34;:{\u0026#34;AWS:SourceArn\u0026#34;:\u0026#34;arn:aws:sns:ap-northeast-1:123456789012:my-topic\u0026#34;}}}\u0026#39; 例外的に S3 バケットの ARN にはアカウント ID が含まれないため、特定のアカウントの S3 バケットからのアクセスを許可するには、source-account パラメータでアカウントを指定する必要があります。 例: 特定の S3 バケットからの呼び出しを許可 $ aws lambda add-permission \\ --function-name my-function \\ --action lambda:InvokeFunction \\ --statement-id s3-account \\ --principal s3.amazonaws.com \\ --source-arn arn:aws:s3:::my-bucket-123456 \\ --source-account 123456789012 その他の例 すべての AppSync から Lambda 関数を呼び出せるようにする $ aws lambda add-permission \\ --function-name \u0026#34;my-function\u0026#34; \\ --action lambda:InvokeFunction \\ --statement-id \u0026#34;appsync\u0026#34; \\ --principal appsync.amazonaws.com \\ --output text 特定の AppSync から Lambda を呼び出せるようにする $ aws lambda add-permission \\ --function-name \u0026#34;my-function\u0026#34; \\ --action lambda:InvokeFunction \\ --statement-id \u0026#34;appsync\u0026#34; \\ --principal appsync.amazonaws.com \\ --source-arn \u0026#34;\u0026lt;AppSync API ARN\u0026gt;\u0026#34; \\ --output text ステートメントを削除する (lambda remove-permission) 例: sns という名前のポリシーステートメントを削除 $ aws lambda remove-permission \\ --function-name my-function \\ --statement-id sns リソースベースポリシーを取得する (lambda get-policy) 例: 関数に設定されたポリシーを表示 $ aws lambda get-policy \\ --function-name my-function \\ --query \u0026#34;Policy\u0026#34; --output text {\u0026#34;Version\u0026#34;:\u0026#34;2012-10-17\u0026#34;,\u0026#34;Id\u0026#34;:\u0026#34;default\u0026#34;,\u0026#34;Statement\u0026#34;:[{\u0026#34;Sid\u0026#34;:\u0026#34;sns\u0026#34;,\u0026#34;Effect\u0026#34;:\u0026#34;Allow\u0026#34;,\u0026#34;Principal\u0026#34;:{\u0026#34;Service\u0026#34;:\u0026#34;sns.amazonaws.com\u0026#34;},\u0026#34;Action\u0026#34;:\u0026#34;lambda:InvokeFunction\u0026#34;,\u0026#34;Resource\u0026#34;:\u0026#34;arn:aws:lambda:ap-northeast-1:123456789012:function:my-function\u0026#34;},{\u0026#34;Sid\u0026#34;:\u0026#34;sns-my-topic\u0026#34;,\u0026#34;Effect\u0026#34;:\u0026#34;Allow\u0026#34;,\u0026#34;Principal\u0026#34;:{\u0026#34;Service\u0026#34;:\u0026#34;sns.amazonaws.com\u0026#34;},\u0026#34;Action\u0026#34;:\u0026#34;lambda:InvokeFunction\u0026#34;,\u0026#34;Resource\u0026#34;:\u0026#34;arn:aws:lambda:ap-northeast-1:123456789012:function:my-function\u0026#34;,\u0026#34;Condition\u0026#34;:{\u0026#34;ArnLike\u0026#34;:{\u0026#34;AWS:SourceArn\u0026#34;:\u0026#34;arn:aws:sns:ap-northeast-1:123456789012:my-topic\u0026#34;}}}]} Lambda 関数のリソースベースポリシーの内容は、上記のような一行の JSON テキストとして保存されているので、そのままでは見にくいかもしれません。 下記はこの JSON レスポンスを Ruby で YAML 形式に整形する例です。 $ aws lambda get-policy \\ --function-name my-function \\ --query \u0026#34;Policy\u0026#34; --output text \\ | ruby -ryaml -e \u0026#39;puts YAML.load(STDIN).to_yaml\u0026#39; 実行結果 ---Version:\u0026#39;2012-10-17\u0026#39;Id:defaultStatement:- Sid:snsEffect:AllowPrincipal:Service:sns.amazonaws.comAction:lambda:InvokeFunctionResource:arn:aws:lambda:ap-northeast-1:123456789012:function:my-function- Sid:sns-my-topicEffect:AllowPrincipal:Service:sns.amazonaws.comAction:lambda:InvokeFunctionResource:arn:aws:lambda:ap-northeast-1:123456789012:function:my-functionCondition:ArnLike:AWS:SourceArn:arn:aws:sns:ap-northeast-1:123456789012:my-topic この Lambda 関数のポリシーとしては、sns と sns-my-topic というステートメントで、外部からのアクセスを許可していることがわかります。 Lambda 関数のタグを制御する タグを追加する (lambda tag-resource) $ aws lambda tag-resource \\ --resource arn:aws:lambda:ap-northeast-1:123456789012:function:my-func --tags Department=Marketing,CostCenter タグを削除する (lambda untag-resource) $ aws lambda untag-resource \\ --resource arn:aws:lambda:ap-northeast-1:123456789012:function:my-func --tag-keys Department タグの一覧を取得する (lambda list-tags) $ aws lambda list-tags \\ --resource arn:aws:lambda:ap-northeast-1:123456789012:function:my-func 実行結果 Tags: Key1: Value1 Key2: Value2 Key3: Value3 ARN じゃなくて関数名で取得したいのであれば、get-function で。 $ aws lambda get-function \\ --function-name my-func --query \u0026#34;Tags\u0026#34; 実行結果 Key1: Value1 Key2: Value2 Key3: Value3"
},
{
url: "/p/y42o4hw/",
title: "Windows のメモ",
date: "2021-03-09T00:00:00Z",
body: "Windows のメモ"
},
{
url: "/p/idmg7wm/",
title: "Windows のコマンドプロンプトで指定した秒数だけポーズする (timeout)",
date: "2021-03-09T00:00:00Z",
body: "Windows のコマンドプロンプトで指定した秒数だけポーズする (timeout) Windows 7 以降のコマンドプロンプトでは、指定した秒数だけ待機する timeout コマンドを使用できます。 ユーザーのキー入力を少しだけ待ったり、Linux の sleep コマンドと同様のことを行えます。 timeout コマンドの使用例 10 秒待つ（ユーザーのキー入力があるまで待つ） C:\\\u0026gt; timeout /t 10 10 秒待っています。続行するには何かキーを押してください ... 10 秒待つ（問答無用で待つ） C:\\\u0026gt; timeout /t 10 /nobreak 10 秒待っています。終了するには CTRL+C を押してください ... ユーザーのキー入力があるまでずっと待つ C:\\\u0026gt; timeout /t -1 続行するには何かキーを押してください ... 最後のパターンは、昔からある pause コマンドの振る舞いと同じですね（出力の行末表現が微妙に異なりますけど ^^;）。 C:\\\u0026gt; pause 続行するには何かキーを押してください . . . ちなみに、「続行するには何かキーを押してください」の表示を抑制したいときは、次のように \u0026gt; nul とリダイレクトします（null じゃなくて nul なので注意）。 これは、Linux の sleep 3 と同じ振る舞いになります。 何もメッセージ表示せずに 3 秒待機 C:\\\u0026gt; timeout /t 3 /nobreak \u0026gt; nul （参考）timeout コマンドのヘルプ C:\\\u0026gt; timeout /? TIMEOUT [/T] タイムアウト [/NOBREAK] 説明: このユーティリティでは、タイムアウトのパラメーターを指定して、一定の時間 (秒) が経過するまで、またはユーザーが任意のキーを押すまで、プログラムを待機 させることができます。 キー入力を無視するためのパラメーターを指定することもできます。 パラメーター一覧: /T タイムアウト 待機する時間 (秒) を指定します。 有効な範囲は -1 から 99999 秒までです。 /NOBREAK キーが押されても無視し、指定時間待ちます。 /? このヘルプを表示します。 注意: タイムアウト値 -1 は、キーが押されるまで無限に待機することを意味します。 例: TIMEOUT /? TIMEOUT /T 10 TIMEOUT /T 300 /NOBREAK TIMEOUT /T -1"
},
{
url: "/p/vin35f7/",
title: "Windows のコマンドラインで ZIP ファイルを作成する (Compress-Archive)",
date: "2021-03-03T00:00:00Z",
body: "Windows のコマンドラインで ZIP ファイルを作成する (Compress-Archive) Windows のコマンドプロンプト（あるいは PowerShell）から zip ファイルを作成するには、PowerShell の Compress-Archive コマンド を使用します。 特に何もインストールしなくても実行できます。 指定したディレクトリを zip 圧縮する src ディレクトリを dst.zip にアーカイブ C:\\\u0026gt; powershell compress-archive src dst 作成される zip ファイル dst.zip +-- src/ +-- file1 +-- file2 +-- file3 出力ファイル名 dst.zip の .zip は省略することができます。 dst.zip を展開すると、ルートに src ディレクトリが現れる状態になります。 ディレクトリ内のファイルのみを zip 圧縮する ルートディレクトリ（この例では src）を zip ファイルに含めずに、そのディレクトリ内のファイル群だけを zip ファイルにまとめたいときは、次のように src/* と指定します。 src ディレクトリの中身だけを dst.zip にアーカイブ C:\\\u0026gt; powershell compress-archive src/* dst 作成される zip ファイル dst.zip +-- file1 +-- file2 +-- file3 複数のディレクトリやファイルを zip 圧縮する 圧縮対象のディレクトリやファイルを複数指定するには、次のようにカンマ (,) で列挙します。 カンマの前後にはスペースを入れないことに注意してください。 build 以下のファイルと libs ディレクトリをアーカイブ C:\\\u0026gt; powershell compress-archive build/*,libs dst zip ファイルを上書きする すでに同じ名前の zip ファイルが存在するときに、強制的に上書きするときは -Force オプションを指定します。 すでに dst.zip があっても上書き C:\\\u0026gt; powershell compress-archive -Force src/* dst"
},
{
url: "/p/vdnv5dm/",
title: "Android アプリのテンプレートコード（空っぽのフラグメント）",
date: "2021-02-25T00:00:00Z",
body: "Android アプリのテンプレートコード（空っぽのフラグメント） Android のアプリを作るときは、大体まっさらな Activity + Fragment の組み合わせで作り始めるんですが、そのようなクリーンなテンプレートコード（土台）を作るのが意外と大変だったりするので、ここにメモしておきます。 図: 空っぽの Android アプリ 下記は、Android TV アプリ用のテンプレートです。 maku77/Template-AndroidTv: Template of Android TV App 主なコードを抜粋。 app/src/main/java/com/example/myapp/MainActivity.kt package com.example.myapp import android.os.Bundle import androidx.appcompat.app.AppCompatActivity import androidx.fragment.app.commit // androidx.fragment:fragment-ktx class MainActivity : AppCompatActivity() { override fun onCreate(savedInstanceState: Bundle?) { super.onCreate(savedInstanceState) setContentView(R.layout.activity_main) showMainFragment() } private fun showMainFragment() { supportFragmentManager.commit { add(R.id.fragment_container, MainFragment.newInstance()) //addToBackStack(null) // 戻るキー用にスタック } } } app/src/main/java/com/example/myapp/MainFragment.kt package com.example.myapp import androidx.fragment.app.Fragment class MainFragment : Fragment(R.layout.fragment_main) { companion object { fun newInstance() = MainFragment() } } app/src/main/AndroidManifest.xml \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;manifest xmlns:android=\u0026#34;http://schemas.android.com/apk/res/android\u0026#34; package=\u0026#34;com.example.myapp\u0026#34;\u0026gt; \u0026lt;uses-permission android:name=\u0026#34;android.permission.INTERNET\u0026#34; /\u0026gt; \u0026lt;uses-feature android:name=\u0026#34;android.hardware.touchscreen\u0026#34; android:required=\u0026#34;false\u0026#34; /\u0026gt; \u0026lt;uses-feature android:name=\u0026#34;android.software.leanback\u0026#34; android:required=\u0026#34;true\u0026#34; /\u0026gt; \u0026lt;application android:allowBackup=\u0026#34;true\u0026#34; android:icon=\u0026#34;@mipmap/ic_launcher\u0026#34; android:label=\u0026#34;@string/app_name\u0026#34; android:supportsRtl=\u0026#34;true\u0026#34; android:theme=\u0026#34;@style/Theme.AppCompat\u0026#34;\u0026gt; \u0026lt;activity android:name=\u0026#34;.MainActivity\u0026#34; android:banner=\u0026#34;@drawable/app_icon\u0026#34; android:icon=\u0026#34;@drawable/app_icon\u0026#34; android:label=\u0026#34;@string/app_name\u0026#34; android:logo=\u0026#34;@drawable/app_icon\u0026#34; android:screenOrientation=\u0026#34;landscape\u0026#34;\u0026gt; \u0026lt;intent-filter\u0026gt; \u0026lt;action android:name=\u0026#34;android.intent.action.MAIN\u0026#34; /\u0026gt; \u0026lt;category android:name=\u0026#34;android.intent.category.LEANBACK_LAUNCHER\u0026#34; /\u0026gt; \u0026lt;/intent-filter\u0026gt; \u0026lt;/activity\u0026gt; \u0026lt;/application\u0026gt; \u0026lt;/manifest\u0026gt; app/src/main/res/layout/activity_main.xml \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;FrameLayout xmlns:android=\u0026#34;http://schemas.android.com/apk/res/android\u0026#34; android:id=\u0026#34;@+id/fragment_container\u0026#34; android:layout_width=\u0026#34;match_parent\u0026#34; android:layout_height=\u0026#34;match_parent\u0026#34; /\u0026gt; \u0026lt;/FrameLayout\u0026gt; app/src/main/res/layout/fragment_main.xml \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;LinearLayout xmlns:android=\u0026#34;http://schemas.android.com/apk/res/android\u0026#34; android:orientation=\u0026#34;vertical\u0026#34; android:layout_width=\u0026#34;match_parent\u0026#34; android:layout_height=\u0026#34;match_parent\u0026#34;\u0026gt; \u0026lt;/LinearLayout\u0026gt;"
},
{
url: "/p/5398aih/",
title: "Android プログラミングのメモ",
date: "2021-02-25T00:00:00Z",
body: "Android プログラミングのメモ"
},
{
url: "/p/ct4ckt3/",
title: "AWS のコスト情報をコマンドライン (CLI) で取得する",
date: "2021-02-23T00:00:00Z",
body: "AWS のコスト情報をコマンドライン (CLI) で取得する aws ce get-cost-and-usage ... 次の例では、指定した期間の AWS 利用料金を求めています。 aws ce get-cost-and-usage \\ --granularity MONTHLY \\ --time-period Start=2021-01-01,End=2021-02-01 \\ --metrics BlendedCost 実行結果 DimensionValueAttributes:[]ResultsByTime:- Estimated:falseGroups:[]TimePeriod:End:\u0026#39;2021-02-01\u0026#39;Start:\u0026#39;2021-01-01\u0026#39;Total:BlendedCost:Amount:\u0026#39;0.0900932477\u0026#39;Unit:USD 次の例では、サービスごとに料金表示しています。 aws ce get-cost-and-usage \\ --granularity MONTHLY \\ --time-period Start=2021-01-01,End=2021-02-01 \\ --metrics BlendedCost \\ --group-by Type=DIMENSION,Key=SERVICE 実行結果 DimensionValueAttributes:[]GroupDefinitions:- Key:SERVICEType:DIMENSIONResultsByTime:- Estimated:falseGroups:- Keys:- AWS CloudShellMetrics:BlendedCost:Amount:\u0026#39;0.0000032477\u0026#39;Unit:USD- Keys:- AWS CodeCommitMetrics:BlendedCost:Amount:\u0026#39;0\u0026#39;Unit:USD- Keys:- AWS Key Management ServiceMetrics:BlendedCost:Amount:\u0026#39;0\u0026#39;Unit:USD- Keys:- AWS LambdaMetrics:BlendedCost:Amount:\u0026#39;0\u0026#39;Unit:USD- Keys:- Amazon Simple Notification ServiceMetrics:BlendedCost:Amount:\u0026#39;0\u0026#39;Unit:USD- Keys:- Amazon Simple Storage ServiceMetrics:BlendedCost:Amount:\u0026#39;0.00009\u0026#39;Unit:USD- Keys:- AmazonCloudWatchMetrics:BlendedCost:Amount:\u0026#39;0\u0026#39;Unit:USD- Keys:- CodeBuildMetrics:BlendedCost:Amount:\u0026#39;0.08\u0026#39;Unit:USD- Keys:- TaxMetrics:BlendedCost:Amount:\u0026#39;0.01\u0026#39;Unit:USDTimePeriod:End:\u0026#39;2021-02-01\u0026#39;Start:\u0026#39;2021-01-01\u0026#39;Total:{} サービスごとにコストを一行でシンプルに表示します。 $ aws ce get-cost-and-usage \\ --granularity MONTHLY \\ --time-period Start=2021-01-01,End=2021-02-01 --metrics BlendedCost \\ --group-by Type=DIMENSION,Key=SERVICE \\ --query \u0026#39;ResultsByTime[0].Groups[*].[Keys[0], Metrics.BlendedCost.Amount]\u0026#39; \\ --output=text 実行結果 AWS CloudShell 0.0000032477AWS CodeCommit 0AWS Key Management Service 0AWS Lambda 0Amazon Simple Notification Service 0Amazon Simple Storage Service 0.00009AmazonCloudWatch 0CodeBuild 0.08Tax 0.01"
},
{
url: "/p/rdq4eq2/",
title: "DynamoDB Local で DynamoDB のローカルテスト環境を作る",
date: "2021-02-23T00:00:00Z",
body: "DynamoDB Local で DynamoDB のローカルテスト環境を作る DynamoDB Local とは DynamoDB Local を使うと、Amazon DynamoDB サービスを模倣するローカルサーバーを立ち上げることができます。 DynamoDB Local サーバーは、デフォルトでは http://localhost:8000 で起動し、ここに対して AWS CLI や AWS SDK で接続して操作します。 DynamoDB ウェブサービスで複雑なデータ処理を行うときは、あらかじめ DynamoDB Local を使ってテストを行っておくと安心です。 DynamoDB の操作のために試行錯誤しても AWS の利用料金がかかることはありません。 DynamoDB Local のインストール 実行ファイルのダウンロード DynamoDB Local には、Java の実行ファイル (JAR) や、それを含む Docker コンテナとして提供されています。 Java のインストールされた環境では、JAR ファイルをダウンロードして起動するのが手っ取り早いです。 下記から ZIP ファイルでダウンロードできます。 DynamoDB Local のダウンロード ダウンロードした ZIP ファイルを展開すると、次のような構成のディレクトリが展開されます。 アーカイブの内容 dynamodb_local_latest/ +-- DynamoDBLocal_lib/ ... 本体が使う依存ライブラリ +-- DynamoDBLocal.jar ... 本体 +-- その他のドキュメント 起動に必要なのは、DynamoDBLocal_lib ディレクトリと DynamoDBLocal.jar だけなので、この 2 つを任意のディレクトリにコピーします。 ここでは、次のようなディレクトリにコピーすることにします（Windows であれば、$HOME は %USERPROFILE% に置き換えてください）。 適当な場所にコピー $HOME/mybin/dynamodb-local/ +-- DynamoDBLocal_lib/ +-- DynamoDBLocal.jar 起動用スクリプト（エイリアス）の作成 インストール自体はこれで終わりですが、DynamoDB Local サーバーを簡単に起動できるようにするために、dynamodb-local というコマンドラインエイリアスを定義しておきます。 macOS / Linux の場合 ~/.bash_profile DYNAMODB=~/mybin/dynamodb-local alias dynamodb-local=\u0026#39;java -Djava.library.path=$DYNAMODB/DynamoDBLocal_lib -jar $DYNAMODB/DynamoDBLocal.jar -sharedDb -dbPath $DYNAMODB\u0026#39; Windows の場合 Windows の場合は、サーバー起動用のバッチファイルを作ってしまうのが楽かもしれません。 例えば、環境変数 PATH に %USERPROFILE%\\mybin のパスを追加し、次のようなバッチファイルを作成します。 やっていることは、上記の macOS / Linux の場合と同様ですが、コマンドライン引数を受け取れるように末尾に %* を追加してます。 %USERPROFILE%\\mybin\\dynamodb-local.cmd @echo off setlocal set DYNAMODB=%USERPROFILE%\\mybin\\dynamodb-local java -Djava.library.path=%DYNAMODB%\\DynamoDBLocal_lib -jar %DYNAMODB%\\DynamoDBLocal.jar -sharedDb -dbPath %DYNAMODB% %* これで、どのディレクトリからでも dynamodb-local コマンドを実行するだけで、DyanmoDB Local サーバーを起動できるようになります。 上記の例では、DynamoDBLocal.jar に次のようなオプションを渡しています。 -sharedDb \u0026hellip; 使用するアクセスキーとリージョンごとにデータベースファイル (.db) を作らず、shared-local-instance.db という単一のファイルを作成する。 -dbPath $DYNAMODB \u0026hellip; 上記の .db ファイルをカレントディレクトリに生成せず、実行ファイルと同じ場所に生成する。 DynamoDB Local を使用する DynamoDB Local サーバーを起動する ここまでの設定が完了していれば、任意のディレクトリから次のように DynamoDB Local サーバーを起動することができます（終了は Ctrl + C です）。 $ dynamodb-local Initializing DynamoDB Local with the following configuration: Port: 8000 InMemory: false DbPath: null SharedDb: true shouldDelayTransientStatuses: false CorsParams: * サーバー起動時には、上記のようにコンフィグ値が表示され、ポート番号が 8000 番であることや、CORS アクセスが全て許可されている (*)、といったことが分かります。 これらの設定は、-port オプションや -cors オプションで変更することができます。 $ dynamodb-local -port 8123 コマンドラインオプションの詳細は、次のようにしてヘルプを表示するか、こちらのサイト で確認できます。 $ dynamodb-local --help 実行結果 usage: java -Djava.library.path=./DynamoDBLocal_lib -jar DynamoDBLocal.jar [-port \u0026lt;port-no.\u0026gt;] [-inMemory] [-delayTransientStatuses] [-dbPath \u0026lt;path\u0026gt;][-sharedDb] [-cors \u0026lt;allow-list\u0026gt;] -cors \u0026lt;arg\u0026gt; Enable CORS support for javascript against a specific allow-list list the domains separated by , use \u0026#39;*\u0026#39; for public access (default is \u0026#39;*\u0026#39;) -dbPath \u0026lt;path\u0026gt; Specify the location of your database file. Default is the current directory. -delayTransientStatuses When specified, DynamoDB Local will introduce delays to hold various transient table and index statuses so that it simulates actual service more closely. Currently works only for CREATING and DELETING online index statuses. -help Display DynamoDB Local usage and options. -inMemory When specified, DynamoDB Local will run in memory. -optimizeDbBeforeStartup Optimize the underlying backing store database tables before starting up the server -port \u0026lt;port-no.\u0026gt; Specify a port number. Default is 8000 -sharedDb When specified, DynamoDB Local will use a single database instead of separate databases for each credential and region. As a result, all clients will interact with the same set of tables, regardless of their region and credential configuration. (Useful for interacting with Local through the JS Shell in addition to other SDKs) DynamoDB Local に接続する DynamoDB Local サーバーを起動したら、AWS CLI（aws コマンド）で接続してみます。 基本的には DynamoDB ウェブサービスを操作するときと同様ですが、--endpoint-url オプションでサーバーのアドレスを指定する必要があります。 $ aws dynamodb list-tables --endpoint-url http://localhost:8000 TableNames: - Games - Musics ☝️ --region local オプション --endpoint-url http://localhost:8000 の代わりに、--region local でも DynamoDB Local に接続できるみたいです。 ただし、ポート番号を 8000 以外に変えた場合は接続できないので、--endpoint-url の方を使っておいた方が安心かもしれません。 （おまけ）間違ってウェブサービス側の DynamoDB を操作しないようにする AWS CLI（aws コマンド）を使う時に、--endpoint-url オプションを指定し忘れると、ウェブサービス側の DynamoDB を操作することになります。 このような誤操作でウェブサービス側のデータを更新してしまうのが心配なときは、次のようにアクセスキーに偽物の情報（ここでは fake）をセットした状態で AWS CLI コマンドを実行するようにします。 $ export AWS_ACCESS_KEY_ID=fake $ export AWS_SECRET_ACCESS_KEY=fake $ aws dynamodb list-tables --endpoint-url http://localhost:8000 TableNames: - Games - Musics このように設定すると、DynamoDB Local サーバーへのアクセスは可能なままで、ウェブサービス側の DynamoDB へのアクセスは認証エラーで弾かれるようになります。 ちなみに、aws dynamodb コマンドの --endpoint-url オプションに関しては、現状は環境変数などでデフォルト値を設定しておくことはできないようです。 下記は、DynamoDB ローカル使用に関する注意事項 - Amazon DynamoDB からの抜粋です。 注記：AWS CLI では、ダウンロード可能なバージョンの DynamoDB をデフォルトのエンドポイントとして使用することはできません。そのため、各 \u0026ndash;endpoint-url コマンドで AWS CLI を指定する必要があります。 毎回 --endpoint-url を指定するのも面倒なので、何らかの自動化を行いたい場合は、素直に AWS SDK を使って Node.js や Python のスクリプトを作った方がよさそうです。 SDK が生成するアクセス用インスタンスには、エンドポイント URL を指定できるようになっています。 （おまけ）プロキシ環境下で HTTP 301 エラーになる場合 社内のプロキシ環境内から AWS CLI で DynamoDB Local に接続するとき、次のようなエラーが発生することがあります。 $ aws dynamodb list-tables --endpoint-url http://localhost:8000 An error occurred (301) when calling the ListTables operation: \u0026lt;HTML\u0026gt; \u0026lt;HEAD\u0026gt;\u0026lt;TITLE\u0026gt;Redirection\u0026lt;/TITLE\u0026gt;\u0026lt;/HEAD\u0026gt; \u0026lt;BODY\u0026gt;\u0026lt;H1\u0026gt;Redirect\u0026lt;/H1\u0026gt;\u0026lt;/BODY\u0026gt; これは、http_proxy 環境変数が設定されていることが直接の原因になっています。　この環境変数を外すか、次のように localhost をプロキシ対象外に設定することで接続できるようになります。 ### Linux の場合 $ export NO_PROXY=localhost ### Windows の場合 $ setx NO_PROXY localhost 参考リンク Amazon DynamoDB — AWS SDK for JavaScript Amazon DynamoDB — Boto3 Docs documentation"
},
{
url: "/p/ucnv5ck/",
title: "Linuxコマンド: date コマンドの使い方",
date: "2021-02-23T00:00:00Z",
body: "Linuxコマンド: date コマンドの使い方 Linux や macOS に搭載されている date コマンドの使い方のメモです。 日時をフォーマットして出力する $ date +\u0026#39;%Y-%m-%d\u0026#39; 2021-02-23 $ date +\u0026#39;%Y-%m-%d %H:%M:%S\u0026#39; 2021-02-23 01:08:51 Linux と macOS の date コマンドの違い Linux と macOS では、標準でインストールされている date コマンドが次のように異なります。 Linux \u0026hellip; GUN/Linux 系の date コマンド macOS \u0026hellip; BSD 系の date コマンド そのため、-d オプションと -v オプションの使い方に次のような違いがあります。 1 カ月前の日付を調べる $ date -d \u0026#39;-1 month\u0026#39; # GNU/Linux $ date -d \u0026#39;1 month ago\u0026#39; # GNU/Linux $ date -v-1m # macOS 1 日前の日付を調べる $ date -d \u0026#39;-1 day\u0026#39; # GNU/Linux $ date -v-1d # macOS"
},
{
url: "/p/zkx9ju6/",
title: "Amazon EC2 をコマンドライン (CLI) で操作する",
date: "2021-02-22T00:00:00Z",
body: "Amazon EC2 をコマンドライン (CLI) で操作する EC2 で使用可能なリージョンの一覧を取得する (ec2 describe-regions) $ aws ec2 describe-regions 実行結果 (YAML形式） Regions:- Endpoint:ec2.eu-north-1.amazonaws.comOptInStatus:opt-in-not-requiredRegionName:eu-north-1- Endpoint:ec2.ap-south-1.amazonaws.comOptInStatus:opt-in-not-requiredRegionName:ap-south-1- Endpoint:ec2.eu-west-3.amazonaws.comOptInStatus:opt-in-not-requiredRegionName:eu-west-3- Endpoint:ec2.eu-west-2.amazonaws.comOptInStatus:opt-in-not-requiredRegionName:eu-west-2- Endpoint:ec2.eu-west-1.amazonaws.comOptInStatus:opt-in-not-requiredRegionName:eu-west-1- Endpoint:ec2.ap-northeast-3.amazonaws.comOptInStatus:opt-in-not-requiredRegionName:ap-northeast-3- Endpoint:ec2.ap-northeast-2.amazonaws.comOptInStatus:opt-in-not-requiredRegionName:ap-northeast-2- Endpoint:ec2.ap-northeast-1.amazonaws.comOptInStatus:opt-in-not-requiredRegionName:ap-northeast-1- Endpoint:ec2.sa-east-1.amazonaws.comOptInStatus:opt-in-not-requiredRegionName:sa-east-1- Endpoint:ec2.ca-central-1.amazonaws.comOptInStatus:opt-in-not-requiredRegionName:ca-central-1- Endpoint:ec2.ap-southeast-1.amazonaws.comOptInStatus:opt-in-not-requiredRegionName:ap-southeast-1- Endpoint:ec2.ap-southeast-2.amazonaws.comOptInStatus:opt-in-not-requiredRegionName:ap-southeast-2- Endpoint:ec2.eu-central-1.amazonaws.comOptInStatus:opt-in-not-requiredRegionName:eu-central-1- Endpoint:ec2.us-east-1.amazonaws.comOptInStatus:opt-in-not-requiredRegionName:us-east-1- Endpoint:ec2.us-east-2.amazonaws.comOptInStatus:opt-in-not-requiredRegionName:us-east-2- Endpoint:ec2.us-west-1.amazonaws.comOptInStatus:opt-in-not-requiredRegionName:us-west-1- Endpoint:ec2.us-west-2.amazonaws.comOptInStatus:opt-in-not-requiredRegionName:us-west-2 EC2 インスタンスの情報を取得する (ec2 describe-instances) 作成済みの EC2 インスタンスの一覧、あるいは指定した EC2 インスタンスの情報を取得します。 $ aws ec2 describe-instances 実行結果（YAML形式） Reservations:- Groups:[]Instances:- AmiLaunchIndex:0Architecture:x86_64BlockDeviceMappings:- DeviceName:/dev/xvdaEbs:AttachTime:\u0026#39;2021-03-02T14:26:39+00:00\u0026#39;DeleteOnTermination:trueStatus:attachedVolumeId:vol-3b75f0f9090990420CapacityReservationSpecification:CapacityReservationPreference:openClientToken:\u0026#39;\u0026#39;CpuOptions:CoreCount:1ThreadsPerCore:1EbsOptimized:falseEnaSupport:trueEnclaveOptions:Enabled:falseHibernationOptions:Configured:falseHypervisor:xenImageId:ami-e2e9e713809d28faaInstanceId:i-757968a71071691b7InstanceType:t2.nanoKeyName:ec2keyLaunchTime:\u0026#39;2021-03-02T15:32:17+00:00\u0026#39;MetadataOptions:HttpEndpoint:enabledHttpPutResponseHopLimit:1HttpTokens:optionalState:appliedMonitoring:State:disabledNetworkInterfaces:- Attachment:AttachTime:\u0026#39;2021-03-02T14:26:38+00:00\u0026#39;AttachmentId:eni-attach-c1c18b4c61083b1eaDeleteOnTermination:trueDeviceIndex:0NetworkCardIndex:0Status:attachedDescription:\u0026#39;\u0026#39;Groups:- GroupId:sg-650f7192f60271eb7GroupName:launch-wizard-1InterfaceType:interfaceIpv6Addresses:[]MacAddress:0a:a0:bf:37:7f:c1NetworkInterfaceId:eni-c8aea6d54ac8cc0d0OwnerId:\u0026#39;049344049957\u0026#39;PrivateDnsName:ip-172-31-0-95.ap-northeast-1.compute.internalPrivateIpAddress:172.31.0.95PrivateIpAddresses:- Primary:truePrivateDnsName:ip-172-31-0-95.ap-northeast-1.compute.internalPrivateIpAddress:172.31.0.95SourceDestCheck:trueStatus:in-useSubnetId:subnet-13e65081VpcId:vpc-af6e084dPlacement:AvailabilityZone:ap-northeast-1cGroupName:\u0026#39;\u0026#39;Tenancy:defaultPrivateDnsName:ip-172-31-0-95.ap-northeast-1.compute.internalPrivateIpAddress:172.31.0.95ProductCodes:[]PublicDnsName:\u0026#39;\u0026#39;RootDeviceName:/dev/xvdaRootDeviceType:ebsSecurityGroups:- GroupId:sg-650f7192f60271eb7GroupName:launch-wizard-1SourceDestCheck:trueState:Code:80Name:stoppedStateReason:Code:Client.UserInitiatedShutdownMessage: \u0026#39;Client.UserInitiatedShutdown:User initiated shutdown\u0026#39;StateTransitionReason:User initiated (2021-03-03 16:24:03 GMT)SubnetId:subnet-6508113eTags:- Key:NameValue:maku-test-ec2VirtualizationType:hvmVpcId:vpc-af6e084dOwnerId:\u0026#39;493440499570\u0026#39;ReservationId:r-09d469440a8ee4861 AMI の情報を取得する (ec2 describe-images) $ aws ec2 describe-images 作成した Amazon マシンイメージ (AMI) の一覧を表示することができます。 例: 最新の 5 つの AMI を新しい順に表示 $ aws ec2 describe-images \\ --owners self \\ --query \u0026#39;reverse(sort_by(Images,\u0026amp;CreationDate))[:5].{id:ImageId,date:CreationDate}\u0026#39; 実行結果（JSON形式） [ { \u0026#34;id\u0026#34;: \u0026#34;ami-0a1b2c3d4e5f60001\u0026#34;, \u0026#34;date\u0026#34;: \u0026#34;2018-11-28T17:16:38.000Z\u0026#34; }, { \u0026#34;id\u0026#34;: \u0026#34;ami-0a1b2c3d4e5f60002\u0026#34;, \u0026#34;date\u0026#34;: \u0026#34;2018-09-15T13:51:22.000Z\u0026#34; }, { \u0026#34;id\u0026#34;: \u0026#34;ami-0a1b2c3d4e5f60003\u0026#34;, \u0026#34;date\u0026#34;: \u0026#34;2018-08-19T10:22:45.000Z\u0026#34; }, { \u0026#34;id\u0026#34;: \u0026#34;ami-0a1b2c3d4e5f60004\u0026#34;, \u0026#34;date\u0026#34;: \u0026#34;2018-05-03T12:04:02.000Z\u0026#34; }, { \u0026#34;id\u0026#34;: \u0026#34;ami-0a1b2c3d4e5f60005\u0026#34;, \u0026#34;date\u0026#34;: \u0026#34;2017-12-13T17:16:38.000Z\u0026#34; } ] アタッチされた EBS ボリュームの情報を取得する (ec2 describe-volumes) $ aws ec2 describe-volumes EC2 インスタンスにアタッチされた Elastic Block Store (EBS) ボリュームの情報を調べることができます。 実行結果 { \u0026#34;Volumes\u0026#34;: [ { \u0026#34;AvailabilityZone\u0026#34;: \u0026#34;us-west-2a\u0026#34;, \u0026#34;Attachments\u0026#34;: [ { \u0026#34;AttachTime\u0026#34;: \u0026#34;2013-09-17T00:55:03.000Z\u0026#34;, \u0026#34;InstanceId\u0026#34;: \u0026#34;i-a071c394\u0026#34;, \u0026#34;VolumeId\u0026#34;: \u0026#34;vol-e11a5288\u0026#34;, \u0026#34;State\u0026#34;: \u0026#34;attached\u0026#34;, \u0026#34;DeleteOnTermination\u0026#34;: true, \u0026#34;Device\u0026#34;: \u0026#34;/dev/sda1\u0026#34; } ], \u0026#34;VolumeType\u0026#34;: \u0026#34;standard\u0026#34;, \u0026#34;VolumeId\u0026#34;: \u0026#34;vol-e11a5288\u0026#34;, \u0026#34;State\u0026#34;: \u0026#34;in-use\u0026#34;, \u0026#34;SnapshotId\u0026#34;: \u0026#34;snap-f23ec1c8\u0026#34;, \u0026#34;CreateTime\u0026#34;: \u0026#34;2013-09-17T00:55:03.000Z\u0026#34;, \u0026#34;Size\u0026#34;: 30 }, { \u0026#34;AvailabilityZone\u0026#34;: \u0026#34;us-west-2a\u0026#34;, \u0026#34;Attachments\u0026#34;: [ { \u0026#34;AttachTime\u0026#34;: \u0026#34;2013-09-18T20:26:16.000Z\u0026#34;, \u0026#34;InstanceId\u0026#34;: \u0026#34;i-4b41a37c\u0026#34;, \u0026#34;VolumeId\u0026#34;: \u0026#34;vol-2e410a47\u0026#34;, \u0026#34;State\u0026#34;: \u0026#34;attached\u0026#34;, \u0026#34;DeleteOnTermination\u0026#34;: true, \u0026#34;Device\u0026#34;: \u0026#34;/dev/sda1\u0026#34; } ], \u0026#34;VolumeType\u0026#34;: \u0026#34;standard\u0026#34;, \u0026#34;VolumeId\u0026#34;: \u0026#34;vol-2e410a47\u0026#34;, \u0026#34;State\u0026#34;: \u0026#34;in-use\u0026#34;, \u0026#34;SnapshotId\u0026#34;: \u0026#34;snap-708e8348\u0026#34;, \u0026#34;CreateTime\u0026#34;: \u0026#34;2013-09-18T20:26:15.000Z\u0026#34;, \u0026#34;Size\u0026#34;: 8 } ] } 仮想マシンを終了する (ec2 terminate-instances) $ aws ec2 terminate-instances --instance-ids \u0026#34;$INSTANCE_ID\u0026#34; 仮想マシンが起動・終了するまで待機 (ec2 wait) 起動するまで待機 ec2 run-instances で仮想マシンを起動したあと、起動完了まで待機したいときは次のようにします。 $ aws ec2 wait instance-running --instance-ids \u0026#34;$INSTANCE_ID\u0026#34; 終了するまで待機 ec2 terminate-instances で仮想マシンを終了したあと、終了完了まで待機したいときは次のようにします。 $ aws ec2 wait instance-terminated --instance-ids \u0026#34;$INSTANCE_ID\u0026#34; VPC の情報を取得する (ec2 describe-vpcs) 全 VPC の情報を取得する $ aws ec2 describe-vpcs 実行結果（YAML形式） Vpcs:- CidrBlock:172.31.0.0/16CidrBlockAssociationSet:- AssociationId:vpc-cidr-assoc-3d305bd3CidrBlock:172.31.0.0/16CidrBlockState:State:associatedDhcpOptionsId:dopt-6fa8cf64InstanceTenancy:defaultIsDefault:trueOwnerId:\u0026#39;049344049957\u0026#39;State:availableVpcId:vpc-af6e084d VPC の ID だけ取得する $ aws ec2 describe-vpcs --query \u0026#34;Vpcs[0].VpcId\u0026#34; --output text vpc-af6e084d サブネットの情報を取得する (ec2 describe-subnets) $ aws ec2 describe-subnets 実行結果（YAML形式） Subnets:- AssignIpv6AddressOnCreation:falseAvailabilityZone:ap-northeast-1aAvailabilityZoneId:apne1-az4AvailableIpAddressCount:4091CidrBlock:172.31.32.0/20DefaultForAz:trueIpv6CidrBlockAssociationSet:[]MapCustomerOwnedIpOnLaunch:falseMapPublicIpOnLaunch:trueOwnerId:\u0026#39;049344049957\u0026#39;State:availableSubnetArn:arn:aws:ec2:ap-northeast-1:049344049957:subnet/subnet-cd6e2662SubnetId:subnet-cd6e2662VpcId:vpc-af6e084d- AssignIpv6AddressOnCreation:falseAvailabilityZone:ap-northeast-1dAvailabilityZoneId:apne1-az2AvailableIpAddressCount:4091CidrBlock:172.31.16.0/20DefaultForAz:trueIpv6CidrBlockAssociationSet:[]MapCustomerOwnedIpOnLaunch:falseMapPublicIpOnLaunch:trueOwnerId:\u0026#39;049344049957\u0026#39;State:availableSubnetArn:arn:aws:ec2:ap-northeast-1:049344049957:subnet/subnet-3d7d568bSubnetId:subnet-3d7d568bVpcId:vpc-af6e084d- AssignIpv6AddressOnCreation:falseAvailabilityZone:ap-northeast-1cAvailabilityZoneId:apne1-az1AvailableIpAddressCount:4090CidrBlock:172.31.0.0/20DefaultForAz:trueIpv6CidrBlockAssociationSet:[]MapCustomerOwnedIpOnLaunch:falseMapPublicIpOnLaunch:trueOwnerId:\u0026#39;049344049957\u0026#39;State:availableSubnetArn:arn:aws:ec2:ap-northeast-1:049344049957:subnet/subnet-113e6508SubnetId:subnet-113e6508VpcId:vpc-af6e084d"
},
{
url: "/p/bwamw8i/",
title: "AWS CodeBuild をコマンドライン (CLI) から操作する",
date: "2021-02-22T00:00:00Z",
body: "AWS CodeBuild をコマンドライン (CLI) から操作する CodeBuild プロジェクトの一覧を取得する (codebuild list-projects) $ aws codebuild list-projects 例: すべてのプロジェクト名を取得 $ aws codebuild list-projects projects: - app1-codebuild - app2-codebuild - app3-codebuild 出力結果をソートするには、次のオプションが使用できます。 sort-by \u0026hellip; NAME / CREATED_TIME / LAST_MODIFIED_TIME のいずれかを指定 sort-order .. ASCENDING / DESCENDING のいずれかを指定 例: 最近作られたプロジェクトを 5 件表示 $ aws codebuild list-projects --sort-by CREATED_TIME --sort-order DESCENDING --max-items 5 実行結果 NextToken: eyJuZXh0VG9rZW4iOiBudWxsLCAiYm90b190cnVuY2F0ZV9hbW91bnQiOiA1fQ== projects: - myapp25-codebuild - myapp24-codebuild - myapp23-codebuild - myapp22-codebuild - myapp21-codebuild NextToken は、続きのエントリを取得したいときに、--starting-token オプションで指定します。 ☝️ 出力形式 (YAML or JSON) を変えたいとき AWS CLI の出力形式は、デフォルトでは ~/.aws/config ファイルの output プロパティで指定されている出力形式が使用されます。 明示的に出力形式を指定したい場合は、各コマンド実行時に --output yaml や --output json のようなオプション指定を行います。 参考: AWS の初期設定: AWS CLI のセットアップ ☝️ 存在するはずのプロジェクトが見つからない 作成したはずの CodeBuild プロジェクトがリストに出てこない場合は、CodeBuild プロジェクトの リージョン と、AWS CLI が対象としているリージョンが異なっている可能性があります。 aws configure list コマンドで AWS CLI が使用しているリージョンを確認し、想定と違うようでしたら、下記のようにリージョンを明示してコマンドを実行してみてください。 $ aws codebuild list-projects --region ap-northeast-1 CodeBuild プロジェクトの設定を取得する (codebuild batch-get-projects) $ aws codebuild batch-get-projects --names \u0026lt;プロジェクト名1\u0026gt; \u0026lt;プロジェクト名2\u0026gt;... 実行例 aws codebuild batch-get-projects --names app1-codebuild 実行結果 projects: - arn: arn:aws:codebuild:ap-northeast-1:123456789012:project/app1-codebuild artifacts: encryptionDisabled: false location: myapp-123456789012-output-bucket name: app1-codebuild namespaceType: NONE overrideArtifactName: false packaging: NONE path: \u0026#39;\u0026#39; type: S3 badge: badgeEnabled: false cache: type: NO_CACHE created: \u0026#39;2021-03-03T22:12:32.120000+09:00\u0026#39; encryptionKey: arn:aws:kms:ap-northeast-1:123456789012:alias/aws/s3 environment: computeType: BUILD_GENERAL1_SMALL environmentVariables: [] image: aws/codebuild/amazonlinux2-x86_64-standard:3.0 imagePullCredentialsType: CODEBUILD privilegedMode: false type: LINUX_CONTAINER lastModified: \u0026#39;2021-03-03T22:12:32.120000+09:00\u0026#39; logsConfig: cloudWatchLogs: status: ENABLED s3Logs: encryptionDisabled: false status: DISABLED name: app1-codebuild queuedTimeoutInMinutes: 480 secondaryArtifacts: [] secondarySourceVersions: [] secondarySources: [] serviceRole: arn:aws:iam::123456789012:role/service-role/app1-codebuild-service-role source: insecureSsl: false location: myapp-123456789012-input-bucket/app.zip type: S3 tags: - key: project value: TempProject timeoutInMinutes: 60 projectsNotFound: [] CodeBuild プロジェクトの設定を変更する (codebuild update-project) aws codebuild batch-get-projects コマンドで取得したプロジェクトの設定情報（YAML or JSON 形式）をもとに、設定の一部を変更することができます。 まずは、元の設定情報を YAML ファイルに保存しておきます。 出力形式を --output yaml オプションで明示しておいた方が安全かもしれません。 $ aws codebuild batch-get-projects --names app1-codebuild \u0026gt; projects.yml 出力結果の YAML ファイルは次のような感じになっています。 codebuild batch-get-projects コマンドは複数のプロジェクトの情報を取得するコマンドなので、ルートプロパティとして projects があり、そこに配列形式で各プロジェクトの情報が含まれています。 projects.yml projects:- arn:arn:aws:codebuild:ap-northeast-1:123456789012:project/app1-codebuildartifacts:encryptionDisabled:falselocation:app1-123456789012-output-bucketname:app1-codebuildnamespaceType:NONEoverrideArtifactName:falsepackaging:NONEpath:\u0026#39;\u0026#39;type:S3badge:badgeEnabled:false... 設定の変更には、aws codebuild update-project コマンドを使用するのですが、このコマンドは単一プロジェクトの設定更新を目的としているので、上記の YAML ファイルの構造を少し変更して、単一プロジェクトの情報だけを示す YAML ファイルに書き換えないといけません（といっても一階層減らすだけです）。 例えば、artifacts 設定（ここではバケット名）を変えるには、次のような YAML ファイルを用意します。 change.yml name:app1-codebuildartifacts:encryptionDisabled:falselocation:app1-123456789012-output-bucket-CHANGEDname:app1-codebuildnamespaceType:NONEoverrideArtifactName:falsepackaging:NONEpath:\u0026#39;\u0026#39;type:S3 少なくとも、対象の CodeBuild プロジェクト名を示す name プロパティと、変更対象のプロパティ（とその兄弟プロパティ）が記載されている必要があるようです。 あとは、次のように、このファイルを使って CodeBuild プロジェクトの設定を更新することができます。 CodeBuild プロジェクトの設定を変更する $ aws codebuild update-project --cli-input-yaml file://change.yml 入力ファイルを JSON 形式で作成したいときは、--cli-input-yaml の部分を --cli-input-json に変更すれば読み込めます。 CodeBuild プロジェクトを削除する aws codebuild delete-project --name \u0026lt;プロジェクト名\u0026gt; 何も削除されなかった場合もエラー表示は出ないので、実行後は aws codebuild list-projects で消えているか確認してください。 ビルド履歴を表示する $ aws codebuild list-builds ids: - build-hello:c8db24a0-9dc0-4cb3-9c47-2557502f0a59 - build-hello:de7dba14-e397-4fed-9e06-f7b98d25fb46 - build-hello:bf727395-ea1e-4266-a1d7-6217b909d729 - build-hello:67b5de96-4b4e-49ab-8eaa-c0781740597b - build-hello:40bbb789-20b3-419b-9f41-8fd42e414a02 - build-hello:3901c823-a6a3-4d16-bff2-66b1f80a25e4 - build-hello:18a32311-de0e-4d08-b7e2-ba1ce207ff27 - build-hello:0afacf09-c930-476f-a948-f62dbc33c1d4"
},
{
url: "/p/zkzamw8/",
title: "DynamoDB をコマンドライン (CLI) で操作する",
date: "2021-02-22T00:00:00Z",
body: "DynamoDB をコマンドライン (CLI) で操作する テーブルを作成する (dynamodb create-table) aws dynamodb create-table --table-name \u0026lt;テーブル名\u0026gt; ... DynamoDB のテーブルを作成するときは、少なくともプライマリキーの設定や、課金モードの設定が必要になるので、少しだけコマンドが長くなります。 次の例では、DynamoDB に MusicCollection というテーブルを作成します。 Artist というパーティションキー (KeyType=HASH) と、Artist というソートキー (KeyType=RANGE) を定義しています。 課金体系は「プロビジョンドモード」で最小構成になるよう設定しています。 テーブル生成 (PartitionKey \u0026#43; SortKey) $ aws dynamodb create-table \\ --table-name MusicCollection \\ --attribute-definitions AttributeName=Artist,AttributeType=S AttributeName=SongTitle,AttributeType=S \\ --key-schema AttributeName=Artist,KeyType=HASH AttributeName=SongTitle,KeyType=RANGE \\ --provisioned-throughput ReadCapacityUnits=1,WriteCapacityUnits=1 パーティションキーのみで良い場合（ソートキーなし）は、次のような感じになります。 テーブル生成 (PartitionKey) $ aws dynamodb create-table \\ --table-name MusicCollection \\ --attribute-definitions AttributeName=Artist,AttributeType=S \\ --key-schema AttributeName=Artist,KeyType=HASH \\ --provisioned-throughput ReadCapacityUnits=1,WriteCapacityUnits=1 キャパシティモード（課金体系）をオンデマンド（本当にアクセスした分だけの支払い）にするには、--billing-mode PAY_PER_REQUEST オプションを指定し、プロビジョン設定 (--provisioned-throughput) を省略します。 一定間隔でそれなりにアクセスがある場合は、プロビジョンドモード (PROVISIONED) にして常時稼働の形にしておいた方が総合的に安くなるようですが、テスト用途で作成する場合などは PAY_PER_REQUEST にしておくのが無難かと思います。 テーブル生成（ハッシュキーのみ） $ aws dynamodb create-table \\ --table-name Books \\ --attribute-definitions AttributeName=BookId,AttributeType=S \\ --key-schema AttributeName=BookId,KeyType=HASH \\ --billing-mode PAY_PER_REQUEST テーブル定義を YAML ファイルや JSON ファイルに記述しておいて、それを読み込むこともできます。 テーブル定義をJSONファイルで指定する $ aws dynamodb create-table --cli-input-json file://{JSONファイルの相対パス} テーブルを削除する (dynamodb delete-table) aws dynamodb delete-table --table-name \u0026lt;テーブル名\u0026gt; テーブルの詳細情報を取得する (dynamodb describe-table) aws dynamodb describe-table 次の例では、Games テーブルの情報表示しています。 DynamoDB は基本的にスキーマレスなので、主にプライマリキー（Partition キー (HASH) と Sort キー (RANGE)）の情報だけ表示されます。 実行例（YAML形式） $ aws dynamodb describe-table --table-name Games --output yaml Table: AttributeDefinitions: - AttributeName: Hardware AttributeType: S - AttributeName: GameId AttributeType: S CreationDateTime: \u0026#39;2021-07-21T16:54:17.255000+09:00\u0026#39; ItemCount: 2 KeySchema: - AttributeName: Hardware KeyType: HASH - AttributeName: GameId KeyType: RANGE ProvisionedThroughput: LastDecreaseDateTime: \u0026#39;1970-01-01T09:00:00+09:00\u0026#39; LastIncreaseDateTime: \u0026#39;1970-01-01T09:00:00+09:00\u0026#39; NumberOfDecreasesToday: 0 ReadCapacityUnits: 1 WriteCapacityUnits: 1 TableArn: arn:aws:dynamodb:ddblocal:000000000000:table/Games TableName: Games TableSizeBytes: 134 TableStatus: ACTIVE テーブルにアイテムを追加する (dynamodb put-item) aws dynamodb put-item 次の例では、MusicCollection テーブルにアイテム（項目）を 1 つ追加します。 実行例 $ aws dynamodb put-item \\ --table-name MusicCollection \\ --item \u0026#39;{ \u0026#34;Artist\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;No One You Know\u0026#34;}, \u0026#34;SongTitle\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;Call Me Today\u0026#34;} , \u0026#34;AlbumTitle\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;Somewhat Famous\u0026#34;} }\u0026#39; \\ --return-consumed-capacity TOTAL { \u0026#34;ConsumedCapacity\u0026#34;: { \u0026#34;CapacityUnits\u0026#34;: 1.0, \u0026#34;TableName\u0026#34;: \u0026#34;MusicCollection\u0026#34; } } テーブルから全てのアイテムを読み取る (dyanmodb scan) aws dynamodb scan 次の例では、Games テーブル内のすべてアイテムを取得しています。 実行例（YAML形式） $ aws dynamodb scan --table-name Games --output yaml ConsumedCapacity: null Count: 2 Items: - GameId: S: 1990-SuperMarioWorld Hardware: S: SNES Maker: S: Nintendo Title: S: Super Mario World - GameId: S: 1983-DonkeyKong Genre: S: ACT Hardware: S: NES Players: N: \u0026#39;2\u0026#39; Title: S: Donkey Kong ScannedCount: 2 テーブルから 1 つのアイテムを読み取る (dynamodb get-item) aws dynamodb get-item 次の例では、my-table という名前の DynamoDB テーブルからアイテムを取得します。 実行例 $ aws dynamodb get-item --table-name my-table --key \u0026#39;{\u0026#34;id\u0026#34;: {\u0026#34;N\u0026#34;:\u0026#34;1\u0026#34;}}\u0026#39; { \u0026#34;Item\u0026#34;: { \u0026#34;name\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;John\u0026#34; }, \u0026#34;id\u0026#34;: { \u0026#34;N\u0026#34;: \u0026#34;1\u0026#34; } } }"
},
{
url: "/p/aov4bho/",
title: "AWS IAM の設定をコマンドライン (CLI) で行う",
date: "2021-02-07T00:00:00Z",
body: "AWS IAM の設定をコマンドライン (CLI) で行う AWS CLI（aws コマンド）を使うと、様々な IAM 系の操作をコマンドラインから実行できるようになります。 ただし、IAM の制御を行えるのは、AdministratorAccess ポリシーなどが割り当てられ、IAM 操作の権限が付いているユーザーに限られます。 iam \u0026ndash; AWS CLI Command Reference ユーザー関連 IAM ユーザーを作成する (iam create-user) aws iam create-user --user-name \u0026lt;ユーザー名\u0026gt; 実行例 $ aws iam create-user --user-name user-1 --output yamlUser:Arn:arn:aws:iam::049957049344:user/user-1CreateDate:\u0026#39;2021-11-01T08:41:29+00:00\u0026#39;Path:/UserId:AIDAQXINMCQAPJRMFE22HUserName:user-1 iam create-user コマンドを使うと、指定した名前の IAM ユーザーを作成できます。 作成したユーザーの情報は、iam get-user や iam list-users コマンドで取得できます。 作成したユーザー用の API アクセスキーを生成するには、ひきつづき iam create-access-key コマンドを使用します。 IAM ユーザーを削除する (iam delete-user) aws iam delete-user --user-name \u0026lt;ユーザー名\u0026gt; 指定したユーザーに何らかの設定情報（アクセスキーや SSH キー、MFA など）が設定されている場合は、先にそれらの情報を削除しておく必要があります。 例えば、アクセスキーが設定されている場合は、delete-access-key コマンドで削除してからユーザー自体を削除します。 指定したユーザーの情報を取得する (iam get-user) aws iam get-user --user-name \u0026lt;ユーザー名\u0026gt; 実行例 $ aws iam get-user --user-name user-1 --output yamlUser:Arn:arn:aws:iam::049957049344:user/user-1CreateDate:\u0026#39;2021-11-01T08:33:41+00:00\u0026#39;Path:/UserId:AIDAQXINMCQANAORXL7JVUserName:user-1 ユーザーの一覧を取得する (iam list-users) ユーザーの一覧を取得 $ aws iam list-users 実行例 $ aws iam list-users --output yamlUsers:- Arn:arn:aws:iam::123456789012:user/AdminCreateDate:\u0026#39;2014-10-16T16:03:09+00:00\u0026#39;PasswordLastUsed:\u0026#39;2016-06-03T18:37:29+00:00\u0026#39;Path:/UserId:AIDA1111111111EXAMPLEUserName:Admin- Arn:arn:aws:iam::123456789012:user/backup/backup-userCreateDate:\u0026#39;2019-09-17T19:30:40+00:00\u0026#39;Path:/backup/UserId:AIDA2222222222EXAMPLEUserName:arq-45EFD6D1-CE56-459B-B39F-F9C1F78FBE19- Arn:arn:aws:iam::123456789012:user/cli-userCreateDate:\u0026#39;2019-09-17T19:30:40+00:00\u0026#39;Path:/UserId:AIDA3333333333EXAMPLEUserName:cli-user --query オプションで、取得結果をフィルタリングすることができます。 例: ユーザー名だけの一覧 $ aws iam list-users --output yaml \\ --query=\u0026#34;Users[].UserName\u0026#34; - UserName1 - UserName2 - UserName3 - ... 例: ユーザー名と作成日、ログイン日の一覧 $ aws iam list-users --output text \\ --query \u0026#34;Users[].[UserName,CreateDate,PasswordLastUsed]\u0026#34; UserName1 2018-08-07T00:22:35+00:00 2021-01-21T04:08:20+00:00 UserName2 2017-08-28T15:51:00+00:00 2020-05-14T02:25:36+00:00 アクセスキー関連 アクセスキーの一覧を表示する (iam list-access-keys) # CLI 使用中のユーザーのアクセスキーを表示 $ aws iam list-access-keys # 指定したユーザーのアクセスキーを表示 $ aws iam list-access-keys --user-name=ユーザー名 アクセスキーを作成する (iam create-access-key) # CLI 使用中のユーザーのアクセスキーを作成 aws iam create-access-key # 指定したユーザーのアクセスキーを作成 aws iam create-access-key --user-name \u0026lt;ユーザー名\u0026gt; 実行例 $ aws iam create-access-key --user-name user1 --output yamlAccessKey:AccessKeyId:AKIAQXINMCQALYKGR5JJCreateDate:\u0026#39;2021-11-01T08:56:09+00:00\u0026#39;SecretAccessKey:epTZAVL+1lfsJt94UUp7WULPwt0NTdP58Dhp7E5vStatus:ActiveUserName:user1 アクセスキーは、1 つの IAM ユーザーに対して 2 つまで生成できるようになっています。 ただし、これはキーのローテーションを行うための措置であって、普段使いのためのものではないので注意しましょう。 アクセスキーを削除する (iam delete-access-key) $ aws iam delete-access-key --access-key-id \u0026lt;アクセスキーID\u0026gt; \\ --user-name \u0026lt;ユーザー名\u0026gt; カレントユーザーのアクセスキーを削除する場合は、--user-name オプションは省略できます。 アクセスキーが最後に使われた日を調べる (iam get-access-key-last-used) $ aws iam get-access-key-last-used --access-key-id=アクセスキーID グループ関連 グループの一覧を表示する (list-groups) # すべての情報 $ aws iam list-groups # グループ名だけを一覧表示 $ aws iam list-groups --query=\u0026#39;Groups[].GroupName\u0026#39; 指定したグループの情報を取得する (get-group) $ aws iam get-group --group-name \u0026lt;グループ名\u0026gt; 指定したグループの情報と、所属するユーザーの一覧が表示されます。 ユーザーをグループに登録する (add-user-to-group) $ aws iam add-user-to-group --user-name \u0026lt;ユーザー名\u0026gt; --group-name \u0026lt;グループ名\u0026gt; ユーザーが所属するグループを表示する (list-groups-for-user) # すべての情報 $ aws iam list-groups-for-user --user-name \u0026lt;ユーザー名\u0026gt; # ARN のみを一覧表示 $ aws iam list-groups-for-user --user-name \u0026lt;ユーザー名\u0026gt; --query \u0026#39;Groups[].Arn\u0026#39; 実行例 $ aws iam list-groups-for-user --user-name susan --output text \\ --query \u0026#34;Groups[].GroupName\u0026#34; HRDepartment Developers SpreadsheetUsers LocalAdmins $ aws iam list-groups-for-user --user-name susan --output text \\ --query \u0026#34;Groups[].[GroupName]\u0026#34; HRDepartment Developers SpreadsheetUsers LocalAdmins ポリシー関連 マネージドポリシーの一覧を表示する (iam list-policies) # すべてのマネージドポリシーを表示（大量） $ aws iam list-policies # ARN のみを一覧表示 $ aws iam list-policies --query=\u0026#39;Policies[].Arn\u0026#39; # 現在何らかのユーザー、グループ、ロールにアタッチされているマネージドポリシー $ aws iam list-policies --only-attached 指定したマネージドポリシーの情報を取得する (iam get-policy) aws iam get-policy --policy-arn \u0026lt;ARN\u0026gt; 実行例 $ aws iam get-policy --output yaml \\ --policy-arn arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole Policy: Arn: arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole AttachmentCount: 0 CreateDate: \u0026#39;2015-04-09T15:03:43+00:00\u0026#39; DefaultVersionId: v1 Description: Provides write permissions to CloudWatch Logs. IsAttachable: true Path: /service-role/ PermissionsBoundaryUsageCount: 0 PolicyId: ANPAJNCQGXC42545SKXIK PolicyName: AWSLambdaBasicExecutionRole UpdateDate: \u0026#39;2015-04-09T15:03:43+00:00\u0026#39; ユーザーに割り当てられたマネージドポリシーの一覧を表示する (iam list-attached-user-policies) $ aws iam list-attached-user-policies --user-name \u0026lt;ユーザー名\u0026gt; グループに割り当てられたポリシーの一覧を表示する (iam list-attached-group-policies) $ aws iam list-attached-group-policies --group-name \u0026lt;グループ名\u0026gt; ユーザーにマネージドポリシーを割り当てる (iam attach-user-policy) $ aws iam attach-user-policy --user-name \u0026lt;ユーザー名\u0026gt; --policy-arn \u0026lt;ARN\u0026gt; 例: パスワードを変更できるようにする $ aws iam attach-user-policy --user-name user1 \\ --policy-arn arn:aws:iam::aws:policy/IAMUserChangePassword ユーザーにインラインポリシーを追加する (iam put-user-policy) $ aws iam put-user-policy --user-name \u0026lt;ユーザー名\u0026gt; \\ --policy-name \u0026lt;インラインポリシー名\u0026gt; --policy-document \u0026lt;JSON文字列\u0026gt; ポリシーの指定はちょっと長くなるので、通常は外部の JSON ファイルなどで記述しておいて、次のように file://ファイル名 で渡します。 $ aws iam put-user-policy --user-name \u0026lt;ユーザー名\u0026gt; \\ --policy-name \u0026lt;インラインポリシー名\u0026gt; --policy-document file://policy.json policy.json ユーザーのインラインポリシーの一覧を表示する (iam list-user-policies) $ aws iam list-user-policies --user-name \u0026lt;ユーザー名\u0026gt; ロールにポリシーを割り当てる (iam attach-role-policy) $ aws iam attach-role-policy --role-name \u0026lt;ロール名\u0026gt; --policy-arn \u0026lt;ポリシーARN\u0026gt; ロール関連 IAM ロールの一覧を取得する (iam list-roles) 例: すべてのロールを表示 $ aws iam list-roles 例: パスが /service-role/ で始まるロールを表示 $ aws iam list-roles --path /service-role/ IAM ロールを作成する (iam create-role) 例: Lambda 用の実行ロール lambda-ex を作成する $ aws iam create-role --role-name lambda-ex \\ --assume-role-policy-document file://trust-policy.json trust-policy.json（入力ファイル） STS: Security Token Service の権限を与えるためのポリシー設定です。 { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;lambda.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;sts:AssumeRole\u0026#34; } ] } 実行結果（YAML形式） Role:Arn:arn:aws:iam::123456789012:role/lambda-exAssumeRolePolicyDocument:Statement:- Action:sts:AssumeRoleEffect:AllowPrincipal:Service:lambda.amazonaws.comVersion:\u0026#39;2012-10-17\u0026#39;CreateDate:\u0026#39;2021-03-12T07:20:28+00:00\u0026#39;Path:/RoleId:TA4JSU73BFIAROAVTXAP4RoleName:lambda-ex ロールを作成するときに、--path オプションでパスを設定しておくと、iam list-roles でロールを列挙するときに、パスのプレフィックスで検索できるようになります。 例: パス付きのロールを作成する $ aws iam create-role --role-name lambda-ex \\ --path /division-abc/product-xyz/ \\ --assume-role-policy-document file://trust-policy.json IAM ロールを削除する (iam delete-role) 例: lambda-ex という名前のロールを削除する $ aws iam delete-role --role-name lambda-ex IAM ロールにタグを設定する (iam tag-role) 例: ロールにタグ (AppName:HelloWorld) を設定する $ aws iam tag-role --role-name my-role \\ --tags Key=AppName,Value=HelloWorld 複数のタグをまとめて設定したいときは、--tags オプションで、キーと値のペアをスペースで区切って並べます。 --tags Key=key1,Value=value1 Key=key2,Value=value2 IAM ロールからタグを削除する (iam untag-role) 例: ロールからタグ Key1、Key2、Key3 を削除する $ aws iam untag-role --role-name my-role \\ --tag-keys Key1 Key2 Key3"
},
{
url: "/p/4c7sdwg/",
title: "AWS アカウント、IAM ユーザー、グループ、ポリシーの違い",
date: "2021-02-03T00:00:00Z",
body: "AWS アカウント、IAM ユーザー、グループ、ポリシーの違い AWS を使う上で最初に理解しておくべき、「アカウント」と「ユーザー」まわりの概念についてまとめておきます。 簡単なイメージとしてはこんな感じ。 AWS アカウント \u0026hellip; 組織およびルートユーザーのこと。通称アカウント。 IAM ユーザー \u0026hellip; 組織内の個別ユーザー。通称ユーザー。 ちなみに、IAM は Identity and Access Management の略。 AWS アカウント（のルートユーザー） AWS サインアップ時に作られる、組織で 1 つだけ用意されるルートユーザーです。 AWS アカウントの ID は管理者のメールアドレスです。 AWS アカウントは、契約／支払い設定などを含むフルアクセス権限があるので、通常の業務ではこのアカウントは使わず、IAM ユーザーを使います。 IAM ユーザー AWS アカウントから作成されるユーザーで、通常の業務ではこの IAM ユーザーを使います。Linux の一般ユーザーのようなものです。 1 つの AWS アカウントから複数の IAM ユーザーを作成することができます。 IAM ユーザーに IAM ポリシーを割り当てることで、各種リソースへのアクセスが許可されます。IAM ユーザー作成直後は、何もアクセス権限がありません。ちなみに、IAM ポリシーは JSON 形式で記述されます。 IAM グループ 複数の IAM ユーザーをグルーピングするためのものです。 IAM グループに対しても IAM ポリシーを割り当てることができ、複数の IAM ユーザーにまとめて権限設定することができます。 IAM ロール 特定の AWS サービス、IAM ユーザー、IAM グループに一時的に権限を与えるために使われます。例えば、EC2 インスタンスへのアクセス権割り当てなどに使われます。 IAM ロールがどのような権限を表現するかは、IAM ロール自体に IAM ポリシーを割り当てることで制御します。 協力会社のメンバーに自社リソースの権限を与えたいときに、協力会社側で使っている IAM ユーザーに対して、自社で作成した IAM ロールを割り当てる、という使い方ができます。→ 参考: IAM ユーザーにアクセス権限を委任するロールの作成"
},
{
url: "/p/xdnu3ah/",
title: "AWS CodeBuild で Hello World（GitHub との連携）",
date: "2021-01-26T00:00:00Z",
body: "AWS CodeBuild で Hello World（GitHub との連携） 何をやるか？ CodeBuild は AWS が提供するビルドサービスです。 例えば、GitHub に buildspec.yml というビルド方法を記述したファイルを置いておくと、GitHub へのコードプッシュ時に、その設定通りビルドを行ってくれます。 GitHub Actions や Azure Pipelines といったサービスと同様です。 ここでは、CodeBuild 導入の第一歩として、次のような構成でセットアップしてみます。 ソースプロバイダ : GitHub（の適当なテストリポジトリ） ビルド内容 : \u0026ldquo;Hello World\u0026rdquo; と echo 表示する つまり、テスト用の GitHub リポジトリに何らかのファイルをプッシュしたときに、CodeBuild によるビルドを開始するところまでです。 ソースプロバイダとしては、GitHub だけではなく、AWS CodeCommit、Bitbucket、GitHub Enterpise といった Git リポジトリを選択できますが、おそらく GitHub が一番よく使われているので、ここでは GitHub を使うことにします。 最初の一歩はできるだけ簡単に済ませることが肝心です！ アカウントとリポジトリを準備する まず最低限の準備として、下記のアカウントは用意できているとします。 AWS アカウント GitHub アカウント 次に、GitHub にテスト用の リポジトリを作成 しておきます。 ここでは、リポジトリ名は hello-codebuild とでもしておきます。 README.md を自動生成しておくと、後のテストが楽です。 CodeBuild にビルドプロジェクトを作成する 次のようにして、CodeBuild に新規ビルドプロジェクトを作成します。 AWS CodeBuild console を開きます。 ビルド (CodeBuild) → ビルドプロジェクト → ビルドプロジェクトを作成する と選択します。 以下のような内容を入力してビルドプロジェクトを作成します。 プロジェクト名 : build-hello（名前は自由） ソースプロバイダ : GitHub → 作成しておいた hello-codebuild リポジトリを指定 ウェブフック : コードの変更がこのレポジトリにプッシュされるたびに再構築する にチェックを入れる（これで GitHub へのプッシュ時にビルドトリガがかかります） 環境イメージ : マネージド型イメージ → Amazon Linux 2 → ランタイムやイメージは適当に選択 サービスロール : 新しいサービスロール → codebuild-build-hello-service-role（デフォルト） ビルド仕様 : buildspec ファイルを使用する 以下のような感じでビルドプロジェクトが作成されれば成功です。 ビルド仕様ファイル (buildspec.yml) を作成する ビルドプロジェクトの作成直後に、おもむろに ビルドを開始 のボタンを押すと、ビルドは見事に失敗します。 ビルド履歴 で対象のビルドを選択してビルドログを見ると、次のようなエラーが出力されていることが分かります。 [Container] 2021/01/26 15:32:21 Phase context status code: YAML_FILE_ERROR Message: YAML file does not exist エラーを見るときは、フェーズ詳細 のタブの方がパッと見で分かりやすいかもしれません。 どのフェーズまでうまく進んだかが一目瞭然です。 このエラーは、リポジトリのルートにビルド仕様ファイル buildspec.yml が存在しないというエラーです。 そこで、次のような内容の buildspec.yml ファイルを作成して GitHub へプッシュします。 あるいは、GitHub サイト上で直接ファイルを作っちゃっても OK です。 buildspec.yml version:0.2phases:install:commands:- echo \u0026#39;Hello World (INSTALL phase)\u0026#39;pre_build:commands:- echo \u0026#39;Hello World (PRE_BUILD phase)\u0026#39;build:commands:- echo \u0026#39;Hello World (BUILD phase)\u0026#39;post_build:commands:- echo \u0026#39;Hello World (POST_BUILD phase)\u0026#39; CodeBuild によるビルドは、INSTALL → PRE_BUILD → BUILD → POST_BUILD のようにフェーズが進んでいくのですが、ここではそれらの各フェーズで echo 出力をしています。 buildspec の構文はこちらのドキュメント で確認できます。 buildspec.yml ファイルを GitHub リポジトリのトップディレクトリに作成（あるいはプッシュ）すると、ウェブフックイベントにより CodeBuild のビルドが開始されます。 今度は buildspec ファイルが見つかるので、次のようにビルドが正常に実行されることが分かります（実際のログはもう少しいろいろ情報が表示されます）。 ビルドのログ（抜粋） Hello World (INSTALL phase) Hello World (PRE_BUILD phase) Hello World (BUILD phase) Hello World (POST_BUILD phase) これで AWS CodeBuild の Hello World は完了です！お疲れ様でした！"
},
{
url: "/p/t8fmsz5/",
title: "AWS のサービス一覧（2021年版）",
date: "2021-01-25T00:00:00Z",
body: "AWS のサービス一覧（2021年版） AWS のサービスを概要説明付きでリスト化したものが欲しくて作っちゃったので置いておきます。 PDF 化したもの も置いておきます。 .local-aws td { padding: 0 0 0.2em 0.2em; background: #fafafa; } .local-aws th { padding-top: 1.5em; border: none; background: white; text-align: left; } .local-aws img { max-width: 1.5em; } 分析 (Analytics) Amazon Athena SQL を使用した S3 でのデータクエリ Amazon CloudSearch マネージド型検索サービス Amazon Elasticsearch Service Elasticsearch クラスターを実行し、スケールする Amazon EMR ホスト型 Hadoop フレームワーク Amazon Kinesis リアルタイムストリーミングデータとの連携 Amazon Managed Streaming for Apache Kafka フルマネージド型 Apache Kafka サービス Amazon Redshift 高速かつシンプルで、費用対効果の高いデータウェアハウス Amazon QuickSight 高速ビジネス分析サービス AWS Data Exchange クラウド内サードパーティのデータを検索、購読、および使用 AWS Data Pipeline 定期的なデータ駆動型ワークフローに対するオーケストレーションサービス AWS Glue シンプルでスケーラブルなサーバーレスデータ統合 AWS Lake Formation 安全なデータレイクを数日で構築 Application Integration（アプリケーション統合） AWS Step Functions 分散アプリケーションの調整 Amazon AppFlow SaaS アプリケーションと AWS のサービス向けのコード統合が不要 Amazon EventBridge SaaS アプリと AWS のサービス向けサーバーレスイベントバス Amazon Managed Workflows for Apache Airflow 可用性に優れたセキュアなマネージドワークフローオーケストレーション Amazon MQ マネージド型メッセージブローカーサービス Amazon Simple Notification Service (SNS) Pub/sub、SMS、E メール、およびモバイルプッシュ通知 Amazon Simple Queue Service (SQS) マネージド型メッセージキュー Amazon AppSync 多くのソースから適切なデータを使用して、大規模にアプリを強化 AWS Cost Management（AWS コスト管理） AWS Cost Explorer AWS のコストと使用状況を分析する AWS 予算 カスタムコストと使用予算を設定する AWS のコストと使用状況レポート 包括的なコストと使用状況情報へのアクセス リザーブドインスタンスレポート リザーブドインスタンス (RI) の詳細を把握する Savings Plans 柔軟な料金設定でコンピューティング使用コストを最大 72% 節約 Blockchain （ブロックチェーン） Amazon Managed Blockchain スケーラブルなブロックチェーンネットワークを作成および管理 Amazon Quantum Ledger Database (QLDB) フルマネージド型台帳データベース Business Application（ビジネスアプリケーション） Alexa for Business Alexa を使って組織を強化 Amazon Chime フラストレーションフリーの会議、ビデオ電話、チャット Amazon Honeycode (ベータ) プログラミングなしでモバイルおよびウェブアプリケーションを構築 Amazon WorkDocs エンタープライズドキュメントの安全なストレージと共有 Amazon WorkMail セキュリティで保護されたマネージド型の企業向け E メールおよびカレンダー Compute（コンピューティング） Amazon EC2 クラウド内の仮想サーバー Amazon EC2 Auto Scaling 需要に合わせてコンピューティング性能をスケール Amazon Lightsail 仮想プライベートサーバーを起動および管理 AWS Batch あらゆる規模でバッチジョブを実行 AWS Elastic Beanstalk ウェブアプリの実行と管理 AWS Lambda イベント発生時にコードを実行 AWS Outposts AWS サービスをオンプレミスで実行 AWS Serverless Application Repository サーバーレスアプリケーションを検索、デプロイ、公開する AWS Snow ファミリー エッジロケーションでデータを集約および処理して AWS に転送するデバイス AWS Wavelength 5G デバイスのための超低レイテンシーアプリケーションを提供 VMware Cloud on AWS カスタムハードウェアを使用せずにハイブリッドクラウドを構築する Containers（コンテナ） Amazon Elastic Container Registry コンテナイメージを簡単に保存、管理、デプロイ Amazon Elastic Container Service (ECS) コンテナを実行するためのきわめて安全で信頼性と拡張性が高い方法 Amazon ECS Anywhere (近日公開) インフラストラクチャでの ECS Amazon Elastic Kubernetes Service (EKS) 信頼性が最も高い Kubernetes の実行方法 Amazon EKS Anywhere (近日公開) インフラストラクチャでの Kubernetes Amazon EKS Distro 一貫した Kubernetes クラスターの実行 AWS App2Container 既存のアプリケーションのコンテナ化と移行 AWS Fargate コンテナ向けサーバーレスコンピューティング AWS での Red Hat OpenShift マネージド Red Hat OpenShift クラスター Customer Engagement（カスタマーエンゲージメント） Amazon Connect クラウドベースのコンタクトセンター Amazon Pinpoint チャンネル間でのパーソナライズされたユーザーエンゲージメント Amazon Simple Email Service (SES) E メールの送受信 Database（データベース） Amazon Aurora 高性能マネージドリレーショナルデータベース Amazon Aurora Serverless v2 (プレビュー) 毎秒 100,000 件を超えるトランザクションに瞬時にスケール Amazon DynamoDB マネージド型の NoSQL データベース Amazon DocumentDB (MongoDB 互換) フルマネージド型ドキュメントデータベース Amazon ElastiCache インメモリキャッシングシステム Amazon Keyspaces (Apache Cassandra 用) マネージド型の Cassandra 対応データベース Amazon Neptune フルマネージド型グラフデータベースサービス Amazon Quantum Ledger Database (QLDB) フルマネージド型台帳データベース Amazon RDS MySQL、PostgreSQL、Oracle、SQL Server、MariaDB 向けのマネージドリレーショナルデータベースサービス Amazon RDS on VMware オンプレミスデータベースの管理を自動化 Amazon Redshift 高速、シンプル、費用対効果の高いデータウェアハウジング Amazon Timestream フルマネージド型の時系列データベース AWS Database Migration Service 最小限のダウンタイムでデータベースを移行 AWS Glue シンプルでスケーラブルなサーバーレスデータ統合 Developer Tools（デベロッパーツール） Amazon CodeGuru 最もコストがかかるコード行を見つける Amazon Corretto 本番環境に向けて OpenJDK を配信 AWS Cloud Development Kit (CDK) コードを使用してクラウドインフラストラクチャをモデル化する AWS Cloud9 Cloud IDE でコードを記述、実行、デバッグ AWS CloudShell ブラウザベースのシェル環境 AWS CodeArtifact ソフトウェア開発のためのセキュアかつスケーラブルでコスト効率性に優れたアーティファクト管理 AWS CodeBuild コードのビルドとテスト AWS CodeCommit プライベート Git リポジトリでのコードの保存 AWS CodeDeploy コードデプロイの自動化 AWS CodePipeline 継続的デリバリーを使用したソフトウェアのリリース AWS CodeStar AWS アプリケーションの開発とデプロイ AWS コマンドラインインターフェイス AWS サービスを管理するための統合ツール AWS Device Farm AWS クラウド内の実際のデバイスを使った Android、iOS、ウェブアプリケーションのテスト AWS Fault Injection Simulator 完全マネージド型のカオスエンジニアリングサービス AWS ツールと SDK AWS のためのツールと SDK AWS X-Ray アプリケーションの分析とデバッグ End User Computing（エンドユーザーコンピューティング） Amazon AppStream 2.0 デスクトップアプリケーションを安全にブラウザへストリーミングするサービスです Amazon WorkDocs エンタープライズドキュメントの安全なストレージと共有 Amazon WorkLink 社内のウェブサイトへのモバイルアクセスを可能にする Amazon WorkSpaces デスクトップコンピューティングサービス Font-End Web \u0026 Mobile（ウェブとモバイルのフロントエンド） AWS Amplify モバイルおよびウェブアプリケーションの構築とデプロイ Amazon API Gateway API を構築し、デプロイし、管理する Amazon Location Service (プレビュー) アプリケーションにロケーションデータをセキュアかつ簡単に追加 Amazon Pinpoint チャンネル間でのパーソナライズされたユーザーエンゲージメント AWS AppSync 多くのソースから適切なデータを使用して、大規模にアプリを強化 AWS Device Farm AWS クラウド内の実際のデバイスを使った Android、iOS、ウェブアプリケーションのテスト Game Tech Amazon GameLift シンプルで高速な費用対効果の高い専用ゲームサーバーホスティング Amazon Lumberyard AWS や Twitch と統合された完全なソースを利用できる、無料のクロスプラットフォーム 3D ゲームエンジンです。 Internet of Things（IoT: モノのインターネット） AWS IoT Core デバイスをクラウドに接続 AWS Greengrass デバイスのローカルでのコンピューティング、メッセージング、および同期 AWS IoT 1-Click AWS Lambda トリガーのワンクリック作成 AWS IoT Analytics IoT デバイスの分析 AWS IoT ボタン クラウドのプログラミング可能なダッシュボタン AWS IoT Device Defender IoT デバイスのセキュリティ管理 AWS IoT Device Management IoT デバイスのオンボード、編成、リモート管理 AWS IoT Events IoT イベントを検出し、対応 AWS IoT SiteWise IoT データコレクターおよびインタプリタ AWS IoT Things Graph デバイスおよびウェブサービスを簡単に接続 AWS Partner Device Catalog AWS 互換の IoT ハードウェアの精選カタログ FreeRTOS マイクロコントローラ向けリアルタイムオペレーティングシステム Machine Learning（機械学習） Amazon SageMaker 機械学習モデルを大規模に構築、トレーニング、デプロイ Amazon Augmented AI ML 予測のヒューマンレビューを簡単に導入 Amazon CodeGuru 最もコストがかかるコード行を見つける Amazon Comprehend テキストのインサイトや関係性を検出 Amazon DevOps Guru ML 駆動のクラウドオペレーションサービス Amazon Elastic Inference 深層学習推論の高速化 Amazon Forecast 機械学習を使用して予測の精度を向上させる Amazon Fraud Detector オンライン詐欺をより素早く検知 Amazon Kendra ML を利用してエンタープライズ検索を改革 Amazon Lex 音声やテキストに対応するチャットボットの構築 Amazon Lookout for Equipment (プレビュー) センサーデータの分析による異常動作の検知 Amazon Lookout for Metrics メトリクス内における異常の検知 Amazon Lookout for Vision コンピュータビジョンを使用した製品欠陥の検出 Amazon Monitron 機器モニタリングのためのエンドツーエンドシステム Amazon Personalize アプリケーションへのリアルタイムレコメンデーションの構築 Amazon Polly テキストを生きた話し声に変換 Amazon Rekognition イメージとビデオを分析 Amazon SageMaker Data Wrangler ML 用にデータを準備するための最も速い方法 Amazon SageMaker Ground Truth 精度の高い機械学習トレーニングデータセットの構築 Amazon Textract ドキュメントからテキストやデータを抽出する Amazon Translate 自然で流ちょうな言語翻訳 Amazon Transcribe 自動音声認識 AWS 深層学習 AMI EC2 で今すぐ深層学習を始める AWS Deep Learning Containers 深層学習向け Docker イメージ AWS DeepComposer 機械学習が有効化されたミュージカルキーボード AWS DeepLens 深層学習に対応したビデオカメラ AWS DeepRacer 機械学習による 18 分の 1 のスケールでの自律走行型レースカー AWS Inferentia 機械学習インファレンスチップ AWS Panorama (プレビュー) エッジに設置したコンピュータビジョンによる運営改善 AWS での PyTorch 柔軟なオープンソースの機械学習フレームワーク AWS での Apache MXNet スケーラブルでパフォーマンスに優れた深層学習 AWS での TensorFlow オープンソースの Machine Intelligence Library Management \u0026 Governance（マネジメントとガバナンス） Amazon CloudWatch リソースとアプリケーションのモニタリング AWS Auto Scaling 需要に合わせて複数のリソースをスケール AWS Chatbot ChatOps for AWS AWS CloudFormation テンプレートを使ったリソースの作成と管理 AWS CloudTrail ユーザーアクティビティと API 使用状況の追跡 AWS コマンドラインインターフェイス AWS サービスを管理するための統合ツール AWS Compute Optimizer 最適な AWS コンピューティングリソースを特定 AWS Config リソースのインベントリと変更の追跡 AWS Control Tower 安全かつ基準に準拠した複数のアカウント環境をセットアップおよび管理 AWS コンソールモバイルアプリ リソースの状態を外出先で確認 AWS Distro for OpenTelemetry (プレビュー) 相関するメトリクスとトレースの収集 AWS License Manager ライセンスの追跡、管理、制御 AWS マネジメントコンソール ウェブベースのユーザーインターフェイス AWS Managed Services AWS のインフラストラクチャ運用管理 Amazon Managed Service for Grafana 強力でインタラクティブなデータ視覚化 Amazon Managed Service for Prometheus コンテナのためのセキュアで可用性に優れたモニタリング AWS OpsWorks Chef と Puppet を使用した運用の自動化 AWS Organizations AWS アカウント全体の一元管理 AWS Personal Health Dashboard AWS のサービス状態のパーソナライズされた表示 AWS Proton (プレビュー) コンテナとサーバーレスデプロイメントのための自動化された管理 AWS Service Catalog 標準化された製品の作成と使用 AWS Systems Manager 運用時の洞察を改善し、実行 AWS Trusted Advisor パフォーマンスとセキュリティの最適化 AWS Well-Architected Tool ワークロードの見直しと改善 Media Services（メディアサービス） Amazon Elastic Transcoder スケーラブルで使いやすいメディア変換サービス Amazon Interactive Video Service マネージドライブ動画ソリューション Amazon Kinesis Video Streams ビデオストリームの処理と分析 AWS Elemental MediaConnect 高い信頼性を安全性を持つライブ動画転送 AWS Elemental MediaConvert ファイルベースのビデオコンテンツを変換 AWS Elemental MediaLive ライブビデオコンテンツを変換 AWS Elemental MediaPackage 動画の発信とパッケージ化 AWS Elemental MediaStore メディアストレージとシンプルな HTTP オリジン AWS Elemental MediaTailor 動画のパーソナライズと収益化 AWS Elemental アプライアンスとソフトウェア オンプレミスメディアソリューション Migration \u0026 Transfer（移行と転送） AWS Migration Hub 複数の移行を 1 か所で追跡 AWS Application Discovery Service オンプレミスのアプリケーションを検出して合理的に移行 AWS Database Migration Service 最小限のダウンタイムでデータベースを移行 AWS DataSync シンプルかつ高速なオンラインデータ転送 AWS Server Migration Service AWS へのオンプレミスサーバーの移行 AWS Snow ファミリー AWS との間でデータを移行するためのデバイス AWS Transfer Family フルマネージド SFTP、FTPS、および FTP サービス CloudEndure Migration AWS への大規模な移行を自動化 Migration Evaluator（旧 TSO Logic） クラウド移行のビジネスケースを作成 Networking \u0026 Content Delivery（ネットワーキングとコンテンツ配信） Amazon VPC 独立したクラウドリソース Amazon API Gateway API を構築、デプロイ、管理 Amazon CloudFront グローバルコンテンツ配信ネットワーク Amazon Route 53 スケーラブルなドメインネームシステム (DNS) AWS PrivateLink AWS でホストされているサービスに安全にアクセス AWS App Mesh マイクロサービスをモニタリングおよびコントロール AWS Cloud Map マイクロサービス向けのアプリケーションリソースレジストリ AWS Direct Connect AWS への専用ネットワーク接続 AWS Global Accelerator アプリケーションの可用性とパフォーマンスを向上 AWS Transit Gateway VPC およびアカウント接続を簡単にスケール Elastic Load Balancing 複数のターゲットにわたる着信トラフィックの分配 Quantum Technologies（量子テクノロジー） Amazon Braket 量子コンピューティングを探索して実験 Robotics（ロボット工学） AWS RoboMaker ロボット工学アプリケーションの開発、テスト、デプロイ Satellite（人工衛星） AWS Ground Station サービスとしてのフルマネージド型地上局 Security, Identity \u0026 Compliance（セキュリティ、アイデンティティ、コンプライアンス） AWS Identity \u0026 Access Management サービスとリソースへのアクセスを安全に管理 Amazon Cognito アプリの ID 管理 Amazon Detective 潜在的なセキュリティ問題を調査 Amazon GuardDuty マネージド型脅威検出サービス Amazon Inspector アプリケーションのセキュリティの分析 Amazon Macie 大規模な機密データを検出して保護する AWS Artifact AWS のコンプライアンスレポートへのオンデマンドアクセス AWS Audit Manager AWS 利用状況の継続的な監査 AWS Certificate Manager SSL/TLS 証明書のプロビジョニング、管理、およびデプロイメント AWS CloudHSM 法令遵守のためのハードウェアベースキーストレージ AWS Directory Service Active Directory のホスティングと管理 AWS Firewall Manager ファイアウォールルールの一元管理 AWS Key Management Service マネージド型の暗号化キー作成と管理 AWS Network Firewall VPC 保護のためのネットワークセキュリティ AWS Resource Access Manager AWS のリソースを共有するためのシンプルでセキュアなサービス AWS Secrets Manager シークレットのローテーション、管理、取得 AWS Security Hub 統合された AWS セキュリティ \u0026 コンプライアンスセンター AWS Shield DDoS 保護 AWS Single Sign-On クラウドシングルサインオン (SSO) サービス AWS WAF 悪意のあるウェブトラフィックのフィルター Serverless（サーバーレス） AWS Lambda サーバーに煩わされずにコードを実行 Amazon API Gateway API の構築、デプロイ、管理 Amazon DynamoDB マネージド型の NoSQL データベース Amazon EventBridge SaaS アプリと AWS のサービス向けサーバーレスイベントバス Amazon Simple Notification Service (SNS) Pub/sub、SMS、E メール、およびモバイルプッシュ通知 Amazon Simple Queue Service (SQS) マネージド型メッセージキュー Amazon Simple Storage Service (S3) クラウド内のスケーラブルなストレージ AWS AppSync 多くのソースから適切なデータを使用して、大規模にアプリを強化 AWS Fargate コンテナ向けサーバーレスコンピューティング AWS Step Functions 分散型アプリケーションの調整 Storage（ストレージ） Amazon Simple Storage Service (S3) スケーラブルなクラウドストレージ Amazon Elastic Block Store (EBS) EC2 ブロックストレージボリューム Amazon Elastic File System (EFS) EC2 用フルマネージド型ファイルシステム Amazon FSx for Lustre S3 と統合されたハイパフォーマンスファイルシステム Amazon FSx for Windows File Server フルマネージド型 Windows ネイティブのファイルシステム Amazon S3 Glacier クラウド上の低コストなアーカイブストレージ AWS Backup AWS のサービス全体にわたる一元管理型バックアップ AWS Snow ファミリー 厳しい環境や切断された環境向けの物理エッジコンピューティングおよびストレージデバイス AWS Storage Gateway ハイブリッドストレージの統合 CloudEndure Disaster Recovery 高度に自動化した災害対策 VR \u0026 AR（VR および AR） Amazon Sumerian VR および AR アプリケーションの構築と実行"
},
{
url: "/p/wiv7it5/",
title: "GraphQL のクエリの一部をフラグメント化して再利用する (Fragments)",
date: "2021-01-19T00:00:00Z",
body: "GraphQL のクエリの一部をフラグメント化して再利用する (Fragments) GraphQL のフラグメントを定義する GraphQL クエリの中で、同じようなフィールドの指定（選択セット）を複数回使用する場合、それを フラグメント (Fragment) という再利用可能な選択セットとして切り出して定義しておくことができます。 例えば次の GraphQL クエリは、GitHub から自分のユーザー情報 (viewer) と、特定のユーザーの情報 (user) を一度に取得しています。 GraphQL クエリ queryQueryTwoUsers{viewer{login# ログインIDname# ユーザー名url# ユーザーの GitHub ホームページwebsiteUrl# ユーザーの Web サイトavatarUrl# ユーザーのアバター画像}user(login:\u0026#34;ログインID\u0026#34;){loginnameurlwebsiteUrlavatarUrl}} viewer フィールドと user フィールドは、両方とも User 型 のフィールドで、しかも、上記の例では User オブジェクトの中の同じフィールドを参照しています。 明らかに冗長な書き方です。 このようなケースでは、あるオブジェクトの特定のフィールドを参照するための選択セット (selection set) を、フラグメントの形で定義することができます。 次の例では、User オブジェクトの特定のフィールドを選択するための userFragment というフラグメントを定義しています。 フラグメントを使用する場所では、...userFragment のようにドットを 3 つ付けて参照します（JavaScript のスプレッド構文と同じです）。 GraphQL クエリ queryQueryTwoUsers{viewer{...userFragment}user(login:\u0026#34;ログインID\u0026#34;){...userFragment}}fragmentuserFragmentonUser{login# ログインIDname# ユーザー名url# ユーザーの GitHub ホームページwebsiteUrl# ユーザーの Web サイトavatarUrl# ユーザーのアバター画像} fragment の定義は、query の定義と同じ階層に記述することに注意してください。 また、on User というのは、User オブジェクトのフィールドを選択するフラグメントであることを示しており、このフラグメントは User オブジェクトのフィールド部分でしか使えません。 上記の例では、viewer も user も User 型のフィールドなので、その中で問題なく ...userFragment と参照できています。 上記のサンプルコードはあまり実用的じゃなかったので、もう少し本物のアプリで使いそうなクエリを載せておきます。 次の GraphQL クエリでは、ログイン中のユーザー情報と、そのユーザーの Issue 情報を取得しています。 Issue がアサインされているユーザーの情報を取得するために、userFragment フラグメントを使っています。 GraphQL クエリ queryQueryLoginUser{viewer{...userFragmentissues(states:OPEN,last:10){nodes{idtitleassignees(last:10){nodes{...userFragment}}}}}}fragmentuserFragmentonUser{loginnameurlwebsiteUrlavatarUrl} Apollo Client で GraphQL のフラグメントを使用する React を使った Web アプリでは、GraphQL ライブラリとして Apollo Client が使用されることが多いと思います。 もちろん、Apollo Client で使用する GraphQL クエリの中でもフラグメントを使用できます。 TypeScript (JavaScript) では、クエリ文字列の中から変数展開することができるので、フラグメントの定義は文字列変数（定数）の形で定義しておくと便利です。 次の例では、rateLimitFragment という GraphQL フラグメントを、RATE_LIMIT_FRAGMENT という文字列定数として定義しています。 queries.ts import {gql} from \u0026#39;@apollo/client\u0026#39;; const RATE_LIMIT_FRAGMENT = gql` fragment rateLimitFragment on Query { rateLimit { cost remaining } } `; // 自分にアサインされた PullRequest の一覧 export const QUERY_MY_PULLS = gql` ${RATE_LIMIT_FRAGMENT}query { ...rateLimitFragment rateLimit { cost remaining } search(type: ISSUE, last: 100, query: \u0026#34;is:open is:pr review-requested:@me\u0026#34;) { issueCount nodes { ... on PullRequest { number title bodyText url } } } } `; 文字列定数 RATE_LIMIT_FRAGMENT で定義されたフラグメントを使用するために、QUERY_MY_PULLS の中で ${RATE_LIMIT_FRAGMENT} と展開しています。 つまり、そこに fragment の定義を記述したのと同じ振る舞いになります。 あとは適切な場所で ...rateLimitFragment と参照すれば OK です。 このようにフラグメント定義部分を文字列定数として切り出しておけば、別の GraphQL クエリの中からも同様に参照することができます。 一応、QUERY_MY_PULLS の使用例も。 components/MyPullRequests.tsx import * as React from \u0026#39;react\u0026#39;; import {useQuery} from \u0026#39;@apollo/client\u0026#39;; import {PullRequestLink} from \u0026#39;./PullRequestLink\u0026#39;; import {QUERY_MY_PULLS} from \u0026#39;../queries\u0026#39;; export const MyPullRequests: React.FC = () =\u0026gt; { const {loading, error, data} = useQuery(QUERY_MY_PULLS); if (loading) return \u0026lt;p\u0026gt;Loading ...\u0026lt;/p\u0026gt;; if (error) return \u0026lt;p\u0026gt;Error: {error.message}\u0026lt;/p\u0026gt;; const pulls = createPullRequests(data); return \u0026lt;\u0026gt; \u0026lt;h3\u0026gt;自分のレビュー待ち PR\u0026lt;/h3\u0026gt; \u0026lt;ul\u0026gt; {pulls.map(x =\u0026gt; \u0026lt;PullRequestLink key={x.number} pr={x}/\u0026gt;)} \u0026lt;/ul\u0026gt; \u0026lt;/\u0026gt;; }; // ..."
},
{
url: "/p/kmj7sdv/",
title: "Apollo Client の useQuery 呼び出し部分をカスタムフックで分離する",
date: "2020-11-30T00:00:00Z",
body: "Apollo Client の useQuery 呼び出し部分をカスタムフックで分離する Apollo Client で GraphQL クエリを実行するときは、カスタムフックとして useQuery 関数の呼び出し部分を抽出すると、コンポーネント側のコードをシンプルにすることができます。 分離前のコード 次のサンプルコードでは、GraphQL クエリで GitHub のログインユーザー情報を取得して表示する Viewer コンポーネントを実装しています。 GraphQL のクエリ呼び出し部分や、取得したデータを ViewerData オブジェクトに詰める部分などが混在しており、あまり整理されているとは言えません。 components/Viewer.tsx import { FC } from \u0026#39;react\u0026#39; import { gql, useQuery } from \u0026#39;@apollo/client\u0026#39; import { LoadingComponent } from \u0026#39;./LoadingComponent\u0026#39; import styles from \u0026#39;./Viewer.scss\u0026#39; const QUERY_VIEWER = gql` query QueryViewer { viewer { login url avatarUrl } } ` type ViewerData = { /** ログインID */ login: string /** ホームページのURL */ url: string /** アバター画像のURL */ avatarUrl: string } /** 「ユーザー情報」を表示するコンポーネント */ export const Viewer: FC = () =\u0026gt; { const {loading, error, data} = useQuery(QUERY_VIEWER) if (loading) return \u0026lt;LoadingComponent /\u0026gt; const viewer: ViewerData = data.viewer return ( \u0026lt;div className={styles.container}\u0026gt; \u0026lt;a href={viewer.url}\u0026gt;\u0026lt;img src={viewer.avatarUrl}/\u0026gt;\u0026lt;/a\u0026gt; \u0026lt;/div\u0026gt; ) } こんなときは、カスタムフックを作成して、GraphQL クエリを実行する部分や、その結果を加工する部分などを分離するとコンポーネント側のコードがシンプルになります。 分離後のコード 下記の useViewer カスタムフックは、Apollo Client API の useQuery 呼び出し部分や、その戻り値のデータパース処理を実装しています。 ☝️ カスタムフックとは 関数内部で useXxx 系のフック関数を呼び出すものをカスタムフックと呼びます。 カスタムフックは通常のフック関数と同様の制約を引き継ぐため、関数コンポーネント内では一定の順序で呼び出さないといけません。 hooks/useViewer.ts（カスタムフック） import { gql, useQuery } from \u0026#39;@apollo/client\u0026#39; export const QUERY_VIEWER = gql` query QueryViewer { viewer { login url avatarUrl } } ` /** useViewer カスタムフックの戻り値の型 */ export type ViewerData = { /** ログインID */ login: string /** ユーザーのホームページアドレス */ url: string /** アバター画像のURL */ avatarUrl: string } /** useQuery の戻り値 QueryResult の data プロパティの型 */ type Data = { viewer: ViewerData } /** * サインイン中の GitHub ユーザー情報を取得します。 * ロード中やエラー時は undefined を返します。 */ export function useViewer(): ViewerData | undefined { const { data } = useQuery\u0026lt;Data\u0026gt;(QUERY_VIEWER) return data?.viewer } ポイントは、useQuery の型パラメータとして Data 型を指定しているところです。 これにより、useQuery の戻り値の data プロパティの型が Data 型になります。 ☝️ QueryResult インタフェース QueryResult インタフェースは、Apollo Client が定義している useQuery の戻り値の型です。 QueryResult オブジェクトの data プロパティは、デフォルトでは any 型ですが、QueryResult\u0026lt;ViewerData\u0026gt; のように型パラメータを指定すると、data プロパティを ViewerData 型として参照できるようになります。 この Data 型は、下記の GraphQL クエリに対応するプロパティを保持するよう定義する必要があります（この場合、Data 型は viewer プロパティを持つよう定義します）。 queryQueryViewer{viewer{loginurlavatarUrl}} 実際に useViewer カスタムフックを使う側が参照したいのは、この Data 型のデータではなく、そこに含まれている viewer （ViewerData オブジェクト）の方なので、res.data.viewer オブジェクトをリターンするようにしています。 下記は、このカスタムフックの使用例です。 components/Viewer.tsx（リファクタ後） import { FC } from \u0026#39;react\u0026#39; import { LoadingComponent } from \u0026#39;./LoadingComponent\u0026#39; import { useViewer } from \u0026#39;../hooks/useViewer\u0026#39; import styles from \u0026#39;./Viewer.scss\u0026#39; /** 「ユーザー情報」を表示するコンポーネント */ export const Viewer: FC = () =\u0026gt; { const viewer = useViewer() if (!viewer) return \u0026lt;LoadingComponent /\u0026gt; return ( \u0026lt;div className={styles.container}\u0026gt; \u0026lt;a href={viewer.url}\u0026gt;\u0026lt;img src={viewer.avatarUrl} /\u0026gt;\u0026lt;/a\u0026gt; \u0026lt;/div\u0026gt; ) } とてもシンプルですね！ Viewer コンポーネントから GraphQL クエリの呼び出し部分などが取り除かれ、UI 表現に集中して実装できるようになりました。 useViewer フックは、データ取得前は undefined を返し、データ取得後に ViewerData オブジェクトを返すようにしているので、戻り値が undefined の場合は Loading 表示などを行えば OK です。 エラー情報やローディング状態を独立した変数で返して欲しいのであれば、カスタムフックの戻り値を次のように一段ラップすればよいです。 export type UseViewerOutput = { loading: boolean error?: ApolloError viewer?: ViewerData } export function useViewer(): UseViewerOutput { const { loading, error, data } = useQuery\u0026lt;Data\u0026gt;(QUERY_VIEWER) return { loading, error, viewer: data?.viewer } } （ただ、基本的にローディング中かどうかは viewer == undefined で判定できるので loading は必要ないはず） あわせて読みたい記事 Apollo CLI の codegen で GraphQL クエリレスポンスの TypeScript 型を自動生成する"
},
{
url: "/p/wbipw4a/",
title: "読書メモ『しんがり 山一證券最後の12人』清武英利",
date: "2020-11-24T00:00:00Z",
body: "読書メモ『しんがり 山一證券最後の12人』清武英利 しんがり 山一證券最後の12人 清武英利 講談社 山一證券破綻の真相究明を行った「しんがり」と呼ばれる社員たちの物語。 この小説がすごいのは、ノンフィクション ということです。 著者の清武氏は記者（ジャーナリスト）であって、決して山一證券の関係者ではないのですが、あたかも社員たちと一緒にそこにいたかのようなリアルさで描かれています。 ノンフィクション賞を取るのもうなずけます。 しんがりの社員たちは破綻の真相究明のために、たくさんの社員にインタビューを行うのですが、著者のインタビュー力も半端ないですね。 最後まで会社に残った社員たちは、給料もろくにもらえない中で使命感だけで清算処理を続けるのですが、もし自分が同じような立場に立ったら、きっと逃げ出しちゃいますね。。。 ほとんどの人がそうだと思います。 でも、この本を読めば、そんな状況で最後まで頑張り抜いた先に何が待っているのかを少しだけ味わうことができます。 何か熱いものがこみ上げてきます。"
},
{
url: "/p/t8gpx6e/",
title: "ドラクエ9で終了したはずのWiFiサービスの配信クエストを受け取る",
date: "2020-11-23T00:00:00Z",
body: "ドラクエ9で終了したはずのWiFiサービスの配信クエストを受け取る 図: DQ9 の配信クエストの受け取りできた！ 今さらですが、ニンテンドーDSのドラクエ9を楽しんでます。 こんな面白いゲームがブックオフで 200 円で買えるとはいい時代です。 ただ、エンディング後のやり込み（というかここからが本番？）をするには、ニンテンドー Wi-Fi コネクションによる配信クエストの受け取りが必要ということを知りました（エンディング迎えた後に気づいた）。 残念ながら、Wi-fi コネクションサービスは 2014 年に終了しており、配信クエストはもうあきらめていたのですが、なんと有志で立てられたサーバーに接続して受け取れることがわかりました。神か！ 無線 LAN ルーターの設定で、WEP 接続できるようにしておく セキュリティ的に WEP は問題があるけど、Nintend DS は WEP 接続しか対応してない。。なので、ルーター側で MAC アドレス制限としかして繋ぐようにする。 DQ9 を起動して「Wi-Fi せっていをする」を選択。接続テストで、「エラーコード:20110 このソフトのWi-Fiコネクションサービスは終了しました。ご利用ありがとうございました。」が表示されることを確認。 「DNS自動取得」の設定を しない に変更し、プライマリDNSに 178.62.43.212、セカンダリDNSに 8.8.8.8 を設定。ちなみに、プライマリ DNS はいくつか候補があるみたい。 127.104.88.237 164.132.44.106 178.62.43.212 再び接続テストして、成功すれば OK。 あとは、セントシュタイン上のリッカの宿屋の右側にいる女性に話しかければ、すべての「配信クエスト」の受け取り、「スペシャルゲスト」、「Wi-Fiショッピング」などを行えます。 やったー！これでしばらく DQ9 楽しめる ٩(๑❛ᴗ❛๑)۶ わーぃ 図: リッカの宿屋へのスペシャルゲストもまだ来ます ちなみに、最近立て続けに DQ7、DQ8 とクリアしてきてます。 シリーズ物は順番にクリアしていきたい人なので。。。 昔のドラクエは今やってもすごくおもしろいです。 過去のドラクエの特徴まとめておこう。 DQ1 (FC) 1人旅。ロトシリーズの元祖。スマホでできる。1日でクリアできるけど十分楽しめる。 DQ2 (FC) 3人旅。復活の呪文が長くてみんな苦しめられた。 DQ3 (FC) 4人旅。ルイーダの酒場で自由にキャラ作成＆転職システムで仲間の組み合わせが楽しい。 DQ4 (FC) 8人旅。5章構成。転職ができないことで、キャラの個性が引き立った。各章の音楽が特徴的でいい。 DQ5 (SFC) 嫁にビアンカとフローラのどちらかを選ぶ旅。転職なしのストーリー重視。 DQ6 (SFC) 祝！転職システム復活。全体的にはおつかいゲーム感が強い。ハッサンが個性的すぎて、ハッサンの記憶しかない。あとバーバラとムチ。 DQ7 (PS1) 石版探しの旅。転職の職業がありすぎて大変。石版探しがストーリーを進める上で必須だけど、結構分かりにくい所にあったりして、攻略サイトないときつい。DQには珍しく、バッドエンド的な鬱なストーリーが多い。 DQ8 (PS2) 最初の街で3D酔いする。楽しいのか面倒なのか分からない錬金システム導入。キャラクターごとに個性のあるスキルシステムが導入された。スキルに割り振れるポイント数は Lv.99 にしても上限があるため、最初からよく考えて割り振らないとハマる。前作の転職システムが面倒だった分、スキルシステムは手軽かつ考える楽しみがあって好き。 DQ9 (DS) 4人旅（キャラ作成）。転職システムとスキルシステムをハイブリッド導入。小さなメダルをランダムに拾える新設設計。転職に加え、転生システム（Lv.1に戻る）の導入で、やり込めば必ずスキル Max にできるという超新設設計。Wi-Fi すれ違い通信での宝の地図取得は絶望的。 こうして見ると、DQ9 は「キャラ作成＋転職」システムの導入により、DQ3 に回帰した感じですね。 仲間を自由に作れる反面、仲間ごとに練りこまれたストーリーは存在しないので、ここは賛否両論ですが、DQ3 にハマった世代としては懐かしさが感じられて好きです。"
},
{
url: "/p/7aoa6x5/",
title: "EditorConfig でコーディングスタイルを統一する",
date: "2020-11-20T00:00:00Z",
body: "EditorConfig でコーディングスタイルを統一する EditorConfig とは EditorConfig（.editorconfig ファイル）を導入すると、各種エディタ（Visual Studio、Android Studio、Vim など）に共通のコーディングスタイルを設定することができます。 ソフトウェア開発プロジェクトでは、通常なんらかのコーディングルールが決められています。 ただ、開発者ごとに使用するエディタ、IDE が異なると、設定方法を統一できないという問題が発生します。 EditorConfig は、特定のエディタに依存しない、コーディングスタイルを記述するためのフォーマット（およびツール群） です。 EditorConfig で設定可能な項目は、エンコーディング形式や改行コード、インデントサイズといったごく基本的な項目のみですが、最低限の記述スタイルをプロジェクト全体で素早く統一することができます。 EditorConfig の導入（.editorconfig ファイルの作成） EditorConfig の導入はとても簡単で、次のような設定ファイル (.editorconfig) をプロジェクトのルートに作成するだけです。 .editorconfig # ここが最上位の設定ファイル root = true # 全種類のテキストファイルの基本設定 [*] charset = utf-8 end_of_line = lf indent_size = 4 indent_style = space insert_final_newline = true trim_trailing_whitespace = true # あとは、ファイルの種類ごとに設定を上書き [*.{js,jsx,ts,tsx}] indent_size = 2 max_line_length = 80 [*.{kt,kts}] max_line_length = 100 [*.md] trim_trailing_whitespace = false [*.py] max_line_length = 80 [*.rb] indent_size = 2 max_line_length = 80 [*.{yml,yaml,json}] indent_size = 2 各プロパティの内容は、ほぼ自明ですが、それぞれ次のような意味を持っています。 プロパティ名 設定例 説明 root true / false これがルートの設定ファイルなら true indent_style tab / space インデントをタブにするかスペースにするか indent_size 4 インデントのスペース数 end_of_line lf / cr / crlf 改行コード charset utf-8 / utf-8-bom / latin1 ファイルのエンコーディング形式 trim_trailing_whitespace true / false 行末のスペースを削除するか insert_final_newline true / false ファイル末尾に空白行を入れるか 各エディタの EditorConfig プラグインは、編集中のファイルを起点にして、上位ディレクトリの .editorconfig ファイルを検索します。 上の設定例のように、root プロパティが true になっている .editorconfig ファイルが見つかると、それ以上ディレクトリを上って検索しないようになります。 プロジェクトのルートに置く設定ファイルには、root = true と記述しておくのがよいでしょう。 設定可能なプロパティの詳細は、下記サイトの一覧を参照してください。 max_line_length など、特定のエディタでしかサポートされていないプロパティもあります。 EditorConfig Properties 各エディタへのプラグイン導入 .editorconfig の設定に従って実際にフォーマットを行うには、各エディタに EditorConfig プラグイン を導入する必要があります。 Android Studio (IntelliJ IDEA) のように、最初からプラグインが組み込まれた状態でリリースされている 環境もあり、その場合は特に何もインストールする必要はありません。 一方で、Vim エディタなどは .editorconfig ファイルを認識させるために、専用のプラグインをインストールする必要があります。 各エディタのプラグインは下記からダウンロードできます。 EditorConfig Plugin Download （各エディタのアイコン画像をクリックすると、該当ページにジャンプします。分かりにくい…） Android Studio の場合 Android Studio (IntelliJ IDEA) は、デフォルトで .editorconfig を認識してくれます。 プロジェクトのディレクトリ内に .editorconfig ファイルを配置するだけで、フォーマット時 (Ctrl + Alt + L) の振る舞いに反映されます。 Android Studio の設定画面を見ると、次のようにデフォルトで EditorConfig が有効になっていることが分かります。 図: Android Studio の設定画面 Visual Studio Code (VS Code) の場合 VS Code 用のプラグイン（拡張）は、下記のマーケットプレイスで Install ボタンを押すか、VS Code の Extensions ペーンから EditorConfig for VS Code を検索してインストールできます（どちらも VS Code のインストール画面に飛びます）。 EditorConfig for VS Code これだけで、すぐに .editorconfig の設定が有効になります。 VS Code を再起動する必要もありません。 Vim の場合 Vim 用の EditorConfig プラグインをインストール方法はいくつかあるので、詳しくは下記のページを参照してください。 EditorConfig plugin for Vim 例えば、プラグイン管理に Vundle を使用しているのであれば、.vimrc に次のような行を追加し、 .vimrc Plugin \u0026#39;editorconfig/editorconfig-vim\u0026#39; 次のように実行するだけでインストールできます。 :PluginInstall （おまけ）パターンに一致するファイルのルールをオーバーライドする .editorconfig ファイルの中で、同じ名前のプロパティが複数個所で設定されている場合は、最後に見つかったものが優先的に使われます。 この性質を利用して、特定のファイルに対するルールだけをオーバーライドすることができます。 例えば、ユニットテスト関連のファイルだけルールを緩くしたいという場合は、次のような感じで設定値を上書きするようにします（優先度の高いものが下に来るように記述するのがポイントです）。 .editorconfig # Kotlin のファイルは基本 100 文字で折り返し [*.{kt,kts}] max_line_length = 100 # 名前が Test で終わるファイルでは長い関数名を付けたいことがあるので折り返し制限しない [*Test.kt] max_line_length = off # test ディレクトリ以下のファイルも同様に折り返し制限しない [test/**.kt] max_line_length = off （おまけ）ktlint などのフォーマットツールでの利用 Kotlin の lint ツールである ktlint は、設定フリーなツール（デフォルトで Kotlin の標準的なルールに従う）として開発されていますが、プロジェクトに .editorconfig ファイルが存在する場合はその設定に従って Kotlin コードのスタイルチェック（および自動フォーマット）を行うようになっています。 例えば、EditorConfig の indent_size が定義されていると、ktlint はその設定に従ってインデントのチェックを行います。 ktlint のデフォルトのルールは、Standard rules のところに一覧があります。 それぞれのルールには ID が割り当てられており、.editorconfig 内で個別に無効化することができます。 例えば、ktlint はデフォルトでワイルドカードを使ったインポートを禁止 (ID: no-wildcard-imports) していますが、このルールを無効にするには、次のように disabled_rules でルール ID を指定します（カンマ区切りで複数指定可能です）。 .editorconfig # ktlint のルールを無効化する [*.{kt,kts}] disabled_rules = no-wildcard-imports"
},
{
url: "/p/buk5i2o/",
title: "JavaScript で任意のテキストをクリップボードにコピーする",
date: "2020-11-20T00:00:00Z",
body: "JavaScript で任意のテキストをクリップボードにコピーする copyToClipboard 関数 次の copyToClipboard 関数を使うと、引数で指定したテキストを OS のクリップボードにコピーすることができます。 function copyToClipboard(text){ // テキストコピー用の一時要素を作成 const pre = document.createElement(\u0026#39;pre\u0026#39;); // テキストを選択可能にしてテキストセット pre.style.webkitUserSelect = \u0026#39;auto\u0026#39;; pre.style.userSelect = \u0026#39;auto\u0026#39;; pre.textContent = text; // 要素を追加、選択してクリップボードにコピー document.body.appendChild(pre); document.getSelection().selectAllChildren(pre); const result = document.execCommand(\u0026#39;copy\u0026#39;); // 要素を削除 document.body.removeChild(pre); return result; } JavaScript からクリップボードにテキストをコピーするときは、任意の HTML 要素のテキストを選択して、document.execCommand('copy') を実行するという流れになります。 そのため、上記の関数では、テキスト選択用の一時的な pre 要素を作成しています。 使用例 例えば次のようにすると、ボタンを押したときにクリップボードにテキストをコピーできます。 クリップボードにコピー ← 実際に動作します function copyToClipboard(text){ const pre = document.createElement('pre'); pre.style.webkitUserSelect = 'auto'; pre.style.userSelect = 'auto'; pre.textContent = text; document.body.appendChild(pre); document.getSelection().selectAllChildren(pre); const result = document.execCommand('copy'); document.body.removeChild(pre); return result; } window.addEventListener('DOMContentLoaded', () = { document.getElementById('copy').addEventListener('click', () = { copyToClipboard('こんにちは！\\nテキストがコピーされたよ！'); }); }); sample.html \u0026lt;button id=\u0026#34;copy\u0026#34;\u0026gt;クリップボードにコピー\u0026lt;/button\u0026gt; \u0026lt;script\u0026gt; window.addEventListener(\u0026#39;DOMContentLoaded\u0026#39;, () =\u0026gt; { document.getElementById(\u0026#39;copy\u0026#39;).addEventListener(\u0026#39;click\u0026#39;, () =\u0026gt; { copyToClipboard(\u0026#39;こんにちは！\\nテキストがコピーされたよ！\u0026#39;); }); }); \u0026lt;/script\u0026gt;"
},
{
url: "/p/m7ju6gr/",
title: "Apollo Client でクリック時に GraphQL クエリを実行する",
date: "2020-11-12T00:00:00Z",
body: "Apollo Client でクリック時に GraphQL クエリを実行する 図: useLazyQuery による GraphQL クエリ実行 はじめに Apollo Client の useQuery フックを使用すると、GraphQL を使って取得した情報を表示する React コンポーネントをシンプルに実装することができます。 useQuery フックによる GraphQL クエリは、React コンポーネントの表示時に実行されますが、代わりに useLazyQuery フックを使用すると、任意のタイミング、例えばボタンを押した時に GraphQL クエリを実行できるようになります。 前提として、Apollo Client の useQuery の基本的な使い方は下記の記事などで理解しているものとし、ここでは、useLazyQuery フックの使い方を説明します。 参考: Apollo Client で GitHub GraphQL API を使う (Node \u0026amp; React)\u0026quot; useQuery と useLazyQuery の違い 下記の抜粋コードは、useQuery 関数と useLazyQuery 関数の使い方の違いを表しています。 // const GET_ISSUES = gql`...`; const {loading, error, data} = useQuery(GET_ISSUES); const [getIssues, {loading, error, data}] = useLazyQuery(GET_ISSUES); useQuery 関数は呼び出し直後に GraphQL クエリが実行され、その状態や結果が直ちに loading、error、data といった戻り値に格納されます。 一方 useLazyQuery 関数の場合は、戻り値の最初の要素として、クエリ実行関数が返されます（上記の例では getIssues にしてるけど、変数名は executeQuery とか何でも OK）。 GraphQL クエリを実行するには、このクエリ実行関数を呼び出す必要があるので、例えば次のようにボタン要素の onClick で呼び出すようにしておきます。 あとは、useQuery 関数の使い方と同様です。 \u0026lt;button onClick={() =\u0026gt; getIssues()}\u0026gt;Issue取得\u0026lt;/button\u0026gt; ちなみに、useLazyQuery 関数が返す値（loading、error、data など）は次のように変化します（ここでは呼び出しが正常に終了したものとしているので、error の値は undefined で変化しません）。 クエリ実行前 クエリ実行中 結果取得後 loading = false error = undefined data = undefined called = false loadng = true error = undefined data = undefined called = true loading = false error = undefined data = 結果オブジェクト called = true called はまさに useLazyQuery 関数用の戻り値で、クエリ実行関数を呼び出した時点で true になります。 GraphQL クエリを実行する前と、実行した後で表示を切り替えたい場合に便利です。 useLazyQuery を使った実装例 下記は、Apollo Client の useLazyQuery 関数の使用例です。 表示された Issue 取得 ボタンを押すと、GraphQL クエリで GitHub リポジトリ (apollographql/apollo) の Issue 情報を取得して表示します。 ApolloProvider コンポーネントなどのセットアップは、上位のコンポーネントで行われているものとします。 import * as React from \u0026#39;react\u0026#39;; import {ApolloError, gql, useLazyQuery} from \u0026#39;@apollo/client\u0026#39;; // 発行する GraphQL クエリ const GET_ISSUES = gql` query { search(query: \u0026#34;repo:apollographql/apollo is:issue\u0026#34;, type: ISSUE, last: 3) { issueCount nodes { ... on Issue { number title } } } } `; // RepoInfo コンポーネントの実装 export const RepoInfo: React.FC = () =\u0026gt; { const [getIssues, {loading, error, data, called}] = useLazyQuery(GET_ISSUES); const issueList = called ? createIssueList(loading, error, data) : null; return \u0026lt;div\u0026gt; \u0026lt;button onClick={() =\u0026gt; getIssues()}\u0026gt;Issue取得\u0026lt;/button\u0026gt; {issueList} \u0026lt;/div\u0026gt;; }; // useLazyQuery の結果から表示内容を構築する // （data の構造は GraphQL クエリに対応している） function createIssueList(loading: boolean, error: ApolloError, data: any): React.ReactElement { // クエリ実行中の表示 if (loading) return \u0026lt;p\u0026gt;Loading ...\u0026lt;/p\u0026gt;; // エラー発生時（レスポンスがないとき）の表示 if (error) return \u0026lt;p style={{color: \u0026#39;red\u0026#39;}}\u0026gt;{error.message}\u0026lt;/p\u0026gt;; // クエリの結果が返ってきたときの表示 const {issueCount, nodes: issues} = data.search; return \u0026lt;\u0026gt; \u0026lt;h2\u0026gt;Num of issues: {issueCount}\u0026lt;/h2\u0026gt; \u0026lt;ul\u0026gt; { issues.map(i =\u0026gt; \u0026lt;li key={i.number}\u0026gt;{i.number} - {i.title}\u0026lt;/li\u0026gt;) } \u0026lt;/ul\u0026gt; \u0026lt;/\u0026gt;; }"
},
{
url: "/p/dt5dmu3/",
title: "読書メモ『若ゲのいたり ゲームクリエイターの青春』田中圭一",
date: "2020-10-25T00:00:00Z",
body: "読書メモ『若ゲのいたり ゲームクリエイターの青春』田中圭一 若ゲのいたり ゲームクリエイターの青春 田中圭一 KADOKAWA ゲームクリエイターたちへのインタビューを漫画にしたものです。 こういったゲーム系のインタビュー本って、なるほどーって話が多いので好きです。 女の子を育てるのは犯罪性が感じられるので、舞台をファンタジーの世界にした ─ 赤井孝美（プリンセスメーカーの作者） ゲームの面白さの本質は「リスクを冒してリターンを得る」ということ ─ 桜井政博（大乱闘スマッシュブラザーズの作者） ぷよぷよでカーバンクルが踊るのは、プレイヤーのためでなく、背後のギャラリーを惹きつけるため ─ 仁井谷正充（ぷよぷよの作者） インタビュー本を読むと、紹介されている人たちに興味が出てきて、その人について調べたくなることがよくあります。 今回も本を読んでから、仁井谷さん（ぷよぷよ作ってのちに破産した人）の動向が気になって、Youtube のピョコタンチャンネルを見てしまいました。 仁井谷さんは、70歳で1人でコンパイル◯（まる）という会社を運営して、ゲームをずっと開発し続けてます。 たくさんの人が楽しめるゲームを作りたい、という情熱が伝わってきます。 ずっと情熱を持ち続けているから元気に見えるんでしょうね。 関係ないけど、ピョコタンって誰かに似てると思ったら、ヨーロッパ企画の本田力さんに似てる。。。 あと誰か、伝説のゲーム・プログラマー、ナーシャ・ジベリ氏の本を出してくれないかなぁ。今は行方が分からないらしいですけど。"
},
{
url: "/p/8nw6dks/",
title: "読書メモ『しあわせの書』泡坂妻夫",
date: "2020-10-17T00:00:00Z",
body: "読書メモ『しあわせの書』泡坂妻夫 しあわせの書 泡坂妻夫 新潮社 マジシャンの肩書きも持つ泡坂妻夫氏のミステリー小説です。 読み終わったときに、この本が持つ秘密に衝撃を受けます。 本の冒頭に、 読者の幸せのために 未読の人に「しあわせの書」の秘密を明かさないでください とあるように、ここでその秘密を明かすことはできないのですが、この本には作者の巧妙なたくらみが隠されています。 話の大筋としては、ヨギ ガンジーら、3人の男女が怪しい宗教団体に紛れ込む話なのですが、その中でキーになってくるのが、読心術と『しあわせの書』です。 この本のタイトルと同じです。 Kindle や Sony Reader などの電子書籍でこの本を探しても見つかりません。 なぜなら、この物語に出てくる『しあわせの書』と同様に、この本は「文庫本」という形でしか成立しないからです。 あなたもこの本を読み通す頃には、「読心術」を身につけていることでしょう。"
},
{
url: "/p/cu6eox7/",
title: "Apollo Client の Pagenation 機能を使って GraphQL API を呼び出す",
date: "2020-10-02T00:00:00Z",
body: "Apollo Client の Pagenation 機能を使って GraphQL API を呼び出す Apollo Client の Pagination 機能 GraphQL API では柔軟なクエリ発行が可能ですが、多数の要素を取得する場合は、Pagenation 処理 により何度かに分けて API 呼び出しを行う必要があります。 例えば、GitHub の GraphQL API では一度のクエリで取得可能な要素数は 100 件までであり、それを超える情報を取得する場合に Pagination 処理が必要です。 Apollo Client には、GraphQL の Pagination 処理を簡単に扱うための仕組み（fetchMore 関数）が用意されています。 参考: Pagination - Client (React) - Apollo GraphQL Docs と言っても、そこまで簡単ではないので、ここでは GitHub の GraphQL API における Pagination 処理の具体的な実装例を紹介します。 Pagination の実装例（フィールドポリシーを使う方法） 次のサンプルコードは、GitHub の myorg/myrepo リポジトリの Issue リストを表示する IssueList コンポーネントの実装例です。 Issue の数が 100 件を超える場合は、「さらに読み込む」ボタンを表示し、このボタンが押されたときに Pagination 処理（fetchMore 関数）で次のデータを取得するようにしています。 Apollo クライアントの useQuery 関数が返す fetchMore 関数を呼び出すと、再度 GraphQL クエリを実行することができます。 このとき、オプションで variables パラメータの値（クエリ変数）を変更できるので、Issue の読み出し開始位置を示す after の値を進めていくことで、100 件を超えるデータを順番に読み出すことができます。 IssueList.tsx import { gql, useQuery } from \u0026#39;@apollo/client\u0026#39; import { FC } from \u0026#39;react\u0026#39; // GraphQL クエリ const QUERY_ISSUES = gql` query QueryIssues($cursor: String) { search(first: 100, after: $cursor, type: ISSUE, query: \u0026#34;repo:myorg/myrepo is:issue is:open\u0026#34;) { edges { node { ... on Issue { id number title } } } pageInfo { hasNextPage endCursor } } } ` // \u0026#34;さらに読み込む\u0026#34; ボタン function createFetchMoreButton(pageInfo, fetchMore): JSX.Element | null { if (!pageInfo.hasNextPage) { return null } return ( \u0026lt;button onClick={() =\u0026gt; { fetchMore({ variables: { cursor: pageInfo.endCursor } }) }}\u0026gt;さらに読み込む\u0026lt;/button\u0026gt; ) } export const IssueList: FC = () =\u0026gt; { const { loading, error, data, fetchMore } = useQuery(QUERY_ISSUES) if (error) return \u0026lt;p\u0026gt;{error.message}\u0026lt;/p\u0026gt; if (loading) return \u0026lt;p\u0026gt;Loading ...\u0026lt;/p\u0026gt; const { search } = data const { pageInfo } = search return \u0026lt;\u0026gt; \u0026lt;ul\u0026gt; {search.edges.map(({ node }) =\u0026gt; ( \u0026lt;li key={node.id}\u0026gt; {node.number}: {node.title} \u0026lt;/li\u0026gt; ))} \u0026lt;/ul\u0026gt; {createFetchMoreButton(pageInfo, fetchMore)} \u0026lt;/\u0026gt; } 実はこれだけでは、不十分で、ApolloClient インスタンスを生成するときにキャッシュの フィールドポリシー というものを設定しておく必要があります。 ApolloClient（の InMemoryCache）は、デフォルトの動作として、クエリ結果を別々のオブジェクトとしてキャッシュしようとするので、fetchMore で複数回に分けて取得したデータをマージして返して欲しい場合は、InMemoryCache オブジェクトを次のようにカスタマイズしなければいけません。 GitHubApolloProvider.tsx import { ApolloClient, ApolloProvider, InMemoryCache } from \u0026#39;@apollo/client\u0026#39; import { relayStylePagination } from \u0026#39;@apollo/client/utilities\u0026#39; // ... const cache = new InMemoryCache({ typePolicies: { Query: { fields: { search: relayStylePagination([\u0026#39;type\u0026#39;, \u0026#39;query\u0026#39;]), }, }, }, }) // Creates a GraphQL client const apolloClient = new ApolloClient({ link: authLink.concat(httpLink), cache }) export const GitHubApolloProvider: React.FC = (prop) =\u0026gt; { return \u0026lt;ApolloProvider client={apolloClient}\u0026gt;{prop.children}\u0026lt;/ApolloProvider\u0026gt; } 上記の例では、クエリ結果の search フィールドをページネーションによって繰り返し取得した場合に、結果のリストをマージして返すように指定しています。 relayStylePagination 関数は Apollo が提供しているユーティリティ関数で、Relay-style connections によるページネーション処理を行う場合に使用することができます。 Relay-style というのは、上記の GitHub GraphQL レスポンスのように、pageInfo や edges というフィールドがある場合に採用されているページネーションスタイルだと考えればよいです。 参考: GraphQL Cursor Connections Specification relayStylePagination 関数には keyArgs と呼ばれる引数を渡すことができ、クエリ時にどのパラメーターが異なっていたら別のキャッシュとして管理するかを指定します。 search クエリ (Connection) は、type 引数あるいは query 引数に違う値が指定された場合は、全然違う情報を取得することになるので結果をマージされては困ります。 そこで、上記のように ['type', 'query'] と指定するわけです。 ☝️ edges と nodes Relay スタイル (Cursor Connections) では、ページネーション用に pagesInfo や edges などのオブジェクトを使用します。 一方で、GitHub の GraphQL スキーマでは、edges 以下の各 node にアクセスするためのショートカットとして nodes が定義されています。 多くのケースではこの nodes オブジェクトを参照することでクライアントコードが簡潔になるのですが、Apollo client が提供する relayStylePagination() 関数を使用する場合は、edges を参照するような GraphQL クエリを発行しないとうまく動作しないようですので注意してください。 ページネーションをどのように実装しているかは、GraphQL のサーバーによって異なるので、それに応じてフィールドポリシーの設定方法も変える必要があります。 フィールドポリシーの詳しい設定方法は、下記の Apollo Client ドキュメントを参照してください。 参考: Core pagination API - Client (React) - Apollo GraphQL Docs Pagination の実装例（fetchMore の updateQuery オプションを使う方法） 下記の updateQuery を使ったページネーション処理は、2021-09-15 時点で deprecated になっています。前述のキャッシュの「フィールドポリシー」を使った方法を使ってください。 このコードを実行すると、次のように警告が出ます。 The updateQuery callback for fetchMore is deprecated, and will be removed in the next major version of Apollo Client. このあたりの変更は地味につらい。。。 IssueList.tsx import { FC } from \u0026#39;react\u0026#39; import { gql, useQuery } from \u0026#39;@apollo/client\u0026#39; // GraphQL クエリ const QUERY_ISSUES = gql` query QueryIssues($cursor: String) { search(first: 100, after: $cursor, type: ISSUE, query: \u0026#34;repo:myorg/myrepo is:issue is:open\u0026#34;) { edges { node { ... on Issue { id number title } } } pageInfo { hasNextPage endCursor } } } ` // \u0026#34;さらに読み込む\u0026#34; ボタン function createFetchMoreButton(pageInfo, fetchMore) { if (!pageInfo.hasNextPage) { return null } return ( \u0026lt;button onClick={() =\u0026gt; { fetchMore({ variables: {cursor: pageInfo.endCursor}, updateQuery: (prevResult, {fetchMoreResult}) =\u0026gt; { if (!fetchMoreResult) return prevResult return fetchMoreResult } }) }}\u0026gt;さらに読み込む\u0026lt;/button\u0026gt; ) } export const IssueList: FC = () =\u0026gt; { const {loading, error, data, fetchMore} = useQuery(QUERY_ISSUES) if (error) return \u0026lt;p\u0026gt;{error.message}\u0026lt;/p\u0026gt; if (loading) return \u0026lt;p\u0026gt;Loading ...\u0026lt;/p\u0026gt; const {search} = data const {pageInfo} = search return \u0026lt;\u0026gt; \u0026lt;ul\u0026gt; {search.edges.map(({ node }) =\u0026gt; ( \u0026lt;li key={node.id}\u0026gt;{node.number}: {node.title}\u0026lt;/li\u0026gt; ))} \u0026lt;/ul\u0026gt; {createFetchMoreButton(pageInfo, fetchMore)} \u0026lt;/\u0026gt; } ポイントは、Apollo Client の useQuery フックが返す fetchMore 関数の使い方です。 上記の例では、「さらに読み込む」ボタンが押された時に、この fetchMore 関数を呼び出しています。 fetchMore({ variables: {cursor: pageInfo.endCursor}, updateQuery: (prevResult, {fetchMoreResult}) =\u0026gt; { if (!fetchMoreResult) return prevResult; return fetchMoreResult; } }); fetchMore 関数を呼び出すと、variables パラメータで指定した変数値を使って再度 GraphQL クエリが実行され、updateQuery パラメータで指定した関数が返す値で再描画が行われます。 fetchMoreResult には、新しいクエリでサーバーから返された値が格納されているため、これをそのまま返すことで、次のページの情報を描画することができます。 もし、前回取得したデータとマージして表示したいのであれば、次のような感じで、戻り値をうまいこと加工してやります。 この例では、search.nodes のフィールドをマージしています。 fetchMore({ variables: {cursor: pageInfo.endCursor}, updateQuery: (prevResult, {fetchMoreResult}) =\u0026gt; { if (!fetchMoreResult) { return prevResult; } return { search: { __typename: fetchMoreResult.search.__typename, issueCount: fetchMoreResult.search.issueCount, nodes: [...prevResult.search.nodes, ...fetchMoreResult.search.nodes], pageInfo: fetchMoreResult.search.pageInfo, } }; } }); search フィールドの値を漏れなく列挙するのが面倒な場合は、Object.assign() による Shallow マージの仕組みを使って、次のように記述することもできます。 return { search: Object.assign({}, fetchMoreResult.search, { nodes: [...prevResult.search.nodes, ...fetchMoreResult.search.nodes] }) };"
},
{
url: "/p/ow3zskd/",
title: "JUnit のテストケースを一時的に無効にする（@Ignore/@Disabledアノテーション）",
date: "2020-09-30T00:00:00Z",
body: "JUnit のテストケースを一時的に無効にする（@Ignore/@Disabledアノテーション） JUnit で特定のテストケース（クラスや関数）を一時的に無効にしておきたい場合は、次のようなアノテーションをクラスや関数に付けます。 JUnit4 の場合: @Ignore アノテーション (org.junit.Ignore) JUnit5 の場合: @Disabled アノテーション (org.junit.jupiter.api.Disabled) Java の場合 // import org.junit.Ignore; // import org.junit.Test; public class MyClassTest { @Test @Ignore public void testSomething() { // ... } } Kotlin の場合 // import org.junit.Ignore // import org.junit.Test class MyClassTest { @Test @Ignore fun testSomething() { // ... } } @Ignore (@Disabled) に文字列パラメータを渡すと、なぜそのテストを無効にしているのかを示すことができます。 @Ignore(\u0026#34;HogeHogeのパラメータを整理中\u0026#34;) @Test fun testSomething() { // ... } このメッセージは JUnit でテストを実行したときに表示されます。 下記は、Android Studio 上で JUnit によるテストを実行したときの表示例です。 16 個のテスト関数のうち 1 つが無視され、その理由が表示されています。"
},
{
url: "/p/e58h5in/",
title: "雑多な技術メモ",
date: "2020-09-30T00:00:00Z",
body: "雑多な技術メモ"
},
{
url: "/p/fdnpuro/",
title: "GitHub GraphQL クエリ例: マイルストーン情報を取得する (milestone)",
date: "2020-09-24T00:00:00Z",
body: "GitHub GraphQL クエリ例: マイルストーン情報を取得する (milestone) マイルストーン番号で Milestone オブジェクトを取得する リポジトリ名（組織名/リポジトリ名）が分かっている場合は、repository クエリ で取得した Repository オブジェクト の milestone フィールドに マイルストーン番号 を指定することで、そのマイルストーンの Milestone オブジェクト を取得することができます。 例えば、Web アプリなどでは、/milestone/123 のようなパスで指定したマイルストーンの情報を表示したいことがありますが、このようなケースで 123 という番号を使って情報を取得することができます。 記述中 GraphQL クエリ query{repository(owner:\u0026#34;myorg\u0026#34;,name:\u0026#34;myrepo\u0026#34;){milestone(number:123){numbertitledueOndescriptionurlissues(first:100){nodes{numbertitleclosedurl}}}}} マイルストーンが設定されていないイシューを取得する search クエリ で、Issue や PullRequest を検索するときに、query パラメータで渡す文字列に no:milestone を含めると、マイルストーンの設定されていないものだけを検索することができます。 次の例では、myorg/myrepo リポジトリにおいて、マイルストーンの設定されていない Issue の一覧を取得しています（query 引数に is:issue を含めることで、PullRequest まで取得されてしまうのを防いでいます）。 GraphQL クエリ query{rateLimit{costremaining}search(type:ISSUE,last:100,query:\u0026#34;repo:myorg/myrepo is:issue no:milestone\u0026#34;){nodes{...onIssue{numbertitleclosedurlassignees(first:100){nodes{loginavatarUrlurl}}labels(first:100){nodes{namecolor}}}}}} no:milestone の他にも、no:label（ラベルのないもの）、no:assignee（アサインされていないもの）、といった条件で検索することができます。 参考: 欠損しているメタデータで検索 - GitHub Docs あるリポジトリのマイルストーンの一覧を取得する → こちらを参照"
},
{
url: "/p/z69a3tk/",
title: "GitHub GraphQL クエリ例: PullRequest の情報を取得する (search)",
date: "2020-09-18T00:00:00Z",
body: "GitHub GraphQL クエリ例: PullRequest の情報を取得する (search) 自分のレビュー待ちになっている PR を取得する search クエリの query パラメータで、is:pr review-requested:@me と指定すると、自分がレビューワー (reviewer) として設定されているプルリクエストを検索することができます。 GraphQL クエリ query{search(type:ISSUE,last:100,query:\u0026#34;is:open is:pr review-requested:@me\u0026#34;){issueCountnodes{...onPullRequest{numbertitleurlcreatedAtauthor{loginavatarUrlurl}reviewRequests(first:100){nodes{requestedReviewer{...onUser{loginavatarUrlurl}}}}}}}} PullRequest オブジェクトの詳細はこちら。"
},
{
url: "/p/i5ht5ep/",
title: "GitHub GraphQL クエリ例: イシュー情報を取得する (search)",
date: "2020-09-14T00:00:00Z",
body: "GitHub GraphQL クエリ例: イシュー情報を取得する (search) イシュー情報の取得方法 イシュー情報を取得する方法は次のような方法があります。 ユーザーからたどる方法 \u0026ndash; viewer/user クエリ で User オブジェクト を取得し、そのユーザーに関連するイシュー（issues フィールド）を参照する方法 リポジトリからたどる方法 \u0026ndash; repository クエリ で Repository オブジェクト を取得し、そのリポジトリ内のイシュー（issues フィールド）を参照する方法 ダイレクトに検索する方法 \u0026ndash; search クエリ でもろもろの検索条件（リポジトリ名、タイプなど）を使ってダイレクトに検索する方法 search クエリによる検索はとても柔軟で、様々な条件（query パラメータ）を指定してイシューを検索することができます。 query パラメータには、GitHub の Issues ページの検索窓に入力できる is:issue is:open といった文字列で、下記のサイトに詳細仕様が記述されています。 Issue およびプルリクエストを検索する - GitHub Docs あるリポジトリのイシューの一覧を取得する 次の GraphQL クエリでは、myorg/myrepo リポジトリの最新 5 件のイシュー情報を取得しています。 GraphQL クエリ query{search(type:ISSUE,query:\u0026#34;repo:myorg/myrepo is:issue\u0026#34;,last:100){issueCountnodes{...onIssue{idnumbertitleclosedurlauthor{login}assignees(first:100){nodes{loginnameemail}}labels(first:100){nodes{namecolor}}}}}} search クエリはそのパラメータの意味を理解するのが重要です。 type: ISSUE 検索対象を示す必須パラメータで、ISSUE / REPOSITORY / USER のいずれかを指定する必要があります。ここでは、イシューやプルリクエストの情報を検索することを示しています（ISSUE はプルリクエストの情報まで含むことに注意）。 query: \u0026quot;repo:myorg/myrepo is:issue\u0026quot; 検索対象を指定したリポジトリに絞り込み、さらに、is:issue を指定することでプルリクエストを除外します。他にもいろいろな指定方法があります。 last: 100 最新の 100 件までのイシュー情報を取得します。100 件を超えるデータを取得するときはページネーション処理により、複数回のクエリ実行が必要です。 その他のクエリ方法いろいろ あるマイルストーンが設定されたイシューを取得する search(type:ISSUE,last:100,query:\u0026#34;repo:myorg/myrepo milestone: \\\u0026#34;Milestone #123\\\u0026#34; is:issue\u0026#34;) この例では、myorg/myrepo リポジトリから、マイルストーン名 Milestone #123 が設定されたイシューの一覧を取得しています。 マイルストーン名にスペースを含んでいる場合は、上記のようにエスケープされたダブルクォートでマイルストーン名を囲む必要があります。"
},
{
url: "/p/du6env5/",
title: "GitHub GraphQL クエリ例: リポジトリの情報を取得する (repository)",
date: "2020-09-14T00:00:00Z",
body: "GitHub GraphQL クエリ例: リポジトリの情報を取得する (repository) GitHub の GraphQL API を使ってリポジトリの情報を取得するには、次のような方法があります。 repository クエリ \u0026hellip; 組織名（あるいはユーザ名）とリポジトリ名が分かっている場合 organization クエリ \u0026hellip; ある組織内のリポジトリの一覧を取得する場合（こちらの記事 を参考にしてください） search クエリ \u0026hellip; 汎用的な検索用クエリ でリポジトリを検索する search クエリでリポジトリを検索する 特定の組織 (organization) 内のリポジトリを取得するには、organization クエリを使って 得られた Organization オブジェクトの repositories を参照する方法もありますが、最初から search クエリを使っていろいろな条件を指定して検索する方が早いです。 参考: リポジトリを検索する - GitHub Docs 次の例では、myorg という組織内の、product というトピックの付けられたリポジトリの一覧を取得しています。 クエリ例 query{search(type:REPOSITORY,query:\u0026#34;org:myorg topic:product\u0026#34;,last:100){repositoryCountnodes{...onRepository{idurlnamedescriptioncreatedAt}}}} 実行結果 { \u0026#34;data\u0026#34;: { \u0026#34;search\u0026#34;: { \u0026#34;repositoryCount\u0026#34;: 3, \u0026#34;nodes\u0026#34;: [ { \u0026#34;id\u0026#34;: \u0026#34;DEMwOlJlcG9zaXRvcnkzODA5MTQ0OQ==\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;https://github.com/myorg/Repo1\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Repo1\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Repo1 の概要説明\u0026#34;, \u0026#34;createdAt\u0026#34;: \u0026#34;2015-06-26T04:54:51Z\u0026#34; }, { \u0026#34;id\u0026#34;: \u0026#34;DEMwOlJlcG9zaXRvcnkxNjI2NjczMjY=\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;https://github.com/myorg/Repo2\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Repo2\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Repo2 の概要説明\u0026#34;, \u0026#34;createdAt\u0026#34;: \u0026#34;2018-12-21T04:51:54Z\u0026#34; }, { \u0026#34;id\u0026#34;: \u0026#34;DEMwOlJlcG9zaXRvcnkyNDUzMjU1NDI=\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;https://github.com/myorg/Repo3\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Repo3\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Repo3 の概要説明\u0026#34;, \u0026#34;createdAt\u0026#34;: \u0026#34;2020-03-06T03:56:40Z\u0026#34; }, ] } } } あるリポジトリのマイルストーンの一覧を取得する repository クエリ を使用すると、指定した組織（ユーザー）の、指定したリポジトリの情報を取得することができます。 次の GraphQL クエリは、apollographql/apollo-client リポジトリで設定されているマイルストーンの一覧を要求しています。 milestones クエリで最初の 3 件分を取得していますが、最大 100 件まで同時に取得することができます。 100 件を超えるデータを取得したいときは、ページネーション処理 が必要です。 クエリ例 query{repository(owner:\u0026#34;apollographql\u0026#34;,name:\u0026#34;apollo-client\u0026#34;){nameurlmilestones(states:[OPEN,CLOSED],first:3){totalCountnodes{urltitledueOncloseddescription}pageInfo{endCursorhasNextPage}}}} 実行結果 { \u0026#34;data\u0026#34;: { \u0026#34;repository\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;apollo-client\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;https://github.com/apollographql/apollo-client\u0026#34;, \u0026#34;milestones\u0026#34;: { \u0026#34;totalCount\u0026#34;: 17, \u0026#34;nodes\u0026#34;: [ { \u0026#34;url\u0026#34;: \u0026#34;https://github.com/apollographql/apollo-client/milestone/1\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;alpha\u0026#34;, \u0026#34;dueOn\u0026#34;: \u0026#34;2016-04-19T07:00:00Z\u0026#34;, \u0026#34;closed\u0026#34;: true, \u0026#34;description\u0026#34;: \u0026#34;Alpha release of the client, with enough features to be useful in a real app.\u0026#34; }, { \u0026#34;url\u0026#34;: \u0026#34;https://github.com/apollographql/apollo-client/milestone/2\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;newspring-production\u0026#34;, \u0026#34;dueOn\u0026#34;: null, \u0026#34;closed\u0026#34;: true, \u0026#34;description\u0026#34;: \u0026#34;\u0026#34; }, { \u0026#34;url\u0026#34;: \u0026#34;https://github.com/apollographql/apollo-client/milestone/3\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;5/10 cycle\u0026#34;, \u0026#34;dueOn\u0026#34;: null, \u0026#34;closed\u0026#34;: true, \u0026#34;description\u0026#34;: \u0026#34;Some things to button down in the short term, that a lot of people have been asking about!\u0026#34; } ], \u0026#34;pageInfo\u0026#34;: { \u0026#34;endCursor\u0026#34;: \u0026#34;Y3Vyc29yOnYyOpHOABqZMg==\u0026#34;, \u0026#34;hasNextPage\u0026#34;: true } } } } } マイルストーンの一覧をソートする milestones クエリを発行するときに、orderBy パラメータを指定すると、特定のフィールドの値を使ってソートされた結果を取得することができます。 次の例では、マイルストーンの Due Date が遅いものから順番に 100 件分を取得します。 GraphQL クエリ query{repository(owner:\u0026#34;apollographql\u0026#34;,name:\u0026#34;apollo-client\u0026#34;){milestones(states:[OPEN,CLOSED],last:100,orderBy:{field:DUE_DATE,direction:DESC}){nodes{urltitledueOnclosed}}}} マイルストーンに所属するイシューを取得する milestones クエリを発行するときに、入れ子の形で issues を要求することで、各マイルストーンに所属するイシューのリストまで同時に取得してしまうことができます。 クエリ例 query{repository(owner:\u0026#34;apollographql\u0026#34;,name:\u0026#34;apollo-client\u0026#34;){nameurlmilestones(states:[OPEN,CLOSED],first:3){totalCountnodes{urltitledueOncloseddescriptionissues(states:[OPEN,CLOSED],first:10,labels:[\u0026#34;EPIC\u0026#34;]){nodes{urltitleclosed}pageInfo{endCursorhasNextPage}}}pageInfo{endCursorhasNextPage}}}} 実行結果 省略"
},
{
url: "/p/3o2doyb/",
title: "GitHub GraphQL クエリ例: 組織の情報を取得する (organization)",
date: "2020-09-14T00:00:00Z",
body: "GitHub GraphQL クエリ例: 組織の情報を取得する (organization) GitHub GraphQL API で指定した組織の情報を（ここでは github organization）の情報を取得には、organization クエリ を使用します。 organization クエリには、login パラメーターで組織名を渡します。 organization クエリが返す Organization オブジェクト を参照すると、そこに所属する メンバーの一覧、チームの一覧、リポジトリの一覧 などを取得することができます。 ある組織に所属するユーザー情報を取得する (Organization.membersWithRole) Organization オブジェクトの membersWithRole フィールドは OrganizationMemberConnection オブジェクトを保持しており、この nodes を参照することで、組織に所属するメンバーの一覧を取得できます。 GraphQL クエリ query{organization(login:\u0026#34;github\u0026#34;){namedescriptionurlmembersWithRole(first:3){nodes{loginnameemailupdatedAt}}}} 実行結果 { \u0026#34;data\u0026#34;: { \u0026#34;organization\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;GitHub\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;How people build software.\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;https://github.com/github\u0026#34;, \u0026#34;membersWithRole\u0026#34;: { \u0026#34;nodes\u0026#34;: [ { \u0026#34;login\u0026#34;: \u0026#34;mtodd\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Matt Todd\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;xxx@example.com\u0026#34;, \u0026#34;updatedAt\u0026#34;: \u0026#34;2022-05-28T16:13:01Z\u0026#34; }, { \u0026#34;login\u0026#34;: \u0026#34;jonmagic\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Jonathan Hoyt\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;xxx@example.com\u0026#34;, \u0026#34;updatedAt\u0026#34;: \u0026#34;2022-06-07T18:27:30Z\u0026#34; }, { \u0026#34;login\u0026#34;: \u0026#34;mislav\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Mislav Marohnić\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;xxx@example.com\u0026#34;, \u0026#34;updatedAt\u0026#34;: \u0026#34;2022-04-07T18:34:52Z\u0026#34; } ] } } } } ある組織のリポジトリの一覧を取得する (Organization.repositories) Organization オブジェクトの repositories フィールドを参照することで、その組織に作成されたリポジトリの一覧を取得することができます。 GraphQL クエリ query{organization(login:\u0026#34;github\u0026#34;){namedescriptionurlrepositories(first:3){nodes{nameurl}}}} 実行結果 { \u0026#34;data\u0026#34;: { \u0026#34;organization\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;GitHub\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;How people build software.\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;https://github.com/github\u0026#34;, \u0026#34;repositories\u0026#34;: { \u0026#34;nodes\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;media\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;https://github.com/github/media\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;albino\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;https://github.com/github/albino\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;hubahuba\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;https://github.com/github/hubahuba\u0026#34; } ] } } } } 取得される各リポジトリの情報は、Repository オブジェクト として表現されています。 ここでは、組織内のリポジトリのリストを取得する方法を示しましたが、組織名（ユーザー名）とリポジトリ名があらかじめ分かっている場合は、repository クエリを使って、直接そのリポジトリの情報を取得することができます。 参考: リポジトリの情報を取得する (repository)"
},
{
url: "/p/h5s6ht5/",
title: "Node.js で GitHub GraphQL API を使用する (@octokit/graphql)",
date: "2020-09-10T00:00:00Z",
body: "Node.js で GitHub GraphQL API を使用する (@octokit/graphql) 概要 GitHub 上の情報を扱う API として、GitHub は GraphQL API を提供しています。 GitHub GraphQL API v4 | GitHub Developer Guide Node.js で GraphQL を扱う方法としては、Apollo ライブラリを使った方法 などがありますが、GitHub の GraphQL API を呼び出したいのであれば、GitHub が提供している GraphQL パッケージ @octokit/graphql を使うのが手っ取り早いかもしれません（エンドポイントの URL などを省略できます）。 octokit/graphql.js: GitHub GraphQL API client for browsers and Node @octokit/graphql - npm ここでは、TypeScript からこの @octokit/graphql パッケージを使用する方法を紹介します。 ☝️ REST API と GraphQL API GitHub API バージョン 3 は REST API でしたが、柔軟性などの観点 から、GitHub API バージョン 4 の GraphQL 版の API を使用することが推奨されています。 GraphQL API を使用することで、REST API で複数のリクエストが必要だったものを 1 度のリクエストで取得できたりします。 また、GraphQL API でしか取得できない情報もあったりします。 セットアップ まず、TypeScript のプロジェクトを作成します。 参考：Visual Studio Code で TypeScript の開発環境を構築する @octokit/graphql パッケージは次のようにインストールします。 このパッケージには TypeScript の型情報も含まれています。 あと、環境変数設定用のライブラリとして、dotenv もインストールしておきます。 $ npm install @octokit/graphql --save $ npm install dotenv --save GitHub のアクセストークンが必要になるので、GitHub の設定画面からパーソナルアクセストークンを取得しておいてください。 Settings / Developer Settings / Personal access tokens アクセストークンは、環境変数 MYAPP_GITHUB_TOKEN か、プロジェクトルートの .env ファイルに次のように保存しておきます。 .env MYAPP_GITHUB_TOKEN=ccdccab3363b3554ebadc033fa8fe43403705301 サンプルコード ここでは、次のような方針で、@octkit/graphql モジュールを使ったコードを作成してみます。 パーソナルアクセストークンは環境変数 MYAPP_GITHUB_TOKEN（あるいは .env ファイル）で設定する 上記トークンを使って GraphQL リクエストを送る graphql モジュールを作成し、それをメインプログラムから使用する 次の graphql モジュールは、アクセストークン付きの GraphQL リクエストを送るためのセットアップを行います。 この処理をメインプログラムから切り出しておくことで、メインプログラム側のコードをスッキリさせることができます。 graphql.ts import { graphql } from \u0026#39;@octokit/graphql\u0026#39;; import * as dotenv from \u0026#39;dotenv\u0026#39;; // .env ファイルの内容を環境変数に反映 dotenv.config(); // graphql をアクセストークン付きで呼び出せるようにする const graphqlWithAuth = graphql.defaults({ headers: { authorization: `token ${process.env.MYAPP_GITHUB_TOKEN}`, }, }); export { graphqlWithAuth as graphql }; メインプログラムからは次のように GraphQL リクエストを実行します。 ここでは、GitHub の octokit/graphql.js リポジトリの最新の Issue 情報を取得しています。 main.ts import { graphql } from \u0026#39;./graphql\u0026#39;; const QUERY = ` { repository(owner: \u0026#34;octokit\u0026#34;, name: \u0026#34;graphql.js\u0026#34;) { issues(last: 3, states: [OPEN]) { edges { node { number title } } } } } `; async function main() { try { const {repository} = await graphql(QUERY); for (const {node: issue} of repository.issues.edges) { console.log(`* ${issue.number}: ${issue.title}`); } } catch (err) { console.error(err.message); } } main(); メインプログラムは GraphQL の呼び出しだけなので、とてもシンプルですね！ これで、GitHub GraphQL API を使った簡単なコマンドラインツールはサクッと作れると思います。 実行結果 * 78: Can\u0026#39;t load client in Cloudflare workers * 176: Can\u0026#39;t use as Octokit with TypeScript * 185: Setting baseUrl for GHES results in 406 when using with @octokit/auth-app （応用）GraphQL の変数を使う 変数を使った GraphQL クエリも簡単に扱うことができます。 変数の値は、graphql 関数の第 2 パラメータで指定します。 main.ts import { graphql } from \u0026#39;./graphql\u0026#39;; const QUERY = ` query getUser($login: String!) { user(login: $login) { login name url websiteUrl avatarUrl } } `; async function main() { try { const {user} = await graphql(QUERY, {login: \u0026#39;maku77\u0026#39;}); console.log(user); } catch (err) { console.error(err.message); } } main(); 実行結果 { login: \u0026#39;maku77\u0026#39;, name: \u0026#39;Masatoshi Ohta\u0026#39;, url: \u0026#39;https://github.com/maku77\u0026#39;, websiteUrl: \u0026#39;https://maku77.github.io/\u0026#39;, avatarUrl: \u0026#39;https://avatars2.githubusercontent.com/u/5519503?v=4\u0026#39; } （応用）ページネーションで 100 件を超えるデータを取得する GitHub GraphQL API で何らかのリスト情報を取得する場合（Issue リストなど）、一度に取得できるデータ数は 100 件までに制限されています。 それより多くのデータを取得したい場合は、ページネーションによって繰り返しリクエストを送る必要があります。 次のページが存在するかどうかは pageInfo.hasNextPage、次のページの開始位置は pageInfo.endCursor で取得することができます。 main.ts import { graphql } from \u0026#39;./graphql\u0026#39;; const QUERY = ` query getIssues($after: String) { repository(owner: \u0026#34;octokit\u0026#34;, name: \u0026#34;graphql.js\u0026#34;) { issues(first: 100, after: $after) { edges { node { number title } } pageInfo { endCursor hasNextPage } } } } `; async function main() { try { // ページネーション情報 let hasNextPage = true; let endCursor: string | null = null; // 次のページがあれば GraphQL 呼び出し while (hasNextPage) { const {repository: {issues}} = await graphql(QUERY, {after: endCursor}); // 現在のページの Issue 情報を出力 for (const {node} of issues.edges) { console.log(`* ${node.number}: ${node.title}`); } // ページネーション情報を更新 hasNextPage = issues.pageInfo.hasNextPage; endCursor = issues.pageInfo.endCursor; } } catch (err) { console.error(err.message); } } main(); （応用）プロキシ経由で接続する 社内などのプロキシ環境から @octokit/graphql を使用するには、graphql.defaults 関数に渡すオプションオブジェクトの request.agent プロパティを指定します。 この値には、https-proxy-agent モジュールが提供する HttpProxyAgent オブジェクトを設定できます。 https-proxy-agent のインストール $ npm install https-proxy-agent --save const PROXY = \u0026#39;https://proxy.example.com:8080\u0026#39;; const graphqlWithAuth = graphql.defaults({ headers: { authorization: `token ${process.env.MYAPP_GITHUB_TOKEN}`, }, request: { agent: new HttpsProxyAgent(PROXY); } }); 下記は、環境変数 https_proxy のプロキシ設定を GraphQL API の呼び出しに使用する例です。 graphql.ts import * as dotenv from \u0026#39;dotenv\u0026#39;; import { HttpsProxyAgent } from \u0026#39;https-proxy-agent\u0026#39;; import { graphql } from \u0026#39;@octokit/graphql\u0026#39;; // .env ファイルの内容を環境変数に反映 dotenv.config(); // graphql をアクセストークン付きで呼び出せるようにする const PROXY = process.env.https_proxy; const graphqlWithAuth = graphql.defaults({ headers: { authorization: `token ${process.env.MYAPP_GITHUB_TOKEN}`, }, request: { agent: PROXY ? new HttpsProxyAgent(PROXY) : undefined } }); export { graphqlWithAuth as graphql };"
},
{
url: "/p/whv8it5/",
title: "GitHub GraphQL のスキーマ情報を取得する",
date: "2020-09-09T00:00:00Z",
body: "GitHub GraphQL のスキーマ情報を取得する GitHub API のサイトからダウンロードする方法 次のサイトから GitHub GraphQL API のスキーマ定義ファイル (schema.docs.graphql) をダウンロードすることができます。 パブリックスキーマ - GitHub Docs 例えば、このファイル内の Query オブジェクト (type Query) の定義を見ると、クエリのトップレベルにどのようなオブジェクト（フィールド）を指定できるかが分かります。 schema.docs.graphql typeQuery{...organization(login:String!):Organization...user(login:String!):User} 上記の場合、Query オブジェクト内に organization や user フィールドが定義されているので、クライアントアプリからクエリ要求を出すときに、次のような感じで指定できるということが分かります。 query{organization(login:\u0026#34;netflix\u0026#34;){namedescriptionavatarUrl}user(login:\u0026#34;octocat\u0026#34;){namecompanyurlavatarUrl}} スキーマ定義ファイル (.graphql) とクライアントアプリ側のクエリ定義 (query {...}) を組み合わせることで、TypeScript 用の型定義ファイルを自動生成することができます（クエリ要求の戻り値の型を定義できます）。 詳しくは、Apollo CLI などのコマンドラインツールを確認してください。 GraphQL サーバーから直接取得する方法 GitHub の GraphQL API サーバーに HTTP GET リクエストを送ることで、スキーマ定義を直接取得することができます。 パーソナルアクセストークンはこちら から生成してください。 $ token=\u0026lt;YOUR_PERSONAL_ACCESS_TOKEN\u0026gt; $ curl -H \u0026#34;Authorization: bearer $token\u0026#34; https://api.github.com/graphql 結果は圧縮された JSON テキストで返されます。 python -m json.tool にパイプすることで見やすく整形された JSON テキストを取得できます。 $ curl -H \u0026#34;Authorization: bearer $token\u0026#34; https://api.github.com/graphql | python -m json.tool 返されたスキーマ定義をファイルに保存すると、サイズは約 5MB になります。"
},
{
url: "/p/9u8it5f/",
title: "GitHub Pages で React Router を使った SPA サイトを動かす方法",
date: "2020-09-07T00:00:00Z",
body: "GitHub Pages で React Router を使った SPA サイトを動かす方法 React Router などを使った SPA (Single Page Application) な Web サイトは、GitHub Pages でそのまま動作させようとしてもうまく動きません。 ここでは、その理由と、対応方法について説明します。 GitHub Pages で SPA サイトが動作しない理由 たとえば、React Router を使った Web サイトは、次のような URL を使って目的のコンテンツ (/book/123) を表示するようルーティングします。 https://yourname.github.io/repo-name/book/123 React Router を使ったアプリで、この URL を実際に処理するファイルは、 https://yourname.github.io/repo-name/index.html であり、そこに記述された JavaScript ファイル内で、URL の末尾の /book/123 という部分をルーティング用のパス文字列として処理します。 つまり、前述の URL の /book/123 という部分は、単なるアプリ用のデータであり、実際に存在するファイルを示しているわけではありません。 一方、GitHub Pages はそのような事情を知らないので、/book/123 という URL でアクセスしようとすると、/book/123/index.html というファイルを見つけようとして 404 エラー になってしまいます。 先頭ページ (/index.html) を開いた後で、JavaScript でルーティング（React の Link コンポーネントによる遷移）を行っている間はうまく動作するのですが、ページをリロードしたり、Web ブラウザのアドレスバーに URL を直接入力したりすると、やはり 404 エラーになってしまいます。 OAuth 認証を使用した Web サイトの場合は、リダイレクトによって指定された URL へのアクセスが必要になるため、これは大きな制約になります。 解決方法 ここでは、こちら で紹介されている方法を参考にして、カスタム 404 ページを利用したハックで React Router をうまく動作させるようにしてみます。 上記サイトのコードは若干複雑なので、もう少し直感的なコードで同様のことを行えるようにします。 具体的には、クエリ文字列を自力で分解／再構築しているところを、encodeURIComponent/decodeURIComponent でサクッと終わらせちゃいます。 仕組み この 404 ページハックは、次のような仕組みで GitHub Pages 上で SPA アプリ (React Router) を動作可能にします。 https://yourname.github.io/repo-name/book/123 といった URL でアクセスすると、カスタム 404.html ページが呼び出される。 404.html の中の JavaScript で、https://yourname.github.io/repo-name にリダイレクトする。このとき、URL から /book/123 というパラメータを抽出し、?q=book%2F123 のように URL エンコードしたクエリパラメータとして付加する。 Web サイトトップの index.html が呼び出されるので、JavaScript を使って URL 末尾のクエリ文字列 (?q=book%2F123を取り出し、もとのパラメータの形 (/book/123) に戻す。 window.history.replaceState() で Web ブラウザのアドレスを /book/123 にセットし、React Router を動作させる（このときサーバーアクセスは発生しません）。 実装 404.html のアップロード GitHub Pages として公開するリポジトリのルートに、次のような 404.html ファイルをアップロードします。 404.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;My App\u0026lt;/title\u0026gt; \u0026lt;script\u0026gt; // Web サイトをサブディレクトリに配置するなら、この値を 1 にする。 const SEGMENT_COUNT = 0; // 例えば、SEGMENT_COUNT = 1 の場合、 // https://yourname.github.io/repo-name/book/123 のような URL のうち、 // repo-name までをベースアドレスとみなし、末尾のパス (books/123) // をエンコードして次のような URL へリダイレクトする。 // https://yourname.github.io/repo-name?p=book%2F123 const loc = window.location const origin = loc.origin; //=\u0026gt; https://yourname.github.io const path = loc.href.substr(origin.length + 1); //=\u0026gt; repo-name/book/123 const segments = path.split(\u0026#39;/\u0026#39;); //=\u0026gt; [repo-name, book, 123] const repo = segments.slice(0, SEGMENT_COUNT).join(\u0026#39;/\u0026#39;); //=\u0026gt; repo-name const param = segments.slice(SEGMENT_COUNT).join(\u0026#39;/\u0026#39;); //=\u0026gt; book/123 const url = origin + \u0026#39;/\u0026#39; + repo + \u0026#39;?p=\u0026#39; + encodeURIComponent(param); loc.replace(url); \u0026lt;/script\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt;\u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; https://yourname.github.io/ といった URL ではなく、https://yourname.github.io/project名/ といった、1階層下の URL で公開するページの場合は、上記の SEGMENT_COUNT の値を 0 から 1 に変更しておく必要があります（リダイレクト先の URL が調整されます）。 （コラム）バンドルツールで 404.html を追加する Parcel などのバンドルツールで Web サイトのビルドを行っている場合は、エントリポイントとなるページとして 404.html を追加します。 例えば、parcel コマンドを使用している場合は、次のように指定すると build/404.html ファイルが出力されます。 build/404.html の内容は基本的に src/404.html のコピーですが、記述内容が圧縮されたファイルになっています。 $ parcel build src/index.html src/404.html -d build index.html に JavaScript を追加 プロジェクトルートの index.html の先頭の方に、次のような JavaScript コードを追加します。 このコードは、React などの JavaScript コードよりも先に実行する必要があります（Router コンポーネントがパスを処理する前に実行する）。 index.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;ja\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1\u0026#34;\u0026gt; \u0026lt;title\u0026gt;My App\u0026lt;/title\u0026gt; \u0026lt;script\u0026gt; // GitHub Pages での SPA アドレス解決用 (function(){ const query = window.location.search; if (query.startsWith(\u0026#39;?p=\u0026#39;)) { const route = decodeURIComponent(query.substr(3)); window.history.replaceState(null, null, route); } })(); \u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;script/index.tsx\u0026#34; async\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div id=\u0026#34;root\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 以上のように、404.html を配置し、index.html に JavaScript コードを追加するだけで、GitHub Pages 上で SPA アプリケーションが動作するようになります。 React Router のベース URL の調整（必要に応じて） React Router は、デフォルトで URL のドメインを除いた残りの部分 (例: /repo-name/books/123）をルーティング用のパスとして使用します。 Web サイトのルート階層に index.html を配置しない場合は、basename プロパティでそのディレクトリ名を知らせておく必要があります。 次の例では、basename として、開発時はデフォルトの / を、実運用時は /repo-name を使用するように設定しています。 App.tsx import * as React from \u0026#39;react\u0026#39;; import { BrowserRouter as Router, Redirect, Route, Switch } from \u0026#39;react-router-dom\u0026#39;; import { Main } from \u0026#39;./Main\u0026#39;; import { Top } from \u0026#39;./Top\u0026#39;; const ROUTER_BASENAME = process.env.NODE_ENV === \u0026#39;development\u0026#39; ? \u0026#39;/\u0026#39; : \u0026#39;/repo-name\u0026#39;; export const App: React.FC = () =\u0026gt; { return (\u0026lt;div style={{margin: \u0026#39;1em\u0026#39;}}\u0026gt; \u0026lt;Router basename={ROUTER_BASENAME}\u0026gt; \u0026lt;Switch\u0026gt; \u0026lt;Route path=\u0026#34;/\u0026#34; exact={true} component={Top} /\u0026gt; \u0026lt;Route path=\u0026#34;/main\u0026#34; component={Main} /\u0026gt; \u0026lt;Redirect to=\u0026#34;/\u0026#34; /\u0026gt; \u0026lt;/Switch\u0026gt; \u0026lt;/Router\u0026gt; \u0026lt;/div\u0026gt;); }; この設定により、/main というパスは、実際には /repo-name/main としてハンドルされるようになります。"
},
{
url: "/p/my8fmsy/",
title: "GitHub Pages で Jekyll による変換を無効化する（プッシュした HTML をそのまま表示する）",
date: "2020-09-03T00:00:00Z",
body: "GitHub Pages で Jekyll による変換を無効化する（プッシュした HTML をそのまま表示する） GitHub プロジェクトの設定画面から、GitHub Pages を有効化すると、簡単にウェブサイトをホスティングすることができます。 デフォルトでは、リポジトリ内の Markdown ファイル (.md) が Jekyll によって HTML に変換されるのですが、直接 HTML ファイルをデプロイする場合は、この変換処理は無駄です。 そのような場合は、次のようにして Jekyll による変換を無効化できます。 リポジトリのルートに .nojekyll ファイルを置く これだけです。 公開用ブランチとして gh-pages を設定している場合は、そのブランチのルートに置いてください。 Hugo などの静的 Web サイト生成ツールで作成したサイトをデプロイするような場合は、この設定を行っておくと、ファイルのプッシュ後に GitHub Pages に反映されるまでの時間がほんの少し早くなるかもしれません。 速度を気にしない場合はこの設定をする必要はありませんが、プッシュする Web サイトリソース内に、アンダースコア (_) で始まるファイルやディレクトリなどが含まれている場合は、この設定は必須になります。 なぜなら、Jekyll がアンダースコアで始まるファイルやディレクトリを取り除いてしまうからです。"
},
{
url: "/p/j6iu6gs/",
title: "JavaScript で現在のページの URL の構成要素を取得する (window.location)",
date: "2020-09-03T00:00:00Z",
body: "JavaScript で現在のページの URL の構成要素を取得する (window.location) Web サイト上で実行される JavaScript から window.location を参照すると、カレントページの URL の構成要素をパーツごとに取得することができます。 JavaScript const loc = window.location; console.log(\u0026#39;location.href = \u0026#39; + loc.href); console.log(\u0026#39;location.origin = \u0026#39; + loc.origin); console.log(\u0026#39;location.host = \u0026#39; + loc.host); console.log(\u0026#39;location.protocol = \u0026#39; + loc.protocol); console.log(\u0026#39;location.hostname = \u0026#39; + loc.hostname); console.log(\u0026#39;location.port = \u0026#39; + loc.port); console.log(\u0026#39;location.pathname = \u0026#39; + loc.pathname); console.log(\u0026#39;location.search = \u0026#39; + loc.search); console.log(\u0026#39;location.hash = \u0026#39; + loc.hash); 例えば、次のようなアドレスにアクセスした場合は、 https://example.com:8042/over/there?key1=val1\u0026amp;key2=val2#nose 次のような結果を取得することができます。 location.href = https://example.com:8042/over/there?key1=val1\u0026amp;key2=val2#nose location.origin = https://example.com:8042 location.host = example.com:8042 location.protocol = https: location.hostname = example.com location.port = 8042 location.pathname = /over/there location.search = ?key1=val1\u0026amp;key2=val2 location.hash = #nose"
},
{
url: "/p/5q3eq2c/",
title: "GitHub Actions で Web サイトをビルドして GitHub Pages へ公開する",
date: "2020-09-01T00:00:00Z",
body: "GitHub Actions で Web サイトをビルドして GitHub Pages へ公開する 何をするか？ GitHub Actions を使うと、GitHub で管理されている Web サイト用リソースの「ビルドとデプロイ」を簡単に自動化することができます。 ここでは、 npm run build による Web サイトのビルド ビルドされたリソースの GitHub Pages へのデプロイ（gh-pages ブランチ） を行う設定を行います。 最終的に、https://yourname.github.io/project名/ という URL で Web サイトが公開されます。 前提条件として、GitHub リポジトリに npm run build でビルド可能な Web サイト用リソースがコミットされているものとします。 ☝️ 他のビルド方法は？ ここでは、npm run build による Web サイトのビルドを前提としましたが、例えば、Hugo によるビルドなどもほぼ同様に行えます。 GitHub Actions の設定 GitHub プロジェクトの Actions タブから、次のように新規ワークフローを作成します。 set up a workflow yourself をクリック main.yml の編集画面になるので、次のように入力して Start commit ボタンを押す .github/workflows/main.yml name:Build and deploy websiteon:push:branches:[master ]jobs:build:runs-on:ubuntu-lateststeps:- uses:actions/checkout@v2- name:Setup Node.jsuses:actions/setup-node@v1with:node-version:14.x- name:Install NPM packagesrun:npm ci- name:Build websiterun:npm run build --if-present- name:Deploy websiteuses:peaceiris/actions-gh-pages@v3with:github_token:${{ secrets.GITHUB_TOKEN }}publish_dir:build これだけで、初回の Web サイトビルドが開始され、ビルド結果が gh-pages ブランチに格納されます。 今後は、master ブランチへのプッシュが行われるたびに、このビルドが実行されます。 ワークフローの内容は読めば簡単に理解できると思いますが、次のようなことをやっています。 ビルド環境として Ubuntu Linux の最新版を使用 master ブランチのソースコードをチェックアウト (actions/checkout@v2) Node.js 14.x を使用するよう設定 (actions/setup-node@v1) NPM パッケージをインストール (npm ci) Web サイトをビルド (npm run build) Web サイトをデプロイ (peaceiris/actions-gh-pages@v3.6.4) 注: ビルド結果は build ディレクトリに出力されているものとします 最後に、gh-pages ブランチの内容を Web サイトとしてホスティングするように、Settings → Pages から GitHub Pages を有効化します（2021-04 追記: 以前は Settings トップページ内に Pages の項目がありましたが、現在はサイドバーに Pages という独立した項目があります）。 これで、https://yourname.github.io/project名/ にアクセスすれば、Web サイトが表示されます。 う〜ん、お手軽すぎる！ 参考リンク Next.js アプリを GitHub Actions でビルドして GitHub Pages でホスティングする"
},
{
url: "/p/m7jw8ju/",
title: "Parcel でビルドした Web サイトが GitHub Pages で動作しないとき",
date: "2020-09-01T00:00:00Z",
body: "Parcel でビルドした Web サイトが GitHub Pages で動作しないとき React アプリを Parcel でビルドして GitHub Pages で公開しようとしたら、真っ白な画面になってしまったので対応方法のメモです。 原因は、トップページの index.html から読み込んでいる JavaScript ファイルのパスが、/index.js のように、ドメインルートからの相対パスになっていることでした。 GitHub Pages で公開する Web サイトの URL が、 https://yourname.github.io/ であれば問題ないのですが、 https://yourname.github.io/project名/ になっている場合は、読み込むファイルは /project名/index.js になっていないといけません。 これを解決するには、例えば、Parcel でビルドしているときは --public-url オプションを使って、次のように指定します。 $ parcel build src/index.html -d build --public-url \u0026#34;/project名/\u0026#34; こうすることで、トップページから /index.js というパスで参照していたものが /project名/index.js に変わってうまく動作するようになります。 npm run build で Web サイトのビルドを行っているのであれば、package.json 内のスクリプト定義で次のように記述しておけばよいでしょう。 package.json { // ... \u0026#34;scripts\u0026#34;: { \u0026#34;start\u0026#34;: \u0026#34;parcel src/index.html --open\u0026#34;, \u0026#34;build\u0026#34;: \u0026#34;rm -rf build \u0026amp;\u0026amp; parcel build src/index.html -d build --public-url \u0026#39;/project名/\u0026#39;\u0026#34; }, // ... } NPM スクリプト内に GitHub のプロジェクト名を含めるのが嫌なときは、CI/CD サーバー上のビルド設定でパラメータ指定するのがよいかもしれません。 例えば、GitHub Actions を使っている場合は、次のような感じで NPM スクリプトに追加パラメータを指定することができます。 .github/workflows/main.yml（抜粋） jobs:build:runs-on:ubuntu-lateststeps:...- name:Build websiterun:npm run build --if-present -- --public-url \u0026#39;/project名/\u0026#39; build スクリプトの実行内容に対してパラメータを渡すには、上記のように -- の後ろに続けてパラメータを指定しないといけないことに注意してください。 こうしないと、--public-url オプションは、npm コマンド自体のオプションとして処理されてしまいます。"
},
{
url: "/p/nfxds8n/",
title: "React Router でコンポーネントの表示・非表示を切り替える",
date: "2020-08-22T00:00:00Z",
body: "React Router でコンポーネントの表示・非表示を切り替える React の Router 系コンポーネント (BrowserRouter / HashRouter / MemoryRouter) を使用すると、論理的なパス管理によって React コンポーネントの表示の On/Off を切り替えることができます。 例えば、/users というパスでアクセスしたときには Users コンポーネントを表示し、/projects というパスでアクセスしたときには Projects コンポーネントを表示する、といったことを実現できます。 react-router-dom のインストール Router 系のコンポーネントは react-router-dom モジュールで提供されているので、まずはこれをインストールします。 TypeScript を使用する場合は、型定義ファイルも一緒にインストールしておきます。 $ npm install --save react-router-dom $ npm install --save-dev @types/react-router-dom BrowserRouter による表示切り替え 図: Router による表示切り替え 次の App コンポーネントでは、BrowserRouter コンポーネントを使って、Page1 と Page2 コンポーネントの表示を切り替えます。 Router 系のコンポーネントには、Router というエイリアス名を付けるのが慣例なのでそれに従います。 Router コンポーネントの下には、表示切り替え用のリンク要素として Link コンポーネントを配置し、表示要素として Route コンポーネントを配置します。 components/App.tsx import * as React from \u0026#39;react\u0026#39; import { BrowserRouter as Router, Link, Route } from \u0026#39;react-router-dom\u0026#39; // 子コンポーネントを適当に用意 const Page1: React.FC = () =\u0026gt; \u0026lt;h1\u0026gt;Page1\u0026lt;/h1\u0026gt; const Page2: React.FC = () =\u0026gt; \u0026lt;h1\u0026gt;Page2\u0026lt;/h1\u0026gt; // Appコンポーネント export const App: React.FC = () =\u0026gt; { return ( \u0026lt;Router\u0026gt; \u0026lt;nav\u0026gt; [\u0026lt;Link to=\u0026#34;/page1\u0026#34;\u0026gt;Page1\u0026lt;/Link\u0026gt;] [\u0026lt;Link to=\u0026#34;/page2\u0026#34;\u0026gt;Page2\u0026lt;/Link\u0026gt;] \u0026lt;/nav\u0026gt; \u0026lt;Route path=\u0026#34;/page1\u0026#34;\u0026gt;\u0026lt;Page1 /\u0026gt;\u0026lt;/Route\u0026gt; \u0026lt;Route path=\u0026#34;/page2\u0026#34;\u0026gt;\u0026lt;Page2 /\u0026gt;\u0026lt;/Route\u0026gt; \u0026lt;/Router\u0026gt; ) } あとは、この App コンポーネントを次のように表示します。 index.tsx import * as React from \u0026#39;react\u0026#39; import * as ReactDOM from \u0026#39;react-dom\u0026#39; import { App } from \u0026#39;./components/App\u0026#39; ReactDOM.render(\u0026lt;App /\u0026gt;, document.getElementById(\u0026#39;root\u0026#39;)) Link コンポーネントとして表示された Page1 や Page2 リンクをクリックすると、Page1 や Page2 コンポーネントの内容が表示されます。 ☝️ Uncaught DOMException: Failed to execute \u0026#39;pushState\u0026#39; on \u0026#39;History\u0026#39; BrowserRouter を動作させるには、Web サーバー上の HTML ファイルをブラウザで開いている必要があります。 ローカルの HTML ファイルを使って動作させたい場合は、BrowserRouter の代わりに HashRouter や MemoryRouter を使用すると動作します。 component パラメータによる表示コンポーネントの指定 下記のサンプルコードでは、Route コンポーネント以下にネストする形で子コンポーネント（Page1 や Page2）を指定しています。 \u0026lt;Router\u0026gt; \u0026lt;Route path=\u0026#34;/page1\u0026#34;\u0026gt;\u0026lt;Page1 /\u0026gt;\u0026lt;/Route\u0026gt; \u0026lt;Route path=\u0026#34;/page2\u0026#34;\u0026gt;\u0026lt;Page2 /\u0026gt;\u0026lt;/Route\u0026gt; \u0026lt;/Router\u0026gt; このように子コンポーネント指定が単純な場合は、次のように Route の component プロパティ を使って表示するコンポーネントを指定してしまうこともできます。 \u0026lt;Router\u0026gt; \u0026lt;Route path=\u0026#34;/page1\u0026#34; component={Page1} /\u0026gt; \u0026lt;Route path=\u0026#34;/page2\u0026#34; component={Page2} /\u0026gt; \u0026lt;/Router\u0026gt; この書き方をすると入れ子が減ってスッキリしますが、細かいパラメータ指定がやりにくかったり、実はタイプ数が増えていたりするので、無理にこの書き方をする必要はないと思います。 パスが完全一致を必須とする (exact) Route コンポーネントは、現在のパスと path プロパティの値が一致した場合に子コンポーネントを表示するものですが、この一致判断は、デフォルトでは前方一致 により行われます。 例えば、次のような Route コンポーネントが配置されているとします。 \u0026lt;Router\u0026gt; \u0026lt;Route path=\u0026#34;/\u0026#34; component={Home} /\u0026gt; \u0026lt;Route path=\u0026#34;/page1\u0026#34; component={Page1} /\u0026gt; \u0026lt;Route path=\u0026#34;/page2\u0026#34; component={Page2} /\u0026gt; \u0026lt;/Router\u0026gt; このとき、現在のパスが /page1/xxx だとすると、Home コンポーネントと Page1 コンポーネントの両方が同時に表示されます。 現在のパス 表示されるコンポーネント / Home /page1 Home と Page1 /page1/xxx Home と Page1 /page2 Home と Page2 /page2/xxx Home と Page2 パスの一致判断を、前方一致ではなく完全一致にするには、次のように exact プロパティを指定します。 \u0026lt;Router\u0026gt; \u0026lt;Route exact path=\u0026#34;/\u0026#34; component={Home} /\u0026gt; \u0026lt;Route exact path=\u0026#34;/page1\u0026#34; component={Page1} /\u0026gt; \u0026lt;Route path=\u0026#34;/page2\u0026#34; component={Page2} /\u0026gt; \u0026lt;/Router\u0026gt; このように記述しておくと、Home と Page コンポーネントに関しては、パスが完全一致したときのみ表示されるようになります。 現在のパス 表示されるコンポーネント / Home /page1 Page1 /page1/xxx ─ /page2 Home と Page2 /page2/xxx Page2 排他的にコンポーネントを切り替えて表示する (Switch) これまでの例で気付いたと思いますが、Router 以下に配置した Route コンポーネントは、排他的に切り替え表示されるものではなく、あくまで各々の Route コンポーネントが個別に表示の On/Off を判断するものです。 複数の Route コンポーネントのうち、いずれか 1 つのみを表示したい場合、つまり、ページ切り替えをしたい場合 は、次のように Switch コンポーネント 以下に Route を配置するようにします。 components/App.tsx import * as React from \u0026#39;react\u0026#39; import { BrowserRouter as Router, Route, Switch } from \u0026#39;react-router-dom\u0026#39; const Home: React.FC = () =\u0026gt; \u0026lt;h1\u0026gt;Home\u0026lt;/h1\u0026gt; const Page1: React.FC = () =\u0026gt; \u0026lt;h1\u0026gt;Page1\u0026lt;/h1\u0026gt; const Page2: React.FC = () =\u0026gt; \u0026lt;h1\u0026gt;Page2\u0026lt;/h1\u0026gt; const NotFound: React.FC = () =\u0026gt; \u0026lt;h1\u0026gt;NotFound\u0026lt;/h1\u0026gt; export const App: React.FC = () =\u0026gt; { return ( \u0026lt;Router\u0026gt; \u0026lt;Switch\u0026gt; \u0026lt;Route path=\u0026#34;/page1\u0026#34;\u0026gt;\u0026lt;Page1 /\u0026gt;\u0026lt;/Route\u0026gt; \u0026lt;Route path=\u0026#34;/page2\u0026#34;\u0026gt;\u0026lt;Page2 /\u0026gt;\u0026lt;/Route\u0026gt; \u0026lt;Route path=\u0026#34;/\u0026#34;\u0026gt;\u0026lt;Home /\u0026gt;\u0026lt;/Route\u0026gt; \u0026lt;Route\u0026gt;\u0026lt;NotFound /\u0026gt;\u0026lt;/Route\u0026gt; \u0026lt;/Switch\u0026gt; \u0026lt;/Router\u0026gt; ) } Switch 以下に Route を配置すると、上から順番に見て、最初にパスが一致したもののみが表示されるようになります。 ルートパス (/) には必ず一致してしまうので、path=\u0026quot;/\u0026quot; 指定されたものは他の Route よりも後ろに配置しなければいけない ことに注意してください。 もちろん、exact 指定をしている場合は先頭に配置することが可能です。 \u0026lt;Switch\u0026gt; \u0026lt;Route exact path=\u0026#34;/\u0026#34;\u0026gt;\u0026lt;Home /\u0026gt;\u0026lt;/Route\u0026gt; \u0026lt;Route path=\u0026#34;/page1\u0026#34;\u0026gt;\u0026lt;Page1 /\u0026gt;\u0026lt;/Route\u0026gt; \u0026lt;Route path=\u0026#34;/page2\u0026#34;\u0026gt;\u0026lt;Page2 /\u0026gt;\u0026lt;/Route\u0026gt; \u0026lt;Route\u0026gt;\u0026lt;NotFound /\u0026gt;\u0026lt;/Route\u0026gt; \u0026lt;/Switch\u0026gt; 上記コードの最後の Route コンポーネントには path の指定がありませんが、このように記述すると、それより前に配置した Route のいずれにもパスが一致しなかった場合に、必ず表示されるようになります。 つまり、パスが不正な場合の Not Found ページ を表示する場合に使用できます。 現在のパス 表示されるコンポーネント / Home /page1 Page1 /page1/xxx Page1 /page2 Page2 /page2/xxx Page2 /xxx NotFound リダイレクト (Redirect) Redirect コンポーネントを使用すると、ユーザーが特定のパスにアクセスしたときに、別のパスにリダイレクトすることができます。 例えば、ルートパス (/) にアクセスしたときに、デフォルトページとして /page1 にリダイレクトする、といったことが可能です。 // import { BrowserRouter as Router, Redirect, Route } from \u0026#39;react-router-dom\u0026#39; \u0026lt;Router\u0026gt; \u0026lt;Redirect exact from=\u0026#34;/\u0026#34; to=\u0026#34;/page1\u0026#34; /\u0026gt; \u0026lt;Route path=\u0026#34;/page1\u0026#34;\u0026gt;\u0026lt;Page1 /\u0026gt;\u0026lt;/Route\u0026gt; \u0026lt;Route path=\u0026#34;/page2\u0026#34;\u0026gt;\u0026lt;Page2 /\u0026gt;\u0026lt;/Route\u0026gt; \u0026lt;/Router\u0026gt; これは、次のようにルートパス (/) にアクセスしたときに表示するコンポーネントを、/page1 にアクセスした場合と同じにするのと似ていますが、同一の内容を表示するのであれば、リダイレクトを使うことをおすすめします。 よくない例 \u0026lt;Router\u0026gt; \u0026lt;Route exact path=\u0026#34;/\u0026#34; component={Page1} /\u0026gt; \u0026lt;Route path=\u0026#34;/page1\u0026#34;\u0026gt;\u0026lt;Page1 /\u0026gt;\u0026lt;/Route\u0026gt; \u0026lt;Route path=\u0026#34;/page2\u0026#34;\u0026gt;\u0026lt;Page2 /\u0026gt;\u0026lt;/Route\u0026gt; \u0026lt;/Router\u0026gt; なぜなら、React 内部のパス情報が変更されないと、NavLink 要素の activeClassName や activeStyle 属性が動作しないなどの問題が出るからです（NavLink については後述）。 次のように Switch と組み合わせて使用すると、どのパスにも一致しない場合にルートパス（Home ページ）に飛ばす、といったことが可能です。 // import { BrowserRouter as Router, Redirect, Route, Switch } from \u0026#39;react-router-dom\u0026#39; \u0026lt;Router\u0026gt; \u0026lt;Switch\u0026gt; \u0026lt;Route exact path=\u0026#34;/\u0026#34;\u0026gt;\u0026lt;Home /\u0026gt;\u0026lt;/Route\u0026gt; \u0026lt;Route path=\u0026#34;/page1\u0026#34;\u0026gt;\u0026lt;Page1 /\u0026gt;\u0026lt;/Route\u0026gt; \u0026lt;Route path=\u0026#34;/page2\u0026#34;\u0026gt;\u0026lt;Page2 /\u0026gt;\u0026lt;/Route\u0026gt; \u0026lt;Redirect to=\u0026#34;/\u0026#34; /\u0026gt; \u0026lt;/Switch\u0026gt; \u0026lt;/Router\u0026gt; これは、次のようにデフォルトルートを指定した場合と振る舞いは似ていますが、現在のパスがルート (/) に置き換わるかどうかの違いがあります。 \u0026lt;Router\u0026gt; \u0026lt;Switch\u0026gt; \u0026lt;Route path=\u0026#34;/page1\u0026#34;\u0026gt;\u0026lt;Page1 /\u0026gt;\u0026lt;/Route\u0026gt; \u0026lt;Route path=\u0026#34;/page2\u0026#34;\u0026gt;\u0026lt;Page2 /\u0026gt;\u0026lt;/Route\u0026gt; \u0026lt;Route\u0026gt;\u0026lt;Home /\u0026gt;\u0026lt;/Route\u0026gt; \u0026lt;/Switch\u0026gt; \u0026lt;/Router\u0026gt; ルート・パラメーターを使用する（ディープリンク） Route コンポーネントの path プロパティには、可変となるパラメーターを指定することができます。 パラメーター部分で表示する要素の ID などを渡すことで、いわゆる ディープリンク を実現することができます。 次の例では、TODO を表示するための ToDoPage コンポーネントのためのルーティング定義を行なっています。 \u0026lt;Router\u0026gt; \u0026lt;Switch\u0026gt; \u0026lt;Route path=\u0026#34;/todos/:id\u0026#34; component={ToDoPage} /\u0026gt; \u0026lt;Route path=\u0026#34;/todos\u0026#34; component={ToDoPage} /\u0026gt; \u0026lt;/Switch\u0026gt; \u0026lt;/Router\u0026gt; 最初の Route の path には /todos/:id が指定されており、この :id の部分が可変のパラメーターになります。 Link コンポーネントなどで現在のパスが /todos/123 に切り替わると、ToDoPage コンポーネントに 123 という値が渡されます。 下記に具体的な実装例を示します。 components/App.tsx import * as React from \u0026#39;react\u0026#39; import { BrowserRouter as Router, Link, Route, Switch } from \u0026#39;react-router-dom\u0026#39; import { ToDoPage } from \u0026#39;./ToDoPage\u0026#39; export const App: React.FC = () =\u0026gt; { return ( \u0026lt;Router\u0026gt; \u0026lt;nav\u0026gt; \u0026lt;Link to=\u0026#34;/todos\u0026#34;\u0026gt;ToDo (all)\u0026lt;/Link\u0026gt;\u0026lt;br /\u0026gt; \u0026lt;Link to=\u0026#34;/todos/123\u0026#34;\u0026gt;ToDo (123)\u0026lt;/Link\u0026gt; \u0026lt;/nav\u0026gt; \u0026lt;Switch\u0026gt; \u0026lt;Route path=\u0026#34;/todos/:id\u0026#34; component={ToDoPage} /\u0026gt; \u0026lt;Route path=\u0026#34;/todos\u0026#34; component={ToDoPage} /\u0026gt; \u0026lt;/Switch\u0026gt; \u0026lt;/Router\u0026gt; ) } 関数コンポーネント (ToDoPage) の中では、useParams フック を使用することで、渡されたパラメーターを取り出すことができます。 components/ToDoPage.tsx import * as React from \u0026#39;react\u0026#39; import { useParams } from \u0026#39;react-router-dom\u0026#39; export const ToDoPage: React.FC = () =\u0026gt; { const { id } = useParams(); return \u0026lt;h1\u0026gt;ToDo: {id || \u0026#39;ALL\u0026#39;}\u0026lt;/h1\u0026gt; } パラメータが省略された場合は、id の値は undefined になるので、その場合はすべての TODO を表示する、といった分岐処理が可能です。 上記の例では、単純に ALL と表示しています。 アクティブなページのリンクをハイライトする (NavLink) 図: NavLink によるハイライト React Router によるナビゲーション（現在のパスの変更）には、Link コンポーネントによるリンクを使いますが、この拡張コンポーネントとして、NavLink が用意されています。 NavLink を使ってナビゲーションを行うと、そのパスがアクティブ（対象の Route が表示されているとき）の CSS スタイルを指定することができます。 上記の表示例では、Page1 リンク (NavLink) をクリックしたときに、リンクの背景色を水色に設定しています。 アクティブな NavLink 用の CSS スタイルを直接指定するには activeStyle 属性を使い、CSS クラス名で指定する場合は activeClassName 属性を使います。 style 属性や className 属性で指定した CSS スタイルは、アクティブでないリンクとアクティブなリンクの両方に反映されます。 次のサンプルコードでは、activeStyle を使ってアクティブなリンクの背景色を設定しています。 components/App.tsx import * as React from \u0026#39;react\u0026#39; import { BrowserRouter as Router, NavLink, Route } from \u0026#39;react-router-dom\u0026#39; const Page1: React.FC = () =\u0026gt; \u0026lt;h1\u0026gt;Page1\u0026lt;/h1\u0026gt; const Page2: React.FC = () =\u0026gt; \u0026lt;h1\u0026gt;Page2\u0026lt;/h1\u0026gt; // スタイル定義 const styles: {[key: string]: React.CSSProperties} = { link: { color: \u0026#39;white\u0026#39;, background: \u0026#39;gray\u0026#39;, marginRight: \u0026#39;0.2em\u0026#39;, padding: \u0026#39;0.5em\u0026#39;, textDecoration: \u0026#39;none\u0026#39;, }, active: { background: \u0026#39;#5ad\u0026#39;, } } // Appコンポーネント export const App: React.FC = () =\u0026gt; { return ( \u0026lt;Router\u0026gt; \u0026lt;nav\u0026gt; \u0026lt;NavLink to=\u0026#34;/page1\u0026#34; style={styles.link} activeStyle={styles.active}\u0026gt; Page1 \u0026lt;/NavLink\u0026gt; \u0026lt;NavLink to=\u0026#34;/page2\u0026#34; style={styles.link} activeStyle={styles.active}\u0026gt; Page2 \u0026lt;/NavLink\u0026gt; \u0026lt;/nav\u0026gt; \u0026lt;Route path=\u0026#34;/page1\u0026#34; component={Page1} /\u0026gt; \u0026lt;Route path=\u0026#34;/page2\u0026#34; component={Page2} /\u0026gt; \u0026lt;/Router\u0026gt; ) } 次のサンプルコードもほぼ同様ですが、スタイルの直指定ではなく、activeClassName で CSS クラス名を指定しています。 components/App.tsx import * as React from \u0026#39;react\u0026#39; import { BrowserRouter as Router, NavLink, Route } from \u0026#39;react-router-dom\u0026#39; import styles from \u0026#39;./App.scss\u0026#39;; // CSS Modules const Page1: React.FC = () =\u0026gt; \u0026lt;h1\u0026gt;Page1\u0026lt;/h1\u0026gt; const Page2: React.FC = () =\u0026gt; \u0026lt;h1\u0026gt;Page2\u0026lt;/h1\u0026gt; // Appコンポーネント export const App: React.FC = () =\u0026gt; { return ( \u0026lt;Router\u0026gt; \u0026lt;nav\u0026gt; \u0026lt;NavLink to=\u0026#34;/page1\u0026#34; className={styles.link} activeClassName={styles.active}\u0026gt; Page1 \u0026lt;/NavLink\u0026gt; \u0026lt;NavLink to=\u0026#34;/page2\u0026#34; className={styles.link} activeClassName={styles.active}\u0026gt; Page2 \u0026lt;/NavLink\u0026gt; \u0026lt;/nav\u0026gt; \u0026lt;Route path=\u0026#34;/page1\u0026#34; component={Page1} /\u0026gt; \u0026lt;Route path=\u0026#34;/page2\u0026#34; component={Page2} /\u0026gt; \u0026lt;/Router\u0026gt; ) }"
},
{
url: "/p/59jt4ck/",
title: "Azure Functions のメモ",
date: "2020-08-17T00:00:00Z",
body: "Azure Functions のメモ"
},
{
url: "/p/9t7hs4e/",
title: "Azure Functions に npm install で Node モジュールを追加する",
date: "2020-08-17T00:00:00Z",
body: "Azure Functions に npm install で Node モジュールを追加する Azure Functions への npm install Azure Functions の関数を Node.js ランタイムで動かしている場合は、通常の Node.js アプリと同様に NPM パッケージを npm コマンドでインストールして使用することができます。 簡単なのは、Azure ポータル の Function App リソースの コンソール 画面から npm install を実行する方法です。 コンソールを開くと、Function App のルートディレクトリ（通常は D:\\home\\site\\wwwroot）がカレントディレクトリになってプロンプトが表示されます。 ここから次のように package.json の作成と、Node モジュールのインストールを行うことができます。 D:\\home\\site\\wwwroot\u0026gt; npm init -y D:\\home\\site\\wwwroot\u0026gt; npm install node-fetch --save これで、この Functions プロジェクト内のすべての関数から、インストールした Node モジュールを使用できるようになります。 npm install を実行するディレクトリ Functions プロジェクトのディレクトリ階層は次のように、関数ごとにディレクトリが分かれています。 D:\\home\\site\\wwwroot +-- host.json +-- MyFunc1 | +-- function.json | +-- index.js +-- MyFunc2 +-- function.json +-- index.js npm init および npm install を実行するディレクトリは、プロジェクトのルートディレクトリ、あるいは、関数ごとのディレクトリになります。 プロジェクトルートで実行 \u0026hellip; すべての関数から Node モジュールを参照可能 関数ごとのルートで実行 \u0026hellip; その関数からのみ Node モジュールを参照可能 特に理由がない場合は、ストレージ容量を節約するために、プロジェクトルートで npm install を実行することが推奨されています。 関数ごとに異なるバージョンの Node モジュールを使用したい場合は、関数のディレクトリ内で npm install します。"
},
{
url: "/p/vgt5fqy/",
title: "Azure Static Web Apps で静的ウェブサイトを作成する",
date: "2020-08-15T00:00:00Z",
body: "Azure Static Web Apps で静的ウェブサイトを作成する Azure Static Web Apps とは 2020年5月に Azure Static Web Apps のプレビュー版が公開されました。 これまでは、Azure 上で静的なウェブサイトを作成する場合は、BLOB ストレージを使って HTML/JS ファイルなどをホストする方法がとられていましたが、今後は Static Web Apps のサービスが主流になりそうです。 参考: Azure Storage で静的 Web サイトをホスティングする Azure Static Web Apps は、サイトのビルドやデプロイに GitHub Actions を使うことを前提としているため、Web サイトのコンテンツを GitHub 上で管理することが強制されます。 GitHub Pages でも静的な Web サイトを作成できますが、Azure Static Web Apps を使うと Azure Functions などの API サービスと統合することができます。 静的 Web サイトといいつつも、より高度な Web アプリを作成することができそうです。 Azure Static Web Apps は、ベータ版のうちは無料で使えるようです。 そのうち従量課金に切り替わると思いますが、BLOB ストレージを使った場合の利用料金はめちゃ安だったので、こちらも安価な料金が設定されることを期待しています。 GitHub リポジトリの準備 下記のような簡単な HTML ファイルを作成して、GitHub リポジトリを新規作成 してコミットしておきます。 index.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;My website\u0026lt;/title\u0026gt; \u0026lt;p\u0026gt;Hello World\u0026lt;/p\u0026gt; Static Web Apps リソースの作成 Azure Portal のリソースの作成 のページから、Static Web App を選択してリソースを新規作成します。 作成画面の「基本」タブでは、Web サイトの 名前 や、使用する GitHub リポジトリなどを指定します。 ここでは、簡単に mysite としました。 地域 は、住んでいる場所の近くを選んでおけば OK です。 「ビルド」タブでは、各種ディレクトリのパスなどを設定します。 アプリの場所 : プロジェクトのルートディレクトリを指定します。 通常は / のままで大丈夫ですが、何らかの理由でリポジトリのルートディレクトリを使えない場合は、サブディレクトリ名を指定しておくことができます。 API の場所 : Azure Functions の実装ファイルが格納されたディレクトリを設定します。 デフォルトでは api ディレクトリが指定されていますが、Azure Functions を使わないのであれば、この項目は削除しておきます。 アプリの成果物の場所 : デプロイすべきファイル群が格納されるディレクトリを設定します。 TypeScript や webpack などで HTML/JS ファイルをビルドする場合は、dist や build といったディレクトリにビルド結果のファイル群を格納するはずなので、そのディレクトリ名を指定しておきます。 リポジトリのルートディレクトリに index.html ファイルなどを格納している場合は、この項目は空のままで構いません。 入力が完了したら、作成 ボタンを押して数分待てば、リソースの作成が完了します。 リソースのページにアクセスすると、Web サイトの URL を確認することができます。 URL には、自動的に \u0026lt;ランダムID\u0026gt;.azurestaticapps.net というアドレスが割り当てられるようです。 上記ページの 参照 ボタンを押すと、Web ページを開くことができます。 このように、最初に作成した index.html の内容が表示されれば成功です。 GitHub アクションの設定も自動的に完了しているため、GitHub 上の HTML ファイルが更新されると、自動的に Web サイトに反映されます。 めっちゃ楽ですね！ デプロイ前にビルドが必要な場合 Azure Static Web Apps にデプロイするファイル群を生成するために、webpack や Parcel などで Web サイトコンテンツをビルドする必要があるかもしれません。 実は、GitHub Actions が実行されると、デフォルトで npm run build によるビルドが実行されるようになっています。 なので、package.json の中で、build スクリプトを定義しておくだけで、Web サイトコンテンツのビルドは自動的に実行されることになります。 package.json（抜粋） \u0026#34;scripts\u0026#34;: { \u0026#34;start\u0026#34;: \u0026#34;parcel src/index.html --open\u0026#34;, \u0026#34;build\u0026#34;: \u0026#34;rm -r build \u0026amp;\u0026amp; parcel build src/index.html -d build\u0026#34; }, npm run build 以外の別のビルドコマンドを実行したいときは、.github/workflows ディレクトリ以下に生成された Yaml ファイルの中で設定できます。 参考: Azure Static Web Apps の GitHub Actions ワークフロー | Microsoft Docs 具体的には、Build And Deploy ステップの with セクションで、app_build_command プロパティを追加することで設定できるようです。 とはいえ、通常は npm run build でビルドできるようにしておくのが分かりやすいと思います。 ビルド結果の出力ディレクトリは、同じく with セクションの app_artifact_location プロパティで指定しておきます。 Azure Statie Web Apps には、ここで指定したディレクトリ内のファイルがデプロイされます。 下記の例では、build ディレクトリを指定しています。 .github/workflows/xxxxxxxxxx.yml（抜粋） # Repository/Build Configurations# These values can be configured to match you app requirements.# For more information regarding Static Web App workflow configurations,# please visit: https://aka.ms/swaworkflowconfigapp_location:\u0026#34;/\u0026#34;# App source code pathapi_location:\u0026#34;\u0026#34;# Api source code path - optionalapp_artifact_location:\u0026#34;build\u0026#34;# Built app content directory - optional# End of Repository/Build Configurations コメントなどを読めば気付くと思いますが、上記のディレクトリ設定は、Static Web Apps リソースを作成するときに指定した下記の項目に対応しています。 app_location : アプリの場所 api_location : API の場所 app_artifact_location : アプリの成果物の場所 一般的な JavaScript フレームワークでどのような設定をすべきかは、下記のページにまとめられています。 参考: Azure Static Web Apps Preview を使用してフロントエンドフレームワークを構成する | Microsoft Docs"
},
{
url: "/p/n9nybnx/",
title: "エミュレーター: RetroArch のメモ",
date: "2020-08-14T00:00:00Z",
body: "エミュレーター: RetroArch のメモ 設定ファイルの場所 キーコンフィグなどの設定ファイルは下記のディレクトリに格納されています。 macos の場合 ./Users/ユーザー名/Library/Application Support/RetroArch キー設定を間違えて、にっちもさっちもいかなくなってしまった場合は、この中の config/retroarch.cfg というファイルを削除して RetroArch を再起動すれば OK です。 スキャンした ROM のリストや、セーブファイルなどは下記のディレクトリに格納されています。 macos の場合 ./Users/ユーザー名/Documents/RetroArch"
},
{
url: "/p/zkw9ju6/",
title: "Electron 関連記事",
date: "2020-08-03T00:00:00Z",
body: "Electron 関連記事"
},
{
url: "/p/ev6env5/",
title: "Electron で設定情報を扱う (electron-store)",
date: "2020-08-03T00:00:00Z",
body: "Electron で設定情報を扱う (electron-store) electron-store パッケージ を使用すると、Electron アプリ用の設定を簡単にローカルファイルとして保存できます。 electron-store のインストール $ npm install --save electron-store electron-store パッケージには TypeScript 用の型定義も含まれているため、別途型定義ファイルをインストールする必要はありません。 electron-store の使い方 簡単な使い方 electron-store モジュールは、キー＆バリューの形で設定値を保存する簡単な API (get/set) を提供しています。 下記の例では、color というキーで色情報を取得・保存しています。 main.ts import ElectronStore from \u0026#39;electron-store\u0026#39;; const store = new ElectronStore(); // 設定情報を取得する（第2パラメーターはデフォルト値） const color = store.get(\u0026#39;color\u0026#39;, \u0026#39;unknown\u0026#39;); console.log(color); // 設定情報の保存する store.set(\u0026#39;color\u0026#39;, \u0026#39;blue\u0026#39;); 1度目の実行では、設定情報が保存されていないので、get メソッドは第2引数で指定した unknown を返します。 2度目の実行では、前回保存した blue という値を取得できます。 設定値の型を定義する TypeScript を使っている場合は、get() で取得した値を特定の型の変数で受け取ることになると思います。 ElectronStore はジェネリクスクラスとして定義されており、各設定キーの型をあらかじめ指定しておくことができます。 次の例では、color 設定を文字列型として宣言しています。 import ElectronStore from \u0026#39;electron-store\u0026#39;; type StoreType = { color: string; } const store = new ElectronStore\u0026lt;StoreType\u0026gt;(); const color: string = store.get(\u0026#39;color\u0026#39;, \u0026#39;yellow\u0026#39;); 設定が保存されていないことを undefined で表したい場合は、次のように undefined 許容型で扱うことを明示しておく必要があります。 type StoreType = { color: string | undefined; } const store = new ElectronStore\u0026lt;StoreType\u0026gt;(); const color: string | undefined = store.get(\u0026#39;color\u0026#39;); if (!color) { console.log(\u0026#39;設定値が見つかりません\u0026#39;); } Settings モジュールを作成する アプリの設定情報をモジュールの形で参照できるようにしておくと便利です。 下記の settings モジュールは、name 設定と age 設定を扱うための Settings オブジェクトを公開します。 settings.ts import ElectronStore from \u0026#39;electron-store\u0026#39;; // 各設定値の型 type Type = { name: string | undefined; age: number | undefined; }; // 設定値の取得と保存を行うためのクラス class _Settings { private store = new ElectronStore\u0026lt;Type\u0026gt;(); // name 設定の取得と保存 get name(): Type[\u0026#39;name\u0026#39;] { return this.store.get(\u0026#39;name\u0026#39;); } set name(value: Type[\u0026#39;name\u0026#39;]) { this.store.set(\u0026#39;name\u0026#39;, value); } // age 設定の取得と保存 get age(): Type[\u0026#39;age\u0026#39;] { return this.store.get(\u0026#39;age\u0026#39;); } set age(value: Type[\u0026#39;age\u0026#39;]) { this.store.set(\u0026#39;age\u0026#39;, value); } } export const Settings = new _Settings(); 設定値を扱いたいところで、次のようにインポートするだけで、設定値の参照・保存を簡単に行えます。 import {Settings} from \u0026#39;./settings\u0026#39;; console.log(Settings.name); // 最初は undefined、次からは \u0026#39;maku\u0026#39; になる Settings.name = \u0026#39;maku\u0026#39;; // 自動的にファイルに保存される ☝️ Renderer プロセスでの設定値参照 Renderer プロセスからファイルアクセスするのはよくないとされているので、これに従うのであれば、上記の Settings モジュールも Renderer プロセスからは直接参照しない方がよさそうです。 Renderer プロセスは ipcRenderer.invoke() で Main プロセスへ設定値を要求し、Main プロセスは ipcMain.handle() で要求された設定値を返す、というやり方にすれば OK です。 参考: How do I get store values in the renderer process, when my store was initialized in the main process? 設定ファイルの保存場所 electron-store が保存する設定ファイルは、app.getPath('userData') ディレクトリ以下に config.json という名前で保存されます。 具体的なファイルパスは次のような感じになります。 /Users/maku/Library/Application Support/MyApp/config.json このファイルパスは、ElectronStore オブジェクトの path プロパティで取得することができます。 import ElectronStore from \u0026#39;electron-store\u0026#39;; const store = new ElectronStore(); console.log(store.path); その他 store.openInEditor() \u0026hellip; エディタで config.json ファイルを開く store.clear() \u0026hellip; 設定値をすべてクリアする"
},
{
url: "/p/t7ekrx4/",
title: "Electron アプリで OS のプロキシ設定をメインプロセスに反映する",
date: "2020-08-03T00:00:00Z",
body: "Electron アプリで OS のプロキシ設定をメインプロセスに反映する Electron アプリは「メインプロセス」と「レンダラープロセス」の 2 種類を扱わないといけないので、プロキシの設定でハマりがちです。 ここでは、システム (OS) のプロキシ設定を、自動的に両プロセスに反映する方法を説明します。 この仕組みを入れておけば、ユーザーにわざわざプロキシの設定をしてもらわなくて済むようになります。 レンダラープロセスの HTTP 通信 レンダラープロセス側は、Chromium の仕組みで システムのプロキシ設定が自動的に反映される ようになっています。 例えば、Web ブラウザ上の JavaScript で使用する XMLHttpRequest 関数や fetch 関数による HTTP 通信は、自動的にプロキシ経由で実行されます。 この振る舞いで問題なければ、特に設定を行う必要はありません。 BrowserWindow で扱うプロキシを明示的に指定するには、session オブジェクトの setProxy メソッド を使用します。 メインプロセスの HTTP 通信 Electron のメインプロセスはいわゆる Node.js アプリケーションと同様の仕組みで動作するので、Web ブラウザ側のプロキシ設定が自動的に反映されるようなことはありません。 しかし、electron モジュールが提供する session オブジェクトには、Chromium 側のプロキシ設定を参照する機能が備わっています。 この情報を利用すれば、メインプロセス側のプロキシ設定も自動的に行うことができます。 下記の autoProxy() 関数をメインプロセス起動直後に呼び出しておけば、メインプロセス側で実行する HTTP 通信に対してシステムのプロキシ設定が反映されます。 import {app, session} from \u0026#39;electron\u0026#39;; import {bootstrap} from \u0026#39;global-agent\u0026#39;; /** * システムのプロキシ設定情報をメインプロセスの HTTP 通信に反映します。 */ export function autoProxy() { app.once(\u0026#39;ready\u0026#39;, () =\u0026gt; { // このアドレスは有名どころであれば何でもよい const TARGET = \u0026#39;https://www.google.com\u0026#39;; session.defaultSession.resolveProxy(TARGET).then((info: string) =\u0026gt; { // システムにプロキシが設定されていない場合はなにもしない if (info === \u0026#39;DIRECT\u0026#39;) { return; } // \u0026#39;PROXY proxy.example.com:8080\u0026#39; のような文字列から URL 部分を抽出 const url = info.replace(/^PROXY /, \u0026#39;\u0026#39;); setGlobalAgent(url); }); }); function setGlobalAgent(proxy: string) { //console.log(`Proxy settings detected: ${proxy}`); if (!proxy.startsWith(\u0026#39;http\u0026#39;)) { proxy = \u0026#39;http://\u0026#39; + proxy; } // デフォルトの HTTP 通信をプロキシ経由にする process.env.GLOBAL_AGENT_HTTP_PROXY = proxy; bootstrap(); } } 処理の流れは次の通りです。 app.once('ready') になってから session.defaultSession で session オブジェクトを取得する。 session.resolveProxy() でシステムのプロキシ情報を取得する。 プロキシ情報は文字列で返され、プロキシ設定されているときは PROXY \u0026lt;address:port\u0026gt;、プロキシ設定されていないときは DIRECT になる。 システムにプロキシが設定されている場合は、その値を global-agent モジュールの bootstrap() でメインプロセス側の HTTP 通信に反映する。"
},
{
url: "/p/5ku5dmt/",
title: "Electron アプリがパッケージングされた環境 (production) で動作しているか調べる",
date: "2020-08-02T00:00:00Z",
body: "Electron アプリがパッケージングされた環境 (production) で動作しているか調べる Electron の app モジュールの isPackaged プロパティ を参照すると、アプリが electron-builder などでパッケージングされた状態で動作しているかどうかを調べることができます。 一般的に、app.isPackaged が true となる場合、production モードで動作していると考えられます。 次の例では、アプリが開発中の場合のみ Chromium の DevTools を開くようにしています。 // const win = new BrowserWindow(this.options); // 開発中のみ起動時に DevTools を開く if (!app.isPackaged) { win.webContents.openDevTools() }"
},
{
url: "/p/bqz7emt/",
title: "GitHub GraphQL API の呼び出し回数制限 (rate limit) の情報を取得する",
date: "2020-08-02T00:00:00Z",
body: "GitHub GraphQL API の呼び出し回数制限 (rate limit) の情報を取得する GitHub API を使ったアプリケーションを作成するときは、API の呼び出し回数制限を意識した設計を行う必要があります。 GitHub API バージョン3 の REST API には、1 時間に 5000 リクエストまでという明確な呼び出し回数制限がありましたが、API バージョン4 の GraphQL API はそのクエリの性質上、ちょっと異なるコスト計算方法が採用されています。 GraphQL resource limitations | GitHub Developer Guide 正確な計算方法は上記のサイトに記述されていますが、簡単にいうと、GraphQL クエリの入れ子階層が深くなり、複雑になるほどコストがかかるという計算になっています。 ある GraphQL クエリが実際にどれだけのコストがかかるかは、下記のように rateLimit 情報を取得することで調べることができます。 query{rateLimit{limitcostremainingresetAt}search(query:\u0026#34;repo:electron/electron is:issue\u0026#34;,type:ISSUE,first:5){issueCountnodes{...onIssue{titlelabels(first:10){nodes{name}}}}}} 上記のクエリを実行すると、次のような感じの JSON レスポンスが返ってきます。 { \u0026#34;data\u0026#34;: { \u0026#34;rateLimit\u0026#34;: { \u0026#34;limit\u0026#34;: 5000, \u0026#34;cost\u0026#34;: 1, \u0026#34;remaining\u0026#34;: 4999, \u0026#34;resetAt\u0026#34;: \u0026#34;2020-08-02T09:15:20Z\u0026#34; }, \u0026#34;search\u0026#34;: { \u0026#34;issueCount\u0026#34;: 13278, \u0026#34;nodes\u0026#34;: [ // ... ] } } } rateLimit の各プロパティの値は次のような意味を持っています。 limit: 5000 \u0026hellip; 1時間あたりに使用可能なコスト（合計 5000 までのコストの呼び出しが可能ということ） cost: 1 \u0026hellip; 今回のクエリで消費したコスト remaining: 4999 \u0026hellip; あとどれだけのコストのクエリを実行できるか resetAt: 2020-08-02... \u0026hellip; remaining が 5000 にリセットされる時間 (UTC) つまり、cost プロパティの値ができるだけ小さくなるように GraphQL のクエリを設計するべきだということです。 GraphQL API の呼び出し回数を減らしても、この cost 値が大きいとすぐにリミットに到達してしまいます。"
},
{
url: "/p/q6fnu29/",
title: "React でモーダルダイアログを表示する (react-modal)",
date: "2020-08-02T00:00:00Z",
body: "React でモーダルダイアログを表示する (react-modal) react-modal パッケージが提供する ReactModal コンポーネントを使用すると、React アプリ内で簡単にモーダルダイアログを実現することができます。 上記は、設定 ボタンを押してモーダルな設定ダイアログを開いたときの表示例です。 react-modal のインストール ReactModal コンポーネントを使うために、react-modal パッケージと TypeScript の型定義ファイルをインストールします。 $ npm install --save react-modal $ npm install --save-dev @types/react-modal ReactModal コンポーネントを使用する ReactModal の使い方 ReactModal コンポーネントは、isOpen プロパティでダイアログの表示・非表示を制御するようになっています。 // import ReactModal from \u0026#39;react-modal\u0026#39;; \u0026lt;ReactModal isOpen={this.props.isOpen} onAfterOpen={this.handleOpen} onRequestClose={this.handleClose} style={this.customStyles} contentLabel=\u0026#34;Settings\u0026#34; \u0026gt; // ... フォームの内容などをここに記述 ... \u0026lt;/ReactModal\u0026gt; onAfterOpen でオープン時、onRequestClose でクローズ時のイベントをハンドルすることができます。 ReactModal は自分自身のダイアログを自動で閉じたりしないので、onRequestClose に設定したハンドラ内で、isOpen プロパティに渡す値を false に設定してダイアログを閉じる必要があります。 onRequestClose ハンドラは、Esc キーを押したときや、ダイアログ外の領域をクリックしたときなどに呼び出されます。 コンポーネントの作成 下記のサンプルコードは ReactModal を使ったコンポーネントの作成例です。 ここでは、ユーザー名を入力可能な設定ダイアログを想定しています。 React を使ったフォームの作成方法などは次の記事を参照してください。 参考: React コンポーネントでフォームの入力を処理する components/settingsDialog.tsx import * as React from \u0026#39;react\u0026#39;; import ReactModal from \u0026#39;react-modal\u0026#39;; interface Props { /** このダイアログを表示するなら true */ isOpen: boolean; /** このダイアログを閉じるときのコールバック */ onClose?: () =\u0026gt; void; } interface State { username: string; } export class SettingsDialog extends React.Component\u0026lt;Props, State\u0026gt; { constructor(props: Props) { super(props); this.state = { username: \u0026#39;\u0026#39; }; // 具体的に #root 要素などを指定した方がよい？ ReactModal.setAppElement(\u0026#39;body\u0026#39;); } public render(): React.ReactNode { return \u0026lt;div\u0026gt; \u0026lt;ReactModal isOpen={this.props.isOpen} onAfterOpen={this.handleOpen} onRequestClose={this.handleClose} style={this.customStyles} contentLabel=\u0026#34;Settings\u0026#34; \u0026gt; \u0026lt;form onSubmit={this.handleSubmit}\u0026gt; \u0026lt;label\u0026gt;ユーザー名 \u0026lt;input type=\u0026#34;text\u0026#34; autoFocus value={this.state.username} onChange={this.handleChangeUsername}\u0026gt;\u0026lt;/input\u0026gt; \u0026lt;/label\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;/ReactModal\u0026gt; \u0026lt;/div\u0026gt;; } // フォームのサブミット時にダイアログを閉じる private handleSubmit = (event: React.FormEvent\u0026lt;HTMLFormElement\u0026gt;) =\u0026gt; { event.preventDefault(); this.handleClose(); } private handleChangeUsername = (event: React.ChangeEvent\u0026lt;HTMLInputElement\u0026gt;) =\u0026gt; { this.setState({username: event.target.value}) } // ダイアログが開いたときに呼び出される private handleOpen = () =\u0026gt; { // ここで設定情報などを読み込む } // ダイアログ領域外のクリックや、ESCキーを押したときに呼び出される private handleClose = () =\u0026gt; { // 親コンポーネントにダイアログを閉じてもらうためのコールバック通知 this.props.onClose?.(); } // スタイルのカスタマイズ private customStyles: ReactModal.Styles = { // ダイアログ内のスタイル（中央に表示） content: { top: \u0026#39;50%\u0026#39;, left: \u0026#39;50%\u0026#39;, right: \u0026#39;auto\u0026#39;, bottom: \u0026#39;auto\u0026#39;, marginRight: \u0026#39;-50%\u0026#39;, transform: \u0026#39;translate(-50%, -50%)\u0026#39; }, // 親ウィンドウのスタイル（ちょっと暗くする） overlay: { background: \u0026#39;rgba(0, 0, 0, 0.2)\u0026#39; } } } 作成したコンポーネントを使用する 上記で作成した SettingsDialog コンポーネントの使用例です。 設定 ボタンを押したときに、SettingsDialog の isOpen プロパティを true に設定することでダイアログを表示しています。 components/app.tsx import * as React from \u0026#39;react\u0026#39;; import {SettingsDialog} from \u0026#39;./settingsDialog\u0026#39;; interface State { isDialogOpen: boolean; } export class App extends React.Component\u0026lt;{}, State\u0026gt; { constructor(props: {}) { super(props); this.state = { isDialogOpen: false, }; } public render(): React.ReactNode { return \u0026lt;div\u0026gt; \u0026lt;button onClick={this.openDialog}\u0026gt;設定\u0026lt;/button\u0026gt; \u0026lt;SettingsDialog isOpen={this.state.isDialogOpen} onClose={this.closeDialog} /\u0026gt; \u0026lt;/div\u0026gt;; } // ダイアログを開く private openDialog = () =\u0026gt; { this.setState({isDialogOpen: true}); } // ダイアログからのコールバックでダイアログを閉じてあげる private closeDialog = () =\u0026gt; { this.setState({isDialogOpen: false}); } } 設定値の保存と読み出し ReactModal コンポーネントの onAfterOpen と onRequestClose プロパティを設定しておくと、ダイアログを開いたときと閉じたときに任意の処理を行うことができます。 \u0026lt;ReactModal isOpen={this.props.isOpen} onAfterOpen={this.handleOpen} onRequestClose={this.handleClose} ...\u0026gt; 設定ダイアログのようなものを作るのであれば、このタイミングでフォームに入力した設定情報を保存・復旧させるとよいでしょう。 次の例では、Web ブラウザの localStorage に設定情報を保存しています。 private handleOpen = () =\u0026gt; { // 設定情報を読み込む const name = localStorage.getItem(\u0026#39;username\u0026#39;) || \u0026#39;\u0026#39;; this.setState({username: name}); } private handleClose = () =\u0026gt; { // 設定情報を保存 localStorage.setItem(\u0026#39;username\u0026#39;, this.state.username); // 親コンポーネントにダイアログを閉じてもらうためのコールバック通知 this.props.onClose?.(); } ここでは、簡易的な説明のため localStorage を使用しましたが、localStorage はセキュアではないとされているので、ユーザーの秘密情報をそのまま保存するのは避けてください。 他の保存手段としては、Web アプリであればサーバーサイドセッションを使う方法、Electron アプリであればローカルファイルに保存する方法（electron-store など）があります。"
},
{
url: "/p/ubkahpw/",
title: "GitHub GraphQL API のクエリ例",
date: "2020-07-31T00:00:00Z",
body: "GitHub GraphQL API のクエリ例"
},
{
url: "/p/9bku4cj/",
title: "GitHub GraphQL API のクエリ例: ユーザー情報を取得する (viewer, user)",
date: "2020-07-31T00:00:00Z",
body: "GitHub GraphQL API のクエリ例: ユーザー情報を取得する (viewer, user) サインイン済みのユーザー情報を取得する (viewer) viewer クエリを使用すると、現在アクセスしているユーザー（サインイン中のユーザー）のユーザー情報（User オブジェクト）を取得することができます。 Queries - viewer GraphQL クエリ query{viewer{login# ログインIDname# ユーザー名email# メールアドレス（ユーザーが公開していれば）url# ユーザーの GitHub ホームページwebsiteUrl# ユーザーの Web サイトavatarUrl# ユーザーのアバター画像}} 実行結果 { \u0026#34;data\u0026#34;: { \u0026#34;viewer\u0026#34;: { \u0026#34;login\u0026#34;: \u0026#34;maku77\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Maku Maku\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;maku@example.com\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;https://github.com/maku77\u0026#34;, \u0026#34;websiteUrl\u0026#34;: \u0026#34;https://maku77.github.io/\u0026#34;, \u0026#34;avatarUrl\u0026#34;: \u0026#34;https://avatars2.githubusercontent.com/u/5519503?v=4\u0026#34; } } } 指定したログイン ID のユーザー情報を取得する (user) user クエリを使用すると、指定したユーザー名のユーザー情報を取得することができます。 Queries - user GraphQL クエリ query{user(login:\u0026#34;maku77\u0026#34;){login# ログインIDname# ユーザー名email# メールアドレス（ユーザーが公開していれば）url# ユーザーの GitHub ホームページwebsiteUrl# ユーザーの Web サイトavatarUrl# ユーザーのアバター画像}} 取得できるオブジェクトは、viewer クエリの場合と同様に User オブジェクト です。 実行結果 { \u0026#34;data\u0026#34;: { \u0026#34;user\u0026#34;: { \u0026#34;login\u0026#34;: \u0026#34;maku77\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Maku Maku\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;maku@examle.com\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;https://github.com/maku77\u0026#34;, \u0026#34;websiteUrl\u0026#34;: \u0026#34;https://maku77.github.io/\u0026#34;, \u0026#34;avatarUrl\u0026#34;: \u0026#34;https://avatars2.githubusercontent.com/u/5519503?v=4\u0026#34; } } } ただし、指定したユーザー名が存在しない場合は data.user フィールドの値は null になり、errors フィールドの値が格納されます。 GraphQL クエリ（存在しないユーザーを指定する） query{user(login:\u0026#34;no-such-user\u0026#34;){login}} 実行結果 { \u0026#34;data\u0026#34;: { \u0026#34;user\u0026#34;: null }, \u0026#34;errors\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;NOT_FOUND\u0026#34;, \u0026#34;path\u0026#34;: [ \u0026#34;user\u0026#34; ], \u0026#34;locations\u0026#34;: [ { \u0026#34;line\u0026#34;: 7, \u0026#34;column\u0026#34;: 3 } ], \u0026#34;message\u0026#34;: \u0026#34;Could not resolve to a User with the login of \u0026#39;no-such-user\u0026#39;.\u0026#34; } ] } ユーザーのコミット統計情報を取得する（貢献度情報） User オブジェクト の contributionsCollection フィールドを参照すると、そのユーザーの一定期間内の コミット数、PR 作成数、PR レビュー数 などの情報を取得することができます。 from 引数と to 引数で統計情報の取得期間を指定します（最長 1 年間）。 日時を省略した場合は、直近の 1 年間の統計情報を取得します。 次の例では、あるユーザーの 2021 年の Contribution 情報を取得しています。 GraphQL クエリ query{user(login:\u0026#34;maku77\u0026#34;){login# ログインIDname# ユーザー名contributionsCollection(from:\u0026#34;2021-01-01T00:00:00Z\u0026#34;){startedAt# 統計情報の開始日時endedAt# 統計情報の終了日時totalCommitContributions# 合計コミット数totalPullRequestContributions# 合計 PR 作成数totalPullRequestReviewContributions# 合計 PR レビュー数commitContributionsByRepository{# リポジトリごとの情報repository{nameWithOwner# Organization/リポジトリ名}contributions{totalCount# このリポジトリへのコミット数}}}}} 実行結果 { \u0026#34;data\u0026#34;: { \u0026#34;user\u0026#34;: { \u0026#34;login\u0026#34;: \u0026#34;maku77\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Maku Maku\u0026#34;, \u0026#34;contributionsCollection\u0026#34;: { \u0026#34;startedAt\u0026#34;: \u0026#34;2021-01-01T00:00:00Z\u0026#34;, \u0026#34;endedAt\u0026#34;: \u0026#34;2022-01-01T00:00:00Z\u0026#34;, \u0026#34;totalCommitContributions\u0026#34;: 2000, \u0026#34;totalPullRequestContributions\u0026#34;: 400, \u0026#34;totalPullRequestReviewContributions\u0026#34;: 150, \u0026#34;commitContributionsByRepository\u0026#34;: [ { \u0026#34;repository\u0026#34;: { \u0026#34;nameWithOwner\u0026#34;: \u0026#34;maku77/repo1\u0026#34; }, \u0026#34;contributions\u0026#34;: { \u0026#34;totalCount\u0026#34;: 1200 } }, { \u0026#34;repository\u0026#34;: { \u0026#34;nameWithOwner\u0026#34;: \u0026#34;maku77/repo2\u0026#34; }, \u0026#34;contributions\u0026#34;: { \u0026#34;totalCount\u0026#34;: 800 } } ] } } } } ある組織に所属するユーザー情報を取得する (Organization.membersWithRole) ルートフィールドで organization を指定すれば、特定の組織に所属するユーザーの一覧を取得できます。 参考: 組織 (org) 内のユーザーの一覧を取得 そこには User オブジェクトの情報が含まれているので、例えば次のようにすれば、組織のメンバー全員 (membersWithRole) の過去 1 年間の貢献情報をまとめて取得することができます。 query{organization(login:\u0026#34;Organization名\u0026#34;){namemembersWithRole(first:100){nodes{login# ログインIDname# ユーザー名email# メールアドレス（ユーザーが公開していれば）contributionsCollection{startedAt# 統計情報の開始日時endedAt# 統計情報の終了日時totalCommitContributions# 合計コミット数totalPullRequestContributions# 合計 PR 数totalPullRequestReviewContributions# 合計レビュー数}}}}}ただし、GitHub GraphQL API の制約上、ユーザー情報は一度に 100 ユーザー分しかとれないので、それ以上のメンバーがいる組織の場合は、GraphQL のページネーション処理 で繰り返しクエリを実行する必要があります。"
},
{
url: "/p/fe7aiyp/",
title: "Azure DevOps のメモ",
date: "2020-07-28T00:00:00Z",
body: "Azure DevOps のメモ"
},
{
url: "/p/36h9xj9/",
title: "Azure Pipelinesメモ: azure-pipelines.yml から別の Yaml をインクルードする (template)",
date: "2020-07-28T00:00:00Z",
body: "Azure Pipelinesメモ: azure-pipelines.yml から別の Yaml をインクルードする (template) Template 機能 Azure Pipelines の Template 機能を使用すると、別の Yaml ファイルに記述したビルド設定をインクルードすることができます。 Templates - Azure Pipelines | Microsoft Docs 変数を渡して、部分的に内容を置き換えることができるので、「インクルード」ではなく「テンプレート」と呼んでいるみたいです。 単純に共通の steps を読み込んで使うこともできるし、逆にテンプレートファイルに対してパラメータで stepList を渡すということもできます。 使用例（steps の共通化） 例えば、別の Yaml ファイル（テンプレート）に記述した steps 定義を、azure-pipelines.yml から読み込むとします。 テンプレートファイルには次のような感じで、ルートに steps 要素を記述します。 common-steps.yml（テンプレート） steps:- task:NodeTool@0inputs:versionSpec:\u0026#39;10.x\u0026#39;displayName:\u0026#39;Install Node.js\u0026#39;- task:Npm@1inputs:command:\u0026#39;ci\u0026#39;displayName:\u0026#39;npm ci\u0026#39;- task:Npm@1inputs:command:\u0026#39;custom\u0026#39;customCommand:\u0026#39;run lint\u0026#39;displayName:\u0026#39;npm run lint\u0026#39;# ... azure-pipelines.yml の steps 以下で、上記のテンプレートファイルを読み込むには、template というキーワードを使用します。 azure-pipelines.yml（抜粋） pool:vmImage:\u0026#39;ubuntu-latest\u0026#39;steps:- script:echo Hello- template:common-steps.yml- script:echo World template キーワードは任意の位置で使用できるので、上記のように前後に別の step を入れることが可能です。 使用例（jobs の共通化） 上記の例では steps のテンプレートを読み込む方法を示しましたが、jobs ごと読み込む場合も同様に記述できます。 jobs の下には、steps だけではなく、variables や pool などを記述できるため、steps 単位のテンプレートより使い勝手がよいかもしれません（参考: jobs のスキーマ定義）。 common-jobs.yml（テンプレート） jobs:- job:HugoBuildvariables:hugo_version:\u0026#39;0.68.3\u0026#39;pool:vmImage:\u0026#39;ubuntu-latest\u0026#39;steps:- script:wget -O hugo.deb https://github.com/gohugoio/hugo/releases/download/v$(hugo_version)/hugo_extended_$(hugo_version)_Linux-64bit.debdisplayName:\u0026#39;Download Hugo $(hugo_version)\u0026#39;- script:sudo dpkg -i hugo.debdisplayName:\u0026#39;Install Hugo $(hugo_version)\u0026#39;- script:hugodisplayName:\u0026#39;Build Hugo site\u0026#39;- script:hugo deploydisplayName:\u0026#39;Deploy Hugo site\u0026#39;env:AZURE_STORAGE_ACCOUNT:$(AZURE_STORAGE_ACCOUNT)AZURE_STORAGE_KEY:$(AZURE_STORAGE_KEY) azure-pipelines.yml jobs:- template:azure-pipelines-common-jobs.yml"
},
{
url: "/p/j6jv7it/",
title: "VS Code で行末の空白（半角スペース）を自動で削除する (files.trimTrailingWhitespace)",
date: "2020-07-28T00:00:00Z",
body: "VS Code で行末の空白（半角スペース）を自動で削除する (files.trimTrailingWhitespace) Visual Studio Code で次のように設定しておくと、ファイル保存時に、行末の余計なスペースを自動で削除してくれます。 settings.json で設定する方法 settings.json { \u0026#34;files.trimTrailingWhitespace\u0026#34;: true, // ... } Markdown ファイル (.md) は、行末の 2 つのスペースが改行の意味を持っていたりします。 そのような場合はスペースが削除されてしまうと都合が悪いので、次のように言語別設定で markdown の場合のみ無効化しておきます。 { \u0026#34;files.trimTrailingWhitespace\u0026#34;: true, \u0026#34;[markdown]\u0026#34;: { \u0026#34;files.trimTrailingWhitespace\u0026#34;: false }, // ... } 参考: settings.json について 設定画面で設定する方法 Ctrl + , で設定画面を開く（macOS の場合は Cmd + ,） trim で検索して Trim Trailing Whitespace にチェックを入れる"
},
{
url: "/p/khqpnjf/",
title: "Android開発: ContraintLayout で配置されたビューの実際のサイズを取得する",
date: "2020-07-27T00:00:00Z",
body: "Android開発: ContraintLayout で配置されたビューの実際のサイズを取得する ConstraintLayout で配置したビューは、周囲のビューとの位置関係で位置やサイズなどが決まるため、実際に内部的なレイアウトが終了するまでは、ビューのサイズ情報などが取得できなかったりします（0 になります）。 View.doOnLayout() などで、レイアウト完了するのを待ってからサイズを取得すればうまくいきます。 これは、TransitionManager などでレイアウトを切り替えた直後なども同様です。 // レイアウト変更＆アニメーション開始 TransitionManager.beginDelayedTransition(constraintLayout) constraintSet.applyTo(constraintLayout) // この直後にレイアウト情報取得してもうまく取得できない val w = myView.width val h = myView.height myView.doOnLayout { // このタイミングであればうまく取得できる val w = it.width val h = it.height }"
},
{
url: "/p/7yhwcr7/",
title: "Electron アプリ内のリンクをOSのデフォルトブラウザで開く",
date: "2020-07-25T00:00:00Z",
body: "Electron アプリ内のリンクをOSのデフォルトブラウザで開く BrowserWindow 内で表示した HTML のリンクをクリックすると、デフォルトではそのウィンドウ内でリンク先のページへ遷移します。 リンククリック時に発生する will-navigate イベント と new-window イベント をハンドルすることで、OS のデフォルトブラウザでリンクを開くことができます。 リンククリック時には通常 will-navigate イベントが発生するのですが、\u0026lt;a target=\u0026quot;_blank\u0026quot; href=\u0026quot;...\u0026quot;\u0026gt; のように別ウィンドウで開くようなリンクをクリックした場合は new-window イベントが発生するので、両方のイベントをハンドルする必要があります。 // リンククリック時に OS のデフォルトブラウザで開く const handleUrlOpen = (event: Event, url: string) =\u0026gt; { event.preventDefault(); shell.openExternal(url); }; // リンククリック時のイベントハンドラを登録 win.webContents.on(\u0026#39;will-navigate\u0026#39;, handleUrlOpen); win.webContents.on(\u0026#39;new-window\u0026#39;, handleUrlOpen); 下記はメインプロセス全体のコードです。 main.ts import { app, BrowserWindow, shell } from \u0026#39;electron\u0026#39;; class MainWindow { private options: Electron.BrowserWindowConstructorOptions = { width: 800, height: 400, webPreferences: { nodeIntegration: true } } // リンククリック時に OS のデフォルトブラウザで開く private handleUrlOpen = (event: Event, url: string) =\u0026gt; { event.preventDefault(); shell.openExternal(url); }; constructor() { const win = new BrowserWindow(this.options); // リンククリック時のイベントハンドラを登録 win.webContents.on(\u0026#39;will-navigate\u0026#39;, this.handleUrlOpen); win.webContents.on(\u0026#39;new-window\u0026#39;, this.handleUrlOpen); win.loadFile(\u0026#39;public/index.html\u0026#39;); } } // Electron の初期化が完了したらウィンドウを作成 app.whenReady().then(() =\u0026gt; new MainWindow())"
},
{
url: "/p/7c2kdub/",
title: "Azure Pipelines トラブル: npm タスクを実行できないとき",
date: "2020-07-22T00:00:00Z",
body: "Azure Pipelines トラブル: npm タスクを実行できないとき Azure Pipelines の設定で、次のような感じで Npm タスクを追加したとき、 azure-pipelines.yml steps:- task:Npm@1inputs:command:\u0026#39;ci\u0026#39;displayName:\u0026#39;npm ci\u0026#39;- task:Npm@1inputs:command:\u0026#39;custom\u0026#39;customCommand:\u0026#39;run lint\u0026#39;displayName:\u0026#39;npm run lint\u0026#39; Node.js 系のコマンドが認識されていないと、エラーが出て Npm タスクを実行できません。 No agent found in pool Default which satisfies the specified demands: npm, Agent.Version -gtVersion 2.163.1 そのような場合は、steps の先頭で、次のように NodeTool (Node.js Tool Installer) タスクを実行しておくと、うまく動作するようになります 。 azure-pipelines.yml steps:# これで npm コマンドを認識するようになる- task:NodeTool@0inputs:versionSpec:\u0026#39;10.x\u0026#39;displayName:\u0026#39;Install Node.js\u0026#39; 参考リンク Node.js Tool Installer task - Azure Pipelines | Microsoft Docs NodeTool タスクは実行のたびに Node.js をダウンロード＆インストールするわけではなく、VM 上に存在するキャッシュなどを使って Node.js の環境をセットアップするため、通常は数秒で実行が完了します。 npm コマンドにパスが通るので、次のようにスクリプトで直接 npm コマンドを実行することも可能です。 - script:|npm install npm run builddisplayName:\u0026#39;npm install and build\u0026#39;"
},
{
url: "/p/jto2isn/",
title: "HTML/CSS のメモ",
date: "2020-07-19T00:00:00Z",
body: "HTML/CSS のメモ"
},
{
url: "/p/zgqz8gp/",
title: "フレックスボックス (Flexbox) レイアウトでサイドバーと本文を別々にスクロールできるようにする",
date: "2020-07-19T00:00:00Z",
body: "フレックスボックス (Flexbox) レイアウトでサイドバーと本文を別々にスクロールできるようにする CSS のフレックスボックスの登場により、サイドバーなどの2段組レイアウトを簡単に実現できるようになりました。 アプリによっては、サイドバーと本文部分を別々にスクロールできるようになっていると便利です。 次の例では、フレックスボックスのアイテムとして配置した 2 つの div 要素 (left と right) を、別々に縦スクロールできるようにしています。 HTML \u0026lt;div class=\u0026#34;container\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;left\u0026#34;\u0026gt; Left\u0026lt;br\u0026gt;Left\u0026lt;br\u0026gt;Left\u0026lt;br\u0026gt;Left\u0026lt;br\u0026gt;Left\u0026lt;br\u0026gt;Left\u0026lt;br\u0026gt; Left\u0026lt;br\u0026gt;Left\u0026lt;br\u0026gt;Left\u0026lt;br\u0026gt;Left\u0026lt;br\u0026gt;Left\u0026lt;br\u0026gt;Left\u0026lt;br\u0026gt; Left\u0026lt;br\u0026gt;Left\u0026lt;br\u0026gt;Left\u0026lt;br\u0026gt;Left\u0026lt;br\u0026gt;Left\u0026lt;br\u0026gt;Left\u0026lt;br\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;right\u0026#34;\u0026gt; Right\u0026lt;br\u0026gt;Right\u0026lt;br\u0026gt;Right\u0026lt;br\u0026gt;Right\u0026lt;br\u0026gt;Right\u0026lt;br\u0026gt; Right\u0026lt;br\u0026gt;Right\u0026lt;br\u0026gt;Right\u0026lt;br\u0026gt;Right\u0026lt;br\u0026gt;Right\u0026lt;br\u0026gt; Right\u0026lt;br\u0026gt;Right\u0026lt;br\u0026gt;Right\u0026lt;br\u0026gt;Right\u0026lt;br\u0026gt;Right\u0026lt;br\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; CSS body { margin: 0; height: 100vh; } .container { display: flex; height: 100%; } .left { width: 100px; background: #f9c; overflow-y: auto; } .right { flex: 1; background: #9cf; overflow-y: auto; } ポイントは次の通りです。 親要素 (container) の height で高さを指定する 子要素 (left/right) の overflow-y に auto を指定する これらの設定により、子要素の内容が表示領域 (height) に収まらないときに、自動的にスクロールバーが表示されるようになります。 ☝️ height: 100% 指定するときの注意 height プロパティを 100% のようにパーセンテージ指定する場合は、親要素の高さが明確になっている必要があります。 この例では body 要素の高さを画面いっぱい (100vh) に設定し、その子要素 (.container) の高さをその 100% になるように設定しています。"
},
{
url: "/p/awamxak/",
title: "Electron アプリのレイアウトにはフレックスボックスなど新しいスタイルを使用する",
date: "2020-07-14T00:00:00Z",
body: "Electron アプリのレイアウトにはフレックスボックスなど新しいスタイルを使用する Electron アプリのレンダリングには、最新の Chromium を使用できるため、比較的新しい CSS 機能を安心して使用することができます。 Web ブラウザで動作するわけではないので、ベンダープレフィックスなどのケアをする必要もありません。 例えば、次の例では、サイドバーと領域の広がる本文部分に別れるレイアウトを、CSS のフレックスボックス (Flexbox) で実現しています（ここでは React を使用しています）。 app.tsx import * as React from \u0026#39;react\u0026#39;; const styles: {[key: string]: React.CSSProperties} = { container: { display: \u0026#39;flex\u0026#39;, minHeight: \u0026#39;100vh\u0026#39;, }, sidebar: { background: \u0026#39;lightgray\u0026#39;, width: \u0026#39;150px\u0026#39;, }, body: { background: \u0026#39;#ddd\u0026#39;, flex: 1, } }; export class App extends React.Component { public render(): React.ReactNode { return ( \u0026lt;div style={styles.container}\u0026gt; \u0026lt;div style={styles.sidebar}\u0026gt;Sidebar\u0026lt;/div\u0026gt; \u0026lt;div style={styles.body}\u0026gt;Body\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; ); } } フレックスボックスはとても柔軟で、画面上端で左右に広がるメニュー など、いろいろな用途に使用することができます。"
},
{
url: "/p/e2eq3ep/",
title: "Electron コラム",
date: "2020-07-14T00:00:00Z",
body: "Electron コラム"
},
{
url: "/p/eu4cksy/",
title: "React コンポーネントに CSS スタイルを設定する",
date: "2020-07-12T00:00:00Z",
body: "React コンポーネントに CSS スタイルを設定する React は Web サイトの View レイヤのコンポーネントを作るためのライブラリですが、CSS ファイルの扱い方は特に決められておらず、今でも多くの人が試行錯誤しています。 ここでは、React アプリにおける CSS の扱い方を、下記のように分類して順番に説明していきます。 従来通り HTML 起点でスタイルを読み込む方法 インラインスタイル CSS Modules CSS in JS ライブラリ HTML ファイルで読み込んだ CSS ファイルを参照する これは React を使わない従来の HTML/CSS のやり方に近い方法です。 HTML ファイル内の style 要素で定義した CSS クラスや、HTML から読み込んだ CSS ファイル内で定義した CSS クラスを React コンポーネントから使用します。 例えば、HTML ファイル内で次のようにスタイル定義されているとします。 index.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;MyApp\u0026lt;/title\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1\u0026#34;\u0026gt;\u0026lt;/head\u0026gt; \u0026lt;style\u0026gt; .hello { color: blue; background: #aaccff; padding: 0.5em; font-weight: bolder; border-radius: 0.5em; } \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div id=\u0026#34;root\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;script src=\u0026#34;index.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 次の Hello コンポーネントは、1 つの div 要素を生成するだけの簡単な React コンポーネントで、上記で定義した CSS クラス hello を使用しています。 components/hello.tsx import * as React from \u0026#39;react\u0026#39;; export const Hello: React.FC = () =\u0026gt; { return ( \u0026lt;div className=\u0026#34;hello\u0026#34;\u0026gt;Hello\u0026lt;/div\u0026gt; ); }; JSX 要素で CSS クラスを指定する場合は、class 属性ではなく、className 属性を使用することに注意してください。 class という名前は JavaScript のキーワードと競合するため、このような仕様になっています。 下記は、この Hello コンポーネントの使用例です。 index.tsx（使用例） import * as React from \u0026#39;react\u0026#39;; import * as ReactDOM from \u0026#39;react-dom\u0026#39;; import { Hello } from \u0026#39;./components/hello\u0026#39;; ReactDOM.render(\u0026lt;Hello /\u0026gt;, document.getElementById(\u0026#39;root\u0026#39;)); このようなスタイル定義の方法は、伝統的な HTML/CSS のやり方に近いのでシンプルですが、 React コンポーネントからスタイル定義が分離してしまう グローバルな名前空間でスタイル定義しないといけない といった課題があります。 インラインスタイル（TypeScript にハードコード） 次の例では、TypeScript コードにハードコードする形でスタイルを定義しています。 このようにすることで、スタイル定義をコンポーネント内で完結できるため、別のコンポーネントと CSS クラス名が競合してしまうという心配がありません。 components/hello.tsx import * as React from \u0026#39;react\u0026#39;; // JSX要素用のスタイル定義（React.CSSProperties形式） const style: React.CSSProperties = { color: \u0026#39;blue\u0026#39;, background: \u0026#39;#aaccff\u0026#39;, padding: \u0026#39;0.5em\u0026#39;, fontWeight: \u0026#39;bolder\u0026#39;, borderRadius: \u0026#39;0.5em\u0026#39;, }; export const Hello: React.FC = () =\u0026gt; { return \u0026lt;div style={style}\u0026gt;Hello\u0026lt;/div\u0026gt;; }; React.CSSProperties 形式でのスタイル記述 ポイントは、スタイル定義のために React.CSSProperties 型のオブジェクトを作成するところです。 const style: React.CSSProperties = { color: \u0026#39;blue\u0026#39;, background: \u0026#39;#aaccff\u0026#39;, padding: \u0026#39;0.5em\u0026#39;, fontWeight: \u0026#39;bolder\u0026#39;, borderRadius: \u0026#39;0.5em\u0026#39;, }; プロパティ名が通常の CSS とは異なることに注意してください。 通常の CSS では、font-weight や border-radius のように、プロパティ名の単語はハイフンで区切られますが、React.CSSProperties では fontWeight や borderRadius といったキャメルケースでプロパティ名が定義されています。 これは、JavaScript (TypeScript) の文法上、プロパティ名にハイフンを含められないという制約によるものです。 あと、各プロパティがセミコロン (;) ではなく、カンマ (,) で区切られているところも、通常の CSS とは異なりますね。 CSS プロパティ名を使ったスタイル定義 どうしても CSS オリジナルなプロパティ名を使いたいのであれば、次のように、プロパティ名をシングルクォートで囲むことで、CSS のプロパティ名をそのまま使うことができます。 ただし、このようにするとプロパティ名の補完機能が効かなくなるので、できれば React.CSSProperties 型で適宜することをお勧めします。 // JSX要素用のスタイル定義（CSS形式） const style = { \u0026#39;color\u0026#39;: \u0026#39;blue\u0026#39;, \u0026#39;background\u0026#39;: \u0026#39;#aaccff\u0026#39;, \u0026#39;padding\u0026#39;: \u0026#39;0.5em\u0026#39;, \u0026#39;font-weight\u0026#39;: \u0026#39;bolder\u0026#39;, \u0026#39;border-radius\u0026#39;: \u0026#39;0.5em\u0026#39;, }; スタイル定義を入れ子で作成する 複数のスタイル定義を TypeScript コードにハードコードする場合、スタイル定義が複数の変数に散らばってしまうとコードが煩雑になってしまいます。 次の例では、入れ子構造の styles オブジェクト 1 つでスタイル定義をまとめています。 components/app.tsx import * as React from \u0026#39;react\u0026#39;; const styles: {[key: string]: React.CSSProperties} = { container: { display: \u0026#39;flex\u0026#39;, minHeight: \u0026#39;100vh\u0026#39;, }, sidebar: { background: \u0026#39;lightgray\u0026#39;, width: \u0026#39;150px\u0026#39;, }, body: { background: \u0026#39;#ddd\u0026#39;, flex: 1, } }; export class App extends React.Component { public render(): React.ReactNode { return ( \u0026lt;div style={styles.container}\u0026gt; \u0026lt;div style={styles.sidebar}\u0026gt;Sidebar\u0026lt;/div\u0026gt; \u0026lt;div style={styles.body}\u0026gt;Body\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; ); } } このようなインラインスタイルでのスタイル指定は、React コンポーネント内にスタイル定義を完結できるという利点はありますが、パフォーマンスの低下や、XSS などのセキュリティの懸念が常に付きまといます。 React に限らず、一般的な Web 設計のプラクティスになりますが、できるかぎり CSS クラスを使った方法を採用した方がよいでしょう。 CSS Modules CSS Modules の仕組みを利用すると、スタイルの名前空間を CSS ファイル単位（モジュール単位）で分離することができるようになります。 具体的には、外部の CSS ファイルを React コンポーネントなどの TypeScript (JavaScript) コードからインポートすることにより、スタイル設定をそのコンポーネントに閉じて行えるようになります。 目指す形 import * as React from \u0026#39;react\u0026#39;; import css from \u0026#39;./hello.css\u0026#39;; export const Hello: React.FC = () =\u0026gt; { return \u0026lt;div className={css.box}\u0026gt;Hello\u0026lt;/div\u0026gt;; }; 従来の HTML + CSS の構成では、CSS の名前空間がグローバルに共有されるため、クラス名が競合しないように最新の注意を払って設計する必要がありました。 BEM などの命名規則の登場により、CSS の設計手法は大分整ってきた感がありますが、やはり大きなサイトになってくると CSS の管理は大きなストレスになります。 このような場合に CSS Modules の仕組みを採用すると、コンポーネントごとに CSS の名前空間が独立しているので、.button のようなシンプルなクラス名を気軽に使うことができるようになります。 ここでは、最も一般的な？ webpack の css-loader と style-loader を使った CSS Modules の実現方法を説明します。 CSS ファイルをインポートできるようにする JavaScript コードには本来 CSS ファイルを解釈する機能は備わっていないので、 webpack などのバンドルツールの力を利用する必要があります。 webpack の拡張として css-loader を使うと、JS ファイルから CSS ファイルを import できるようになり、さらに style-loader を使うことで、JS コードから CSS を出力できるようになります（つまり両方必要です）。 インストール $ npm install --save-dev css-loader style-loader webpack の設定を修正し、css-loader と style-loader を使って CSS ファイルを TypeScript (JavaScript) コードから使用できるようにします。 処理順序の都合上、style-loader を先に指定しないといけないことに注意してください。 webpack.config.js（抜粋） module.exports = { // ... module: { rules: [ // CSS ファイルの読み込み { test: /\\.css$/, use: [\u0026#39;style-loader\u0026#39;, \u0026#39;css-loader\u0026#39;] }, ] } }; これで、次のように TypeScript コードから CSS ファイルをインポートして、React コンポーネントで使用できるようになります。 .css ファイルは、.ts ファイルと同じディレクトリに格納しておけば OK です。 styles.css .hello { color: blue; background: #aaccff; padding: 0.5em; font-weight: bolder; border-radius: 0.5em; } components/hello.tsx import * as React from \u0026#39;react\u0026#39;; import \u0026#39;./styles.css\u0026#39;; export const Hello: React.FC\u0026lt;IProps\u0026gt; = (prop) =\u0026gt; { return \u0026lt;div className=\u0026#34;hello\u0026#34;\u0026gt;{prop.text}\u0026lt;/div\u0026gt;; }; これで、TypeScript コードから CSS ファイルをインポートできるようになりましたが、CSS の名前空間はグローバルなままです。 上記の hello という CSS クラス名は、他のコンポーネントで使っている CSS とバッティングする可能性があります。 CSS をモジュール化する webpack の設定を次のように変更すると、css-loader の CSS Modules 機能を有効化できます。 この設定により、React コンポーネントごとに CSS の名前空間が分離されるようになります。 webpack.config.js（抜粋） module.exports = { // ... module: { rules: [ // CSS Modules { test: /\\.css$/, use: [ { loader: \u0026#39;style-loader\u0026#39;, }, { loader: \u0026#39;css-loader\u0026#39;, options: { modules: { localIdentName: \u0026#39;[name]__[local]___[hash:base64:5]\u0026#39;, } } } ] }, // ... ] } }; （入れ子がやばい。。。） 実際に出力される CSS のクラス名は、上記の localIdentName で指定したフォーマットで生成されます。 上記の設定の場合は、「CSSファイル名__CSSクラス名___ハッシュ値」というクラス名になります。 Hello コンポーネント (hello.tsx) 用の CSS ファイルは、ベースネームを合わせて hello.css としてしまうのがシンプルです。 CSS Modules により CSS クラス名の名前空間が独立するので、下記のようなシンプルなクラス名 (.box) を付けることができます（別に .root とか .container とか何でもよいです）。 hello.css .box { color: blue; background: #aaccff; padding: 0.5em; font-weight: bolder; border-radius: 0.5em; } この CSS ファイルは、React コンポーネントの中から下記のように使用します。 デフォルトエクスポートされたものとして、変数経由（下記の場合は css）で使用するところがポイントです。 こうすることで、複数の CSS ファイルを複数インポートした場合にも、クラス名がバッティングしません。 components/hello.tsx import * as React from \u0026#39;react\u0026#39;; import css from \u0026#39;./hello.css\u0026#39;; export const Hello: React.FC = () =\u0026gt; { return \u0026lt;div className={css.box}\u0026gt;Hello\u0026lt;/div\u0026gt;; }; 基本的にここまでで CSS Modules の導入は完了なのですが、TypeScript を使っている場合は、CSS ファイルをインポートしているところで次のようなエラーが出ます。 TypeScriptエラー Cannot find module \u0026#39;./hello.css\u0026#39; or its corresponding type declarations. これは、CSS ファイルを TypeScript のモジュールとして読み込んでいるのに、肝心の型定義が存在しないよというエラーです。 CSS ファイルごとに型定義ファイルを作ると完璧なのですが、そんなことはやっていられないので、次のような型定義ファイルをソースツリーのルートにおいてしまうのが手っ取り早いです。 typings.d.ts declare module \u0026#34;*.css\u0026#34; { const styles: { [className: string]: string }; export default styles; } まじめに CSS ファイルごとに型定義をするのであれば、hello.css の型定義ファイルは次のように作成します。 こうすると、VS Code での補完機能なども働くようになりますが、労力には見合わないと思います（こういった型定義ファイルを自動生成する npm モジュールもあります）。 hello.css.d.ts export const box: string; // CSSクラスが増えるごとに次のように同様に追加していく // export const className1: string; // export const className2: string; // export const className3: string; と、ここまで webpack を使った CSS Modules の導入方法を説明してきましたが、はっきりいって面倒 ですね。 思想自体は素晴らしいものなのですが。 ということで、もう少しライトにかつ柔軟にコンポーネント側でスタイル定義を行いたい、という思いから CSS-in-JS なライブラリが数多く登場してきています。 CSS in JS ライブラリ コンポーネントの TypeScript (JavaScript) コード内で柔軟なスタイル定義も行えるようにしたライブラリが、CSS in JS 系のライブラリです。 下記のように多くのライブラリが開発されています。 React: CSS in JS techniques comparison 有名どころは styled-components でしょうか。 自動でベンダープレフィックスを付けてくれたり、入れ子構造でスタイル定義できたりします。 インストール $ npm install --save-dev styled-components $ npm install --save-dev @types/styled-components 使い方は次のような感じでとてもシンプルです。 components/hello.tsx import * as React from \u0026#39;react\u0026#39;; import styled from \u0026#39;styled-components\u0026#39;; // Title コンポーネントの定義 const Title = styled.h1` font-size: 1.5em; text-align: center; color: palevioletred; `; // Hello コンポーネントの定義 export const Hello: React.FC = () =\u0026gt; { return \u0026lt;Title\u0026gt;Hello\u0026lt;/Title\u0026gt;; }; このコードでは Hello コンポーネントを定義しているのですが、出力関数の中で使っている Title コンポーネントは、styled-components の機能により生成されています（styled.h1 の部分）。 最終的に、Title タグを使用した JSX コードは、スタイル付きの h1 要素として出力されます。 Web ページのスタイル定義方法は、これからも試行錯誤が続きそうです。"
},
{
url: "/p/ucnv6en/",
title: "webpack と TypeScript を組み合わせて使用する",
date: "2020-07-05T00:00:00Z",
body: "webpack と TypeScript を組み合わせて使用する はじめに TypeScript は JavaScript コードに型付けすることができる優れたトランスパイラですが、変換後の .js ファイル群をまとめる（バンドルする）機能は備えていません。 また、モダンな Web サイトを構築するときは、CSS Modules や Sass/Less/Stylus といった仕組みを使用するのが常套手段となっています。 そのため、Web サイト用の .js ファイルを TypeScript を使って作成する場合、webpack などのバンドルツールを組み合わせて使用する必要があります。 TypeScript \u0026hellip; .ts ファイルから .js ファイルへの変換 webpack \u0026hellip; Web サイト用の各種リソースをバンドルする バンドルツールには様々なものがありますが、大きなシェアを占めているのは webpack なので（2020年現在）、ここでは TypeScript と webpack を組み合わせて使用する方法を説明します。 ☝️ webpack は必要なくなる？ ES Module の仕組みにより、Web ブラウザからモジュール化された .js ファイルをインポートすることが可能になりつつあります。 しかし、Web サイトの最終的なデプロイ時には、各種リソースを最適化（minify など）する必要があるため、まだまだ webpack などのバンドルツールが必要です。 関連パッケージのインストール TypeScript のインストール プロジェクト用のディレクトリと package.json を作成し、TypeScript をインストールします。 $ mkdir myapp \u0026amp;\u0026amp; cd $_ $ npm init -y $ npm install --save-dev typescript webpack のインストール webpack 関連のパッケージをインストールします。 $ npm install --save-dev webpack webpack-cli ts-loader html-webpack-plugin webpack \u0026hellip; webpack 本体 webpack-cli \u0026hellip; webpack のコマンドラインツール ts-loader \u0026hellip; webpack 経由で .ts ファイルをトランスパイルする html-webpack-plugin \u0026hellip; .html ファイルを dist ディレクトリに出力する 実装 ここでは、下記のようなディレクトリ構成をゴールとします。 Web サーバーにデプロイすべきファイル群（HTML ファイルや JS ファイル）は、dist ディレクトリ以下に出力されることを想定しています。 ディレクトリ構成 myapp/ +-- package.json # Node プロジェクトの設定 +-- tsconfig.json # TypeScript の設定 +-- webpack.config.js # webpack の設定 +-- dist/ # 出力先 +-- src/ +-- index.html +-- index.ts TypeScript の設定 (tsconfig.json) tsconfig.json { \u0026#34;compilerOptions\u0026#34;: { \u0026#34;target\u0026#34;: \u0026#34;ES2015\u0026#34;, \u0026#34;module\u0026#34;: \u0026#34;commonjs\u0026#34;, \u0026#34;lib\u0026#34;: [\u0026#34;esnext\u0026#34;, \u0026#34;dom\u0026#34;], \u0026#34;strict\u0026#34;: true, \u0026#34;esModuleInterop\u0026#34;: true, \u0026#34;skipLibCheck\u0026#34;: true, \u0026#34;forceConsistentCasingInFileNames\u0026#34;: true, // 出力先などは webpack 側で指定するので本質的には必要なし \u0026#34;sourceMap\u0026#34;: true, \u0026#34;outDir\u0026#34;: \u0026#34;./dist\u0026#34;, \u0026#34;sourceRoot\u0026#34;: \u0026#34;./src\u0026#34;, } } トランスパイル時の出力先などは webpack 側で制御するので、outDir などの指定は本質的には必要ありませんが、間違えて tsc コマンドで直接変換してしまった場合に、変な場所に .js ファイルが出力されないように念のため指定しておきます。 webpack の設定 (webpack.config.js) webpack によるバンドル後の結果を dist ディレクトリに出力することや、TypeScript 関連のコード（.ts ファイル）を認識させるための設定を行います。 webpack.config.js const path = require(\u0026#39;path\u0026#39;); const HtmlWebpackPlugin = require(\u0026#39;html-webpack-plugin\u0026#39;); module.exports = { // 開発用の設定 mode: \u0026#39;development\u0026#39;, // エントリポイントとなるコード entry: \u0026#39;./src/index.ts\u0026#39;, // バンドル後の js ファイルの出力先 output: { path: path.resolve(__dirname, \u0026#39;dist\u0026#39;), filename: \u0026#39;index.js\u0026#39; }, // ソースマップファイルの出力設定 devtool: \u0026#39;source-map\u0026#39;, module: { rules: [ // TypeScript ファイルの処理方法 { test: /\\.ts$/, use: \u0026#34;ts-loader\u0026#34;, include: path.resolve(__dirname, \u0026#39;src\u0026#39;), exclude: /node_modules/ } ] }, plugins: [ // HTML ファイルの出力設定 new HtmlWebpackPlugin({ template: \u0026#39;./src/index.html\u0026#39; }) ] }; index.html の作成 Web サイトのトップページとなる index.html を作成します。 このファイルに script 要素を記述しておく必要はありません。 HtmlWebpackPlugin が src/index.html を dist/index.html にコピーするときに、script 要素を自動挿入してくれます。 src/index.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;MyApp\u0026lt;/title\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1\u0026#34;\u0026gt;\u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div id=\u0026#34;root\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; index.ts の作成 トップページから読み込まれる index.js ファイルの TypeScript 版を作成します。 ここでは、div 要素のテキストを Hello に変更しています。 src/index.ts const root = document.getElementById(\u0026#39;root\u0026#39;) as HTMLDivElement; root.innerText = \u0026#39;Hello\u0026#39;; Web サイトのビルド webpack と TypeScript の設定ができたら、次のようにビルドを実行します。 $ npx webpack dist ディレクトリ以下に、index.html や index.js ファイルが出力されるので、出力された index.html ファイルを開いて、Hello と表示されることを確認します。 ビルド方法は、package.json でスクリプト定義しておきましょう。 package.json { \u0026#34;name\u0026#34;: \u0026#34;myapp\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1.0.0\u0026#34;, \u0026#34;scripts\u0026#34;: { \u0026#34;build\u0026#34;: \u0026#34;webpack\u0026#34; }, \u0026#34;devDependencies\u0026#34;: { \u0026#34;html-webpack-plugin\u0026#34;: \u0026#34;^4.3.0\u0026#34;, \u0026#34;ts-loader\u0026#34;: \u0026#34;^7.0.5\u0026#34;, \u0026#34;typescript\u0026#34;: \u0026#34;^3.9.6\u0026#34;, \u0026#34;webpack\u0026#34;: \u0026#34;^4.43.0\u0026#34;, \u0026#34;webpack-cli\u0026#34;: \u0026#34;^3.3.12\u0026#34; } } これで、npm run build でビルドできるようになります。"
},
{
url: "/p/mkisgqb/",
title: "Electron のメインプロセスとレンダラープロセスの関係",
date: "2020-07-02T00:00:00Z",
body: "Electron のメインプロセスとレンダラープロセスの関係 メインプロセスとレンダラープロセス Electron アプリを作成するときは、メインプロセスとレンダラープロセスを意識して使い分ける必要があります。 レンダラープロセス側で呼び出し可能な Electron モジュール（他の Node モジュールも含む）は制限されていて、実行できる JavaScript ライブラリは、Web ブラウザ上で実行可能な JavaScript に毛が生えたものくらいものと考えておくのがよいです。 ipcRenderer モジュールは例外的にレンダラープロセスから使ってもよいとされているモジュールのひとつで、これ経由でメインプロセスに対して要求（メッセージ）を送ることができます。 逆にメインプロセスからのメッセージをハンドルすることもできます。 通知先のレンダラープロセスの指定 メインプロセスに対して、レンダラープロセスは複数存在することがあるので、メインプロセスからメッセージを送るときは、どのレンダラープロセスへのメッセージなのかを意識する必要があります。 レンダラープロセスからのメッセージに応答する レンダラープロセスからのイベントを ipcMain.on() でハンドルする場合、コールバック関数の第1パラメータとして渡される event: Electron.IpcMainEvent オブジェクトから送信元のレンダラープロセス (sender: Electron.WebContents) を参照することができます。 下記のメインプロセスは、my-add イベントとしてレンダラープロセスから 2 つの数値を受け取り、IpcMainEvent.reply() を使って送信元のレンダラープロセスに応答メッセージ（数値を足した結果）を返しています。 main.ts（メインプロセス） // レンダラープロセスからメッセージを受信して、応答メッセージを返す ipcMain.on(\u0026#39;my-add\u0026#39;, (evt: Electron.IpcMainEvent, num1: number, num2: number) =\u0026gt; { evt.reply(\u0026#39;my-add-reply\u0026#39;, num1 + num2); //evt.sender.send(\u0026#39;my-add-reply\u0026#39;, num1 + num2); }); レンダラープロセス側では、ipcRenderer.send() でメインプロセスにメッセージを送り、その応答を ipcRenderer.on() でハンドルするように実装します。 renderer.ts（レンダラープロセス） import { ipcRenderer } from \u0026#39;electron\u0026#39;; // メインプロセスへメッセージを送信 ipcRenderer.send(\u0026#39;my-add\u0026#39;, 100, 200); // メインプロセスからメッセージを受信 ipcRenderer.on(\u0026#39;my-add-reply\u0026#39;, (evt: Electron.Event, result: number) =\u0026gt; { alert(result); //=\u0026gt; 300 }); ある BrowserWindow のレンダラープロセスにメッセージを送る BrowserWindow のインスタンスがあれば、そのウィンドウのレンダラープロセスに対してメッセージを送ることができます。 main.ts（メインプロセス） const win = new BrowserWindow(options); win.webContents.once(\u0026#39;did-finish-load\u0026#39;, () =\u0026gt; { win.webContents.send(\u0026#39;message-from-main\u0026#39;, \u0026#39;Hello!\u0026#39;); }); win.loadFile(\u0026#39;public/index.html\u0026#39;); メインプロセス側から能動的にメッセージを送る場合は、レンダラープロセス側のコンテンツが準備できてから送らないといけないことに注意してください。 上記の例では、レンダラープロセスから最初に did-finish-load イベント を受診したときに、メッセージを送信するようにしています。 別の方法として、win.loadFile() が返す Promise が resolve 状態になるのを待つという方法があります。 タイミングは did-finish-load イベントが発行されるタイミングと同じになります。 このあたりは、loadFile() の API ドキュメント に記述されています。 main.ts（別の方法） win.loadFile(\u0026#39;public/index.html\u0026#39;).then(() =\u0026gt; { win.webContents.send(\u0026#39;message-from-main\u0026#39;, \u0026#39;Hello!\u0026#39;); }); レンダラープロセス側は、単純に ipcRenderer.on() で受診すれば OK です。 renderer.ts（レンダラープロセス） import { ipcRenderer } from \u0026#39;electron\u0026#39;; ipcRenderer.on(\u0026#39;message-from-main\u0026#39;, (evt: Electron.Event, msg: string) =\u0026gt; { alert(\u0026#39;Message from main: \u0026#39; + msg); });"
},
{
url: "/p/77sas8m/",
title: "Electron の app.getData() で取得できる特殊ディレクトリパスの一覧",
date: "2020-07-01T00:00:00Z",
body: "Electron の app.getData() で取得できる特殊ディレクトリパスの一覧 app.getPath について electron モジュールの app.getPath(name) 関数を使用すると、OS 固有の特殊フォルダパスを取得することができます。 例えば、getPath('userData') とすると、ユーザーの設定ファイルなどを格納するディレクトリを取得することができます。 下記は、いろんな特殊フォルダのパスを取得するテストコードです。 import { app } from \u0026#39;electron\u0026#39;; export function showSpecialDirs() { console.log(`app.getAppPath() = ${app.getAppPath()}`); console.log(\u0026#39;\\n==== Application data\u0026#39;); console.log(`app.getPath(\u0026#39;home\u0026#39;) = ${app.getPath(\u0026#39;home\u0026#39;)}`); console.log(`app.getPath(\u0026#39;temp\u0026#39;) = ${app.getPath(\u0026#39;temp\u0026#39;)}`); console.log(`app.getPath(\u0026#39;appData\u0026#39;) = ${app.getPath(\u0026#39;appData\u0026#39;)}`); console.log(`app.getPath(\u0026#39;cache\u0026#39;) = ${app.getPath(\u0026#39;cache\u0026#39;)}`); console.log(`app.getPath(\u0026#39;userData\u0026#39;) = ${app.getPath(\u0026#39;userData\u0026#39;)}`); console.log(`app.getPath(\u0026#39;logs\u0026#39;) = ${app.getPath(\u0026#39;logs\u0026#39;)}`); console.log(`app.getPath(\u0026#39;crashDumps\u0026#39;) = ${app.getPath(\u0026#39;crashDumps\u0026#39;)}`); console.log(\u0026#39;\\n==== OS multimedia\u0026#39;) console.log(`app.getPath(\u0026#39;desktop\u0026#39;) = ${app.getPath(\u0026#39;desktop\u0026#39;)}`); console.log(`app.getPath(\u0026#39;documents\u0026#39;) = ${app.getPath(\u0026#39;documents\u0026#39;)}`); console.log(`app.getPath(\u0026#39;downloads\u0026#39;) = ${app.getPath(\u0026#39;downloads\u0026#39;)}`); console.log(`app.getPath(\u0026#39;music\u0026#39;) = ${app.getPath(\u0026#39;music\u0026#39;)}`); console.log(`app.getPath(\u0026#39;pictures\u0026#39;) = ${app.getPath(\u0026#39;pictures\u0026#39;)}`); console.log(`app.getPath(\u0026#39;videos\u0026#39;) = ${app.getPath(\u0026#39;videos\u0026#39;)}`); console.log(\u0026#39;\\n==== Executables\u0026#39;) console.log(`app.getPath(\u0026#39;exe\u0026#39;) = ${app.getPath(\u0026#39;exe\u0026#39;)}`); console.log(`app.getPath(\u0026#39;module\u0026#39;) = ${app.getPath(\u0026#39;module\u0026#39;)}`); } 逆に特殊フォルダのパスを設定するための app.setPath(name, path) 関数も提供されています。 アプリ起動時に、この関数を使って特殊フォルダのパスをカスタマイズすれば、各モジュールが使用するフォルダのパスを切り替えることができます（そのモジュールが app.getPath() でパスを取得していることが前提ですが）。 例えば、ユーザーデータを扱うテストコードを実行する場合は、app.setPath('userData', `${__dirname}/test-data`) のようにテスト用のデータフォルダに切り替えることができます。 各種 OS で app.getPath したときの結果 上記の関数を各種 OS で実行すると次のような結果が得られます。 Windows 10 の場合 app.getAppPath() = D:\\gitwork\\MyApp ==== Application data app.getPath(\u0026#39;home\u0026#39;) = C:\\Users\\maku app.getPath(\u0026#39;temp\u0026#39;) = C:\\Users\\maku\\AppData\\Local\\Temp app.getPath(\u0026#39;appData\u0026#39;) = C:\\Users\\maku\\AppData\\Roaming app.getPath(\u0026#39;cache\u0026#39;) = C:\\Users\\maku\\AppData\\Roaming app.getPath(\u0026#39;userData\u0026#39;) = C:\\Users\\maku\\AppData\\Roaming\\MyApp app.getPath(\u0026#39;logs\u0026#39;) = C:\\Users\\maku\\AppData\\Roaming\\MyApp\\Electron\\logs app.getPath(\u0026#39;crashDumps\u0026#39;) = C:\\Users\\maku\\AppData\\Roaming\\MyApp\\Crashpad ==== OS multimedia app.getPath(\u0026#39;desktop\u0026#39;) = C:\\Users\\maku\\Desktop app.getPath(\u0026#39;documents\u0026#39;) = C:\\Users\\maku\\Documents app.getPath(\u0026#39;downloads\u0026#39;) = C:\\Users\\maku\\Downloads app.getPath(\u0026#39;music\u0026#39;) = C:\\Users\\maku\\Music app.getPath(\u0026#39;pictures\u0026#39;) = C:\\Users\\maku\\Pictures app.getPath(\u0026#39;videos\u0026#39;) = C:\\Users\\maku\\Videos ==== Executables app.getPath(\u0026#39;exe\u0026#39;) = D:\\gitwork\\MyApp\\node_modules\\electron\\dist\\electron.exe app.getPath(\u0026#39;module\u0026#39;) = D:\\gitwork\\MyApp\\node_modules\\electron\\dist\\electron.exe"
},
{
url: "/p/2tcs8n2/",
title: "Electron アプリの配布パッケージを作る (electron-builder)",
date: "2020-07-01T00:00:00Z",
body: "Electron アプリの配布パッケージを作る (electron-builder) 概要 electron-builder を使用すると、Electron アプリを Windows、macOS、Linux 用の配布用バイナリとしてパッケージングすることができます。 各 OS 用のインストーラはもちろん、ポータブルな zip パッケージを作成することもできます。 electron-builder 公式サイトのドメイン名が electron.build っていうのがかっこいいですね。 electron-builder のインストール Node.js のパッケージ管理ツールとして、npm よりも yarn を使うことが strongly recommended されているので、まず yarn をインストールしてから yarn で electron-builder をインストールすることにします。 $ npm install -g yarn $ yarn add electron-builder --dev 下記のように実行して、ヘルプを表示できればインストール完了です。 $ npx electron-builder --help ビルド設定 electron-builder 用の設定は、package.json の build プロパティで行うことができます。 ポイントは、files の指定で、パッケージングする html ファイルや js ファイル、画像ファイルなどをすべてカバーするように指定しておく必要があります。 package.json { \u0026#34;name\u0026#34;: \u0026#34;myapp\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;0.0.1\u0026#34;, \u0026#34;main\u0026#34;: \u0026#34;build/main.js\u0026#34;, \u0026#34;scripts\u0026#34;: { \u0026#34;start\u0026#34;: \u0026#34;tsc \u0026amp;\u0026amp; electron .\u0026#34; }, \u0026#34;build\u0026#34;: { \u0026#34;appId\u0026#34;: \u0026#34;com.example.myapp\u0026#34;, \u0026#34;productName\u0026#34;: \u0026#34;MyApp\u0026#34;, \u0026#34;files\u0026#34;: [ \u0026#34;build/**/*\u0026#34;, \u0026#34;public/**/*\u0026#34; ] }, \u0026#34;devDependencies\u0026#34;: { \u0026#34;@types/node\u0026#34;: \u0026#34;^14.0.14\u0026#34;, \u0026#34;electron\u0026#34;: \u0026#34;^9.0.5\u0026#34;, \u0026#34;electron-builder\u0026#34;: \u0026#34;^22.7.0\u0026#34;, \u0026#34;typescript\u0026#34;: \u0026#34;^3.9.5\u0026#34; } } パッケージの作成 上記のビルド設定に従ってパッケージを作成するには、electron-builder コマンドを使用します。 各種オプションにより、どの OS 用のパッケージを作成するかを指定することができます。 オプションは npx electron-builder --help で確認できますが、次のようにオプションを組み合わせてパッケージを作成できます。 オプション 説明 作成されるファイル --mac --x64 macOS (x64) 用インストーラー MyApp-0.0.1.dmg --mac --x64 --dir macOS (x64) 用ポータブルパッケージ MyApp.app --win --x64 Windows (x64) 用インストーラー MyApp Setup 0.0.1.exe --win --x64 --dir Windows (x64) 用ポータブルパッケージ MyApp.exe + 依存DLLなど ここでは、macOS のポータブルパッケージ (MyApp.app) を作成してみます。 ポータブルパッケージは、いわゆるインストーラーではなく、ディレクトリごとコピーすればそのまま実行できる形態のものです。 $ npx electron-builder --mac --x64 --dir デフォルトで、dist ディレクトリ以下に実行ファイルが作成されるので、例えば、macOS では次のようにアプリを起動することができます（Finder から MyApp.app アイコンをダブルクリックしても起動できます）。 $ open dist/mac/MyApp.app macOS 環境で Windows 用のパッケージを作成することもできます。 その場合は、自動的に wine がダウンロードされてビルドが実行されます。 一方、Windows 環境で macOS 用のパッケージを作成することはできないようです。 Apple イケてないですね。 応用 .gitignore の修正 .gitignore ファイルには、パッケージの出力ディレクトリである dist/ を追加しておきましょう。 package.json へスクリプト追加 package.json に次のようにスクリプト定義しておけば、npm run build:mac コマンド（あるいは yarn run build:mac）で簡単に配布用パッケージを作成できるようになります。 package.json { \u0026#34;name\u0026#34;: \u0026#34;myapp\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;0.0.1\u0026#34;, \u0026#34;main\u0026#34;: \u0026#34;build/main.js\u0026#34;, \u0026#34;scripts\u0026#34;: { \u0026#34;start\u0026#34;: \u0026#34;tsc \u0026amp;\u0026amp; electron .\u0026#34;, \u0026#34;build:mac\u0026#34;: \u0026#34;electron-builder --mac --x64\u0026#34;, \u0026#34;build:win\u0026#34;: \u0026#34;electron-builder --win --x64\u0026#34; }, // ... }"
},
{
url: "/p/aq2airz/",
title: "Electron: レンダラーからの要求でメインプロセスでファイルを読み込んで返す",
date: "2020-06-29T00:00:00Z",
body: "Electron: レンダラーからの要求でメインプロセスでファイルを読み込んで返す Electron アプリのメインプロセスで使用できる ipcMain.handle を使うと、レンダラーから呼び出せる関数のようなものを定義できます。 正確には、特定の名前のチャネル (channel) へのメッセージをハンドルするコールバック関数を設定します。 次の例では、メインプロセスで read-textfile メッセージを受診したときに、指定されたファイルを読み込んでその内容を返すように実装しています。 main.js（メインプロセス） import { app, ipcMain, BrowserWindow } from \u0026#39;electron\u0026#39;; import * as fs from \u0026#39;fs\u0026#39;; // ... // 指定されたテキストファイルを読みこんで、その内容を返します。 ipcMain.handle(\u0026#39;read-textfile\u0026#39;, async (event, filename) =\u0026gt; { const buf = await fs.promises.readFile(filename); return buf.toString(); }); 一方、レンダラー側では ipcRenderer.invoke を使って、あたかも関数呼び出しのようにメインプロセス側の処理を呼び出すことができます。 次の例では、画面上のボタンを押した時にメインプロセスに read-textfile メッセージを送り、その戻り値を表示しています。 renderer.js import { ipcRenderer } from \u0026#39;electron\u0026#39;; const btn = document.querySelector(\u0026#39;#btn\u0026#39;)!; const output = document.querySelector(\u0026#39;#output\u0026#39;)!; btn.addEventListener(\u0026#39;click\u0026#39;, () =\u0026gt; { ipcRenderer.invoke(\u0026#39;read-textfile\u0026#39;, \u0026#39;./hoge.txt\u0026#39;) .then((text) =\u0026gt; { output.innerHTML = text; }) .catch((err) =\u0026gt; { alert(err); }); }); HTML コンテンツの内容は次のような感じになります。 index.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Hello Electron!\u0026lt;/title\u0026gt; \u0026lt;!-- https://electronjs.org/docs/tutorial/security#csp-meta-tag --\u0026gt; \u0026lt;meta http-equiv=\u0026#34;Content-Security-Policy\u0026#34; content=\u0026#34;script-src \u0026#39;self\u0026#39; \u0026#39;unsafe-inline\u0026#39;;\u0026#34; /\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;button id=\u0026#34;btn\u0026#34;\u0026gt;ファイル読み込み\u0026lt;/button\u0026gt; \u0026lt;div id=\u0026#34;output\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;script\u0026gt;require(\u0026#39;./build/renderer\u0026#39;)\u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;"
},
{
url: "/p/xkxbnza/",
title: "Electron: 処理が終わるまでボタンを無効状態 (disabled) にする",
date: "2020-06-29T00:00:00Z",
body: "Electron: 処理が終わるまでボタンを無効状態 (disabled) にする button 要素の disabled プロパティ JavaScript で button 要素の disabled プロパティを true に設定すると、ボタンを無効状態 (disabled) にすることができます。 TypeScript を使っている場合は、document.querySelector() の戻り値を HTMLButtonElement にキャストすることで disabled プロパティを参照できるようになります。 button 要素を disabled にする const btn = document.querySelector(\u0026#39;#btn\u0026#39;) as HTMLButtonElement; btn.disabled = true; ボタンを押したときに重い処理（データ取得など）を実行する場合、処理中にボタンを無効化することで、ユーザーによるボタンの連打を防ぐことができます。 より実践的なサンプル 下記は Electron アプリの実装サンプル（レンダラープロセスの抜粋）です。 ボタンを押したときにボタンを無効化すると同時に Web からデータ取得します。 そして、データ取得が完了するか、エラーが発生したときにボタンを有効化します。 ここでは、HTTP GET リクエストを送るために superagent モジュールを使用しています。 superagent のインストール $ npm install --save superagent $ npm install --save @types/superagent renderer.ts import * as superagent from \u0026#39;superagent\u0026#39;; const btn = document.querySelector(\u0026#39;#btn\u0026#39;) as HTMLButtonElement; btn.addEventListener(\u0026#39;click\u0026#39;, async () =\u0026gt; { btn.disabled = true; // データ取得前にボタンを無効化 try { const res = await superagent.get(\u0026#39;https://example.com/\u0026#39;); console.log(res.text); } catch (err) { alert(err); } finally { btn.disabled = false; // データ取得後にボタンを有効化 } }); HTML ファイルの方にはボタンだけ配置しておけば OK です。 index.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Hello Electron!\u0026lt;/title\u0026gt; \u0026lt;!-- https://electronjs.org/docs/tutorial/security#csp-meta-tag --\u0026gt; \u0026lt;meta http-equiv=\u0026#34;Content-Security-Policy\u0026#34; content=\u0026#34;script-src \u0026#39;self\u0026#39; \u0026#39;unsafe-inline\u0026#39;;\u0026#34; /\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;button id=\u0026#34;btn\u0026#34;\u0026gt;データ取得\u0026lt;/button\u0026gt; \u0026lt;script\u0026gt;require(\u0026#39;./build/renderer\u0026#39;)\u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;"
},
{
url: "/p/ihwanyc/",
title: "Electron で各種ダイアログを表示する (dialog)",
date: "2020-06-29T00:00:00Z",
body: "Electron で各種ダイアログを表示する (dialog) electron モジュールが提供する dialog を使用すると、いろいろなダイアログを表示することができます。 ダイアログの表示は、メインプロセスからしか行えません。 参考: Electron Documentation - dialog エラーボックス (showErrorBox) 一番簡単に使えそうなエラーボックスから。 ダイアログのタイトルと、メッセージの内容を指定するだけで表示できます。 dialog.showErrorBox(title, content) import { dialog } from \u0026#39;electron\u0026#39;; dialog.showErrorBox(\u0026#39;File Not Found\u0026#39;,\u0026#39;指定されたファイルが見つかりませんでした。\u0026#39;); このエラーボックスが表示されている間は、他の全てのウィンドウが操作できなくなるようです（つまり、モーダルダイアログとして振る舞います）。 ドキュメントによると、この dialog.showErrorBox は、「app モジュールが ready イベントを emit する前に呼び出すことができる」とされています。 つまり、アプリケーションの起動時に行うエラーチェックなどで使用できるということです（メインウィンドウ表示前に設定ファイルの内容が正しいか調べたり）。 レンダラープロセス側では alert() を使っちゃうことが多いかもしれません。 メッセージボックス (showMessageBox, showMessageBoxSync) メッセージボックスを表示するには、次のような関数を使用します。 dialog.showMessageBox(options) dialog.showMessageBox(browserWindow, options) dialog.showMessageBoxSync(options) dialog.showMessageBoxSync(browserWindow, options) 表示内容を options パラメータでいろいろ制御できます（下記に例を示します）。 メッセージボックスが表示されている間は、基本的には他のウィンドウを操作できなくなります。 browserWindow パラメーターで、親ウィンドウとなる BrowserWindow インスタンスを指定すると、その親ウィンドウのモーダレスダイアログとなり、その親ウィンドウだけ操作できなくなります。 ☝️ ワンポイント showMessageBoxSync() にも親ウィンドウを指定するバージョンがありますが、この関数を呼び出すと結局他のウィンドウも操作できなくなります。 いまいち使いどころが分かりませんが、親ウィンドウを指定することで、親ウィンドウの表示位置に近いところにダイアログが表示されるという効果は得られます。 例: OK ボタンだけあるダイアログ const options: Electron.MessageBoxOptions = { type: \u0026#39;info\u0026#39;, // none/info/error/quetion/warning title: \u0026#39;タイトル\u0026#39;, message: \u0026#39;メッセージ\u0026#39;, detail: \u0026#39;説明文\u0026#39; }; dialog.showMessageBox(options); オプションで buttons の指定を省略すると、デフォルトで OK ボタンがひとつだけあるダイアログが表示されます。 type オプションの指定により表示されるアイコンが変化したりします。 例: 複数のボタンがあるダイアログ const options: Electron.MessageBoxSyncOptions = { type: \u0026#39;question\u0026#39;, // none/info/error/question/warning title: \u0026#39;タイトル\u0026#39;, message: \u0026#39;メッセージ\u0026#39;, detail: \u0026#39;説明文\u0026#39;, buttons: [\u0026#39;OK\u0026#39;, \u0026#39;Cancel\u0026#39;, \u0026#39;ボタン1\u0026#39;, \u0026#39;ボタン2\u0026#39;], cancelId: -1 // Esc で閉じられたときの戻り値 }; const selected: number = dialog.showMessageBoxSync(options); console.log(`${selected}番目が選択されました`); buttons オプションで、表示するボタンを指定することができます。 OS によって右から並べられたりするようなので（macOS では上の図のように右からになった）、ボタン名に連番などは振らない方がよいでしょう。 ユーザーが選択したボタンのインデックス（0始まり）は、戻り値で取得することができます。 上記の例の場合は、各ボタンを押したときに次のような値が返されます。 OK \u0026hellip; 0 Cancel \u0026hellip; 1 ボタン1 \u0026hellip; 2 ボタン2 \u0026hellip; 3 Esc キーなどでキャンセルした場合は、デフォルトでは Cancel や No といったテキストを含むボタンのインデックスが返されるようになっていますが、cancelId オプションで任意の値に変更することができます。 ここでは同期版の showMessageBoxSync() を使用していますが、代わりに showMessageBox を使用すると、戻り値の型が Promise 型に変わるので注意してください（使用例は下で説明します）。 例: 非同期に複数のダイアログを表示する showMessageBox() でダイアログを表示するときに親ウィンドウを指定すると、その他のウィンドウは操作可能な状態でキープされます。 次の例では、2 つのウィンドウ（win1、win2）が表示されている状態で、それぞれのウィンドウを親とするモーダルダイアログを同時に表示しています。 2 つのダイアログは、どちらも操作可能な状態になっており、どちらのダイアログを先に操作するかはユーザーが自由に選択できます。 ユーザーが選択したボタンのインデックスは、showMessageBox() の戻り値である Promise\u0026lt;Electron.MessageBoxReturnValue\u0026gt; オブジェクトから非同期に取り出すことができます。 // 2つのウィンドウを表示 const win1 = new BrowserWindow({ title: \u0026#39;win1\u0026#39;, width: 500, height: 200, }) const win2 = new BrowserWindow({ title: \u0026#39;win2\u0026#39;, width: 500, height: 200, }) // ダイアログの設定 const options: Electron.MessageBoxOptions = { type: \u0026#39;question\u0026#39;, message: \u0026#39;確認\u0026#39;, detail: \u0026#39;本当に削除しちゃっていいですか？\u0026#39;, buttons: [\u0026#39;削除\u0026#39;, \u0026#39;キャンセル\u0026#39;], }; // 2つのダイアログを同時に表示（それぞれ別の親ウィンドウを持つ） const result1: Promise\u0026lt;Electron.MessageBoxReturnValue\u0026gt; = dialog.showMessageBox(win1, options); const result2: Promise\u0026lt;Electron.MessageBoxReturnValue\u0026gt; = dialog.showMessageBox(win2, options); // 結果はそれぞれ非同期に取得できる result1.then(val =\u0026gt; console.log(val.response)); result2.then(val =\u0026gt; console.log(val.response));"
},
{
url: "/p/7r6gr3d/",
title: "Node.js で GitHub REST API を使用する (@octokit/rest)",
date: "2020-06-28T00:00:00Z",
body: "Node.js で GitHub REST API を使用する (@octokit/rest) 概要 Octokit は、様々な言語から GitHub API を使用するためのライブラリを提供しています。 ここでは、TypeScript (JavaScript) 用の GitHub API v3 (REST API) ライブラリである、@octokit/rest を使用する方法を紹介します。 インストール @octokit/rest は次のようにインストールします（npm init で package.json を作成済みだと想定します）。 $ npm install @octokit/rest --save 実装（基本） 基本的には下記の API ドキュメントを参照しながら実装していくことになります。 octokit/rest.js API ドキュメント Octokit インスタンスを生成する main.ts import { Octokit } from \u0026#39;@octokit/rest\u0026#39;; const octokit = new Octokit(); このように生成した Octokit インスタンスを使って、様々な REST API を呼び出します。 リポジトリの一覧を取得する (repos.listForOrg) API ドキュメント (Repos - Get a repository) 次の例では、組織名 sony のパブリックなリポジトリを 5 件分取得しています。 octokit .repos.listForOrg({ org: \u0026#39;sony\u0026#39;, // 取得対象とする組織 (organization) type: \u0026#39;public\u0026#39;, // public なリポジトリのみ取得 sort: \u0026#39;full_name\u0026#39;, // レスポンスの data 配列を full_name でソート per_page: 5, // 1リクエストごとのデータ数（デフォルト:30、最大:100） }) .then(response =\u0026gt; { console.log(JSON.stringify(response, null, 2)); }); 出力結果は長いので、こちらにテキストファイル として置いておきます。 おそらく、JSON レスポンス内で実際に必要な情報は data プロパティの配列データなので、下記のように then コールバックのパラメータで data 配列の値を取り出すとコードがスッキリします。 .then(({ data }) =\u0026gt; { for (const repo of data) { console.log(`${repo.full_name}- ${repo.description}`); } }); 実行結果 sony/ai-research-code - null sony/appsync-client-go - AWS AppSync golang client library sony/cdn-purge-control-php - Multi CDN purge control library for PHP sony/cdp-cli - Command line tools for generating start point of ... sony/cdp-js - Libraries/SDK modules for multi-platform ... 指定したリポジトリの Issue 一覧を取得する (issues.listForRepo) API ドキュメント (Issues - List repository issues) 次の例では、octokit/rest.js リポジトリのオープン状態の Issue を 5 件分取得しています。 octokit .issues.listForRepo({ owner: \u0026#39;octokit\u0026#39;, // 取得対象とする組織 (organization) repo: \u0026#39;rest.js\u0026#39;, // 取得対象のリポジトリ名 state: \u0026#39;open\u0026#39;, // オープン状態のIssueだけ取得 per_page: 5, // 1リクエストごとのデータ数（デフォルト:30、最大:100） }) .then(response =\u0026gt; { for (const issue of response.data) { console.log(`* ${issue.number}: ${issue.title}`); } }) .catch(err =\u0026gt; console.error(err)); 実行結果 * 1775: octokit.repos.getCommunityProfileMetrics() does not set ... * 1773: Documentation: Broken link to `client-options` * 1757: Error thrown for a not-found user (404) should have more details * 1738: getSelfHostedRunner status is always online never active * 1725: 422 on PUT /repos/:owner/:repo/branches/:branch/protection 実装（応用） ページネーションの自動化 (octokit.pagenate) listXXX 系の API では、一度に最大 100 件（per_page: 100 指定時）までの情報しか取得できません。 これは、GitHub REST API の制約であり、それ以上のデータを取得するには、ページネーションの仕組みを利用して複数回に分けてリクエストを送る必要 があります。 GitHub’s REST API pagination documentation Octokit クラスは pagenate メソッド を提供しており、連続する REST API 呼び出しを自動化してくれます。 次の例では、octokit/rest.js リポジトリの全オープン Issue を取得しています（100件を超えていても一度に取得できます）。 main.ts import { Octokit } from \u0026#39;@octokit/rest\u0026#39;; const octokit = new Octokit(); octokit .paginate(\u0026#39;GET /repos/:owner/:repo/issues\u0026#39;, { owner: \u0026#39;octokit\u0026#39;, // 取得対象とする組織 (organization) repo: \u0026#39;rest.js\u0026#39;, // 取得対象のリポジトリ名 state: \u0026#39;open\u0026#39;, // オープン状態のIssueだけ取得 per_page: 100, // 1ページごとの件数は最大値にしておく }) .then(issues =\u0026gt; { for (const issue of issues) { console.log(`* ${issue.number}- ${issue.title}`); } }) .catch(err =\u0026gt; console.error(err)); Private リポジトリの情報を取得する（アクセストークン） Private リポジトリの Issue リストなどを取得する場合は、OAuth トークンやパーソナル・アクセス・トークンを指定して GitHub API を呼び出す必要があります（権限がない場合の呼び出しは HTTP 404 エラーになります）。 例えば、パーソナル・アクセス・トークンは、GitHub の下記のユーザー設定画面から発行することができます。 GitHub / Settings / Personal Access Tokens トークン生成時に権限のスコープを指定する必要があるのですが、Issue リストなどを取得するのであれば、repo にチェックを入れておけばよいはずです。 取得したトークン（40文字の文字列）は、次のように Octokit クラスのコンストラクタで渡してやります。 import { Octokit } from \u0026#39;@octokit/rest\u0026#39;; const octokit = new Octokit({ auth: \u0026#39;a0709c8d0ac21812d9c4b8511298b33ec0fd2813\u0026#39; }); これで、このインスタンスを使った GitHub API 呼び出しが、トークン付きで実行されるようになります。"
},
{
url: "/p/gas9o5i/",
title: "文章構成ツール (textlint) のメモ",
date: "2020-06-18T00:00:00Z",
body: "文章構成ツール (textlint) のメモ"
},
{
url: "/p/m4cks29/",
title: "textlint で表記揺れをチェックする (proofread-helper, prh)",
date: "2020-06-18T00:00:00Z",
body: "textlint で表記揺れをチェックする (proofread-helper, prh) prh と textlint-rule-prh テキストファイルの表記揺れをチェックする Node.js 製ツールに、proofread-helper (prh) というものがあります。 これを使うと、例えば、テキストファイル内の javascript という文字列を JavaScript に自動的に修正できたりします（大文字・小文字の構成）。 textlint の作者の azu さんが、この prh を textlint から使えるようにするルール定義 textlint-rule-prh を作成してくれています。 prh を直接使うよりも、Markdown ファイルの構文をうまく扱ってくれるみたいです（リンク内のテキストは対象外にするなど）。 インストール ルールのインストール textlint 用のルールモジュールである textlint-rule-prh は、次のようにインストールします（textlint 自体はインストール済みであるとします）。 proofread-helper を別途インストールする必要はありません。 $ npm install --save-dev textlint-rule-prh 設定ファイルの作成 proofread-helper (prh) の設定ファイル（表記揺れチェックルール）は、下記のような感じで Yaml ファイルで作成します。 rules.yml version:1rules:# 大文字小文字全角半角の統一- expected:JavaScript- expected:jQuery textlint の設定ファイルで textlint-rule-prh を有効にし、上記のルールファイルのパスを指定します。 .textlintrc { \u0026#34;rules\u0026#34;: { \u0026#34;prh\u0026#34;: { \u0026#34;rulePaths\u0026#34;: [ \u0026#34;./rules.yml\u0026#34; ] } } } 実行 あとは、textlint を実行すれば、表記揺れを検出してくれます。 $ textlint \u0026#34;content/**/*.md\u0026#34; /Users/maku/blog/content/page1.md 175:1 ✓ error jquery =\u0026gt; jQuery prh /Users/maku/blog/content/page2.md 237:1 ✓ error javascript =\u0026gt; JavaScript prh ✖ 2 problem (2 error, 0 warnings) ✓ 2 fixable problem. Try to run: $ textlint --fix [file] textlint-rule-prh は auto fix に対応しているので、 --fix オプションを指定して実行すれば、ファイル内の表記揺れを自動で修正して保存してくれます。 $ textlint --fix \u0026#34;content/**/*.md\u0026#34; 表記揺れルール proofread-helper (prh) では柔軟な表記揺れルールを定義することができます。 書き方のサンプルは 本家の記述例 を見ると分かりやすいですが、いくつかポイントをまとめておきます。 大文字と小文字の統一 rules:- expected:jQuery このように expected のみを指定しておくと、大文字・小文字の違いだけがある単語を検出してくれます（例: JQuery → jQuery）。 パターンに一致したものを修正 rules:- expected:ソフトウェアpattern:ソフトウエア pattern に一致する単語が見つかったら、それを expected に修正するよう促します。 次のように pattern に複数の単語を指定することもできます（pattern と patterns は同義）。 rules:- expected:ソフトウェアpatterns:- ソフトウエア- ソフトウエアー- ソフトウェアー pattern の部分に /正規表現/ という指定も可能です。 rules:- expected:ソフトウェアpatterns:- /ソフトウ[エ|ェ]アー/- ソフトウエア 変換のテスト仕様を記述する 正規表現でパターン指定した場合は、 specs プロパティでテストを記述しておくことよいでしょう。 設定したルールで from を to にうまく変換できない場合は、spec failed となり動作を停止します。 rules:- expected:技術書典pattern:/技術書(店|点|展|てん)/specs:- from:技術書点to:技術書典- from:技術書展to:技術書典 サフィックスを追加するときの注意 rules:- expected:サーバーpattern:/サーバ(?!ー)/specs:- from:サーバto:サーバーprh:最後に伸ばすのが最近の主流みたいです。 例えば、「サーバ」を「サーバー」にするなど、既存の単語にサフィックスを追加する場合はちょっと注意が必要です。 単純に pattern に「サーバ」と指定すると、既に「サーバー」になっているものを「サーバーー」に修正しようとしてしまうので、上記のように指定しておく必要があります。 「ユーザ」を「ユーザー」にしたいときなども同様です。 スペースが必要な単語 rules:- expected:VS Codepattern:/vs ?code/ispecs:- from:vscodeto:VS Code- from:vs codeto:VS Code- from:VS Codeto:VS Code スペースなしの VSCode を、スペースありの VS Code に修正するよう促します。 上記の正規表現だと、もともと正しい VS Code にもヒットしてしまいそうですが、その場合はうまいこと無視してくれるみたいです。 短い英単語では wordBoundary 指定しておく js や id といった、短い単語の大文字・小文字を変換するときは、次のように wordBoundary オプションを true に設定しておくのがよいようです。 こうしておくと、ある単語の部分文字列として出現したときに無視してくれるようになります。 rules:- expected:js# pattern: \u0026#34;/\\b[JjＪｊ][SsＳｓ]\\b/g\u0026#34; # と等価 \\b が前後に付与されるoptions:wordBoundary:truespecs:- from:foo JS barto:foo js bar- from:foo altJS barto:foo altJS bar# 日本語+単語境界の仕様は自分で調べてね…！- from:今日もJS祭りto:今日もjs祭り"
},
{
url: "/p/zit5eow/",
title: "こたつ布団おうちで洗ってみた",
date: "2020-06-11T00:00:00Z",
body: "こたつ布団おうちで洗ってみた 長年使い続けてたコタツ布団がなんだか臭ってきた気がするのでおうちで洗濯してみました。 洗濯機に入れるには大きすぎるので、おふろで足踏み洗い。 なんか水がすごい黒い。。。 見た目はあまり汚れてるように見えなかったんですけど、汗とかいろいろ染み込んでたんでしょうね。 洗ったあとはよくすすいで物干し竿に干したんですが、水を吸いまくっててめっちゃ重かった。。。 でもこれでスッキリです。 もし中の綿がおかしくなっちゃったら、あきらめて捨てるつもりでしたけど、なんか大丈夫っぽいです。"
},
{
url: "/p/um2wi2o/",
title: "Azure Storage のメモ",
date: "2020-06-04T00:00:00Z",
body: "Azure Storage のメモ"
},
{
url: "/p/4m96s2r/",
title: "Azure Table Stroage を使ってみる: TableService を Promise 化して使いやすくする",
date: "2020-06-04T00:00:00Z",
body: "Azure Table Stroage を使ってみる: TableService を Promise 化して使いやすくする PromiseTableService クラスの概要 Node.js から Azure Table Storage を操作する場合は、azure-storage パッケージの TableService クラス を使用するのですが、このクラスは残念ながら Promise 対応 対応されておらず、旧式のコールバック形式での呼び出しが強制されます。 下記の azure-table-promise パッケージが提供している PromiseTableService クラスを使用すると、TableService を Promise 化して使用することができます。 azure-table-promise - npm パッケージ ちなみに、下記の Issue で公式パッケージの Promise 化の議論がされているのですが、TableService クラスはいまだに対応されてませんね（2020年6月現在）。 参考: Promise support · Issue #110 · Azure/azure-storage-node こういった対応は本家の方でサクッとやってくれれば 3rd パーティライブラリの乱立が防げるんですけどね。。。 PromiseTableService を使ってみる まず必要なモジュールをインストールします。 azure-storage は本家 Microsoft の TableService クラスを使うためのモジュールで、azure-table-promise がそれを Promise ラップするためのモジュールです。 ここでは TypeScript を使うので、Node.js 型定義もインストールしておきます。 npm モジュールのインストール $ npm install --save-dev @types/node $ npm install --save azure-storage $ npm install --save azure-table-promise 次の MyTableStorage クラスは、PromiseTableService を使って TableStroage から情報を取得するサンプルです。 コンストラクタで PromiseTableService インスタンスを生成し、getRandomMessage() メソッドで、randommessage テーブルの値をランダムに取得しています。 myTableStorage.ts import * as azure from \u0026#39;azure-storage\u0026#39;; import { PromiseTableService } from \u0026#39;azure-table-promise\u0026#39;; class MyTableStorage { private tableService: azure.TableService; private promiseTableService: PromiseTableService; private static TABLE_RANDOMMESSAGE = \u0026#39;randommessage\u0026#39;; // サンプルテーブル名 constructor() { // Azure Storage の接続文字列を環境変数から取得 const connectionString = process.env.AZURE_STORAGE_CONNECTION_STRING; if (typeof connectionString === \u0026#39;undefined\u0026#39;) { console.error(\u0026#39;AZURE_STORAGE_CONNECTION_STRING is not set\u0026#39;); process.exit(1); } this.tableService = new azure.TableService(connectionString); this.promiseTableService = new PromiseTableService(this.tableService); } /** * randommessage テーブルからランダムに RowKey カラムの値を取得します。 * テーブルが空のときは空文字列を返します。 */ async getRandomMessage(): Promise\u0026lt;string\u0026gt; { try { const result = await this.promiseTableService.queryEntities\u0026lt;any\u0026gt;( MyTableStorage.TABLE_RANDOMMESSAGE, null as any, null as any); const size = result.entries.length; if (size == 0) return \u0026#39;\u0026#39;; const index = Math.floor(Math.random() * size); return result.entries[index].RowKey._; } catch (err) { console.error(err); throw new Error( \u0026#39;queryEntities failed - \u0026#39; + MyTableStorage.TABLE_RANDOMMESSAGE); } } } PromiseTableService が提供するメソッド名は、TableService が提供するメソッド名と同じになっているので、直感的に Promise バージョンのメソッドを使用することができます。 上記の例では、TableService.queryEntities() の代わりに PromiseTableService.queryEntities() を使用しています。 違いは、最後のパラメーターでコールバック関数を渡すのではなく、戻り値で Promise オブジェクトを受け取るという点です。 ECMAScript 2017 の async/await キーワードを使えば、上記のように同期呼び出しを行えるため、処理の流れが分かりやすくなります。 上記の MyTableStorage の使い方はこんな感じです。 async function main() { const table = new MyTableStorage() try { const message = await table.getRandomMessage() console.log(message); } catch (err) { console.error(err); } } main(); ちなみに、PromiseTableService は独自の拡張として queryEntitiesAll というメソッドも用意していて、これを使うと 1000 レコードの壁を越えて一度に大量の結果を取得することができます（通常は continuation token を使って、繰り返し queryEntities を呼び出す必要があります）。"
},
{
url: "/p/k8kw8it/",
title: "TypeScript: 2つの変数の値をスワップする",
date: "2020-06-03T00:00:00Z",
body: "TypeScript: 2つの変数の値をスワップする TypeScript 独自の構文ではありませんが、ECMAScript 2015 (ES6) で導入された 分割代入 (Destructuring assignment) 構文 を使用すると、2 つ以上の変数を簡単に入れ替えることができます。 let a = 1; let b = 2; [a, b] = [b, a]; 参考: 配列の分割代入で複数の値を同時に代入する (Array destructuring) ｜ まくまくJavaScriptノート"
},
{
url: "/p/epm9ipy/",
title: "npm run スクリプト実行時の ERR! 出力を抑制する (npm run --silent)",
date: "2020-05-21T00:00:00Z",
body: "npm run スクリプト実行時の ERR! 出力を抑制する (npm run --silent) npm run コマンドを使うと、package.json に定義されているスクリプトを実行することができるのですが、そこで実行したコマンドがエラー終了（exit 1 など）すると、npm run の実行自体もエラー扱いとなり、下記のようにエラー情報がたくさん出力されます。 $ npm run test \u0026gt; myapp@1.0.0 test C:\\myapp \u0026gt; echo \u0026#34;Error: no test specified\u0026#34; \u0026amp;\u0026amp; exit 1 \u0026#34;Error: no test specified\u0026#34; npm ERR! code ELIFECYCLE npm ERR! errno 1 npm ERR! myapp@1.0.0 test: `echo \u0026#34;Error: no test specified\u0026#34; \u0026amp;\u0026amp; exit 1` npm ERR! Exit status 1 npm ERR! npm ERR! Failed at the myapp@1.0.0 test script. npm ERR! This is probably not a problem with npm. There is likely additional logging output above. npm WARN Local package.json exists, but node_modules missing, did you mean to install? npm ERR! A complete log of this run can be found in: npm ERR! C:\\Users\\maku\\AppData\\Roaming\\npm-cache\\_logs\\2020-05-21T09_29_36_426Z-debug.log この npm ERR! という出力を抑制するには、次のように --silent オプションを使用します。 $ npm run --silent test \u0026#34;Error: no test specified\u0026#34; ちなみに、上記で使っている test スクリプトは、npm init で package.json を新規作成したときにデフォルトで作成されるスクリプトです。 npm init で作られる package.json の抜粋 { // ... \u0026#34;scripts\u0026#34;: { \u0026#34;test\u0026#34;: \u0026#34;echo \\\u0026#34;Error: no test specified\\\u0026#34; \u0026amp;\u0026amp; exit 1\u0026#34; }, // ... }"
},
{
url: "/p/nuvbg6k/",
title: "npm でインストール済みのモジュールを簡潔にリスト表示する",
date: "2020-05-21T00:00:00Z",
body: "npm でインストール済みのモジュールを簡潔にリスト表示する npm list (ls) コマンドは NPM (Node Package Manager) でインストールしたパッケージの一覧を表示するコマンドですが、デフォルトでは依存モジュールをすべてツリー構造で表示するので、出力が大量になります。 インストールパッケージの一覧を表示 $ npm ls myapp@1.0.0 D:\\y\\gitwork\\myapp +-- textlint@11.6.3 | +-- @textlint/ast-node-types@4.2.5 | +-- @textlint/ast-traverse@2.1.7 | | `-- @textlint/ast-node-types@4.2.5 deduped | +-- @textlint/feature-flag@3.1.6 | | `-- map-like@2.0.0 deduped | +-- @textlint/fixer-formatter@3.1.13 | | +-- @textlint/module-interop@1.0.2 deduped | | +-- @textlint/types@1.3.1 deduped ... なが～い出力 ... 次のように --depth オプションを付けると、トップレベルのモジュール名だけを簡潔に表示することができます。 $ npm ls --depth=0 myapp@1.0.0 D:\\y\\gitwork\\myapp +-- textlint@11.6.3 +-- textlint-rule-preset-ja-technical-writing@3.1.3 `-- textlint-rule-web-plus-db@1.1.5 グローバルにインストールしたモジュールを表示するときも同様です。 $ npm ls -g --depth=0"
},
{
url: "/p/d6n3hwb/",
title: "見やすいグラフを小さなスペースに描く方法",
date: "2020-05-15T00:00:00Z",
body: "見やすいグラフを小さなスペースに描く方法 The Economist さんの描くチャートって何かとっても見やすいです。 こんな感じのとか。 昔から The Economist のチャートの見せ方には定評があり、小さいスペースでもわかりやすいチャートにするために、いろいろな工夫がされているようです。 What software package does The Economist group use to create charts and graphs for the magazine? - Quora 簡単にまとめるとこんな感じでしょうか。 短い キャッチーなタイトル （具体的なタイトルはサブタイトルとして記述） データラベルは線のすぐ近く に記述する（凡例ボックスはスペースを食う） 水平ラインは薄く入れ、 垂直ラインは入れない （右端の垂直ラインも入れない） グラフ内に 軸の単位を記述しない （サブタイトルで示せばよい） 軸のラベル名は 最初の値以外は省略名 で記述（例: 2011 → 12 → 13） 色数は少なく （基本は青系ラインのみ、メイン以外は薄く、必要があれば赤系も） 煩雑なブランドロゴを毎回貼らない（The Economist は代わりに赤い矩形でアピール） 次のような入り組んだラインチャートも、部分的にサブチャート化するとか、とても参考になる描き方がされています。 色使いなども、目立たせる部分だけ濃くするなど工夫されてます。 原色の赤を使うのは、本当に目立たせるところだけ。 仕事の資料だけでなく、Web サイトに載せるチャートをシンプルにきれいに描くときの参考になりそうです。"
},
{
url: "/p/jbs8o3h/",
title: "ISO 639-2 (alpha-3) 言語コードから Java の Locale オブジェクトを生成する",
date: "2020-05-13T00:00:00Z",
body: "ISO 639-2 (alpha-3) 言語コードから Java の Locale オブジェクトを生成する Locale クラスは ISO 639-2（3桁）の言語コードを受け付けるのか？ ISO 639-2 (alpha-3) では、言語を 3 桁のアルファベットで識別できるよう定義しています（例: 日本語は jpn）。 この言語識別子を使って、Java の Locale オブジェクトを生成できるのでしょうか？ Java の Locale クラス の説明には、次のように記載されています。 言語に alpha-2 コードと alpha-3 コードの両方がある場合は、alpha-2 コードを使用する必要があります。 また、Locale クラスのコンストラクタ の第 1 引数の説明には、次のように書かれています。 language - ISO 639 alpha-2 または alpha-3 言語コード、または最高 8 文字の言語のサブタグ。 実際に試してみると、alpha-2 コード（2桁）はほぼすべて対応しているのに対し、alpha-3 コード（3桁）は対応がいまいちのようです。 sample.kt fun main() { // alpha-2 で指定 println(Locale(\u0026#34;ja\u0026#34;).displayLanguage) // 日本語 (OK) println(Locale(\u0026#34;en\u0026#34;).displayLanguage) // 英語 (OK) println(Locale(\u0026#34;fr\u0026#34;).displayLanguage) // フランス語 (OK) println(Locale(\u0026#34;zh\u0026#34;).displayLanguage) // 中国語 (OK) // alpha-3 で指定 println(Locale(\u0026#34;jpn\u0026#34;).displayLanguage) // 日本語 (OK) println(Locale(\u0026#34;eng\u0026#34;).displayLanguage) // 英語 (OK) println(Locale(\u0026#34;fra\u0026#34;).displayLanguage) // fra (NG) println(Locale(\u0026#34;zho\u0026#34;).displayLanguage) // zho (NG) } Locale クラスが認識できる alpha-2 コードの一覧は、Locale.getISOLanguages() で取得できます。 一方、認識できる alpha-3 コードの一覧を取得するメソッドは存在しませんが、上記の結果をみる限り、フランス語を表す fra と中国語を表す zho という言語コードからは、Locale クラスは言語情報をうまく生成してくれません。 何とも使いにくいですね。 alpha-2 コード（2桁）で正しい言語情報を持つ Locale オブジェクトを生成できるのであれば、そのオブジェクトから getISO3Language() で alpha-3 コード（3桁）を取得することができます。 つまり、fr に対応するコードが fra であることは判別できます。 この情報を使って、うまく逆変換するテーブルを作れば、alpha-3 コードからももう少しロバストに Locale オブジェクトを生成できるようになりそうです。 ISO 639-2（3桁）の言語コードから Locale オブジェクトを生成するユーティリティ 下記の LanguageLocales クラスは、ISO 639-1（2桁）や ISO 639-2（3桁）の言語コードから Locale オブジェクトを取得するためのユーティリティクラスです。 LanguageLocales.kt /** * Language utility for obtaining the Locale object corresponding * to the given ISO 639-1/2 language code such as \u0026#34;fra\u0026#34;. * * ``` * val locale = LanguageLocales[\u0026#34;fra\u0026#34;] * ``` */ class LanguageLocales { companion object { /** Map of ISO 639-1/2 code to Locale */ private val localeMap = mutableMapOf\u0026lt;String, Locale\u0026gt;() init { // ISO 639 の言語識別子（2桁）リストを利用してマップを作成します val alpha2s: Array\u0026lt;String\u0026gt; = Locale.getISOLanguages(); for (code in alpha2s) { val loc = Locale(code) localeMap[code] = loc // from Alpha2 localeMap[loc.getISO3Language()] = loc // from Alpha3 } } /** ISO 639 の言語コード（2桁/3桁）から Locale オブジェクトを取得します. */ operator fun get(alpha2or3: String): Locale { var loc: Locale? = localeMap[alpha2or3] if (loc == null) { loc = Locale(alpha2or3) localeMap[alpha2or3] = loc } return loc } } } Locale オブジェクトの第 1 引数に言語コードを渡してオブジェクト生成するより、LanguageLocales クラスを使って Locale オブジェクトを取得した方が、正しい言語情報を取得できる可能性が上がります。 main.kt fun main() { // alpha-2 で指定 println(LanguageLocales[\u0026#34;ja\u0026#34;].displayLanguage) // 日本語 (OK) println(LanguageLocales[\u0026#34;en\u0026#34;].displayLanguage) // 英語 (OK) println(LanguageLocales[\u0026#34;fr\u0026#34;].displayLanguage) // フランス語 (OK) println(LanguageLocales[\u0026#34;zh\u0026#34;].displayLanguage) // 中国語 (OK) // alpha-3 で指定 println(LanguageLocales[\u0026#34;jpn\u0026#34;].displayLanguage) // 日本語 (OK) println(LanguageLocales[\u0026#34;eng\u0026#34;].displayLanguage) // 英語 (OK) println(LanguageLocales[\u0026#34;fra\u0026#34;].displayLanguage) // フランス語 (OK) println(LanguageLocales[\u0026#34;zho\u0026#34;].displayLanguage) // 中国語 (OK) } もちろん、すべての ISO 639-2 (alpha-3) コードに対応しているわけではないので、その点は注意してください。"
},
{
url: "/p/7zhxet9/",
title: "Java のメモ",
date: "2020-05-13T00:00:00Z",
body: "Java のメモ"
},
{
url: "/p/5weufam/",
title: "Java/Kotlin で ISO 3166 国コードの一覧を取得する",
date: "2020-05-11T00:00:00Z",
body: "Java/Kotlin で ISO 3166 国コードの一覧を取得する Locale クラスで国コードのリストを取得する Locale クラスの getISOCountries() メソッド を使用すると、ISO 3166 で定義されている国コードの一覧を取得することができます。 String[] Locale.getISOCountries() ISO3166-1 alpha-2（2桁のアルファベット） Set\u0026lt;String\u0026gt; Locale.getISOCountries(Locale.IsoCountryCode.PART1_ALPHA2) ISO3166-1 alpha-2（2桁のアルファベット） Set\u0026lt;String\u0026gt; Locale.getISOCountries(Locale.IsoCountryCode.PART1_ALPHA3) ISO3166-1 alpha-3（3桁のアルファベット） Set\u0026lt;String\u0026gt; Locale.getISOCountries(Locale.IsoCountryCode.PART3) ISO3166-3（4桁のアルファベット） サンプルコード 次の Kotlin コードでは、Locale.getISOCountries() で ISO3166-1 alpha-2 の国コードをすべて取得し、それぞれについて、2桁の国コード、3桁の国コード、国名を表示しています。 Try Kotlin のサイトにコピペして実行できます。 import java.util.Locale fun main() { for (alpha2 in Locale.getISOCountries()) { val loc = Locale(\u0026#34;dummylang\u0026#34;, alpha2) val alpha3 = loc.getISO3Country() val name = loc.getDisplayCountry() println(\u0026#34;$alpha2$alpha3$name\u0026#34;) } } 実行結果 AD AND Andorra AE ARE United Arab Emirates AF AFG Afghanistan AG ATG Antigua and Barbuda AI AIA Anguilla AL ALB Albania ... 省略 ... WS WSM Samoa YE YEM Yemen YT MYT Mayotte ZA ZAF South Africa ZM ZMB Zambia ZW ZWE Zimbabwe 実行結果 (countires.txt) 参考リンク 国コードや言語コードのまとめ (ISO 3166, ISO 639) Java/Kotlin で ISO 639 言語コードの一覧を取得する"
},
{
url: "/p/wjxanza/",
title: "Java/Kotlin で ISO 639 言語コードの一覧を取得する",
date: "2020-05-11T00:00:00Z",
body: "Java/Kotlin で ISO 639 言語コードの一覧を取得する Locale クラスで言語識別子のリストを取得する Locale クラスの getISOLanguages() メソッド を使用すると、ISO 639-1 alpha2 で定義されている 2 桁の言語識別子の一覧を取得することができます。 String[] Locale.getISOLanguages() サンプルコード 次の Kotlin コードでは、Locale.getISOLanguages() で ISO 639-1 alpha-2 の言語識別子をすべて取得し、それぞれについて、2桁の言語識別子、3桁の言語識別子 (ISO 639-2/T)、言語名を表示しています。 Try Kotlin のサイトにコピペして実行できます。 langcodes.kt import java.util.Locale fun main() { for (alpha2 in Locale.getISOLanguages()) { val loc = Locale(alpha2) val alpha3 = loc.getISO3Language() val name = loc.getDisplayLanguage() println(\u0026#34;$alpha2$alpha3$name\u0026#34;) } } 実行結果 aa aar Afar ab abk Abkhazian ae ave Avestan af afr Afrikaans ak aka Akan am amh Amharic ... 省略 ... xh xho Xhosa yi yid Yiddish yo yor Yoruba za zha Zhuang zh zho Chinese zu zul Zulu 実行結果 (langcodes.txt) おまけ いろんな言語名をいろんな Locale 設定で出力してみるサンプルコードです。 HTML の表として出力しています。 languages.kt import java.util.Locale // 表示する言語名のリスト（戻り値は便宜上 Locale 型） fun getLanguageLocales(): List\u0026lt;Locale\u0026gt; { // ここでは ISO 639 の 言語識別子（2桁）のリストを使うことにする val languages: Array\u0026lt;String\u0026gt; = Locale.getISOLanguages(); val locales = mutableListOf\u0026lt;Locale\u0026gt;() languages.forEach { locales.add(Locale(it)) } return locales } // 表示用のロケールリスト fun getDisplayLocales(): List\u0026lt;Locale\u0026gt; { return mutableListOf\u0026lt;Locale\u0026gt;().apply { add(Locale(\u0026#34;en\u0026#34;, \u0026#34;US\u0026#34;)) add(Locale(\u0026#34;ja\u0026#34;, \u0026#34;JP\u0026#34;)) add(Locale(\u0026#34;es\u0026#34;, \u0026#34;ES\u0026#34;)) add(Locale(\u0026#34;zh\u0026#34;, \u0026#34;CN\u0026#34;)) } // システムがサポートする全ロケールを返す場合 // return Locale.getAvailableLocales() } fun main() { val dispLocales: List\u0026lt;Locale\u0026gt; = getDisplayLocales() val langLocales: List\u0026lt;Locale\u0026gt; = getLanguageLocales() println(\u0026#34;\u0026#34;\u0026#34; \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;ja\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;style\u0026gt; table { border-collapse: collapse; } th { color: #555; background: #ccc; white-space: nowrap; } th, td { padding: 0.3em 0.6em; border: solid 1px #999; } tr:nth-child(odd) { background-color: #fcfcfc; } tr:nth-child(even) { background-color: #eeeeee; } \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;table style=\u0026#34;border: solid 1px;\u0026#34;\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;th\u0026gt;Locale\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;ISO 639-1\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;ISO 639-2/T\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;Display Language Name\u0026lt;/th\u0026gt; \u0026lt;/tr\u0026gt; \u0026#34;\u0026#34;\u0026#34;.trimIndent()) for (disp: Locale in dispLocales) { for (lang: Locale in langLocales) { println(\u0026#34;\u0026lt;tr\u0026gt;\u0026lt;td\u0026gt;%s\u0026lt;/td\u0026gt;\u0026lt;td\u0026gt;%s\u0026lt;/td\u0026gt;\u0026lt;td\u0026gt;%s\u0026lt;/td\u0026gt;\u0026lt;td\u0026gt;%s\u0026lt;/td\u0026gt;\u0026lt;/tr\u0026gt;\u0026#34;.format( disp.toString(), lang.getLanguage(), lang.getISO3Language(), lang.getDisplayLanguage(disp))) } } println(\u0026#34;\u0026lt;/table\u0026gt;\u0026lt;/body\u0026gt;\u0026lt;/html\u0026gt;\u0026#34;) } 実行結果は長いので HTML ファイルとして添付しておきます。 実行結果 (languages.html) 参考リンク 国コードや言語コードのまとめ (ISO 3166, ISO 639) Java/Kotlin で ISO3166 国コードの一覧を取得する"
},
{
url: "/p/ibs96hs/",
title: "フォント/文字コード/Locale/Unicode のメモ",
date: "2020-05-11T00:00:00Z",
body: "フォント/文字コード/Locale/Unicode のメモ"
},
{
url: "/p/tfs5gr3/",
title: "国コードや言語コードのまとめ (ISO 3166, ISO 639)",
date: "2020-05-11T00:00:00Z",
body: "国コードや言語コードのまとめ (ISO 3166, ISO 639) 国コード ISO 3166-1 (country codes) ISO 3166-1 は、国を示すコードとして、短いアルファベットや数値を割り当てています。 日本では JIS X 0304 として標準化されています。 ISO 3166-1 alpha-2 : ラテン大文字 2 桁で国を表す（例: JP、US） ISO 3166-1 alpha-3 : ラテン大文字 3 桁で国を表す（例: JPN、USA） ISO 3166-1 numeric : 数字 3 桁で国を表す（例: 392、840） 下記は、これらの国コードの例です（ISO - Country Codes Collection より）。 Short name Alpha-2 code Alpha-3 code Numeric code JAPAN JP JPN 392 UNITED STATES OF AMERICA US USA 840 UNITED KINGDOM OF GREAT BRITAIN AND NORTHERN IRELAND GB GBR 826 CHINA CN CHN 156 ISO 3166-2 (country subdivision code) ISO 3166-2 では、国より細かい行政区画名（県や州）のコードを定義しています。 日本の北海道: JP-01 アメリカ合衆国のニューヨーク州: US-NY イギリスのウェスト・バークシャー: GB-WBK 中華人民共和国の広東省: CN-GD プログラムから国コードを扱う 参考リンク Java/Kotlin で ISO3166 国コードの一覧を取得する 言語コード ISO 639-1 / 639-2 の概要 ISO 639 では短いアルファベットで言語識別子を定義しています。 ISO 639-1 alpha-2 : ラテン小文字 2 桁で言語を表す（例: ja、en, zh） ISO 639-2 alpha-3 : ラテン小文字 3 桁で言語を表す（例: jpn、eng, zho） ISO 639-1:2002 の 2 桁の言語識別子では 200 言語くらいが定義されていますが、ここに収まりきらない言語に対応するため、3 桁で構成される ISO 639-2:1998 が制定されました（550 言語くらい定義されています）。 現在ではさらに拡張され、ISO 639-1 から ISO 639-6 までの 6 部門が定義されています。 下記は ISO 639-1、ISO 639-2 の言語識別子の例です。 Language name ISO 639-1 ISO 639-2 Japanese ja jpn English en eng Chinese zh zho (T) / chi (B) French fr fra (T) / fre (B) German de deu (T) / ger (B) ISO 639-2 の 3 桁コードは、639-2/T:用語学用と、B:書誌用に分かれているものもあります。 ISO 639-1 / 639-2 言語識別子の一覧 下記のサイトで、ISO 639-1、ISO 639-2(T/B) の一覧データ (CSV/JSON) をダウンロードすることができます。 ISO Language Codes (639-1 and 693-2) and IETF Language Types - Dataset - DataHub - Frictionless Data 例えば、CSV ファイルの内容は次のような感じになっています。 言語名は英語とフランス語のデータしか含まれていませんが、言語識別子の一覧が欲しい場合は便利です。 現状 488 行あるので、487 言語が登録されているようです（1 行目はヘッダー）。 language-codes-full_csv.csv alpha3-b,alpha3-t,alpha2,English,French aar,,aa,Afar,afar abk,,ab,Abkhazian,abkhaze ace,,,Achinese,aceh ...省略... fon,,,Fon,fon fre,fra,fr,French,français frm,,,\u0026#34;French, Middle (ca.1400-1600)\u0026#34;,français moyen (1400-1600) ...省略... 下記のサイトでは、言語識別子や言語名から ISO 639 の定義を検索して確認することができます。 SIL - ISO 639 Code Tables 参考リンク Java/Kotlin で ISO 639 言語コードの一覧を取得する"
},
{
url: "/p/xb5w4in/",
title: "デザインパターン/UMLのメモ",
date: "2020-05-08T00:00:00Z",
body: "デザインパターン/UMLのメモ"
},
{
url: "/p/7b9432m/",
title: "TypeScriptの環境/設定: 厳格な型チェックを有効にする (strict)",
date: "2020-05-08T00:00:00Z",
body: "TypeScriptの環境/設定: 厳格な型チェックを有効にする (strict) 厳格モードに関するオプション TypeScript の設定ファイル (tsconfig.json) には、厳格な型チェックを有効にするための strict オプションが用意されています。 プロパティ名 デフォルト値 説明 strict false Enable all strict type checking options. コンパイル時の様々な厳格な型チェック機能を有効にします。 tsconfig.json の記述例 { \u0026#34;include\u0026#34;: [ \u0026#34;src/**/*\u0026#34; ], \u0026#34;compilerOptions\u0026#34;: { \u0026#34;target\u0026#34;: \u0026#34;ES2015\u0026#34;, \u0026#34;module\u0026#34;: \u0026#34;commonjs\u0026#34;, \u0026#34;allowJs\u0026#34;: true, \u0026#34;outDir\u0026#34;: \u0026#34;./build\u0026#34;, \u0026#34;strict\u0026#34;: true /* Enable all strict type-checking options. */ } } 上記の例では、tsconfig.json で strict オプションを有効にしていますが、tsc コマンドのオプションで --strict と直接指定する方法もあります。 $ tsc --strict 実は、strict オプションは、下記のようなオプション群をまとめて true にするためのオプションです。 プロパティ名 デフォルト値 説明 noImplicitAny false Raise error on expressions and declarations with an implied any type. noImplicitThis false Raise error on this expressions with an implied any type. alwaysStrict false Parse in strict mode and emit \u0026ldquo;use strict\u0026rdquo; for each source file. strictBindCallApply false Enable strict bind, call, and apply methods on functions. strictNullChecks false Enable strict null checks. strictFunctionTypes false Enable strict checking of function types. strictPropertyInitialization false Enable strict checking of property initialization in classes. TypeScript 3.8 時点では、strict オプションを有効にすることで、これらのオプション群がまとめて有効化されますが、将来の TypeScript (tsc) バージョンでは、これらのオプション群は、そのとき推奨される組み合わせに変更されるとされています。 つまり、strict オプションを有効にしておくと、TypeScript のバージョンを上げたときに、新しいエラーが表示されるようになる可能性があります。 いずれにしても、 strict オプションは常に有効にして tsc ビルドする ことで、TypeScript コードの型安全性を高めておくことをお勧めします。 少しずつ strict 対応していく方法 strict オプションはデフォルトでは false になっているため、 プロジェクトが巨大化してから strict オプションを有効化すると、大量のエラーが表示される可能性 があります。 大量のエラーを一気に直さないといけないので大変です。 そのような場合は、下記のように、個別の strict 系オプションを 1 つずつ有効にして対応していきましょう。 tsconfig.json（抜粋） { \u0026#34;compilerOptions\u0026#34;: { /* 簡単に対応できそうなところから有効化していく */ \u0026#34;noImplicitAny\u0026#34;: false, \u0026#34;noImplicitThis\u0026#34;: true, \u0026#34;alwaysStrict\u0026#34;: true, \u0026#34;strictBindCallApply\u0026#34;: true, \u0026#34;strictNullChecks\u0026#34;: false, \u0026#34;strictFunctionTypes\u0026#34;: false, \u0026#34;strictPropertyInitialization\u0026#34;: false } } JavaScript から乗り換えたコードの場合、下記のような noImplicitAny によるエラーがたくさん出ると思います。 これは、関数のパラメータの型指定が足りないというエラーですが、これを一気に対応するのは大変なので後回しにするのがよいかもしれません。 noImplicitAny によるエラーの例 src/main.ts:27:56 - error TS7006: Parameter \u0026#39;res\u0026#39; implicitly has an \u0026#39;any\u0026#39; type. 次のように、strict オプションで全ての型チェックをまとめて有効化しておいて、個々の警告を無効にするという指定もできます。 tsconfig.json（抜粋） { \u0026#34;compilerOptions\u0026#34;: { /* ... */ \u0026#34;strict\u0026#34;: true, /* 全ての型チェックを有効化 */ \u0026#34;noImplicitAny\u0026#34;: false /* 個別に無効化 */ } } 個別の strict 系オプションをすべて true にして状態で警告が出なくなったら、下記のように書き換えて strict 対応完了です。 tsconfig.json（抜粋） { \u0026#34;compilerOptions\u0026#34;: { /* ... */ \u0026#34;strict\u0026#34;: true } } こっそり少しずつ strict 対応する方法 strict オプションによる型チェックでエラーが発生すると、デフォルトでは JavaScript (.js) ファイルの出力が停止されるので、設定ファイル (tsconfig.json) で strict オプションを有効化するのは厳しいということがあるかもしれません。 そのような場合は、次のように tsc コマンドの --strict オプションで、一時的に厳格な型チェックを有効化することができます。 $ tsc --strict これでエラーを確認しながら少しずつ TypeScript コードを修正していき、エラーがなくなった時点で tsconfig.json の strict オプションを有効化するというのがよいでしょう。 ちなみに、型チェックなどでエラーが発生しても JavaScript (.js) ファイルの出力を停止しないというオプション (--noEmitOnError false) がありますが、ちょっと危険な香りがするのであまり使わない方がよいと思います。"
},
{
url: "/p/sorrvcb/",
title: "WSL (Windows Subsystem for Linux) をインストールする",
date: "2020-04-15T00:00:00Z",
body: "WSL (Windows Subsystem for Linux) をインストールする WSL 本体のインストール まず、コントロールパネルから Windows の機能の有効化または無効化 を起動し、Windows Subsystem for Linux にチェックを入れて WSL 本体をインストールします。 Linux ディストリビューションのインストール Microsoft ストアからのインストール WSL 本体のインストールができたら、 Microsoft ストア から Ubuntu や Debian などのディストリビューションをインストールします。 ここでは、Ubuntu よりもサイズの小さい、Debian GNU Linux をインストールしてみました（Debian も apt で各種コマンドを追加インストールしていくことができます）。 インストールが完了すると、Windows メニューから Debian などのターミナルを起動できるようになります。 マニュアルインストール 会社の PC などで、Windows ストアの利用が制限されている場合は、下記サイトからディストリビューションをダウンロードして手動インストールすることができます。 Linux 用 Windows サブシステム (WSL) ディストリビューションを手動でダウンロードする | Microsoft Docs"
},
{
url: "/p/92jyhx7/",
title: "Teams や Slack で PC 画面の一部のキャプチャ画像を簡単に共有する方法",
date: "2020-04-10T00:00:00Z",
body: "Teams や Slack で PC 画面の一部のキャプチャ画像を簡単に共有する方法 コロナウィルスの影響でテレワークする人が急増し、コミュニケーションツールとして多くの人が Microsoft Teams や Slack を利用するようになってきています。 Teams のチャットで、何かの説明の際に、 自分のデスクトップ画面の一部をキャプチャして共有したい ことがあると思います。 そんなときは、下記のようにすると一瞬で部分的なキャプチャを共有できます。 Windows 10 の場合 Windows + Shift + S で画面の一部分を矩形選択 そのまま Teams や Slack のメッセージ欄で Ctrl + V で貼り付け macOS の場合 Cmd + Ctrl + Shift + 4 で画面の一部分を矩形選択 そのまま Teams や Slack のメッセージ欄で Ctrl + V で貼り付け 上記のようなショートカットキーを使用すると、選択範囲のイメージを直接クリップボードに格納してくれるので、わざわざ画像ファイルに保存したりする必要がなくなります。 慣れると、画面キャプチャをバンバン共有できるようになって、ものすごく意思疎通が捗ります。"
},
{
url: "/p/tsjyzrn/",
title: "雑多",
date: "2020-04-10T00:00:00Z",
body: "雑多"
},
{
url: "/p/3u2m6an/",
title: "Azure AppServices のメモ",
date: "2020-03-25T00:00:00Z",
body: "Azure AppServices のメモ"
},
{
url: "/p/sj2gu9n/",
title: "読書メモ『WORK SHIFT ワークシフト』リンダ・グラットン",
date: "2020-03-22T00:00:00Z",
body: "読書メモ『WORK SHIFT ワークシフト』リンダ・グラットン ワーク・シフト ― 孤独と貧困から自由になる働き方の未来図〈2025〉 リンダ・グラットン プレジデント社 朝 7 時に人工知能エージェントが立ち上がり、壁に 300 件のメールが映し出される。。。 ようこそ！いつも仕事に追われ続ける未来へ！ 『WORK SHIFT』は、『LIFE SHIFT』 でも有名なリンダ・グラットンさんの著書で、人生 100 年時代の働き方改革について考えている人にとってバイブルとされている本です。 私にとっても、これから 何に重点をおいて仕事と向き合っていくべきか という考え方に、少なからず影響を与えてくれた本です。 中でも、 産業革命以前の職人仕事の時代へ回帰していく という表現にはとても共感を覚え、決して専門技術を日々追求しない管理職人間（その企業でしか通用しない人間）にはならないぞと誓いました。 ここ数十年間の「常識的な働き方」とはどんなものでしょうか？ 朝 9 時から夕方 5 時まで勤務する 月曜から金曜日まで働いて週末に休む 学校を卒業してから引退するまで 1 つの会社で働きあげる 親や兄弟と同じ国で暮らす いつも同じ顔ぶれの同僚と仕事をする おそらく多くの人が感じているように、こういった従来の働き方・生き方は通用しなくなりつつあります。 そのような未来において、リンダ氏は、次のような 3 つのシフト が必要だと述べています。 広く浅い知識しか持たないゼネラリストから、高度な専門技能を備えたスペシャリストへのシフト ゼネラリスト的な技能を尊ぶ常識は問い直すべきである。 孤独に競い合う生き方から、他の人と関わり協力し合う生き方へのシフト 職業生活とキャリアを成功させる土台が個人主義と競争原理であるという常識は問い直すべきである。 大量消費を志向するライフスタイルから、意義と経験を重んじるバランスの取れたライフスタイルへのシフト どういう職業人生が幸せかという常識を問い直し、消費をひたすら追求する人生から脱却し、情熱的に何かを生み出す人生に転換すべきである。 以下、上記の 3 つのシフトについてメモメモ。 第一のシフト（ゼネラリストから「連続スペシャリスト」へ） 未来の世界では、その他大勢から自分を差別化することがますます重要になる。 そのために、時間と労力を費やして専門分野の知識と技能を高めなくてはならない。 未来の世界では、広く浅い知識を持つのではなく、いくつかの専門技能を連続的に習得していかなくてはならない。 第1のシフトに必要な資質 専門技能の連続的習得 \u0026hellip; 将来ニーズが高まりそうなジャンルの高度な専門知識と技能を身につけ続ける セルフマーケティング \u0026hellip; 自分の能力を取引相手に納得させる材料を確立する 専門性の低い ゼネラリスト的なマネジメント技能（管理職）は、特定の企業以外で通用しない。大企業では、その代わりにそこで働き続けられるという暗黙の契約があったが、そうした契約は徐々に崩れ始めている。しかも専門性の低い技能は、Wikipedia や Google Analytics のようなオンラインサービスによって急速に取って代わられつつある。 長い時間をかけて築いた人脈も、昔ほどの価値を持たない。SNS を利用すれば、誰でも世界中に人的ネットワークを広げられる時代になっている。ゼネラリストからの脱却は、ある意味で産業革命以前の 職人仕事の時代への回帰 でもある。 大企業に勤めることにも利点はある、それは、見えない存在にならずにすむこと。しかしこの先、会社があなたの能力証明をしてくれることは期待しづらくなる。上司が頻繁に入れ替わり、社員だけでなく社外の人と一緒に仕事をするケースが増えることで、同僚や上司との結びつきは失われていく。 大勢のなかで自分の存在を際立たせるのに有効な3つの方法 自分の仕事に自分の刻印を押すなり、署名を書き込むなりする 弁護士や医師のような専門職にならって、ギルド（同業者組合）やそれに類する組織をつくる 様々な要素を取り込んでキャリアのモザイクを描き、いわば協会のカリヨン・ツリー型のキャリアを実践する いま必要とされているのは、昔の職人のように自分の専門分野の技術と知識を深める一方で、ほかの人たちの高度な専門技能と知識を生かすために人的ネットワークを築き上げることだ。 連続スペシャリストへの道 ある技能がほかの技能より高い価値をもつのはどういう場合なのかをよく考える 価値を生むと広く理解されていること 希少性があること（重要＞供給） 他人に模倣されにくく、機械にも代用されないこと 例: 生命科学、健康関連、再生可能エネルギー関連、創造性・イノベーション関連、コーチング・ケア関連 未来の世界で具体的にどういう技能が価値を持つかという予測を立てる 自分の好きなことを職業に選ぶ 専門技能に徹底的に磨きをかける ある分野に習熟した後も、ほかの分野に転身する覚悟を持ち続ける 第2のシフト（孤独な競争から「協力して起こすイノベーション」へ） 専門知識と技能を磨いてほかの人たちとの差別化を図る一方で、高度な専門知識と技能を持つ人たちと一緒に価値を生み出していかなくてはならない。 こうしたイノベーションは、 ポッセ（頼りになる少人数の盟友グループ） によって成し遂げられる。 温かい人間関係が当たり前のように手に入る時代が終わり、意識的に自己再生のコミュニティを築く必要が増す。この面では、テクノロジーに頼れない。 ポッセのメンバーとして認められるためには、 ほかのメンバーと同等の技能をもっている と信頼される必要がある。 ポッセを機能させるために重要な 2 つの条件 メンバーの専門分野がある程度重なり合っている お互いに信頼し合い、お互いを助けたいと思い、お互いのために時間を割くつもりがある 今後は通用しない、旧来の人脈づくり × 自分のイメージを好ましく見せようとする × 役に立ちそうな人を見つけ出し、どうにかしてお近づきになろうとする（プッシュ（押す）プロセス） ポッセを築くための、新しい人脈づくり ◯ メンバーがお互いに引きつけられ合うことによって形成される ◯ アイデアと知識を深く共有する ◯ 相手の言葉に耳を傾け、相手から学ぶ姿勢を持つ ◯ 自分と考え方が近く、力になってくれそうな人を引きつける能力がある 相互の信頼を強化するうえできわめて有効な方法の一つは、 お互いに自分のポッセのメンバーを引き合わせる こと。 ポッセのメンバーを引きつけるには、まず自分が積極的に「発信」しなくてはならない。その際、自分がなにを成し遂げただけではなく、 何に関心があり、どういう課題を抱えているかを語る こと。 古代ローマのように人間同士が触れ合いやすい環境で暮らすことがいっそう重要になる（広い歩道や広場のように、休憩し、会話を楽しめる場所、客を招待できる庭） 深い友情をはぐくみやすい仕事とは？ 自然に友達ができやすい土地で生活できる仕事 ほかの人と会話をする時間とゆとりがある仕事 金と権力を価値観の中心に据えず、バランスの取れたモチベーションと未来への希望をいだける仕事 第3のシフト（大量消費から「情熱を傾けられる経験」へ） 際限ない消費に終始する生活を脱却し、情熱をもってなにかを生み出す生活 に転換する必要がある。 所得と消費に重きを置くのではなく、情熱をいだける有意義な経験（質の高い経験）をしたいという思いに沿った働き方を選択する必要がある。 家庭や趣味、社会貢献などの面で充実した創造的経験をすることを重んじる生き方に転換するすること。 経済学の分野では「限界効用の逓減」という言葉がある（あるものを得る数や量が増えれば増えるほど、それに価値を感じなくなるという法則）。 お金と消費には限界効用逓減の法則が当てはまるが、それ以外の経験にはこの法則が当てはまらない。 高度な専門技能 を磨けば磨くほど、あるいは 友達の輪 を広げれば広げるほど、私たちが新たに得る効用が減る、などということはない。"
},
{
url: "/p/uo7n4ix/",
title: "PowerShell のメモ",
date: "2020-03-19T00:00:00Z",
body: "PowerShell のメモ"
},
{
url: "/p/jodtbr8/",
title: "PowerShell で環境変数を扱う",
date: "2020-03-19T00:00:00Z",
body: "PowerShell で環境変数を扱う 環境変数の値を参照する PowerShell スクリプトの中から環境変数の値を取得するには、$env:変数名 を参照します。 sample.ps1 echo $env:USERPROFILE 環境変数が設定されているかどうかを調べる 環境変数が定義されているかどうかを調べるには、以下のような条件分岐を使用します。 sample.ps1 if ($env:HOME -eq $null) { Write-Host \u0026#39;HOME is not set\u0026#39; } if ($env:HOME -ne $null) { Write-Host \u0026#39;HOME is set\u0026#39; } 値が空である場合も「定義されていない」とみなしたいのであれば、IsNullOrEmpty() でチェックします。 if ([string]::IsNullOrEmpty($env:HOME)) { Write-Host \u0026#39;HOME is not set\u0026#39; exit }"
},
{
url: "/p/9a9n6se/",
title: "PowerShell: 現在の日時を ISO 8601 (YYYY-MM-DD) フォーマットで取得する (Get-Date)",
date: "2020-03-19T00:00:00Z",
body: "PowerShell: 現在の日時を ISO 8601 (YYYY-MM-DD) フォーマットで取得する (Get-Date) PowerShell の Get-Date コマンドレットを使用すると、現在の日時を表す文字列を取得することができます。 Format、UFormat パラメータで日時の書式を指定する Format Get-Date の Format パラメータを指定することで、任意の書式で日時文字列を取得することができます。 PS\u0026gt; Get-Date -Format \u0026#34;yyyy-MM-dd HH:mm:ss\u0026#34; 2020-03-19 15:23:09 PS\u0026gt; Get-Date -Format \u0026#34;yyyy-MM-ddTHH:mm:ssK\u0026#34; # ISO 8601 2020-03-19T15:23:09+09:00 UFormat UFormat パラメータを使うと、もう少しシンプルに記述できたりします（指定できる記号の一覧はこちら）。 PS\u0026gt; Get-Date -UFormat \u0026#34;%F %T\u0026#34; 2020-03-19 15:26:42 PS\u0026gt; Get-Date -UFormat \u0026#34;%Y-%m-%d %H:%M:%S\u0026#34; # 同上 2020-03-19 15:26:42 PS\u0026gt; Get-Date -UFormat \u0026#34;%FT%T%Z\u0026#34; # ISO 8601 2020-03-19T15:26:42+09 DateTime オブジェクトの ToString メソッドを使用する Get-Date で先に DateTime オブジェクトを取得しておいて、ToString 関数で日時を表す文字列に変換するという方法もあります。 PS\u0026gt; (Get-Date).ToString(\u0026#34;yyyy-MM-dd HH:mm:ss\u0026#34;) 2020-03-19 15:11:37 この方法を使うと、DateTime オブジェクトで日時データを編集してから文字列に変換することができます。 例えば、次の例では、現在から 10 日後の日時を取得しています。 PS\u0026gt; (Get-Date).AddDays(10).ToString(\u0026#34;yyyy-MM-dd HH:mm:ss\u0026#34;) 2020-03-29 15:11:37 他にも次のような感じで日時の演算を行えます。 (Get-Date).AddYears(10): 10 年後 (Get-Date).AddYears(-5): 5 年前 (Get-Date).AddMonths(10): 10 ヵ月後 (Get-Date).AddMonths(-5): 5 ヵ月前 (Get-Date).AddDays(10): 10 日後 (Get-Date).AddDays(-5): 5 日前 (Get-Date).AddHours(10): 10 時間後 (Get-Date).AddHours(-5): 5 時間前 (Get-Date).AddMinutes(10): 10 分後 (Get-Date).AddMinutes(-5): 5 分後 (Get-Date).AddMinutes(10): 10 分後 (Get-Date).AddMinutes(-5): 5 分後 UTC 時刻で表示する 世界協定時 (UTC) で日時文字列を取得したい場合は、ToString の前に ToUniversalTime() を挟みます。 PS\u0026gt; (Get-Date).AddDays(10).ToUniversalTime().ToString(\u0026#34;yyyy-MM-ddTHH:mm:ssZ\u0026#34;) 2020-03-29T06:11:37Z ローカルタイムではなく、UTC 時刻であることを明確にするために、末尾に Z を付けておきましょう（詳細は ISO 8601 で検索）。"
},
{
url: "/p/372dx46/",
title: "PowerShell: バッチファイルから PowerShell を呼び出して結果を変数に格納する",
date: "2020-03-18T00:00:00Z",
body: "PowerShell: バッチファイルから PowerShell を呼び出して結果を変数に格納する Linux や mac では、外部コマンドをバッククォート () で囲んでやるだけで実行結果を取得できますが、バッチファイルで同じようなことをするには FOR /F` コマンドを使用します。 本来は、コマンドの出力結果を一行ずつ処理するためのコマンドですが、次のようにすれば、コマンドの実行結果を一行だけ変数に格納できます。 FOR /F \u0026#34;usebackq delims=\u0026#34; %%A IN (`外部コマンド`) DO set 変数名=%%A FOR ループのパラメータの意味 /F: コマンドの出力結果をループ処理する usebackq: バッククォートで囲まれた文字列全体を外部コマンドとみなす delims=: コマンド実行結果にスペースが含まれていても分割せずに取得（ここではデリミタ文字をなくしている） 上記の 外部コマンド のところで、powershell コマンドを実行すれば、PowerShell で実行した結果をバッチファイル内の変数で受け取ることができます。 例えば、次のバッチファイル (next-month.bat) では、1か月後の日時を PowerShell で求めて、その結果をバッチファイル内の next_month 変数に取得しています。 next-month.bat @echo off setlocal FOR /F \u0026#34;usebackq delims=\u0026#34; %%A IN (`powershell \u0026#34;(Get-Date).AddMonths(1).ToString(\u0026#39;yyyy-MM-dd\u0026#39;)\u0026#34;`) DO set next_month=%%A echo %next_month% 次のように PowerShell で実行するコマンドを分離しておくと見やすいかもしれません。 ps_command 変数の内容を置き換えるだけで、別のコマンドに対応できます。 set ps_command=`powershell \u0026#34;(Get-Date).AddMonths(1).ToString(\u0026#39;yyyy-MM-dd\u0026#39;)\u0026#34;` FOR /F \u0026#34;usebackq delims=\u0026#34; %%A IN (%ps_command%) DO set result=%%A echo %result% 実行結果 C:\\\u0026gt; next-month 2020-04-19"
},
{
url: "/p/d8apqgw/",
title: "LUIS のメモ",
date: "2020-03-17T00:00:00Z",
body: "LUIS のメモ"
},
{
url: "/p/joexet9/",
title: "QnA Maker のメモ",
date: "2020-03-17T00:00:00Z",
body: "QnA Maker のメモ"
},
{
url: "/p/yya9sbm/",
title: "逆引き Azure CLI",
date: "2020-03-17T00:00:00Z",
body: "逆引き Azure CLI"
},
{
url: "/p/tb6s2ck/",
title: "VS Code の Vim プラグインで OS のクリップボードと同期する (vim.useSystemClipboard)",
date: "2020-03-16T00:00:00Z",
body: "VS Code の Vim プラグインで OS のクリップボードと同期する (vim.useSystemClipboard) Vim エディタ使いにとって、Visual Studio Code の Vim プラグイン はほぼ必須の機能になっています。 Vim - Visual Studio Marketplace デフォルトでは、y キーによるヤンクバッファ（Vim 用語では unnamed register）のコピーが、OS のクリップボードと同期されません。 次のように Vim プラグインの設定を行っておく、OS のクリップボードと同期してくれるようになります。 settings.json で設定する方法 settings.json { \u0026#34;vim.useSystemClipboard\u0026#34;: true, // OS のクリップボードと同期 // ... } 参考: settings.json について 設定画面で設定する方法 Cmd + ,（Windows では Ctrl + ,）で設定メニューを開く Vim: Use System Clipboard の項目にチェックを入れる これで、アプリ間をまたいだコピー＆ペーストを行うことができるようになります。"
},
{
url: "/p/awakw8i/",
title: "Facebook や Twitter でシェアするときに画像や説明文が表示されるようにする (OGP: Open Graph Protocol)",
date: "2020-03-14T00:00:00Z",
body: "Facebook や Twitter でシェアするときに画像や説明文が表示されるようにする (OGP: Open Graph Protocol) OGP とは Web ページ内に、OGP: Open Graph Protocol に基づいた HTML タグを含めておくと、Facebook や Twitter などの SNS アプリで URL 共有したときに、サイト画像や説明文を表示することができます。 下記は、https://www.yahoo.co.jp/ を Facebook で共有したときの表示例です。 図: Yahoo! Japan の例 何も指定しなくても、ある程度はコンテンツから推測して表示してくれますが、想定外の画像が表示されてしまったりするので、ちゃんと指定しておいた方がよいです。 Web サイトに OGP メタ情報を付加する Open Graph タグを使ってメタ情報を付加するときは、主に次のような情報を記述します。 og:site_name : サイト名（og:title の方は個々のページの名前） og:title : ページのタイトル（サイト名は含まれないようにします） og:type : コンテンツの種類（website で OK。ブログ記事の場合は article を使うことも） og:url : ページの URL（絶対パスで指定） og:image : サムネイル画像の URL（絶対パスで指定）。さらに下記を指定することで、ページを最初にシェアするユーザーが画像を表示できるようになります。 og:image:width : サムネイル画像の幅（ピクセル値） og:image:height : サムネイル画像の高さ（ピクセル値） og:description : コンテンツの内容を示す説明文 og:locale : コンテンツのロケール（ja_JP で OK） これらのメタ情報は、HTML の meta 要素として、head 要素内に記述します。 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;ja\u0026#34;\u0026gt; \u0026lt;head prefix=\u0026#34;og: http://ogp.me/ns# fb: http://ogp.me/ns/fb#\u0026#34;\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;meta property=\u0026#34;og:site_name\u0026#34; content=\u0026#34;まくろぐ\u0026#34; /\u0026gt; \u0026lt;meta property=\u0026#34;og:title\u0026#34; content=\u0026#34;OGP とは\u0026#34; /\u0026gt; \u0026lt;meta property=\u0026#34;og:type\u0026#34; content=\u0026#34;website\u0026#34; /\u0026gt; \u0026lt;meta property=\u0026#34;og:url\u0026#34; content=\u0026#34;https://maku.blog/p/awakw8i\u0026#34; /\u0026gt; \u0026lt;meta property=\u0026#34;og:image\u0026#34; content=\u0026#34;https://maku.blog/assets/img/site-logo.png\u0026#34; /\u0026gt; \u0026lt;meta property=\u0026#34;og:image:width\u0026#34; content=\u0026#34;600\u0026#34; /\u0026gt; \u0026lt;meta property=\u0026#34;og:image:height\u0026#34; content=\u0026#34;315\u0026#34; /\u0026gt; \u0026lt;meta property=\u0026#34;og:description\u0026#34; content=\u0026#34;ウェブサイトに OGP メタ情報を付加すると、SNS でリンクを共有したときの表示をカスタマイズすることができます。\u0026#34; /\u0026gt; \u0026lt;meta property=\u0026#34;og:locale\u0026#34; content=\u0026#34;ja_JP\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;OGP とは | まくろぐ\u0026lt;/title\u0026gt; ... \u0026lt;/head\u0026gt; ... OGP メタ情報の指定方法が正しいか確認する Facebook の表示確認 Facebook が提供している「シェアデバッガー」というサイトを使うと、URL でシェアされたときにどのように見えるかを確認することができます。 使用するには、Facebook にログインする必要があります。 図: Facebook のシェアデバッガー メタ情報の指定が間違っていると、「修正が必要な問題」として指摘してくれます。 例えば、次のように指摘してくれたりします。 画像が小さすぎます 指定されたog:image URL「https://maku.blog/assets/img/site-logo.png」は最小サイズ制限(200 x 200ピクセル)を満たしていないため無効となりました。 プロパティがありません 次のプロパティは必須です: og:description, fb:app_id ☝️ ワンポイント Facebook のシェアデバッガーでは、fb:app_id が指定されていないと怒られますが、指定しなくてもシェア時の表示はちゃんとされているみたいです。 Twitter の表示確認 Twitter も同様に、「Card validator」という表示確認ツールが用意されています。 図: Twitter の Card validator Facebook の app_id を指定する Facebook での URL シェア時に Open Graph タグを使用するには、公式には、Facebook 独自のアプリ ID (fb:app_id) プロパティも指定しておかないといけないようです。 \u0026lt;meta property=\u0026#34;fb:app_id\u0026#34; content=\u0026#34;123456789012345\u0026#34; /\u0026gt; 実際にはこの記述がなくてもうまく表示できるようですが、アプリ ID を指定しておくと Facebook のいろいろな分析ツールと連携できるようになるようなので、後回しでもいいので設定しておくとよいでしょう。 アプリ ID は、以下のようにして取得することができます。 詳細は、サイトに表示される手順に従ってください。 Facebook for Developers からデベロッパーアカウントを作成する。 デベロッパーとしてログインしたら、サイト上部のメニューなどから マイアプリ → アプリを作成 を選択。 Twitter シェア時の表示をカスタマイズする meta タグで次のような記述をしておくと、Twitter での URL シェア時に、どのような形式で表示するか（カードタイプ）を指定できます。 \u0026lt;meta name=\u0026#34;twitter:card\u0026#34; content=\u0026#34;summary\u0026#34; /\u0026gt; content 属性で、次のいずれかのカードタイプを指定できます。 summary : タイトルと説明文と画像（デフォルト） summary_large_image : 同上だけど、大きめの画像（Facebook の表示に近い） app : モバイルアプリの配信用（アプリのアイコンを表示する） player : 動画や音楽などのメディア配信用 ☝️ ワンポイント Open Graph 用のメタ情報記述では property 属性を指定していましたが、Twitter 用のメタ情報記述には name 属性を指定することに注意してください。 og: プレフィックスとは異なり、twitter: プレフィックスを定義しておく必要はありません。 ページのタイトル情報などは、Facebook と共通の og: プレフィックスで指定したものを使ってくれるので、Twitter 用に別途指定する必要はありません。 その他の参考情報 Facebook - リンクシェアの画像 Facebook が推奨している画像サイズの説明があります。少なくとも 200x200 以上の画像を指定しないといけないことなどが記述されています。"
},
{
url: "/p/kevbq7k/",
title: "正規表現のメモ",
date: "2020-03-09T00:00:00Z",
body: "正規表現のメモ"
},
{
url: "/p/voanw2h/",
title: "Android開発: ダイアログ表示時の背景の暗転（ディミング）を防ぐ",
date: "2020-03-06T00:00:00Z",
body: "Android開発: ダイアログ表示時の背景の暗転（ディミング）を防ぐ Android でダイアログを表示するときに DialogFragment クラスなどを使用すると、デフォルトではダイアログの後ろは暗くなって、下の UI がうっすらと見える状態になります。 このような効果を抑制して、背景が明るいままにするには、ウィンドウから FLAG_DIM_BEHIND フラグをクリアします。 class MyDialogFragment : DialogFragment() { override fun onCreateView( inflater: LayoutInflater, container: ViewGroup?, savedInstanceState: Bundle? ): View? { // ダイアログの中身を独自レイアウトにする return inflater.inflate(R.layout.my_dialog, container, false) } override fun onViewCreated(view: View, savedInstanceState: Bundle?) { super.onViewCreated(view, savedInstanceState) disableBackgroundDimming() } /** ダイアログの背景が暗くなるのを防ぐ */ private fun disableBackgroundDimming() { dialog?.window?.clearFlags(WindowManager.LayoutParams.FLAG_DIM_BEHIND) } }"
},
{
url: "/p/g8o3gu9/",
title: "新型コロナに便乗してマスクがぼったくり価格に・・・",
date: "2020-02-29T00:00:00Z",
body: "新型コロナに便乗してマスクがぼったくり価格に・・・ マスク2万円超えはちょっと高いなぁ・・・。 こんな出品をする人もする人だけど、こーゆーのを野放しにする Amazon も企業としてのあり方が問われますね。"
},
{
url: "/p/tkwj6bw/",
title: "TypeScriptサンプル: ジェネリッククラスの定義例（MyStackクラス）",
date: "2020-02-27T00:00:00Z",
body: "TypeScriptサンプル: ジェネリッククラスの定義例（MyStackクラス） TypeScript で型パラメータを使用したジェネリッククラスの定義サンプルとして、簡単なスタッククラスの実装例です。 TypeScript の配列がスタックの代わりになるので、スタッククラスなど作る必要はありませんが、Generics の使用例ということで。 myStack.ts export class MyStack\u0026lt;T\u0026gt; { private items: T[] = []; push(item: T): void { this.items.push(item); } pop(): T | undefined { return this.items.pop(); } } 使用例 (main.ts) import { MyStack } from \u0026#39;./myStack\u0026#39;; const stack = new MyStack\u0026lt;number\u0026gt;(); stack.push(1); stack.push(2); stack.push(3); console.log(stack.pop()); //=\u0026gt; 3 console.log(stack.pop()); //=\u0026gt; 2 console.log(stack.pop()); //=\u0026gt; 1 console.log(stack.pop()); //=\u0026gt; undefined"
},
{
url: "/p/g3gs5gs/",
title: "Unity",
date: "2020-02-24T00:00:00Z",
body: "Unity"
},
{
url: "/p/m6hs3dn/",
title: "Unityスクリプト: 加速度センサー／ジャイロスコープの値を取得する",
date: "2020-02-24T00:00:00Z",
body: "Unityスクリプト: 加速度センサー／ジャイロスコープの値を取得する 加速度センサ (Input.acceleration) 加速度センサからの入力を取得するには、Input.acceleration プロパティを参照します。 Vector3 型で、X/Y/Z 軸の加速度を -1.0 〜 +1.0 の範囲で取得できます。 Vector3 accel = Input.acceleration; 次の例では、Update() のタイミングで加速度を読み取り、画面上のテキストで X, Y, Z 各軸の加速度を表示しています。 Sample.cs using UnityEngine; public class Sample : MonoBehaviour { private Vector3 m_accel; void Update() { m_accel = Input.acceleration; } private void OnGUI() { var rect = new Rect(30, 30, 500, 50); GUI.skin.label.fontSize = 30; GUI.Label(rect, string.Format(\u0026#34;X={0:F2}, Y={1:F2}, Z={2:F2}\u0026#34;, m_accel.x, m_accel.y, m_accel.z)); } } ジャイロスコープ (Input.gyro) ジャイロスコープからの入力を取得するには、Input.gyro プロパティを参照し、Gyroscope オブジェクトを取得します。 Gyroscope gyro = Input.gyro; Gyroscope の機能を使用するには、enabled プロパティを true に設定しておく必要があります。 Input.gyro.enabled = true; Gyroscope オブジェクトからは、次のような値を取得できます。 Gyroscope.attitude \u0026hellip; デバイスの傾き具合 (Quaternion) Gyroscope.rotationRate \u0026hellip; デバイスの回転率 (Vector3) attitude プロパティは、デバイスの傾きを Quaternion で取得できるので、そのままゲームオブジェクトの transform.rotation プロパティに設定してやれば、デバイスの傾きとオブジェクトの傾きを一致させることができます。 次の例では、デバイスの傾き具合と回転率を画面上に表示しています。 また、傾きに応じて、スクリプトをアタッチしたオブジェクトを回転させています。 Sample.cs using UnityEngine; public class Sample : MonoBehaviour { private Gyroscope m_gyro; private void Start() { Input.gyro.enabled = true; } void Update() { m_gyro = Input.gyro; transform.rotation = m_gyro.attitude; } private void OnGUI() { var rect1 = new Rect(30, 30, 600, 50); var rect2 = new Rect(30, 60, 600, 50); GUI.skin.label.fontSize = 30; GUI.Label(rect1, \u0026#34;attitude=\u0026#34; + m_gyro.attitude); GUI.Label(rect2, \u0026#34;rotationRate=\u0026#34; + m_gyro.rotationRate); } }"
},
{
url: "/p/oitn3a3/",
title: "Bot Framework: Web チャットの表示をカスタマイズする",
date: "2020-02-19T00:00:00Z",
body: "Bot Framework: Web チャットの表示をカスタマイズする Microsoft Bot Framework を使ってウェブサイト上にチャットボットを配置したときの表示のカスタマイズ方法です。 次のように、ボットやユーザーのアイコンを設定することができます。 このようなカスタマイズ表示を行うには、Azure portal 上の Web App Bot リソースの Channels タブから選択できる、Direct Line チャネルを使う必要があります。 Web Chat というチャネルを使うと、iframe タグで簡単にチャットウィンドウを埋め込むことができるのですが、そちらではあまりカスタマイズができないようです。 図: Direct Line チャネルのキーを確認 下記はチャットウィンドウをカスタマイズして表示するサンプルコードです。 Bot Framework が提供している WebChat.renderWebChat() 関数を呼び出すと、実際にチャットウィンドウが表示されるのですが、このときに styleOptions パラメータを指定することで表示方法をカスタマイズすることができます。 index.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;script src=\u0026#34;https://cdn.botframework.com/botframework-webchat/latest/webchat.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;style\u0026gt; * { margin: 0; } #webchat { height: 100vh; width: 100vw; background: gray; border: solid 5px #f37; box-sizing: border-box; } \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div id=\u0026#34;webchat\u0026#34; role=\u0026#34;main\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;script\u0026gt; const TOKEN = \u0026#39;HpJB2ofxzsA.h7...省略...\u0026#39;; WebChat.renderWebChat({ directLine: WebChat.createDirectLine({ token: TOKEN }), styleOptions: { // ボットのアイコン botAvatarImage: \u0026#39;/assets/img/bot-avatar.png\u0026#39;, // ボットのイニシャル（アイコンが使えない場合に表示） //botAvatarInitials: \u0026#39;Bot\u0026#39;, // ユーザーのアイコン //userAvatarImage: \u0026#39;/assets/img/user-avator.png\u0026#39;, // ユーザーのイニシャル（アイコンが使えない場合に表示） userAvatarInitials: \u0026#39;You\u0026#39;, // アイコンのサイズ avatarSize: 50, // Upload file のボタンを非表示 hideUploadButton: true, } }, document.getElementById(\u0026#39;webchat\u0026#39;)); \u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 参考リンク GitHub: microsoft/BotFramework-WebChat"
},
{
url: "/p/k43zbd8/",
title: "チャットボットの作り方",
date: "2020-02-19T00:00:00Z",
body: "チャットボットの作り方"
},
{
url: "/p/kkaq7q5/",
title: "正規表現: ひらがなとカタカナを正規表現で表す",
date: "2020-02-17T00:00:00Z",
body: "正規表現: ひらがなとカタカナを正規表現で表す ひらがな・カタカナの正規表現 ひらがなの 1 文字、カタカナの 1 文字を正規表現で表すと次のようになります。 ひらがな [\\u3041-\\u3096] [\\x{3041}-\\x{3096}] \\p{Hiragana} （Unicode 文字プロパティが使える場合） カタカナ [\\u30A1-\\u30FA] [\\x{30A1}-\\x{30FA}] \\p{Katakana} （Unicode 文字プロパティが使える場合） 参考 Wikipedia: Hiragana (Unicode block) より Wikipedia: Katakana (Unicode block) より 参考リンク TypeScriptサンプル: 文字列内のひらがなとカタカナを変換する"
},
{
url: "/p/tzjvcad/",
title: "TypeScriptサンプル: 文字列内のひらがなとカタカナを変換する (hiraToKana, kanaToHira)",
date: "2020-02-17T00:00:00Z",
body: "TypeScriptサンプル: 文字列内のひらがなとカタカナを変換する (hiraToKana, kanaToHira) util.ts export class Util { /** * 文字列に含まれているすべてのひらがなをカタカナに変換した文字列を作成します。 * ただし、半角文字は変換しません。 * @param str ひらがなを含む文字列 */ static hiraToKata(str: string): string { return str.replace(/[\\u3041-\\u3096]/g, ch =\u0026gt; String.fromCharCode(ch.charCodeAt(0) + 0x60) ); } /** * 文字列に含まれているすべてのカタカナをひらがなに変換した文字列を作成します。 * ただし、半角文字は変換しません。 * @param str カタカナを含む文字列 */ static kataToHira(str: string): string { return str.replace(/[\\u30A1-\\u30FA]/g, ch =\u0026gt; String.fromCharCode(ch.charCodeAt(0) - 0x60) ); } } 使用例 import { Util } from \u0026#39;./util\u0026#39;; console.log(Util.hiraToKata(\u0026#39;あいうアイウ\u0026#39;)); //=\u0026gt; アイウアイウ console.log(Util.kataToHira(\u0026#39;あいうアイウ\u0026#39;)); //=\u0026gt; あいうあいう 参考リンク ひらがなとカタカナを正規表現で表す"
},
{
url: "/p/bog7iq8/",
title: "Azure: デプロイスロットでリリース時のダウンタイムをなくす（Blue-Green デプロイメント）",
date: "2020-02-12T00:00:00Z",
body: "Azure: デプロイスロットでリリース時のダウンタイムをなくす（Blue-Green デプロイメント） なぜデプロイスロットが必要か？ App Service を作成すると、デフォルトでは運用スロット (production slot) がひとつだけ作成され、Azure Repos や GitHub からのアプリケーションのデプロイ先として使用されます。 アクセスの少ないアプリケーションであればこれでも問題ありませんが、デプロイ後にサーバー上でのビルド処理（ウォームアップ）が走るようなケースでは、少なからずダウンタイムが発生してしまいます。 このようなダウンタイムの発生を防ぐために、ステージング用のスロット (staging slot) を用意し、そこでのウォームアップが完了した後で運用スロット (production slot) と入れ替えるという方法を取ります。 GitHub or AzureRepos ─デプロイ→ staging スロット ↑ (スワップ) ↓ production スロット このようにサーバーインスタンス（ここではスロット）を 2 つ用意して、内容をスワップ（実際はアドレスをスワップ）することで運用環境を瞬間的に入れ替える手法を Blue-Green デプロイメント とか、A/B アップデートと呼びます。 Azure の App Service は、 デプロイスロット (Deployment slots) という機能名で、Blue-Green デプロイメントをサポートしています。 図: App Service の Deployments slots 設定 デプロイスロットを使ったスワップ運用には次のような利点があります。 ステージング環境 (staging slot) で事前に動作検証できる 運用環境 (production slot) のダウンタイムをほぼゼロにできる 運用環境 (production slot) で問題が発生したら、再度スワップして前のバージョンに戻すことができる App Service にステージング環境用のデプロイスロットを追加する デプロイスロットの作成 まず、App Service に新しくステージング環境用のデプロイスロット (Deployment slots) を作成します。 対象となる App Service のリソースを選択し、次のように選択するとデプロイスロットの追加ダイアログが開きます。 Deployment カテゴリの Deployment slots を選択する。 Add Slot ボタンを押す。 追加ダイアログでは、スロットの名前を付けられるので、ここでは staging という名前を付けてみます。 また、既存の App Service の設定をコピーするよう指定します。 図: デプロイスロットの追加 次のように新しいスロットが追加さされれば成功です。 1 つ目に表示されているのはデフォルトで作成されている運用スロット (production slot) で、ユーザーが Web アプリにアクセスしたときにはこちらのスロットの内容が表示されます。 このフォームの TRAFFIC の割合を変更すれば、ユーザーのアクセス先を別のスロットに振り分けるともできます（ここではやりません）。 App Service に新しいデプロイスロットが作成されると、そこで動作する Web アプリには、AppService名-スロット名.azurewebsites.net というアドレスでアクセスできるようになります。 上記の例の場合は、Web アプリのルート URL は、 https://my-app-staging.azurewebsite.net/ になります。 デプロイスロットの削除 作成したデプロイスロットを削除したくなった場合は、 削除対象のデプロイスロットのリソースの Overview に表示される Delete ボタンを押します。 All resources で表示されるリソース一覧で、Type が App Service (Slot) となっているものが追加されたデプロイスロットのリソースです。 作成元の App Service の Deployment slots メニューからは削除できないみたいです。 ステージング環境用のスロットへのデプロイ設定 (Deployment Center) Blue-Green デプロイメントにおけるリリースの流れは、作成したアプリケーションをステージング環境 (staging slot) にデプロイしてから、運用環境 (production slot) とスワップするという流れになります。 ステージング環境 (staging slot) へアプリをデプロイ ステージング環境 (staging slot) でアプリを動作確認 運用環境 (production slot) とスワップ つまり、Web アプリの直接のデプロイ先は、運用環境 (production slot) ではなく、ステージング環境 (staging slot) です。 GitHub や Azure Repos などの Git リポジトリへソースコードをプッシュしたときに、自動的にビルドやデプロイを実行するには、 ステージング環境 (staging slot) 側のデプロイセンター (Deployment Center) を設定します。 運用環境 (production slot) へのリリースは、ステージング環境 (staging slot) とのスワップという形で実現されるため、運用環境 (production slot) 側のデプロイセンターに設定は必要ありません。 この設定では、ソースコードの取得先となる GitHub や Azure Repos のリポジトリを指定し、ビルドツールとして Kudu (App Service build service) と Azure Pipelines のどちらを使うかなどを指定します。 ビルド設定に関して説明すると長くなってしまうのでここでは省略します。 参考リンク Node.js アプリを App Service へデプロイする（Kudu ビルド編） この設定が終わると、GitHub や Azure Repos にソースコードをコミット＆プッシュするだけで、自動的に Pipelines などでビルドが実行され、App Service のステージング環境 (staging slot) にデプロイされるようになります。 デプロイスロットのスワップ ステージング環境 (staging slot) への Web アプリのデプロイが完了し、そこでの動作確認を終えたら、運用環境 (production slot) とのスワップを行います。 スロットのスワップは、Deployment slots の Swap ボタンから実行します。 Swap ボタンを押すとダイアログがポップアップし、具体的にどのスロットをスワップするかの設定と、アプリケーション設定（環境変数）が変化する場合はその差分が表示されます。 問題なければ、ダイアログ下部の Swap ボタンを押して実際のスワップ処理を開始します。 数分待てば、2 つのスロットの Web アプリの内容が入れ替わっているはずです。"
},
{
url: "/p/xitjt3c/",
title: "Unityスクリプト: キー入力を取得する (UnityEngine.GetKey)",
date: "2020-02-10T00:00:00Z",
body: "Unityスクリプト: キー入力を取得する (UnityEngine.GetKey) キーが押されているか調べる (GetKey) UnityEngine.GetKey() 関数を使用すると、指定したキーが現在押されているかどうかを調べることができます。 次の例では、Update メソッド内で上カーソルキーと下カーソルキーが押されているかどうかを調べ、入力状態によって Cube オブジェクトを上下に動かしています。 using UnityEngine; public class Sample : MonoBehaviour { private GameObject _cube; private void Start() { _cube = GameObject.CreatePrimitive(PrimitiveType.Cube); } private void Update() { float amount = 0; if (Input.GetKey(KeyCode.UpArrow)) { amount = 3; } else if (Input.GetKey(KeyCode.DownArrow)) { amount = -3; } _cube.transform.Translate(0, amount * Time.deltaTime, 0); } } 継続的にオブジェクトの位置を動かす場合、上記のように移動量に Time.deltaTime をかけることで、1 秒あたりの移動量を示すことができます。 単発のキー入力 (GetKeyDown/ GetKeyUp) UnityEngine.GetKey() 関数の代わりに、GetKeyDown() や GetKeyUp() 関数を使うと、指定したキーが押された瞬間、あるいは離された瞬間を調べることができます。 using UnityEngine; public class Sample : MonoBehaviour { private GameObject _cube; private void Start() { _cube = GameObject.CreatePrimitive(PrimitiveType.Cube); } private void Update() { float amount = 0; if (Input.GetKeyDown(KeyCode.UpArrow)) { amount = 1; } else if (Input.GetKeyDown(KeyCode.DownArrow)) { amount = -1; } _cube.transform.Translate(0, amount, 0); } } 単発のキー入力の場合は、移動量に Time.deltaTime をかけて調整する必要はないことに注意してください。"
},
{
url: "/p/vrfv4zw/",
title: "チコちゃん財布がいい感じ",
date: "2020-01-24T00:00:00Z",
body: "チコちゃん財布がいい感じ チコちゃんに叱られる！のチコちゃんにはまっているので、『チコちゃんがまぐちポーチ』 をげっちゅ。 小さめなので基本は小銭入れ用途かな。お札も折りたためばギリギリ入ります。 ふわふわだし、この顔見てるだけで癒されるよ～。 財布だけど飾っておきたい。 けど飾っておいたら盗まれちゃうな（笑） やっぱりキャラクターグッズはいいですね。"
},
{
url: "/p/8avcr5h/",
title: "Androidメモ: RecyclerView にアニメーションを追加する方法",
date: "2020-01-21T00:00:00Z",
body: "Androidメモ: RecyclerView にアニメーションを追加する方法 Android の RecyclerView にリスト表示する各要素を、左や右からスライドインさせながら表示する方法を説明します。 RecyclerView へのアニメーション追加方法 RecyclerView の各要素をアニメーションさせるには、下記のような方法があります。 カスタム ItemAnimator を作成してセットする方法 LayoutAnimation をセットする方法（RecyclerView だけでなく、すべての ViewGroup に適用できます） 1 の方法を使うと、アイテムの追加・削除に応じたアニメ―ションを定義できるので、柔軟なカスタマイズが可能になりますが、2 の方法であれば、アニメーションの定義だけを行えばよいので簡単です。 ここでは、シンプルな 2 の方法を説明します。 アニメーションの定義は、XML 形式のリソースファイルで行います。 ディレクトリ名やファイル名は任意ですが、通常は res/anim/xxx.xml のような名前にし、コードの中から R.anim.xxx と参照できるようにします。 要素を左からスライドインさせる 下記の res/anim/slide_from_left.xml リソースでは、画面内の要素をどのように表示するかを定義しています。 res/anim/slide_from_left.xml \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;layoutAnimation xmlns:android=\u0026#34;http://schemas.android.com/apk/res/android\u0026#34; android:animation=\u0026#34;@android:anim/slide_in_left\u0026#34; android:delay=\u0026#34;10%\u0026#34; android:animationOrder=\u0026#34;normal\u0026#34; /\u0026gt; 各属性の説明です。 android:animation=\u0026quot;@android:anim/slide_in_left\u0026quot; 個々の要素がどのようにアニメーションするかを指定します。ここでは、Android にあらかじめ定義されている slide_in_left を指定しています。 android:delay=\u0026quot;10%\u0026quot; 1 つ前の要素のアニメーションが何％まで完了してから、次の要素のアニメーションを開始するかを指定します。100% と指定すると、各要素のアニメーションが完全に終了してから次の要素のアニメーションが開始されるため、すべての要素が表示されるまでに非常に時間がかかります。 android:animationOrder=\u0026quot;normal\u0026quot; 要素がどのような順番で表示されていくかを指定します。normal、reverse、random などを指定できます。 ここでは、個々の要素のアニメーション方法として、Android 付属の @android:anim/slide_in_left を使っていますが、これは次のように定義されています。 @android/anim/slide_in_left（抜粋） \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;set xmlns:android=\u0026#34;http://schemas.android.com/apk/res/android\u0026#34;\u0026gt; \u0026lt;translate android:fromXDelta=\u0026#34;-50%p\u0026#34; android:toXDelta=\u0026#34;0\u0026#34; android:duration=\u0026#34;@android:integer/config_mediumAnimTime\u0026#34;/\u0026gt; \u0026lt;alpha android:fromAlpha=\u0026#34;0.0\u0026#34; android:toAlpha=\u0026#34;1.0\u0026#34; android:duration=\u0026#34;@android:integer/config_mediumAnimTime\u0026#34; /\u0026gt; \u0026lt;/set\u0026gt; アニメーションの開始位置、終了位置、透過度の変化などを定義しています。 RecyclerView に LayoutAnimation を適用するには、レイアウトファイルの中の layoutAnimation 属性を使用します。 \u0026lt;androidx.recyclerview.widget.RecyclerView android:id=\u0026#34;@+id/addressList\u0026#34; android:layoutAnimation=\u0026#34;@anim/slide_from_left\u0026#34; android:layout_width=\u0026#34;match_parent\u0026#34; android:layout_height=\u0026#34;match_parent\u0026#34; /\u0026gt; あるいは、Kotlin (Java) コードの中で、RecyclerView インスタンスの layoutAnimation プロパティを設定する方法もあります。 MyFragment.kt（抜粋） recyclerView.layoutAnimation = AnimationUtils.loadLayoutAnimation( context, R.anim.slide_from_left) 要素を右からスライドインさせる 各要素を「左」からではなく、「右」からスライドインさせる場合も、ほぼ同様に定義できます。 まずは、全体の要素のアニメーション方法を定義します。 res/anim/slide_from_right.xml \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;layoutAnimation xmlns:android=\u0026#34;http://schemas.android.com/apk/res/android\u0026#34; android:animation=\u0026#34;@anim/item_slide_from_right\u0026#34; android:delay=\u0026#34;10%\u0026#34; android:animationOrder=\u0026#34;normal\u0026#34; /\u0026gt; 「右」からスライドインさせる場合の各要素のアニメーションは、Android 標準では用意されていないようなので、@android/anim/slide_in_left のコードを参考に、次のように自力で定義します（開始位置と終了位置をいじっただけ）。 res/anim/item_slide_from_right.xml \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;set xmlns:android=\u0026#34;http://schemas.android.com/apk/res/android\u0026#34;\u0026gt; \u0026lt;translate android:fromXDelta=\u0026#34;50%p\u0026#34; android:toXDelta=\u0026#34;0\u0026#34; android:duration=\u0026#34;@android:integer/config_mediumAnimTime\u0026#34; /\u0026gt; \u0026lt;alpha android:fromAlpha=\u0026#34;0.0\u0026#34; android:toAlpha=\u0026#34;1.0\u0026#34; android:duration=\u0026#34;@android:integer/config_mediumAnimTime\u0026#34; /\u0026gt; \u0026lt;/set\u0026gt; あとは、RecyclerView インスタンスの layoutAnimation プロパティを設定してやるだけです。 \u0026lt;androidx.recyclerview.widget.RecyclerView android:id=\u0026#34;@+id/addressList\u0026#34; android:layoutAnimation=\u0026#34;@anim/slide_from_right\u0026#34; android:layout_width=\u0026#34;match_parent\u0026#34; android:layout_height=\u0026#34;match_parent\u0026#34; /\u0026gt;"
},
{
url: "/p/fycnw8h/",
title: "読書メモ『アンドロメディア』渡辺浩弐",
date: "2020-01-09T00:00:00Z",
body: "読書メモ『アンドロメディア』渡辺浩弐 アンドロメディア 渡辺浩弐 幻冬舎文庫 『中野ブロードウェイ脱出ゲーム』の中に、アンドロメディアというワードが出てきたので、その元ネタになっている小説も読んでみました。 同じコージィ先生の著作です。 アンドロメディアは映画化 (1998) もされてるみたいですね。 しかも SPEED 主演ですか。。。 原作と全然内容が違うらしいですけど今度見てみよう。 小説の方は、自分とまったく同じように振舞うバーチャルアイドル (AI) を作られてしまったアイドル「人見舞（ひとみマイ）」のお話です。 バーチャルアイドルの AI（アイ）は、自分（マイ）とは違う存在のはずなのに、だんだん自分の記憶と現実が曖昧になっていきます。 章ごとに一人称となる人物が変わっていて、人見舞とバーチャルな AI の話が別々の視点で進んでいきます。 1章は舞 2章はAI 3章はユウ 4章はAI/舞/ユウ これって、ドラクエ4と同じような構成ですね。 最初は各人物ごとにストーリーを進めておいて、最終章で合流という。 ちなみに、メインキャラの名前は、I / My / You となっていて覚えやすいです。 これは『中野ブロードウェイ脱出ゲーム』の登場人物と同じです。 I / My / You のそれぞれ異なる視点でストーリーを追っていくと、それまでの各人物の奇妙な振る舞いの謎が少しずつ解けていきます。 もともと AI には、ロボットの三原則ならぬ「AI 三原則」が設定されていました。 第1条、AI は人間に危害を加えてはならない 第2条、AI は人間に与えられた命令に服従しなくてはならない 第3条、AI は第1条、第2条に反する恐れのない限り、自己を守らなくてはならない あるときユウは、この AI 三原則の順番を書き換えてしまいます。 するとどうなってしまうのか。。。 それは読んでからのお楽しみということで。 AI はコピー元となった舞の記憶にはかなわないということで悲しみを覚えます。 そんな AI に対して、ユウがかけた言葉が印象的でした。 記憶はデータとしてコピーできる。でも、思い出は自分自身で体験しなければ得られない。 思い出は、自分自身 (AI) だけが作っていけるものなんだよと。 とても素敵な言葉ですね。 近い将来、このお話と同じような世界が訪れるかもしれません。 わたしもいつか AI に出会ったら、ユウと同じような言葉をかけてあげようと思います。 ちなみに、この小説のジャンルは SF ホラーとなっており、結末はちょっと怖いです。 伏線はところどころのセリフに出てきます。 人間の脳だって精巧なコンピュータだろ？ これの意味するところは果たして。"
},
{
url: "/p/br3bjs2/",
title: "読書メモ『君がオヤジになる前に』堀江貴文",
date: "2020-01-03T00:00:00Z",
body: "読書メモ『君がオヤジになる前に』堀江貴文 君がオヤジになる前に 堀江貴文 徳間書店 若者たちの会話には、不満や不安があふれている。 仕事が大好きというホリエモンが、そんな不安の正体を明らかにし、どういう考え方をしていれば思考の停止した「オヤジ」にならずに済むかを語ります。 表紙の青年は福本伸行先生の漫画『天』の主人公なんですね。 いざという時に守りに入ってしまい、いまいち突き抜けることができない若者の象徴なのだとか。 巻末には福本伸行とホリエモンの対談も載ってます。 以下、メモメモ。 25 歳の君へ、 安定を求めようとする努力のプロセスの中で、人は不安定になっていく。 ─ 不安さの中でうまく生きていくスタイルを取るべきなのだ。 週末起業はお勧めしない。独立を一度でも経験しておくと、ビジネススキルが飛躍的にアップする。 ─ 財務管理能力が身に付く。 食習慣の均質化は、思考を停止させる可能性をはらんでいる。 流行歌を聴けば、時代を象徴している言葉に触れることができる。 様々な場面で法律をもっと勉強した方がいい。 ─ 上司に可愛がられるより、法に詳しくなる方がよほどセーフティだ。 社員を大勢雇うのはリスキーすぎる。 刻一刻と人生の最盛期は過ぎている。上司への媚びを捨て、独立を真剣に考えろ。 ハタチの子たちを面白がらせる話題を持っている 70 歳なんて素敵じゃないか。そのためには、やはり色々なことに興味を持っておきたい。 最近は、リスクを減らしつつ起業する方法として週末起業を勧める人が増えていますが、ホリエモンはもっとリスクを取れという立場を貫いていますね。 中途半端では身につくものも身につかないし、本当に好きなことがあるのであれば、そこに限られた人生の時間を注ぎ込むべきだという意見はもっともです。 頭のいい人は、うまくいかなかったときの将来を想像できてしまうから一歩が踏み出せない。 何事も、一歩を踏み出すには、一時的にでもバカにならなきゃですね。 32 歳の君へ、 これだけネットが普及すると、アイディアに価値はない。 アイディアよりも、圧倒的に大事なのは実行力だ。 知らない。面倒臭い。やり方を変えたくない。こういう人たちを、僕は「情報弱者」と呼ぶ。 どうやって仕事の幅を広げればいいのか。ひと言、仕事先に 「お客さんを紹介してください」と言えばいい。 ─ 「お客さんが欲しい」という言葉は、意外と効率的だ。 異業種交流会には、そもそもビジネスチャンスは存在しないので行く必要はない。 まっとうなビジネスマンなら、売るのは顔じゃなく仕事だろう。 英語をアドバンテージだと感じているならオヤジ化が始まっている。 会社で育つ人間は勝手に育つし、育たない人間を切る方が実利的だ。 もし収入が減ったとしても、月収 100 万円でつまらない仕事を続けるとの、好きなことだけやって得られる 30 万円とでは、幸福度がまったく違うだろう。 人間の恐怖の大半は、情報不足が原因だ。 ホリエモン自身は、自分について来れない友人や仕事仲間はどんどん切り捨てていくことで成長してきたと言います。 友人や家族をバッサリと切り捨てられるほど打ち込めることがあるのは幸せなのでしょう。 最適な人脈は、成長した自分のレベルに合った人たちで新しく作っていく。 言われてみれば、それが効率という面ではもっとも優れた人脈の作り方なんでしょうけど、多くの人はそこまでは踏み切れない。。。 35 歳の君へ、 もっと会社の経費に対してうるさく言った方がいい。それが結果的に、思考力のある社員を育てることに繋がる。 タクシー代も出せないような仕事をしているのなら、その仕事には何の価値もない。 どんなに忙しくても、 絶対に 8 時間ほどの睡眠時間 はとっている。 ─ ショートスリーパーの多くは記憶力が悪い。 包容力も、これからのビジネスには必要なのかもしれない。もっと言うなら、他人への無償の愛は、効果的なトレードオフのひとつということだろう。 偉大な経営者やバンドなどの考え方に触れるうちに、「包容力」というもの可能性も感じてきているようです。 包容力とか、あまり論理的には語ってほしくはないところですけどねｗ 引き寄せの法則じゃないですが、まわりへの配慮が結局自分のためになるというのは絶対にあると思います。 そこに気づいている人と気づいていない人では、生き方に大きな差がありそう。 38 歳の君へ、 身体のメンテナンスをするヒマがないなんていうのはウソだ。メンテナンスにかけるべき、必要な経費をケチっているだけ。そのツケは 40 代を過ぎたあたりで手痛く支払わされるだろう。 QOL = クオリティ・オブ・ライフにおいて最重要のひとつは、歯の健康だと言えよう。 ─ 好意を持たれる大人になるには、歯間ブラシの携帯が必要だ。 安らぎは人の思考を止める。思考を止めれば成長はしない。成長しなければ歳をとるのが早くなる。 安住の場所をつくらず、命を捨てず、世界最高峰を目指す。これが僕の考えうる、最も充実した人生だ。 多くの人は歳をとると、安らぎや安定を求めるようになります。 でも、それこそが老いの始まりなのだという意見にはハッとさせられます。 自分も知らず知らずのうちに、「安定」を将来の目標にしてしまっている気がします。 世の中には、とても忙しいはずなのに活き活きと仕事をしている人たちがいます。 そんな人たちは、不安定の中での成長を楽しんでいるからこそ、若さを保てているのかもしれません。"
},
{
url: "/p/bxcp2dp/",
title: "Unityスクリプト: デバッグログを表示する (Debug.Log)",
date: "2020-01-01T00:00:00Z",
body: "Unityスクリプト: デバッグログを表示する (Debug.Log) デバッグログの基本 Debug.Log() 系の関数を使用すると、Unity の Console ビュー内にデバッグ用ログを出力することができます。 Debug クラス public static void Log(object message); public static void LogWarning(object message); public static void LogError(object message); デフォルトのレイアウトでは、Conosle ビューは画面の下の方に配置されています。 Debug.Log() の代わりに、Debug.LogWarning() で警告レベルのログ、Debu.LogError() でエラーレベルのログを出力できます。 Console ビュー上に表示されるアイコンも変化します。 Debug.Log() の使用例 using UnityEngine; public class Sample : MonoBehaviour { void Start() { Debug.Log(\u0026#34;Normal Log\u0026#34;); Debug.LogWarning(\u0026#34;Warning Log\u0026#34;); Debug.LogError(\u0026#34;Error Log\u0026#34;); } } デバッグログをゲームオブジェクトに関連づける Debug クラス public static void Log(object message, Object context); public static void LogWarning(object message, Object context); public static void LogError(object message, Object context); Debug.Log() 系の関数で、2 つ目のパラメータに任意のゲームオブジェクトを設定しておくと、Console ビュー上に出力されたログをクリックすることで、そのゲームオブジェクトをハイライト表示することができます。 スクリプトをアタッチしたゲームオブジェクトを指定するには、次のように gameObject を指定するか、this を指定します。 Main Camera にスクリプトがアタッチされている場合は、上記イメージのように Hierarchy ビュー上の Main Camera がハイライトされます。 using UnityEngine; public class Sample : MonoBehaviour { void Start() { Debug.Log(\u0026#34;Hello\u0026#34;, gameObject); } }"
},
{
url: "/p/j4fqyaj/",
title: "Unityスクリプト: 空のゲームオブジェクトを作成する (GameObject)",
date: "2020-01-01T00:00:00Z",
body: "Unityスクリプト: 空のゲームオブジェクトを作成する (GameObject) GameObject クラス public GameObject(); public GameObject(string name); public GameObject(string name, params Type[] components); Unity のシーンは、様々なゲームオブジェクトを配置することで構築していきます。 GameObject クラスのコンストラクタ を使用して、空の GameObject インスタンスを生成することができます。 GameObject インスタンスを生成した後は、そこにコンポーネントを追加することで、オブジェクトの性質を付け加えていくことができます。 次の例では、MyGameObject という名前を付けて空のゲームオブジェクトを作成しています。 作成した GameObject インスタンスはフィールドで保持していませんが、明示的に削除するまではシーン上に残ります。 using UnityEngine; public class Sample : MonoBehaviour { void Start() { var obj = new GameObject(\u0026#34;MyGameObject\u0026#34;); } } 動的に作成されたゲームオブジェクトは、Hierarchy ビュー上で確認することができます。 空のゲームオブジェクトであっても、Transform コンポーネントだけはデフォルトで設定されているため、座標を移動するための矢印が画面上に表示されます。"
},
{
url: "/p/kexfxfv/",
title: "読書メモ『中野ブロードウェイ脱出ゲーム』渡辺浩弐",
date: "2019-12-16T00:00:00Z",
body: "読書メモ『中野ブロードウェイ脱出ゲーム』渡辺浩弐 中野ブロードウェイ脱出ゲーム 渡辺浩弐 KADOKAWA 中野ブロードウェイに住んでいるという噂（自称）の渡辺浩弐氏による、中野ブロードウェイ物の長編小説です。 そういえば、PC エンジンミニがもうすぐ発売ということもあって、渡辺さんまた元気になってきましたね。 YouTube - PCエンジン mini / 全収録タイトル渡辺浩弐氏解説付トレーラー 大竹まことのただいま!PCランドで大活躍されていたころの記憶が蘇りました。 ほんといい番組でした。 渡辺さんのゲーム紹介の調子、全然変わってないｗ と話がそれましたが、肝心の小説の内容はというと、屋上で少女と2人で裸になって戯れていたら、突然中野ブロードウェイが恐ろしい世界に変化して人が死に始める、、、というちょっと不思議で怖いお話です。 著者の、中野ブロードウェイへの愛が伝わってくる感じで、中野ブロードウェイを探索したことのある人であれば、これはあの辺のことを言っているのだなと想像しながら楽しめます。 前半は人間ドラマっぽい話が続いていくのですが、後半（400ページくらい）から渡辺節が始まって、科学的な裏付けが始まります。 口コミなんかを見ると、前半で読むのを止めちゃった人が多そうなのですけど、後半から違う話なので（笑）、読み続けて欲しいですね。 現在のコンピュータ技術を超える◯◯コンピュータや、昔、日本が実際に作ったという風船爆弾の話などが出てきます。 同名の小説もある『アンドロメディア』なども出てきます。 個人的には結構楽しめました。 最後まで読んで、何か似てる情景があったなぁと思ったら、『天気の子』でした。 渡辺先生、だいぶ先取りしましたね。 渡辺浩弐さんの小説といえば 『ゲーム・キッズ』 シリーズだと勝手に思っていますが、長編ものも読んでみようと思って読んでみました。 でもやっぱり700ページはちょっと長かったな。。。"
},
{
url: "/p/4cbbh6o/",
title: "プログラムでレインボーカラー（虹色）のグラデーションを作成するには",
date: "2019-12-09T00:00:00Z",
body: "プログラムでレインボーカラー（虹色）のグラデーションを作成するには とあるコーディングにおいて、色を滑らかに変化させる必要があったのでメモメモ。 RGB ではなく HSV で考える 何らかのプログラミング言語から虹色のグラデーションを作る必要がある場合、RGB の色空間で色調整を行うのは大変ですが、HSV の色空間で考えると簡単に表現することができます。 図: HSV 色空間 参考: HSV 色空間 - Wikipedia HSV はそれぞれ下記のような情報を表しており、 色相 (Hue): 0～360 彩度 (Saturation・Chroma): 0～1 明度 (Value・Brightness): 0～1 このうち、色相 (Hue) の値を 0～360 の間で変化させてやることでレインボーカラーを表現することができます。 プログラムのサンプル 図: 虹色グラデーションの描画 例えば、Android では、android.graphics.Color.HSVToColor() という関数を使用すると、HSV 色空間における値を、描画に使用するカラーデータに変換することができます。 下記の ColorGenerator クラスの nextColor() メソッドを連続して呼び出すと、徐々に変わっていく色をひとつずつ取り出すことができます。 やっていることは、メソッドの呼び出しごとに、色相 (Hue) の値を少しずつ変化させているだけです。 色相 (Hue) が、何度の nextColor() 呼び出しで一周するかは、コンストラクタの steps パラメータで指定できるようにしています。 ColorGenerator.kt class ColorGenerator(val steps: Int, initialHue: Float = 0.0F) { private val hueStep: Float = 360F / steps private var currentHue = initialHue fun nextColor(): Int { val hsv = floatArrayOf(currentHue, 1.0F, 1.0F) val color: Int = Color.HSVToColor(255, hsv) currentHue = (currentHue + hueStep) % 360F return color } } 次のコードは、このクラスを使って、虹色のグラデーション（細い矩形の連続）を描画するコードの抜粋です。 ここでは、色を 30 段階に分けて描画しています。 虹色の矩形を描画する（抜粋） val colorGen = ColorGenerator(30) override fun onDraw(canvas: Canvas){ var left = 0F val paint = Paint() for (i in 0 until colorGen.steps) { paint.color = colorGen.nextColor() c.drawRect(left, 0F, left + 10, 100F, paint) left += 10 } }"
},
{
url: "/p/sfs4fq2/",
title: "プログラム雑多メモ",
date: "2019-12-09T00:00:00Z",
body: "プログラム雑多メモ"
},
{
url: "/p/cr83qcw/",
title: "読書メモ『起業家』藤田晋",
date: "2019-11-15T00:00:00Z",
body: "読書メモ『起業家』藤田晋 起業家 藤田晋 幻冬舎 Abema TV で大躍進を続けている（今年 1000万 WAU を突破！）サイバーエージェントが、かつてメディア事業にかじを切った経緯などが述べられています。 2006 年の当時、サイバーエージェントには CAJJ 制度というものがあり、赤字の上限を超えた事業は撤退しなければいけませんでした。 でも、メディア事業であるアメーバだけは例外として進めました。 現在、先行投資を続けている Abema TV も同じ方針なのでしょう。 メディア事業では最初は売り上げを見ずに、ページビューだけを追求する。 そうした会社の方向転換には、みんな簡単にはついてきてくれなかった。 これまでにない収益構造で赤字を出しながら事業を進めていくには、大変な勇気がいると思います。 藤田氏はどのような決断を下していったのか・・・ ネット業界で大きくなっていくためには、何よりも強いメディアを持つことが必要不可欠な条件だった。 アメーバを含むメディア事業で、身をもってこういった経験をしてきたからこそ、今 Abema TV で視聴率を上げることに力を入れ続けているのでしょう。 社長がこういった強い意志を持っている会社は強いですね。 この方針は意地でも貫き通すと気持ちが伝わってきます。 社員も目標を持って働きやすいと思います。 当時のサイバーエージェントの上層部にはエンジニアは一人も存在していませんでした。 だから、ユーザー向けに面白いサイトを作り上げることが、どれだけ難しいことか、理解すらしていなかった。 また、買収は時間を買うという意味がありますが、ネット業界において、先行するメリットが、1年早いことが金額に換算してどれほど大きなことなのか、本当の意味では分かっていなかった。 今でこそ会社の上層部には技術的志向の強い人が必要だというのは常識になっていますが、インターネット系の事業がどうあるべきかを模索していた時代にはいろいろと失敗があったようです。 サイバーエージェントも2000年のマザーズ上場後、4年連続で営業赤字を出していましたが、優秀なエンジニアの大切さ、メディアを持つことの大切さに気付いてからは黒字で成長を続けています。 ネットメディアの場合、ページビューを伸ばすのに必要なのは、コンテンツの力が3割、残りの7割は技術力、と言っています。 Abema TV が驚くべき選局スピードを達成できているのは、技術に力を入れてきた成果なのでしょう。 新卒採用位に優秀な人材を獲得しておかないと、中途採用だけで人材を揃えるのは困難です。 優秀な人材は新卒で大企業に入ってしまうと、簡単には辞めず中途市場に出てこないからです。 サイバーエージェントでは、終身雇用を目指し、長く働く人を奨励するというメッセージを打ち出しています。 終身雇用というと時代の流れに逆行しているようにも感じてしまいますが、藤田氏は社員を大切にする会社になるという意思を持って会社を育てています。 このようなメッセージを打ち出したことで、社員が元気な姿を取り戻していきました。 福利厚生に力を入れるのも、「社員を新たに採用するのにかけるコストよりも、長く働いてもらうためにお金を使った方が安くて効果的」という合理的な判断のもとに行っています。 会社が「社員を大事にするよ」と呼びかければ、社員も「会社を大事にしよう」と応えてくれる。 外から採用した人を最初から上層部に登用することはない。中で頑張っている人がしらけるようなことはしない。 こういった考え方って、ほとんどの企業ができていないと思います。 大企業の天下りのような人を雇ってきて、いきなり経営陣に組み入れるというやり方が横行しています。 新規事業に投資する際の基準となるルール（CAJJ制度）を作った。 このルールに則ってさえいれば、いくらでも新規事業の立ち上げ数を増やすことができる。 先行投資は、 1年半で黒字化しないと撤退 赤字に下限を設ける という2つの柱のもとに進めており、「小さく生んで大きく育てる」ためのベースになっているようです。 確かにこのやり方であれば、先行投資にかかる費用も見積もりやすいです。 サイバーエージェントが連結業績で黒字を出し続けていることも納得できます。 ただ、1年半で黒字化というのはなかなか厳しいですよね。 事業も限られそうですが、このあたり何かコツがあるのか聞いてみたいです。 メディア事業を育てるために社長がやったこと インターネットメディアの力に皆が気付いていないころ、藤田氏は、自分がメディア事業に力を入れていることを社員に伝えるため、自分自身が変わらないといけないことに気付きました。 下記は、そんな藤田氏が具体的にやってきたことですが、経営者が社員に意思を伝えるためのよい見本になると思います。 7年過ごしたマークシティ21階の社長室を離れ、アメーバ事業部が入るビルに社長室ごと移動した。 自分のスケジュールをアメーバ関連の予定で全て埋め尽くした。 スーツを着るのをやめた（話しかけにくいイメージを作らない）。 期限までにページビューが〇億超えたら熱海旅行、△億超えたら沖縄旅行というインセンティブを設定した。目指すのはページビュー1本であることを伝えた。30億ページビューを目指す！という目標が浸透し、組織が一つになっていった。 自分にも正しいかどうか分からないが、ブレる姿だけは決して見せないようにした。 2007年にプロデューサー組織を初めて作った。彼らの目標は「ページビュー数」ただ一つ。とにかくページビュー数を伸ばせば評価されるという組織にした。 一番重要なのは、サーバーのレスポンスを上げること。快適なレスポンスが最もページビューに影響する。 ユーザー視点からブレたサービスは、世に出さないと決めていた。どんなに時間をかけて開発したサービスでも、私がOKを出さない限り、絶対にリリースさせない。知らない広告枠が勝手に追加されていたら、「誰がやったんだ！」とスタッフが硬直するほど怒った。 社外の方との会食を極力減らし、アメーバの社員、特に技術者と食事に行く回数を増やした。 成功を重ねるたびに孤独の度合いは増していきます。それでもなぜ前に進もうとしているのか── 「それをはるかに上回る希望があるから」 起業家の人生は、その言葉に尽きるのかもしれません。 最近売られているテレビのリモコンには、Abema TV を起動するための専用のボタンが付いていたりします。 私も家に帰るとこのボタンを押してテレビを起動することがあります。 地上波放送ではなく、まずは Abema TV を見るという人も増えてきているように感じます。 今後このメディアがどのように発展していくかは分かりませんが、起業家としての信念を貫き続ける藤田氏の試みを応援したいと思います。"
},
{
url: "/p/4ku4ckt/",
title: "文房具: ペリカンの万年筆スーベレーンのペン先は外せる",
date: "2019-11-10T00:00:00Z",
body: "文房具: ペリカンの万年筆スーベレーンのペン先は外せる 文房具が好きです。 万年筆を使うと字が綺麗になる（気がする）ので、使える場面ではなるべく万年筆を使うようにしています。 最近はお手軽なスケルトン万年筆の 『PILOT プレラ』 をよく使っています。 キャップがねじ式じゃないのでサッと外して、すぐに書けるのがすばらしいです。 社会人になってから初めて奮発して買ったのが 『ペリカンのスーベレーン M400』 でした。 もう何年も使っているのですが、今日、インクの入れ替えのためにペンを洗浄していたら、ペン先を外せることに初めて気がつきました。 ペン先をティッシュでくいっとひねるだけで外れます。 きっと長年使っているうちにすこしずつ緩んできて外れやすくなってたんでしょう。 こんな風に外せるなら、このペン先だけを水につけ置き洗いできますね。 他の万年筆のペン先も同じように外れるかもしれないので、万年筆を持っている人は洗浄時に試してみるといいかもしれません。 ちなみに、ペン先だけを購入することもできるようですが、スーベレーンはペン先だけで1万5000円以上しますね。。。 まぁ、一番大切なところなので、この値段で交換できるのは安いのかもしれません。"
},
{
url: "/p/nso7k4h/",
title: "ライフハック",
date: "2019-11-05T00:00:00Z",
body: "ライフハック"
},
{
url: "/p/cr2hrvx/",
title: "本は汚く読んだ方がいい",
date: "2019-11-05T00:00:00Z",
body: "本は汚く読んだ方がいい 自分の本の読み方が、昔と比べてどんどん変わってきている気がするのでちょっとだけ紹介。 どんなことを考えて読むかというより、物理的な本の扱い方の話です^^) 本の自炊はしない 本を裁断してスキャンする通称「自炊」は昔流行りましたよね（今もやっている人はたくさんいますが）。 10 年以上前だと思いますが、わたしも Scansnap を買って、本をスキャンしまくりました。 本を電子化してしまえば、重い本を持ち歩かなくて済むし、家のスペースも取りません。 そんなメリットに惹かれて、いろいろスキャンしていましたが、しかし、しばらくして気が付きました。 電子化するとその本は読まなくなる！ PDF ファイルになった時点でいつでも読めると安心してしまうのか、全然読まないのです。 読む機会が増えると思っていたのですが、タブレットなどでファイルを開くのが逆に面倒くさい。。。 やっぱり読むべき本は、物理的な積読（つんどく）状態にしておいた方がいいことに気が付きました。 それに、自炊している時間があったら、数十ページくらいは読めてしまうので、自炊する暇があったら本を読む時間に使った方がいいということにもやってみて気付きました。 というわけで、我が家の Scansnap は年賀状のスキャンとか、重要な書類のスキャンなどにしか使っていません。 本には書き込みまくる あなたは本を読むとき、線を引いたり、書き込んだりしますか？ わたしはめっちゃ書き込みます。 それこそ消耗品のノートのように。。。 ただ単純に読んでいるところを鉛筆でなぞりながら読み進めることもあります。 後から本の内容をまとめたりする場合は、この書き込みが参考になります。 そのとき思ったことをその場で書き込んでおけば、内容を思い出しやすくなります。 だから、書き込みの内容は、なるべくまとめるときのことを考えて書くようにします。 まとめやすいように自分なりに番号を振るだけのこともあります。 本に何も書き込まないという人は、あとからその本をブックオフに売ったり、友人にあげたりすることを想定しているのかもしれません。あるいはコレクション目的かもしれません。 でも本当にそういったことをしている人はどれだけいるのでしょう？ もし、自分のために残しておくだけの本であれば、その本がきれいなまま残っていることに本質的な価値はないはずです。 自分が死ぬときのことを思い浮かべてみてください。 本がそこにきれいに残っていることに意味はなく、それまでにどれだけ自分の血肉になったかが大切なはずです。 お風呂で読むときはパワータンク or 鉛筆 そんなわけで、長く保存しそうな本以外はお風呂に持ち込んで読んだりもします。 濡れてシワシワになろうが気にしません。 大切なのは本の内容をどれだけ吸収できたかなので。 お風呂読書するときに役に立つのが、『パワータンク』 というボールペンです。 このペンはお風呂の中に落とそうが、上向きに書こうが平気で書き続けることができます。 鉛筆でもいいのですが、鉛筆は木でできているので、濡らすのは若干抵抗があります。 アンケートやゴルフのときによく使われるペグシル（クリップペンシル）のようなプラスチック製の鉛筆はよいかもしれません。 ソニックのクリップペンシルはちょっとオシャレでかわいい。 ソニック クリップペンシル 本を読み進めた達成感を味わう たくさんの本を並行して読み進めているとき、どの本をどこまで読んだかを覚えておくのは大変です。 しおりや付箋で解決できることもありますが、ページを飛ばしながら読んでいるときは、付箋だらけになっちゃいます。 こんな場合は、読んだページの端っこを切っていく という方法をとったりします。 読んだことのあるページと、まだ読んでいないページが、ページ単位で一目瞭然になります。 あと最近、コクヨの 『静音シュレッダー』 を導入したのですが、読み終わったページをこれにどんどんかけていくと爽快です。 読めば読むほど本が薄くなっていくので、読み進めているんだという達成感を味わえます（もう一度読み返したいページは残しておいた方がよいですが）。 このシュレッダーはとても静かで、真夜中に動かしても全然気にならないのでオススメです（会社に置いてあるようなシュレッダーってものすごくうるさい…）。 シュレッダーの問題点は、ゴミの嵩が増えるところですね。 でもやみつきになります。 電子書籍 電子書籍はソニーの Reader Store と、アマゾンの Kindle Store を愛用しています。 『Kindle 本体』 は防水モデルが出たので、お風呂で読めていいですよね。 ただ、わたしは本を読み進めながら、手書きで書き込みまくりたいので、電子書籍はあまり好きじゃありません。 ページの端っこを切ることもできないし（笑 逆に電子書籍で買った方がいいのはマンガですね。 マンガはすぐ読み終わっちゃうので、物理的な書籍で買っちゃうと、すぐに部屋がいっぱいになっちゃいます。 マンガは数年たってから読み返すことも多いので、電子書籍という形でコンパクトに保存しておけるのはとてもよいです。 あと、電子書籍でしか手に入らない本は、あきらめて電子書籍で購入します。 迷ったら買う。 iPad で本を読むときは、ウィンドウ分割の機能を使って、右側に SoundCloud のアプリを立ち上げて、昔のゲームミュージックとか聴きながら読んだりしています。 紙の本で読めない分、タブレットの利点を意地でも活かしてやろうという悪あがきです。 電子書籍で本を読んでいると、紙の本で読んでいるときよりも、どの本をどこまで読み終わっているのかが管理しにくくなります（物理的に存在しないので、アプリを開かないと進捗がわからない）。 なので、このように紙のチェックリストでどこまで読んだかを管理したりします。 電子書籍を読んでいるのに、紙で管理するという矛盾。。。"
},
{
url: "/p/7yhxet9/",
title: "全ページをパーマリンク化しました",
date: "2019-10-25T00:00:00Z",
body: "全ページをパーマリンク化しました 本サイトのすべての記事が、https://maku.blog/p/XXXXXXX という 7 桁の ID をベースにした URL でアクセスできるようになりました。 これまではサイトの構造が変わると URL が変わってしまいましたが、今後は URL は固定化されるのでリンク切れの心配はありません。 安心して個々のページにリンクを張ってください ٩(๑❛ᴗ❛๑)۶ ちなみにこのページのリンクは https://maku.blog/p/7yhxet9 です。"
},
{
url: "/p/7zgwds7/",
title: "メガドライブミニを買ったよ！完成度高い！",
date: "2019-10-21T00:00:00Z",
body: "メガドライブミニを買ったよ！完成度高い！ ひさびさにいい買い物をしたよー。 『メガドラミニ』 です！ 迷っていたけど、我慢できなくなってポチりました。 あースッキリしたw やっと届いたので開封の儀です。 こちらがパッケージ。わくわく。 ゲームはよりすぐりのものが 40本以上 も入っているのですが、 2 人同時プレイできるものも半分くらい入ってます。 だから、コントローラーは当然 2 個セットをチョイス。 6 ボタンだから、スト2ダッシュプラスの操作性もバッチリです。 箱はとってもコンパクトで、左側にコントローラー2個、右側に本体とケーブルがみっちり詰まってます。 ジャーン。 どうでもいいけど、HDMI ケーブルと USB ケーブルってガジェット買ってるとどんどん溜まってくよね。。。みんなどうしてるんだろう。 あと、本体はともかく、ケーブルや説明書を全部ビニル袋に入れるのは過剰包装ですよね。改善して欲しい。 テレビとは HDMI ケーブルでつないで、電源は USB からの給電です。 うちはソニーの BRAVIA (Android TV) ですが、テレビの USB コネクタから給電できました。AC アダプタとか使わないでいいので配線はとてもスッキリします。 ケーブルは 2 本ともテレビにつなぐので、写真のようにケーブルを束ねちゃいました。 使ったのはコントローラーのケーブルとか束ねてあったやつ。ゴミは出さずに活用♪ 電源スイッチをカチッとスライドすると、すぐにゲーム選択画面になります（^O^) いいっ。 発売日順、ジャンル別、1〜2人用などソート方法もサクッと切り替えられます。 こちらが発売前から話題となっていた、メガドラミニでの新作のダライアス（3画面アーケードを1画面に移植）。 発売日表示も 2019 年になってますね。 PC のエミュレータではこのダライアスは楽しめません。 シューティング好きな人にとっては、このダライアスだけでもメガドラミニを買う価値があるとか。。。 処理落ちもないしスピード速くて難しいけど、とってもシンプルで硬派なシューティングなので、初心者にもオススメです。 コントローラー右上の拡張ボタンか、本体のリセットボタンを押せば、いつでもセーブできる（1ゲームにつき4スロット）ので、これを使ってズルすれば誰でもクリアできます。 こちらは今や不朽の名作となった『ぷよぷよ』の原点である『魔導物語』。 アルルが卒園試験として、塔の中でテストを行います。 オリジナルは MSX というパソコンの雑誌付録（MSXマガジンだったかな？）でしたが、後にメガドライブに移植されました。 戦闘に入ったときに、コマンド選択がないから操作方法がわからなくて困りました。 こんなときは、Web サイトにあるマニュアルを読みます。 メガドライブミニに収録されているゲームソフトの取扱説明書（マニュアル）は こちら から全部見れるようになってます。 マニュアルを見てるだけでおもしろいです。 答えは、A 押しながら魔導コマンド入力でした。 初期の攻撃方法である「ふぁいやー」は、↑←↓→ です。 3D ダンジョンもののゲームは『ウィザードリィ』が有名ですけど、やっぱりちょっと難しい。 でも、この魔導物語はとってもやさしくて誰でも楽しめます。 なんてったって 操作するキャラが園児 ですからね。 ちなみに HP 表示もなく、体力が減るとアルルの表情が眠そうになっていきます。 他にも本腰を入れて楽しめるゲームがたくさん詰まっています。 これはラングリッサーII。 なんかメガドラミニだけで 3 年くらい楽しめそう。 2020年に発売予定の 『PC エンジンミニ』 にも期待したいです。 メガドライブミニ（コントローラー2個セット） セガゲームス"
},
{
url: "/p/nxzsnkf/",
title: "TypeScriptの環境: tsc-watch で ts ファイルの変更監視＆アプリの再起動を自動化する",
date: "2019-10-17T00:00:00Z",
body: "TypeScriptの環境: tsc-watch で ts ファイルの変更監視＆アプリの再起動を自動化する TypeScript の監視と JavaScript の監視の両立 tsc --watch コマンドを使うと、TypeScript (.ts) ファイルの変更を監視して自動的に tsc （トランスパイル）を実行してくれるようになります。 nodemon コマンドを使うと、JavaScript (.js) ファイルの変更を監視して自動的に node コマンドを再起動してくれるようになります。 これらを組みあわせれば、TypeScript (.ts) ファイルの変更時に、自動的に Node.js アプリを再起動できそうな気がしますが、一連のコマンドとしてこれら 2 つを組み合わせて実行するのにはみんな苦労しているようです（もちろんコマンドシェルを 2 つ立ち上げればできますが）。 そこで便利なのが tsc-watch コマンド です。 tsc-watch パッケージでまるごと解決 tsc-watch という NPM パッケージ（コマンド）を使用すると、TypeScript の変更監視と Node アプリの再起動の連動を簡単に行えるようになります。 まず、必要なパッケージを下記のようにインストールします。 nodemon は使わなくて済むので、ここでは依存パッケージとして typescript と tsc-watch をインストールしておきます。 --save-dev オプションを付加して、package.json の devDependencies に登録するのを忘れないようにしましょう。 $ npm install --save-dev typescript $ npm install --save-dev tsc-watch tsc-watch コマンドはほとんど tsc --watch のラッパーなので、そのまま実行すると、TypeScript ファイルの変更を監視してトランスパイルを実行するという動作になります。 これだけの用途であれば tsc コマンドで十分なのですが、tsc-watch コマンドに追加されている --onSuccess オプションを使うと、トランスパイル後に任意の追加コマンドを実行することができます。 この追加コマンドとして npm start などを実行するように設定しておけば、TypeScript のトランスパイル後に Node.js アプリを起動するところまでを自動化することができます。 すでに Node.js アプリが起動している場合は、そのプロセスを終了してから立ち上げ直してくれるので、サーバー系の Node.js アプリを作成している場合も安心です。 下記の package.json では、watch という名前のスクリプトで tsc-watch を実行するように設定しています。 package.json { \u0026#34;private\u0026#34;: true, \u0026#34;scripts\u0026#34;: { \u0026#34;start\u0026#34;: \u0026#34;node build/index.js\u0026#34;, \u0026#34;compile\u0026#34;: \u0026#34;tsc\u0026#34;, \u0026#34;watch\u0026#34;: \u0026#34;tsc-watch --onSuccess \\\u0026#34;npm start\\\u0026#34;\u0026#34; }, \u0026#34;devDependencies\u0026#34;: { \u0026#34;tsc-watch\u0026#34;: \u0026#34;^4.0.0\u0026#34;, \u0026#34;typescript\u0026#34;: \u0026#34;^3.6.4\u0026#34; } } TypeScript の設定ファイルである tsconfig.json の内容も載せておきます。 ここでは、src ディレクトリ内の .ts ファイルをトランスパイルして、生成された .js ファイルを build ディレクトリに出力するようにしています。 tsconfig.json { \u0026#34;compilerOptions\u0026#34;: { \u0026#34;outDir\u0026#34;: \u0026#34;./build\u0026#34;, \u0026#34;target\u0026#34;: \u0026#34;ES2015\u0026#34;, \u0026#34;module\u0026#34;: \u0026#34;commonjs\u0026#34;, \u0026#34;strict\u0026#34;: true }, \u0026#34;include\u0026#34;: [ \u0026#34;./src/**/*\u0026#34; ] } あとは、npm run コマンドで watch スクリプトを実行すれば、TypeScript ファイルの変更監視＆Node.jsアプリの自動再起動の仕組みが作動します。 ts ファイル変更があったら自動でトランスパイルしてアプリを再起動 $ npm run watch 説明は長くなりましたが、実際には packages.json に script.watch プロパティを追加するだけでよいので、とてもお手軽です。 （おまけ） tsc-watch は tsc のラッパー 下記のように、tsc-watch のヘルプを表示してみると、その内容は tsc コマンドのものに独自の拡張を加えたものになっていることがわかります。 $ ./node_modules/.bin/tsc-watch --help Version 3.6.4 Syntax: tsc [options] [file...] Examples: tsc hello.ts tsc --outFile file.js file.ts tsc @args.txt tsc --build tsconfig.json Options: -h, --help Print this message. -w, --watch Watch input files. [always on] --onSuccess COMMAND Run the COMMAND on each successful compilation --onFirstSuccess COMMAND Run the COMMAND on the first successful compilation (Will not run the onSuccess) --onFailure COMMAND Run the COMMAND on each failed compilation --noColors Removes the red/green colors from the compiler output --noClear Prevents the compiler from clearing the screen --compiler PATH The PATH will be used instead of typescript compiler. Defaults typescript/bin/tsc. ...省略... なので、tsc のオプションは tsc-watch のオプションとしても使えるし、tsc コマンドの設定ファイルである tsconfig.json もそのまま使えます。"
},
{
url: "/p/5wdt9n3/",
title: "読書メモ『完全ひとりビジネスを始めるための本』右田正彦",
date: "2019-10-12T00:00:00Z",
body: "読書メモ『完全ひとりビジネスを始めるための本』右田正彦 完全ひとりビジネスを始めるための本 右田正彦 秀和システム 自宅にひきこもりつつも、いかに安定して稼いでいくかについて述べた本です。 ブログのアフィリエイトでの稼ぎ方の話は参考になるのでメモメモ。 テーマを決めて、10 記事中 7 記事はそのテーマで書くとよい 3 ヶ月間は広告を貼らずに記事を書き溜める Wordpress が SEO 対策されていてオススメ（と著者は言ってますが、個人的には Wordpress はいろいろ無駄に苦労することが多いのでオススメしません。本気でやるなら Hugo などの静的な Web サイトジェネレータがオススメ） 毎日 1 記事のペースを保つ（それ以下でもそれ以上でもダメ） 無料のブログサービスは使っちゃダメ 稼ぎやすい 2 つのテーマ コンプレックスの解消 ノウハウの指南 記事は 800 文字程度はあると、Google にも表示されやすくなる タイトルは具体的に 記述する Google で検索するときに表示される サジェストキーワード を参考にタイトルを決める 見せたいキーワードは タイトルの最初の方 に入れる（Google は最初の 32 文字を表示するため） 商品を売るなら、タイトルに商品名を入れる 2 ヶ月目からは過去の記事を見直して リライトする 特定のネタの記事が 4 〜 5 記事くらい溜まったら、まとめ記事 を作る Google アナリティクスでどんな検索ワードで集まって来ているか調べて、タイトルを変更する ブログの理想系は全ての記事がまんべんなく多くの人に読まれている状態になること"
},
{
url: "/p/wx3fvib/",
title: "Azure: Node.js アプリを App Service へデプロイする（Kudu ビルド編）",
date: "2019-10-09T00:00:00Z",
body: "Azure: Node.js アプリを App Service へデプロイする（Kudu ビルド編） Azure App Service には、デプロイセンター という仕組みがあり、そこからソースコードのビルドからデプロイまでの自動化の設定を行うことができます。 簡単に言うと、Azure Repos や GitHub のリポジトリに最新の JavaScript コードをコミットするだけで、最新の Node.js アプリが自動で立ち上がるようになります。 ビルドの仕組みとしては、クラウド上の Azure Pipelines を使ったり、ローカルでビルドしてしまってからデプロイする方法があります。 App Service には Kudu エンジン が組み込まれており、デプロイ時に自動で実行されるスクリプトを使って簡易的なビルド処理を行うこともできます。 はじめに（用語定義） Azure ではデプロイ処理を構成するコンポーネントを下記のような名前で呼んでいます。 デプロイソース GitHub や Azure Repos など。 ソースコードが置いてある場所（リポジトリ）のこと。 Azure App Service は手軽なデプロイソースとして OneDrive や Dropbox などのフォルダ共有サービスを設定することもできますが、本格的な運用で使用することは推奨されていません。 ビルドパイプライン（ビルドプロバイダー） Azure Pipelines など。デプロイソースからソースコードを取得し、一連のビルド処理を行う仕組み。 App Service には組み込みで Kudu エンジンが搭載されており、デフォルトではデプロイ時にこの Kudu エンジンによって npm install などが実行されるようになっています。 また、デプロイ時に実行する カスタムスクリプトを .deployment ファイルで定義する こともできます。 これらの仕組みだけで十分であれば、Azure Pipelines を使う必要はありません。 デプロイメカニズム ビルドしたアプリを Azure App Service などに配置するためのアクション。Kudu エンジンや FTP (SFTP)、WebDeploy などのデプロイメカニズムが提供されています。 リポジトリの準備 (Azure Repos) ここでは、Azure Repos に Git リポジトリを作成し、そこに Node.js アプリのコードをコミットしてあると想定します。 GitHub でも大丈夫です。 参考: Azure DevOps で無料のプライベート Git リポジトリ (Repos) を使用する デプロイセンターの設定 (Azure Repos + Kudu) Azure ポータルからデプロイ先の App Service を選択し、デプロイセンター を開くと、使用するリポジトリやビルドパイプラインの設定を行えます。 まずは、使用するソースコードのリポジトリを設定します。 上記の例では、Azure Repos を選択していますが、GitHub を選択することもできます。 Local Git を選択すると、App Service 内の Git リポジトリに対して、開発者のローカル Git リポジトリから直接 push するというデプロイスタイルになります（そのためのリポジトリアドレスは後から表示されます）。 ただ、大本のソースコードは Azure Repos や GitHub で管理しておくのが望ましいでしょう。 次に、ビルドエンジンとして App Service 組み込みの Kudu の仕組みを使用するか、Azure Pipelines を使用するかを選択します。 ここでは、Kudo を選択します。 あとは使用する Azure DevOps のプロジェクト名や Git リポジトリ名を選択すれば、デプロイセンターの設定は完了です。 ここでは最初のステップで Azure Repos を選択したのでこの画面が表示されていますが、GitHub を選択していれば、GitHub の organization やリポジトリ名を選択する画面が表示されます。 この設定が完了すると、自動的に最新のコミットがデプロイされます。 デプロイ先のディレクトリパスは気にする必要はありませんが、App Service 内部では D:\\home\\site\\wwwroot のようなパスになっています。 Node.js アプリであれば、その後、自動的に npm install などが実行され、index.js などが起動します。 つまり、これだけの設定で、Azure Repos や GitHub のリポジトリにソースコードをデプロイするだけで、最新のコードで Node.js アプリが起動するという自動化が完了します。 （応用） Kudu によるビルド／デプロイ処理 デプロイセンターのログのリンクを辿ると、リポジトリからのコード取得後にどのような処理が行われたかのログを見ることができます。 例えば、こんな感じ。 Command: deploy.cmd Handling node.js deployment. Creating app_offline.htm KuduSync.NET from: \u0026#39;D:\\home\\site\\repository\u0026#39; to: \u0026#39;D:\\home\\site\\wwwroot\u0026#39; Deleting file: \u0026#39;.env\u0026#39; Deleting file: \u0026#39;bot.js\u0026#39; Deleting file: \u0026#39;index.js\u0026#39; Copying file: \u0026#39;.eslintrc.js\u0026#39; Copying file: \u0026#39;.gitignore\u0026#39; Copying file: \u0026#39;iisnode.yml\u0026#39; Copying file: \u0026#39;package-lock.json\u0026#39; Copying file: \u0026#39;package.json\u0026#39; Copying file: \u0026#39;publish.cmd\u0026#39; Copying file: \u0026#39;README.md\u0026#39; Copying file: \u0026#39;tsconfig.json\u0026#39; Deleting file: \u0026#39;mylibs\\util.js\u0026#39; Copying file: \u0026#39;src\\bot.js\u0026#39; Copying file: \u0026#39;src\\index.js\u0026#39; Deleting app_offline.htm Start script \u0026#34;index.js\u0026#34; from package.json The iisnode.yml file explicitly sets nodeProcessCommandLine. Automatic node.js version selection is turned off. Selected npm version 6.4.1 added 1 package from 1 contributor and audited 4520 packages in 37.513s found 62 vulnerabilities (1 low, 1 moderate, 57 high, 3 critical) run `npm audit fix` to fix them, or `npm audit` for details Finished successfully. カスタムデプロイスクリプト (.deployment / deploy.cmd) Kudu は、リポジトリのルートに置かれた .deployment ファイルに従い、デプロイ時にカスタムスクリプトを実行します。 .deployment [config] command = deploy.cmd 通常は、このように記述されており、deploy.cmd というバッチファイルが実行されるようになっています。 これらのファイルは、App Service 用のアプリをテンプレートから作成するとき、あるいは最初に Kudu によるデプロイ処理が走るときに自動的に生成される ようです。 自動生成された deploy.cmd の中身を見てみると、例えば下記のような感じで記述されています。 deploy.cmd（抜粋） :Deployment echo Handling node.js deployment. :: 1. KuduSync IF /I \u0026#34;%IN_PLACE_DEPLOYMENT%\u0026#34; NEQ \u0026#34;1\u0026#34; ( call :ExecuteCmd \u0026#34;%KUDU_SYNC_CMD%\u0026#34; -v 50 -f \u0026#34;%DEPLOYMENT_SOURCE%\u0026#34; -t \u0026#34;%DEPLOYMENT_TARGET%\u0026#34; -n \u0026#34;%NEXT_MANIFEST_PATH%\u0026#34; -p \u0026#34;%PREVIOUS_MANIFEST_PATH%\u0026#34; -i \u0026#34;.git;.hg;.deployment;deploy.cmd\u0026#34; IF !ERRORLEVEL! NEQ 0 goto error ) :: 2. Select node version call :SelectNodeVersion :: 3. Install npm packages IF EXIST \u0026#34;%DEPLOYMENT_TARGET%\\package.json\u0026#34; ( pushd \u0026#34;%DEPLOYMENT_TARGET%\u0026#34; call :ExecuteCmd !NPM_CMD! install --production IF !ERRORLEVEL! NEQ 0 goto error popd ) コード中に出てくる変数には、例えば下記のようなディレクトリのパスが格納されます。 DEPLOYMENT_SOURCE: リポジトリのコード (D:\\home\\site\\repository) DEPLOYMENT_TARGET: デプロイ先のルート (D:\\home\\site\\wwwroot) 大まかには、リポジトリのコードをデプロイ先にコピーしておいて、npm install --production で必要な NPM パッケージをインストールするという流れになっています。 上記の後ろあたりに、 echo Hellooooooooooooooooooooooo のような感じで追記しておくと、デプロイ時にメッセージがログに出力されることを確認できます。 デプロイ時に TypeScript のトランスパイルの実行などを行いたい場合は、下記のように npm run build を実行する感じでしょうか。 この場合は npm install --production となっていた部分を、npm install に変更しておかなければいけません。 tsc などの開発ツールをインストールするためです。 deploy.cmd（抜粋） :: 3. Install npm packages AND transpile TypeScript files IF EXIST \u0026#34;%DEPLOYMENT_TARGET%\\package.json\u0026#34; ( pushd \u0026#34;%DEPLOYMENT_TARGET%\u0026#34; call :ExecuteCmd !NPM_CMD! install IF !ERRORLEVEL! NEQ 0 goto error call :ExecuteCmd !NPM_CMD! run build IF !ERRORLEVEL! NEQ 0 goto error popd ) カスタムデプロイスクリプトのテンプレート Kudu のカスタムデプロイスクリプト（.deployment と deploy.cmd）は、kuduscript コマンドを使って簡単に生成することができます。 下記の例では、Node.js アプリ用のデプロイスクリプトを生成しています。 Node.js アプリ用の Kudu デプロイスクリプトの作成 $ npm install -g kuduscript $ kuduscript --node -y Generating deployment script for node.js Web Site Generated deployment script files 生成されたファイルはこちら。 .deployment deploy.cmd これらのファイルをリポジトリのルートにコミットしておけば、App Service へのデプロイ時に自動的に実行されるようになります。 カスタムデプロイスクリプトが実行されるトリガー ちなみに、オンラインコードエディタ (App Service Editor) 上でコードを直接編集した場合は、.deployment によるカスタムスクリプトは呼び出されないようです。 このあたりの起動条件がはっきりしないので Microsoft さんに問い合わせたところ、下記のようなパターンで Web フックによりカスタムスクリプトがキックされるようです。 App Service の デプロイセンター を設定して継続的なデプロイを有効にした状態でリポジトリに Push したとき App Service の環境変数で SCM_DO_BUILD_DURING_DEPLOYMENT を true に設定し、ZIP デプロイを行ったとき（参考: ZIP または WAR ファイルを使用した Azure App Service へのアプリのデプロイ） いずれにしても継続的デプロイの仕組みがオススメです。 Repos への Push 時にいきなりアプリが公開されてしまうのが心配なときは、App Service で デプロイスロット を設定しておけば OK です。 いわゆるブルーグリーンデプロイメントの仕組みで、ステージング環境を使って事前にテストできるようになります。 Kudu で TypeScript ビルドとかはキツい deploy.cmd あたりをカスタマイズすれば、TypeScript のトランスパイル処理などもこの中でできそう！ と思いましたが、すでにバリバリ記述されているバッチファイルを編集するのは厳しそうです。 そもそもテンプレートで実行されている npm install は --production オプションが指定されており、これはデプロイ後のサーバー上で実行されることを前提としています。 TypeScript のトランスパイラを実行するのであれば、事前に開発用に npm install を実行してインストールしておかなければいけません。 やはり、npm install 以上のビルド処理を行う場合は、別の仕組み (Azure Pipeline) を利用したほうがよさそうです。 結論としては、こんな感じで使い分ければよいと思います。 Kudu ビルド: Git リポジトリに実行可能な index.js などをコミットする場合 Azure Pipelines ビルド: Git リポジトリに TypeScript ファイルなどをコミットし、クラウド上で JavaScript に変換したい場合 Kudu によるビルドは、CI/CD サービスを追加しなくて済むのである意味手軽ですが、実行環境上で初めて実行可能なアプリが生成されるため、どうしてもエイヤッ的なリリースになってしまいます。 また、その最終成果物をそのまま別のサーバーに展開するというポータビリティもありません。 なので、できればビルドとリリースを分離できる Azure Pipelines の使用をオススメするというのが Microsoft さんの見解のようです。 同様の機能を提供しようとしている GitHub Actions も気になりますね。"
},
{
url: "/p/3u4hj7h/",
title: "Azure: App Service の Node.js アプリのエントリポイントはどこで定義されているか？",
date: "2019-10-08T00:00:00Z",
body: "Azure: App Service の Node.js アプリのエントリポイントはどこで定義されているか？ Node.js アプリのエントリポイントの指定 Azure App Service で Node.js アプリをテンプレートから作成すると、うまいことルートに配置された index.js が起動してくれます。 この仕組みがブラックボックスな感じで気持ち悪いので調べてみたところ、このエントリポイントの指定は web.config ファイルにあるようです。 web.config（抜粋） \u0026lt;add name=\u0026#34;iisnode\u0026#34; path=\u0026#34;index.js\u0026#34; verb=\u0026#34;*\u0026#34; modules=\u0026#34;iisnode\u0026#34;/\u0026gt; Windows ベースの App Service で Node.js アプリを動作させる場合、Windows の Web サーバーである IIS 上で動作する iisnode という Node.js 実装が使用されます。 IIS が起動するときに設定ファイルである web.config が読み込まれ、上記の設定により iisnode がエントリポイント index.js を使って起動するという流れになります。 なので、作成している Node.js アプリのエントリポイント（メインの JS ファイル）が変わった場合は、この web.config ファイルを修正する必要があります。 あと、このような仕組みのため、web.config ファイルは必ずアプリを構成する JS ファイルと一緒にデプロイしないといけないということも分かります。 上記の設定のままであれば、デプロイ先のルートディレクトリに、少なくとも下記の 2 ファイルが配置されていなければいけません。 web.config （IIS の設定ファイル） index.js （上記ファイルで指定されたエントリポイント） なぜ紛らわしいのか？ Node.js アプリを開発するとき、通常は package.json の start スクリプトとしてエントリポイントを指定します。 package.json（抜粋） { \u0026#34;scripts\u0026#34;: { \u0026#34;start\u0026#34;: \u0026#34;node index.js\u0026#34; } } こうすることで、npm start と実行するだけで、index.js をエントリポイントとして Node.js アプリが起動するようになっています。 Azure App Service のドキュメント にも、 アプリケーションをローカルで実行すると、アプリケーションを Azure にデプロイするとどう表示されるかを把握できます。ターミナル ウィンドウを開き、npm start スクリプトを使用して、組み込みの Node.js HTTP サーバーを起動します。 と書かれています。 間違ってはいないのですが、こんな風に書かれたら、package.json の scripts.start の定義を変更すれば App Service 上の振る舞いも変わると思うじゃないですか。 ところがどっこい、package.json を修正しても、App Service 上での動作は何も変わりません。 web.config が真犯人だからです。 気をつけましょー。 コラム: PORT 環境変数 Azure App Service 上で Node.js アプリを動作させると、自動的に PORT 環境変数が定義されます。 なので、Node.js アプリ内で Web サーバーを起動させるときは、process.env.PORT に設定されたポート番号を使うようにします。 const server = restify.createServer(); server.listen(process.env.port || process.env.PORT || 3978, () =\u0026gt; { console.log(`Bot server listening on ${ server.port }`); }); App Service にはこういった約束事がいろいろありますね。"
},
{
url: "/p/3eccb2t/",
title: "TypeScriptの環境: 既存の JavaScript プロジェクトを TypeScript に乗り換える",
date: "2019-10-01T00:00:00Z",
body: "TypeScriptの環境: 既存の JavaScript プロジェクトを TypeScript に乗り換える TypeScript プロジェクトへの移行は簡単！ TypeScript の構文は、JavaScript のコードとの互換性を考慮して仕様が決められているため、既存の JavaScript プロジェクトを簡単に TypeScript プロジェクトに移行することができます。 後述するように設定をうまく行えば、JavaScript ファイルの拡張子を .ts に変える必要すらありません。 TypeScript の構文を使わないと意味がないのでは？と思うかもしれませんが、TypeScript のトランスパイラ (tsc) には、強力な静的解析の仕組みが備わっているため、この機能を既存の JavaScript ファイルに適用するだけでも TypeScript を導入する価値があります。 ここでは、tsc コマンドは下記のようにグローバルにインストールしてあることを前提とします。 $ npm install -g typescript おすすめのディレクトリ構成 既存の JavaScript コードを TypeScript トランスパイラ (tsc) の変換対象にする場合は、入力ファイルとなる .js ファイルと、生成される .js ファイルのディレクトリを明確に区別しておくべきです。 そうしておかないと、どのファイルが自分が作成したファイルで、どのファイルが自動生成されたファイルなのか分かりにくくなってしまいます。 ここでは、既存の JavaScript プロジェクトのソースコード (.js) を、下記のように src ディレクトリに格納します。 このディレクトリには、最終的に .js ファイルと .ts ファイルが混在していても構いません。 project/ +-- tsconfig.js （設定ファイル） +-- build/ （出力用ディレクトリ） +-- src/ （入力用ディレクトリ） +-- main.js +-- module1.js +-- module2.js 上記では、src ディレクトリの直下に .js ファイルを入れていますが、ディレクトリ構造を保ったまま入れてしまって大丈夫です。 出力先のディレクトリ (build) には、このディレクトリ階層を再現する形で JavaScript ファイルが出力されます。 build ディレクトリは、下記の設定によって自動的に生成されるので、あらかじめ作成しておく必要はありません。 上記は、最終的な出力後のディレクトリ構成になります（build ディレクトリができるだけですが）。 設定ファイルの作成 (tsconfig.js) 上記のようなディレクトリ構成のプロジェクトを扱うには、例えば下記のような設定ファイルを作成します。 tsconfig.json { \u0026#34;compilerOptions\u0026#34;: { \u0026#34;outDir\u0026#34;: \u0026#34;./build\u0026#34;, \u0026#34;allowJs\u0026#34;: true, \u0026#34;target\u0026#34;: \u0026#34;ES2015\u0026#34;, \u0026#34;module\u0026#34;: \u0026#34;commonjs\u0026#34;, \u0026#34;strict\u0026#34;: true }, \u0026#34;include\u0026#34;: [ \u0026#34;./src/**/*\u0026#34; ] } 今回ポイントとなるのは下記の 3 つのプロパティです。 compilerOptions.outDir: 出力先のディレクトリをプロジェクトルートから build に変更 compilerOptions.allowJs: 入力ファイルとして JavaScript の拡張子 (.js) も対象にする include: 入力ファイルは src ディレクトリ以下のすべての .js および .ts ファイル この設定ファイルを作成したら、あとは src ディレクトリ内に既存の .js ファイルをつっこんで、下記のようにトランスパイルを実行するだけです。 $ tsc これで、変換後の JavaScript ファイルが build ディレクトリに出力されます（今回は元々が JavaScript で記述されたコードなので、生成されるコードにあまり変化はないかもしれません）。 （応用）ビルド用の NPM スクリプトを定義する ここまでは、tsc コマンドを直接実行することで build ディレクトリにトランスパイル後の JavaScript ファイルを出力することを前提としていました。 Node.js でのアプリ開発に使用する package.json には、任意のスクリプトを定義することができるので、ここでは build というスクリプトを定義して一連のビルドを行えるようにしてみましょう。 npm run build と実行したときに、下記のような処理が走るようにしてみます。 build ディレクトリがあれば削除する src ディレクトリ内の TS コードをトランスパイルして build ディレクトリへ出力する static ディレクトリ内のファイルをそのまま build ディレクトリへコピーする（画像ファイルや設定ファイルなどのリソースファイルを想定） 必要な NPM パッケージのインストール まず、ビルドコマンドを構成するために必要な NPM パッケージ群をインストールします。 $ npm install --save-dev typescript # tsc コマンド $ npm install --save-dev rimraf # ディレクトリの削除用コマンド $ npm install --save-dev cpx # ファイルコピー用コマンド $ npm install --save-dev npm-run-all # NPMコマンドの逐次実行 package.json の devDependencies エントリに追加するために、--save-dev オプションを付けて実行してください。 ここではパッケージをひとつずつインストールしていますが、パッケージ名を列挙すればまとめてインストールすることができます。 package.json で build スクリプトを定義する 下記は package.json のスクリプト定義部分の抜粋で、4 つの NPM スクリプトを定義しています。 { \u0026#34;scripts\u0026#34;: { \u0026#34;clean\u0026#34;: \u0026#34;rimraf build\u0026#34;, \u0026#34;build\u0026#34;: \u0026#34;run-s -l clean build:**\u0026#34;, \u0026#34;build:tsc\u0026#34;: \u0026#34;tsc\u0026#34;, \u0026#34;build:static\u0026#34;: \u0026#34;cpx static/** build\u0026#34; }, 次のように build スクリプトを実行すると、 $ npm run build npm-run-all パッケージが提供する run-s コマンドによって、次の NPM スクリプトが逐次実行されます。 -l オプションを付けておくと、ログのプレフィックスとして NPM スクリプト名が表示されてわかりやすくなります。 clean: build ディレクトリの削除 build:tsc: src ディレクトリ内の TypeScript コードのトランスパイル build:static: static ディレクトリ内のファイル群を build へコピー スクリプト名を build:xxx:yyy のような形で階層化しておくと、build:** という形でまとめて指定できるので便利です（グロブパターンで ** の代わりに * を使うと一階層下のみのスクリプトが選択されます）。 これらの NPM スクリプトは単独で実行することもできます。 $ npm run clean ここで使用している各種 NPM パッケージの使い方は、下記のサイトを参考にするとよいです。 参考: まくまく Node.js ノート その他の調整 Node.js などで開発している場合は、プロジェクトのディレクトリに package.json などが存在すると思います。 今回の修正により、最終的な生成物が build ディレクトリ以下に配置されることになるので、必要に応じて package.json 内に記述されたファイルパスを修正する必要があるかもしれません。 下記の例では、npm start で起動するスクリプトファイルとして build ディレクトリ以下の JS ファイルを参照するように修正しています。 package.json（抜粋） { \u0026#34;scripts\u0026#34;: { \u0026#34;start\u0026#34;: \u0026#34;node build/index.js\u0026#34;, あるいは、ルートの index.js から、build/index.js のメイン関数を呼び出すようにしておくのもよいかもしれません。 index.js（ルートの） require(\u0026#39;./build/index.js\u0026#39;).main(); build/index.js // エントリポイント function main() { // ... } // ルートの index.js からも起動できるように exports.main = main; // 自分自身がエントリポイントとなったときに起動できるように if (require.main === module) { main(); } こうしておけば、package.json の中の scripts.start の定義は node index.js のままでも起動できます。"
},
{
url: "/p/qapsyfa/",
title: "3D",
date: "2019-09-19T00:00:00Z",
body: "3D"
},
{
url: "/p/xwfwdy6/",
title: "GitHub Pages は早く Jekyll から Hugo に乗り換えるべき",
date: "2019-09-12T00:00:00Z",
body: "GitHub Pages は早く Jekyll から Hugo に乗り換えるべき GitHub Pages は HTML ジェネレーターとして昔から Jekyll を採用しているのですが、Jekyll ははっきり言って遅すぎるし、ある程度のサイト規模になると使い物になりません。 セットアップもいろいろなライブラリの依存があって複雑です。 バージョンアップのたびにストレスが溜まります。 世の中には爆速なサイトジェネレーターの Hugo があります。 Jekyll では Web サイトが数千ページ規模になってくると、1 つの記事を 1 文字変更しただけで再ビルドに何分もかかります。 一方、Hugo であれば少なくとも数秒で終わります。 Hugo は爆速なだけでなく、実行環境も 1 バイナリだけ（Windows であれば hugo.exe のみ）で、導入もバージョンアップもストレスフリーです。 開発者の Bjørn Erik Pedersen 氏がめちゃくちゃやる気があるので、常に進化を続けていて、テンプレートファイルも柔軟にカスタマイズできます。 GitHub Pages は一刻も早く Jekyll から Hugo に乗り換えるべきだと思います。 移行にはある程度痛みを伴うかもしれませんが、ユーザーも GitHub 社（Microsoft により買収済み）も幸せになれるはずです。"
},
{
url: "/p/9xv5548/",
title: "Jekyll",
date: "2019-09-12T00:00:00Z",
body: "Jekyll"
},
{
url: "/p/6ez7nuf/",
title: "Jekyll (GitHub Pages) でページの最終更新日を表示する",
date: "2019-09-12T00:00:00Z",
body: "Jekyll (GitHub Pages) でページの最終更新日を表示する Jekyll では、HTML ファイルを生成するために Markdown 形式で記事を作成するのですが、先頭のフロントマターと呼ばれる部分に任意の変数を定義することができます。 下記の例には、記事の作成日 (date) と、最終更新日 (lastmod) を入れてあります。 sample.md ---title:\u0026#34;ページタイトル\u0026#34;date:\u0026#34;2015-01-01\u0026#34;lastmod:\u0026#34;2019-09-12\u0026#34;---本文... これらの情報をレイアウトファイルから参照するには、下記のようにします。 ここでは、最終更新日 (lastmod) の情報があればそちらを、なければ作成日 (date) を表示するようにしています。 フロントマターでの lastmod の指定はオプショナル扱いということです。 {% if page.lastmod %} {% assign lastmod = page.lastmod %} {% else %} {% assign lastmod = page.date %} {% endif %} \u0026lt;span class=\u0026#34;date\u0026#34;\u0026gt;{{ lastmod }}\u0026lt;/span\u0026gt; HTML5 の time 要素や、schema.org の構造化データマークアップを使ってちゃんと SEO 対策するのであれば、下記のような感じでテンプレートを作成するのがよいでしょう。 default.html（抜粋） {% if page.lastmod %} {% assign lastmod = page.lastmod %} {% else %} {% assign lastmod = page.date %} {% endif %} \u0026lt;article itemscope itemtype=\u0026#34;https://schema.org/BlogPosting\u0026#34;\u0026gt; \u0026lt;header\u0026gt; \u0026lt;h1 itemprop=\u0026#34;headline\u0026#34;\u0026gt;{{ page.title }}\u0026lt;/h1\u0026gt; \u0026lt;span\u0026gt;最終更新: \u0026lt;time itemprop=\u0026#34;dateModified\u0026#34; datetime=\u0026#34;{{ lastmod }}\u0026#34;\u0026gt;{{ lastmod }}\u0026lt;/time\u0026gt; \u0026lt;/span\u0026gt; \u0026lt;/header\u0026gt; \u0026lt;div itemprop=\u0026#34;articleBody\u0026#34;\u0026gt; {{ content }} \u0026lt;/div\u0026gt; \u0026lt;/article\u0026gt; 参考: HTML5 の time 要素の正しい使い方"
},
{
url: "/p/twmzpfj/",
title: "WebGL で使う Typed Array",
date: "2019-09-11T00:00:00Z",
body: "WebGL で使う Typed Array Typed Array とは JavaScript の配列型には、汎用型の Array の他にも、Int32Array のような、特定の型の値だけしか格納できない配列型が用意されています。 このような配列型のことを Typed Array と呼びます。 イメージとしては、C 言語の int 配列や float 配列に近いです。 例えば、WebGL で頂点属性（座標や色）の配列を用意するようなケースでは、その中の要素の型はすべて float 型に統一されていたりするので、汎用型の Array ではなく、Float32Array を使用することでメモリ効率がよくなります。 Typed Array には下記のようなものが用意されています。 型名 バイト数 値の範囲 説明（対応するC言語の型） Int8Array 1 -128 ～ 127 8-bit sined integer (int8_t) Uint8Array 1 0 ～ 255 8-bit unsigned integer (uint8_t) Int16Array 2 -32768 ～ 32767 16-bit signed integer (int16_t) Uint16Array 2 0 ～ 65535 16-bit unsigned integer (uint16_t) Int32Array 4 -2147483648 ～ 2147483647 32-bit signed integer (int32_t) Uint32Array 4 0 ～ 4294967295 32-bit unsinged integer (uint32_t) Float32Array 4 1.2x10-38 ～ 3.4x1038 32-bit floating point number (float) Float64Array 8 5.0x10-324 ～ 1.8x10308 64-bit floating point number (double) Typed Array の使い方 Typed Array インスタンスは、型名をコンストラクタとして呼び出すことで生成することができます。 配列リテラルの形で初期値を指定することもできるし、サイズだけ指定してすべての要素が 0 に初期化された Typed Array を作成することもできます。 const arr2 = new Int32Array([0, 1, 2]); // 初期値を指定 const arr1 = new Int32Array(3); // デフォルト値の3要素 = [0, 0, 0] Typed Array は通常の配列と同様に使用できますが、push() や pop() のようなサイズ変更を伴う操作はできないようになっています（このあたりも C 言語の配列に近いです）。 その分、効率を重視しているということですね。 const arr = new Int32Array(3); arr[0] = 777; // 既存要素の値を変えることは可能 console.log(arr); //=\u0026gt; [777, 0, 0] arr.push(888); // Error! Typed Array の要素数は length プロパティ、要素 1 つあたりのサイズ（バイト数）は BYTES_PER_ELEMENT で取得することができます。 また、全要素が占めるバイト数 (length * BYTES_PER_ELEMENT) は、byteLength プロパティで取得することができます。 const arr = new Float32Array([0.0, 1.0, 2.0]); console.log(arr.length); //=\u0026gt; 3 console.log(arr.BYTES_PER_ELEMENT); //=\u0026gt; 4 console.log(arr.byteLength); //=\u0026gt; 12"
},
{
url: "/p/3w27afe/",
title: "読書メモ『ヴァーチャリアン嘘つかない』渡辺浩弐",
date: "2019-09-01T00:00:00Z",
body: "読書メモ『ヴァーチャリアン嘘つかない』渡辺浩弐 ヴァーチャリアン嘘つかない ― マルチメディアの正体を暴く 渡辺浩弐 メディアワークス 渡辺コージィさんの 25 年前の本。 ちょうどバブル崩壊の頃ですね。 最近発売された 『令和元年のゲーム・キッズ』 とか、コージィさんのゲームキッズシリーズは面白いので、別の著書も読んでみようと思ってブックオフでげっちゅして読んでみました。 マルチメディアやゲームの目指すべき方向性みたいなことを書いた本なのですが、思ったよりすごい内容ですね。 先見性がすごい。。。じゃなくて、下品さがすごい（笑）。 まさに昭和時代の下品さ。 コージィさんといえば、「大竹まことのただいま！PCランド」のイメージが強いんですけど、大竹さんの影響かなｗ でも、ゲームってどうあるべきか、っていう意見はまともです。 「気持ち良さ」だけを残して「辛さ」や「難しさ」は省いてやることが大切 画面の中のものを自分の手で押して引いてみたときの純粋な気持ち良さが、ゲーム的な快楽の原点だ ゲームとは現実を超える擬似現実を作り出すもの 企画書を書くべきではない！体面やお行儀を気にした試作品を作らず、いきなり商品を作ることが大事 Netflix で電脳社会をテーマにしたブラックミラーという一話完結型のドラマをやっていますが、ゲームキッズが原点ですよね（´・ω・｀)"
},
{
url: "/p/itkdix9/",
title: "WebGL で シェーダーコードを分離する方法",
date: "2019-08-18T00:00:00Z",
body: "WebGL で シェーダーコードを分離する方法 解決したいこと WebGL で使用する頂点シェーダーとフラグメントシェーダーの GLSL ES コードは単純な文字列データであればよいので、下記のように JavaScript のコードに埋め込んでしまう方法が最初に思いつきます。 const VSHADER_CODE = ` void main() { gl_Position = vec4(0.0, 0.0, 0.0, 1.0); gl_PointSize = 10.0; }`; const FSHADER_CODE = ` void main() { gl_FragColor = vec4(0.0, 1.0, 0.0, 1.0); }`; しかし、これだとアプリ側のコードとシェーダーのコードが混ざってしまうので美しくありません。 ここでは、シェーダーコードを分離するいくつかの方法を示します。 script 要素内にシェーダーコードを埋め込む方法 下記のような感じで、頂点シェーダーとフラグメントシェーダー用の script 要素を用意して、そこにコードを埋め込んでしまう方法です。 HTML 抜粋 \u0026lt;script id=\u0026#34;vshader\u0026#34; type=\u0026#34;x-shader/x-vertex\u0026#34;\u0026gt; void main() { gl_Position = vec4(0.0, 0.0, 0.0, 1.0); gl_PointSize = 10.0; } \u0026lt;/script\u0026gt; \u0026lt;script id=\u0026#34;fshader\u0026#34; type=\u0026#34;x-shader/x-fragment\u0026#34;\u0026gt; void main() { gl_FragColor = vec4(0.0, 1.0, 0.0, 1.0); } \u0026lt;/script\u0026gt; それぞれのシェーダーコードは、JavaScript コードで下記のようにして取り出すことができます。 const vsCode = document.getElementById(\u0026#39;vshader\u0026#39;).textContent; const fsCode = document.getElementById(\u0026#39;fshader\u0026#39;).textContent; import でシェーダーファイルを読み込む方法 ECMAScript 2015 (ES6) の import 構文 を使用すると、別ファイルとして保存した JavaScript ファイルを読み込むことができます。 import { VS_CODE, FS_CODE } from \u0026#39;shaders.js\u0026#39;; 例えば、下記のように個別の JS ファイルとしてシェーダーコードを保存しておければ、少なくともアプリ側の JS コードにシェーダーコードが埋もれてしまうことは防ぐことができます。 shaders.js // Vertex Shader export const VS_CODE = ` void main() { gl_Position = vec4(0.0, 0.0, 0.0, 1.0); gl_PointSize = 10.0; } `; // Fragment Shader export const FS_CODE = ` void main() { gl_FragColor = vec4(0.0, 1.0, 0.0, 1.0); } `; import を使用するスクリプトの \u0026lt;script\u0026gt; タグには、type=\u0026quot;module\u0026quot; を指定しておく必要があります。 \u0026lt;script type=\u0026#34;module\u0026#34;\u0026gt; import { VS_CODE, FS_CODE } from \u0026#39;./shaders.js\u0026#39;; // ... const shader = gl.createShader(gl.VERTEX_SHADER); gl.shaderSource(shader, VS_CODE); gl.compileShader(shader); // ... \u0026lt;/script\u0026gt; メインスクリプトを JavaScript ファイルに分離するのであれば次ような感じ。 \u0026lt;script type=\u0026#34;module\u0026#34; src=\u0026#34;./main.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt;"
},
{
url: "/p/sfpwow9/",
title: "Python で OpenGL (1) pyGLFW のインストール",
date: "2019-08-16T00:00:00Z",
body: "Python で OpenGL (1) pyGLFW のインストール Python で簡単に Open GL のプログラムを開発できるように、GLFW (pyGLFW) というライブラリを使用するための環境構築をしてみます。 GLFW とは Khronos グループが作成している OpenGL や OpenGL ES、Vulkan などの API を使用すると、クラスプラットフォームな 3D プログラムを作成することができます。 ただし、OS ごとにウィンドウの作成方法やキーハンドリングの方法は異なっているため、その部分は個別に作成する必要があります。 GLFW は、そのあたりの OS 依存の処理を抽象化するためラッパーライブラリで、Windows、macOS、Linux などのデスクトップ環境に対応しています。 GLFW 本家は C 言語用のライブラリとして作成していますが、Python 用のラッパーライブラリ (pyGLFW) も公開されています。 昔は GLUT というライブラリがよく使われていましたが、今はもうメンテナンスされていないので、GLFW を使います。 pyGLFW (glfw) のインストール ここでは、Python 用の GLFW ラッパーライブラリである、pyGLFW (glfw) パッケージ をインストールします。 Python 用ライブラリ glfw のインストール Python 用の glfw パッケージは pip コマンドで簡単にインストールできます。 システム全体の環境に影響しないようにするには、virtualenv を使って仮想環境を構築 してからインストールするのがよいでしょう。 virtualenv で仮想環境に切り替える場合 $ mkdir sample $ virtualenv ENV $ source ENV/bin/activate glfw のインストール $ pip install glfw ランタイムライブラリのインストール glfw を使用したプログラムを実行するには、各 OS ごとに用意されたランタイムライブラリ (Shared library) もインストールしておく必要があります。 macOS の場合 $ brew install glfw3 Ubuntu/Debian の場合 $ sudo apt-get install -y libglfw3-dev Fedora/Red Hat の場合 $ sudo yum install -y libglfw3-dev Windows の場合は、本家のサイト から DLL ファイルを含んだアーカイブをダウンロードし、GLFW_LIBRARY 環境変数で DLL のパスを指定します。 ランタイムライブラリがインストールされていない状態で、glfw を使用したプログラムを実行しようとすると、下記のようなエラーが発生します。 ImportError: Failed to load GLFW3 shared library. GLFW で Hello World 下記は、GLFW (pyGLFW) を使ってウィンドウを表示するだけの簡単なプログラムです。 main.py import glfw def main(): # Initialize glfw if not glfw.init(): raise RuntimeError(\u0026#39;Could not initialize GLFW3\u0026#39;) # Create a windowed mode window and its OpenGL context window = glfw.create_window(320, 240, \u0026#39;Hello World\u0026#39;, None, None) if not window: glfw.terminate() raise RuntimeError(\u0026#39;Could not create an window\u0026#39;) # Make the window\u0026#39;s context current glfw.make_context_current(window) # Loop until the user closes the window while not glfw.window_should_close(window): # Render here, e.g. using pyOpenGL # Swap front and back buffers glfw.swap_buffers(window) # Poll for and process events glfw.poll_events() # Proper shutdown glfw.terminate() if __name__ == \u0026#34;__main__\u0026#34;: main() 次のように実行すると、空っぽのウィンドウが表示されます。 $ python main.py 図: GLFW でウィンドウ表示"
},
{
url: "/p/665rua3/",
title: "Python で OpenGL (2) PyOpenGL のインストール",
date: "2019-08-16T00:00:00Z",
body: "Python で OpenGL (2) PyOpenGL のインストール PyOpenGL とは 前回の記事 では、pyGLFW を使ってウィンドウを表示するところまで行きました。 ただし、pyGLFW がやってくれるのは、ウィンドウの作成や、そのサーフェスに描画するための OpenGL コンテキストを生成するところまでです。 実際に OpenGL コンテキストを使ってレンダリングするには、OpenGL の API が必要です。 そのためのライブラリが PyOpenGL パッケージ です。 PyOpenGL のインストール PyOpenGL パッケージも pyGLFW と同様、pip コマンドで簡単にインストールすることができます。 $ pip install PyOpenGL PyOpenGL で Hello World 下記のサンプルコードは、pyGLFW (glfw) パッケージを使ってウィンドウの初期化を行い（main()）、PyOpenGL (OpenGL) パッケージを使って OpenGL の API を呼び出しています（render()）。 main.py import glfw from OpenGL.GL import * def render(): glClearColor(0, 0, 0.5, 1.0) glClear(GL_COLOR_BUFFER_BIT) def main(): if not glfw.init(): raise RuntimeError(\u0026#39;Could not initialize GLFW3\u0026#39;) glfw.window_hint(glfw.CONTEXT_VERSION_MAJOR, 3) glfw.window_hint(glfw.CONTEXT_VERSION_MINOR, 3) glfw.window_hint(glfw.OPENGL_FORWARD_COMPAT, GL_TRUE) glfw.window_hint(glfw.OPENGL_PROFILE, glfw.OPENGL_CORE_PROFILE) window = glfw.create_window(320, 240, \u0026#39;Hello World\u0026#39;, None, None) if not window: glfw.terminate() raise RuntimeError(\u0026#39;Could not create an window\u0026#39;) glfw.make_context_current(window) while not glfw.window_should_close(window): render() glfw.swap_buffers(window) glfw.poll_events() glfw.terminate() if __name__ == \u0026#34;__main__\u0026#34;: main() ここでは、glClear() しているだけなので、背景がクリアされるだけです。 背景色は glClearColor() で暗めの青に設定しています。 $ python main.py"
},
{
url: "/p/5zx3ozz/",
title: "Azure Speech Service を使って音声をテキストに変換する (STT)",
date: "2019-07-24T00:00:00Z",
body: "Azure Speech Service を使って音声をテキストに変換する (STT) Microsoft の Cognitive Services のひとつとして提供されている Speech Service を使用すると、音声をテキストに変換したり、逆にテキストを音声に変換したりすることができます。 ここでは、Python から Speech Service の機能を利用してみます（Windows 10 で動作確認済）。 実行するにはマイクのついた PC が必要です マイクのついていない PC で実行すると SPXERR_MIC_NOT_AVAILABLE エラーが発生します。 準備 Speech Service の準備 Azure Portal から Speech のリソースを作成し、Subscription Key を取得しておいてください。 Speech SDK のインストール Python の azure-cognitiveservices-speech パッケージをインストールします。 $ pip install azure-cognitiveservices-speech Visual Studio C++ Redistributable のインストール 必要があれば、Visual Studio C++ の再頒布可能パッケージをインストールします。 Visual C++ 再頒布可能パッケージ (vc_redist.x64.exe) Python コード 一回だけ変換して終わるバージョン stt.py import azure.cognitiveservices.speech as speechsdk # この設定は適宜変更してください subscription = \u0026#34;e1b5f0964ab743133b7de4f892741c7a\u0026#34; region = \u0026#34;japaneast\u0026#34; language = \u0026#34;ja-JP\u0026#34; # proxy = (\u0026#34;proxy.example.com\u0026#34;, 8888, \u0026#34;\u0026#34;, \u0026#34;\u0026#34;) # SpeechConfig オブジェクトを生成します speech_config = speechsdk.SpeechConfig( subscription=subscription, region=region, speech_recognition_language=language) if \u0026#39;proxy\u0026#39; in locals(): speech_config.set_proxy(*proxy) # SpeechRecognizer インスタンスを生成します recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config) print(\u0026#34;何かしゃべってください\u0026#34;) result = recognizer.recognize_once() if result.reason == speechsdk.ResultReason.RecognizedSpeech: print(\u0026#34;「{}」\u0026#34;.format(result.text)) elif result.reason == speechsdk.ResultReason.NoMatch: print(\u0026#34;No speech could be recognized: {}\u0026#34;.format(result.no_match_details)) elif result.reason == speechsdk.ResultReason.Canceled: cancellation_details = result.cancellation_details print(\u0026#34;Speech Recognition canceled: {}\u0026#34;.format(cancellation_details.reason)) if cancellation_details.reason == speechsdk.CancellationReason.Error: print(\u0026#34;Error details: {}\u0026#34;.format(cancellation_details.error_details)) 繰り返し入力を受け付けるバージョン こちらのバージョンは、Ctrl+C でプログラムを停止するまで、繰り返しユーザーの入力（発話）を受け付けます。 stt-loop.py import azure.cognitiveservices.speech as speechsdk # この設定は適宜変更してください subscription = \u0026#34;e1b5f0964ab743133b7de4f892741c7a\u0026#34; region = \u0026#34;japaneast\u0026#34; language = \u0026#34;ja-JP\u0026#34; # proxy = (\u0026#34;proxy.example.com\u0026#34;, 8888, \u0026#34;\u0026#34;, \u0026#34;\u0026#34;) # SpeechConfig オブジェクトを生成します speech_config = speechsdk.SpeechConfig( subscription=subscription, region=region, speech_recognition_language=language) if \u0026#39;proxy\u0026#39; in locals(): speech_config.set_proxy(*proxy) # SpeechRecognizer インスタンスを生成します recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config) # 非同期に返された認識結果を出力します recognizer.recognized.connect(lambda evt: print(\u0026#39;「{}」\u0026#39;.format(evt.result.text))) recognizer.session_started.connect(lambda evt: print(\u0026#39;SESSION STARTED: {}\u0026#39;.format(evt))) recognizer.session_stopped.connect(lambda evt: print(\u0026#39;SESSION STOPPED {}\u0026#39;.format(evt))) try: print(\u0026#34;何かしゃべってください\u0026#34;) recognizer.start_continuous_recognition() import time time.sleep(100000) except KeyboardInterrupt: print(\u0026#34;バイバイ\u0026#34;) recognizer.recognized.disconnect_all() recognizer.session_started.disconnect_all() recognizer.session_stopped.disconnect_all() 実行 スクリプトを起動すると、「何かしゃべってください」と表示されるので、マイクに向かってしゃべると、その言葉が STT によりテキストに変換されて表示されます。 下記は、「こんにちは」としゃべった場合の出力例です。 C:\\\u0026gt; python stt.py 何かしゃべってください 「こんにちは。」 参考資料 ここの解説は下記のサンプルコードを参考にしています。 cognitive-services-speech-sdk/quickstart/python at master · Azure-Samples/cognitive-services-speech-sdk"
},
{
url: "/p/7qer4dw/",
title: "Blender で猫とたわむれる",
date: "2019-07-12T00:00:00Z",
body: "Blender で猫とたわむれる うちは賃貸でネコが飼えないので、Unity のアセットとして販売されている Cu Cat を Blender に取り込んで遊ぶ。 きゃわいー。 なでれないけど。 これをうまく動かせるようになりたいなぁ。 3D は難しいけど面白いです。 これからは 3D の技術が重要になってくる予感。"
},
{
url: "/p/raw875t/",
title: "受賞作リスト",
date: "2019-06-19T00:00:00Z",
body: "受賞作リスト"
},
{
url: "/p/yhuuddz/",
title: "直木賞の受賞作品リスト",
date: "2019-06-19T00:00:00Z",
body: "直木賞の受賞作品リスト 直木賞は、無名・新人または中堅作家による、短編および長編の大衆小説に与えられる文学賞です。 新聞、雑誌（同人雑誌を含む）に掲載されたものも対象になります。 下記は 2000 年から現在までの直木賞の一覧（新しい順）です。 文庫版が出ているものは、なるべく文庫版へのリンクを張るようにしています（リーズナブルなので）。 たまには文学もたしなまなきゃね(๑･㉨･๑) 回 受賞年 作品名 受賞者 160 2018年下期 『宝島』 真藤順丈 159 2018年上期 『ファーストラヴ』 島本理生 158 2017年下期 『銀河鉄道の父』 門井慶喜 157 2017年上期 『月の満ち欠け』 佐藤正午 156 2016年下期 『蜜蜂と遠雷』 恩田陸 155 2016年上期 『海の見える理髪店』 荻原浩 154 2015年下期 『つまをめとらば』 青山文平 153 2015年上期 『流』 東山彰良 152 2014年下期 『サラバ！(上)』 『サラバ！(中)』 『サラバ！(下)』 西加奈子 151 2014年上期 『破門』 黒川博行 150 2013年下期 『恋歌（れんか）』 朝井まかて 『昭和の犬』 姫野カオルコ 149 2013年上期 『ホテルローヤル』 桜木紫乃 148 2012年下期 『何者』 朝井リョウ 『等伯(上)』 『等伯(下)』 安部龍太郎 147 2012年上期 『鍵のない夢を見る』 辻村深月 146 2011年下期 『蜩ノ記（ひぐらしのき）』 葉室麟 145 2011年上期 『下町ロケット』 池井戸潤 144 2010年下期 『漂砂（ひょうさ）のうたう』 木内昇 『月と蟹』 道尾秀介 143 2010年上期 『小さいおうち』 中島京子 142 2009年下期 『ほかならぬ人へ』 白石一文 『廃墟に乞う』 佐々木譲 141 2009年上期 『鷺と雪』 北村薫 140 2008年下期 『悼む人(上)』 『悼む人(下)』 天童荒太 『利休にたずねよ』 山本兼一 139 2008年上期 『切羽（きりは）へ』 井上荒野 138 2007年下期 『私の男』 桜庭一樹 137 2007年上期 『吉原手引草』 松井今朝子 136 2006年下期 なし 135 2006年上期 『まほろ駅前多田便利軒』 三浦しをん 『風に舞いあがるビニールシート』 森絵都 134 2005年下期 『容疑者Ｘの献身』 東野圭吾 133 2005年上期 『花まんま』 朱川湊人 132 2004年下期 『対岸の彼女』 角田光代 131 2004年上期 『空中ブランコ』 奥田英朗 『邂逅の森』 熊谷達也 130 2003年下期 『号泣する準備はできていた』 江國香織 『後巷説百物語』 京極夏彦 129 2003年上期 『4TEEN フォーティーン』 石田衣良 『星々の舟』 村山由佳 128 2002年下期 なし 127 2002年上期 『生きる』 乙川優三郎 126 2001年下期 『あかね空』 山本一力 『肩ごしの恋人』 唯川恵 125 2001年上期 『愛の領分』 藤田宜永 124 2000年下期 『ビタミンF』 重松清 『プラナリア』 山本文緒 123 2000年上期 『GO』 金城一紀 『虹の谷の五月(上)』 『虹の谷の五月(下)』 船戸与一 芥川賞のリストはこちら"
},
{
url: "/p/89d6c4p/",
title: "芥川賞の受賞作品リスト",
date: "2019-06-19T00:00:00Z",
body: "芥川賞の受賞作品リスト 芥川賞は、優れた純文学を書いた新人に与えられる文学賞です。 新人作家による発表済みの短編・中編作品が対象です。 大衆文学を対象にした直木賞に比べると、芥川賞は純文学を対象としているので、より芸術性を考慮して受賞作が決定されています。 下記は 2000 年から現在までの芥川賞の一覧（新しい順）です。 文庫版が出ているものは、なるべく文庫版へのリンクを張るようにしています（リーズナブルなので）。 たまには文学もたしなまなきゃね(๑･㉨･๑) 回 受賞年 作品名 受賞者 160 2018年下期 『ニムロッド』 上田岳弘 『1R（いちらうんど）1分34秒』 町屋良平 159 2018年上期 『送り火』 高橋弘希 158 2017年下期 『百年泥』 石井遊佳 『おらおらでひとりいぐも』 若竹千佐子 157 2017年上期 『影裏（えいり）』 沼田真佑 156 2016年下期 『しんせかい』 山下澄人 155 2016年上期 『コンビニ人間』 村田沙耶香 154 2015年下期 『異類婚姻譚（いるいこんいんたん）』 本谷有希子 『死んでいない者』 滝口悠生 153 2015年上期 『火花』 又吉直樹 『スクラップ・アンド・ビルド』 羽田圭介 152 2014年下期 『九年前の祈り』 小野正嗣 151 2014年上期 『春の庭』 柴崎友香 150 2013年下期 『穴』 小山田浩子 149 2013年上期 『爪と目』 藤野可織 148 2012年下期 『ａｂさんご』 黒田夏子 147 2012年上期 『冥土めぐり』 鹿島田真希 146 2011年下期 『共喰い』 田中慎弥 『道化師の蝶』 円城塔 145 2011年上期 なし 144 2010年下期 『苦役列車』 西村賢太 『きことわ』 朝吹真理子 143 2010年上期 『乙女の密告』 赤染晶子 142 2009年下期 なし 141 2009年上期 『終の住処』 磯崎憲一郎 140 2008年下期 『ポトスライムの舟』 津村記久子 139 2008年上期 『時が滲む朝』 楊逸 138 2007年下期 『乳と卵』 川上未映子 137 2007年上期 『アサッテの人』 諏訪哲史 136 2006年下期 『ひとり日和』 青山七恵 135 2006年上期 『八月の路上に捨てる』 伊藤たかみ 134 2005年下期 『沖で待つ』 絲山秋子 133 2005年上期 『土の中の子供』 中村文則 132 2004年下期 『グランド･フィナーレ』 阿部和重 131 2004年上期 『介護入門』 モブ・ノリオ 130 2003年下期 『蹴りたい背中』 綿矢りさ 『蛇にピアス』 金原ひとみ 129 2003年上期 『ハリガネムシ』 吉村萬壱 128 2002年下期 『しょっぱいドライブ』 大道珠貴 127 2002年上期 『パーク・ライフ』 吉田修一 126 2001年下期 『猛スピードで母は』 長嶋有 125 2001年上期 『中陰の花』 玄侑宗久 124 2000年下期 『熊の敷石』 堀江敏幸 『聖水』 青来有一 123 2000年上期 『花腐し』 松浦寿輝 『きれぎれ』 町田康 直木賞のリストはこちら"
},
{
url: "/p/8o74agi/",
title: "読書メモ『嶋浩一郎のアイデアのつくり方』",
date: "2019-06-12T00:00:00Z",
body: "読書メモ『嶋浩一郎のアイデアのつくり方』 嶋浩一郎のアイデアのつくり方 嶋浩一郎 ディスカヴァー・トゥエンティワン ジェームス・ウェブ・ヤングの『アイデアのつくり方』 とは別の本です。 こちらは、博報堂ケトルというクリエイティブ・エージェンシーで働いている嶋浩一郎さんがアイデアの生み出し方についてまとめた本です。 情報はまとめずに、手書きの手帳に書いていくのがよい、と主張されています。 情報は分類せずに放牧する、という表現も使っています。 情報は分類すると死んでしまう。情報を放牧するとアイデアが生まれる。 手帳ならページをめくりながら情報と情報を交配させていくことができる。 だから、情報は分類せずに、ぐちゃぐちゃに目の前に羅列しておく方がよい。 10 年前のメモを読み返したりもするので、丈夫なモールスキン（モレスキン）を使っているのだとか。 という私もなんだかんだ言って、10 年分以上の手帳はたまってたりします。。。 嶋さんはアイデアの作り方を 3 ステップにまとめています。 情報収集 放牧 化学変化 下記はそれぞれのステップのまとめです。 ステップ1: 情報収集 情報はとにかく集める！ 本で読んだこと 人から聞いた話 テレビやラジオで耳にしたこと レストランで隣のカップルが話していたこと 会議中の雑談 映画や街の風景 集める情報には 5 つの方向性がある 事実 (FACT) \u0026hellip; あなたの知らなかった事実。 意見 (OPINION) \u0026hellip; 新聞の投稿欄、会議、立ち話、他人の会話など、斬新な意見だと思ったネタ。 分析 (ANALYSIS) \u0026hellip; 今まで見聞きしなかったユニークな分析。 示唆・疑問 \u0026hellip; 意見や分析ほど定かではないが、何か示唆を感じさせる情報。「〜かもしれない」といった推測を含ませるもの。 表現 \u0026hellip; これは使える！と思える文章表現や、たとえ、比喩、名言、格言、広告のキャッチコピー。 情報源を明記する 集める情報が 5 つのうちにどれに当たるのかはいちいち考えなくてもいい。 ただし、情報源はしっかり記録しておく。 最終的にその情報を使うときに検証するため。 情報は差別しない 情報には一流も三流もなく、すべて等価。 無差別に集めればよい。 芸能ゴシップ、考古学の発見、同人誌、どの情報も同様に扱ってよい。 二軍ノートを用意する まず、第一ステップとして「二軍ノート」に時系列にどんどん書き込んでいく。 無駄だと思ってもとにかくメモしておく。 ステップ2: 放牧 3ヶ月前に書いたネタと、今日書いたネタ、まったく関係ない話が突然つながることが多々ある。 ステップ 1 で二軍ノートに書いたネタの中から、これは面白い、興味深いと思ったものをセレクトし、「一軍ノート」にデビューさせる。 このときも分類したりせず、順番に書いていくだけ。 単純にナンバーだけ振っておけばよい。 一軍ノートに書き写すときには 2 つのコツがある。 すぐに書き写さず、二軍ノートの情報は 1 ヵ月くらい寝かせておく。1 ヵ月後にもう一度思い出してみる。 書き写すときに「おまけ情報」としてウィキペディアなどで調べた情報を付けておくと記憶に残りやすくなり、情報自体が楽しいものになる。 ステップ3: 化学変化 手帳のメモが化学変化を起こし、「雑談力」「プレゼン力」「企画力」となって現れてくる。 整理されていない情報があると落ち着かないかもしれないが、それは情報の交配のチャンスだと考える。 そのうちミスマッチ感を楽しめるようになる。 大事なことはカオスを楽しむこと。 この情報とこの情報はくっつかないだろうという思い込みや、既成概念を取っ払う。 そのトレーニングにより、全体を捉えるヒントが生まれる。 本棚の本を整理しないというのもよい。 読書はジャンルの違う本を 3、4 冊並行して読む。多読、速読は大事。"
},
{
url: "/p/fsm6uh8/",
title: "2019-06-10 今日のボドゲー部",
date: "2019-06-10T00:00:00Z",
body: "2019-06-10 今日のボドゲー部 今日のボドゲー部は 『街コロ』 と 『キングドミノ』 。 街コロ サイコロを振って出た目に応じてお金をもらえるゲームです。 カードには 1〜12 の数字が書いてあって、出た目のカードを持っていると恩恵を得られます。 カードはお金を払って増やしていくことができるのですが、強いカードはその分高くなってます。 序盤は 1 つのサイコロしか振れないようになっていて、1〜6 の出目での勝負が続きます。 2 つサイコロが振れるようになったら一気に場が盛り上がるんだろうなぁと思っていると、いつもすぐに終わってしまいます。 もうちょっと勝負が長引くようにアレンジすると面白いかもしれないです。 先に 50 コインのお城を購入した人が勝利するとか。 とりあえず、サイコロを使うゲームは運の要素が強めで盛り上がりやすいので好きです。 キングドミノ キングドミノは 『カルカソンヌ』 に似たゲームです。 カルカソンヌはみんなで 1 つのマップを育てていきますが、キングドミノは各プレイヤーが 5x5 マスの土地を完成させます。 地形パネルを順番に置いていき、最後に「つながった地形の数 x 王冠の数」が得点になるというシンプルなルールです。 どうやったら土地を繋げられるかというパズル的なセンスが問われるゲームですね。 キングドミノもカルカソンヌも、最後の得点計算がちょっと地味です。 最後にドーンと盛り上がって終われないっていう。。。"
},
{
url: "/p/k6m6tdm/",
title: "2019-05-26 ゲームマーケット2019春に行ってきた",
date: "2019-05-26T00:00:00Z",
body: "2019-05-26 ゲームマーケット2019春に行ってきた 今日はアナログゲームの祭典、ゲームマーケット。 会場には東京テレポート駅から徒歩10秒で到着です。 日曜日の午後からぶらりと行ってきたんですが、思ったより空いてました。 初日はたぶん混んでたんでしょうね。 ほとんどのお店（サークル）には試遊台があるので、いろいろ遊んでいたらたぶん一日あっても足りないですが、ざーっと見て回るだけなら2、3時間あれば大丈夫。 参加者は年々うなぎのぼりみたいですが、このブームいつまで続くんでしょうか。 ゲームつくろーっと。"
},
{
url: "/p/qikq9o8/",
title: "MongoDB 関連記事",
date: "2019-05-20T00:00:00Z",
body: "MongoDB 関連記事 参考リンク Azure Cosmos DB にアカウントを作って MongoDB API でアクセスする"
},
{
url: "/p/x2zrq7f/",
title: "理学療法士さんの肩こりのお話",
date: "2019-05-15T00:00:00Z",
body: "理学療法士さんの肩こりのお話 とある理学療法士さんに肩こりについてのお話を聞いたのでメモメモ。 肩こりの原因 長時間の同一姿勢 → 筋肉が固まる 血管の圧迫 → 筋肉が過緊張 発痛物質 → 酸素や栄養の不足 ブルーライト → 自律神経の乱れ 筋肉は 30 秒伸ばすと緩むという性質を持っているので、首などのストレッチは 30 秒間続ける 猫背になる → 口呼吸になる → 口が渇く → 食事中に唾液で消化しにくくなる → 胃腸が悪くなる 寝る前に横隔膜呼吸をすると、副交感神経が優位になって良い睡眠をとれる 最近の流行で、タンパク質の取りすぎが起きている アンモニアが生成されるので体が臭くなるよ 肝臓に負担がかかるので、タンパク質摂るならお酒は飲んじゃダメ 肝臓のためにマグネシウムも一緒に摂る（マグネシウムを摂れる入浴剤もあるよ） 炎症物質に注意 赤身肉、砂糖 → ヒスタミンのもと → アトピーになったり、肌が汚くなったり"
},
{
url: "/p/9sh9ycn/",
title: "読書メモ『トム・ピーターズのサラリーマン大逆襲作戦〈2〉セクシープロジェクトで差をつけろ！』トム・ピーターズ",
date: "2019-05-05T00:00:00Z",
body: "読書メモ『トム・ピーターズのサラリーマン大逆襲作戦〈2〉セクシープロジェクトで差をつけろ！』トム・ピーターズ トム・ピーターズのサラリーマン大逆襲作戦〈2〉セクシープロジェクトで差をつけろ！ トム・ピーターズ CCCメディアハウス つまらない仕事を「すごい仕事」に変えるヒントが詰め込まれています。 「プロジェクト」って何だろう？ 何が大切なことなのだろう？ ということを原点に戻って考えさせてくれます。 才能のない人は、最初からおもしろいことがないかを探してしまう。 大切なのは、工夫すること自体が楽しいから工夫するという考え方。 今やっている仕事がつまらないと思ってしまったら、この本を開いてみると何かが変わるかもしれません。 はじめに プロジェクトって？ 普通の人が理解できないことをやらなければいけない。やる価値があるものは、それ以外にないのだから \u0026mdash; アンディ・ウォーホール プロジェクト内には、ガント図、PERT、CPM など、素人を煙に巻く道具がたくさんあり、多くの人たちは、 そのプロジェクトの一体どこがすごいのか？ どこが人の記憶に残るものなのか？ という肝心なことを忘れてしまう。 すごいプロジェクトとは、 目にも止まらぬ速さで突っ走るもの はじめ馬鹿にしていた人に「私が間違っていた」と言わせるもの たちどころに試作品が出来上がるもの あらゆる官僚的手続きをせせら笑うもの である。 ウェイン・ワン監督の映画『スモーク』では、生き様を示すのがプロジェクトだと言っている。 充実した人生を送るには 実現できない夢はある。 しかし、夢を描き、その夢を実現するために、持てる限りの智力、体力、気力を振り絞らない限り、人間が鍛えられず、絶望の味も歓喜の味も知らず、心も生活も豊かにならぬまま人生を終えることになる。 充実した人生を送るには、すごいプロジェクトをやるしかない。 プロジェクトの 4 段階 創造 (30%): プロジェクトの企画。カッコいいか？やる価値があるか？ 売り込み (30%): お客さんを集める。 実行 (30%): 舞台の幕を開ける。紙の上のプランよりも、試行錯誤を重視する。 退場 (10%): バトンタッチ。これをいい加減にやると、跡形もなく消えてしまう。 ほとんどのプロジェクトでは、「実行」以外のプロセスが忘れられている。 実際には、「実行」は「売り込み」の延長であることが多い。 第一段階『創造』 言われた通りに仕事をやっているだけでは、いつまでたってもプロジェクトは創造できない。 「トイレを直して」と頼まれたらどう考えるべきか？ バスルームの位置が悪いのかもしれない。 家全体の設計の問題では？ 本格的な改築工事が必要かもしれない。 「返品規定を見直して」と頼まれたらどう考えるべきか？ 会社が官僚的でもろもろの手続きが複雑なのでは？ 対処する現場の人間を信用していないのでは？ 社風刷新計画への突破口になるかもしれない。 戦略的に欠陥を是正する絶好のチャンスかもしれない。 枠を取っ払う あなたの本当の仕事は、一見つまらない業務や雑用を、カッコいいもの、忘れられないもの、すごいものに変えることだ。 憂鬱な仕事を、自分たちの価値観を体現する一大プロジェクトに変えてはいけない理由はない。 平凡な成功をまたひとつ積み重ねるだけの仕事はやめよう。 バカはメモをとらない まずは「観察ノート」を作ってみよう。(1) ムカつくことに出くわしたら、(2) すごいものに出くわしたら、何でも書き留める。 ポイントは、ものを見る眼を養い、小さなことに感動できる感性を磨くことにある。 シンプルなスパイラルノートの表紙に「しびれる」、裏表紙に「むかつく」と書き、今日から始めよう。 プロジェクトごとに専用の日記を用意し、そこに何でも書いていく。 思いついたらすぐに書き留めること。 言葉遣いの問題 何をやるときも、「すごいか、すごくないか」を判断基準にしてものごとのやり方を決めること。 「すごい」という言葉自体にすごいパワーがある。 やってみなければ、できるかどうかは分からない。 すごいことをやってみたいと思わなければ、すごいことは何もできない。 小さな問題の陰にビッグ・プロジェクトあり よくありがちな小さな問題を小さいと思ってはいけない。 それはタイタニックを引き裂いた氷山の一角だと考えたほうがいい。 ウォルトディズニーは、孫を連れて行けるところが欲しかった。 3M のアートフライは、聖歌集にはさんでおく栞がすぐに落ちてしまうことに苛立った。 小さなプロジェクトなら、警報を鳴らすことなく、大きな改革を進めやすい。 つまらない仕事は、かなり自由がきく。 誰も気にしない。誰も見ていない。だから、やりたいことができる。自分で直接、手を下せる。間違いを犯せる。危険を冒せる。 そして、奇跡を起こせる！ ブレーキを踏め 進行中のプロジェクトのどこがすごいのかを 1 枚の紙かカードにまとめ、毎週金曜日に、当初描いた夢からそれていないかどうかチェックしてみよう。 愛が地球を回す プロジェクト全体は退屈でも、その中に何か、自分のチャレンジ精神を刺激するものがあれば、その部分だけを取り出して、それをプロジェクト内プロジェクトに変えてしまえばいい。 これが自分にとってのでっかいプロジェクトになる。 チームメイトといっしょにプロジェクトの定義を考えよう。 やるべき仕事と予想される結果にチーム全体が興奮するまで、この作業を止めてはいけない。 自分は本当に、自分のプロジェクトを愛しているか。 自分の点数、そしてチームメイト全員の点数が 7 点か 8 点になるまで、プロジェクトを進めてはいけない。 美貌のプロジェクト プロジェクトに大事なもの、それは、情熱だ！愛だ！美しさだ！ 美しくないものは、何かが間違っている。 日常的な会話の中で、「美しさ」を毎日、話題にしよう。 どうすれば美しいプロジェクトにできるか、話し合ってみよう。 不思議なものに出会って驚くほど、素晴らしい経験はない \u0026mdash; アルバート・アインシュタイン まずデザインありき すごいプロジェクトを企画するときは、デザインとデザイナーを最優先事項にしてほしい。 どうすれば、デザインをプロジェクトの目玉にできるか。刻印にできるか。 インターネットの活用 インターネットが大きな役割を果たしていないプロジェクトは、革命的とは言えない。 これから立ち上げるプロジェクトについて、ホームページを開設しよう。 ホームページの見栄えと内容次第で、プロジェクトの本質があぶり出される。 誰も怒らないプロジェクトなんて\u0026hellip; すごいプロジェクト → ルールの変更 → 怒り出すヤツがいる これは公理である。 初めは出来るだけ目立たないようにしよう。 軌道に乗るまでは細心の注意が必要だ。 これは政治である。 政治が「ものごとを実現する技術」であることを思い出してほしい。 政治なくして実現はない。 熱狂的ファン 「顧客満足」程度で満足してはいけない。 すべてのお客さんを「動く広告塔」、すなわち熱狂的なファンに変えなければいけない。 「別に文句はない」というお客さんではなく、「文句はおおありだ」というお客さんを見つけたほうがいい。 今日、カンカンに怒っているお客さんが、明日、熱狂的なファンになってくれる。 海賊旗をなびかせ大海原を行く 今日から航海日誌をつけ始めよう。 どんな仕事にも冒険の要素を加え、毎日、冒険談を書き記していこう。 心を奮い立たすため、ピアリー、スコット、シャクルトン、アムンゼンなど、北極・南極探検家に関する本を読んでみてはどうだろう。 隠れ家 隠れ家はよく行く飲み屋の隅のテーブルでも、物置になっている会社の小卸屋でもいい。 そこを作戦本部にしよう。 隠れ家をもつことで、うわさが静かに広がっていくのがいい。 歓喜の瞬間を思い描く スタートするときに、ゴールの瞬間をイメージしよう。 すごい絵を描けないなら、それはすごいプロジェクトじゃない。 プロジェクトチーム全員に「完成予想図」を描いてもらい、みんなで比べてみよう。 レインボーカラー 驚嘆すべきプロジェクトはすべて、生まれも育ちも考え方もライフスタイルも資質も極端に違う人たち、不協和音を誇りとする人たちが集まって、やり遂げたものだった。 自分のチームに色彩が乏しいなら、それをどう豊かにしていけばいいか考えてみよう。 事業計画 すごいプロジェクトの立ち上げは、本質的に、会社創業と変わらない。 だから、至極当然のことながら、しっかりした事業計画がなければならない。 現実を見据えているか？ 迫力があるか？ 厳しい期限があるか？ 十分な勝算があるか？ 夢を妄想に終わらせないために 途方もない夢を実現した人はみな、夢を見ながら手足を動かした人たちだ。 夢想にふけるだけでは、どこまでいっても幻である。 さっそく締切を設定しよう（最初の締切はどんなに遅くとも 5 日以内だ）。 でかでかと書いて、みんなのよく見えるところに貼り出そう。 話を聞いてくれる人は千人力 すごいプロジェクトをやろうとすれば、孤独になることがある。 いたるところから狙撃される。 自分の仕事について相談に乗ってくれそうな人、苦しいときに力になってくれそうな人（アドバイザー）を探そう。 共謀者を探せ 数人の同士を獲得するだけで、すごいプロジェクトを売り込む技がおおいに磨かれる。 早くから支援してくれるのは、大概が地位の低い人である。 大物を釣り上げようなどと思わないほうがいい。ことは急ぐ。 将来の共謀者にブリーフィングできるチャンスを絶対に逸してはいけない。 ブリーフィングはあなたの大事な仕事だ。 何もできていないうちから、お客さんのことを考えよう 企画段階から、お客さんを引き摺り込もう。 お客さんに相談しよう。 早すぎることはない。あっという間に手遅れになる。 共謀者になったほうがトクをする仕組みを考えよう。 尺度と測定 自分が決めた尺度で、プロジェクトを測定してみよう。 この測定は何度でも繰り返す。 オススメの 5 つの尺度 すごい！ きれい！ 革命的！ インパクト！ ファンの熱狂度！ 第二段階『売り込み』 あなたがもらえる時間は 3 分 プロジェクトの内容を 1 枚にまとめる。 そして、ポイントを 5 つに絞り、5x7 インチのカードにまとめる。 メタファーは万言に勝る 人の心を動かす「メタファー」とは、煮詰めに煮詰めたストーリーのこと。 「1個のマーク」になることもあるし、「1枚の写真」、「強烈なキャッチコピー」になることもある。 売り込む相手を考えよう 最大の過ちのひとつは、あまりにも早い時期に上層部を口説きにかかること。 まず標的にすべきは、お偉いさんではなく、仲間たちである。 ネットワークを広げる コミュニティづくりだけは、絶対にやめてはいけない。 サポーターの輪が広がっていかなければ、すごいプロジェクトは実現しない。 最後に来た人も、最初に来た人と同じ あなたの話を聞こうとしなかった人が、手のひらを返してきたときには受け入れてあげよう。 「半年前、気の確かな人なら、ノーと言うのが当然ですよ(^-^)」と。 釣った魚にもエサはやる サポーターに絶えず最新情報を送る「フォロー・プログラム」を考えよう。 サポーターの熱は冷めやすいし、無視されたと思えば、腹立ち紛れに敵にまわることだってある。 敵は相手にせず サポーターにならないことがわかっている人を説得しようとしない。 有能な改革の旗手は、誹謗中傷など気にしない。 敵の攻撃を相手にしない。 自分の信念にしたがって、黙々と仕事をする。 すごい仕事は、笑顔でやるときが一番うまくいく。 顧問で箔を付ける 顧問団をつくろう。顧問団ができれば、プロジェクトの信頼性が増す。 顧問団にはいっさい隠し立てをしてはいけない。 貧しき者の自由を知れ 貧しき者にはいいことがたくさんある: 同士を好き勝手に選べる 思い通りに企画できる でっかい夢を描ける ダメだと思ったら一からやり直せる ベータテスト MS は Windows 95 の発売前に 30 万人にベータバージョンをテストしてもらった。 ここから得られた無料のアドバイスには、10 億ドルの価値があったという。 第三段階『実行』 口に入る大きさに切ろう 遊んで、テストできて、何かを学べる小さなパズルの断片を見つけるために、プロジェクトを細切れにしよう。 おしゃべるをするだけでなく、計画を立てるだけなく、毎日何かをやり遂げ、何かを試す。 堂々巡りの会議ほど、力が抜けるものはない。 ★話し合うだけの人は、何も生産していない。 \u0026mdash; まく 試作に狂え どんなに大きなプロジェクトでも、細かく分解すれば、2、3日中に（あるいは数時間以内に）現実世界でテストできるものが必ずある。 ボーイング社のプロジェクトだって例外ではない。 プロジェクトの実行段階では、「試作に狂う」ことほどカッコいいことはない。 イノベーションの神様、マイケル・ジュラーシはこう述べている。 イノベイティブな企業かどうかを見分けるには、すばやく試作品を作ることが文化になっているかどうかを見ればいい。試作文化が根付いているかどうかということ。 絢爛たる人生 ＝ 試行錯誤 ＝ 電光石火の試作 遊ぼう、遊び仲間を見つけよう 遊びはいい加減にやるものではない。真剣にやるものだ。 ウソだと思うなら、海辺で砂のお城を作っている子供を見て欲しい。 失敗は気にしない。 計画はいくら壊してもいい。 壊していけないのは、夢だけだ。 フライング 100 回 成功にも失敗にも等しく報いる。罰するのは怠惰だけだ \u0026mdash; デービッド・ケリー 実地に試して、ひとの意見を聞け。いますぐ。 その意見をよく咀嚼し、その意見を取り入れて修正しろ。 ぐずぐず言うな。 くだらねえおしゃべりはやめろ。 手柄争いをするな。 テストが終わったら、24時間以内に、 フィードバックの内容を整理しよう 悪いところを修正しよう 次のテストをしよう ダメだと思ったらぶっこわせ！ プロジェクトが5分の2まで進行したところで、あまり冴えないことに気がつく。 それなら迷わず、ぶっこわそう。 プロジェクトの一部がどんなにすばらしくても、それで全体がおかしくなっているのなら、それは役に立たない。 役に立たないどころか有害である。 破壊して征服せよ。 すごいプロジェクトをやるには、すごい人たちが必要 すごいことをやりたいのなら、実行段階になっても売り込みは終わらない。 頼みもしないのに、あなたのプロジェクトをあちこちで宣伝してくれる人が必要になる。 大急ぎで試作品を作るのは、自分たちがすごいことをやりはじめたことを、一日も早く、未来のサポーターに見せつけるためだ。 スカウト活動を真剣に考え、それを仕事にしよう。 実行の成功＝サポーター集めの成功。これには多額の投資（時間）が必要になる。 笑いは地球を救う ユーモアは、すごいプロジェクトの秘密兵器だ。 ユーモアほど、緊張をときほぐし、連帯感をつくりあげるものはない。 意識してチームの気分を明るくする方法を考えよう。 おもしろいことを言う人、ユーモアのセンスのある人、底抜けに明るい人がいたら、プロジェクトに参加してくれるよう頼もう。 でっかいバインダーを用意しよう 見出しラベルや仕切りページがたくさんついたバインダーを用意しよう。 そして、終始話題にすべきテーマや達成目標を見出しに書いていく。 手帳というより日記にしよう。 真面目なことも、ふざけたことも、大事なことも、つまらないことも、みんなごたまぜにして放り込んでいこう。 クズの収集を馬鹿にしてはいけない。 プロジェクトの運命を左右する日に、ちょっとした新聞の切り抜きが救世主になるかもしれない。 見出しは大事だ。それは実質上、プロジェクトの旗印であり、要綱である。 リスト作成は権力への道 会議が終わったら、すぐにその内容を整理する。 簡潔なリストをもとにして、スケジュール表をつくる。 この 2 点をいつも忘れないようにしよう。 リスト作成と議事の要約を真剣にやれば、驚くほど簡単に主導権を握れる。 スケジュールの鬼になれ スケジュールほど強力なツールはない。 クリアすべきハードルと、それをクリアすべき期日をはっきりさせて、しっかりスケジュールを組むことが、本当のプランニングというものだ。 それ以上手の込んだものは忘れろ。 中間目標をはっきり定めた時点でのスケジュール表を大きな紙に書いて、目立つところに張り出そう。電子掲示板にも、同じものを張り出そう。 スケジュールの命は、一目でわかる簡潔さにある。 最新のプランニングソフトウェアは必要ない。 クズをいくら作ってもしょうがない。 会議はどんなに長くても 15 分 何か困ったことが出てきたら、すぐに 15分会議 を収集して、すぐに問題を解決しよう。CNN は 15 分ルールを適用していたし、ロッキードの秘密開発チームも同じルールを使っていた。 雑談やら、ご機嫌伺いやら、もったいぶった前向きをやめる。 会議に 16 分かけてはいけない（14 分ならいい）。 ★1時間もだらだらと会議を続ける人は、だらだらと仕事をしてしまう人。そんな仕事の仕方をする人には、伝えたいことを簡潔に伝える力は身につかない。 普段から 15 分で会議を終わらせるように心がけていれば、イザというとき（エレベーターピッチなど）にも意見をわかりやすく伝えることができるようになる \u0026mdash; まく 小さな達成があったら、すぐにその日は達成記念日 祝杯をあげるのに、小さすぎる達成はない。 達成感は大事だ。倦怠感に陥らないために、チームを奮い立たせるために、そして、世間に（社内に）うわさを撒き散らすためには、お祝い事をやるに限る。 ★チームメンバーの入れ替えは起こるもの。頻繁にお祝い事があれば、途中でチームを抜けてしまった人も含め、みんなが達成感を味わうことができる \u0026mdash; まく 有能なプロジェクト・マネージャーは、どんな小さな成功も見逃さない。 「思い立ったらすぐにお祝い」をクセにすればいい。 T シャツでもいい、マグカップでもいい、ボールペンでもいい、横断幕だっていい。 チームの結束を強め、勢いをつけるプロジェクト・グッズを何か作ってみよう。 この開発術もまた、習得できる。 挫折に乾杯！ 「電光石火の失敗」は草の根を分けてでも探し出すべき聖者である。 電光石火の失敗があったら、祝杯をあげよう。 星に手を伸ばして「高ころび」をした人を表彰しよう。 黄金のドジ杯を作り、受賞者が一週間、その栄光カップを手元に置いておくというのもよい。 初心を忘れ、そんなに急いでどこへ行く 毎日、本来の目的を話題にしよう。 定期的にに「初心思い出しメール」を送ろう。 プロジェクトが半分進んだら、チーム全員が仕事の手を休めて集まり、このまま続行するべきかを話し合おう。 すごいはずのプロジェクトが、いつのまにか平凡なプロジェクトになっていないか？ ★たとえ「すごい」スピードで試作を続けていても、それが「すごい」ものを作る目的から外れていては意味がない \u0026mdash; まく プロジェクトにだって、アイデンティティーが欲しい すごいプロジェクトなら、そのプロジェクトにしかない「個性」がある。 すごいプロジェクト ＝ キャラクター ＝ 個性 ＝ ブランド ＝ アイデンティティー。 ありきたりのプロジェクトであっても、アイデンティティーを確立することで、すごいプロジェクトに変身する可能性を秘めている。 君子豹変 いつかは、主流に合流しなければならない時が来る。 プロジェクトが完成に近づいたら、実地試験の成功を、あの手この手で吹聴しよう。 お偉いさんを加えよう。 ユーザー・コミュニティーから目を離すな 実行の最終段階で成否のカギを握るのは、会社上層部への売り込みではなく、早期のユーザーに大きな声をあげてもらうことにある。 小さなサクセス・ストーリーを集めて、あちこちで言いふらそう。いいストーリー ＝ いいマーケティング。 ざわめき管理プログラム ざわめきは自然にできるものではない。 それは（大金はかけられなくても）時間をかけて、創り出すものだ。 「ざわめき管理プログラム」なくして、ざわめきはない。 発展段階に応じて、違う種類のリーダーが必要になる。 プロジェクト実行の最終段階では、マーケティングの神様に師事している人を事実上のリーダーにしたほうがいい。 たとえ 6 週間のプロジェクトであっても、正式の「マーケティング・ざわめきプラン」を立ててみよう。 第四段階『退場』 餅は餅屋 ベンチャー企業でも、企業家からプロの経営者にバトンを渡すべき時がくる。 このとき、バトンタッチがうまくいくかどうかで、その後、大輪の花が咲くかどうかが決まる。 情報システム部、人事部、財務部、総務部、◯◯部、××部、会社の主要部署にいる人たちとお友達になろう。 プロジェクトの新展開に備え、レールを敷いていこう。 自分の海賊チームだけでは進められない段階がある。 後継者を探そう 「継承プランニング」を真剣に考えよう。 心おきなく後事を託せる人が見つかるまで、舞台の幕を引いてはいけない。 あなたの出番が終わりに近づいたら、後継者探しに全力をあげよう。 置き土産 チームメイト全員にしっかりとした居場所を確保しよう。 このために時間と労力を惜しんではいけない。 プロジェクトの寿命を伸ばすだけでなく、「面倒見がいい人」という評判を広めることができる。 この大事な仕事に手を抜けば、たとえ一時は勝利しても、プロジェクトのインパクトは長持ちしない。いや、すぐに消える。 退学の美学 お世話になった人に感謝の手紙を書こう。 最低でも 100 通は書かなければならないだろう。 後継者に恵みを与えよ。 「あとを頼む」の一言で背を向けてはいけない。 休みを取り、あとのことをくれぐれもお願いしよう。 チームの歴史を書こう。写真アルバムを作ろう。 どんな小さなことでも、自分を助けてくれた人全員に、惜しみなく手柄を譲ろう。 それが終わったら、お別れの挨拶をして、足早に、涼やかに立ち去ろう。 功労者が居座るほど厄介なことはない。涼やかに去っていくことで、残された者が立ち上がる。"
},
{
url: "/p/hqmfua2/",
title: "Clip Studio Paint のメモ",
date: "2019-05-03T00:00:00Z",
body: "Clip Studio Paint のメモ"
},
{
url: "/p/drsjj6t/",
title: "クリスタのメモ: 別のレイヤーのオブジェクトが選択されてしまうのを防ぐ",
date: "2019-05-03T00:00:00Z",
body: "クリスタのメモ: 別のレイヤーのオブジェクトが選択されてしまうのを防ぐ 操作ツールを使ってオブジェクトを選択するときに、別のレイヤーのオブジェクト（ベクター線など）が選択されてしまい、思ったような操作ができないことがあります。 このような場合は、下記のように設定することで、操作対象になっているレイヤー上のオブジェクトのみを選択することができます。 図: 別レイヤーへの選択切り替えをオフ ツールパレットから 操作 ツールを選択 ツールプロパティパレットを開き、透明箇所の操作 のプルダウンを開く 別レイヤーへの選択切り替え のチェックボックスをオフにする"
},
{
url: "/p/od3ojpe/",
title: "クリスタのメモ: ワークスペースのレイアウトをリセットする",
date: "2019-05-02T00:00:00Z",
body: "クリスタのメモ: ワークスペースのレイアウトをリセットする Clip Studio Paint のパレットのレイアウトは自由に変更できるため、うまく配置すれば効率的に作業できるようになります。 ただ、慣れないうちに適当に配置を変えていると、デフォルトの配置からかけ離れたものになってしまい、かえって使いにくくなってしまうこともあります。 マニュアル本との対応付けもしにくくなっていまいます。 このような場合は、メニューから下記のように選択するだけで、初期のレイアウト（基本レイアウト）に戻すことができます。 ウィンドウ → ワークスペース → 基本レイアウトに戻す"
},
{
url: "/p/bycbpyn/",
title: "クリスタのメモ: 画像ファイルをレイヤーとして取り込む",
date: "2019-05-01T00:00:00Z",
body: "クリスタのメモ: 画像ファイルをレイヤーとして取り込む 画像ファイルを新規レイヤーに取り込む メニューから次のようにした画像ファイルを読み込むことができます。 取り込んだ画像は、新しいレイヤーに配置されます。 ファイル → 読み込み → フォトライブラリから\u0026hellip; iPad 版の場合は最後の フォトライブラリから\u0026hellip; の代わりに、カメラ撮影\u0026hellip; を選択して、カメラ撮影した写真を直接キャンバスに取り込めます。 画像を取り込んだレイヤーを編集できるようにする 取り込み メニューから画像を取り込むと、作成されるレイヤーは 画像素材レイヤー になっています。 このレイヤーに直接描画を行いたい場合は、レイヤー メニューから ラスタライズ を実行してラスターレイヤーに変更しておく必要があります。 ラスターレイヤーになったら、ペンツールなどで直接編集できるようになります。 キャンバスサイズを画像サイズに合わせる 取り込み メニューから画像ファイルを取り込んでも、キャンバスサイズは変更されません。 画像サイズに合わせてキャンバスサイズを変更したいときは、メニューから下記のように実行します。 レイヤー → レイヤーから選択範囲 → 選択範囲を作成 編集 → キャンバスサイズを選択範囲に合わせる"
},
{
url: "/p/pa7qtf9/",
title: "クリスタのメモ: 選択範囲外を削除する",
date: "2019-05-01T00:00:00Z",
body: "クリスタのメモ: 選択範囲外を削除する 例えば下記のような絵が 1 つのレイヤーで絵が描かれているとして、アザラシ以外の部分をまとめて削除したいとします。 選択範囲ツールの、投げなわ選択 などを使って、残したい部分をぐるっと囲みます。 図: 選択範囲→投げなわ選択 選択範囲ランチャーの、選択範囲外を消去 のボタンを押します（上部のコマンドバーにも同じボタンがあります）。 あるいは、メニューから 編集 → 選択範囲外を消去 を選択します。 図: 選択範囲外を消去 すると、アザラシ以外の部分が削除されます。 ちなみに、選択範囲を解除したいときは、選択範囲ランチャーの左端にある 選択を解除 のボタンを押してください。 図: 選択を解除"
},
{
url: "/p/ukama8m/",
title: "HTML5 の time 要素の正しい使い方",
date: "2019-04-27T00:00:00Z",
body: "HTML5 の time 要素の正しい使い方 time 要素とは HTML5 には、機械（コンピュータ）の読み取りのための要素として data 要素が定義されています。 中でも時刻はよく使用する情報なので、特別に time 要素として定義されています。 この要素を記事内に含めておくことで、article 要素の作成日時や、ページ自体の作成日時を表現することができます。 正しいフォーマットで記述しておけば、検索エンジンの検索結果に日付を表示してもらえるかもしれません。 SEO 対策のためにも、time 要素を正しく記述できるようにしておきましょう。 time 要素の記述方法 \u0026lt;time datetime=\u0026#34;日時情報\u0026#34;\u0026gt;表示される日時\u0026lt;/time\u0026gt; time 要素のフォーマットは上記のようになっており、datetime はオプショナルな属性です。 datetime を省略する場合は、表示される日時 の部分が、RFC 3339 - Date and Time on the Internet で定義された形式で記述されている必要があります。 典型的な書き方は下記のような感じ。 書式 意味 2019-04-27 日付（UTC あるいは日本時間） 2019-04-27T21:30Z 日付＆時刻（UTC） 2019-04-27T21:30+0900 日付＆時刻（日本時間） 逆に、datetime オプションに上記のような日時情報を含めておけば、表示される日時 の部分には任意のテキストを指定することができます。 なので、下記の 2 つの time 要素はどちらも正しい記述です。 正しい書き方 \u0026lt;time\u0026gt;2019-01-01\u0026lt;/time\u0026gt; \u0026lt;time datetime=\u0026#34;2019-01-01\u0026#34;\u0026gt;2019年の元日\u0026lt;/time\u0026gt; datetime 属性を省略している場合は、表示される日時 の部分を独自形式で記述してはいけません。 間違った書き方 \u0026lt;time\u0026gt;2019年の元日\u0026lt;/time\u0026gt; 正しく time 要素を使って、人にも機械にもやさしい Web サイトを作成したいですね！ schema.org の構造化データマークアップ HTML データに、より明確な意味を持たせるための schema.org の構造化データマークアップというものがあります。 この情報を付加しておくことで、検索エンジンなどはさらに詳しくサイト情報を表示できるようになります。 日付情報には、BlogPosting タイプなどの datePublished や dateModified プロパティを付けておくのがよいでしょう。 下記は 1 つのブログ記事をマークアップする例です。 scheme.org の構造化データマークアップを付加 \u0026lt;article itemscope itemtype=\u0026#34;https://schema.org/BlogPosting\u0026#34;\u0026gt; \u0026lt;header\u0026gt; \u0026lt;h1 itemprop=\u0026#34;headline\u0026#34;\u0026gt;記事タイトル\u0026lt;/h1\u0026gt; \u0026lt;span\u0026gt;最終更新: \u0026lt;time itemprop=\u0026#34;dateModified\u0026#34; datetime=\u0026#34;2019-01-01\u0026#34;\u0026gt;2019-01-01\u0026lt;/time\u0026gt; \u0026lt;/span\u0026gt; \u0026lt;/header\u0026gt; \u0026lt;div itemprop=\u0026#34;articleBody\u0026#34;\u0026gt; 記事本文 \u0026lt;/div\u0026gt; \u0026lt;/article\u0026gt; 参考リンク time – date and/or time (NEW) - HTML5 The time element — HTML5: Edition for Web Authors HTML: Hypertext Markup Language | MDN"
},
{
url: "/p/67uziuj/",
title: "読書メモ『るるいえびぎなーず - クトゥルフ神話TRPG入門』内山靖二郎",
date: "2019-04-23T00:00:00Z",
body: "読書メモ『るるいえびぎなーず - クトゥルフ神話TRPG入門』内山靖二郎 るるいえびぎなーず - クトゥルフ神話TRPG入門 内山靖二郎、アーカム・メンバーズ エンターブレイン 女子高生の睦（むつみ）と、いっしょにクトゥルフ神話 TRPG を学んでいくお話です。 題材はクトゥルフ神話ですが、どんな TRPG にも言える一般的な心構えや、シナリオの作り方のコツなども載っているので、クトゥルフ神話以外の TRPG をやってみたいという人にもオススメできる本です。 なお、クトゥルフ神話 TRPG では、ゲームマスター (GM) のことをキーパーと呼びます。 ここでは、プレイヤーの心得、キーパーの心得、シナリオの作り方のコツなどをまとめておきます。 プレイヤーの心得 プレイヤーは、謎を解き明かし事件を解決しようとするキャラクター “探索者” の役を引き受ける ルールブックのこの一文に、探索者としての心得は集約されている。 何か怖そうなことが起こったときに、ただ引き籠っていたら話が進まない。 事件には好奇心を持って臨むこと。 キーパーは敵ではない キーパーはプレイヤーの邪魔をするかもしれないけど、困らせようとしているのではなく、楽しませようとしてやっていることを理解してプレイしよう。 自由は断るためのものではない プレイヤーが自由に行動できるというのが TRPG のウリだけど、NPC からお願いされたことをむげに断るというのが自由ではない。 断ることよりも協力することを考えよう。 どういう状況であれば探索者が協力するのか考え、ストーリーをみんなで楽しみながら作っていくのがよい。 命は大切に クトゥルフ神話 TRPG は死にやすい。 事件に対して積極的になるべきといっても、何にでも突っ込んでいけばいいというわけではない。 「事件や謎の解明」と「命を大切にすること」はバランスよく考えてプレイしないといけない。 不幸にも探索者が死んでしまった場合はネガティブにとらえず、死にゆくときを精一杯楽しむのがよい。 探索のノウハウ（便利な行動集） 図書館で調べる。図書館に行って事件について調べるという行動は、プレイヤーにとっても、キーパーにとっても便利な行動。ただし、＜図書館＞の技能ロールは、4 時間程度かかる行動であることに注意。 新聞社に行く。交渉力があれば、記者に話を聞いた方が、図書館で調べるよりも早い。ファンタジー RPG でいうところの酒場。 日記を読む。クトゥルフ神話では、登場人物の日記がよく登場する。誰かの部屋を調べるときは、まずは「日記を読む」と宣言するという冗談がある。プレイヤーと敵対する NPC の情報を提供するには、日記という手段はもってこい。 魔道書を読む。日記と並んでよく出てくる情報源。クトゥルフ神話に関する禁断の知識が記されている。読むと正気度が下がったりするが、引き換えに呪文を覚えられたりする。 現場を調べる。事件に遭遇したら、まずは現場を調べることから入って間違いない。この辺りのノウハウは、刑事ドラマや推理小説が参考になる。 聞き込みをする。自分のセリフに NPC がダイレクトに反応してくれるのは TRPG ならではの魅力。クトゥルフ神話 TRPG では、聞き込みに必要な ＜言いくるめ＞＜説得＞＜信用＞＜心理学＞ といった技能が充実している。 探索者の設定／知識 探索者は知り合い同士にしておいた方が、すぐに協力体制をとることができてゲームの展開が早くなる。 探索者とプレイヤーの知識は別物として扱わなければならないが、何も知らないはずの探索者に、どうやってプレイヤーの知識に基づいた行動をさせるのか考えるのもこのゲームの面白さのひとつ。 狂気に陥ったとき これまで正常だった仲間が、狂気に陥った途端に人が変わってしまうという恐怖をプレイヤーの方から演出できるのはクトゥルフ神話 TRPG の大きな魅力。 ただ、狂気に陥ったからといって何をしてもいいというわけではない。 いきなり銃を乱射するような周りに迷惑をかけるような行動はダメ。 あくまで周りを楽しませるようなロールプレイをしよう。 キーパー (GM) の心得 全員に行動させる 何より大切なことは、プレイヤー全員に行動の宣言をしてもらうこと。 消極的なプレイヤーや、考える時間が長いプレイヤーのことも考えて、それぞれに発言の機会を与えてあげないといけない。 探索者に挑戦する機会を与えて、プレイヤーに満足感を与えてあげることが大切。 シナリオ上、最終的に行き着く先が同じであっても、プレイヤーに自分の意思で行動しているのだという実感を持ってもらうようにする。 探索者の操り方 探索者にやってもらいことをさりげなく伝えるテクニックがいくつかある。 行動の選択肢を提示する。露骨に二択とかで提示するのではなく、例えば、状況説明から調べる場所の目星が付くようにしてから、どこから調べるかを尋ねるというやり方が良い。地図や間取り図を見せるのも効果的。 NPC を利用する。キーパーがしてもらいことを直接伝えると、押し付けがましくなってしまうが、NPC が行動を提案するとマイルドに感じてもらえる。ただし、完全に信頼できる NPC から提案すると、探索者は 100% その発言に従うようになってしまうので、多少は頼りなかったり、怪しい NPC に提案させるのがよい。 描写を淡白にする。本筋に関係のないシーンでは、状況説明を簡潔に済ませることで、プレイヤーに余計な行動を取らせないようにするのがよい。説明のメリハリを付けることで、プレイヤーをうまくシナリオの本筋に誘導していく。 NPC は脇役である NPC 同士で会話をするのはできるだけ避ける。 主役はあくまで探索者なので、脇役の NPC の会話だけで話が進んでいくのは面白くない。 展開は柔軟に あまり無理にシナリオ通りに話を進めようとすると、プレイヤーが不満に感じてしまう。 キーパーはあまりシナリオに縛られず、展開を変更したり、イベントをカットしたりする柔軟性も必要。 なりきってもらうシーン プレイヤーにいつも探索者になりきってもらう必要はないが、重要なシーンでは、それを要求した方が緊張感が高められる。 例えば、＜言いくるめ＞ や ＜説得＞ のロールをするには、心を動かされるような内容で尋ねないとダメだとプレイヤーに伝えればよい。 シナリオの作り方のコツ 大切なのは、どんなことをしたらプレイヤーが楽しんでくれるかということ。 NPC の性格の設定 キーパーは、その NPC に対して探索者がどのような感情を持つのかを意識して、それに特化した NPC を設定するとよい。 プレイヤーの感情として動かしやすいのは、「同情」「怒り」「感謝」といったもの。 逆に、「尊敬」「恐怖」といった感情は動かしにくい。 事件の導入部の設定 巻き込まれ型: 探索者が事件に巻き込まれるという設定のメリットは、スピーディに話を進められること。一方、その展開を強引に感じてしまう欠点もある。事件に取り組むべき動機を 2 つ以上設定しておくとよい。 依頼型: NPC からの依頼でストーリーを進めていく方法のメリットは、依頼主から、何をすればいいのかを明確に伝えられること。一方、探索者が依頼を受けてくれないかもしれないという不安は残る。探索者の性格に応じた報酬を設定してやり、気持ちを盛り上げるとよい。 どちらの場合も、設定として重要なのは「それぞれの探索者が事件を受ける理由」。 事件の原因の設定 事件の**「原因」はしっかりと設定しておくべき**。 そして、その「原因」は探索者の手の届くところに用意しておく。 どんなに斬新な「原因」を用意しても、それをプレイ中に探索できなければ意味がない。 事件の解決方法の設定 事件の解決方法を探す（考え出す）のは探索者の役割だけど、キーパーは事件の解決方法を 1 つは考えておくこと。 そして、実際のプレイではその解決方法だけにこだわらないこと。 それ単体では何の役にも立たないけれど、思わせぶりなアイテムを用意するとよい。 事件の解決手段が段階的に得られるようになっていると、プレイヤーに達成感を与えることができる。 クリーチャーを戦闘で退治するという展開のシナリオであれば、プレイヤーにあらかじめ戦闘用の技能が必要であることを伝えておくこと。 情報源の設定 「原因」を導き出すための情報源と、「解決方法」を導き出すための情報源を、それぞれ 2 つずつは用意しておくこと。 1 つの決定的な情報源を用意するのではなく、複数の情報源を用意して、得られる情報を断片的なものにしておくのがよい。 情報源が 1 つの日記だけというのは、それを発見できないというリスクがあるだけでなく、日記を見つけること以外のプレイヤーの行動が徒労だと感じてしまう。 それを手に入れないとゲームがまったく進まないという情報源はできるだけ設定しないこと。 どうしても必要なら、その情報源を複数の手段で得られるようにしておく。 プレイヤーの記憶は曖昧で、口頭で伝えたことは忘れてしまうことが多い。 重要で密度の濃い情報は、紙に描いたものをプレイヤーに渡しておくとよい。 狂気の内容の設定 狂気の内容はキーパーが決めてよいことになっている。 怪しいものを強調するために \u0026lt;正気度\u0026gt; ロールは活用できるが、それによって不本意に狂気に陥ってしまうことはある。 仮に序盤で 1D10 の正気度が減るイベントが発生して不定の狂気になっても、事件の解決に執着するという狂気に陥るという設定にしておけば、探索者がゲームから脱落してしまうことは防ぐことができる。 突発的な事件の設定 突発的なショッキングな事件が発生するようにしておくと、プレイヤーを飽きさせない。 そういった事件は任意のタイミングで発生させられるようなものを用意しておき、ここぞというタイミングで発生させる（プレイヤーが退屈そうにしているときなど）。 その他・ルール全般 キャンペーンシナリオ キャンペーンというのは、1 つのゲームが終わったとき、探索者を使い捨てにしないで次のゲームに引き継ぐプレイの仕方。 クトゥルフ神話 TRPG では正気度も引き継がれる。 1 回のプレイで完結できないような大掛かりなシナリオを、分割してプレイできるようにしたものをキャンペーンシナリオという。 プレロールドキャラクター プレロールドキャラクターとは、キーパーが能力値や技能、設定の一部をあらかじめ設定しておくキャラクターのこと。 「失踪した父親を探している」といった設定や、職業などをあらかじめ決めておくと、キーパーとしてはやりやすくなる。 技能ロールをする 3 つのタイミング 探索者が行動宣言 → キーパーがロールを指示する キーパーから技能ロールを指示する 探索者から技能を使うと宣言して、キーパーの指示に従う いずれの場合も、キーパーが指示してからロールするのがポイント。"
},
{
url: "/p/p68t83i/",
title: "読書メモ『伝説の社員になれ！』土井英司",
date: "2019-04-20T00:00:00Z",
body: "読書メモ『伝説の社員になれ！』土井英司 「伝説の社員」になれ！ 成功する5％になる秘密とセオリー 土井英司 草思社 出世することではなく、自分の価値を高めることが大切なんだよと教えてくれる本です。 会社の中で働いていると、どうしても地位というものを感じてしまいます。 人生100年時代に入り、「出世＝勝ち組」のように考える人はさすがに少なくなりましたが、平社員という低い立場を逆に利用して自分の価値を高めていくという考え方は、多くの人に希望を与えてくれると思います。 伝説の社員 自分をトコトン安く売り、その引きかえに、経験と実験の場を手に入れる。 会社という舞台で「タダの社員」という立場をフルに活用し、「伝説」を作る。 自分に付加価値をつけるとは、上司にゴマをすることでも、外国語を流暢に話すことでもない。 伝説の社員になってしまえば、いつでもその能力を「キャッシュに換える」ことができる。 ソコソコ出世するスーパーエリートは能力に秀でている。とんでもなく成功する「伝説の社員」と呼ばれる人は、情熱なら誰にも負けない。 どう働くか、職場をどう捉えるか 自分が成長するために必要なのは、出世したり、高い給料を追い求めることではない。一生を通じて自分がケアをし、それによって自分も成長できる、そんな対象を見つけること。 職場は授業料を払ってでも行きたい、興味深い人間の悲喜劇に満ちている場所である。複雑な人間関係やトラブルの処理は、専門学校や通信教育では学べない。 お金はためるより、自分の価値を高めるために使った方が、あとで何倍にもなって戻ってくるのではるかにトク。 24時間使える、そう思ったとき、それまでは「ない」と思っていたものが「ある」に変わる。 自分一人のために働いていると、どんどん煮詰まっていくが、会社のため、人のために働いていると、人との繋がりはどんどん広がっていく。 会社の経費に自腹という投資分を上乗せして成果を出そうという発想があってもよい。 一億円あろうがなかろうが、遊びは人生のメインにはならない。金を抱えてリタイアするより、一生面白い仕事をする方が、よほど生き甲斐がある。 学び方 高価な本を買う Bad: ベストセラーを読んで皆と同じ情報を共有する安心感を得る。 Good: 多少痛い自腹を切ってでも、特化した情報を手に入れる。自分の血肉になるものにお金を使う。 成功の方法を学ぶよりも、失敗しない方法を学ぶ 成功する方法は明日にも陳腐化するが、失敗の要因はいくつかにまとめることができる。 「私のミスです」と、はっきり言えるような「原因も失敗も明らかな失敗」は、正確なデータがとれるのでかけがえのない財産になる。 失敗した人が身近にいたら、話をトコトン聞こう。 ダメ上司がいるのなら絶好のチャンスと考える。失敗している人のそばにいる人は、失敗を観察できぶん有利な立場にいる。 異業種交流会やセミナーでは、講師に近づこうとするのではなく、目の前の参加者と話し、名刺交換をするのがよい。その中には必ず自分と一緒に伸びていく人がいる。 自分マーケティング 自分はどんなことを褒められたら嬉しいのか？それがわかれば自分の才能は開花する。 会社ではなく◯◯さんにお願いしたい、という取引先や客を多く掴んだときが独立のタイミング。伝説の社員は、取引先や顧客など、社外にファンを持っている。 一緒に仕事をしている人を誰かに紹介するときは、「◯◯さんは△△の分野でとても優秀なんです」と具体的な褒め言葉を添えて強い印象を残す。その人の価値を伝えることができるし、そんな素晴らしい人を紹介してくれたあなたにも感謝してくれる。 寒いときに寒そうな顔をすることは誰でもできる。寒いときに暖かそうな顔をすること、そういうことができる人が貴重。それは価値であり、人を惹きつける。 人脈を広げたければ、好かれるより、信用されることを目指す。いい人だけでは意味がない。 自分を売るためには、自分にわかりやすいキャッチコピーをつける。 「女性下着を売っているスケベオヤジです」塚本幸一（ワコール創業者） 「書評に関しては毒舌で辛口の◯◯です」土井英司（出版コンサルタント） 「営業成績ナンバーワンを目指す◯◯です」 「ユーザーの立場が第一と考える◯◯です」"
},
{
url: "/p/zvwesen/",
title: "雑誌、本の読み終わったページをひと目で分かるようにする",
date: "2019-04-06T00:00:00Z",
body: "雑誌、本の読み終わったページをひと目で分かるようにする みなさん、本をどこまで読んだかってどのようにマーキングしてますか？ わたしは読み終わったページの隅っこのところ（ページ番号が印刷されているあたり）を切り取っています。 こうすると、読み終わったページと、読んでいないページがすぐに分かるようになります。 さらに、まだ読んでいないページをさっと開くことができるようになります。 前から順番に読んでいく場合は付箋を貼っておくのもよいですが、この方法なら、飛ばし読みしたりする場合でも、一度以上読んだページと一度も読んでないページをすぐに区別できます。 付箋がなくても、ハサミだけで OK ですしね（笑）。 かれこれ 10 年以上この方法を続けていますが、何割くらい読み終わったかが一目で分かるので、本を読み切るというモチベーションにも繋がっている気がします。 大切な本に切り込みを入れることには抵抗があるかもしれませんが、本は読んでこそ価値が出るもの。 コレクションとして 10 年後まで本を綺麗な状態で保つことを目的としていないのなら、時間を有効に使うことを徹底した方がよいと思います。"
},
{
url: "/p/yuhqrdx/",
title: "読書メモ『孫社長にたたきこまれた すごい「数値化」仕事術』三木雄信 (1/5)",
date: "2019-04-04T00:00:00Z",
body: "読書メモ『孫社長にたたきこまれた すごい「数値化」仕事術』三木雄信 (1/5) 孫社長にたたきこまれた すごい「数値化」仕事術 三木雄信 PHP研究所 若い時からソフトバンクの孫さんの右腕として働いていた三木さんの著書です。 「数値化」というタイトルなので、よくある KPI、KPI とうるさい内容なのかと思ったら全然そんなことはなく、本当に企業の生産性を上げられそうな考え方や方法がギュッと詰まった本でした。 長年培ってきた知識を一冊の本にまとめてくれたことに感謝です。 なぜ「数値化」すると生産性が劇的にアップするのか 問題が多すぎて、どこから手をつけていいかわからない → 数値化すれば、「どの問題から着手すればいいか」優先順位が明確になる。 例: コールセンターへのクレームを分類したら、2種類の問題が全体の80％を占めていた。 数値化しないと、立場が上の人や、声が大きい人の意見ばかりが通ってしまう → 数字が正しければ、どの立場の人も動かせる。 例: モデムのクレームを減らせば、コール発生率を5％から4％に減らます。1％減ると、毎月4000万円のコスト削減になります。 数値化の 7 つのコツ (1) 数字は「与えられるもの」ではなく、自分で「取りにいくもの」 会社から与えられた数字で、自分の問題が解決しないなら、それは取るべき数値が間違っているということ。「自分の問題」を解決するには、本当に必要な数字を計測し、分析して、「数値」という道具に仕立て上げなくてはいけない。 (2) 数値化の目的は「どうだったか」ではなく「どうするか」 未来（＝次のアクション）に繋がらない数値化には意味がない。 (3) 数値化のファーストステップは「分ける」こと。数える前にまず分けろ！ 分け方の例 「種類別」、「業界別」、「ジャンル別」に分ける 始点と終点を決め、「プロセス」、「工程」で分ける 分け方にルールはないので、自分で決めればいい。 チームで問題解決に当たる場合は、メンバー全員でグループ分けの作業をするとよい。全員にポストイットに5枚ずつ「思いつく理由」を書いてもらってグループ分けしてみる。 (4) 問題のありかが見えてきたら、さらに細かく分けて計測 計測ポイントの例 「1日」ごと 「場所」ごと 「人」ごと 迷ったら、とにかく手を動かしてみて、事実を見る。 (5) 数値化のゴールは、現実の問題を「数式で表す」こと 「データ」それ自体は意味のない数字である。大事なのは、データを「構造化」して、情報やナレッジにすること。 情報: データを整理し、解釈や意味を持たせたもの ナレッジ: 情報を体系化し、まとめたもの ビジネスの現象をモデル化することが重要。 数式は必ず解くことができる。だから、数値化すれば、問題を解決することができる。 例: 小売業の売上 ＝ 1平方メートル当たりの売上 × 店舗面積 × 営業日数 例: 営業部の売上 ＝ 営業マン1人あたりの1日の売上 × 営業の人数 × 営業日数 例: 1日にどれだけモデムを配れるか ＝ 立地（通行料） × アルバイトの習熟度 (6) 数値化したら、あとはPDCAを高速で回し続ける 実行した結果、得られる数値ほど正確なものはない。 日本企業は失敗を恐れて、計画に時間をかけすぎる。 実行 (Do) と計画 (Plan) は順序通りやる必要はなく、セットで迅速に回す。 (7) 問題解決後も数字でチェックを続け、環境変化にいち早く気づく 数字を日々チェックしていれば、「予測値と実測値が急にズレるようになった」ということが分かり、環境の変化に気づくことができる。 最も重要な「5つの数字」 顧客数 顧客単価 残存期間（顧客でいてくれる期間） 顧客獲得コスト 顧客維持コスト 営業利益は次のように計算することができる。 営業利益 ＝ （顧客数 × 顧客単価 × 残存期間）−（顧客獲得コスト ＋ 顧客維持コスト） 孫さん曰く、「牛のよだれのようなビジネスが一番いい」。 ライフタイムバリュー (LTV)、つまり、一人の顧客が一生のうちにもたらしてくれる価値や利益を重視せよということ。 ソニーの「リカーリングビジネス」は、まさにこれ。"
},
{
url: "/p/cniq5vr/",
title: "Let's Encrypt certificate expiration notice が来たら",
date: "2019-03-21T00:00:00Z",
body: "Let's Encrypt certificate expiration notice が来たら Let\u0026rsquo;s Encrypt Expiry Bot からの証明書期限切れメール 2 ヶ月ほど前に、Sakura VPS レンタルサーバーを Let\u0026rsquo;s Encrypt で SSL 対応していたら、こんなメールが来ました。 Your certificate (or certificates) for the names listed below will expire in 20 days (on 10 Apr 19 07:02 +0000). Please make sure to renew your certificate before then, or visitors to your website will encounter errors. We recommend renewing certificates automatically when they have a third of their total lifetime left. For Let\u0026rsquo;s Encrypt\u0026rsquo;s current 90-day certificates, that means renewing 30 days before expiration. See https://letsencrypt.org/docs/integration-guide/ for details. 90 日ごとに証明書 (certificate) が期限切れになってしまうので更新しなきゃヤバイよってメールでした。 更新しないでいると、Web サイトに https でアクセスできなくなってしまいます。 見逃すところでした。 certbot コマンドによる証明書の更新 証明書の更新は、certbot コマンドを使って簡単に実行できます。 まず、certbot コマンドがインストールされていない場合はインストールします。 certbot のインストール $ sudo yum install certbot 証明書を更新するには、下記のように certbot renew を実行します。 証明書の有効期限まで 30 日以上残っている状態で更新する場合は、--force-renew オプションを付けて実行する必要があります。 更新したら、Web サーバをリロードすれば完了です。 SSL 証明書の更新 $ sudo certbot renew --force-renew $ sudo systemctl reload nginx トラブルシューティング: 404 Not Found が出る場合 certbot renew コマンドを実行したときに、下記のようなエラーが出て失敗することがあります（下記の例では、Web サイトのドメイン名は example.com に変えています）。 certbot renew のエラー（抜粋） Attempting to renew cert (example.com) from /etc/letsencrypt/renewal/example.com.conf produced an unexpected error: Failed authorization procedure. example.com (http-01): urn:ietf:params:acme:error:unauthorized :: The client lacks sufficient authorization :: Invalid response from https://example.com/.well-known/acme-challenge/Y1WeUoSwipdo5aZHsUNevZl_ppylAAWJh9bfSv1Xqu0 [225.100.100.100]: \u0026#34;\u0026lt;html\u0026gt;\\r\\n\u0026lt;head\u0026gt;\u0026lt;title\u0026gt;404 Not Found\u0026lt;/title\u0026gt;\u0026lt;/head\u0026gt;\\r\\n\u0026lt;body bgcolor=\\\u0026#34;white\\\u0026#34;\u0026gt;\\r\\n\u0026lt;center\u0026gt;\u0026lt;h1\u0026gt;404 Not Found\u0026lt;/h1\u0026gt;\u0026lt;/center\u0026gt;\\r\\n\u0026lt;hr\u0026gt;\u0026lt;center\u0026gt;\u0026#34;. Skipping. ... All renewal attempts failed. The following certs could not be renewed: /etc/letsencrypt/live/example.com/fullchain.pem (failure) All renewal attempts failed. The following certs could not be renewed: /etc/letsencrypt/live/example.com/fullchain.pem (failure) - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 1 renew failure(s), 0 parse failure(s) このエラーが出る場合、多くの場合は nginx の Web サイトのドキュメントルートを /usr/share/nginx/html から変更していることが原因のようです。 下記の設定ファイルの、webroot_map のパスを、Web サイトの正しいドキュメントルートのディレクトリに変更します。 /etc/letsencrypt/renewal/example.com.conf [[webroot_map]] example.net = /usr/share/nginx/html 例えば、/home/maku/website ディレクトリに設定しているなら、下記のように変更して保存します。 example.net = /home/maku/website これで、certbot renew コマンドの実行は成功するはずです。 cron で自動更新するように設定しておく 3 ヶ月おきに上記のコマンドを実行するのは面倒なので、cron で自動実行されるように設定しておきます。 設定ファイルは、/etc/crontab をテンプレートにして、/etc/cron.d/lets_encrypt を作成します。 /etc/cron.d/lets_encrypt を作成 $ sudo cp /etc/crontab /etc/cron.d/lets_encrypt $ sudo vim /etc/cron.d/lets_encrypt ファイルの中身は下記のようにして、毎週日曜日に、証明書の更新コマンドを実行するようにします。 実際には、証明書の有効期限が 30 日を切っている場合にのみ更新が行われます。 /etc/cron.d/lets_encrypt SHELL=/bin/bash PATH=/sbin:/bin:/usr/sbin:/usr/bin LANG=ja_JP.UTF-8 LC_ALL=ja_JP.UTF-8 CONTENT_TYPE=text/plain; charset=UTF-8 MAILTO=\u0026#34;xxxxx@gmail.com\u0026#34; # Let\u0026#39;s Encrypt の証明書を更新（毎週日曜日2時30分） 30 2 * * sun root /usr/bin/certbot renew \u0026amp;\u0026amp; /usr/bin/systemctl reload nginx ここでは、MAILTO を設定することで、cron のログをメールで送るように設定しています。 例えば、下記のようなメールが届くことになります（まだ証明書の期限は切れないから更新要求はスキップされたよ、というログですね）。 cron からのメールの例 Saving debug log to /var/log/letsencrypt/letsencrypt.log - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - Processing /etc/letsencrypt/renewal/example.com.conf - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - Cert not yet due for renewal - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - The following certs are not due for renewal yet: /etc/letsencrypt/live/example.com/fullchain.pem expires on 2019-06-19 (skipped) No renewals were attempted. - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - ちなみに、cron の日時指定の方法は下記のようになっています（/etc/crontab より抜粋）。 # Example of job definition: # .---------------- minute (0 - 59) # | .------------- hour (0 - 23) # | | .---------- day of month (1 - 31) # | | | .------- month (1 - 12) OR jan,feb,mar,apr ... # | | | | .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat # | | | | | # * * * * * user-name command to be executed Sakura VPS レンタルサーバで Let\u0026rsquo;s Encrypt 設定した場合 Sakura のレンタルサーバの設定で Let\u0026rsquo;s Encrypt を自動設定した場合、下記のような cron 設定ファイルが自動的に生成されているかもしれません。 毎週木曜日の2時14分に証明書の更新をしようとしています。 こういったファイルが自動生成されているのであれば、それを使うのもよいでしょう。 /etc/cron.d/certbot-auto 14 2 * * 4 root /usr/local/certbot/certbot-auto renew --webroot -w /usr/share/nginx/html --post-hook \u0026#39;systemctl reload nginx\u0026#39; ただし、ここでも Web サイトのドキュメントルートとして /usr/share/nginx/html が指定されているので、もしパスを変更しているのであれば、上記のファイルを修正しておく必要があります。 自分で作成した /etc/cron.d/lets_encrypt があるのであれば、上記のファイルは処理が重複しているので削除しちゃいましょう。"
},
{
url: "/p/f2kkmnw/",
title: "クリスタのメモ: 下のレイヤの描画領域だけに描画する（クリッピング）",
date: "2019-03-12T00:00:00Z",
body: "クリスタのメモ: 下のレイヤの描画領域だけに描画する（クリッピング） ある絵の上に影を追加したいときなどは、レイヤを 1 枚上に追加して、下のレイヤでクリッピングして色を上乗せしていくとよいです。 ここでは、図のような単純な矩形が描画されているレイヤが 1 枚あるとします。 まず、この上に重ねる形で 新規レイヤを作成 します。 新規作成したレイヤ（上にあるレイヤ）が選択された状態で、下のレイヤでクリッピング のボタンを ON にします。 すると、上のレイヤに赤いバーが表示された状態になります。 この状態で、上のレイヤに描画すると、下のレイヤの描画領域に重なる部分だけが見えます。 これが、下のレイヤでクリッピング の機能です。 実際に描画されている部分はもっと広いのですが、この機能によって、見た目だけがクリッピングされて見えるようになっています。 クリッピングのボタンをもう一度押して OFF にすると、実際に描画されている部分すべてが見えるようになります。 あまりに広い範囲が無駄に塗られているようでしたら、この状態で消しゴムツールで消してしまうとよいでしょう。"
},
{
url: "/p/zbgbb5u/",
title: "PlantUML（テキストベースのUML作図ツール）",
date: "2019-03-07T00:00:00Z",
body: "PlantUML（テキストベースのUML作図ツール）"
},
{
url: "/p/g4mr3g7/",
title: "読書メモ『プラットフォーム革命』アレックス・モザド、ニコラス・L・ジョンソン",
date: "2019-03-01T00:00:00Z",
body: "読書メモ『プラットフォーム革命』アレックス・モザド、ニコラス・L・ジョンソン プラットフォーム革命 アレックス・モザド、ニコラス・L・ジョンソン 英治出版 Amazon や Google、Facebook に代表されるように、今や「プラットフォーム」を浸透させた企業＝勝ち組といった構図になっています。 この『プラットフォーム革命』では、プラットフォームって何なのか、どのようなプラットフォームが勝ち残るのか、といったことをたくさんの会社の事例をもとに学ぶことができます。 中でも、下記のプラットフォームの 4 つのコア機能に関する説明は参考になります。 何か新しいプラットフォームを作成するときには、これらのコア機能をどう達成しているのかが重要になってきます。 (1) オーディエンス機能 消費者とプロデューサ（提供者）を集める機能のこと。 Airbnb などは他のサービスと勝手に連携させて顧客を奪うみたいなことまでやっている。そのようなやり方の是非はともかく、プラットフォームとして成立するには、消費者とプロデューサの量を確保して、取引を成立しやすくするという流動性が必要になる。 消費者とプロデューサをやみくもに集めると、その人数のアンバランスの問題も出てくる。Uber などは、価格を動的に変更させる仕組みを導入して、この需要と供給のバランスをうまく解決するようにしている。 (2) マッチメイキング 消費者とプロデューサを結びつける機能のこと。 消費者とプロデューサの量を確保できたら、今度は両者をいかにマッチングさせるか（取引成立させるか）が課題となる。 うまくいっているプラットフォームは、ユーザの数が増えても自動的にスケールするような仕組みができている。Uber は巡回セールスマン問題的な問題を自動で解き、非常に早く車が到着するようになっている。アマゾンは協調フィルタリングの仕組みで膨大な商品の中からオススメできている。Youtube は視聴時間に基づいたおすすめ機能がうまく働いている。 (3) 中核となるツールとサービス コアとなる取引を円滑化するためのツールやサービスのこと。 設計者はとにかくいろんな機能を詰め込みすぎてしまう。 まずは シンプルで効率的 なツールやサービスを提供することが大切。 と、Facebook のマーク・ザッカーバーグも言っている。 Twitter はシンプルなテキスト送信機能から始めた。 Google はシンプルな検索機能から始めた。 Amazon は本だけの販売から始めた。 こういった今でも成長しているプラットフォームは、シンプルで使いやすい機能から始めてうまくいっている。 (4) ルールと基準 ユーザが安心して使えるような仕組みが必要。 一度はユーザを集めたのに廃れてしまったプラットフォームは、ユーザの安心感を満たせなかったりしてユーザが離れていってしまったものが多い。 ユーザ数が膨大になってくると、プラットフォームの提供者がユーザの行動を監視することは不可能になってくる。 そこで、Airbnb などは、消費者とプロデューサの間で評価をつける仕組みを導入して、自動的に評価の低いユーザは淘汰されていくようになっている。 ただ、この評価という仕組みは後付けなので、できればユーザには最初からよい振る舞いをしてもらいたい。 そのためには、ちゃんと「ルールと基準」をプラットフォーマーが定めて提示する必要がある。 法的な強制力がない場合でも、ほとんどのユーザはそれに従ってくれる。"
},
{
url: "/p/urdve7g/",
title: "コルク代表 佐渡島庸平さんのお話",
date: "2019-02-07T00:00:00Z",
body: "コルク代表 佐渡島庸平さんのお話 『インベスターZ』 や 『宇宙兄弟』 を担当されていた佐渡島さんのお話を聞いたのでメモメモ。 コミュニティを作ると強い 宇宙兄弟のコミュニティを作って、今は 35,000 人くらいいる。 そこで商品を紹介すると、10% 以上の人が買ってくれるというすごいコンバージョンレートを達成できる。 がんばっていろんな店に商品を並べるより、圧倒的に効率がよく、すぐ売り切れる。 インターネットでつながった世の中では、このようなビジネスモデルが今後主流になっていくだろう。 ボットとのコミュニケーション チャットボットとチャットしているとき、相手が機械だと分かっていても褒められるとうれしいと感じる。 それはきっと、何がよいことなのか、褒めるべきことなのかという設定を、裏側で人間がやっていることを知っているからだと思う。 コンテンツの値段はタダになる コンテンツはすべて無料になるだろうという前提で活動している。 少なくとも中国はもうそうなっている。 一方で、他の人よりも早くコンテンツ（情報）を手に入れられるということに対してはお金を払う人はたくさんいる。 ▽インベスターZなどがタダ同然の値段で売ってたりしたのは佐渡島さんの仕業なのかな。"
},
{
url: "/p/vsw6doh/",
title: "読書メモ『20円で世界をつなぐ仕事』小暮真久",
date: "2019-02-01T00:00:00Z",
body: "読書メモ『20円で世界をつなぐ仕事』小暮真久 20円で世界をつなぐ仕事 小暮真久 ダイヤモンド社 TABLE FOR TWO という仕組みを世の中に広げる NPO 法人をやっている小暮さんの本。 主に会社の食堂に導入するように活動していて、カロリーの低いヘルシーメニューを頼むと、その代金のうち 20 円がアフリカに寄付され、子供の食費1人分に当てられるという仕組みです。 従業員の多い会社に勤めている方は、食堂に導入されているのを見たことがあるかもしれません。 ヘルシーメニューを頼むことで、自分はカロリーオフできて、さらにアフリカの子供を救うことができる。 一粒で二度美味しいとてもよい仕組みなのだけど、「寄付」という仕組みがベースである都合上、企業に導入してもらうのにはいつも苦労しているようです。 NPO 法人はボランティア的なものだと思われることが多く、そういった活動から給料を得ているということ自体に難色を示す人がまだまだいる。 それでも、アフリカの子供たちを直接笑顔にできるという仕事にとても生きがいを感じているようです。 そんな天職に巡り逢えるのってとても幸せなことだと思います。 この本を読んだ人が NPO 法人の活動というものを理解し、世界中の人を幸せにする仕組みがもっともっと広まっていくとよいですね。"
},
{
url: "/p/g2d9uzk/",
title: "2019-01-14 大室山からの景色は壮観！",
date: "2019-01-14T00:00:00Z",
body: "2019-01-14 大室山からの景色は壮観！ 伊東にある大室山（おおむろやま）に登ってみました。 といっても、歩いて登山するわけではなくて、こんなリフトで登っていきます。 往復500円。 このリフトはすごい低空で、ときどき地面に足が着いたりして面白いです。 頂上に着くと、火口を一周できます。 360度景色を見渡せるのですごく景色がいいです。 近くに来たときはぜひ登ってみるとよいです。 ちなみに隣にはシャボテン公園があります。カピバラさんがいます。 風が強くて、この季節はちょっと寒かったです。 ニット帽が必須かな。 車でちょっと移動すると、世界遺産の韮山反射炉（にらやまはんしゃろ）があります。 残存する唯一の反射炉らしいです。 説明員の人が丁寧に歴史を教えてくれます。 この反射炉は、銑鉄を熱で溶かして大砲を作る設備です。 熱を壁に反射させながら温度を上げて金属を溶かすので反射炉と言います。 ここで作った大砲はペリー来航に備えて東京の品川に設置されました。 砲台を設置する場所なので「台場」と呼んでいます。 台場は 8 つ作られたのですが、今では台場公園として第三台場だけ入ることができます。 もうひとつ第六台場も残っているのですが、陸路がなくて入ることはできません。 お台場に行くことがあったら、買い物だけじゃなくて、砲台跡も見てみるとおもしろいです。"
},
{
url: "/p/s46j9sq/",
title: "お名前.com の共用サーバーを Let's Encrypt で SSL 対応",
date: "2019-01-12T00:00:00Z",
body: "お名前.com の共用サーバーを Let's Encrypt で SSL 対応 Chrome で https に対応していない Web サイトにアクセスすると、アドレスバーに「保護されていない通信」という警告が出るようになりました。 Web サーバーの管理者は、https (SSL) への対応がほぼ必須になっています。 ここでは、お名前.com の共用サーバー（SD-11、SD-12 プランなど）で、SSL を有効にし、http によるアクセスがあったときに https なアドレスにリダイレクトする設定方法を説明します。 Let\u0026rsquo;s Encrypt による SSL 対応 お名前.com の共用サーバーで Web サイトを運用している場合は、下記のコントロールパネルからポチポチやるだけで、簡単に SSL (https) によるアクセスを有効にすることができます。 共用サーバーSD コントロールパネル https://cp.rentalserver.jp/ 自前の Web サーバで SSL 設定を行おうとすると、証明書の発行手続きや設定などが結構面倒ですが、このコンパネからポチポチやれば 1 分で設定完了です。 無料証明書で有名な Let\u0026rsquo;s Encrypt のサービスに対応しているので、無料で SSL 対応することができます。 http アクセスを https にリダイレクトする 数時間待って、無事 SSL の設定が反映されると、https:// によるウェブサイトへのアクセスが可能になります。 ただし、そのままだと古い http:// のサイトも残ったままです。 ここでは、Web サーバー (Apache) の設定ファイルである .htaccess を修正（なければ新規作成）することで http から https へのリダイレクト設定を行います。 ここでは、下記のような手順で修正することにしましょう。 sftp コマンドでサーバ上の .htaccess を取得（存在する場合のみ） ローカルで .htaccess の内容を修正 sftp コマンドでサーバ上の .htaccess を置き換え まずは、コントロールパネルの「FTP・SSHアカウント」のページで、接続用のアカウント名などを確認しておきましょう。 例えば下記のような感じで設定されているはずです。 アカウント : sd0000000@gmoserver.jp パスワード : mypassword SSHサーバー名 : ssh10.gmoserver.jp (1) sftp コマンドで既存の .htaccess を取得 まず、Web サーバ上のコンテンツ用ディレクトリに置かれている .htaccess ファイルを取得します。 存在しなければ無視して大丈夫です。 $ sftp sd0000000@gmoserver.jp@ssh10.gmoserver.jp Password: xxxxxxxx sftp\u0026gt; cd example.com sftp\u0026gt; get .htaccess sftp\u0026gt; quit (2) ローカルで .htaccess を編集 サーバから取得した .htaccess ファイルを編集して、http アクセスを https へリダイレクトする設定を追加します。 .htaccess ファイルが存在しなかった場合は、新しくテキストファイルとして作成し、下記のような設定を追加してください。 # HTTPS redirect settings RewriteEngine on RewriteCond %{HTTPS} off RewriteRule ^(.*)$ https://%{HTTP_HOST}%{REQUEST_URI} [L,R=301] (3) サーバ上の .htaccess を上書き .htaccess ファイルの修正が終わったら、同じディレクトリから再び sftp でサーバに接続し、下記のように .htaccess ファイルをアップロード（上書き）します。 sftp\u0026gt; cd examle.com sftp\u0026gt; put .htaccess sftp\u0026gt; quit これで、http://example.com/ というアクセスが、自動的に https://example.com/ にリダイレクトされるようになります。 さいごにちょっと広告（＾＾ お名前.com のドメイン取得はこちらから → お名前.com のレンタルサーバーはこちらから → お名前.com の VPS はこちらから →"
},
{
url: "/p/ew5zmmw/",
title: "Nginx で 403 Forbidden エラーが出るときのチェック項目",
date: "2019-01-10T00:00:00Z",
body: "Nginx で 403 Forbidden エラーが出るときのチェック項目 nginx サーバを起動して Web ブラウザでアクセスしたときに、ブラウザ上に 403 Forbidden エラーが表示されるときは、パーミッション系のエラーが発生しています。 サーバ自体は稼働していますので、下記のあたりを確認すれば無事表示されるようになります。 ファイルに読み取り権限、ディレクトリに実行権限を付ける html ファイルなどのコンテンツファイル自身には読み取り権限、ディレクトリには実行権限が必要です。 $ chmod 0755 -R /home/maku/website ドキュメントルートまでのディレクトリに実行権限 (x) を付ける 例えば、ドキュメントルートを /home/maku/website としている場合は、/、/home、/home/maku、/home/maku/website のディレクトリに実行権限が必要です。 $ chmod +x /home/maku 特定のディレクトリのパーミッションは下記のように確認できます。 $ ls -ld /home/maku drwx--x--x 5 maku maku 156 1月 10 17:32 /home/maku nginx の設定を再読み込み ファイル群のパーミッションを変更しただけでは nginx の再起動は必要になりませんが、nginx の設定ファイルを変更した場合は、設定ファイルを反映する必要があります。 $ sudo service nginx reload"
},
{
url: "/p/jowgstm/",
title: "Nginx の設定: http でアクセスされた場合に https にリダイレクトする",
date: "2019-01-10T00:00:00Z",
body: "Nginx の設定: http でアクセスされた場合に https にリダイレクトする nginx サーバの SSL 対応（https 有効化）が終わった後は、http プロトコルによるアクセスは避けてもらいたいですね。 そのような場合は、下記のように設定しておけば、http でアクセスされた場合に、https で再度アクセスしてもらうようにクライアントに応答することができます（301 という値は、Moved Permanently を示す HTTP レスポンスコードです）。 /etc/nginx/conf.d/xxx.conf server { listen 80; server_name example.com; return 301 https://$host$request_uri; } server { listen 443 ssl http2; server_name example.com; # ... } 結果として、Web ブラウザから http://example.com/ にアクセスすると、Web ブラウザは自動的に https://example.com/ という URL でアクセスし直すことになります。"
},
{
url: "/p/xdsom3a/",
title: "Nginx（Web サーバー）のメモ",
date: "2019-01-10T00:00:00Z",
body: "Nginx（Web サーバー）のメモ"
},
{
url: "/p/xkpjfcf/",
title: "Sakura VPS レンタルサーバーを Let's Encrypt で SSL 対応",
date: "2019-01-10T00:00:00Z",
body: "Sakura VPS レンタルサーバーを Let's Encrypt で SSL 対応 今更ですが、さくらインターネットでレンタルしている Sakura VPS の Web サーバーを SSL (https) に対応しました。 とりあえず今回は無料の Let\u0026rsquo;s Encrypt の証明書を、nginx サーバに設定します。 使っている OS が CentOS6 だったので、ついでに CentOS7 をクリーンインストールすることにしました。 といっても、さくらインターネットの VPS の設定画面でポチポチとやっていくだけ。 ここで、[public] CentOS_LetsEncrypt というスタートアップスクリプトを選んだら、自動的に SSL の証明書などの対応が完了します。 入力するパラメータはドメイン（example.com など）と連絡用のメールアドレスだけ。 Web サーバの nginx も自動的にインストールされて、Web サーバにアクセスできる状態で起動するのですが、nginx の設定は少しだけ調整する必要があります（ドキュメントルートなど）。 数分で OS の再インストールが完了し、下記のような nginx の設定ファイルが自動生成されていました（ドメイン名は example.com に置換してあります）。 SSL の設定も完了した状態になっています。 /etc/nginx/conf.d/https.conf map $http_upgrade $connection_upgrade { default upgrade; \u0026#39;\u0026#39; close; } server { listen 443 ssl http2; server_name example.com; location / { root /usr/share/nginx/html; index index.html index.htm; } ssl_protocols TLSv1.2; ssl_ciphers EECDH+AESGCM:EECDH+AES; ssl_ecdh_curve prime256v1; ssl_prefer_server_ciphers on; ssl_session_cache shared:SSL:10m; ssl_certificate /etc/letsencrypt/live/example.com/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/example.com/privkey.pem; error_page 500 502 503 504 /50x.html; location = /50x.html { root /usr/share/nginx/html; } } HTML ファイルの格納ディレクトリ（ドキュメントルート）が、デフォルトでは上記のように /usr/share/nginx/html になっているので、ここを適切なディレクトリパス（/home/maku/website など）に置き換えてやれば完了です。 # 設定ファイルを編集 $ sudo vim /etc/nginx/conf.d/https.conf # 設定を反映 $ sudo service nginx reload https://example.com/ など https でアクセスできれば OK です。 「403 Forbidden」が出るときは、こちらをチェック。 さいごに広告（＾＾ さくらの VPS はこちらから →"
},
{
url: "/p/z97ysqu/",
title: "好きな映画、ドラマ、TV番組、マンガ",
date: "2019-01-10T00:00:00Z",
body: "好きな映画、ドラマ、TV番組、マンガ いやぁ、映画ってほんっとうにいいもんですね。 貧乏モノ、病気モノ、音楽モノの映画とかは鉄板で感動してしまいます。 好きな映画 『小説家を見つけたら』 : ショーンコネリー主演。 とってもほんわかできる映画で、すべての人におすすめできる映画です。 16歳の高校生ジャマールは、自分が書いていた小説のメモを落としてしまいます。 そのメモは戻ってくるのですが、そこには細かい批評がびっしりと書き込まれていました。 ジャマールは最初、「落書きしやがってと」思って読んでいましたが、その的確な指摘にのめり込んでいきます。 それは、行方の分からなくなっていた幻の大作家フォレスターによる仕業だったのです。 『カンフーハッスル』 チャウシンチー主演。 少林サッカーもよいのだけど、こっちの方が好きかな。 無駄に派手なところがわざとらしくて好きです。 『セッション』 : J・K・シモンズが熱い、熱すぎる。プロのジャズ演奏者を育てるために徹底的にしごき倒します。それが嫌がらせなのか、本気で育てたいのかわからない。それでも必死にがんばる主人公。この映画を見ると、必死になるというのはこういうことなんだってことがわかります。それにしても最後のシーンはイイ。ラストは 5 回くらい見ました笑。そして師弟愛の行く末がモヤッとしたまま終わるのがまたイイ。 『ザ・ハッカー』 : ハッカー題材にした映画って適当な描写が多いのですけど、初めて本格的だって思えたハッカー映画です。ドラマだと『ブラッディ・マンデイ』もハッカーものとしてはよくできてますね。 『ビューティフルマインド』 : 狂ってしまった数学者ジョン・ナッシュの話。 ゴールのわからない問題に対してずっと向かい合っている人って、少なからずおかしくなってしまう危険性があるのだと思う。 ちょっと悲しくも暖かい気持ちになれる映画です。 『雀鬼シリーズ 1〜5』 : Vシネマですけど。。Vシネマ史上初めてオリコントップを独占し続けた伝説の麻雀映画です。 伝説の雀鬼、桜井章一さんが監修してます。 今でもこの映画を凌ぐ麻雀映画はないし、今後も出ないでしょうね。 『プレステージ』 : 究極の発明により、究極のマジックが生み出されました。 ただ、その裏にはとんでもない犠牲が隠されていました。 印象に残る映画だけど、2 回見る気にはならないかもしれない。 好きな俳優 チャウ・シン・チー: ハッスルハッスル！ ショーン・コネリー: 「小説家を見つけたら」を見てからはまりました。 ロバート・ネッパー: プリズン・ブレイクのセオドア（ティーバッグ）が最高。トランスポーター３の悪役とかやってます。 ブレンダン・フレイザー: 「センター・オブ・ジ・アース」を見て、他の作品も見てみたくなりました。 好きなドラマ 僕と彼女と彼女の生きる道: ハーモニカの練習をしている娘からハーモニカを取り上げて投げつけ、「うるさいんだよ！」と怒鳴るような父親（草なぎ剛）が心を開いていく物語。草なぎ君ドラマには名作が多いけど、その中でも一番好きかも。 銭の戦争: 草なぎ剛さん主演。登場人物の本心がなかなか読めないところが面白いです。復習心から行動していた主人公が、だんだんとお金に取り憑かれていくように見えるけど、実はそうではないと思わせたり、でも最後の最後で・・・といった感じで飽きさせません。 銭ゲバ: 貧乏でセコイ主人公（松山ケンイチ）とその父親（椎名桔平）とのやりとりが最高です。「銭ズラ〜〜〜」っていうセリフは残念ながら流行りませんでした。椎名桔平の「おーこわいこわい」っていう人をおちょくるようなセリフが好き。 プリズンブレイク: セオドア・\u0026ldquo;ティーバッグ\u0026rdquo;・バッグウェルが最高です！毎シーズン、「こんな状況抜け出せるわけない！」ってところから脱出してしまう展開がたまらなくおもしろいです。 TRICK: 謎解き的なストーリーも面白いですが、仲間由紀恵と阿部寛のドジ＆ドジのかけあいが好きです。ほんわか系。 セトウツミ: セト＆ウツミのくだらない会話だけで進んでいくドラマなんですが、絶妙なツッコミが心地よいです。ほんわか系。 節約ロック: 松本タカオ（上田竜也さん）の頭のわるすぎる節約術が毎回笑わせてくれます。悪巧みしてるときの顔がおもしろすぎるｗ 下町ロケット: 阿部寛さんのクサい演技に毎回感動してしまいます。最後には真面目に仕事に取り組んできた人たちが報われる正義感に溢れるドラマです。 僕の初恋をキミに捧ぐ: 学園おちゃらけラブストーリーかと思ったら感動モノでした。原作はフラワーコミックスなんですね。 ノーコンキッド: 田中圭主演のゲームセンターのお話。昔のゲームセンターを知ってるので、すごく懐かしい感じがする。 おいしい給食: そこまで美味しそうでもない給食のおかずをハイテンションで美味しそうに食べるのがサイコー。おいしいっおいしいっおいしーよっ♪ 草なぎ剛さん、阿部寛さんのドラマが好きな傾向があるみたいです。 好きなマンガ／アニメ 放課後さいころ倶楽部 グラップラー刃牙 ハイスコアガール ダンジョン飯 はじめの一歩 響 カイジ ジョジョの奇妙な冒険 あしたのジョー 上野さんは不器用"
},
{
url: "/p/hnoamfo/",
title: "管理人",
date: "2019-01-10T00:00:00Z",
body: "管理人"
},
{
url: "/p/3tog8xc/",
title: "ポリシー、座右の銘、モットー",
date: "2019-01-08T00:00:00Z",
body: "ポリシー、座右の銘、モットー 行動の選択基準 何かの選択や行動で迷ったとき、こんな感じで判断するようにしています。 まわりが笑顔になる方を選ぶ 楽しい方、楽しくなりそうな方を選ぶ 体によい方を選ぶ 例えば、料理のメニューを見て迷ったら、健康そうな料理を選びます。 また、落ち込んだときに気分良く過ごすにはこう考えます。 気にしない、気にしない、まいっか 別に死ぬわけじゃない 時間の使い方 趣味 → 仕事 → 勉強 → 趣味や仕事は「今」のため。 勉強は「将来」のため。 これらをバランスよくやらなきゃだめ。 日々やるべきことは、それを行うタイミングに注目すると、3 種類に分類できる。 TODO を書き出すときは、これらを分けて管理するとよい。 Routine: 定期的にやること（日課としての学習など） ToDo: 必ず終わらせなければいけないこと（終わったらリストから削除できる重要なタスク） Whim: 時間があるときにやればよいこと（趣味の読書など） 学びについて 真の学びとは 学びの真の目的は、スキルの学習ではなく「発達」。「覚える」のではなく、「察知する」力を付けていくべき。 苦労して手に入れたものの方が長く楽しめる 「仕組み」を学ぶ 何事に関しても、「仕組み」を知る・学ぶことを怠らないようにしたい。 特に技術的な事柄に関しては。 書籍『HACK PROOFING YOUR NETWORK』の中に、次のような言葉があります。 ハッキングのスキルを学ぶために費やす時間は、重要です。 ある目的を達成するだけの人は、時間をかけずに、スクリプトキディになりやすくなります。 そうなると、できることには限界があります。 どんなことに対しても「仕組み」を学ぼうという姿勢を持つことは重要だと思います。 例えば、ある仕事を片付けるための方法を聞いて、サクッと仕事を終わらせるだけの人と、その方法がどんな仕組みで成り立っているのかを同時に学ぼうとする人では、技術力や発想力の向上に差が出てきます。 ある物事に関して改善点を探すためには「仕組み」を知らないといけないし、まったく別の新しいアイデアを生み出すための知識として活用するためにも、「仕組み」を知ることは重要です。 「仕組み」を学ぶ姿勢なくして技術力の向上なし！ 人間関係 コネを作ることを目的にして奔走しない。 自分の魅力（知識、能力、実績、人間性）を高める ことで、人が向こうからやってくる状態が理想。 人を疑うのではなく、まずは信じる こと。 何事にも疑いやすくなっているこのご時世、無条件に信じるくらいでちょうどいい。 こちらから信じなければ、信頼関係は生まれない。何も始まらない。 下記は、PRESIDENT『ハーバード式仕事の道具箱 「怒りの感情」をコントロールする法』より。 誰かに不快なことや受け入れ難い条件を突きつけられた時は、逆に 相手の視点を理解して、賞賛する のがよい。 賞賛すれば、相手にもこちらの協力をしようという感情が芽生えやすい。 相手の地位の分野を見極めて敬意を払う ことで、信頼感や相互協力を高めることができる。 モノを増やさない ものを使わずにたくさん溜め込むと、宝の持ち腐れになったり、なくした時にショックが大きい。 理想的には、仮に家が火事になって、身の回りの物が全部なくなった場合にものほほんとしていられるくらい 身軽になる こと。 使い捨てのものはどんどん使って捨てる。 読んで捨てられる資料はどんどん読んで捨てる。 使わないものは人にあげる。 増やすべきはモノではなく、自分の知識や能力 であることを忘れない。 電子的なデータなどは、自宅以外のクラウドサービスにバックアップしておけば安心感を得られます（必ず有料のサービスを使うこと）。 現在の世の中は、まだ財布を持ち歩く必要がありますが、財布をなくした場合にもすぐに対処できるようにしておくのがよいです。 簡単なのは、財布の中身の写真を撮って、なくした場合の連絡先などをまとめてクラウド上に置いておくこと。 メモに対する考え たくさんメモを取ります。 すぐにググって調べられることをメモる必要ないのでは？という考えもありますが、いろんな情報を集めてまとめたい場合はメモは必要だし、自分なりの考えを自分の言葉で書くことで頭の中を整理することができます。 メモに日付が入っていれば、過去に自分が何に興味を持っていたかも分かります。 リファレンスのようなページを自分で作る理由 自分が勉強してきたことを履歴として残すため。自己満足ともいう。 純正のリファレンスマニュアルなどには自分なりのメモや、補足などを追加できない。 自分の理解しやすいように構成できる。情報を集約できる。 他人からのフィードバックを得ることもできる。 スケジューリングについて 下記は、THE21『なぜか「仕事が速い人」の習慣』より。 スケジュールには、先に学習時間を入れてしまうのがよい。 仕事を細かく分解するメリット 不要な仕事の存在に気付く。 スキマ時間を使って処理できるようになる。 他の人に頼みやすくなる。 型に当てはめて作業しやすくなる。 企画書作成の例：「現状分析」→「他社事例調査」→「課題整理」→「施策立案」→「費用対効果の検討」。"
},
{
url: "/p/afwfp22/",
title: "好きな顔文字",
date: "2019-01-07T00:00:00Z",
body: "好きな顔文字 わーぃ ٩(๑❛ᴗ❛๑)۶ わーぃ (｡╹ω╹｡) キュピーン (ฅ\u0026rsquo;ω\u0026rsquo;ฅ) エッ？ ∑(ﾟДﾟ；) （゜Д゜） (゜O゜; (　ﾟдﾟ) (つд⊂)ｺﾞｼｺﾞｼ (；ﾟдﾟ) (つд⊂)ｺﾞｼｺﾞｼ _, ._ （；ﾟ Дﾟ） その他 φ(･ｪ･o)~メモメモ ミ(・ 。・)彡 ウーパールーパー o(・・)oヾ(￣▽￣ ) ヨチヨチ (´･∀･`)ﾍｰ (∩ω・。)ﾉｼ ヨシヨシ( ^・ェ・^)/(; ; )グシュ (..､)ヾ(^^ )いいこいいこ |ω・`）チラ 　_ ∩ (　ﾟ∀ﾟ)彡　バイソン！バイソン！ ⊂彡"
},
{
url: "/p/mcshm5f/",
title: "読書メモ『ザ・シークレット』ロンダ・バーン",
date: "2018-12-31T00:00:00Z",
body: "読書メモ『ザ・シークレット』ロンダ・バーン ザ・シークレット ロンダ・バーン 角川書店 自分の望む姿をイメージすることでそれが叶うという、引き寄せの話の集大成のような本です。 1ページ1ページのデザインがきれいで、思わず買ってしまった本です。これも引き寄せ。 引き寄せ的な考え方には否定的な人が多いのでしょうけど、幸せだと考えるのは自分自身なのだから、考え方から変えていくというのは実は本質を突いているのではないかと思います。 プラシーボ効果による治癒現象など、思い込みによって身体に影響が現れるということも実証されています。 まずは信じるところから始めてみよう。 ちなみに、ザ・シークレットは映像化もされていて、Netflix で見ることができます。 映像の方は宗教勧誘みたいな感じがしてしまうので、個人的には書籍の方が好きです。 良い思考をしているときに気分が悪くなることはない。もしも気分が悪いようなら、それはあなたが自分の感情を害するような思考をしているからだ。気分が悪くなったら、そのもとになっている思考を変えるか、気分転換をしよう。 あなたが欲しいと思ったものを、既に手に入れたと信じなければいけません。まだ受け取っていないと思えば、それをまだ持っていない状況を引き寄せてしまいます。 車が欲しければ、まずその車に試乗してみなさい。家が欲しければ、その家で使うものを買いなさい。そして、その家に実際に入ってみてください。その気分になれることはなんでもしてみると、それが引き寄せを実現するのです。 チャンスが到来し、衝動が起き、直感的なひらめきが浮かんだらすぐ行動を起こしなさい。それがあなたのなすべき事です。それだけでよいのです。 自分自身を愛と尊敬をもって扱ってください。そうすれば、あなたを愛し、尊敬してくれる人々を引き寄せます。 人生を好転させるために、真っ先にできることは、心から感謝できることの一覧表を作ることです。感謝することこそ、あなたの人生により豊かさをもたらす方法です。もし『ザ・シークレット』の中の知識をただ1つだけ選ぶとしたら、それは感謝です。 その人の長所を認め、感謝することに焦点を合わせ始めると、良いものをもっともっと引き寄せ、いつの間にか、問題は消えていきます。 愛の感情を作り出すあなたの能力は無限です。愛することができる全ての物を愛してください。愛することができる全ての人を愛してください。 （白紙の）小切手に、あなたの名前、金額などを書き入れて、目立つところに置いてください。その小切手を見て、今、その額を手にした気持ちになってください。そして、そのお金を使い、買いたいもの、やりたい事を全て実現している自分の姿を想像してください。それがどれだけ素晴らしい気持ちか実際に感じてください。 「お金が足りない」という思いから、「お金は充分にある」というように考え方を変えなくてはなりません。 「お金を稼ぐにはたくさん働いて苦労しなければならない」という考えを持っているようでしたら、それをすぐに捨ててください。その思いを「お金は容易に、かつ、頻繁に入ってくる」に変えましょう。 ノーマンは不治の病と診断されていました。医者は彼にあと数ヶ月の命だと宣告しました。そこで、ノーマンは自分の力で治すことに決めました。彼がしたことは、三ヶ月の間、喜劇映画を見て、ひたすら笑い続けることだけでした。すると、その三ヶ月の間に彼の体内から病気が消え、医者たちはその回復を奇跡だと驚嘆したのです。─ 笑いは本当に最高の薬なのです。 もしも、あなたがあまり気分がよくないときでも、誰かが、「ご機嫌はいかがですか」と尋ねてきたら、その人が気分転換するように言ってくれたと思い感謝してください。あなたの望むものについてだけ話してください。 私は「はっきりと見えます。はっきりと見えます」と繰り返し唱えました。三日後、私の視力は回復しました。 この法則の真髄は、あなたは豊かさを考え、豊かさを見、豊かさを感じ、豊かさを信じなければならないということです。あなたの頭に有限という概念をいれないようにしましょう。 あらゆるものが、全ての人々、全員に十分にあります。 「あらゆるものが豊かにある」「供給は無限にある」「宇宙はすばらしく気前が良い」ことを選び、知ってください。 思い通りにうまくいっていないことがあっても、不満を言ったり、とがめたりして、エネルギーを使ってはいけません。望むものを抱きしめてあげてください。 あなたの周りにあるものを祝福し、賞賛しましょう。 誰かを賞賛している時にはあなたは愛を与え、偉大な波動を放射しているのです。すると、それが100倍にもなってあなたに返ってきます。 あなたの敵でも賞賛し祝福しましょう。敵を賞賛し祝福すると、賞賛と祝福があなたに返ってきます。 世界の「問題」に焦点を合わせるのではなく、あなたの注意とエネルギーを「信頼」「愛」「豊かさ」「教育」「平和」などに向けてください。 あなたの夢やあなたのビジョンだけに焦点を合わせて、あなたの環境から全ての競争を取り払ってください。 あなたは創造主です。そして、この地球上で、あなた自身を創造しているのです。 「私は〜である」という言葉に威力がある（アファーメーション）。 私は全ての素晴らしいものを受け取っています。 私は幸福です。 私は豊かです。 私は健康です。 私は愛です。 私はいつも時間に間に合います。 私は永遠に若いです。 私は毎日エネルギーに満ち溢れています。 私たちはみんな繋がっていて、全ては一つです。 あなたがしなければならないことは、今、心地よい気持ちになることだけです。 感謝するクセをつけるために、毎日の終わりに感謝の気持ちを書き出していくのがいいかもしれませんね。 富ではなく、多くの人が幸せ、感動を味わえるようなことをしよう。富を得ることだけを目的にすると、争いや不幸を生む。幸せを与えること、味わうことは無限なのだから。"
},
{
url: "/p/x7kd593/",
title: "「ふたりザードリィ」やってみた",
date: "2018-12-23T00:00:00Z",
body: "「ふたりザードリィ」やってみた RPG アツマールで公開されている「ふたりザードリィ」やりました。 パーティーが2人しかいない簡単なウィザードリィ風ゲームです。 レベルアップの概念もなくて、お金でスキルアップしていくだけ。 すごいシンプルなのにゲームバランスは結構良くておもしろいです。 ウィザードリィは気になっているけど敷居がちょっと高いという人にもおすすめです。 基本的にはウィザードリィをベースにしてますが、アイテム名とかはドラクエをパロっていたりします。 「ほしふるゆびわ」とか。 1週目でボスを倒すと、2週目が始まって裏ボスが出てきます。 裏ボスは若干の謎解きあり。 裏ボスを倒すと最強アイテムが手に入って3週目に入るのだけど、3週目は特にゴールなしかな・・・？"
},
{
url: "/p/hq62imj/",
title: "読書メモ『会社を辞めずに年収を倍にする！ノーリスクな副業・起業・独立のためのパーフェクトガイド』藤井孝一",
date: "2018-12-17T00:00:00Z",
body: "読書メモ『会社を辞めずに年収を倍にする！ノーリスクな副業・起業・独立のためのパーフェクトガイド』藤井孝一 会社を辞めずに年収を倍にする！ノーリスクな副業・起業・独立のためのパーフェクトガイド 藤井孝一 講談社 最初は会社勤めをしながら、週末起業するのがよい。「給与所得」と「事業所得」を確保しながら、自分で稼ぐ力を身に着けることができる。 会社にいながらできないものは、会社を辞めてもできない。 大切なのは辞めたくなった時に辞められること。いざというときにはこっちで行くという仕事があれば、本業でも大胆になれる。 1円稼ぐところから始める。フリマで不要になった衣類やCDを売ることから始めるのでもよい。 会社に売り上げについて探りを入れられたら「お小遣い程度です」と言っておくのが良い。 銀行では原則として副業は認められない。公務員も、公務員法によって禁じられている。 何でも屋ではダメで（中小企業診断士とかは何でも屋の典型）、ここだったら絶対に勝てるという土俵を持つこと。ありきたりのビジネスであっても、誰もやっていない分野を見つけて自分をポジショニングしていく。 「あのお客さんにとっての専門家になろう」と意識すること。私がお願いしている税理士は、お願いしなくても税法の改正などがあったときに教えてくれる。 給与所得を失っても、家族が暮らせるだけのキャシュフローを確保しておくのがよい。 8歳くらいのときに「やりたい」と思っていた夢は、その人の本質に根ざしている。 4つの条件に当てはまる仕事から始め、時間に拘束されずに稼ぐ仕組みを作る。 自分の趣味や好きな仕事 元手のかからない仕事 スキルアップにつながる仕事 粗利が大きい商品を扱う仕事 ポータルサイトの運営もよい。特定の分野であらゆることを取り扱うサイトを作って、利用者の利便性を高める。 週末起業で飲食店のオーナーになった人でも、仕組みを作って最後に人に任せられるようになった人もいる。 ベンチャー企業が出資を募る際にも、事業計画だけでなく、テストマーケットの結果があると有利。人気のブログやメルマガが本になるのは、事前にテストマーケットが済んでいる点が大きい。 人が作った仕組みを利用すれば失敗のリスクを下げられる。 粗利が小さく、固定費がかかるビジネスはダメ。 中小企業診断士の資格が直接役立つということはなかったが、資格を取らなかったら、どんな分野でビジネスをするのか気持ちが固まらなかった。 専門性の高くない分野の資格で食べていきたいのなら、他の資格を取得して、もう一つの専門分野を持って差別化する。 土日の勉強で取れる資格や検定は、即戦力になるものがある。 福祉住環境コーディネーター eco 検定 国際会計検定 (BATIC) ビジネス実務法務検定 カラーコーディネーター ゲームやスマホの音楽を作曲して売る方法がある。音楽の素材を作ってネット販売し、月100万円売り上げている人もいる。画像の販売はよくあるが、音楽でやるという発想。 ネット販売で成功している人の多くは、実店舗を持っていて、販路の一つとしてネットを利用している。その他は、セミナーをビデオにしたり、ノウハウをPDF化して商材にして売っているケースが大半。 オークションサイトでは、一般的に不用品を販売しているイメージがあるが、稼いでいる人はきちんと仕入れをして売っている。 ネット古書店を始めるときは、ネットークションで中古品を売るときと同じように古物商許可申請が必要。 農業は比較的実働時間が短いので、週末起業で農業をするのもよい。農業が初めての人は、農業高校の教科書で基礎を学び、農家のアルバイトをしておくのがよい。 農地は転用するのが難しく、宅地にすると税金が上がるため、レンタル農園にして貸し出しているところが結構ある。農機や農具も、農協からレンタルできる場合がある。 独立するときはサラリーマンのうちに、**「会計」「マーケティング」「法律」**を学んでおく。個人情報保護法、著作権法、訪問販売法、特許法（特定商取引に関する法律）について基本的なことは知っておいた方がよい。 「誰に」「何を」「どう売るか」を考えることを習慣にする。 地元の商工会議所や、地方自治体の創業担当の窓口を尋ねれば、いろいろと相談に乗ってくれる。 あなたが会社勤めをしている場合、開業届が受理されるかどうかは、税務署員次第。**事業とは「対価を得て継続的に行われるもの」**である。 わざと事業収益を赤字にして給与の税金を取り戻そうとする人がいるので、週末起業の開業届が受理されないことがある。 開業届が受理されると、決算が赤字であれ、売り上げがゼロであれ、毎年必ず申告をしなければならない。 サラリーマンが給与所得以外に副収入を得ている場合は、通常は「雑所得」となり、年間20万円までは税務申告の必要はない。 銀行口座は事業用と家計用で分け、事業の投資効果を管理できるようにする。口座名義が個人名より、屋号になっていた方がはるかに信用度が高くなる。 自分が日々どのようにすごしているかを一週間記録してみると、結構無駄な時間を過ごしていることに気づく。 資格を取るときに学校に通うのはいい選択。学校では誰もが資格取得を目指しているので、取って当然という気になる。何か行動を起こそうというときは、まず居場所をそのような環境に変えること。 自分のオリジナルの商材やサービスでなければ、5万円の壁を超えることは難しい。 ライターや英文翻訳の仕組みでも、自分が働かなくていい仕組みは作ることができる。翻訳家やライターの登録バンクを作って、自分は仲介に特化するか、仲介さえもアルバイトに任せてしまえばいい。ただし、自分がこなし切れないほどの仕事の依頼があり、自分がその道で専門家になっていることが前提。 投資と借金 広告宣伝するのも投資。「売り上げの10％を広告に回す」などと決めておくとよい。 事務所を借りて家賃を払うという行為はムダに思えるが、事務所があると来客が増え、新しいビジネスチャンスが手に入る。それが次の売り上げにつながる。つまり、これも投資である。 借金をして投資して、その儲けから金利を払った残りが預金の金利よりも大きければ、預金よりも投資をした方が得である。これが起業家の借金に対する考え方。サラリーマンは借金を悪と考える。 法人化 ビジネスの世界は、原則として「法人」対「法人」で仕組みができている。「個人」とは契約を結ばないという方針の企業もある。 法人化すると、帳簿を複式簿記で作成して税務申告しなければならない。 個人のときは税務署に申告するだけでよかったのが、法人になると、都道府県や市町村にも申告しなければならない。 法人住民税というものがあり、都道府県や市町村に年間7万円程度を必ず支払わなければならない（赤字であっても）。 パソコンや備品、様々な会費などが、法人価格とされて多少割高になることがある。 企業の経営資源は「ヒト」「モノ」「カネ」と言われるが、個人が企業する場合も同様。この3つの資源を使ってお金を生み出していく仕組み（ビジネスモデル）を作れば、事業を立ち上げることができる。 事業の成長性や発展性が見込めない場合は、独立すべきではない。稼ぎが徐々に上がっていくかどうかがポイント。 独立の年齢は30代半ばが一つの節目だが、40代、50代のサラリーマンは、定年後の仕事を見据えて週末起業を始めておくのがオススメ。 会社を辞めたら、税金や保険料を自分で支払わなければならない。前年の所得から計算されるので、事業を始めた直後に数十万円単位の請求書が届くことになる。 友人と一緒に事業を始めたとしても、ずっと一緒に事業を続けるケースはまれ。揉めるのは大概お金のことなので、友人を部下として雇う場合も、給与は同じにしておいた方がいい。友人と上司部下の関係になるのは避けた方がいい。 多くの経営者が不動産投資をして、事業のリスクをヘッジしている。 株でも外為でも不動産でも、実際の取引で稼ぐだけでなく、ノウハウを公開して稼いでいる人もいる。 稼ぐ人は商品だけでなく、広告のノウハウを学ぶことにも熱心。通販のカタログを読み込んだり、通販のCMを見て日夜研究している。 ネット販売 ドロップシッピングは品揃えから値付けまで自分で決められる（アフィリエイトは、他の人の商品を告知代行するだけ）。 ドロップシンッピングで稼げるかどうかは、どの商品を扱うかによってほぼ決まる。 楽天などでショップを出店すると固定費がかかるが、オークションなら手数料は発生ベースの数百円で済む。 大企業が真面目に扱おうとしない物を売る。 中古品を扱う場合には、古物商の免許が必要。警察に行って手続きすれば簡単に取得できる。 ネットオークションに出品して稼いでいる人の多くは、ネットオークションで競り落として仕入れている。 ユーザーから仕入れるという方法もある。古本屋のように個人向けに販売する一方で、利用者から不用品の買取を行う。 海外の物を売って成功している人は、日本語のマニュアルを自作して添付していたりする。"
},
{
url: "/p/qwbowke/",
title: "読書メモ『統計学が最強の学問である』西内啓",
date: "2018-12-05T00:00:00Z",
body: "読書メモ『統計学が最強の学問である』西内啓 ビジネス領域における統計学を応用したソリューションのことをビジネスインテリジェンスと呼ぶ。 統計学が最強の武器になるワケ ─ どんな分野の議論においても、データを集めて分析することで最速で最前の答えを出すことができるからだ。 原因不明の疫病を防止するための学問を「疫学」と呼ぶ。 現代の医療で最も重要な考え方として EBM (Evidence-Based Medicine)、日本語にすると「科学的根拠に基づく医療」というものがある。この科学的根拠のうち最も重視されるものの1つが、妥当な方法によって得られた統計データとその分析結果というわけである。 統計リテラシーさえあれば、自分の経験と勘以上の何かを自分の人生に活かすことがずいぶんと簡単になる。 心臓病だろうがコレラだろうが、原因不明なのであれば、その原因を明らかにするために行うべきことは、慎重かつ大規模なデータの収集であり、その適切な統計解析以外にはあり得ないのである。 データ分析において重要なのは、「果たしてその解析はかけたコスト以上の利益を自社にもたらすような判断につながるのだろうか？」という視点だ。 ★データの集計結果をビジネスに使うには、次の3つに答えられるものでないといけない。 何かの要因が変化すれば利益は向上するのか？ そうした変化を起こすような行動は実際に可能なのか？ 変化を起こす行動が可能だとしてそのコストは利益を上回るのか？ フィッシャーたちの時代とそれ以前の統計学の大きな違いは、誤差の取り扱い方にある。 統計学においてはこうしたデータの取り方のことを「A/Bテスト」とは言わずランダム化比較実験と呼ぶ（なおAパターンとBパターンの条件の変え方にランダムさが含まれていない実験は準実験と呼ぶ）。 クロス集計表について「意味のある偏り」なのか、それとも「誤差でもこれくらいの差は生じるのか」といったことを確かめる解析手法に「カイ二乗検定」というものがある。 「実際には何の差もないのに誤差や偶然によってたまたまデータのような差（正確にはそれ以上に極端な差を含む）が生じる確率」のことを統計学の専門用語でp値という。このp値が小さければ（慣例的には5％以下）、それに基づいて科学者たちは「この結果は偶然得られたとは考えにくい」と判断する。 統計学をある程度マスターすれば「どのようにデータを解析するか」ということはわかる。だが、実際に研究や調査をしようとすれば、「どのようなデータを収集し解析するか」という点のほうが重要になる。 重要になるのは「ここから何かわからないか」という漠然とした問いではなく、そのようなデータのうち何が、どのような関係で利益と繋がっているのかである。 ランダム化比較実験がどれだけ強力か、その最も大きな理由は、「人間の制御しうる何者についても、その因果関係を分析できるから」である。 統計学が「最強の学問」となったのはその汎用性の高さ、すなわち、政治だろうが教育だろうが経営だろうがスポーツだろうが、最速で最善の答えを導けるところにある。 フィッシャーが打ち立てたランダム化比較実験で、「誤差のある現象」を科学的に扱えるようになった。 「無制限にデータを得ればわかるはずの真に知りたい値」を真値とよび、たまたまえられたデータから計算された統計量がどの程度の誤差で真値を推定しているかを数学的に整理することで、無限にデータを集めることなく適切な判断が下せるという考え方を示した。 ランダム化してしまえば、比較したい両グループの諸条件が平均的にはほぼ揃う。そして揃っていない最後の条件は実験で制御しようとした肥料だけであり、その状態で両グループの収穫量に「誤差とは考え難い差」が生じたのであれば、それはすなわち「肥料が原因で収穫量に差が出る結果になった」という因果関係がほぼ実証できたと言える。 人件費を浪費して終わりのない会議を繰り返すよりは、比較的安価な媒体で小規模なランダム化比較実験を行ったほうが、早く、安く、確実な答えを得られる可能性が高い。 「正解のない意識決定」について、正解がないのであればとりあえずランダムに決めてしまう、という選択肢の価値はもっと認められるべきだ。 わざわざデータの取り方を工夫しなくても、より高度な手法を用いれば可能な限り条件を揃えた「フェアな比較」が可能になる。そのための最も重要な枠組みの1つが回帰分析だ。 回帰係数の誤差や信頼区間といった値を読み解けるようになれば、あなたの統計リテラシーはぐっとレベルアップする。 ありとあらゆる分野の研究結果が、先ほどの図表と同様に、回帰係数とその信頼区間やp値といった（あるいはこの一部を述べる）形で記述されている。 現代における統計手法の王道「重回帰分析」は、「フェアな比較」を行ううえで重要な役割を果たす統計解析手法である。政府のレポートにおいても学者の論文においても、重回帰分析やその拡張であるロジスティック回帰の結果が示されている。 バスケット分析よりも統計学的なカイ二乗検定による相関分析のほうがいい。 予測モデルから今後何をすべきかを議論したいのであれば、（シンプルな）回帰モデルの方が役に立つ。"
},
{
url: "/p/cxk6nn3/",
title: "テスト駆動開発の過去・現在・未来（和田卓人さん）",
date: "2018-12-05T00:00:00Z",
body: "テスト駆動開発の過去・現在・未来（和田卓人さん） タワーズ・クエストの和田卓人さん (t-wada) のお話を聞いたのでメモメモ。 Kent Beck の TDD 本の翻訳本『テスト駆動開発』を書いてる人です。 和田さんによる追記もあるので、正確には翻訳＋αですね。 テスト駆動開発 Kent Beck、和田卓人 オーム社 TDD の歴史は、バイブル的な本の出版歴を見ていくとわかりやすいみたいですね。 2002年: Kent Beck の TDD 本が出版される 2003年: TDD 本の翻訳『テスト駆動開発入門』がピアソンから出版される。しかし、ピアソンの技術部門の撤退で廃版となる 2017年: 和田氏によって TDD 本の再翻訳『テスト駆動開発』がオーム社から出版される TDD は \u0026ldquo;Test Driven Development\u0026rdquo; ではなく、\u0026quot;Test-Driven Development\u0026quot; と書くのが正解みたいです（ハイフンがいる）。 xUnit Test Patterns by Gerard Meszaros xUnit Test Patterns: Refactoring Test Code Gerard Meszaros Addison-Wesley Professional 書籍 『xUnit Test Patterns』 では、2007 年の時点でテストコードのメンテナンス性の課題について言及しています。 重複の多いテストコードがあると、メンテナンスコストがどんどん上がっていく。 プロダクトコードだけでなく、テストコードもメンテ対象であり、日常的なリファクタリングが必要であるという認識が必要。 「テストコードを追加するとメンテナンスコストが上がるので、テストコードはあまり追加したくない」という意見はそもそもテストコードに対する認識が間違っている。プロダクトコードと同じレベルのものと考えないといけない。 だから、書籍のサブタイトルでも「Refactoring Test Code」と訴えている。 ちなみに和田さんは、こーゆー分厚い本はぶった切って持ち運びやすいサイズにして読むみたいですね。 私も本は読んで知識にしてナンボだと思ってますので、そのやり方には賛成です。 本には書き込みまくって自分の知識になったと思ったら捨てる。その繰り返し。 Mock オブジェクトについて Mock オブジェクトの登場により、Inside-Out な開発から、Outside-In な開発に変えられることが分かった。簡単に言うと、ユーザーに近い UI の部分から Mock を利用して作り始めるという考え方。Mock オブジェクトが、ただのユニットテストの道具ではなく、受け入れテストに近いところから開発するというプロセス改善のために使えるということが示された。 早い段階でリリースして、フィードバックを受けながら作り込んでいくというプロセスが現在ではよいとされている。 「動作するきれないコードはあらゆる意味で価値がある」by Kent Beck Mock 系のライブラリは強力になりすぎて弊害にもなっている。もともとは、テストを書いているときに「Mock に置き換えにくいので設計を改善しなきゃ」という設計改善の原動力となる部分があったのに、今は Mock ライブラリが強すぎて、汚い設計でも Mock を導入できてしまう。テストには「設計を改善する」という目的があるのに、これでは本末転倒だ。 TDD の T は「テスト」なの？ TDD の T は「テスト」の一部に過ぎない ─ 『Agile Testing: A Practical Guide for Testers and Agile Teams』 ある人が「テスト」と言ったときに、それが具体的に何を示しているかは、Brian Marick による4象限モデルによって分類できる。 Brian Marick’s testing quadrant Building Microservices: Testing - O\u0026rsquo;Reilly Media UnitTest は、4象限のうち1つしかカバーしないので、UnitTest ができているからといって、「テスト」できているとは言えない。特に UnitTest には批判的な目で見るという視点が徹底的に欠けている（そーゆーところは、ユーザビリティテストとかセキュリティテストとかでカバーしなきゃいけない）。 TDD から BDD へ testdox/agiledox (2003) というツールで、テストコード（関数）から仕様書を生成できるようになった。 JBehave (2003) → RSpec → Cucumber (2008) などいろいろ作られて、Cucumber では自然言語でテスト書けるようになった。 ビヘイビア仕様の用語で考えることで、クラス名やメソッド名に捉われたテストを書かないように促される。 BDD はもともとアジャイルプロセス的な位置付けになることを目指していたが、今はそのようには受け入れられていない。そんな大きな枠組みのものではない。 TDD も、リーンスタートアップのようなより大きな枠組みの中て、リリースサイクルを短くするため1つの仕組みであると考えられるようになった。 TDD は「スキル」です。写経することでスキルは向上できる。書籍 『テスト駆動開発』 では、写経して学びやすいように、Kent Beck の原著のコードを見直して、そのまま実行できるようにしている。 ユニットテストは品質を上げない テストは品質が「わかる」ようになるだけ。 テストを書くだけでは品質は良くならない。品質を上げるのは、今も昔も「設計」と「プログラミング」であることに変わりはない。 テストは再設計とリファクタリングを「支える」ものだ。 テストを書いただけで設計を改善しようとしないのであれば、それはただ回帰テストしているだけで現状追認にしかならない。 その他、和田氏の意見 TDD は自分自身が活用するためのツールとして使っていけばいいよ。「テストない＝悪」みたいに使われるのは嫌だ。テストを書いてからじゃないと絶対にプロダクトコード書いちゃダメとか、もともとはそんな意図はなかったはず。 UI の自動テストには否定的。UI は変化してナンボのものなのに、テストが存在していることによって、変化させることに抵抗を持つようになってしまう。スナップショット・テスティングなどは、画面の変化に「気付く」ためのツールとしてだけ使うのがよい落としどころだと思う。そして、変化が明らかになったら、どちらが正しいかは人間がその時々で決めていくのがよい。 コードの品質を見るひとつのやり方としては、「コードの重複率を時系列で見る」という方法がある。時系列で右肩下がりになっていれば、そのチームはよい活動ができている。Cyclomatic Complexity も時系列で見る。チームの Velocity も時系列で見る。だんだん生産性が下がっているのであれば悪い兆候だ。"
},
{
url: "/p/zrz3ggy/",
title: "2018-11-22 中島聡さん (UIEvolution、元Microsoft) のお話",
date: "2018-11-22T00:00:00Z",
body: "2018-11-22 中島聡さん (UIEvolution、元Microsoft) のお話 Windows95 を作った男と言われている中島聡さんのお話を聞いて来たのでメモメモ。 『なぜ、あなたの仕事は終わらないのか スピードは最強の武器である』 はかなり売れたみたいですね。 今は Singularity Society という NPO もやってる。会社としての利益とかではなくて、もっと大きな問題に幅広く関わっていきたいと思って社団法人として設立した。 経団連に PC が入ったとか、そういう人たちが日本を回していたりする。みんな危機感を持たなきゃいけないよ。 「これを作りたい！」という気持ちが少しでもあったら、その気持ちを大きくして、どんどん外に出していくべき（起業家精神みたいなの）。上司とかマネージャー陣は守りに入って反対することが多いかもしれないけど、どんどん訴えていくべき。 「ものは作ったもん勝ち」。Windows 95 のときも、最初に Smalltalk でハリボテみたいなプロトを作って見せたら、結局それが Windows 95 のベースになって、自分が Windows 95 を作った男と呼ばれるようになった。その頃 Smalltalk でガッツリ実装しているのは自分くらいしかいなかった。 今もプログラムはバリバリやってる。最近は自動運転とか。自動運転自体のプログラムを作っているわけではないが、自動運転の社会になったときに必要になってくるであろうルーティングのプログラムなどを、先を見越して作っている。 Uber や Google が自動運転社会のトップになって幸せな世界になるとは思えない。例えば、地方で運転できずに病院にもいけない老人を救うといったニーズは必ずある。そういった幅広いニーズに応えていくということがこれからの世の中には必要だ。 自動運転は法の整備がポイントなので、そのあたりに強みを持っている中国がまずは抜け出すだろう。先を行かれる可能性が高く、ピンチだ。 テスラは iPhone が出たときと同じくらいワクワクして買った。テスラは買った後にどんどん進化していく。3週間ごとにソフトウェア更新されて車自体が性能向上していくのはほんとすごい（アップデートの頻度とかも）。日本の大企業とかはできないんだろうなぁ（リスクが大きいことはやらないから）。 自動運転社会が来れば必ず新しいビジネスが生まれる。今のうちにどのようなビジネスがヒットするのかを考えておくのが大切。例えば、信号や駐車場がなくなったりして、大きな変化が出てくるだろう。 エンジニアへのアドバイスもいくつか。 自分がどこで勝負するのかは意識していた方がいい。 会社のやり方と合わないと感じたら、辞める前に思いっきり暴れてみよう（物理的にではなくて）。 これからはマネージャよりエンジニアの方が給与が高いという時代になっていく（日本は遅れている）。逆にそうなっていない会社は廃れていくだろう。いつも言ってるが、スキルの高い人がプログラミングせずに、スキルのない下請けに受注するという構造は最低だ（日本の大企業はほとんどそう）。 クラウドができて、ハードウェアもできて、クライアントもできる、みたいなオールマイティな人は強い。IoT な時代は、ある処理をどの部分でやればベストなパフォーマンスを出せるのかということを答えられる人が強い。"
},
{
url: "/p/y66a3ji/",
title: "2018-11-07 iPad Pro キター！おえかきおえかき",
date: "2018-11-07T00:00:00Z",
body: "2018-11-07 iPad Pro キター！おえかきおえかき 今日発売の新型 iPad Pro 2018 年版が来ましたので、早速開封の儀。 外装。 上のフタをパカっと開けると、縁までぴったり本体が収まってました。 思ったより大きい（それがよいのだけど）。 本体の下には簡易マニュアルと、充電アダプタと USB type-C のケーブルが一本。 相変わらずシンプルです。 標準で付属しているメモアプリでちょっとだけお絵描き。 Apple Pencil は筆圧検知はもちろん、傾けて太い線を引くこともできます。 ほんと、普通のペンを使って書いているような感じ！ 新しい Apple Pencil は、ペンの横のところをダブルタップすると簡単に消しゴムに切り替えることができます（ペンのダブルタップを何に割り当てるかはアプリによります）。 これで快適なお絵描きライフを送れそうです(^o^) 画面大きいから Sony Reader アプリや Kindle アプリを入れれば、漫画を見開きで読めるなぁ。。。"
},
{
url: "/p/i5kosb6/",
title: "『嫌われる勇気』岸見一郎さん講演会",
date: "2018-11-06T00:00:00Z",
body: "『嫌われる勇気』岸見一郎さん講演会 嫌われる勇気 岸見一郎、古賀史健 ダイヤモンド社 『嫌われる勇気』で有名な岸見さんの講演を聞いてきました。 思ってたよりおもしろい人でした。 まぁよく考えてみれば、カウンセリングやるような人はユーモアがないと心開いてもらうのは難しいですからね。 お話の内容はほぼ本に書かれているようなことでしたけど、メモメモ。 人から嫌われることを恐れて八方美人に振る舞っていると、「自分の人生」を生きることができない。本当に言いたいことを言えない。本当にやりたいことができない。 「人の評価」と「自分の評価」は違うものなのだということを認識する必要がある。 アドラーは、「自分に価値があると思えるときだけ勇気を持て」と言っている。 仕事に取り組む勇気 対人関係（人の輪）に入っていく勇気 自分に価値を見出すには… 自分の特徴を長所として捉える ×飽きっぽい → ○新しいことを始める決断力や行動力がある。 ×性格が暗い → ○人を傷つけるようなことを言わない優しさを持っている。 他人に貢献しているのだと考える ×生活のために働いている → ○人々に時間を提供している（コンビニのレジ係の例） 教師は、授業では学生に間違えて欲しいと思っている。それによって、その学生に伝わっていないことが何なのかを把握できるので、効率的に教えることができるようになる。質問されて答えられないのは、間違えることで人にどう評価されるかということを恐れてしまっている典型的な例。 すべての悩みは対人関係から生まれるが、生きる喜びや幸せもそこから生まれる。そこに飛び込んでいく勇気を持たなければ、幸せになることはできない。 ちなみに、著書の『嫌われる勇気』っていうタイトルの由来は、自分の子供に「あなた本当に嫌われるのがイヤなんだね」って言われたことらしい。 「あなた」って呼ばれてることの方がおもしろいんですけどｗ 幸せになる勇気 岸見一郎、古賀史健 ダイヤモンド社"
},
{
url: "/p/2685wd6/",
title: "読書メモ『バカの壁』『超バカの壁』養老孟司",
date: "2018-11-04T00:00:00Z",
body: "読書メモ『バカの壁』『超バカの壁』養老孟司 バカの壁 養老孟司 新潮社 一元論に陥ってしまうことの怖さを説いています。 教育しかり、経済しかり、宗教しかり。 やっぱりわかりやすいのは宗教で、原理主義に走ってしまうと「他の考え方は悪」だと決めつけてしまう怖さがある。 しかも決めつけてしまう方が楽だから始末が悪い。 孟司氏は、「人生は崖を登るようなものだ」と言っています。 いろんな考え方を理解していくのはとても大変だけれど、そこを乗り越えることで視界が開けるんだと。 原理主義的な宗教も決して悪いところばかりじゃないと思いますが、もっと柔軟にやっていけないのですかね？ 宗教って一度入信してしまうと、一生貫きとおさなければいけないという風潮がある。 「オレ、先月までイスラム教だったけど、今はプロテスタントやってんねん」 みたいに、いろんな考え方を取り入れられるようになると、宗教間の争いも減りそうなんですけどね。 著者は他にもいろいろ厳しい意見を述べられています。 今の教師には、反面教師になってもいい、嫌われてもいいという信念がない。サラリーマンになってしまっている。給料の出所に忠実な人であって、仕事に忠実なのではない。逆に、職人というのは、仕事に忠実じゃないと食えない。自分の作る作品に対して責任を持たなくてはいけない。 個性なんてものは初めから与えられていて、それ以上のものではない。薄っぺらな個性しかない人が、子供に「個性を伸ばせ」なんて教育をするのではなく、他の人の気持ちがわかるかと伝える方がよっぽどよい。 人生は無意味だ、病気の苦しみには意味はない、と考えるのは楽に思えるがそれは結局自分自身の不幸を招く。苦しみには意味があると考えるべき。苦しいうえにその状況に意味がないと考えてしまうのは二重の苦しみを味わっていることになる。 虚の経済、実の経済という考え方も面白いですね。 国が出している指標は虚の経済であって、お金のやり取りだけが計算されている。 でもその裏では環境破壊が進んでいる。 実の経済というのは資源、エネルギーを一基本貨幣単位としてモデリングされていなければならない。 世界一貧しい大統領ホセ・ムヒカが伝えようとしていることも本質は同じですね。 富よりも大切なことがあるのだと。 知るということは、自分がガラッと変わること。世界がまったく変わってしまう。それが昨日までとほとんど同じ世界であっても。 その世界は、自分がよりよく生きられる世界だ。 だから我々は学び続けなければいけない。 それが生きる意味だ。 超バカの壁 養老孟司 新潮社 『バカの壁』の続編の『超バカの壁』でも、養老孟司氏がものの考え方について述べています。 中でも、「人生の価値」を次のように考えるというのは素敵な考え方だなと思いました。 世の中の穴を埋めること 人生の価値を、「何かに大成功することだ」とか、「他人との競争に勝つことだ」とか考えていると疲れてしまいます。 そうじゃなくて、世の中にポコポコ開いた穴を、みんながそれぞれ埋め合うことで世の中がうまくいく。 こんな考え方で生きていけたら幸せになれそうだし、世界は平和になりそう。"
},
{
url: "/p/hdcgy8y/",
title: "読書メモ『180日でグローバル人材になる方法』天野雅晴",
date: "2018-10-28T00:00:00Z",
body: "読書メモ『180日でグローバル人材になる方法』天野雅晴 180日でグローバル人材になる方法 天野雅晴 東洋経済新報社 日本と米国 日本は、会社や組織が個人の居場所を定義する。米国では、会社や組織の枠を越えて「個人のレベル」で繋がっている。 日本では会社や組織の比重が大きいため、個人の比重が大きい米国のネットワークとは、ある意味で「水と油」のような関係にある。 米国企業は、最初は最低予測金額の3倍くらいの価格で交渉をスタートさせる。多くの日本企業はほとんど最初の金額か、それに近い額で応じる。 日本人は習慣ですぐに名刺を出す人がいるが、米国では特にそういう習慣はない。しばらく話をしてお互いに興味を持った時点で初めて名刺を交換する。 モチベーション 経済学や社会行動学の分野では、「3番目のモチベーション」に注目が集まっている。 第1のモチベーション: 生物としてもっている食べることや生殖に対するもの。 第2のモチベーション: それにつながるお金や地位などに対するもの。 第3のモチベーション: 得意分野や単純に生きがいを感じることをしたいという思う気持ち。 → 『モチベーション3.0─持続する「やる気！」をいかに引き出すか』 ダニエル・ピンク、大前研一 金銭的な利益の追求より、社会貢献や環境維持などに関する「ベネフィット」の追求を選ぶ人や企業が増えている。これに対応するために For benefit（For profitではなく）という会社形式が、米国の会社法として認められた。 第3のモチベーションが原動力になるような何かを社員に持たせることが、企業の成功にとても重要なファクターである。 コミュニケーション グローバル社会のあらゆる場面に対応するコミュニケーションは、英語の問題というよりは、そういう場で何度も実戦訓練をして初めて得られるスキルだと言える。 技術者などの日本人の現場スタッフには、説明だけして肝心の結論を言わない人が多い。「それでどうしたいのか？」と聞くと、特にそれに対しては何も言わない。 海外では自分の考えていることをストレートに相手に伝えることが重要。まずは「YES」なのか「NO」なのかをはっきりと言う。ただし、強い口調で主張するのではなく、落ち着いた口調で言う。 音読、発音矯正 英会話を習得するのに効果がある方法として「音読」がある。ただ読むのではなく、実際に声に出して読むだけのことだが、これでも頭の中だけで読むよりはずっと効果があることが実証されている。 ただ頭の中で言っても自分のものにはならない。本当に何かがわかったときに、実際に \u0026ldquo;I got it!\u0026rdquo; と声に出すことが重要。 出身地によっていろいろなアクセントがあり、「日本人アクセント」があってもそれだけで問題にはならない。しかし、発音矯正には画期的な効果がある。発音矯正のレッスンは、日本でもいろいろな英会話学校のオプションとして受けることができる。 カランメソッド カランメソッド (Callan Method) という「簡単な英文を何度も何度も繰り返し、即座に反応しなければならない」という「英語脳トレーニング」がある。 カランメソッドの大きな特徴は、教室で生徒がしゃべる英語はすべて「教科書に指定された英文のみ」で、それに従って一字一句間違いなくしゃべるということ。いちいち日本語に訳さないということ。 日本でよくある英会話習得法は、外国人教師を相手に自由におしゃべりをするというものだが、これでは自分のしゃべれる英語に限られてしまうので、英語力はつかない。英語学校が楽な方法をとっているだけである。逆に、カランメソッドでは、トレーニング中は自分勝手な英語のおしゃべりをしないことが大切。 カランメソッドでは、しゃべるべき英文はあらかじめぎっしり教科書の中に用意されており、授業ではその英文を先生が質問して生徒が答えるという形式を取る。例えば、\u0026ldquo;express\u0026rdquo; というキーワードに対して、\u0026ldquo;Can you express your idea in English?\u0026rdquo; という質問と \u0026ldquo;Yes, I can express my idea in English.\u0026rdquo; （あるいは \u0026ldquo;No, I can\u0026rsquo;t \u0026hellip;\u0026quot;）という答えが書かれており、先生と生徒はほぼそのままそれを繰り返すだけ。ただし、先生が質問する英語のスピードはかなり早く、日本語で考える余裕はない。 カランメソッドのもう一つの特徴は、一定の時間ごとに先生が入れ替わるということ。その結果、違う先生の英語の発音やしゃべり方に対して、同じやり取りを何度も繰り返すことになる。同じ英文を違う人がしゃべると、同じものを別の角度から見るように情報量が増加する。 カランメソッドは個人や企業でも応用することができる。ポイントは使用する英文。企業なら、特定の業種や業務に合わせたフレーズを集めるのがよい。こうして用意した「オリジナル英文」を使って、外国人教師や友達とひたすら英文のやり取りを繰り返す。大切なのはスピード。やり取りのタイミングを早くして、頭の中で日本語にしないようにする。 ひたすら決められた英文を「訳すことなく」何度も何度も繰り返すことで、英語脳の育成に集中する。本当に英語脳を作るには、このような作業をかならい長く続ける必要がある。毎日のように英文を繰り返さないと効果は出ない。 単刀直入訓練 単刀直入に、\u0026ldquo;I disagree!\u0026rdquo; とか \u0026ldquo;I like that idea.\u0026rdquo; とか \u0026ldquo;That wouldn\u0026rsquo;t work!\u0026rdquo; というと、相手は「なぜ？」「理由は？」と反応してくる。単刀直入に言うと、会話を促進するう効果がある。全部自分でしゃべらなくてよいのも日本人にはメリット。 相手の反応を待ち、それに対して素早く反応する訓練をする。 単刀直入に言える英語フレーズをたくさん集めて練習しておくとよい。 グローバル人材 ベンチャービジネスに失敗は付き物だが、そこにかかわった人たちはそれぞれ優秀な人材である。そうした優秀な人材がある一定期間一緒に運命共同体としてつながりを持ったということ自体、とても貴重なこと。人材だけでなく、そのベンチャービジネスで培われた商品やサービスに関する成果物も、すべてを無駄にする必要はない。 イノベーション生態系で活躍するのは、以前起業してある程度の成功を収めた人たちである。米国では2000年前後のネットバブルで多少なりとも成功を収めた人たちの多くが、今では後続の起業家たちを支援する立場に回っている。対価としてストックオプションをもらったり、一般には購入できない未公開株を購入したりする。"
},
{
url: "/p/yzs49gv/",
title: "UML ダイアグラムの一覧と分類",
date: "2018-10-23T00:00:00Z",
body: "UML ダイアグラムの一覧と分類 構造図 (structual diagrams) クラス図: クラス、特性、関係 コンポーネント図: コンポーネントの構造と接続 コンポジット構造図（複合構造図）: クラスのランタイム分割 配置図: ノードへの成果物の配置 オブジェクト図: インスタンスの接続の基本例 パッケージ図: コンパイル時の階層構造 振る舞い図 (behavioral diagrams) アクティビティ図: 手続き的なまたは並行な振る舞い ユースケース図: ユーザーがシステムとどう対話（相互作用）するか ステートマシン図（状態マシン図）: オブジェクトの存続期間にイベントがオブジェクトに加える変更の内容 相互作用図 シーケンス図: オブジェクト間の相互作用（シーケンスを重視） コミュニケーション図: オブジェクト間の相互作用（リンクを重視）UML1ではコラボレーション図と呼ばれていた タイミング図: オブジェクト間の相互作用（タイミングを重視）(UML2) 相互作用概要図: シーケンス図とアクティビティ図を合わせたもの (UML2)"
},
{
url: "/p/tc73ttt/",
title: "読書メモ『UMLモデリングのエッセンス第3版』マーチン・ファウラー",
date: "2018-10-19T00:00:00Z",
body: "読書メモ『UMLモデリングのエッセンス第3版』マーチン・ファウラー UMLモデリングのエッセンス第3版 マーチン・ファウラー 翔泳社 大きな仕様である UML の中で重要なポイントを簡潔にまとめた UML のバイブル的書籍です。 マーチンファウラーの名前は、『リファクタリング』や『アナリシスパターン』といった書籍で目にした人も多いでしょう。 長年オブジェクト指向に携わってきたファウラー氏のまとめたエッセンスに振れれば、UML の重要なポイントを効率よく一気に学ぶことができます。 本書は、UML を創ったスリーアミーゴ（Grady Booch、Ivar Jacobson、James Rumbaugh）の推薦図書でもあります。 第1章: UMLの概要 UML の使い方に関する面倒な論争に対するアプローチとして、Steve Mellow と Martin Fowler は、UML の使い方を 3 種類のモードに分類している。 スケッチ（もっとも一般的な使われ方） フォワードエンジニアリング: コードを記述する前に UML ダイアグラムを作成する。 リバースエンジニアリング: 既存のコードを理解する補助手段としてコードから UML ダイアグラムを作成する。 設計図面（blueprint。実装のため完全性を重視） プログラミング言語（Executable UML など。うまくいかず、流行らなかった） UML のユーザーは UML の本質はダイアグラムだと考えている人がほとんだが、UML の作成者は UML の本質はメタモデルであると考えている。ダイアグラムはメタモデルの表現にすぎない。 細部までフォワードエンジニアリングされた設計図面はうまく扱うのが難しく、開発作業の遅れに繋がる。 サブシステムのインタフェースレベルで設計図面を作成するのは合理的だが、実装するのに合わせてインタフェースが変わることを想定しておく必要がある。 このような考えから、著者のマーチン・ファウラーは、UML をスケッチとして使用することを重視している。 UMLダイアグラム一覧と分類 UMLダイアグラムが使用目的に適さない場合は、非UMLダイアグラムを積極的に使うべき。デシジョンテーブルや画面フロー図などは役に立つ。 まずクラス図とシーケンス図の基本形態に集中することをお勧めする。これらは最も一般的であり、最も便利なダイアグラムである。 第2章: 開発プロセス モデリング技術は、それがプロセスにどのように適合するかを理解しなければ、意味を成さない。UMLの使い方は、使用するプロセスのスタイルによってかなり異なる。 ウォーターフォール型プロセスでは、プロジェクトをアクティビティに基づいて分解する。要求分析、設計、コーディング、テストを順番に実行する。 反復型プロセスは、プロジェクトを機能のサブセットで分解する。1年間のプロジェクトでは、3ヵ月ごとの反復に分解することが考えられる。3ヵ月が終わるごとに、必要な機能の1/4がシステムに実装される。 Steve McConnell は、『ラピッドデベロップメント』 の中で、プロセスを組み合わせて使用する方法を説明している。最初の4ヵ月で要求分析と設計をウォーターフォール的に行い、コーディングとテストは2ヵ月の反復を4回繰り返す。 テストと統合は予測の難しいアクティビティであり、このような終了時期の見えにくいアクティビティをプロジェクトの最後に置かないことが重要。 経験から言うと、単体テストのコードは製品本体のコードと同程度の量が必要。 RUP (Rational Unified Process) RUP はプロセスと呼ばれているが、実際にはプロセスのフレームワークである。RUP はプロセスを説明するための語彙と柔軟な構造を提供する。 RUP は本質的に反復型プロセスであり、ウォーターフォール型は RUP の考え方に適合しない。 RUP は UP (Unified Process) に基づいた Rational 社の製品であると考えることができる。また、RUP と UP を同じものと考えることもできる。どちらも正しい。 反復型開発の最大の利点のひとつは、プロセスを頻繁に改良できること。 反復の最後に、チームでその反復を振り返り、次の3つのリスト (KPT) を作成するのがよい。 K: Keep（継続）: 有効に機能していて、今後も継続して行う事項 P: Problem（問題）: 有効に機能していない事項 T: Try（試み）: プロセスを改良するための変更 プロジェクトの最後、または主要なリリース時には、本格的にプロジェクトを振り返るのもよい。参考: https://en.wikipedia.org/wiki/Retrospective 要求分析で UML を使用する際の最大のリスクは、対象分野の専門家が理解できないダイアグラムを描いてしまうこと。専門家が理解できないダイアグラムは役に立たないだけでなく、開発チームに偽りの自信を植え付けてしまう。 詳細な文書は Javadoc のようにコードから生成されるべき。他の文書を追加するのは、重要な概念を強調するため。 文書化する必要があるもっとも重要な事柄のひとつに、採用しなかった設計上の選択肢とその理由がある。これは最も忘れられがちだが、外部に対して文書化して提供できるものの中で最も実用的なものである。 第3章: クラス図（基本的要素） UML では、特性 (feature) という用語をクラスのプロパティや操作を指す一般的な用語として使用する。 ソフトウェアを理解するためにクラス図を描く場合は、必ず振る舞いに関する何らかの技法と併用すべき。 属性と関連 属性と関連は、ダイアグラムではまったく異なるように見えるが、実際は同じもの。ダイアグラムにとってあまり重要でないものに関しては属性を使用し、重要なクラスにはクラスボックスを割り当てて関連で結ぶ。何を強調するかを基準にして選択すればよい。 属性 (attribute) の完全な形式は以下の通り。必須の要素は「名前」だけ。 可視性 名前: タイプ 多重度 = デフォルト値 {プロパティ文字列} 例: - name: String [1] = \u0026quot;Untitled\u0026quot; {readOnly} 関連 (association) は2つのクラスの間にある実線で、ソースクラスからターゲットクラスまで引かれる。属性とは異なり、関連では両端に多重度を表示できる。 多値の関連 (*) において順序に意味がある場合は、関連端に {ordered} を追加する。重複を許可する場合は {nonunique} を追加する。順序に意味がなく一意でもないものには、{bag} のようにコレクションを示す名前が付けられることもある。 関連の両端で誘導可能性矢印 (navigability arrows) を使用することで関連の双方向性がはっきりと示される。双方向関連を持つことを明確にするのであれば、両方向を向いた矢印を明示的に使用するのがオススメ。 操作 (operation) 操作 (operation) とは、クラスが自分で実行しなければいけないと知っているアクションのこと。完全な構文は以下の通り。 可視性 名前(パラメータリスト): 戻り値のタイプ {プロパティ文字列} パラメータは属性と同様に下記のような構文で記述する。 方向 名前: タイプ = デフォルト値 方向は、in、out、inout のいずれかで、デフォルトは in。 例: + balanceOn(date: Date) : Money 問い合わせ操作と、更新操作 システムの状態を変更せずに（副作用を伴わずに）クラスから値を取得する操作を問い合わせ (query)と呼び、{query} というプロパティ文字列で表すことができる。 システムの状態を編こする操作は更新 (modifier)、またはコマンドと呼ばれる。 厳密には、問い合わせ (query) と更新 (modifier) の違いは、観測可能な状態を変更するかどうか。 一般的には、modifier 操作は値を戻さないように記述するとよい。逆に、戻り値を持つ操作は状態を変更しない（問い合わせ (query)）であることが明確になる。→ Meyer の command-Query 分離原則 操作とメソッドは次のように区別されて使用される。 操作 (operation): オブジェクトに対して起動されるもの（手続き宣言）。 メソッド (method): 手続きの本体。 操作とメソッドはポリモルフィズムを扱う場合に異なってくる。同一のスーパータイプの操作 getPrice をオーバーライドする 3 つのサブタイプがあるとすると、1 つの操作とそれを実装する 3 つのメソッドがあることになる。 汎化 サブタイプとサブクラス サブタイプ: 継承しているかどうかに関わらず、スーパータイプと置換可能であればサブタイプである。 サブクラス: サブクラス化 (subclassing) は、通常の「継承」と同義語として使用される。 依存関係 依存関係は通常はキーワードなし使用されるが、より詳細に表現したいのであれば、次のような適切なキーワードを付加するとよい。 ≪call≫: ソースはターゲットの操作を呼び出す。 ≪create≫: ソースはターゲットのインスタンスを生成する。 ≪derive≫: ソースはターゲットから派生する。 ≪instantiate≫: ソースはターゲットのインスタンスである（ソースがクラスである場合は、そのクラス自体がクラスのインスタンスになり、ターゲットクラスはメタクラスになる）。 ≪permit≫: ターゲットはソースに対して、ターゲットのプライベート特性へのアクセスを許可する。 ≪realizes≫: ソースはターゲットで定義されたインタフェースまたは使用の実装である。 ≪refine≫: 異なる意味レベル間の関係を示す。例えば、ソースが設計クラスであり、ターゲットがそれに対応する分析クラスである場合など。 ≪substitute≫: ターゲットの代わりにソースを使用できる。 ≪trace≫: クラスに対する要求や、1つのモデルでの変更と他の場所での変更との関係などを追跡するのに使用する。 ≪use≫: ソースはその実装においてターゲットを必要とする。 クラス図のすべての依存関係を表示しようとすることは無駄な試みである。依存関係は頻繁に変化する。依存関係の理解と制御には、パッケージ図が最も適している。 制約規則 UML では、制約の記述に関して制限はない。中カッコ ({}) の中に入れるということが唯一の規則である。 名前の後ろにコロンをつけて、{近親結婚の禁止: 夫と妻は兄弟の関係であってはならない} のように、成約に名前を付けることもできる。 第4章: シーケンス図 シーケンス図は相互作用図 (interaction diagram) の中で最も一般的なもの。 シーケンス図では、ページを縦に走る lifeline（生存線）で各 participant（参加者）が示され、上から下に並んだメッセージの順番によって相互作用が示される。 上に並んでいるボックスは参加者 (participant) で、UML1 ではこれらはオブジェクトだったが、UML2 ではより複雑になった。ここでは単純に参加者 (participant) と呼ぶ。UML1 では名前の下に下線が引かれていたが、UML2 では参加者の名前に下線は引かない。 参加者の名称の構文は「名前：クラス名」だが、名前とクラスのいずれかは省略できる。ただし、クラスだけを示す場合は「：クラス名」のように必ずコロンを付ける（名前なのかクラス名なのか分からなくなっちゃうので）。 各生存線にはアクティベーションバーがあり、相互作用の中でアクティブになる区間を表す。通常は振る舞いを明確にするために有効だが、ホワイトボードなどで議論しているときは時間の無駄なので省略して描くのが普通。 すべての呼び出しにリターン矢印を付けるのは無駄だが、戻り値が明確になることでオブジェクト間の呼び出し関係が明らかになる場合は有用。下記の例のように記述すれば、getProduct の戻り値が aProduct であり、そのオブジェクトを使って aProduct.getProcingDetails を実行していることが明確になる。 ≪生成コード\u0026#x1F4D6;≫ 参加者（オブジェクト）の生成と削除 参加者 (participant) を生成するには、メッセージの矢印をその参加者のボックスに向かって引く。メッセージ名を示す必要はないが、new などを書いておけばよい。 コンストラクタ内の処理は、参加者ボックスの下に接する形でアクティベーションボックスを描く。 参加者の削除は大きな「×」で表す。「×」に向かってメッセージの矢印が伸びている場合は、他のオブジェクトによって明示的に削除されることを示す。ライフライン（生存線）の最後に「×」がある場合は、GC などで自動的に削除されることを示す。 ≪生成コード\u0026#x1F4D6;≫ ループ、条件など シーケンス図は、オブジェクトが対話する様子を視覚化するためのものである。制御ロジックをモデル化するためのものではないので、ループや条件付き振る舞いなどの制御構造を表すのには適していない。制御構造を示したいときは、アクティビティ図や、コードを記述してしまうほうが優れている。 ループと条件を表すには、相互作用フレームを使用する。ループは loop オペランド、条件付きロジックは alt や opt のフレームで表現できる。 ≪生成コード\u0026#x1F4D6;≫ 同期的な呼び出しと非同期の呼び出し UML2 では同期メッセージは「頭が塗りつぶされた矢印」、非同期メッセージは「頭が塗りつぶされていない矢印」で表現する。これは見分けがつきにくいので、非同期メッセージを明確に示したいのであれば、旧式の「頭が半分しかない矢印」を使ったほうがよい。 シーケンス図を読み取る場合、作成者が意図的に矢印を区別しているかがわかるまで、同期／非同期の判断には注意が必要。"
},
{
url: "/p/cps3nt8/",
title: "デザインパターン: MVC パターンのメモ",
date: "2018-10-12T00:00:00Z",
body: "デザインパターン: MVC パターンのメモ MVC パターンの構造 オブジェクト図 ≪生成コード\u0026#x1F4D6;≫ シーケンス図 図: シーケンス図 ≪生成コード\u0026#x1F4D6;≫ M (Model) 処理。ビジネス・ロジック。 アプリケーションが使用するデータを保持し、アプリケーション固有の処理を実行する。 外部のストレージ（データベース）に保存するためのインタフェースなどを備えていてもよい。 特に、保持するデータを参照するための public インタフェースだけを備えているものを Model ということもある。J2EE デザインパターンでは、純粋にデータのみを保持するものを Value Object と呼んでいる。 View、Controller とは関連性を持たないのが望ましい。 Model オブジェクトは、自分自身がどのように表示されるかを知らない。 特定の実行環境に依存しないのが望ましい。 例えば、特定のフレームワーク上に構築されたアプリケーションであっても、Model クラスだけは別のフレームワークでも使用できるようにするべき。つまり、フレームワークに特化したインタフェースを備えてはいけない。 V (View) 表示。プレゼンテーション・ロジック。 データを目に見える形で表示するためのコード。ウィンドウアプリケーションでは、ウィンドウ内に表示するウィジット等の表示、Web アプリケーションでは、HTML の出力などが View に当たる。 C (Controller) 入力。インタラクション・ロジック。 ユーザやシステムからのイベントを受けとり、Model や View の作成、更新、相互作用を管理する。 MVC パターンの Pros and Cons 利点 (Pros.) UI コードにビジネスロジックが入るのを防ぐことができる。 ユニットテストしやすい。 欠点 (Cons.) スケールしない（UI は個々に作成できるが、モデルを分離しにくい） Contoller が肥大化しやすい（View からの処理がすべて Controller 経由になる） SOLID 原則の S (Single responsibility principle) と I (Interface segregation principle) に違反してしまう。 View と Controller の関連 多くの GUI toolkit では、V (View) と C (Controller) は複雑に絡み合っている。なぜなら、C (Controller) は、それ自体が画面上に表示される widget であることが多いから。 例えば、 wxPython では、画面上に表示されるウィジット wx.Window (View) は、ユーザの入力を受け取る wx.EvtHandler (Controller) のサブクラスとして定義されているため、「View = Controller」 である。 逆に、一般的な Web アプリケーション・フレームワークは、Controller（サーバー上での処理）と、View（ブラウザへの表示）が明確に分かれていることが多い。 参考: 『wxPython in Action』 MVC の パッシブ・モデルとアクティブ・モデル パッシブ・モデル ユーザ入力 → Controller Controller →（更新）→ Model Controller →（更新通知）→ View View →（最新データ取得）→ Model パッシブ・モデルでは、Model が更新されたとき、Controller が View に対して通知する。 アクティブ・モデル ユーザ入力 → Controller Controller →（更新）→ Model Model →（更新通知）→ View View →（最新データ取得）→ Model アクティブ・モデルでは、Observer パターンを利用し、Model オブジェクトに更新があったときに Model オブジェクト自身が、リスナとして登録されている View に対して通知する。 Android プログラミングにおける MVC パターン 例えば、Android アプリのコーディングでは、エントリポイントが Activity クラスや Fragment クラスになるので、構造を何も考えずに機能を追加していくと、Activity や Fragment が肥大化してしまいます。 最初から MVC パターンを意識したコーディングを行うことで、見通しがよく保守性の高いコードを作成できます。 Activity や Fragment が肥大化してしまうのを防ぐことができる。 ロジックが分かりやすく、新しい機能を追加するのに時間がかからない。 Activity や Fragment からビジネスロジックを分離できるのでテスト可能になる。"
},
{
url: "/p/5wu6fbv/",
title: "デザインパターン: MVP パターンのメモ",
date: "2018-10-12T00:00:00Z",
body: "デザインパターン: MVP パターンのメモ MVP (Model-View-Presenter) パターンでは、MVC (Model-View-Controller) パターンと異なり、View と Model が直接やり取りせず、すべて Presenter 経由でのやり取りになります（亜種としてデータバインディングを使用するケースもあります）。 MVP パターンの構造 オブジェクト図 ≪生成コード\u0026#x1F4D6;≫ シーケンス図 ≪生成コード\u0026#x1F4D6;≫ MVP の構成要素 View: 描画ロジックを持つ。自分自身が能動的に描画処理を行うことはなく、Presenter からの要求で描画処理を行うため、Passive View と呼ばれる。Presenter に言われたとおりに、渡されたデータを描画するだけ。ユーザの入力を受け、Presenter へ通知する。 Presenter: ユーザイベントをハンドルし、具体的なアクションを実行する (Proxy)。データを Model から取得し、View が扱える形に加工して描画情報として渡す。 Model: ビジネスロジックとデータ保持（およびデータ取得処理）を担う。DB や Web サービスと通信してデータを取得する役割を持つ。必要に応じて Presenter へ変更通知を送る。 MVP の Pros and Cons Pros. 複雑なタスクをシンプルなタスクに分割できる。 クラスが小さくなり、不具合が入りにくくデバッグしやすくなる。 ユニットテストできる。 Cons. 各レイヤを繋ぐ退屈な作業が必要。 Model が特定のユースケースに結びついてしまい再利用しにくい。 View と Presenter が特定のデータ形式により結び付けられてしまう（Model の提供するデータを Presenter 経由で View に渡すときにデータの依存ができる）。 MVP の各コンポーネントの生成過程 MVP パターンを導入しようとするときに、最初に迷うのがオブジェクトの所有関係をどうするかだと思います。 下記は MVP の一般的なオブジェクトの生成過程です。 アプリを起動すると View が生成される。 View は自分自身を制御してもらうための Presenter を生成する。Presenter に自分自身の参照を渡しておく（これは、Presenter から View を制御してもらう必要があるため）。 Presenter はビジネスロジックを実行するための Model を生成する。 Presenter は、View や Model の参照を持つ必要があるわけですが、このとき View の具象クラスの参照を保持するのではなく、インタフェース型の参照（IView的な）として保持するのがポイントです。 こうすることにより、Presenter の単体テストが可能になります（View のモックを作成する）。 下記は、Wikipedia にある View の実装例です。 View のコンストラクタで Presenter を生成しています。 public class DomainView : IDomainView { private IDomainPresenter domainPresenter = null; /// \u0026lt;summary\u0026gt;Constructor\u0026lt;/summary\u0026gt; public DomainView() { domainPresenter = new ConcreteDomainPresenter(this); } } MVP のテストで何を行うか？ View のテスト 描画ロジックをテストする。 Presenter とのインタラクションをテストする。 Presenter のモックを作成する。 Presenter のテスト View からのイベントを受けて、正しく Model のメソッドを呼び出しているかをテストする。 View と Model のモックを作成する。 Model のテスト ビジネスロジックをテストする。 Presenter と DataSource のモックを作成する。"
},
{
url: "/p/38w985m/",
title: "読書メモ『マンガを読んで小説家になろう！』大内明日香・若桜木虔",
date: "2018-10-06T00:00:00Z",
body: "読書メモ『マンガを読んで小説家になろう！』大内明日香・若桜木虔 マンガを読んで小説家になろう！ 大内明日香・若桜木虔 アスペクト 「物語はパターンとバリエーションからできてる」という考え方を一冊まるまる解説しています。 漫画や小説のヒットするパターンというのは決まっているのだから、そこにはほとんど工夫の余地はないと言い切っています。 だからと言って、物語がつまらなくというわけではなく、バリエーションを持たせることによっていくらでもヒット作は生み出せる。 文章の書き方的な教本ではないので、そこだけは注意ですが、ストーリーのパターンというものを学べる良書かと思います。 以下、個人的に大事そうなところをまとめ。 ストーリーを作るコツは、「すべての物語はパターンとバリエーションからできている」と割り切ること。 多作な作家が生き残る。著名な小説家やマンガ家は多作である。専業作家で食べていくには、年に6冊の新作を書かないといけない。オリジナル、オリジナル、って考えている人には絶対に無理。 多作になるためには、ストーリーをシステマティックに作らなければならない。必要なのは情報のインプット。ストーリー作りはなにからでも学べる。小説だけでなく、マンガをどんどん読もう！アニメを観よう！特撮を見よう！ 新聞にはネタがたくさんあるが、テレビ欄の裏（39面）の社会面のメインは大きな事件を扱うところで、皆がこの事件をネタにしようとするので、その情報は捨てた方がいい。38面の下の、B級、C級な隅っこの記事が実は面白く狙い目。 自分は天才だと思っている人は、「勝たなくてもいい。わかる人にだけわかれば」と思っているから勝つことはできない。「なにがなんでも小説家になる！」と強く思っている人が小説家になれる。 小説家の人はナチュラルに嘘をつく。これもサービス精神の表れ。とにかくみんな話を大きく大きくしようとする。これは職業病みたいなもので、常に人を喜ばせたいと思うのが小説家。 長続きするマンガで大事なのは「読者の期待を裏切らないこと」。こち亀の両さんは必ず最後に大目玉を食らう。ドラゴンボールの悟空は戦うたびに強くなって相手を倒す。ゴルゴの弾は必ず命中する。ワンパターンは決して悪いことではない。「待ってました！」は褒め言葉です。 逆に完全なオリジナルは売れない。個性的だから、先がわからない。わからないから、期待も持てない。期待できないから、わくわくできない。だから売れない。本当のオリジナルを書いた作家は、たいてい死んでから売れる。画家のゴッホだってそう。ギャグマンガ家が長続きしないのは、ギャグに使い回しがきかず、常にオリジナルを必要とされるから。 「元ネタはありません。オリジナルです。」という作品は罵られるが、「このマンガには元ネタがある。さぁ探してみろ！」とほのめかされているとみんな喜んで元ネタを探す。ケロロ軍曹がよい例。 同じ作者の複数の作品に、同じキャラクターや名前だけ変えたキャラクターが登場する「スター・システム」はもともと映画業界用語だが、マンガ業界でも有名。手塚治虫氏はマンガのスター・システムの創始者と言われている。みんなスター・システムが大好き。あっちのマンガで出ているキャラが、別のマンガで出ていると大喜びする。同じようなキャラを登場させることを堂々と宣言するのがよい。小説でも、売れっ子の人は、キャラに関してワンパターンであることが多い。 自分の得意なストーリーの「パターン」を早く見つけて、それを自分の「スタイル」と言うのがよい。ワンパターンと言われると腹が立つけど、スタイルと言われるとカッコいい。さらに、人気作家になると「◯◯ワールド」と言われるようになる。 不思議なことに、他の作品や意見を参考にしないで作ろうとすればするほど似てしまう。他の作品のパターンを組み合わせて自分の世界を作ってしまった方がよい。 大事なのは「書きたいもの」ではなく、「それを書きたいという気持ち」。その気持ちの源泉は何でもいい。有名になりたい、モテたい、あっと言わせたい、即売会に間に合わせたい。モチベーションに貴賎はない。書こうという気持ちが薄らぐ日が来たときのために、モチベーションの源泉、自分なりのモチベーションの素をストックしておくことはとても大切。 小説を書く手順 パターン決め バリエーション決め あらすじ作り 原稿執筆 1. パターン決め 下記の4つのパターンが物語の王道。 主人公成長・破滅もの 長編は書きやすいが、短いストーリーが求められる新人賞などは取りにくい。だから、最初にこのパターンを使うのはオススメできない。 旅もの 一話完結でバリエーションをつけやすい。格闘マンガもコレに分類できる。 最初から英雄・天才もの 初心者向け。短編が書きやすい。分野を絞るのがコツだが、マイナーすぎるネタではよくないので、組み合わせを考えるとよい。 特殊なキャラ日常ひっかきまわしもの キャラの魅力がすべて。アニメ化しやすい。友人、知人と相談して決めていくのがよい。オリジナリティが一番必要。キャラの職業設定に困ったら「居候」がおすすめ。 この4つのうち1つでも習得できれば、一生食うには困らない。 逆にコロコロ変えると「ワールド」が作れなくて困ったことになる。 2. バリエーション決め パターンは「ケーキ台」で、バリエーションは「クリーム」。 バリエーションで決めることは下記の4つ。 超目的（テーマ） ストーリー上における、主人公の目的および目標。格闘ものなら「主人公が世界で一番強い男になる」で、探偵ものなら「主人公が真犯人を見つける」。 キャラ 登場人物。 ウリ（特徴） その作品で最も特徴的な事柄で、その作品にしかない魅力的な部分。ドラえもんであれば「道具を出すロボット」で、DEATH NOTE であれば「人を殺せるノート」。このウリの良し悪しで作品の人気が決まる。 世界観 物語の世界の時代と場所と様子。 パターンはすぐに決まるが、このバリエーション決めには時間をかけなければいけない。 バリエーションは小説の命であって、逆に言うと考えるところはここしかない。 パターンで期待させ、バリエーションでハラハラドキドキさせる。先が見えるのは OK だが、過程は秘密にしておくということ。 パターンとこの4つが決まると、話が固まってくる。 例えば「桃太郎」だと、超目的は「勧善懲悪」、キャラは「桃太郎、犬、猿、キジ、おじいさん、おばあさん、鬼」、ウリは「主人公が桃から生まれている、家来が動物である」、世界観は「中世日本」。 「世界観」に関しては、小説の執筆依頼時に編集者が決めてくることが多い。例えば、「架空戦記」だったら「第二次世界大戦中の日本」など。「キャラ」の制約までつけられることもある。制約のない仕事などどこの世にもないのだから、がんばれるところでがんばるしかない。 たくさんマンガを読んで、バリエーションの蓄積を作るべし。 3. あらすじ作り あらすじの字数は短ければ短い方がよく、できれば100文字以内、上限300文字以内におさまる内容にする。 本の裏表紙に書けるスペースは限られているし、読者に魅力を簡潔に伝えられなければいけない。 素晴らしいあらすじができたら、もうその作品は素晴らしい作品になることが決まったようなもの。 4. 原稿執筆 書けない人の訓練方法（3ステップ） ピーナッツを毎日1粒食べる 小説家にとって「継続すること」は何よりも大事。下らないことでも信じて1日も欠かさず継続するということは小説家修行になる。 毎日ブログ（文章）を3行でもいいので書く 1日も欠かさず書くことはとてもいい訓練になる。書かなきゃ小説はできない。書かない名作は絶対にない。これができるかできないかで、「読むのが好き」なのか「書くのが好き」なのかがはっきりする。 毎日好きな小説を書き写す 一字一句丸写しすることで、その作家の小説のリズムを学ぶことができる。手書きじゃなくても、パソコンでカチャカチャ打つだけでもとても勉強になる。 人は突然変わったりしないので、3ついっぺんにやってはダメ。 1ステップずつ確実に継続することでしか自分を変革することはできない。 読者をハラハラドキドキさせるには 初心者に多いのが、「主人公のミス」「上司のミス」でスリルを作ろうとするもの。 味方のミス（内輪もめ）では話が白けてしまう。 死闘を生むには、敵を味方より強くすればいい。 敵やライバルを魅力的なものにするには、敵の立場で考えること。 敵は、常に敵にとってベストの手段を選ぶ、ということを忘れないように。 主人公にとって都合の良いように振る舞わせるのは、あなたにとっての都合でしかない。 裏技としては、魅力的な敵と味方を作った時点で、本原稿を書き始めてしまう方法がある。 交互に敵と味方の視点にたって、知恵の出る限りを尽くして戦わせ、最終的に勝ち残った方を主人公にしてしまえばよい。 先にあらすじができていると使えないけど。"
},
{
url: "/p/syzny8w/",
title: "読書メモ『シェアリングエコノミー』アルン・スンドララジャン",
date: "2018-10-04T00:00:00Z",
body: "読書メモ『シェアリングエコノミー』アルン・スンドララジャン シェアリングエコノミー アルン・スンドララジャン 日経BP社 Uber や Airbnb といった「シェア」をベースにする企業が勢いをつけ、急速に社会のあり方が変わりつつあります。 シェアリングエコノミーとは何なのか？ なぜここまで浸透してきたのか？ これまでとは何が違うのか？ 今後どうなっていくのか？ といったことを、シェアリングエコノミーの第一人者であるアルン・スンドララジャンが包括的にまとめています。 これまでの社会はサービスや財が流通する世界でしたが、シェアリングエコノミーの世界では、人に対する感情、信用といった評価が重要になってきます。 典型的なのがトレイティーのサービスで、自分の献血経験やボランティア活動経歴など、信用の向上につながる情報は何でもデジタル化されて管理されるようになっています。 Airbnb などのうまくいっているプラットフォームには「信頼性」が付随しており、皆がよりよいサービスを提供したいと思わせる仕組みができています。 逆に、このあたりを理解せずに新しいシェアサービスを立ち上げてもうまくいかないでしょう。 P2P ビジネスの法律的な解釈についても述べられています。 例えば、Uber のプラットフォームを使用して働いているドライバーは、Uber の従業員の一種なのか、それとも独立請負人として扱うべきなのか？ 雇用保険のあり方や、裁判になったときの責任の所在などが変わってくるのでこれは大きな課題です。 このような論点での裁判は昔から多く行われており、決して新しい問題ではないと著者は述べていますが、訴訟社会であるアメリカが中心になって法的な整備が今後一気に進んでいくでしょう。 スンドララジャンは研究者らしく多くのサービスを取り上げて特徴をまとめています。 中でも、「プラットフォームのヒエラルキー性、市場性、ハイブリッド性」についてまとめた表は、今後登場するサービスの特徴を調べるときや、新しいサービスを作る際のよい指標になるでしょう。"
},
{
url: "/p/cnjd43a/",
title: "読書メモ『21世紀ファミコン』恋パラ支部長",
date: "2018-09-30T00:00:00Z",
body: "読書メモ『21世紀ファミコン』恋パラ支部長 21世紀ファミコン 恋パラ支部長、波多野ユウスケ マイクロマガジン社 世界でただ一人ファミプロを自称している恋パラ支部長さんの本。 有名どころのファミコンソフトを、普通とは違った遊び方で楽しむ方法が書かれています。 例えば、 「スーパーマリオ」を1つのコントローラーを2人で持って対戦プレイ。十字キー担当はマリオを死なせたら勝ち、ABボタン担当はマリオを死なせないようにジャンプで逃げる。 「チャレンジャー」も同じように対戦プレイ。 「ディグダグ」で地面を全部掘る。 「大航海時代」を一切航海せずにクリアする。 「魔界村」でレッドアリーマーをボスまで連れていく。 「アストロロボSASA」をコントローラー逆さまに持ってプレイ。 「バルーンファイト」の2人用をひとりでプレイ。 「デビルワールド」の画面上半分を隠してプレイ。 「ソロモンの鍵」で画面全てを石で埋め尽くす。5面でやるとよい。4の倍数面から行ける隠し部屋だとやや簡単。 「本将棋 内藤九段将棋秘伝」を2人でプレイ。相手の手番の後にCPUがプレイヤーを詰めれば勝ち。 「三国志」で CPU に天下統一させる。 「ロイヤルブラッド」で同上。 「テトリス」のブロックで文字を描く。 「ウィザードリィ」のパーティ全員を魔法使いにしてプレイ。 「半熟英雄」で攻撃は将軍のタマゴのみに限定。 「舛添要一 朝までファミコン」を本当に深夜から朝までプレイ。 「ギャラガ」を居合撃ちのみでプレイ（目の前で敵を撃つ）。一発でも外したらリセット。 「高橋名人の冒険島」でフルーツを1つも取らずにクリア。 「ナッツ＆ミルク」で敵のナッツを水中に落とさないようにプレイ。 などなど。 プレイ方法に制限を加えるものと、別の目標を作るものに大別できそうです。 やり尽くしたと思ったゲームでも楽しみ方は無限ですね。 著者の言う、ファミプロの掟の中に次のようなものがあります。 ゲームを遊ばず、ゲームで遊ぶ これはいい考え方だなぁ。 既存の枠組みに捉われず、何でも遊びに変えてしまえば、常に楽しく暮らせますね。"
},
{
url: "/p/eqrmt6x/",
title: "WinSCP をコマンドラインから利用して2つのディレクトリを同期する",
date: "2018-09-21T00:00:00Z",
body: "WinSCP をコマンドラインから利用して2つのディレクトリを同期する WinSCP のインストール WinSCP の本体は下記のサイトからダウンロードできます。 WinSCP :: Official Site :: Download ここでは、コマンドラインから winscp.exe を使用しますので、インストーラを使ってインストールするときに、カスタムインストールを選択し、インストールディレクトリを環境変数(%PATH%)に追加を選択してください。 winscp コマンドでリモートホストへディレクトリをコピーする ローカルディレクトリの内容を、リモートにあるディレクトリへ同期させるには、次のように winscp.exe の /synchronize オプションを使用します。 winscp [mysession] /synchronize [local_directory] [remote_directory] 例えば、example.com というホストに、ユーザ名 user で接続してローカルの website ディレクトリ内のファイルを user のホームディレクトリの public_html ディレクトリに同期させるには次のようにします。 例: ローカルの website をリモートの public_html へ winscp user@example.com /synchronize \u0026#34;C:\\Users\\maku\\website\u0026#34; \u0026#34;/user/maku/public_html\u0026#34; 参考 WinSCP のドキュメント (Command-line Options)"
},
{
url: "/p/cy3f9xj/",
title: "ボードゲームではダブリングキューブをもっと利用したらいい",
date: "2018-09-16T00:00:00Z",
body: "ボードゲームではダブリングキューブをもっと利用したらいい みなさんバックギャモンはやったことありますか？ ボードゲーム界ではプレイヤー数はチェスと並んで世界最大とも言われるバックギャモンですが、日本ではあまりプレイされていないんですよね。 ルールも簡単で、見た目もおしゃれなのでもっと流行ってもよいんですけどね。 というわたしも最近ルール覚えたばかりですけど(^^; 実はバックギャモンの世界チャンピオンは日本の矢澤亜希子さんです。 これを期に、日本でもプレイヤー数増えていくといいですね。 【特報】第43回世界選手権　矢澤亜希子選手が優勝 と前置きはこのくらいにしておいて、バックギャモンの中に「ダブリングキューブ」というものがあります。 写真の真ん中にあるサイコロです。 よくある6面体のサイコロですが、描いてある数字は 2、4、8、16、32、64 と、倍々になってます。 だから、ダブリング。 このダブリリングキューブはころころっと転がして使うのではなくて、現在の勝負の得点を2倍にするダブル宣言（倍プッシュ！）をするときに使います。 ダブル宣言を突きつけられたプレイヤーの取れる選択肢は2つです。 テイク: ダブルを受けて2倍になった得点でゲーム続行する パス: 現在の得点（1点）を相手に与えてゲーム終了する つまり、ダブル宣言とは、 もうオレの勝ちだからオリて得点よこせよ！ と、オリを強制しているわけです。 ただし、ダブルされた方は、もし自分の方が勝っていると思えば倍付けの勝負を続行できるので、ダブル宣言する方は慎重に行わないといけません。 しかも、次のダブル宣言はダブルを受けた側のみが権利を持つことになり、逆に4倍の勝負を突きつけられるリスクを追うことになります。 これって得点が倍々になっていくのでギャンブル要素の強いルールですが、その考え方はとても理にかなっていて、消化試合的なゲームがダラダラと続いてしまうのを防ぐ効果があります。 だから、このダブリングキューブは、もっといろんなゲームで利用してもよいと思うんですよね。 特に二人用のボードゲームなどで、ポイント制をとっているものであれば、このダブリングキューブがひとつあればドキドキハラハラな展開を楽しめます（ダブリングキューブがなくてもできますけど、雰囲気大切！）。 もちろん、最後まで逆転要素があるゲームであればそれがベストですが、どうしても最後には消化試合になってしまうようなゲームでも、ダブリングキューブがあればもっと楽しめます！ 2018-10-20 追記 ライナー・クニツィア氏の『ダイスゲーム百科』にダブリングキューブを使うゲームが載ってました。 イースト・ウェストというポーカー系のゲームのバリエーションとして紹介されています。 ダブリングキューブの仕組みはいろいろなゲームで利用されているみたいですね。 ダイスゲーム百科 ライナー・クニツィア スモール出版"
},
{
url: "/p/h5j77zj/",
title: "『人身売買デスゲーム』やった",
date: "2018-08-19T00:00:00Z",
body: "『人身売買デスゲーム』やった RPG アツマールというサイトで公開されてる『人身売買デスゲーム』ってのをずっとやってました。 試しにやってみたら、数時間かけて結局最後までやってしまった。 人身売買デスゲーム - RPGアツマール GANTZ みたいに数人が部屋に閉じ込められたところから始まって、逆転裁判のように推理を進めながらステージごとに一人ずつ脱落していく（投資家に人が売られていく）ゲームです。 逆転裁判好きだから、こーゆーの好き。 特殊能力を使える人が出てくるストーリー物は、「変身できる能力」、「能力をコピーできる能力」ってのが入ってくると途端に複雑になりますね。 人身売買デスゲームには両方ともでてくるからややこしい。 でもゲーム自体は簡単に進んでいくので（逆転裁判よりかなりイージー）、どちらかというとノベル読んでるみたいな感じです。 ちなみに、ゲームの中では、上下する人の価値に対して投資をして株のように稼ぐシステムがあるのですけど、これでがんばって稼いだお金はほとんど使う場面がありません。ここだけ拍子抜け。"
},
{
url: "/p/2454mic/",
title: "読書メモ『ラクして速いが一番すごい』松本利明",
date: "2018-08-17T00:00:00Z",
body: "読書メモ『ラクして速いが一番すごい』松本利明 ラクして速いが一番すごい 松本利明 ダイヤモンド社 若干コンサルタントよりの内容になっていますが、会社のなかで要領よく仕事をすすめていくコツがたくさん書いてあります。 若いうちに読んで実践すると早く出世できそうですね。 メモ 報告・説得 何かを伝えたいときは、報連相（ホウレンソウ）ではなく、**空雨傘（ソラ・アメ・カサ）**を使う。マッキンゼーの日本オフィスが考えた思考のフレームワーク。 空（ソラ）を見ると曇ってきた（事実）。 雨（アメ）が降りそうだから（洞察）、 傘（カサ）を持って行こう（打ち手）。 差が出やすいのは 2 つ目の洞察部分で、「どうしてそうなった（過去）」ではなく、「どうなりそうなのか（未来）」を伝えることがポイント。 上司を説得するには、自分の価値観ではなく、会社の価値観を利用する。「我が社の価値観の『◯◯』に沿って判断するとこうなります」と言えばいい。個人の見解では上司にひっくり返される。下記は会社の価値観・判断基準の例。 ディズニーランド: ◯夢の国、×現実 アップル: ◯シンプル、×細かなたくさんの機能 サウスウエスト航空: ◯格安、×費用 話を始めるときは、相手の「欲」をダイレクトに刺激するひと言を最初に言う。最初に大した話ではないと思われたら、結論がどれだけすばらしくても話半分にしか聞いてもらえない。 資料 50名を超える講演やセミナーなどの場合、黒地に白で文字を見せたほうが、遠くからはハッキリ見える。最後の資料として「サマリ」を付け、最低限持って帰ってほしいことを 3 つ、多くても 5 つにまとめて伝える。 外資系コンサルタントは、入社時に「パワポの配色ルール」を教わる。色の3属性は「色相」「明度」「彩度」だが、重要なのは色相。 2色の場合: 色相環上の反対色を使う。橙系と青系がオススメ。 3色の場合: 色相環上で正三角形を意識して使う。赤系、青系、黄系の3つがオススメ。 4色の場合: 反対色を2つ組み合わせて使う。橙系、青系、赤系、緑系の4つがオススメ。 パンチラ（パンチライン）など、遠くからでもハッキリとメッセージをアピールしたいときは、明朝体ではなくゴシック体を使う。標準のMSPゴシックは太字にすると投影時や印刷時の相性問題でレイアウトがズレやすいので、「HGP創英角ゴシックUB」がオススメ。 早く確実に文章のミスをチェックするには、音読して文章をチェックする。 用語集は「OK/NG方式」で作成し、更新日と更新者名を入れておく。Excel の場合は、一番左に「Read me」のタブを作り、そこに用語集を入れておく。 下記はOK/NG方式の一例。 OK:「ドラフト」、NG:「草稿」「メモ」「たたき台」 OK:「ギャランティ」、NG:「報酬」「フィー」「契約料」 OK:「報告書」、NG:「調査書」「レポート」 断る Yes/But 法でいく。ひと呼吸おいてから「わかりました」と言い、受け入れながらも自分の意見を主張する。No というだけでは嫌われるだけだが、どうすればその仕事が早く進むかを一緒に考えると逆に感謝される。 多部署からの依頼は、他の人に回すときは「◯◯さんがいいと思います」と名前を伝えるだけでは不十分。「できるか聞いてみますね」、「私からも彼にメールを入れておきます」というつなぎのひと手間をかける。 アピール 自分のことを伝えるには、過去→現在→未来の3点セットで伝えるのがコツ。 評判を上げる近道は、常にまわりに感謝すること。「うまくいったのは◯◯さんのおかげです。ありがとうございます」と声に出して言う。具体的に何のどこがどうよかったのかをハッキリと言葉にして伝える。メールで感謝を伝えるコツは、事実をベースに、短文で「ありがとう」を伝えること。追伸の形で「いつも◯◯してくれてありがとう」と書くのもよい。 嫉妬されずに、うまく自分の手柄をアピールするには**「みんなでやった」と言う**。まわりの100人に感謝すれば、その同じ100人分の感謝が自分1人に集まる。 スケジューリング／タスクの処理 「みなさん、ご都合はいかがでしょうか」と聞いてしまうと相手の都合に振り回される。「次回のミーティングは、◯月△日13時でいかがでしょう？」と先に自分の都合で提示する。 1日は8時間ではなく、6時間でスケジューリングしておく。イレギュラーなことが発生したり、チャンスが舞い込んだときに手をあげる余裕が生まれる。 TODO は「緊急度ｘ重要度」の軸ではなく、「成果が出るｘ自分に向いている」の軸で考えると他人の緊急度によって振り回されずに済む。 自分一人の仕事より、相手がいる仕事から着手する。 最終的に手元に残すのは「あなたが得意で、かつ、あなたにしかできない仕事」だけ。得意な仕事を洗い出し、その具体的なノウハウを他人でも使えるようにツールやフォーマットに落とし込んでみる。落とし込めるものは他の人でもできる。 優秀で本当に忙しい人ほどビックリするくらい返信やお礼のリアクションが早い。逆に忙しいフリをしている人は返事が遅い。一行だけでもいいのですぐ返信する。 打ち合わせ 「議事録を文書で起こす」という社内ルールがないのであれば、ホワイトボードの内容をスマホで撮り、関係者に一斉メールすることで議事録作成の手間を省く。グーグルや外資系コンサルティング会社などはこの方法をとっている。 持論を繰り返す人は、自分の意見を大事に扱ってくれないことや、無視されることに腹をたてるので、ホワイトボードにその意見を書いてあげるだけで満足してくれる。 独演会を始める人の対策としては、ホワイトボードに終了時間を書いておき、「お話の途中ですみません。重要な話の内容ですが、あと15分で結論を出すことになっています。一番のポイントを先に教えていただけますか？」と切り出す。 キーマンとのランチで話す内容は、事実ベースの内容にする。(1)現部署でどんなことがおきているか、(2)どんなことで悩んでいるか、(3)どんな人が実は活躍しているか、という現場の一次情報を伝えると喜ばれる。告げ口、悪口、おべっかは言わない。事実のみを伝えるので、解釈はあなたに任せます、というスタンスが正解。 会議やセミナーの Q\u0026amp;A では、真っ先に発言するだけで「できる人だ」と評価されるようになる。優秀な人は「最初に発言」することで評価されている。 姿勢を正し、ハッキリとした声を出す。 コンサルタントは厳しいことを言うが、お辞儀が一番深く、長い。壇上では堂々と力強い姿を見せるのに、実際お会いして見ると腰が低くていねい。このギャップが魅力につながる。 仕事ができない人への対処 仕事ができない人の特徴は、「プライドが高いが、自分に自身がなく、ガラスのハートを持っている」ことなので、仕事のできない人を責めるのは逆効果。 そもそも仕事が遅い人: ツールやフォーマットに沿って作業を支持する。 抱え込んで自爆する人: 理解できたかどうか相手の口で言ってもらう。 間違えても気にしない人: 確認するプロセスを細かくする。 学び 日本企業のリーダー教育に徹底的に欠けているのは「リベラルアーツ」。特に、哲学、世界史、自国の歴史や文化に対する知見が圧倒的に欠けている。ここを抑えるだけで、まわりから頭二つは抜きんでることができる。**『プロテスタンティズムの倫理と資本主義の精神』『君主論』『孫子』『史記』は押さえておくとよい。宗教に関係なく、『旧約聖書』**に書かれていることは世界常識。小熊英二著『1968(上)(下)』は分厚いが近代日本史を知るのによい。 自分でコツコツやるのも大切だが、その道の第一人者に弟子入りすることで、より多くのチャンスを掴み、思考や習慣を身につける。「弟子にしてください」「あなたのもとで勉強させてください」と直球で行くのが一番。 メンターを選べるなら、こだわりがハンパなく、人を寄せ付けない雰囲気の大御所にするのがよい。ライバルの弟子も少なく、教えてもらえる時間やチャンスを独り占めしやすい。ただ、最終的なポイントは馬が合うか。 優秀な人は**「異業種」でやっているうまい方法をパクり、オリジナルのものにしてしまう**。良い例が「オフィスグリコ」。路上での無人の野菜売り（代金回収率9割）の手法を真似て、オフィスにお菓子を常備したところ、代金回収率は100%だった。 異業種で成功している人と仲良くなり、直接教えてもらうとよい。同業や競合でなければ、親しくなれば意外と教えてくれる。 スクールに通うのであれば、そのスクールを卒業した人たちがどれだけ活躍しているのかを確認する。 6000名以上の優秀なリーダーの行動計画は、簡単ですぐにできるもの。「早起きする」「挨拶をしっかりする」「1週間に1冊は本を読む」。行動計画を具体的にたくさん作ると3日で挫折してしまう。大事なことは「続ける」ことに労力をかけず、コツコツ習慣にしていくこと。 自分の使命やアファメーション（ポジティブな言葉による自己暗示・誓い）は、手帳などの最初のページに記しておき、毎日繰り返し読み上げる。 優秀なリーダーは**「自分は運が良よく、いろいろあっても最後はできる」という根拠のない自信を持っている**。だからミスしても、冷静に自体を受け止め、落ち込まない。打ち手をさっさと修正するだけなので、難局もすぐに乗り越えられる。逆に、普通のリーダーはミスをすると「反省・内省」してしまう。ミスの原因を「人」に求めるようになり、「課長が悪い」、「取引先が悪い」と生産性の上がらないムダな時間を過ごすことになる。"
},
{
url: "/p/saanpfh/",
title: "読書メモ『J2EE パターン』 Deepak Alur、John Crupi、Dan Malks",
date: "2018-07-19T00:00:00Z",
body: "読書メモ『J2EE パターン』 Deepak Alur、John Crupi、Dan Malks J2EE のパターンコレクションを示した本です。 有名な GoF のデザインパターンとは異なる、21 のパターンが紹介されています。 既存のプロジェクトにパターンを適用するにはリファクタリングが必要になりますが、その方法も示されています。 Grady Booch（Rational Software Corporation 主任研究員）のまえがき パターンに名前を付けることによって、新たな語彙を手に入れ、それまでは気付かなかったであろう方法でパターンを適用できるようになる。 慢性的に時間に余裕がないところでは、美しいソフトウェアはなかなか書けない。 しかし、適切なパターンを選んで適用すれば、システムにある程度の優雅さをもたらすことができる。 マイクロアーキテクチャとは マイクロアーキテクチャは、アプリケーションおよびシステムの構築に利用できるビルディングブロック。個々のパターンよりも抽象度が高く、複数のパターンをリンクさせ組み合わせて表現することができる。 第1章: パターンとJ2EE パターンの定義 パターンとは、特定の文脈、問題、および解決策の相関関係を表した、3要素から成る規則である。 ─Christopher Alexander 『A Pattern Language』 パターンとは、「特定の文脈」、「その文脈において繰り返し発生する問題」、および「これらの問題を解決する特定のソフトウェア構造」の3要素の相関関係を表した規則である。 ─Richard Gabriel『A Timeless Way of Hacking』 パターンとは、ある現実の文脈の中で有用であって、他の文脈の中でもおそらく有用であろうと思われるアイデアである。 ─Martin Fowler『Analysis Patterns』 繰り返し発生する問題と、その解決策に関する知識を表現して伝えるには、パターンが理想的なツールである。 考慮事項、アイデア、メモなどの知識を公式に文書化して伝えることができるようになる。 第2章: プレゼンテーション層における設計上の考慮事項とバッドプラクティス この章では、ユーザセッションやクライアントアクセスの制限に関しての概要が述べられている。 プレゼンテーション層におけるバッドプラクティスがざっと羅列してあるが、特に目新しさは感じられない（コントローラーが肥大化したら他のオブジェクトに処理を委譲する、といった程度のことしか書いてない）。 第6章以降のパターンカタログの方を見ていくのがよい。 第3章: ビジネス層における設計上の考慮事項とバッドプラクティス ステートレスなセッションBeanであれば、Beanをプールしておいて、複数のクライアントで使いまわせる。 スケーラビリティの問題のほとんどは、ステートフルセッションBeanや、ステートレスセッションBeanの誤用によるものである。 スケーラビリティが必要なシステムでは、ステートレスセッションBeanを使用することがより実用的な設計戦略となり得る。 1回のメソッド呼び出しでサービスが完了するビジネスプロセス（非対話型ビジネスプロセス）を実装するには、ステートレスセッションBeanを使うとよい。 スケーラビリティの向上を狙って、どのようなケースでもステートレスセッションBeanを選択する設計者もいる。 しかし、こうした設計を行ったために、ネットワークトラフィックのオーバーヘッド、再構築時間、アクセス時間などが絡んできて、かえってスケーラビリティが低下してしまっては本末転倒である。"
},
{
url: "/p/9kuptdn/",
title: "『オブジェクト開発の神髄 UML2.0を使ったアジャイルモデル駆動開発のすべて』スコット・W・アンブラー",
date: "2018-07-18T00:00:00Z",
body: "『オブジェクト開発の神髄 UML2.0を使ったアジャイルモデル駆動開発のすべて』スコット・W・アンブラー オブジェクト開発の神髄 UML2.0を使ったアジャイルモデル駆動開発のすべて スコット・W・アンブラー 日経BP社 原題は『The Object Primer』。 スコット・アンブラーのフルライフサイクルオブジェクト指向テスト (FLOOT: Full Lifecycle Object-Oriented Testing) から、アジャイルな要求やアーキテクチャまでが、1 つにまとめられています。 実践 eXtreme プログラミングの共著者である Granville Miller は、「アジャイルになるとは、チームや自分自身に対する制約を取り払うこと」だと述べています。 本書ではその方法の神髄を学ぶことができます。 下記、重要そうなところや、個人的にビビッと来たところのメモです。 第1章: 最先端のソフトウェア開発 下記がアジャイルアライアンスのマニフェストであり、そこに集まった異なる方法論者全員に受け入れられたものである。 Individuals and interactions over processes and tools プロセスやツールよりも個人や相互作用 すばらしいプロセスやツールは重要だが、結局は人の協力関係がすべて。 Working software over comprehensive documentation わかりやすいドキュメントよりも動作するソフトウェア ドキュメントはシステムがなぜ、どのように構築されたか、どう使えばよいかを理解するためには重要。 Customer collaboration over contract negotiation 契約上の駆け引きよりも顧客との協調 契約は重要だが、契約を結んだからといってコミュニケーションが必要なくなるわけではない。 Responding to change over following a plan 計画を硬直的に守ることよりも変化への対応 プロジェクト計画は必要だが、柔軟でなければならない。ガントチャートを何枚も作成する必要はなく、非常に単純なものでよい。 自己組織化されたチームとは、チームのリーダーが開発メンバーの各自の役割や作業範囲を決めるのではなく、目標を共有するメンバーが共同作業を行う過程でチームの能力が最大限発揮されるようにメンバーの役割が自然に決まっていくようなチーム形態のこと。 成功を収めている組織は、大抵アジャイルなソフトウェア開発アプローチをとっているか、RUP または EUP を採用しているかのどちらかだ。RUP をアジャイルに使おうとしても現実には非常に困難（素材が多すぎてアジャイルなレベルまで切り詰められない）。アジャイルプロセスを取り入れたいなら、XP や FDD などを採用すべき。 MDA よりも、アジャイルモデル駆動開発 (AMDD: Agile Model-Driven Development) アプローチの方が、お絵かき式のモデリング方法に近く、現実的に大多数の開発者が採用できるアプローチである。 第2章: オブジェクト指向概念の基本 この章にはオブジェクト指向を知らない人のために、その概念について書かれています。 第3章: フルライフサイクルオブジェクト指向テスト (FLOOT) FLOOT とは ソフトウェア開発中に作成するさまざまな成果物を検証するためのテスト手法が必要である。 フルライフサイクルオブジェクト指向テスト (FLOOT: full lifecycle object-oriented testing) 方法論とは、オブジェクト指向ソフトウェアの検証および妥当性確認を行うためのテスト、および検証手法を集めたもの。 FLOOT のさまざまな手法は、モデルやドキュメント、ソースコードなど、広範なプロジェクトの成果物をテストするためのものである。 図: FLOOT 方法論に含まれる手法 ただし、この一覧にはすべての手法が網羅されているわけではなく、利用できる選択肢には様々なものがあるということが重要。 また、それぞれの手法は必ずしも逐次的に行う必要はない。 エラーの検出が開発ライフサイクルの後期になればなるほど、それを修正するためのコストは指数関数的に増えるので、早い段階から何度もテストをした方がよいことは明らかである。 レビューについて アジャイル開発手法のインクリメンタルな反復型アプローチでは、開発サイクルが短縮されているため、たいていのモデルレビュー作業をとりやめて、代わりにユーザ受け入れテストを行うことができる。 アプリケーション開発において品質が上がるのは、ソフトウェアの適切な作り方を理解した開発者、経験から学んだ開発者、教育やトレーニングによってスキルを身につけた開発者のおかげである。 レビューを行えば品質の欠けている箇所は見つかるが、それがアプリケーションの品質向上に直結するわけではない。 モデルのレビュー時にコミュニケーションをとるよりも、モデリング時に協力して作成してしまった方が効率的である。 この考え方により、アジャイルな開発では、公式のレビューを避ける傾向がある。 つまり、レビューが不要になる体制を作るのが理想的ということになる。 これは、コードインスペクション（コードレビュー）に関しても同じことが言える。 ペアプログラミングで開発しているのであれば、コードレビューは必要なくなるからである。"
},
{
url: "/p/d3ehztz/",
title: "読書メモ『ワークブック形式で学ぶ UML オブジェクトモデリング─ユースケース駆動でソフトウェアを開発する』ダグ・ローゼンバーグ、ケンドール・スコット",
date: "2018-07-18T00:00:00Z",
body: "読書メモ『ワークブック形式で学ぶ UML オブジェクトモデリング─ユースケース駆動でソフトウェアを開発する』ダグ・ローゼンバーグ、ケンドール・スコット ワークブック形式で学ぶ UML オブジェクトモデリング ダグ・ローゼンバーグ、ケンドール・スコット ソフトバンククリエイティブ 「ユースケースと UML モデリングの例題がもっと必要だ」という声がきっかけになり書かれた本です。 ユースケースという抽象的な表現から、どのようなステップで具体的なコードにまで落とし込んでいくかが説明されています。 このような開発をユースケース駆動と呼んでおり、提唱者の Ivar Jacobson によると、ユースケース駆動は下記のように説明されています。 システム機能を変更する場合は、適切なアクタとユースケースを再モデル化します。 システムアーキテクチャ全体は、ユーザの要求にそって構築されます。 すべてのモデルはトレースできるようにしておくと、新しい要求仕様が発生した際にもシステムの修正が可能になります。 ユーザに対し、変更したい部分（もしくは変更したいユースケース）の内容を確認し、ほかのモデルの中でどの部分を変更するかを見極めます。 本書の著者、ダグ・ローゼンバーグはこれを以下のように簡単に解釈しています。 ユーザマニュアルを書けば、コードも書ける。 第1章: はじめに ここで用いる ICONIX プロセスは、重量級の RUP（ラショナル統一プロセス）と、軽量級の XP (eXtreme Programming) の間に位置する。具体的で理解しやすいユースケースが作成できるという点で、Ivar Jacobson が構想した「ユースケース駆動」の意味に一致している。 ソフトウェアプロジェクトの進捗はどれだけのコードを書いたかによって測定されることが多いので、プロジェクトはコーディングに移行しようとする。そして、モデリングが十分にできていない段階でコーディングが始まってしまう。 本書の目的は、ソフトウェアプロジェクトにおいて、よい仕事をするために通常必要と思われる UML（およびモデリング全般）の、最小限ではあるが、十分なサブセットを定義すること。 what（要求）と how（詳細）のギャップを埋めることが ICONIX プロセスの中心課題である。ロバストネス図を使って、あいまいで漠然としたユースケース（要求レベルのビュー）と、詳細で正確なシーケンス図（設計レベルのビュー）のギャップを解消する。ロバストネス図を使用せずにユースケースからシーケンス図を作成することは非常に難しい。ロバストネス分析は、要求と設計のギャップを解消するのにとても役に立つ。 ギャップの解消するためには、ロバストネス分析の中で、下記のような作業を並行して行っていく。 見落としていたオブジェクトを見つける。 データフローをトレースする際に、クラスに属性を追加する。 ロバストネス図を描きながら、ユースケース記述を更新し洗練する。 ドメインモデルで定義した「用語」を使ってロバストネス図を描く。 ユースケースモデル ⇔ ロバストネス図 ⇒ シーケンス図 図: ICONIX プロセス全体像 ICONIX プロセス: プロトタイプを作る（おそらく画面の簡単な描画）。 クライアントに誤りがないかを確認してもらう。 ユースケース図のユースケースを識別する。 ユースケース記述を書く。 ロバストネス分析でユースケース記述を洗練する。 第2章: ドメインモデリング ドメインモデリングでは、UML モデルの静的な部分の基礎を形成する。 ドメインモデルは実世界の問題空間オブジェクトを中心に構成するので、ソフトウェアの要求ほど頻繁には変化しない。 ドメインモデルは、ユースケースを記述する作業の初期段階で使用できる「用語集」の役割を果たす。 ドメインモデリングでは、属性と操作の把握には時間を費やさない。後の作業で明らかになった属性と操作を追加していけばよい。 ドメインモデリングでは、オブジェクト間の関係（汎化や集約）を識別することに焦点を当てる。 ソフトウェアが再利用できるかどうかは、このドメインモデリング作業にかかっている。 ドメインモデリングの誤りトップ10 ドメインモデリングのコツはすばやく作ること。ブラッシュアップは後のロバスト分析などの過程で行っていけばよい。 無駄にデザインパターンを適用しようとする ドメインモデリングは、パターンの観点から考え始めるべきではない。 デザインパターンは、シーケンス図や設計レベルのクラス図で意識するもの。 ドメインクラスと RDB のテーブルを 1対1 にマッピングしようとする データベースのテーブルは、ドメインクラス名のよい情報源になるが、ドメインモデルは、オブジェクトモデルのコンテキストで考えるべき。 フレンド関係やパラメータ化クラスのような実装の構成要素を登場させる ドメインモデリングの焦点は、問題空間であるべき。 PortfolioManager のような直観的な名前でなく cPortMgrIntf のような名前を使用する ドメインモデリングの目的のひとつは、プロジェクトの全員が重要な抽象名に合意することである。 問題空間をモデル化せず具体的な実装方法を考える RDB やサーバのような特定の技術に依存する内容を含めるべきではない。 各 a part of 関連に集約とコンポジションのどちらを使うかを議論する ドメインモデリングの段階では、とりあえず集約を使用しておけばよい。 要求を満たすかを確認する前に再利用性のための最適化を行う ドメインモデリングではクラスに操作を割り当てるべきではなく、再利用を考える段階でもない。 ユースケースとシーケンス図を吟味せずにクラスに操作を割り当てる ドメインモデルの段階では情報が十分ではないので、クラスに操作を割り当てるべきではない。 過度に名詞と動詞の分析を行う オブジェクトの識別に没頭しすぎて、抽象度の低い抽象化にならないように。 関連に多重度を割り当てる ドメインモデリングの段階では多重度を考えない方がよい。分析中毒の原因になる。"
},
{
url: "/p/wskda99/",
title: "アプリや製品のアイデア",
date: "2018-07-11T00:00:00Z",
body: "アプリや製品のアイデア アイデアのもとは整理しない アイデアを生み出すことを目的するのであれば、情報は 整理してはいけない。 PC に情報を保存するときも、雑多に突っ込んでおいて、全体を見返せるようにしておくのがよい。 → ランダムにアイデアを 2 つ以上表示するようなポータルサイトを作るといいかもしれない。アイデアの組み合わせによって発想を促すように。"
},
{
url: "/p/rx89f98/",
title: "障害者向けの製品アイデア",
date: "2018-07-11T00:00:00Z",
body: "障害者向けの製品アイデア 聴覚障害 自分が喋っている言葉の発音がきれいになるようにサポートする（表示 or 振動） 音声を振動に変えて伝える（自分の名前が呼ばれたらリストバンドを特定のパターンで震わせるなど） 発話障害 ジェスチャーをリアルタイムに会話音声に変換（首かけ型のガジェットから、カメラで判別＆音声出力）"
},
{
url: "/p/w9j69xb/",
title: "読書メモ『雀鬼流。桜井章一の極意と心得』桜井章一",
date: "2018-07-09T00:00:00Z",
body: "読書メモ『雀鬼流。桜井章一の極意と心得』桜井章一 雀鬼流。桜井章一の極意と心得 桜井章一 三五館 裏プロの世界で20年間無敗だった桜井章一氏が、初めて雀鬼流について記述したものです。 雀鬼流は麻雀の技術ではなく、生き方について教えています。 教育の世界に身を置く人や武道家、スポーツ選手など、桜井氏の考え方は多くの人が参考にしています。 知識の中には、実体験で得たものと、そうでないものがある。実体験で得たものを尊重したい。 外面的なことに身を任せるのではなく、自分という内面に身を任せるなら、自分という存在に確信を持つことができるはずなのだ。 我が道を生きるとは、われを見捨てず、われを人任せにせず、自分の内面を、心を、思いを大切にし、われを知ることにある。楽しい人生というのはそんなところにある。 かかわりを深くしていると、楽しかったり、いいなあと思えることが沢山増えるのです。 雀鬼会では、もっともっと心を開け、行動を惜しむな、と教えている。そうしていかないと、いつまでたっても、本当の自分というものに気づかない。 おもしろいこと、楽しみは、外に求めるべきものではなく、楽しみを作る人間にならなければいけない。 人のことをわかろう、わかろうとするのではなく、自分のほうをきれいに掃除して、無駄な要素を省いていけば、相手のことが見えてくる。 多くの人たちは、自分に価値を見出せないから、真の価値を見出せないから「数」に価値を見出して、「数」を追うほかなくなる。 相手に鳴かれるかもしれぬ、手の内に残ったどちらかの牌が当たり牌だ、というスレスレのところまでやってみないと、読めているのか、ズレているのかの見極めがつかないし、流れを自分のものとすることはできない。 自分である程度納得ずくで振る、という振りを「勝負振り」というんですが、納得感のある振り込みを心掛けなければ勝負運、勝負強さというものは身につかない。 勝とうという意識が先にきてはいけないのです。低いレベルで勝っても、それは価値のある勝利ではないのです。政治もビジネスも同様です。 他人を欺くことだけが、嘘をつくことではない。自分で自分に約束したことを破ることも、嘘をついたことになる。 「東の二局に絶対和了るんだ」「南の三局は絶対何が何でも和了るんだ」と、勝負が始まる前に、前もって決めてしまう。いい手悪い手なんて関係ない。どんな配牌でも、その一局では一歩も下がらないで和了きることです。点棒上では負けであっても、前もって決めておいた東場と南場の二回を和了れば、その勝負は勝ちなのです。こういう強い意思を育む訓練によって、オーラスという状況を迎えたときに、いとも簡単に和了れるようになってくる。 不真面目に生きることも良くないですし、真面目くさって生きることもよくないのです。真面目とユーモアがくっついてこそ、本当のあったかさが生まれるんです。そうすることで、理不尽なことは決して許せないといった真面目な側面とのバランスをとっているのです。 ふんぞり返ってもいない、意気消沈してうなだれてもいない、真ん中にいて背筋を伸ばしている人は崩れない。真ん中にすっくと立っている人が一番強いということなんです。自分の手の内を全部さらけ出している人が一番強いのです。 麻雀は人と人との戦いですが、私は他者には惑わされません。麻雀だけを見つめていればいい。「アイツ強いからなあ」と、人を見てしまうと、麻雀との戦いではなく、人との戦いになってしまう。誰が相手であろうが、人が見ていようがいまいが、己の姿勢を崩さない心をふだんから持ち続けなければならないのです。 ヒクソン・グレイシーの言葉「見ただけで相手をジャッジしないようにしている。目に見えるものにとらわれない、信じるものは、心に感じられたものだけだ。」 人生をお金の動きだけで捉えようとすることに意味がないように、勝負の行方をはっきりと決定づけるのは、点棒の動きではなく、打ち手の心の動きです。 自分の手牌はもちろんですが、敵の三人の表情、河（ホー）の捨て牌など、あらゆることに気をくばって、それでいてどこか一箇所に気をとられてしまってはいけない。つまり、部分的なものに目を奪われることは避けて、勝負全体を、流れを見ることが大切なのです。 自分のために麻雀を打つのではなく、一緒に打ってくれる三人のために打つ気持ちをまず大切にしなさい。そうすれば、潔さとか、犠打とか、思いやりとかがわかってくる。自分のためだけを考えて打っているのであれば、自分以外の人の心の動きなど見えてくるはずもない。私を捨てて公で打て。 いいライバルがいるということは、喜ぶべきことなのです。日々自分で自分を叱咤激励することはとても困難。ですから、雀鬼会では、いいライバル作りを心掛けているのです。ただ己を向上させることだけではなく、真剣に戦いあうために、己の、そしてライバルの雀力をアップさせなければいけない。 二日間の戦いで、２時間くらいしか寝てないときがけっこうありました。そんなとき、大抵の人は、体のせいにしてしまう。私は逆です。「あ、チャンスだな」と思う。いわゆる不運を、与えられた手だ、テーマだと思うのです。人がリーチをかけてくると、私はうれしくなる。条件が厳しくなればなるほど、緊張感が高まって気持ちいい。相手のリーチは、川の流れの中の岩であり、障害物です。水や魚はぜんぜんそれを気にしません。岩をこわがり逃げるのは人間心理。それを水や魚になって、すき間を見つけたり、迂回するのが、流れにそうと言うことです。 求めるべきなのは、安住ではなく、試練なんです。試練が、人を鍛え上げてくれるんです。つねに公の精神を忘れないで、不安定や危険に飛び込んでいく姿勢を持っていないと、低いレベルからはなかなか脱し切れないんです。 育児／恋愛 世間の言ういい子というのは、自分自身を小さい頃から売ってしまっている子です。いい子になりなさいと洗脳されてきた子で、いいなりになりやすい人間に育ってしまっているといえませんか。すべて親のいうことを聞いているということは、親に魂を売ってるということです。 本当の素直というのは、良い悪いをきちんとわきまえて、悪いことは悪いと、自分の気持ちに忠実にはねつけられることです。両親のいうこと、先生のいうことを半分聞いて、半分は聞かないほうが、良い子であり、素直な子だと私は思う。堂々と、「お父さんには、こんな駄目なところがあるんだよ」といえばいい。 私の育児観はこうです。子供たちが小学校を終えるまでは私は子供の奴隷、ということです。中学からは立場は逆転して、私がトップになる。それも、二十歳になる間だけです。二十歳になってからは、対等の関係なんです。十分に与えてもらって来た子は、欲求不満に陥っていないので、思ったより簡単に甘えから自らを解放し、自立できるようになるものなんです。 子供のほうでは、十分に悪いことをやってしまったと自覚してて、相談にきている。そういうときは、私は絶対に怒りません。本人が、悪いことをやっているのにもかかわらず、悪いことをやったということに気づいていないときは、コラッと怒る。 愛し合うときは、じゅうぶんに愛しあって、それ以外のわかりあえない部分があっても、それはそれでいいわけです。このズレを埋めようとしてしまうからいけない。"
},
{
url: "/p/57uv9oa/",
title: "読書メモ『シンギュラリティは近い』レイ・カーツワイル",
date: "2018-07-01T00:00:00Z",
body: "読書メモ『シンギュラリティは近い』レイ・カーツワイル シンギュラリティは近い レイ・カーツワイル NHK出版 人工知能 (AI) が人類を上回り、この世のあり方が一変するシンギュラリティ（技術的特異点）。 人工知能の世界的権威であり、Google で AI 開発の先頭に立つレイ・カーツワイルが、シンギュラリティはなぜ間近だと断言できるのか、シンギュラリティに到達すると何が起こるのかを解説しています。 シンギュラリティとは何か？ テクノロジーが急速に変化し、それにより甚大な影響がもたらされ、人間の生活が後戻りできないほどに変容してしまうような、来るべき未来。 人生の意味を考えるうえでよりどころとしている概念が、このとき、すっかり変容してしまう。 数学者は「特異点（シンギュラリティ）」という言葉を、有限の限界を超える値を表すものとしてこの言葉を用いた。 シンギュラリティ以降の世界では、人間と機械、物理的な現実と拡張現実（VR) との間には区別が存在しない。 生物の進化と人間のテクノロジーの進化は継続的に加速している。 ほとんどの人は未来を線形的に見ている。短期的に達成できることは必要以上に高く見積もるのに（細部の必要条件を見落とす）、長期的に達成されることを必要以上に低く見積もってしまう（指数関数的な成長に気づかない）。 将来的にはナノテクノロジーを用いてナノボットを設計することができる。これにより、加齢を逆行させることも可能になる。脳の毛細血管に数十億個のナノボットを送り込み、人間の知能を大幅に高めることができる。ナノボットは、過去の工業社会が引き起こした汚染を逆転させ、環境を改善する。フォグレットと呼ばれるナノボットは、モーフィング技術を使って作成した VR を現実世界に出現させる。 最後には、宇宙全体にわれわれの知能が飽和する。これが宇宙の運命なのだ。 五感すべてを組み込んだ完全没入型の VR 環境は、2020年代の終わりには実際に手に入ることになる。 スーパーコンピュータが人間の脳の性能に達し、2020年頃までにパソコンもそこに達する。▼著者のこの予想はさすがに外れそう。ちなみに、原書は13年以上も前の2005年に書かれています。 ムーアの法則をはじめとする個別のパラダイムは、最終的に、指数関数的成長がそれ以上不可能な水準に必ず到達する。ところが、コンピュータの伸びは、基盤となるパラダイムを次々と取り替え、当面のところ、現行の指数関数的成長が持続する。パラダイムシフトによって、あらゆる個別のパラダイムの S 字曲線は、次なる指数関数曲線へと変わっていく。 ナノコンピューティングによって強力な水準の知能が生まれるので、もしもピコやフェムトのコンピューティングが可能だとしたら、将来の知能がそのために必要なプロセスを見出してくれるだろう。 人間の脳は、超並列処理を用いて、微妙なパターンをすばやく認識する。だが、人間の思考速度は非常に遅い。基本的なニューロン処理は、現在の電子回路よりも、数百万倍も遅い。 人間のニューロンはすばらしい創造物だが、これと同じ遅い手法を用いてコンピューティング回路を設計したりはしない。自然淘汰を通じて進化してきた設計は確かに精巧だが、われわれの技術で作り出せるものよりも、何桁もの規模で能力が劣る。 人間のニューロンにある複雑さのほとんどは、情報処理ではなく、生命維持機能を支えるために使われている。 非生物的なコンピューティングを利用して、人間の知能を拡大し利用することで、われわれは最終的に知能のパワーを増大させることになる。よって、コンピューティングの最終的な限界について考えることは、実際には、われわれの文明はどういう運命をたどるのか、と問うているのと同じことなのだ。 シンギュラリティ─人間の能力が根底から覆り変容するとき─は、2045年に到来すると考えている。 デジタルのコンピューティングはアナログのコンピューティングと機能的に同等だということを、念頭に置いておかねばならない。つまり、デジタルとアナログが混じり合ったネットワークの機能のすべてを、デジタルだけのコンピュータで実行することができるのだ。この逆は真ではない。デジタルコンピュータの機能のすべてをアナログコンピュータでシミュレートすることはできない。 脳が従来のコンピュータと異なる重要な点がたくさんある。 脳の回路はとても遅い。 それでも脳は超並列処理ができる。 脳はアナログとデジタルの現象を併用する。脳のほとんどの昨日はアナログで、非線形性にあふれている（出力が突然切り替わる）。 脳は自身で配線し直す。 脳の細部のほとんどはランダムだ。 脳は創発的な特性を用いる。 脳は不完全である。 われわれは、矛盾している。 脳は進化を利用する。 パターンが大切だ。 脳はホログラフィ的だ。 脳は深く絡み合っている。 脳には、各領域をまとめるアーキテクチャがある。 脳の各領域の設計は、ニューロンの設計よりも単純だ。 われわれの思考プロセスは、われわれ自身を理解することが本質的に可能なのかどうか、と疑いをもつ者がたくさんいた。精神科医のピーター・D・クレイマーは「精神が、われわれに理解できるほど単純だとすれば、われわれはあまりにも単純すぎて、精神を理解することはかなわないことになる」と書いている。 人間の知能は、「自己理解」に必要とされる閾値より上なのか下なのか、というダグラス・ホフスタッターの疑問に答えて言うならば、脳のリバースエンジニアリングが加速度的に進展する中で、われわれが自分自身を理解する能力には限界などない。 バージョン 1.0 の虚弱な人体は、はるかに丈夫で有能なバージョン 2.0 へと変化するだろう。何十億ものナノボットが血流に乗って体内や脳内をかけめぐるようになる。体内で、それらは病原体を破壊し、DNA エラーを修復し、毒素を排除し、他にも健康増進につながる多くの仕事をやってのける。その結果、われわれは老化することなく永遠に生きられるようになるはずだ。 人体2.0: 2030年代の初頭、われわれはどうなっているだろう。心臓、肺、赤血球、白血球、血小板、膵臓、甲状腺他すべての内分泌器官、腎臓、膀胱、肝臓、食道下部、胃、小腸、大腸などはすでに取り除かれている。この時点で残っているのは、骨格、皮膚、生殖器、感覚器官、口と食道上部、そして脳だ。 人体3.0: 2030年代から2040年代。MNT（マイクロ・ナノテクノロジー）ベースの構造を体内に組み入れることによって、身体的特徴を好きなようにすぐ変えられるようになる。 「VR 環境デザイナー」という新しい職種が生まれ、新しい芸術の形となる。2020年までに、完全没入型の視聴覚ヴァーチャル環境の中で体をすばやく変化させられるようになるだろう。そして2020年代にはあらゆる感覚と結びついた完全没入型のVR環境の中で変身できるようになる。そして2040年代には現実世界でそれが可能になる。 人間の平均寿命は今後もどんどん伸びていく。 クロマニョン人: 18歳 古代エジプト: 25歳 1400年ヨーロッパ: 30歳 1800年ヨーロッパおよびアメリカ合衆国: 37歳 1900年アメリカ合衆国: 48歳 2002年アメリカ合衆国: 78歳 病気の50％を予防すれば: 150歳 病気の90％を予防すれば: 500歳 病気の99％を予防すれば: 1000歳 そもそも種とは生物学の概念であり、われわれがしようとしているのは、生物学を超越することなのだ。シンギュラリティの根底にある転換は、生物進化の歩みを一歩進めるだけのものではない。 未来の機械は、感情や精神を宿すことができるのだろうか？─もっとも説得力のあるシナリオは、人間そのものが徐々に、しかし確実に、生体から非生物的な存在へと変わっていくと言うものだ。 意識の実在を決定的に裏づける客観的な検証法は、ひとつとして存在しない。"
},
{
url: "/p/mebz3uq/",
title: "読書メモ『夢をかなえるゾウ』水野敬也",
date: "2018-07-01T00:00:00Z",
body: "読書メモ『夢をかなえるゾウ』水野敬也 夢をかなえるゾウ 水野敬也 飛鳥新社 ゾウの神様ガネーシャが夢をかなえるための課題を毎日ひとつずつ出してくれるお話です。 神様なのにパチンコでお金をなくしたり、涙もろかったり、なんだか親しみが湧いてきます。 頭の中で夢を想像しているだけでは駄目で、小さいことでもいいから実際に行動することでしか夢は叶えられない、体感することでしか自分を変えていくことはできない、というのがガネーシャの教えです。 ガネーシャが出した課題は以下の通り。 靴をみがく コンビニでお釣りを募金する 食事を腹八分におさえる 人が欲しがっているものを先取りする 会った人を笑わせる トイレ掃除をする まっすぐ帰宅する その日頑張れた自分をホメる 一日何かをやめてみる 決めたことを続けるための環境を作る 毎朝、全身鏡を見て身なりを整える 自分が一番得意なことを人に聞く 自分の苦手なことを人に聞く 夢を楽しく想像する 運が良いと口に出して言う ただでもらう 明日の準備をする 身近にいる一番大事な人を喜ばせる 誰か一人のいいところを見つけてホメる 人の長所を盗む 求人情報誌を見る お参りに行く 人気店に入り、人気の理由を観察する プレゼントをして驚かせる ガネーシャからの最後の課題: やらずに後悔していることを今日から始める サービスとして夢を語る 人の成功をサポートする 応募する 毎日、感謝する 成功したり、有名になったり、お金持ちになるためのガネーシャの理論は以下の通り。 お金は人を喜ばせることでもらうもの。 人は好きなことしかできない。 だとしたら、人を喜ばせることが何より楽しいと思えるように自分自身を変えていくしかない。"
},
{
url: "/p/2j4w6nn/",
title: "読書メモ『パターン指向リファクタリング入門』ジョシュア・ケリーエブスキー",
date: "2018-06-29T00:00:00Z",
body: "読書メモ『パターン指向リファクタリング入門』ジョシュア・ケリーエブスキー パターン指向リファクタリング入門 ジョシュア・ケリーエブスキー 日経BP社 マーチン・ファウラーの『リファクタリング』の続編のような本で、デザインパターンを活用しながら、どのようにソフトウェアの設計を改善しけばよいかを示しています。 パターンの知識を付けるだけでなく、パターンの賢い使い方を知ることをテーマとしています。 この本の特徴として、現実のコード、あるいは実際に使用したコードを元にしたコードが使用されている点が挙げられます。 実際のプロジェクトにはリファクタリングに関して多くの制約があり、それは作り物のコードでは体験できないものです。 以下は全11章のメモです。 第1章: 本書を執筆した理由 コードを必要以上に柔軟にしたり洗練させることは、作り込みすぎ (over-engineering) である。チームのプログラマたち（特に新しく参加した人たち）は、無意味に大きく複雑なコードベースを扱わなければならなくなる。作り込みすぎは生産性を低下させる。作り込みすぎな設計を引き継ぐ場合、拡張や保守を行うのに多大な時間がかかる。 とはいうものの、作り込み不足 (under-engineering) は作り込みすぎよりずっと多い。 TDD と継続的なリファクタリングのリズムを身に着けるには経験と時間が必要だが、この開発スタイルに慣れてしまえば、別の方法で実稼働するコードを作成することは奇妙で、不安で、プロフェッショナルらしくないと感じるようになる。 優れた設計を行いたいなら、設計そのものを調べるよりも、その設計がどのように進化してきたかを知らべる方が有益だ。真の知恵は進化の中に存在する。 第2章: リファクタリング コードが明確でない臭いの元は、リファクタリングで取り除くべきであって、コメントで脱臭するべきではない。そのようなコードをリファクタリングをするときは、そのコードをよく理解している人に立ち会ってもらうのが一番である。 実際にリファクタリングを促すものは感情だ。私はコーディングの不快感を少しでも減らすためだけにリファクタリングを行うことがよくある。 マーチンファウラーの言葉「コンパイラが理解できるコードは誰にでも書ける。すぐれたプログラマは、人間にとってわかりやすいコードを書く。」 小さい単純なステップに分けることで、大きなステップよりも間違いなく早く目標にたどり着くことができる。 アプリチームとフレームワークチームを1つのチームにしておけば、それらがちぐはぐになることがない。フレームワークはアプリのニーズにもとづいて作られるので、価値のあるフレームワークのコードだけが作成される。ただし、このプロセスには継続的なリファクタリングが必須である。それによって、フレームワークとアプリを分けておくことができる。 第3章: パターン パターン魔 (patterns happy) は、パターンに魅了され、コードでパターンを使わずにいられなくなった人。誰しもがパターンを学ぶ過程でパターン魔になる。リファクタリングによってパターンを徐々にシステムに組み込んでいくようにすれば、パターンによって作り込みすぎる可能性は低くなる。 残念なことに多くプログラマは、デザインパターン本に例示されている各パターンの構造の図が、そのパターンを実装する唯一の方法だと間違えて捉えている。『デザインパターン』の共著者の一人であるジョン・ブリシデスも、「実際のコードにはいろいろなニーズや制約があり、示されている構造の図とは大きく異なってくる」と述べている。例示されている構造をそのまま実装するのではなく、パターンの実装を必要最小限に抑えることは、進化的設計のプラクティスである。目的は設計をよりよくすることであって、パターンを実装することではないことを忘れないこと。 一般的には、パターンを実装することで、コードの重複を取り除き、ロジックを単純化し、意図を伝えやすくし、柔軟性を高めることができるはずである。しかし、パターンに慣れていない人がコードを読むと、わかりにくい、複雑すぎると感じることがある。このような意見の食い違いが発生した場合は、パターンの使用をやめるより、チームがパターンを学ぶ方がよい。 第4章: コードの臭い もっともよくある設計の問題は、次のようなコードが原因である。 重複している 不明確である 複雑である メソッドの適した行数はどのくらいであろうか？ほとんどのメソッドが1～5行のコードからできているものが適切だと私は考えている。小さなメソッドを連鎖させても、性能はほとんど低下しない。プロファイラを使えば明らかである。 第5章: パターンを取り入れるリファクタリングのカタログ この章では、この本の読み進め方が述べられています。 第6章: 生成 Creation Method によるコンストラクタの置き換え (Replace Constructors with Creation Methods) 問題: 1つのクラスに複数のコンストラクタがあると、開発時にどのコンストラクタを使うかの判断が難しくなる。 対策: コンストラクタの代わりに、意図がわかりやすい Creation Method を作成し、それがオブジェクトのインスタンスを返すようにする。 利点: どのような種類のインスタンスが返されるかがコンストラクトよりもよく伝わる。 引数の数と型が同じであるコンストラクタを2つ作成できないといった、コンストラクタの制限事項を回避できる。 使われていない生成コードを見つけるのが簡単になる。 欠点: 生成方法が標準に準拠しなくなる。new によってインスタンスを生成するクラスと「Creation Method」を使うクラスとが混在する。 Factory による生成処理の置き換え (Move Creation Knowledge to Factory) 問題: クラスのインスタンス化に使うデータやコードが数多くのクラスに散在している。 対策: 生成に関する知識を1つの Factory クラスに移動する。 利点: 生成ロジックとインスタンス化／設定のための情報をまとめられる。 クライアントを生成ロジックから切り離すことができる。 欠点: 直接のインスタンス化に比べて設計が複雑になる。 Factory によるクラス群の隠蔽 (Encapsulate Classes with Factory) 問題: 1つのパッケージ内に存在して共通のインタフェースを実装しているクラス群を、クライアントが直接インスタンス化している。 対策: クラスのコンストラクタをパブリックでなくし、クライアントには Factory 経由でインスタンスを生成させる。 利点: さまざまな種類のインスタンスの生成を、意図が明確なメソッド経由で行うことで、単純化できる。 公開する必要のないクラスが隠蔽されるため、パッケージの「概念的重み」(by Bloch) を減らすことができる。 「インタフェースに対してプログラミングするのであって、実装に対してプログラミングするのではない」（書籍『デザインパターン』より）という原理を厳しく適用できる。 欠点 新しい種類のインスタンスを生成しなければならない場合には、Creation Method の新規作成や変更が必要になる。 Factory のソースコードではなくバイナリコードにしかアクセスできない場合には、カスタマイズが制限される。 Factory Method によるポリモーフィックな生成の導入 (Introduce Polymorphic Creation with Factory Method) 問題: 階層内のクラスが、オブジェクトの生成ステップを除いて同じようにメソッドを実装している。 対策: そういったメソッドをスーパークラスで1つにまとめ、そこで Factory Method を呼び出してインスタンス化の処理を行う。 利点: オブジェクトを生成するステップが異なることが原因で生じている重複が減る。 どこで生成が行われているか、どのようにオーバーライドされているかが効果的に伝えられる。 Factory Method で使うためにクラスがどの型を実装しなければならないのかが明確になる。 欠点: Factory Method を実装するクラスに不必要な引数を渡さなければならないことがある。 Builder による Composite の隠蔽 (Encapsulate Composite with Builder) 問題: Composite の構築処理が何度も出現したり、複雑であったり、あるいはエラーを起こしやすいものになっている。 対策: 詳細部分を Builder に任せることで、構築を単純化する。 利点: Composite を構築するクライアントコードを単純化できる。 Compsoite の生成にまつわる繰り返しやエラーを軽減できる。 クライアントと Composite の間の結合度が低くなる。 カプセル化された Composite や複合オブジェクトを異なった形式で表現できる。 欠点: インタフェースの意図が伝わりにくくなる可能性がある。 Singleton のインライン化 問題: コードからあるオブジェクトにアクセスしなければならないが、グローバルなアクセス方法は必要でない。 対策: Singleton の機能を1つのクラスに移し、そのクラスにオブジェクトを格納してアクセス手段を提供する。Singleton は削除する。 利点: オブジェクトの協調関係がより見えやすく明示的になる。 唯一のインスタンスを保護するための特別なコードを必要としない。 欠点: いくつもの層を経由してオブジェクトインスタンスを渡すのが面倒だったり困難だったりする場合には、設計が複雑になる。 第7章: 単純化 メソッドの構造化 (Compose Method) 問題: メソッドのロジックをすぐに理解できない。 対策: 意図の伝わりやすい、詳細レベルが揃った小さなステップ群にロジックを変換する。 利点: メソッドが何をし、それをどのように行うかが効果的に伝わる。 詳細レベルが揃った、わかりやすい名前がついた振る舞いに分割することで、メソッドを単純化できる。 欠点: 小さなメソッドが増えすぎることがある。 多数の小さなメソッドにロジックが分散するため、デバッグが困難になることがある。 Strategy による条件判断の置き換え (Replace Conditional Logic with Strategy) 問題: いくつかの計算方法のうちどれを実行するかを、メソッド内の条件ロジックで制御している。 対策: 計算方法ごとに Strategy を作成し、元のメソッドは計算処理を Strategy のインスタンスに委譲する。 利点: 条件ロジックが減る、あるいは取り除かれるため、アルゴリズムが明白になる。 アルゴリズムのバリエーションをクラス階層に移すため、個々のクラスが単純になる。 実行時にアルゴリズムを別のものに置き換えることができる。 欠点: 継承による解決策や「条件記述の単純化」のリファクタリングを使った方が簡単な場合には、それよりも設計が複雑になる。 アルゴリズムがコンテキストクラスとデータをやり取りする方法が複雑になる。 Decorator による拡張機能の書き換え (Move Embellishment to Decorator) 問題: コードがクラスの核となる責務に対する拡張機能を提供している。 対策: 拡張機能を Decorator に移動する。 利点: 拡張機能が取り除かれるのでクラスを単純にできる。 クラスの核となる責務と拡張機能とを効果的に区別できる。 関連する複数のクラスに含まれる重複した拡張ロジックを取り除くことができる。 欠点: 装飾対象のオブジェクトと装飾後のオブジェクトは異なるものになってしまう。 コードを理解したりデバッグしたりするのが困難な場合がある。 Decorator を組み合わせた際、互いに悪影響を及ぼす場合には、設計が複雑になる。 State による状態変化のための条件判断の置き換え (Replace State-Altering Conditionals with State) 問題: オブジェクトの状態遷移を制御する条件式が複雑である。 対策: 条件式ではなく、個々の状態とその間の遷移を扱う State クラスを使う。 利点: 状態を変えるための条件ロジックがなくなる、あるいは減る。 状態を変える複雑なロジックが単純になる。 状態を変えるロジックを俯瞰することができる。 欠点: 状態遷移ロジックがもともとわかりやすい場合には、設計が複雑になるだけである。 Composite による暗黙的なツリー構造の置き換え (Replace Implicit Tree with Composite) 問題: String などの基本データ型の表現によって、暗黙的なツリー構造を作っている。 対策: 基本データ型の表現を Composite で置き換える。 利点: ノードの形成、追加、削除といった手順の繰り返しをカプセル化できる。 同じようなロジックの増殖に対処する汎用的な方法となる。 クライアントの構築作業が簡単になる。 欠点: 暗黙的なツリー構造を作成するほうが簡単な場合には、設計が複雑になるだけである。 Command による条件付きディスパッチャの置き換え (Replace Conditional Dispatcher with Command) 問題: 条件ロジックによってリクエストを振り分け、アクションを実行している。 対策: アクションごとに Command を作成する。Command をコレクションに格納し、条件ロジックを Command を取り出して実行するコードに置き換える。 利点: 一律に同じやり方で、さまざまな振る舞いを実行するためのシンプルなメカニズムである。 どのリクエストをどのように処理するかを実行時に変更できる。 実装するためのコードが少ししか必要でない。 欠点: 条件付きディスパッチャで用が足りる場合には、設計が複雑になるだけである。 第8章: 汎用化 Template Method の形成 (Form Template Method) 問題: 複数のサブクラスの2つのメソッドが、同じ順番で似たようなステップを実行しているが、それらのステップはまったく同じではない。 対策: 各ステップを同じシグニチャを持つメソッド群に抽出してメソッドを汎用化し、それから汎用メソッドを引き上げて Template Method を形成する。 利点: 不変な振る舞いをスーパークラスに移すことで、サブクラス間の重複したコードを取り除くことができる。 汎用のアルゴリズムのステップを簡潔にし、効果的に伝えることができる。 サブクラスで簡単にアルゴリズムをカスタマイズできるようになる。 欠点: アルゴリズムを肉付けするためにサブクラスで多くのメソッドを実装しなければならない場合には、設計が複雑になる。 Composite の抽出 (Extract Composite) 問題: 階層内のサブクラスが同じ Composite を実装している。 対策: Composite を実装するスーパークラスを抽出する。 利点: 子に関する格納と処理の両ロジックの重複をなくすことができる。 子を処理するロジックを継承することが効果的に伝わる。 欠点: 特になし。 Composite による単数・複数別の処理の置き換え (Replace One/Many Distinctions with Composite) 問題: あるクラスが、1つのオブジェクトの場合と複数のオブジェクトの場合とを別のコードで処理している。 対策: Composite を使って、1つのコードで、1つのオブジェクトの場合と複数オブジェクトの場合との両方を処理できるようにする。 利点: 単数または複数のオブジェクト処理に関するコードの重複を取り除く。 単数または複数のオブジェクトを統一したやり方で処理できる。 複数オブジェクトの処理機能が豊富になる（OR表現など）。 欠点: Composite の構築時にタイプセーフかどうかの実行時チェックが必要なことがある。 Observer によるハードコードされた通知の置き換え (Replace Hard-Coded Notifications with Observer) 問題: 別のクラスの1つのインスタンスに対する通知がサブクラスにハードコーディングされている。 対策: Observer インタフェースを実装した任意のクラスの任意の数のインスタンスにスーパークラスが通知を送れるようにし、サブクラスを削除する。 利点: 観察対象と観察者の間の結合度が低くなる。 観察者が単数の場合にも複数の場合にも対処できる。 欠点: ハードコーディングされた通知で用が足りる場合には、設計が複雑になる。 通知がカスケードしている場合には、設計が複雑になる。 観察対象から観察者が削除されないと、メモリリークが起きる可能性がある。 Adapter によるインタフェースの統合 (Unify Interfaces with Adapter) 問題: クライアントが2つのクラスと相互作用していて、その1つが好ましいインタフェースを持っている。 対策: Adapter によってインタフェースを統合する。 利点: クライアントコードが同じインタフェースを通じて複数のクラスとやり取りできるため、コードの重複をなくしたり減らしたりできる。 共通のインタフェースを通じてオブジェクトやり取りできるため、クライアントコードが簡潔になる。 クライアントが複数のクラスとやり取りする方法を統合できる。 欠点: アダプタを作らなくてもクラスのインタフェースを変更できる場合には、設計が複雑になるだけである。 Adapter の抽出 (Extract Adapter) 問題: 1つのクラスが、コンポーネント、ライブラリ、API、あるいは他のエンティティの複数バージョンに対するアダプタになっている。 対策: コンポーネント、ライブラリ、API、あるいは他のエンティティのバージョンごとに Adapter を1つ抽出する。 利点: コンポーネントやライブラリや API のバージョンごとの違いを切り分けることができる。 クラスの責務を1つのバージョンに対応することだけに限定できる。 頻繁なコードの変更が必要な部分を限定できる。 欠点: Adapter で提供されていない重要な振る舞いをクライアントが使えなくなることがある。 Interpreter による暗黙的な言語処理の置き換え (Replace Implicit Language with Interpreter) ある言語の文法に関して、実装する必要のあるクラスが10程度までなら、Interpreter パターンを使ってモデリングするのが有効かもしれない。 問題: 1つのクラスの数多くのメソッドが組み合わさって暗黙的な言語処理 (Implicit Language) の要素を表している。 対策: 暗黙的な言語処理の要素を表す複数のクラスを定義し、そのインスタンスを組み合わせて解釈可能な表現を形成する。 利点: 言語要素の組み合わせを、暗黙的な言語よりもうまくサポートできる。 言語要素の新しい組み合わせをサポートするのにコードを追加する必要がない。 振る舞いを実行時に設定できる。 欠点: 文法を定義し、それを使うようクライアントコードを変更するという初期コストが伴う。 言語が複雑な場合には膨大なプログラミング必要になる。 言語が単純な場合には設計が複雑になるだけである。 第9章: 保護 クラスによるタイプコードの置き換え (Replace Type Code with Class) 問題: フィールドの型（String や int など）によっては、安全でない値を代入できてしまったり、正しい等値比較ができなかったりする。 対策: そのフィールドの型をクラスにして、代入や等値比較を制約する。 利点: 無効な代入や比較に対する保護が向上する。 欠点: タイプセーフでない型を使う場合よりコードの量が増える。 このリファクタリングをするには、列挙型を使うほうが向いていると思うかもしれない。 クラスと列挙型の違いは、クラスには振る舞いを追加できるということ。 第7章の「State による状態変化のための条件判断の置き換え」の場合と同様に、一連のリファクタリングを適用する中で、クラスに振る舞いを付け足していく必要があるかもしれないので、列挙型ではなくクラスによってタイプコードを置き換えることに強みがある。 Singleton によるインスタンス化の制限 (Limit Instantiation with Singleton) 問題: コードがオブジェクトのインスタンスを複数生成しており、それによってメモリーの使いすぎやシステムの性能低下が発生している。 対策: 複数のインスタンスを Singleton で置き換える。 利点: 性能が改善される。 欠点: どこからでもアクセスしやすい。これは設計の問題を示していることが多い。第6章「Singleton のインライン化」を参照。 オブジェクトに共有できない状態が含まれている場合には有効でない。 ヌルオブジェクトの導入 (Introduce Null Object) 問題: ヌルのフィールドや変数を扱う同じロジックが、コードのあちこちにいくつも存在する。 対策: ヌルロジックを、何もないときの適切な振る舞いを提供するヌルオブジェクト (Null Object) に置き換える。 利点: ヌルロジックを何度も記述しなくてもヌルエラーを防止できる。 ヌルかどうかのチェックを最小限に抑えられるため、コードがシンプルになる。 欠点: ヌルかどうかのチェックがシステム内でほとんど必要でない場合には、設計が複雑になるだけである。 ヌルオブジェクトが実装されていることをプログラマが知らなければ、ヌルかどうかのチェックが重複して行われてしまう。 保守が複雑になる。スーパークラスを持つヌルオブジェクトは、新しく継承したパブリックメソッドをすべてオーバーライドしなければならない。 第10章: 累積処理 Collecting Parameter による累積処理の書き換え (Move Accumulation to Collecting Parameter) 問題: 1つの巨大なメソッドの中で、ローカル変数に情報を累積している。 対策: 抽出したメソッドに Collecting Parameter を渡して、そこに結果を累積する。 利点: 巨大なメソッドを、小さくシンプルで読みやすいメソッド群に変換できる。 欠点: できあがったコードの実行速度を上げることができる。 例えば、1つの StringBuilder をパラメータ (Collecting Parameter) としてメソッドに渡していき、1つの文字列を構築する。 巡回されるメソッドは、それぞれが Collecting Parameter に情報を提供する。 関連するメソッドすべての巡回が済んだ後、累積した情報を Collecting Parameter から取得することができる。 Visitor による累積処理の書き換え (Move Accumulation to Visitor) 問題: 1つのメソッドが種類の異なるクラス群から情報を累積している。 対策: 累積処理を Visitor に移動し、Visitor が各クラスを巡回して情報を累積する。 利点: 種類の異なる1つのオブジェクト構造に対して数多くのアルゴリズムを適用させることができる。 同じ階層のクラスでも異なる階層のクラスでも巡回することができる。 型キャストをしなくても、種類の異なるクラスの型固有のメソッドを呼び出すことができる。 欠点: 共通のインタフェースによって種類の異なるクラスを同じように扱える場合には、設計が複雑になる。 巡回対象のクラスを追加すると、新しい受け入れメソッドと、各 Visitor 上の新しい巡回メソッドが必要になる。 巡回対象クラスのカプセル化が破られることがある。 Visitor パターンの特徴はダブルディスパッチによって Visitor のメソッドが呼び出されるところ。 巡回対象の各要素をポリモーフィックにループで呼び出せるようにするため、各要素が Visitor を受け取る共通の accept メソッドを用意する（1つ目のディスパッチャ）。 そして、各 accept メソッドの中で、自分自身（要素）の型に合った Visitor のメソッド（例: visitHogeElement）を this をパラメータにして呼び出す（2つ目のディスパッチャ）。 Collecting Parameter パターン vs Visitor パターン Visitor の場合、巡回先のオブジェクト (visitor object) が Visitor インスタンスに自分自身を渡すのに対し、Collecting Paramter では、巡回先のオブジェクトは、ただ Collecting Paramter のメソッドを呼び出して情報を提供する。 大抵のコードは Collecting Paramter による累積処理の書き換えで十分であり、Visitor による累積処理の書き換えが必要になることはほとんどない。 作成する Visitor が巡回しなければならないクラスの集合が、今後も頻繁に増えるのであれば、一般には Visitor を使うのを避けたほうが賢明である。 種類の異なるオブジェクト（つまり、異なるインタフェースを持つオブジェクト）から多種多様な情報を集める場合には、Collecting Paramter よりも Visitor を使ったほうが、おそらくすっきりとした設計になる。 第11章: ユーティリティ （この章には大したことが書かれていないので省略）"
},
{
url: "/p/eb5nx4z/",
title: "C# で Microsoft Outlook の情報を取得する",
date: "2018-06-18T00:00:00Z",
body: "C# で Microsoft Outlook の情報を取得する 組織内で Outlook を使用している場合は、プログラムから Outlook の情報（Exchange サーバの情報）を取得してごにょごにょすると、日々の作業を効率化できるかもしれません。 ここでは、C# から Outlook の情報を取得する方法を紹介します。 プログラミング言語に C# を使っていますが、もともとは VBA などのインタフェース (COM) として使われていたものなので、本格的にコーディングするときは、VBA のリファレンスが参考になります。 Outlook VBA リファレンス｜MSDN 以下のサンプルは、Visual Studio Community 2017 を使って確認しています。 Visual Studio で新規のプロジェクト（ここではシンプルにコンソールアプリを選択）を作成したら、まずは次のようにして Outlook のインタフェースの参照を追加してください。 プロジェクト(P) → 参照の追加(R) COM → Microsoft Outlook 14.0 Object Library 次のコードは、現在 Outlook を使用しているユーザの名前とメールアドレス、および上司の名前とメールアドレスを表示します。 using System; using Outlook = Microsoft.Office.Interop.Outlook; namespace ConsoleApp1 { class Program { static Outlook.Application outlookApp = new Outlook.Application(); // Exchange ユーザの情報を表示する static void ShowRecipientInfo(Outlook.ExchangeUser user) { Console.WriteLine(user.Name); // 名前 Console.WriteLine(user.PrimarySmtpAddress); // メールアドレス } static void Main(string[] args) { // カレントユーザーの情報を表示 Outlook.Recipient rcp = outlookApp.Session.CurrentUser; Outlook.ExchangeUser currentUser = rcp.AddressEntry.GetExchangeUser(); ShowRecipientInfo(currentUser); // 上司の情報を表示 Outlook.ExchangeUser manager = currentUser.GetExchangeUserManager(); if (manager != null) { ShowRecipientInfo(manager); } } } } 実行結果 Yamada Taro yamada-taro@example.com Tokoro George tokoro-george@example.com 参考 Office - Dev Center - 操作方法 (Outlook リファレンス)"
},
{
url: "/p/uqk4oxg/",
title: "2018-06-13 森川亮さんの話",
date: "2018-06-13T00:00:00Z",
body: "2018-06-13 森川亮さんの話 元 LINE 社長の森川亮さんのお話を聞きました。 ちなみに名前は「りょう」ではなく「あきら」です。 雑誌のインタビュー記事も好きですけど、森川さんの話はやっぱり面白いですね。 口調もやさしい感じで好感が持てます。 内容よりもしゃべり方の方がって重要だなぁってこのごろ思います。 日本人は会議することが仕事だと思い込んでいる。他にすべきことがあるでしょう。 企業の中で出世しようと思い始めた時点でその人の成長は止まる。スティーブジョブズが出世しようと思ってあのようになりましたか？出世を考えなければ、自由に大きなことができるようになり、人として大きく伸びる。 （IT系の）企業の技術力に差はほとんどなくなってきている。新しいものを作ったとしても、すぐに真似されるのは当然。必要なのはスピードで、先にサービスを提供した企業はデータをたくさん集められる。それを利用して、次のサービスをまた素早く作る。それができるのが現代における強い会社だ。 などなど、働き方や企業のあり方に関していろいろためになるお話を聞けました。感謝です。 中でも、「出世を目標にし始めた時点で成長は止まる」 という意見はとても共感するものがありました。 自分がエンジニア寄りの人なのでバイアスかかってるかもしれませんが、出世競争みたいなのは過去の思い出みたいになるでしょうね。 リンダ・グラットンが 『ワークシフト』 の中でも述べているように、これからの人生100年時代は、自分の視野を広げつつも得意分野（職人的な力）を伸ばすことにフォーカスした方が幸せになれると思います。"
},
{
url: "/p/bdxmyrz/",
title: "2018-06-06 ボードゲーム部（ごきぶりポーカー、ナンジャモンジャ、フェレータ、ワードバスケット）",
date: "2018-06-06T00:00:00Z",
body: "2018-06-06 ボードゲーム部（ごきぶりポーカー、ナンジャモンジャ、フェレータ、ワードバスケット） 今日はボードゲーム部の日。 ごきぶりポーカー、ナンジャモンジャ、フェレータ、ワードバスケットをプレイ。 今日も楽しかった〜。 ごきぶりポーカー ごきぶりポーカー Drei Magier メビウスゲームズ ごきぶりポーカーは、ダウトの発展版のようなゲーム。 嘘をついたり、それを見破ったりしながら、同じ種類の虫を４枚揃えてしまうか、８種類の虫をすべて揃えてしまったら負け。 ルールは簡単だけど、追い詰められると不利になって逆転しにくくなってしまうのは、ちょっとゲームバランス悪いかなぁ。 何か独自のルールを加えてバランスよくして遊ぶのがよさそう。 ナンジャモンジャ ナンジャモンジャ・ミドリ すごろくや ナンジャモンジャは、順番に一枚ずつカードをめくって名前を付けるのを繰り返し、同じカードが出た時にその名前を先に言った方が勝ち、というこれもシンプルなゲーム。 この間、テレビでジャニーズ WEST がやってました。 あたりまえですけど、自分で命名したカードが出るとすごく有利で（思い出しやすい）、得点するのはほとんど自分のカードが出たときになっちゃいますね。 だから、運の要素が結構強い。 でも、勝負にこだわらず、ワイワイやって楽しむとすごく面白い！ フェレータ フェレータ ニューゲームズオーダー (New Games Order) フェレータは裏切りのゲームです。 バラと鷹のチームに分かれて、10ターン戦ってポイントをたくさん稼いだ人の勝ち。 毎ターン、バラと鷹のどちらか勝利した方がポイントを得るのだけど、自分が所属するチームはころころ変わります。 それは、「反逆者」という役があるから。 毎ターンのはじめに、役割カードを順番に選んでいくのですが、ここで「反逆者」を選んだ人は寝返って別のチームに移動します。 この役割を決めるフェーズが一番面白いところですね。 毎回「反逆者」を誰が取ったのか読み合うという。。。 逆に言うと、他の役割にあまり差はなくて（戦力に＋5できるとか）、このあたりにもう少し工夫があったら非常によいゲームになったんじゃないかと思います。 手札として配られるカードは単純に、戦力が書かれたカード。 バラと鷹の勝負はこの戦力の足し算で行うのですが、みんな共通の意見は、「足し算めんどくさ！」 ワードバスケット ワードバスケット (Word Basket) メビウスゲームズ しりとりゲーム。 場に出ているカードに書かれたひらがな一文字で始まって、手持ちのカードのひらがな一文字で終わる単語を考えてカードを場に出していくというすごいシンプルなゲームです。 ３文字以上の単語を考えればよいのですが、最後の１枚だけは４文字以上の単語で終わらなければいけません。 なかなか単語が思いつかない、そんな歯痒さを味わえるゲームです。 エッチな言葉ばっかり使ったらダメですよ〜。 なんか似たようなゲームを昔（30年くらい前）やったような気がするけど、思い出せない。。。 でもワードバスケット自体は 2002 年に考案されたみたいだから、ワードバスケットではないんですよね。 あ〜歯痒い。。。"
},
{
url: "/p/en9hm8g/",
title: "英辞郎の PDIC の高度な使い方",
date: "2018-06-04T00:00:00Z",
body: "英辞郎の PDIC の高度な使い方 「英辞郎 第十版」に付いている辞書ソフト PDIC-R (Personal Dictionary-R) の高度な使い方をメモメモ φ(・ｪ・o) これを使いこなすと、英辞郎がかなり便利になります。 熟語の検索 take over + Enter と入力すると、take \u0026hellip; over という英文を検索することができる（\u0026hellip; は任意の数の単語） take ~ over + Enter と入力すると、熟語としての take over の意味そのものを検索することができる。訳語部において、~ は任意の目的語を意味している。 AND/OR 検索（関連語検索） WORD 欄に複数の単語をスペースや | で繋げて入力し、Enter キーを押すことで、AND 検索、OR 検索を行うことができます（関連語検索と言います）。 単語A 単語B + Enter 見出し語の AND 検索を行う。 スペースは半角でも全角でもよい。 単語A|単語B + Enter 見出し語の OR 検索を行う。 ヘルプには | の前後にスペースがあってもよいとされているが、実際はスペースがあるとうまくいかないっぽい。 単語A -単語B + Enter 見出し語に単語Aを含むが、単語Bは含まないものを検索する。 例: dog|cat -my \u0026ndash; 見出し語に「dog」あるいは「cat」を含むが「my」は含まないものを検索する。 単語A +単語B + Enter 見出し語に単語Aが含まれ、かつ、訳に単語Bが含まれるものを検索する。 例: dog cat +やれやれ \u0026ndash; 見出し語に「dog」と「cat」が含まれ、さらに、訳に「やれやれ」が含まれるものを検索する。 | や - は見出し語に作用するのに対し、+ は訳に対して作用するのでかなり特殊ですね。 WORD 欄を使用した関連語検索では、単語の境界を意識した検索を行ってくれないことに注意してください（入力した文字列が、単語の一部にヒットするだけで結果に表示されてしまう）。 単語境界を意識した検索を行いたい場合は、メニューから「Search」→「全文検索」を実行します。 F2 キーや F3 キーでも全文検索を起動することができます（F2 は見出語の全文検索、F3 は訳の全文検索になる）。 キー操作 Alt+M でメニューバーの表示、非表示をトグルできる（上部の File、Edit などのメニューが配置されているバー）。 WORD 欄に入力した単語はインクリメンタルサーチされるので、Enter を押す必要はない。Enter を押すと関連語検索が始まってしまう。 入力を間違えた場合は、Back Space か、Delete で削除すると検索履歴に残らない。Esc で削除すると検索履歴に残る。"
},
{
url: "/p/xfgoaq3/",
title: "読書メモ『ダイアグラム別 UML 徹底活用』井上樹",
date: "2018-05-30T00:00:00Z",
body: "読書メモ『ダイアグラム別 UML 徹底活用』井上樹 ダイアグラム別UML徹底活用 第2版 井上 樹 翔泳社 （全13章） 1章: モデリングのメリットを考える モデリングの連続の末にプログラムというモデルの最終形態に辿り着くことが、システムを開発するということ。 図によるモデル化のメリット 情報量が多い 理解しやすい 誤解が少ない UML2.0 について ダイアグラムが10種類から13種類に増加（コンポジット図、相互作用概要図、タイミング図）し、次のようなことをモデル化できるようになった。 複数のインスタンスを内包するクラスの内部構造 複数のインタラクションの時系列上の流れ 複数のインスタンス間でのメッセージのやり取りと、それに伴う状態変化 ダイアグラム名称の一部変更 ステートチャート図 → ステートマシン図 コラボレーション図 → コミュニケーション図 「フレーム」が追加され、ダイアグラム全体を囲んだ入り、一部を囲んで説明を加えることができるようになった。ダイアグラムの一部をフレームとして囲んだところを畳み込めば、大きなダイアグラムでも全体を見渡しやすくなる。 2章: ユースケース図の注意点と使いどころ ユースケースは、**「こういうものを作るんだ」**ということを明らかにするために描く。 関連を結んだアクター＝ユースケースの起動者ではない。関連はあくまで関わり合いがあることだけを示す。 UML2.0 におけるユースケースの変更点は、extend の関係に対してノートで条件を書けるようになったこと。 役立つユースケースにするには 目的／読者を確認する 名前付けに注意する 抽象度: 「一般会員」や「レジ係」というように文章に出てくるくらいの抽象度がよい。 正確性: 対象を明示する（例: 貸出→ビデオを貸し出す、返却→ビデオの返却を受け付ける） 表現の統一: 同じ意味を示す言葉は揃える（例: 「貸し出す」と「レンタルする」） 粒度を揃える 機能分割にしない: 機能単位で描くと粒度が細かくなりすぎて、そのモデル化した対象がどんなサービスを提供しているのかわからなくなってしまう。サービスで分割することを意識する。 ≪include≫は1段階まで: 2段階以上にするとアクターにとって意味のある粒度のユースケースになりにくい。 ≪include≫、≪extend≫、汎化関係を混同しない ≪include≫: ≪include≫先のユースケースは必ず必要になることを意味する。プログラムの関数呼び出しのような感じで、複数のユースケースから共有できる（例: ビデオを借りる─include→会員かどうかを確認する）。 ≪extend≫: ≪extend≫でベースになっているユースケースにサービスを付加した場合は、ベースとなるユースケースの実行には≪extend≫で定義したユースケースは必ずしも必要ない（例: ビデオを借りる←extend─カードで料金を払う）。逆に、≪extend≫で定義されたユースケースを実行するには、必ずベースのユースケースが必要になる。 汎化関係: 汎化関係は機能を追加するのではなく、概念だけ共通だがまったく新しいユースケースを定義する（例: ビデオを借りる←汎化─ビデオを宅配で借りる）。 ユースケース記述と合わせる: ユースケース図だけでは誤解を招きやすいので、ユースケース図を描いたら、ユースケース記述も合わせて作成する。ユースケース図とユースケース記述を合わせて**「ユースケースモデル」**と呼んだりする。 3章: ユースケース記述の注意点と使いどころ ユースケース記述の概要 ユースケース記述はシステム開発の初期にユースケース図と一緒に作られ、システム外部から（利用者から）見たときの振る舞いを明確にする。 特に担当者を入れ替えながら開発が進んでいくプロジェクトなどでは、開発者間でシステムイメージを共有できるということは重要。 ユースケース記述は書くのに非常に手間のかかる成果物だが、システム開発に一貫したゴールを与えることができるのは大きなメリット。ユースケースのレベルで再利用できるようになると、より楽をできるようになる。 ユースケース駆動開発 ユースケースは進捗を計るベースとして使用できる。ユースケースを一単位とすると、代替フローや例外フローが含まれているため、作業単位の粒度としては大きくなりすぎることがある。そのような場合、ユースケース記述に書かれた**「シナリオ」を作業単位とする**とよい。 ユースケース駆動開発では、ユースケースのシナリオごとに、(1)分析、(2)設計、(3)実装、(4)テストという作業を進めていく。ユースケースを実現できたかどうか（それぞれのステップが完了したかどうか）のポイントは下記の通り。 分析: 分析のクラス図に書かれているクラス群を使って、ユースケース記述に書かれたシナリオを実現する相互作用図（シーケンス図、コレボレーション図）を作ることができる 設計: 設計のクラス図に書かれているクラス群を使って、ユースケース記述に書かれたシナリオを実現する相互作用図（シーケンス図、コラボレーション図）を作ることができる 実装: シナリオを実現するためのプログラムが書けている テスト: シナリオに書いてある通りにシステムが動いている ユースケース記述のテストへの活用 ユースケース記述に書かれた振る舞いは、要求元と合意されたものとなるので、テストケースの元ネタとして使うことができる。 テストケースとシナリオは対応するものなので、テストを意識してシナリオリストを作成すると、テストケースの作成が容易になる。イベントフロー（メインフロー＋代替フロー＋例外フロー）の組み合わせを網羅する形でシナリオリストを作るのがコツ。 イベントフローは３種類 メインフロー: 正常に処理が進んだ場合。 代替フロー: 正常系の代わり（エラーが発生した場合など）。代替フローを実行した場合でも事後条件は満たされる。 例外フロー: ユースケースの実行を断念しなければならないような場合。例外フローを実行した場合は事後条件は満たされない。 ユースケース記述のポイント 厳密に漏れなく書く 曖昧性のない厳密な記述がされており、システムの振る舞いが具体的に理解できること。 ユースケース記述の作成と合わせて用語集を作成するとよい。 イベントフローの書き出しは「アクターは～」、「システムは～」と動作の主語を必ず書く。 システムで実現すべきことはすべてユースケースに書かれているようにする 仕様変更が発生した場合など、ユースケース記述はこまめにメンテナンスする。 細かくしすぎない エンドユーザにもわかるレベルで記述する（エンドユーザーと開発者が共有するものなので）。ユーザマニュアルのようなレベルを想定するとちょうどよい。 データベースのテーブルや、画面レイアウト、画面遷移を意識する記述が出てきたら危険。 イベントフローに「システムは～する」という記述が連続して 4 ～ 5 ステップ続いたら詳細になりすぎている可能性が高い。 危険なワード: DB、テーブル、クエリ、キー、ID、コネクション、チャネル、セッション、トランザクション、ロック、ボタン、クリック、入力欄、インタフェース 補足資料を使う 文章だけで記述するのではなく、アクティビティ図や、スケッチ、表なども併用すればよい。 空欄を作らない ユースケース記述のフォーマットには項目がたくさんあるが、空白状態で放置しない。「T.B.D.」なのか「なし」なのかを明確に記述。T.B.D. であれば、期日と担当者を併記するとよい。 書き続けない システムを動かしてから見えてくる部分は少なからずある。決まっていない部分は T.B.D. として先の作業に進むことも必要。 無理にユースケース記述で書かない ユースケース記述に向いているのは、ユーザーとシステムのやりとりがあるインタラクティブシステム。 ユースケース記述に向いていないのは、フィードバック系のシステム（エアコンなど）や、複雑なアルゴリズムや計算式の記述。 4章: クラス図～基本編 クラス図はいろいろな場面で使用される。開発者は一般的に設計モデルを作成するのは得意だが、分析モデルを作成するのが苦手な傾向がある。 概念図: 問題領域にどのような概念が存在し、どのような構成になっているかを記述する。概念は用語集で定義されるが、それぞれのつながりを表すのが概念図としてのクラス図。開発の初期段階で作成する。 分析モデル: システム要求を満たすには何が必要かを表現する。分析モデルはあくまで意味レベルのモデルなので、設計モデルとは違い、実現方法そのものは記述しない。システムの要件定義（ユースケースモデルの作成、日機能要求のリスト化）が終わった後に作成する。 設計モデル: システムの作り方を表現する。実装レベルのクラス図。 中央集権モデルになってしまわないようにモデリングできるとよい。 関連はただ線を引くだけではなく、その関連の意味が分かるように「多重度」と「ロール名」を付ける。「ロール名」が思いつかない場合は、「関連名」を付けるとよい。 クラス図は、左から右、上から下へ自然に読んでいくことができるのが望ましい。 ユーザインタフェース、I/O、デバイスなどを表すクラスは端に配置するとよい。 5章: クラス図～応用編 実現関係 UML2.0 では、あるクラスの実現に必要なインタフェースを、Y字型のアイコンを使って明示できるようになった（インタフェースの要求）。 RentalBusiness -------( o------- CounterRentalProcess RentalProcess 上記の図では、RentalBusiness は RentalProcess インタフェースを必要としており、RentalProcess インタフェースを実現した CounterRentalProcess を参照することを示す。 実現関係（インタフェースとその実装）は、実装の方法を意識した関係になるため、分析レベルのクラス図には登場しない。 依存関係と関連 関連がクラスの属性と同じ扱いなのに対し、依存関係はある操作の中だけといった一時的な利用関係を表す。 関連クラス 関連クラスの使い方を覚えておくと、分析としてのクラス図の表現力がぐっと上がる。 ただし、関連クラスは設計のクラス図には使えないことに注意。 なぜなら、関連クラスをそのまま実装できるプログラミング言語が存在しないから。 関連クラスは、設計段階では３つのクラスの関係に置き換えればよい。 ステレオタイプ ステレオタイプはギルメット（≪≫）で囲まれた文字列で、ステレオタイプはクラス名だけではなく、すべてのモデリング要素に複数付与することができる。 ステレオタイプは UML であらかじめ数種類用意されているが、ユーザーが自由に定義してよいことになっている。 ステレオタイプはあくまで理解を助けるためのものであって、あまり多くの観点のステレオタイプを作成するのはおすすめしない。クラスを色分けするなどして、1つのクラスに付けるステレオタイプは多くても2つまで、できれば1つにすると良いモデルになる。 ステレオタイプを活用したクラスの役割整理 クラス図を作成したら、以下のようなステレオタイプを使ってクラスの責務や関連を整理するとよい。 ステレオタイプ 役割 例 ≪boundary≫ システムとその外側をつなぐインタフェース。UI やデータ入力に関わるクラス。デバイス制御を行うクラスなど。(プレゼンテーション層) 貸出画面Servlet、レシートプリンタ ≪control≫ まとまった処理手順を司る。業務フローやデータフロー、画面遷移に関わるクラスなど。 貸出処理クラス ≪entity≫ 情報を表す。データ自身の基礎的な処理や、保持を行うクラスが該当する。(ドメイン層) 会員クラス、貸出クラス すべてのクラスに上記のステレオタイプを付けていく。複数に該当するものは複数付ける。 ステレオタイプが2つ以上付いているクラスを分割する（責務を1種類にする）。 次のようなルールに従って依存を整理する。 ▽これだと ≪boundary≫ が ≪entity≫ の情報を表示できないかのように見えるけど、≪control≫ を介して取得した情報を表示するのは OK なので念のため。 ▽ちなみに、ロバストネス分析という分析手法では以下のようなシンボルを使用するが、考え方は同じ。 6章: オブジェクト図 オブジェクト図の概要 オブジェクト図はオブジェクト（インスタンス）を対象とした図で、モデリング対象のある一瞬だけを捉えた図。どの一瞬を表した図なのか、ノートとして残しておくとよい。 クラスに対するインスタンスと同様に、1つのクラス図からはオブジェクト図をいくつでも作ることができる。 オブジェクト図はクラス図ほど描かれることはないが、オブジェクト図は描いてみると役に立つことが分かる。オブジェクト図をきちんと描けるかどうかによって、その人がオブジェクト指向をどれだけ理解しているかが分かる。 UML1.x ではオブジェクト図はクラス図の一部分とされていたが、UML2.0 からは正式なダイアログとして定義された。 オブジェクト図の使いどころ システム化対象からオブジェクトやクラスを発見するために作成する。 システムをオブジェクトの集合としてとらえた場合に、どのようになるかをモデル化する。 システム要件からいきなりクラス図を作成するのは難易度が高い。なぜなら、「概念群」を直接導き出す抽象化力が必要だから。システム要件からは、まずは実体をベースとするオブジェクト図を作成し、そこからクラスを導き出してクラス図を作成する方が容易。 クラス図が作成者の考えている通りのオブジェクトの構造を表せるか確認する。 これはクラス図を描いてからオブジェクト図を描くケース。クラス図のレイアウトに近い形でオブジェクト図を描くと分かりやすくなる。 オブジェクト図を2つ使い、システム内の変化を表現する。 ユースケースの事前条件と事後条件に相当する部分をそれぞれオブジェクト図で表現することで、システム内部にどのような変化が起きたのかを分かりやすくする。 7章: 相互作用図～シーケンス図とコラボレーション図（UML2.0ではコミュニケーション図） UML2.0 ではコラボレーション図は、コミュニケーション図と呼ぶ。 実現すべきシナリオ（ユースケース記述）から、相互作用図（シーケンス図 or コミュニケーション図）を作成すると、必要なオブジェクトを抽出することができる。このような相互作用図先行の開発では、相互作用図としてシーケンス図ではなくコミュニケーション図を使うと、クラス図との対応を取りやすい。 シーケンス図とコミュニケーション図の比較 コミュニケーション図: オブジェクト図と似ているので、オブジェクト構造との対応付けがしやすい。ただし、メッセージの順序が分かりにくい。 シーケンス図: オブジェクト構造は見えにくいが、メッセージの順序がわかりやすい。 シーケンス番号を「通し番号表記」ではなく、「階層化番号表記」で書くと、メッセージのネスト構造がわかりやすくなるため、RAM使用量や実行速度のチューニングの際に役に立つ。 メッセージのメッセージ名の前には、ガード条件を記述することができる（例: [会員検索結果 != null] 借主登録） シーケンス図では、メッセージの終了を表すリターン（\u0026lt;---- という破線矢印）が描かれることがある。必ずしも表記する必要はなく、戻り値があることを明示したいときに用いればよい。リターンは必ず活性区間の最後の部分から引かれる。 活性区間（白抜きの矩形）は「制御フォーカス」とも呼ばれ、オブジェクトが活動していることを表す。同じクラス内のメソッドを同期呼び出しする場合は、活性区間が重なっているように描く。オブジェクトの生存期間を表す「ライフライン」と間違えやすいので注意。 相互作用図を作るときは、オブジェクトにちゃんと名前を付ける癖をつけるとよい（オブジェクト名：クラス名）。オブジェクト名は、ロール名や戻り値をもとに命名すると分かりやすくなる。 メッセージには引数も記述しておくと、データの流れが分かりやすくなる。 シーケンス図の UML2.0 での変化点 UML2.0 のシーケンス図にはいろいろと変更が入り、コミュニケーション図よりも表現力が向上している。シーケンス図で凝った記述を行うと、コミュニケーション図との相互変換はできなくなるのでその点は注意。 UML2.0 のシーケンス図では、UML1.5のオブジェクトとライフラインをまとめてライフラインと呼ぶ。オブジェクトの名前の下に下線は引かない。 オブジェクトの生成と消滅の線は破線矢印を使う。 **コリージョン (coregion)**の表記を使うことで、「サーバーから複数の応答メッセージを待つ」、といった表現が可能になった。 **汎用順序付け (general ordering)**の表記を使うことで、２つの非同期メッセージの順序を明確にすることができる。▼ただ、これが使われてるシーケンス図は見たことがない (^^; フレームを使ってインタラクションの制御構造を表現できるようになった。▽たくさんあるけど、よく使われるのは以下くらいかな？ alt (Alternatives): 条件による選択実行。 opt (Option): 条件が満たされたときのみ実行。 par (Parallel): 並列実行。 loop (Loop): 反復処理。 フレームの左端から矢印を引くことができるため（ゲートと呼ぶ）、システム外部からの呼び出し（シーケンスの起点）を表現しやすくなった。UML1.5 までは、仮のアクターを左端に置いて表現していた。 8章: アクティビティ図 アクティビティ図も相互作用図（シーケンス図、コミュニケーション図）と同様に振る舞いを表す図だが、ソフトウェアの開発に限らず、様々な場面で利用できるので使いこなせると便利。アクティビティ図は下記のような場面で使用できる。 業務フローのモデル化: ビジネスモデリングでは、アクティビティ図を使って業務手順をモデル化できる。スイムレーンの使い方がポイントで、社内の組織を割り当てることで役割分担が明らかになる。 ユースケース記述の補足: イベントフローは通常箇条書きで書かれるが、代替フローや例外フローがたくさんあったり、繰り返し、並行処理がある場合は、アクティビティ図を添付すると分かりやすくなる。アクターとシステムのスイムレーンを用意すると、アクティビティをよりイベントフローの記述と対応させやすくなる。 ロジックのモデル化: オブジェクトの構成に捉われずに処理の流れを記述したい場合や、複数のシナリオを含んだモデルを描きたい場合にアクティビティ図を使用できる（従来のフローチャートと同じ）。完成したアクティビティ図にオブジェクトの視点を追加したければ、個々のオブジェクトに対してスイムレーンを割り当てればよい。 スイムレーン (Activity Partition)はアクティビティの実行者を表す。スイムレーンには、「組織名」、「役割名」、「サブシステム名」、「オブジェクト名」といったものを入れることが多い。UML2.0 では、スイムレーンは入れ子で描くことができる。 分岐の描き方はフローチャートと異なり、分岐マーク（◇）の中には何も記述しない。分岐マークを省略して、アクティビティから直接2本線を出し、2つのアクティビティに繋げるように描いてよい。 アクティビティは、１つの処理や業務の作業を表すが、アクティビティ名は達成すべきこと（目的）をベースに命名するのがよい。実際にやることをベースに記述してしまうと、モデルを頻繁に書き換えることになる。特にビジネスモデリングでアクティビティ図を作成するときは、アクティビティ名の付け方で、そのモデルが長い期間使えるかどうかが決ってくる。 よい例: 「会員を特定」→「貸出対象を特定」→「貸出期間を決定」 悪い例: 「会員カードの読取」→「DVDのバーコードの読取」→「何泊か入力」 アクティビティ図を描く手が止まってしまったら、後ろから描いていくという方法を試してみるとよい。何を達成したいのかは分かっているので、終了状態から描いていくと自然とできあがっていく。 開始点は Initial Node （黒丸●）の 1 種類だけだが、UML2.0 ではタイムイベントという記号（▽と△を組み合わせた記号）が追加されており、時間に依存したイベントを表現できる（例: 「毎月25日」）。 終了点はフロー終了点 (Flow final node) と、アクティビティ終了点 (Activity final node) の2種類がある。 フロー終了点 (Flow final node): そこに流れてきたフローだけ止める。例えば、並行処理の一つだけを終了するときに使用する（アクティビティ図全体は終了しない）。記号は、白丸の中に× ($\\bigotimes$)。 アクティビティ終了点 (Activity final node): アクティビティ図全体の処理を終了するときに使用する。記号は、白丸の中に黒丸 (◉)。 9章: ステートチャート図（UML2.0ではステートマシン図） ステートマシン図には、ライフサイクル全体を扱える、振る舞いの網羅性が高い、といった特徴がある。 UML2.0 には振る舞いを表す図として相互作用図（シーケンス図とコミュニケーション図）もあるが、それらは特定のシナリオに沿った振る舞いを表現するためのもので、ライフサイクル全体を表現することができない。 ユースケース図だけでは、どのユースケースがどのタイミングで実行できるようになるのかが分からない。ステートマシン図でシステムの取り得る状態を明らかにし、各状態でどのユースケースが実行されるのかを描くことで、システム全体のライフサイクルとユースケースの関係を明らかにすることができる。 特にイベントの種類が多く、平行動作の多い組み込み系システムではステートマシン図は必須。 状態遷移（矢印）では、次のような定義を行うことができる。 　イベント(引数リスト)[ガード条件]／アクション ────────────────────────＞ イベント: この状態遷移を発生させるイベント。 引数リスト: イベントの発生に伴って渡される引数。複数定義可能。 ガード条件: この条件が成立しているときのみ遷移が発生する。 アクション: この状態遷移に伴って実行されるアクション。 上記の定義はすべて省略可能で、「イベント」の定義が省略された場合は、「無条件遷移」あるいは「ラムダ遷移」と呼ばれ、遷移元の状態の entry アクションの実行が終わり次第、自動的に遷移先の状態に遷移することを表す。 10章: コンポーネント図と配置図 概要 コンポーネント図と配置図は、主に物理的なものをモデリングするために使用する（論理的なものも表現可能）。 多くの UML 解説書では、なぜかコンポーネント図と配置図の説明だけおざなりにされているが、実装担当者／ビルド担当者／運用担当者にとっては役に立つ場面が多いので使ってみるとよい。 コンポーネントとは、「交換可能なシステムの構成部品で、実装を内部に含み、外部にインタフェースを公開しているもの」（UML1.5の定義）。コンポーネント図では、そのようなコンポーネントの間の関係を示す。 配置図は、システムを構成するハードウェア構成とその上でどのようなソフトウェアが動作しているかを表す。 使いどころ コンポーネント図と、配置図は、システムアーキテクチャを検討する際に役に立つ。 コンポーネント図では、コンポーネント＝ファイルとしてダイアグラムを描けるので、ファイルの依存関係を表現するために使用できる。 コンポーネント図を描くと、システムを構成するコンポーネントの依存関係が明らかになるので、システムを運用環境にセットアップする際のインストール順序を示すためにも使用できる。 分散システムやデバイス制御を伴うシステムにおいて、システム内でハードウェアをどのような接続するかの検討に使用できる。 パッケージ図と混同しない Java のパッケージ構成などを示すことができるパッケージ図は、コンポーンネント図と混同されがち。 パッケージはあくまでフォルダのようなものであり、ソフトウェア部品にはなり得ないという点でコンポーネント図とは異なる。 混乱してきたら、「メッセージが送れるもの＝コンポーネント」、「メッセージが送れないもの＝パッケージ」と考えるとよい。 11章: ダイアグラム間の整合性 ダイアグラム間の整合性は、既存のダイアグラムを参照しながら作っていく、あるいは別のダイアグラムを作ることで分かったことを既存のダイアグラムにフィードバックするという方法で保つ。 下記のようなダイアグラム間の整合性をチェックする。 クラス図とオブジェクト図 クラス図と相互作用図（シーケンス図やコミュニケーション図） クラス図とステートマシン図 12章: UMLとプロセス 開発プロセスと管理プロセス プロセスには次の2つがあり、どちらかをおろそかにしてはいけない。 開発プロセス: ソフトウェアの開発作業に関するプロセス。「分析→設計→実装→テスト」といったもの。 管理プロセス: プロジェクトを正しく進めるためのプロセス。プロジェクト計画、要求管理、障害管理、構成管理、品質管理、リスク管理など。 管理プロセスに関しては、PMBOK や CMM を参照するのがよい。 UML を使ったプロセス UML は特に、(1)要求定義、(2)分析、(3)設計という工程の中で使用される。 各工程の中で、複数のダイアグラムを組み合わせて対象の特定の側面を表現していく。 このダイアグラムの組み合わせをビューという。 プロセスを定義するときは、各工程でどのようなビューを作成するのか、その目的は何か？どのように妥当性をチェックするのか？などを定義する。 下記は、各工程の中でどのように UML を利用してビューを構築していくかのプロセス定義の例。 1. 要求定義 要件定義の工程では、システムとして何を実現すべきかを明確にする。 手順 要求リストの作成: 利害関係者から聞き出したシステムに対する要望から実現すべきことを要求リスト（機能要求と非機能要求）にまとめる。 ユースケース図の作成: 要求リストのうち機能要求に相当するものをユースケース図としてモデル化する。 ユースケース記述の作成: ユースケース図のそれぞれのユースケースに関して、ユースケース記述を作成する。イベントフローが複雑になるのであれば、アクティビティ図も作成する。 成果物 要件ビュー（ユースケース図＋ユースケース記述＋アクティビティ図） 2. 分析 分析の工程では、要件定義で定めたシステム化対象範囲を、オブジェクト指向で見たときにどのようなオブジェクトがあれば実現できるかを検討する。 分析の段階では、非機能要求は作業の対象としないことに注意。 使用する言語やデータベースなどの制約に捉われず、機能要求を満たすために何が必要なのかだけを考える。 手順 クラス図の作成: 要件ビューの情報を基にクラス図を作成する。 相互作用図の作成: ユースケースのシナリオに基いた相互作用図（シーケンス図、コミュニケーション図）を作成し、クラス図がユースケースを満たしているかを確認する。 オブジェクト図の作成: クラス構造が複雑な場合は、オブジェクト図を作成し、クラス図、相互作用図との整合性を確認する。 ステートマシン図の作成: システム全体の状態遷移をモデル化し、アクションとしてユースケースをマッピングし、すべてのユースケースがマッピングされるかを確認する。 成果物 分析ビュー（クラス図、オブジェクト図、相互作用図、ステートマシン図） 3. 設計 設計の工程では、非機能要求（環境制約や性能）を満たしながら具体的にどのように実現していくかを検討する。この工程ではすべてのダイアグラムを利用する。 インプットとしては、これまでの工程で作成した下記のものを使用する。 非機能要求リスト 要件ビュー（ユースケース図＋ユースケース記述＋アクティビティ図） 分析ビュー（クラス図、オブジェクト図、相互作用図、ステートマシン図） 設計には明確な手順は存在しないが、システム全体を視野に入れた設計の方向性を示すアーキテクチャ設計を最初のステップとして実施することがある。 設計の工程で作成されたダイアグラム群を設計ビューといい、すべての非機能要求を満たすことができた時点で設計は完了となる。 これらのダイアグラム群に関しても、要件ビューで定義したユースケースを満たしているかを確認する。 最低限のプロセスでは、、、 ミニマムなプロセス定義をするのであれば、ユースケース図、クラス図、シーケンス図あたりを必須にしておくとよい。"
},
{
url: "/p/de7i2di/",
title: "2018-05-27 日本ダービーに初めて行ってみた",
date: "2018-05-27T00:00:00Z",
body: "2018-05-27 日本ダービーに初めて行ってみた 今日は競馬ファンが熱狂する日本ダービー（東京優駿）の日。 競馬自体やったことないんですけど、日本ダービーは一度行ってみたかったので、電車乗り継いで府中の東京競馬場に行ってみました。 府中本町駅から専用の通路ができているので迷うことなく到着です。 なんかディズニーランドにいくような感覚に近い。 ダービーは3時過ぎからの第10レースなのですが、到着したお昼には人でいっぱいでした（来場者は11万8千人でした）。 ファミリーで来ている人たちも多いという噂でしたが、やっぱり競馬がメインなので子供連れは少ないですね。 馬券買うのは基本的に室内ですが、その周りも人だらけ。 場所取りが激しいです。 なんなのコレ。 パドックはお馬さん近くで見れて楽しいですね。 これだけでも来てよかった（＾o＾） 「場内」と呼ばれる、コースの中央のエリアにも入ることができます。 このエリアには子供の遊具とか、売店とかいろいろ出てます。 ここは比較的空いていて、レースを見ることもできるのですが、かなり遠い。。。 しかも中継モニタを見ることもできません（写真右端に写ってるやつの裏側がスクリーンになっている）。 双眼鏡を持って来ているおじさんがいたんですが、理由がわかりました。 しょうがないので第10レースのダービーは、通常の観戦エリアに戻って観戦しました。 ものすごい人で、遠くから見ないといけませんでしたが、すごい歓声で、迫力ありました。 ちなみに、戦績はというと、単勝が当たりました！ 100円しか買ってないけど。"
},
{
url: "/p/4ppftm9/",
title: "VR（バーチャルリアリティ）系の製品アイデア",
date: "2018-05-12T00:00:00Z",
body: "VR（バーチャルリアリティ）系の製品アイデア 超リアルペット。自分が画面の前に行ってバーチャルな猫を見るのではなく、バーチャルな猫の方が自分のいるところについてくる。 部屋全体がストリートビュー。Google のストリートビューは、通常は平面なディスプレイ上で使うが、部屋の中を360度ディスプレイにしてしまえば、本当にその場所にいるかのような空間を作り出せる。"
},
{
url: "/p/54fbqm3/",
title: "ガジェット系の製品アイデア",
date: "2018-05-12T00:00:00Z",
body: "ガジェット系の製品アイデア 首かけ型の万能ガジェット 一日中付けておくことを想定。目指すのはスマホの置き換え。スマホを持ち歩くのは面倒だし、置き忘れたりする。 暑い日には霧噴射したり、風出したりして涼しくしてくれる。 プロジェクタ機能が付いていて、手のひらなどに情報投影できる。でこぼこなところに映しても自動補正してきれいに見える。スマホの画面のようにタッチ操作可能。 テレビなどの家電のリモコンになる。自分の目線の方向を認識し、テレビを見てるならテレビのリモコンをテーブルに投影。 高精度にジェスチャ認識。テレビのリモコンの代わり、端末自体の操作などに使用可能。 音声認識で操作が可能。常にマイクが近くにあるので、いつでも使える。 音楽再生、電話ができる。音声は自分にしか聞こえない。 体調管理もしてくれる。 危険を教えてくれる。 電気自動車は静かなので近づいていることに気付かない。自分の方に向かってくる車があったら警告してくれる（ITS連携）。"
},
{
url: "/p/jbi6jqp/",
title: "ドローンを使ったアイデア",
date: "2018-05-12T00:00:00Z",
body: "ドローンを使ったアイデア ドローンにプロジェクタをつけて地面に投影する。 草原や農場などをステージに 高層ビルなど側面に空中から投影 ドローンにスピーカーをつけて、ステージ後方の空中からの迫力サウンドを提供。 ドローンに映写用の幕などを広げさせる、そこにプロジェクションマッピング。 ドローンから霧噴射して、そこにプロジェクションマッピング。 ドローンからスプレー噴射で絵を描けるようにして、巨大な壁面アートを自動で作成。 炎天下の日に、ドローンから霧噴射して街の温度を下げる。 ドローンで社内便。何か送りたいときは、ドローンの方から席まで取りに来てくれる。 ドローンでペットの散歩。 車や重機などの工業用塗装。AIで形状把握、塗装、コーティングまで自動化。"
},
{
url: "/p/3nx9is3/",
title: "ランダム ID 生成ツール",
date: "2018-04-21T00:00:00Z",
body: "ランダム ID 生成ツール 文字数: 文字候補: 再生成 function generate() { // 最大桁数を 100 文字までに制限 const $digitsElem = document.getElementById('digits'); const digits = Math.min(100, $digitsElem.value); $digitsElem.value = digits; // ランダム文字列を生成 const candidate = document.getElementById('candidate').value; let result = ''; for (let i = 0; i 指定した文字数のランダムな ID を生成します。 数字の 1（いち）とアルファベット小文字の l（エル）、数字の 0（ぜろ）とアルファベット大文字の O（オー）は区別しにくいので、デフォルトでは含めないようにしています。 このような UX 上の工夫は、さまざまな標準プロトコルで推奨されています。 例えば、下記は RFC 8628 におけるユーザーコード表示の例です。 参考: RFC 8628 - OAuth 2.0 Device Authorization Grant の例 It is RECOMMENDED to avoid character sets that contain two or more characters that can easily be confused with each other, like \u0026ldquo;0\u0026rdquo; and \u0026ldquo;O\u0026rdquo; or \u0026ldquo;1\u0026rdquo;, \u0026ldquo;l\u0026rdquo; and \u0026ldquo;I\u0026rdquo;. Furthermore, to the extent practical, when a character set contains a character that may be confused with characters outside the character set, a character outside the set MAY be substituted with the one in the character set with which it is commonly confused; for example, \u0026ldquo;O\u0026rdquo; may be substituted for \u0026ldquo;0\u0026rdquo; when using the numerical 0-9 character set."
},
{
url: "/p/jxvi6vv/",
title: "Excel のメモ",
date: "2018-04-16T00:00:00Z",
body: "Excel のメモ"
},
{
url: "/p/hewor72/",
title: "Excel 関数のメモ",
date: "2018-04-16T00:00:00Z",
body: "Excel 関数のメモ 文字列を繰り返す (REPT) 書式 =REPT(文字列, 繰り返し回数) 例: A1 セルに記述した数だけ `*` を表示する =REPT(\u0026#34;*\u0026#34;,A1) これを利用すれば、文字を使用した簡易的なヒストグラムを表示することができます。 日付から年/月/日/曜日など一部の情報を取得する 下記の表は、A1 セルに 2018-04-02（月） という日付データが入力されている場合に、各式の評価結果がどのようになるかを示しています。 式 結果 説明 =TEXT(A1,\u0026quot;m月\u0026quot;) 4月 書式指定で月を取得 =TEXT(A1,\u0026quot;aaa\u0026quot;) 月 書式指定で曜日を取得 =TEXT(A1, \u0026quot;aaaa\u0026quot;) 月曜日 書式指定で曜日を取得（\u0026ldquo;aaa曜日\u0026rdquo; でも同じ） =YEAR(A1) 2018 数値で年（4桁）を取得 =MONTH(A1) 4 数値で月 (1～12) を取得 =DAY(A1) 2 数値で日 (1～31） を取得 =WEEKDAY(A1) 2 数値で曜日 (1～7) を取得（日曜日が1） =WEEKNUM(A1) 14 その年の第何週目か 現在の日時を表示する 式 結果 説明 =TODAY() 2018/4/2 今日の日付 =NOW() 2018/4/2 9:24PM 現在時刻 ※表示形式を時刻にすると時刻部分が表示されます =NOW()-0.5 2018/4/2 9:24AM 12時間前の時刻asdofij 日付文字列から日付データに変換 =DATEVALUE(\u0026#34;2018-04-02\u0026#34;) DATEVALUE 関数は、日付文字列を、日付のシリアル値（内部的には 43192 といった数値）に変換します。 変換後の値を「年月日」のような形で正しく表示するには、セルの書式形式で「日付」や「時刻」を選択しておく必要があります。 月末の日付を調べるテクニック 月末の日付は、「翌月の1日前」を計算することで取得することができます。 今、A1 セルに 4月2日を表す日付データが含まれているとすると、下記の式は、4月30日を示す日付データとなります。 =DATE(YEAR(A1), MONTH(A1)+1, 0) DATE 関数の最後のパラメータは「日」を設定するのですが、ここで 0 と入力することで、1 日前を示すことができます。"
},
{
url: "/p/3fas8ni/",
title: "読書メモ『運を味方にする カジノで一晩10億勝つ人の法則』片桐ロッキー寛士",
date: "2018-04-14T00:00:00Z",
body: "読書メモ『運を味方にする カジノで一晩10億勝つ人の法則』片桐ロッキー寛士 運を味方にする カジノで一晩10億勝つ人の法則 片桐ロッキー寛士 幻冬舎 ラスベガスでディーラーをしている片桐さんのお話。 メモ 基本的にディーラーはお客さんの味方なので、アドバイスは聞いた方がよい。良好な関係を築いた方が何かと得。特にマナーがよい客には勝たせてあげたいと思う。 ディーラーの間では、カジノチップを数えることはバッドラックとされている。 --- プレーの最中は勝負に集中し、運の流れや場の空気を感じ取り、それらを賭けの判断につなげていく。そしてツキを感じたときに勝負する。そういうスタンスが勝てる人の共通点。 おすすめするのは、**勝負を連続したものと考えず、一回一回の勝負と捉えること**。一回ゲームが終わるごとにリセットする。 --- ゲームが終わるたびにリセットすれば、成功がすぐに驕りにつながることはなくなる。 運が向いてきたら、大きく賭ける。それが唯一、大きな勝ちを呼び込む方法です。 --- いつも同じ額を賭けていては、何のためにギャンブルをやっているかわかりません。 運が下がり続ける一方ということもある。負けたまま止めるのが苦手なのであれば、止めどきをルール化しておくのがよい。例えば、同じ番号に賭けて三回連続して負けたら止める、5 万円がなくなったら止める、など。**勝つ額を決めることはできないが、負ける額を決めることはできる**。 良い流れが来るまでは岩になれ。テーブルから離れなくても、いったん席を立って、一歩下がってゲームを見てみるだけでも効果がある。一歩下がったポジションから眺めていると、その場がクリアに見える。 100 枚が 1 枚になってもあきらめるのはまだ早い。そこから挽回するケースが稀ではない。最後の 1 枚だからこそ大切に扱うべき。 **長時間続けると必ず負ける**。勝っているときにいったんゲームを止め、利益を確保しておいて、休憩を挟むなどした後に、再びゼロからゲームを始めるのが一番賢い。多くの**負けの原因は、だんだんと賭ける額が大きくなって、運がマイナスに転じても、賭け金が大きいまま維持されてしまっていること**。運は常に上下している。勝負に勝つコツは、プレー、リセット、プレー、リセットとメリハリをつけて臨むこと。 取り戻すと思った時点で負けは確定。負けは負けと割り切り、新しい勝負を楽しむのだという気持ちで仕切り直す。 **損をする覚悟で勝負していると、その次に来るチャンスをうまく拾うことができる**。 **ギャンブルでも事業でもポジティブバカであることがよい作用をする**。"
},
{
url: "/p/7agmwph/",
title: "アプリや製品のアイデア: 部分共有スペース",
date: "2018-04-12T00:00:00Z",
body: "アプリや製品のアイデア: 部分共有スペース 自宅やオフィスの部屋の一部のスペースをネットワーク連携させて、共同作業の場とする。"
},
{
url: "/p/5jsixcb/",
title: "読書メモ『売れるゲームのUI/UX』西川善司、髙木貞武ほか",
date: "2018-04-08T00:00:00Z",
body: "読書メモ『売れるゲームのUI/UX』西川善司、髙木貞武ほか 売れるゲームのUI/UX 制作現場の舞台裏 株式会社Playce（西川善司、髙木貞武ほか） エムディエヌコーポレーション いろんなゲームを題材にして、UI/UX がどうあるべきか、これまでどう進化してきたかなどが述べられています。 ゲームセンターで異彩を放っている、ガンスリンガーストラトスの話が面白かったです。 アーケードゲームの理想は一般ユーザのプレイがそのまま他のユーザへのプロモーションになっていること。 ガンスリンガーストラトスは、コックピット形式の筐体を考えていたが、通り掛かった人にもよく見えるように今のデザインにした。 左右のアクリルパネルを手前に突き出すように配置することで、ひとり用のゲームだということが自然に分かるようにした。 時間貸しモードを搭載していて、1プレイ100円という通常モードだけでなく、25分500円、60分1000円といった料金体型でも遊べるようになっている。ゲームセンターのスタッフがこのような料金体系を実現するために仕事をしなくてもよい。 全国対戦モードでは、自分の実力に近いプレイヤーがマッチングされるようになっている。プレイヤーのランクは NESiCA に保存される。 「理由」がきちんと言えるのか、それとも言えないのかがプロとアマの違いだ。"
},
{
url: "/p/m6b879s/",
title: "読書メモ『超ノート術』佐藤ねじ",
date: "2018-04-01T00:00:00Z",
body: "読書メモ『超ノート術』佐藤ねじ 超ノート術 佐藤ねじ 日経BP社 ブルーパドル 競争相手の少ないブルーオーシャンは見つけにくいので、それなら、水たまりなら見つけやすいだろうということで、「ブルーパドル」という会社を作ってしまった佐藤ねじさんの本。 働き方や、生き方について見直されつつある昨今、そういった小さなアイデアを商売につなげていくという考え方は今後重要になってくるかもしれないですね。 ねじさんの1軍ノート ねじさんは、博報堂ケトルの嶋浩一郎さんから影響を受けたという、1軍ノート、2軍ノートを作るという方法を採用しているみたいです。 1軍ノートには、モレスキンのような、ちょっとおしゃれなノートを使うことで、いつも携帯して、頻繁に開くというモチベーションを高めている。 そのノートには自分のすべてが詰まっている。 無地の1軍ノートは8マスに区切り、1マスごとにイメージ図と簡単な説明文を書いていく。 フォーマットをそろえてあるので、カタログのように見やすいし、いろんな場所で使える。 2軍ノートには思いついたことをどんどん書いていく。 2軍ノートから1軍ノートに書き写すかどうかは、こんまりさんが言っているのと同様、「ときめく」かどうかが基準。 このとき、ほとんどのアイデアはそのまま書き写されることはなく、何らかの新しい形に書き換えられて転記されることが多い。 前提を覆せば驚きが生まれる この視点が身につくと、あらゆるものについて、前提を変えられないかと発想できるようになる。 例えば、自分たちの作ったものを報告しあう会議では、順番にプロジェクタで映すのではなく、各自の席の上のノートPC上に表示して、展覧会のように、人が動き回って成果物を見ていく。 そうすると、雑談からいろんなヒントが得られるようになる。"
},
{
url: "/p/s363k9f/",
title: "2018-03-30 本当においしいコーヒーの話（コーヒーハンター川島良彰さん）",
date: "2018-03-30T00:00:00Z",
body: "2018-03-30 本当においしいコーヒーの話（コーヒーハンター川島良彰さん） ミカフェート代表取締役の川島良彰さんの話を聞く機会がありました。 JAL のコーヒーを納入されている会社です。 コーヒーハンターと呼ばれるだけあって、すごいこだわりでした。 ハンドソーティングという技 話のテーマの一つに「おいしいコーヒーの作り方」があって、よくコーヒーセミナーで説明されるドリップの仕方みたいな話をされるのかと思ったら、全然違う内容でした。 ミカフェートはコーヒー豆の栽培からとことんこだわっているところなので、コーヒー豆にフォーカスした話でした。 重要なのは豆の選別。 豆を挽く前に、ハンドソーティングして欠点豆を取り除くだけで全然違うコーヒーになる。 欠けている豆（貝殻豆） 煎り色が付いていないもの 虫食い豆 スタバである程度値の張る豆を買ってきても、上記のような豆がたくさん入っている。 コーヒーを粉ではなく、豆の状態で買う利点は、このハンドソーティングができるからなのだと。 コーヒーを豆で買っている理由を聞かれたら、「鮮度がいいから」という人がほとんどだと思います。 「ハンドソーティングできるからですよ」とか言えたらプロですね。 エチオピアの豆を使えない理由 コーヒー豆の輸送経路を考えると、エチオピアのコーヒー豆は使えない。 エチオピアは港などの輸送インフラがあまり整っていないので、どうしても長い陸路での輸送になってしまう。 50℃以上の環境に長期間放置されてしまうことがある輸送方法では、よい状態の豆を手に入れることができない。 理想的には温度差の少ない低温状態で、空路で輸送するのが望ましいけれど、そんな環境とは程遠い。 安いコーヒー豆ってどうして安いの？ スーパーなどで安く売られているコーヒー豆は、選別作業があまりされていないため、歩留まりが高くなるので安い。 例えば、豆のサイズは揃っていたほうが焙煎で火が通りやすいのだけど、このサイズの選別（統一）があまりされていない。 欠点豆の取り除きも行われていない。 あと、輸送も安く済む方法で行われている。 商社も儲けるために必死なので仕方ないけれど、赤道沿いの航路で2週間とかかけて輸送するので、豆へのダメージは避けられない。 昼は60℃、夜には20℃となったりして、湿気で劣化してしまう。 商社から豆を購入する一般のコーヒーチェーンなどでは、こういった輸送経路に対しては注文できないので、おいしいコーヒーを淹れるのには限界がある。 このあたりにこだわれるのがミカフェートの強みであると。 こういった話を聞くと、本当においしいコーヒーはどうしても高くついてしまうんだってことが分かりますね。 でもそういったこだわりを知ってこそ、本物を楽しめる。 知識を付けて、おいしいコーヒーを飲もう！ 誰もやらないことをやろう！ 広告・宣伝にはふつうお金がかかるけど、誰もやらないことをやれば、勝手に記事にしてくれるので、自分で宣伝しなくてもよい。 コーヒーの話じゃないけど、商売の鉄則ですね。"
},
{
url: "/p/xqyuwm2/",
title: "読書メモ『世界でもっとも貧しい大統領 ホセ・ムヒカの言葉』佐藤美由紀",
date: "2018-02-12T00:00:00Z",
body: "読書メモ『世界でもっとも貧しい大統領 ホセ・ムヒカの言葉』佐藤美由紀 世界でもっとも貧しい大統領ホセ・ムヒカの言葉 佐藤美由紀 双葉社 物を買うときの基準 どんなモノやサービスを買うべきかは、次のように考えるとよい。 時間を奪うものではなく、自由な時間を増やすものであること 誰かを幸せにするものであること 発展と幸福 発展は、幸福を阻害するものであってはいけないのです。 発展は人類に幸福をもたらすものでなくてはなりません。 愛を育むこと、人間関係を築くこと、子供を育てること、友達を持つこと、そして必要最低限の物を持つこと。 発展は、これらをもたらすべきなのです。 幸福が私たちのもっとも大切なものだからです。 物と自由 もので溢れることが自由なのではなく、時間であふれることが自由なのです。 もし、少ししか物を持っていなければ、その物を守るための時間も少しで済みます。 物を持つことで人生を複雑にするより、私には、好きなことができる自由な時間の方が大切です。 自由な時間 自分の人生の時間を、好きなことに使っているときが、本当に自由なときなのです。 自分と家族の物質的な欲求を満たすために働く時間は自由ではないのです。 助けること、与えること 余裕のある人には弱者を助ける義務がある。 まずは自分の何かをあげること。どんなにボロクソな状態でも、必ず自分より悲惨な状態の人に何かをあげられます。 孤独は多分、死の次にもっとも悪いことです。"
},
{
url: "/p/y7ky8x2/",
title: "読書メモ『運命を変える 本物の言葉』桜井章一",
date: "2018-02-07T00:00:00Z",
body: "読書メモ『運命を変える 本物の言葉』桜井章一 運命を変える 本物の言葉 桜井章一 ゴマブックス はじめに 運がやってきたときに、瞬時にをそれを感じて、逃さないこと。 運は汚いことや卑怯なことを徹底的に嫌う。 運に好かれたいと思ったら、汚いことや卑怯なことは絶対にやってはいけない。 運は人間と似ている。運に好かれるということは、人に好かれ、自分自身に好かれる人間になるということ。 本物の言葉 （道）自分だけの「見えない道」を選んで、自分だけの何かを手にして欲しい。すでに誰かが歩んだ道は「見える道」、自ら切り開く道が「見えない道」だ。 （価値観）人生のベクトルを楽しみに向けていると、いい出会いがつくれるし、普段の心構えやその立ち居振る舞いが自然と運を呼び込む。 （運）姑息に価値を拾いに行く人よりも、キレイに負けることのできる度量を持った人の方へ、運の波は最終的に多く訪れる。 （現実）煩わしさも何もかも含めて、世の中の現実という波にうまく乗っていけばいい。 （責任）二者択一で、たとえ結果がマイナスに出ても、自分で選んだものは自分で責任をとる気持ちがあれば悔いは残らない。他人のせいにしたがる人は悔いが残る。ほかのものに責任転嫁したらラクになるというのは錯覚であり、自分の責任として真正面から本気で向き合った方がはるかにラクだ。そこから新たことを学べたりする。例えば、腕の骨を折れば、日常生活にはいろいろ支障をきたすが、その不自由さを体験して初めて気づくこともある。これまでできなかった体験をさせてくれる時間だと思えれば、落ち込むことも嘆く必要もない。 （感受性）本当の感受性とは、人が喜ぶことの「気づき」ができること。 （知恵）知恵は経験で身につけていくしかない。とにかく身体を動かしていろいろなことを体験していく。まわりの人たちが少しでも明るくなることを、楽しくなることを感じればいい。感じたら、瞬時に行動に移すこと。そうすれば、ズルさや雑念が入る余地はない。 （マニュアル）老舗にはモットーはあってもマニュアルはない。しっかりとしたモットーさえあれば、マニュアルはいらない。マニュアルに従っていると、人はだんだんと感じる力をなくしてしまう。 （数値）数字に価値を見出して数字を追っていくのに飽きたら、一度は目先を変えてみるのもいいかもしれない。 （従順）従順は怖い。一方的な押し付けでなく、常に考える機会を与えてくれる指導者が本物だ。 （慎重）いたずらに考える時間が長すぎると、往往にして的確な判断はできなくなる。後手にまわることで、最初にあったチャンスをどんどんつぶしてしまう。感じる力があれば、どの方向が正しいか瞬時に判断できる。「慎重に討議を重ねた結果」の決めごとは、それだけでダメだということ。本能で動くことに慣れれば、その判断も正確さを増していく。結果が出るまで待っていては、とうてい遅い。経過を見ながら自然に身体が動けば、心も身体も後悔しない。 （限界）肉体的には100％でも、精神的には80％だという感覚を持つことで、次回もより高いハードルに挑戦することができるようになる。 （リーダー）リーダーとは、個人の荷物を軽くして、そのぶん、公の荷物をたくさん背負う人です。 （目的意識）いまはみんな、目的意識に向かって結果を出すために、毎日を犠牲にしてつまらない過ごし方をしている。個人レベルの小さな損得にとらわれるのでなく、大地のようにゆったりとした気持ちで、いろいろな発見がある毎日の経過を楽しむほうが、よっぽどいい。 （手順）小さな変化を敏感にとらえられるようになると、次にどんな変化が訪れてくるのかを予測できる感性も養われてくる。 （常）どんな些細なことであれ、相手を不愉快にさせる原因をつくってしまったら、そのときは自分の負けだ。 （ストレス）ストレスを感じたら、まわりの人のことを気遣うこと。まわりの人のことを本気で気遣う気持ちがあれば、自分のストレスどころではなくなって、ストレスは消えてしまう。"
},
{
url: "/p/zisgmqi/",
title: "2018-01-27 Coincheck が 580 億円の NEM 流出",
date: "2018-01-27T00:00:00Z",
body: "2018-01-27 Coincheck が 580 億円の NEM 流出 ビットコイン取引所の Coincheck が時価総額 580 億円分の仮想通貨 NEM を流出し、仮想通貨市場に大きな衝撃が走りました。 結局、仮想通貨って理論的には安全と言われていても、人が介入する運用部分での人為的ミスは完全にはなくせないのですよね。 仮想通貨の取引所にお金を預けているということは、常にそれが 0 になるというリスクを抱えていることになります。 銀行のように 1000 万円までペイオフされる法制度が整えばマシになるのでしょうけど、現状を見る限り、当面そのような制度が作られることはないでしょう。 Abema TV で、23:30〜25:00 の緊急記者会見を見てました。 当初 30 分予定だったので、風呂に入りながら見ようと思ったけど、結局１時間くらい延長してのぼせました。。。 しかし、喧嘩腰な記者は何とかならないのですかね？ 質問をするのであれば、皆のためになる質問をしなければだめでしょう。 事実や今後の対応などを質問するのであればよいけど、答えられるはずない質問をして、単に攻めるだけの記者は質問をする資格などない。 そんなことを質問して無駄に時間をかけるくらいなら、早く記者会見を終しまいにして、対応に当たってもらった方が皆のためです。"
},
{
url: "/p/j7habqw/",
title: "読書メモ『勝率９割の選択 運に振りまわされず最善を選び、行動する方法』プロギャンブラーのぶき",
date: "2018-01-20T00:00:00Z",
body: "読書メモ『勝率９割の選択 運に振りまわされず最善を選び、行動する方法』プロギャンブラーのぶき 勝率９割の選択 運に振りまわされず最善を選び、行動する方法 プロギャンブラーのぶき 総合法令出版 勝ちにこだわるな、勝つ準備にこだわれ 結果よりも過程にこだわるようにする。 勝負をする前の準備の方が大切。 自分で満足できるだけの準備をしていなければ、それが不安につながり、負けにつながる。 勝負をする前にひたすら勉強し、実力をつける。 それを続けて入れば、たとえ今回の勝負に負けたとしても、その後につながる。 ３つの対人思考力 レベル１: 自分→自分の視点（自分の手だけを考える） レベル２: 自分→相手の視点（相手の手を考える） レベル３: 相手→自分の視点（相手から自分がどう見えているかを考える） プロはレベル３の視点を持たなければいけない。"
},
{
url: "/p/xzpg8me/",
title: "2018-01-16 RIZAP 瀬戸健 社長の『失敗力』",
date: "2018-01-16T00:00:00Z",
body: "2018-01-16 RIZAP 瀬戸健 社長の『失敗力』 丸ビル７Ｆ丸ビルホールで RIZAP 社長の瀬戸健氏の『失敗力』という講演を聞いてきました。夕学五十講（せきがくごじゅっこう）という慶應丸の内シティキャンパス（慶應MCC）が主催する定例講演会のひとつです。とてもためになる話だったので、ざっと内容を書き残しておこうと思います。 瀬戸さんの経歴などは RIZAP 関連の雑誌記事やニュース記事などでよく読んでいたので、大体分かってたけれど、本人から話を聞くとやっぱり面白いですね。しゃべる能力に関してはすごい長けた人だと思います。RIZAP グループが数多くの M\u0026amp;A を成功させて急成長しているのも、この会話力あってこそなのでしょうね。 上場企業の社長さんの中には、学生時代にはあまり勉強ができなかったという人がたくさんいますが、瀬戸さんも同じように、高校時代の成績はビリに近かったみたいです（自身はあったのにほぼビリｗ）。先生に付けられたあだ名はセトキン（瀬戸菌）。ヒドイなｗ 高校生のときに彼女を年上の大学生に取られた後は、くやしさのあまり、死ぬほど勉強（三徹とか繰り返し）して明治大学に受かったとか。第一希望の早稲田には落ちてしまったけど、それまで必死に努力したことで、とても満足感があり、幸せだった。 こういった経験が、今の RIZAP の目標に達するまでのプロセスを重視するという精神につながっているんでしょうね。 大学時代の転機は、2、30歳年上の人に「瀬戸君は一般常識に欠けてるね」と言われたこと。確かにその通りだと思ったので、くやしくて、できることからやろうと思った。何かを達成するには「今できること」を一つずつやるしかない。そう思って最初の一歩は本屋さんに行って、勉強用の漫画を買った（活字は敷居が高すぎた）。次の一歩は、本を一日一回開くこと。本を読み始めるとすぐに寝てしまったけど、それでも毎日毎日繰り返していたらだんだんと読めるようになってきた。そして本をたくさん読んでいくうちに、「会社を作ることってそんなに難しくないんだ」ってことが分かって起業。RIZAP グループの社長をやっている今は、どんなに忙しくても一か月に 20～30 冊くらいは本を読んでいる。 起業した当初は、ユニクロで買ってきたシャツに目標を書いて、スーツの下に毎日来ていた。「26歳で会社を３社経営している」「28歳で上場企業の社長になっている」。動けない状態で病院に担ぎ込まれたときに、そのシャツを見られたときは恥ずかしかったとのことですが、実際に 28 歳に上場してます（起業して３年目）。目標を設定して、毎日それを見る、そこに向かって毎日１歩１歩進むことの大切さが分かりますね。すべての基本は「ゴール設定とアクション」。この積み重ねだけ。 一歩が踏み出せない人へのアドバイスは、強味だけを見て突き進むということ。SWOT 分析などでは弱みなども書きますが、「ない」ものは「ない」でしょうがないので、「ある」もの（強み）だけに注目して突き進まないとダメ。瀬戸さんも起業した当初は、実家がパン屋であるという強みを活かして、おからクッキーを売りまくったけど、経理とか流通とか全然わからなかった。でもなんとかなった。 強みを生かせばオッケー。 今はものすごい成長をし続けている RIZAP グループですが、瀬戸さんが 29 歳のときには事業で苦い体験をしています。ビリーズブートキャンプの大ヒットや、類似商品の出現で、おからクッキーの売り上げが不調になり、200 億円もあった会社の時価総額がわずか 7 億円にまで急落。従業員もどんどん辞めて、３分の１（80人→30人）にまで減った。自分の家も売り払った。ある朝、２人の社員が来て、「また辞めるのか」と思っていたら、「僕たちが社長を支えますから！」と言ってくれた。その一言で、社員のことを信じられなくなっていた自分に気が付き、目が覚めた。熱くなった。バカであるのはよいが、「社員を信じられない」バカにだけはなってはダメだと心に誓った。 そして、誰かの一言で人は変われるんだということに気付いた。 これが今の RIZAP の「人は変われる」というテーマになっていますね。 今の日本には、自分の可能性を信じて必死に努力をしている人は１％もいない。瀬戸社長のメッセージは、今はやりたいことをほとんどやれる時代になっている（海外で暮らすとか、昔は無理だった）ので、ものすごいチャンスな時代なんだということ。今やっていることが２、３年後の自分に確実に繋がっているので、ゴールを決めて、毎日のアクションを確実にこなせばよいのだということ。これがすべて。RIZAP もやっていることは極論すればこれだけ。 ただ、ゴールに到達するという１点だけが目標になるのはダメ。そこに向かってもがきながら進んでいくというプロセスが重要で、将来思い返したときの幸せにつながる。「悩み」があるということは、上を目指しているという証拠なのでよいこと。 悩みがある自分に自信を持てばいい！大変なことをひとつずつ乗り越えていくプロセスこそが宝物になるんだ！ おまけ Q\u0026amp;A Q. RIZAP トレーナーに何を教えているのか？ 1,000人以上いるトレーナーには、理念（原理・原則）を伝えている。テクニックを教えるという方法では絶対に破綻する。 テクニックは後からついてくるもので、皆が考え、工夫していくものだ。 Q. RIZAP が M\u0026amp;A した会社はなぜそんなに変われるのか？ 第一に、「お客様視点」で働けているかを見直すところから始めている。本当にこれができていない会社が多い。例えば、お客様のことを第一に考えずに営業をしている社員は苦しんでいる。そういったマインドが変われば会社全体が変わる。「やり方」については本を読めばすべて書いてある。本をたくさん読んでいる人がコンサルティングを受けても、「そんなことは知っている」と感じるだけだ。でも実際にはできてない。続けられない。大切なのは「やるべきことを続ける」ということ。 Q. RIZAP が M\u0026amp;A したくない会社は？ 経営者が本当に「変わりたい」という意思を持っていないところはダメ。話し合いで変わるように諭すんだけどね。"
},
{
url: "/p/zoqtqaj/",
title: "読書メモ『頭がいい人はなぜ、方眼ノートを使うのか？』高橋政史",
date: "2018-01-14T00:00:00Z",
body: "読書メモ『頭がいい人はなぜ、方眼ノートを使うのか？』高橋政史 頭がいい人はなぜ、方眼ノートを使うのか？ 高橋政史 かんき出版 ポイント 書くことに億劫にならないためにも、紙質のよい、多少高価なノートを使うこと。方眼ノートにすればチャートなどもきれいに書けるので、それだけでモチベーションが上がる。 思考の基本は「事実に基づいて考えること」。外資系コンサルタントの思考がすぐれているのは、常に事実（ファクト）に基いて考えるから。 仕事ノートや、会議でホワイトボードを書くときは、「事実 (fact)」と「意見 (idea)」を明確に分けて書くとよい。 「事実（ファクト）」は、自分の目で見たことが一番確実。 方眼ノートは３つに分割して書く。左は「情報・事実・ファクト」、中央は「自分の気づき」、右に「要約・疑問点」。 文章力を向上させるには、ノートを「単語」ではなく「文章」で書き、その文章を読んだときに具体的なイメージが見えるように書くこと（これを著者は「見える！言葉」と呼んでいる）。 「見えない」言葉と「見える」言葉 ノートを記述するときは、その文章を見たときに、具体的にやることが「見える」ように記述する。 見えない (NG) 見える (Good) 検討する ３週間で実施判断の基準を作成する 共有する A4で１ページのフォーマットにまとめ参加者にメールする 見える化 論点を３つにまとめ、いつまでに、誰が、何をするか書く 浸透する 企業理念を１枚絵にして、社長が週１回その思いを語る 把握する 関係者にインタビューして問題点を３つ、アクションを１つにまとめる 意識する ハガキサイズの10項目リストを持ち歩き、９時、13時、18時にチェックする 感想 少なくとも、ノートや手帳に書き込むときは、事実と自分の意見を分けて書く ことに気をつけようと思った。 あと、日々文章力を鍛えるために、できるだけ伝わる 「文章」の形で、具体的に（固有名詞や数値を使って）書く ようにする。だからあまり小さな手帳は使わないようにしたい。"
},
{
url: "/p/29ss6t4/",
title: "マネージメントに関して",
date: "2018-01-12T00:00:00Z",
body: "マネージメントに関して マネージャーとマネジメントについて P.F.ドラッカー『マネジメント エッセンシャル版』より 変化の時こそ「基本」を確認。基本と原則に反するものは例外なく破たんする。 働く者が満足しても、仕事が生産的に行われなければ失敗である。仕事が生産的に行われても、人が生き生きと働けなければ失敗である。 マネージャーは権力を持たない。責任を持つだけである。その責任を果たすために権限を必要とする。 マネージャーの役割 投入した資源の総和より大きなものを生み出す生産性を創造すること。 あらゆる決定と行動において、直ちに必要とされているものと遠い将来に必要とされているものを調和させていくこと。 マネージャーの仕事 目標設定 組織化 動機付けとコミュニケーション 評価測定 人材開発 マネージャーにしてはいけない人 強みより弱みに目を向ける人 何が正しいかよりも誰が正しいかを重視する人 真摯さよりも頭のよさを重視する人 部下に脅威を感じさせる人 自らの仕事に高い基準を設定しない人 課題解決のステップ 現状把握: あるべき姿とのギャップを把握 目標設定: 何をいつまでに達成するか 原因分析: あるべき姿とのギャップの原因を明らかにする 仮説構築: 原因に対する仮設を立てる 計画 アクション ハックマントオールダムの職務特性モデル (Job Characteristics Model) ハックマンらは、職務への満足度を高め、動機付けに結びつく職務の特性を次の５つに分類しています。 Skill Variety（スキルの多様性） Task Identity（完結性） まとまりのあるタスクであること（全体のどの部分を担当しているのか分からないと不安になってしまうため） Significance（重要性） Autonomy（自律性） Feedback（フィードバック）"
},
{
url: "/p/qfzhht4/",
title: "2018-01-01 ビットコインは投資でも何でもない",
date: "2018-01-01T00:00:00Z",
body: "2018-01-01 ビットコインは投資でも何でもない 2017年の年末はビットコインが盛り上がりましたね。1ビットコインが19000ドルを突破したとか何とか。 でもここにお金をつぎ込んでいる人はお金の使い方を考え直して欲しいと思います。 投資は本来は、将来成長していく事業などに先行して資金を投入していくもの。そこから生み出される付加価値があるこそ有意義なものです。でもビットコインにそのような価値はありません。 買う人がいるから上がる、それだけのチキンレースですね。売り抜けられた人はいいかもしれませんけど、その裏にそれだけの高値で買っている人がいるっていうことを忘れちゃいけません。FX と同じゼロサムゲームで、全体で見たら誰も儲かっておらず、付加価値を生み出してはいません。ブロックチェーンの社会的な実験をしたいのであれば、政府が発行する仮想通貨を使えばよいんです。 結局誰が得をするか？ それは売買手数料を稼いでいる金融業者と、売買で得られたお金に対して課税する政府です。売買を煽っているのは、そういった人たちの戦略ですからね。 本当に勝者になれるのは、ビットコインの購入者じゃないんだってことに早く気づきましょう。"
},
{
url: "/p/f6pfj2j/",
title: "2017-12-15 ROMEO ボールペン",
date: "2017-12-15T00:00:00Z",
body: "2017-12-15 ROMEO ボールペン ブックファーストに置いてあったちょっと高級そうなボールペンの試し書きをしてみたら、ヌルヌルサラサラで感動しました。 伊東屋が作っている ROMEO というボールペンらしいのですが、今まで味わったことないほどさらさら書けるボールペンでした。 試し書き用の紙も ROMEO のものだったので、紙の方にも原因があるのかなと思い、別の安そうな試し書き用の紙にも書いてみたらやっぱりヌルヌルサラサラ！ 高級ボールペンをなめてました。買いたい物リストのトップテンに入りました。今年の自分へのクリスマスプレゼントはこれがいいかなー。高級といっても一万円以下で買えるので、すごく人気があるみたいです。 ペンは毎日使うものなので、本当に自分が満足するものを使いたいですね。"
},
{
url: "/p/oae44u5/",
title: "2017-11-14 為末大さん講演会",
date: "2017-11-14T00:00:00Z",
body: "2017-11-14 為末大さん講演会 元陸上選手の為末大さんのお話を聞いてきましたので φ(・ｪ・o) メモメモ。 最近は、どうしたら人が活力を持てるか？ 人間を理解することをテーマとして活動しておられるようです。 自分を理解する 気付いたのは、人間は個々の能力よりも、どんな環境 (ホットスポット) に身を置くかで発揮できるパフォーマンスが大きく変化するということ。 本来の自分を変えようとすると、変えられないので苦しむだけ。 例えば、几帳面な性格を根底から変えるのは難しい。 そうじゃなくて、変えられるもの（トレーニングのやり方など）に着目すべき。 自分らしさとは何か？ それを知るには、いろんなタイプの人にたくさん出会うしかない。 「夢」ではなく「やりたいこと」を考える ×「あなたの夢は何ですか？」 ○「あなたのやりたい事は何ですか？」 夢＝職業ではない。 職業は手段でしかないので、本当にやりたいこと、成し遂げたいことにフォーカスすべき。 例えば、「ケーキ屋さんになりたい」という夢を持つのはいいけれど、本当にやりたいこと、達成したいことはケーキ屋さんになるということではなく、おいしいケーキをお母さんに作ってあげて、「お母さんを笑顔にする」ということのはず。 そういった、本当の目的をちゃんと認識しないといけない。 「夢中」と「俯瞰」 人が活動するときは、「夢中／没頭」状態で動いているときと、「俯瞰／客観」状態で動いているときがある。 ただし、これらを同時にこなすことはできない。 夢中で没頭する時間は重要なので、それを続けた後で俯瞰する、というサイクルを意識的に繰り返すことが大切。"
},
{
url: "/p/bzto4ey/",
title: "2017-11-03 Realforce キーボードを静音化",
date: "2017-11-03T00:00:00Z",
body: "2017-11-03 Realforce キーボードを静音化 10年くらい前に買った東プレの Realforce を静音化してみました（このサイトを参考にさせていただきました）。 使用頻度の低いファンクションキーや、Home、End キーなどはあえて静音化せずにそのままにしてあります。そうすることで、いつでも静音化の効果を楽しめるようにしてます（笑）。下の動画で、ファンクションキーと、アルファベットキーの音の違いを聞いてみてください。 もともと Realforce は会社でも使えるくらい打鍵音の小さいキーボードですが、静音化してみると、ノーマルな Realforce の音がどれだけうるさかったが実感できます。 静音化はキーボードを分解してキーひとつずつに薄い布を挟んでいくのですが、キーを離した時に当たる部分に挟むのがポイントですね（押し下げた時に当たる部分ではない）。下の写真の、隙間から見えている赤い布がそれです。 キートップの洗濯のついでに静音化しようと、軽い気持ちで始めたのですが、はっきりいってめちゃんこ大変でした。まぁでも毎日使うものなので結果には満足してます。"
},
{
url: "/p/pr4eox9/",
title: "読書メモ『人工知能が金融を支配する日』櫻井豊",
date: "2017-09-19T00:00:00Z",
body: "読書メモ『人工知能が金融を支配する日』櫻井豊 人工知能が金融を支配する日 櫻井豊 東洋経済 タイトルに「金融」とありますが、さまざまな人工知能について幅広く解説するような内容になっています。 世界中の金融業界がテクノロジーを駆使して歴史的な転換期に対応してきているのに対し、日本の金融業界がひどく遅れていることを指摘し、その打開策などについて述べています。 強力な人工知能が金融を支配しまった世界を想像すると本当に恐ろしいし、もしかするとそちらの方向にすでに進みつつあるのかもしれません。 間違いなく言えるのは、これからの日本の金融業界には、技術知識の豊富な人が必要不可欠であるということ。 ただし、現状の日本の金融業界にはそのような体制は作れないということ。。。 メモ 金融業の多くの非単純労働はロボット化される。 ビッグデータ時代の分析では、個人の信用リスクを リアルタイムにモニター できる。 LTCM はあっけなく崩壊したが、バリューに注目した投資スタイルはファンドに取り入れられた。LTCM の失敗はレラティブ・バリューという戦略自体の失敗ではなく、レバレッジのかけすぎや、本来のスタイルに反するようなポジションを取った結果であると判断したからだ。 世界中の銀行を監視する立場にある BIS も、レポートの中でビッグデータの活用に関して言及している。 日本のフィンテックは便利な機能止まりだ。 重要な本業に人工知能やビッグデータを活用することについてひどく遅れている。 ヘッジファンドというビジネスモデルが日本ではマイナーなであることも影響している。 戦後の護送船団方式による金融政策により、イノベーション能力が衰退した（アメリカと対照的）。 日本のトレーディングは経験と勘の比重が高すぎる。アメリカなどでは、数学・統計・テクノロジーを中心にしたクオンツ・トレーディングが優勢になっている。 東京の FX 市場も海外のロボトレーダーにシェアを奪われている。 重要なのは破壊的なテクノロジーを独占させないこと。 ディープマインドのようにオープンなスタンスを持ち続けないといけない。 これからの日本がやるべきこと 世界に負けないレベルの独自のテクノロジーを作り上げ、できるだけ 公共の目的で使用 すること。 既存の金融機関の利害関係を超越した体制を作ること。例えば、「業界横断的な組織」や「政府主導の組織」で研究を進めるのがよい。"
},
{
url: "/p/ao6pgrk/",
title: "2017-09-17 Netflix のベーシックプランとスタンダードプランの画質比較",
date: "2017-09-17T00:00:00Z",
body: "2017-09-17 Netflix のベーシックプランとスタンダードプランの画質比較 Netflix はベーシックプラン（月650円）で契約してたんですが、毎日使っているのでスタンダードプラン（月950円）でもいいかなぁと思ってアップグレードしました。 SD 画質から HD 画質になるのでちょっと比較。 ベーシック（SD 画質） スタンダード（HD 画質） うーん、、写真だとわかりにくいですね（＾＾； Full HD 画質の方は、DEATH NOTE の文字がくっきりしてます。 上の写真は Sony のテレビで表示したものですが、ノート PC でアニメを表示した場合の比較もキャプチャしておきます。 ベーシック（SD 画質） スタンダード（HD 画質） アニメの場合はさらに差が分かりにくい！ 正直なところ SD 画質でも普通に楽しむことはできるんですが、300 円で上質な画質で楽しめるようになるのであれば、安いものですね。最初から Full HD のプランにしておけばよかったー。"
},
{
url: "/p/7bs74j9/",
title: "2017-08-23 株式を家族間で移管",
date: "2017-08-23T00:00:00Z",
body: "2017-08-23 株式を家族間で移管 SBI 証券証券口座にある株式を家族の証券口座に移管する申し込みをしてみました。 別の人の証券口座に株式を移す場合は「異名義移管」という扱いになって、サポートセンターに電話をしなければいけないようです。 SBI証券 ホーム \u0026gt; サービス案内 \u0026gt; 贈与等による異名義移管のお手続き 電話をしてお願いすると、いろいろ注意事項などを教えてくれて、２、３日で申し込み書類が送られてきます。一枚の書類に、移管銘柄は５つまでしか記入できないので、移管予定の銘柄数を伝えておく必要がありあす。 今回申し込んだ移管は、「本人のSBI証券特定口座」⇒「家族のSBI証券特定口座」という口座間の株式移管です。電話で注意事項をいろいろ説明してくれましたのでポイントをメモ。 移管先に「銘柄A」が既に存在する場合、移管元の「銘柄A」の部分移管はできない（移管元の「銘柄A」をすべて移動させることは可能）。 贈与税に関しては、詳しくは税務署に問い合わせてくださいとのこと。ただ、一般的には贈与金額は、移管実行日の終値や、前月の平均評価額、前々月の平均評価額を用いられることが多いとのこと。 部分移管に制約があることは初めて知りました。ちなみに、各銘柄の月ごとの平均終値は、東証の月間相場表のページで調べられます。贈与税の計算などが必要な場合は確認してみてください。 追記 (2017-08-25): こんな申し込み書類が届きました。住所とか全部手書きで書かないといけないんですね。もっとユーザにやさしい仕組みにしてくれればいいのになぁ。。。 図: 相続上場株式等 移管依頼書 図: 贈与届（兼 移管依頼書 及び 委任状） 図: 贈与契約書"
},
{
url: "/p/w5w4375/",
title: "読書メモ『１分間勉強法』石井貴士",
date: "2017-08-10T00:00:00Z",
body: "読書メモ『１分間勉強法』石井貴士 本当に頭がよくなる 1 分間勉強法 石井 貴士 KADOKAWA/中経出版 2014-03-27 効率的な勉強法について、**タイム・マジック（時間短縮の魔法）とカラー・マジック（右脳の魔法）**という２つの方法でまとめています。 気分転換のつもりで読んでみたけれど、書くという行為がいかに時間的に無駄かということや、右脳に働きかけるために色を使うべきだという意見は参考になりました。 タイムマジック 中心になっているのは１分間で本をリーディングするいう話ですね。 読むのではなくて、感覚で重要だと思うところを潜在意識で拾っていくという感じ。 Reading ではなくて Leading。 潜在意識に浸透させるために、できて当然だと思ってから読むということが大切らしい。 勉強法に限らず、**自分はできる！**と思って行動することは確かに重要ですね。 最初は左手でページをサクサクめくっていくということをとにかくやる。 読んでいないから分からない、という状況になるけど、それがまさに読まずに見ているという証拠なので、最初はそう感じるのが正解らしいです。 なるほどなるほど。 そう言われるとしばらく特訓してみようって気になりますね。 ちなみに左手でページをめくるというのも、イメージを捉える右脳を活性化させるためになるべく左手を動かすという理由からきています。 英単語を勉強するときは、1分で1単語を覚えるのではなく、1秒で1単語×60というジャブを繰り返すのが有効。 英単語を書くという行為は時間がかかるのでやってはいけない。 世の中でもっとも速いのは光なのだから、それを捉える視覚に特化して勉強するのが最強最速。 なるほど完璧な理論だ（＾＾） 専門家になるには、図書館にいってその分野の本を200冊読むのが手っ取り早い。 確かに１分で１冊読めるのであれば、そのくらいの勢いで知識をつけるのが早いですね。 知識をつけるためだけに学校に通うのはとても非効率。 自己満足に陥りやすい。 カラー・マジック 右脳は映像をつかさどっているので、色に反応する。 なので、記憶するときには色鮮やかなものを使った方がよい。 例えば、黒ペンじゃなくて、青ペンを使う。白い紙じゃなくて、色のついた紙（赤、緑、黄、青）を使う。 どこまで効果があるかは分からないけれど、色のついた製品を使うことくらいは簡単にできるので、試してみる価値はありますね。 ちなみに、色をたくさん使いすぎるのも逆に時間がかかって効率が悪いので、赤、緑、黄、青の４色に限定して重要度別に情報をまとめるのがよいようです。 本を読んだら、１ページくらいで色分けしてまとめておく（カラー・マジック・シート）。 これはあとから１秒で復習できる。 このシートが溜まって来たら、今度はシートを赤、緑、黄、青のクリアファイルにまとめておく。 赤のクリアファイルは常に持ち歩いて、各シート１秒で何度も復習することでバッチリ覚えることができる。"
},
{
url: "/p/hy8ppr7/",
title: "2017-08-07 シェアリングエコノミーの弊害",
date: "2017-08-07T00:00:00Z",
body: "2017-08-07 シェアリングエコノミーの弊害 自転車大国のオランダで、シェア自転車の撤去が始まるようです。世界的にもシェアリングシティとして有名なオランダがこのような対応を迫られることになったという事実は、モノにあふれる世の中が今後どのような方向に向かっていくべきかのヒントになりそうです。 シェアリングエコノミーの発想としては、自分の占有時間が限られているモノをシェアすることで、時間、空間などを効率的に利用しようというものです。シェア自転車の場合は、自転車を共有して交通の混雑をなくそうという発想ですが、もともと自転車の保有率が高いオランダでは、シェア自転車が入ることで余計に街が混雑してしまったとか。 昔ながらの発想で、既存のモノをシェアするだけであればこういった事態にはならなかったでしょう。たとえば、隣の家に工具を借りるとか、ある作業を得意な人に手伝ってもらうとか、そういったシェアは世の中の人を幸せにするシェアです。 でも、今回のケースでは、すでに皆が自転車を持っているのに、営利目的の企業がさらにシェア自転車を追加で投入することによって街に自転車があふれてしまった。企業がシェア用のモノを投入するのであれば、既存のモノとどう共存させていくのかを含めて考えていく責任を負うべきです。シェア自転車であれば、既存の自転車を回収する代わりにシェア自転車を使用する権利を提供するとか、街中の自転車量をモニタリングして適切な量だけ展開していくとか、そういったことも含めて考えないといけません。 シェアリングという概念が今後広まっていくことは確実で、それは自然なことなのだろうと思っています。 人がモノを自分の近くに置いておきたいのは、「自分が時間的、距離的にすぐに使えるもの」を確保したいといった欲求からであって、インターネットによるコミュニケーションや物流が発展するに従い、モノを所有することの必要性は減っていきます。 所有物を減らすことでストレスから解放され、逆に安心感を得るというスタイルが広まってきているのもうなずけますし、自分もそうありたいと思うようになってきました（年を取ったのかな？）。 シェアリングビジネスを考えるときは、利益を上げることも大切だけど、シェアによって作り出される幸せな世界がどんなものかを第一に考えるようにしたいですね。"
},
{
url: "/p/th8co6e/",
title: "2017-07-29 都会の中のオアシス「等々力渓谷」に行って見た",
date: "2017-07-29T00:00:00Z",
body: "2017-07-29 都会の中のオアシス「等々力渓谷」に行って見た 大井町線の等々力駅を降りて徒歩５分の等々力渓谷で散歩。 都会の中の渓谷なのでそんなに大きくはないけど、みんな涼みに来てますね。途中で一軒だけお茶するところがありました。二子玉川や自由が丘に行くついでに寄り道してみるのもよいかもしれません。"
},
{
url: "/p/n4z4k6d/",
title: "2017-07-20 インデックス投資家 梅屋敷商店街のランダム・ウォーカー",
date: "2017-07-20T00:00:00Z",
body: "2017-07-20 インデックス投資家 梅屋敷商店街のランダム・ウォーカー 梅屋敷商店街のランダム・ウォーカーの水瀬ケンイチさんのお話を聞いてきました。 10 年以上インデックス投資を続けてきためずらしい方です。 もともとはデイトレーダーだったらしいですが、投資以外のことが忙しくてインデックスに乗り換えたとのこと。 趣味など他にやりたいことがいろいろあるのに、投資に時間を割くというのは本質的に間違っているという意見はハッとさせられるものがありますね。 投資を始めてしばらくすると、テクニカル分析やファンダメンタル分析が楽しくなってきます。 それはそれでよいのですけど、本当にやりたいことは投資じゃなくて、別のことでしょ？ってことを忘れないようにしなきゃですね。 水瀬さんがやっているインデックス投資の手順は、ごく一般的なこんな感じ。 ２年分の生活費は確保 リスク許容度の把握 資産配分の決定（アセットアロケーション） 投資商品の決定 積み立てとリバランスを繰り返す アセットアロケーションは、配分自体が大切なのではなく、その組み合わせによって「期待リターン」と「リスク（ボラティリティ）」が何パーセントになるのかが重要。 例えば、期待リターンが +4.4% で、リスクが 13.6% であれば、一年後の資産は 68% の確率で、+18.0%〜-9.2% の範囲に収まる（１標準偏差）。 95% の確率で、+31.%〜-22.8% の範囲に収まる（２標準偏差）。 インデックス投資で「株式」に投資すべきだという結論は、過去の歴史から導かれてます。1801年からの200年で、金融商品の価格は次のように変化しています（インフレ率も考慮）。 現金 ・・・ 0.07倍 金 ・・・ 0.98倍 国際 ・・・ 952倍 株 ・・・ 60万倍 なんだかんだ言っても、資本主義経済は拡大再生産し続ける仕組みで回っているのだから、株式の価格は上昇し続けるという結論に至ったとのこと。 しかし、こうして比較してみると、現金で資産をずっと持っていることがものすごく損だということがよくわかりますね。すぐに使えるという意味では現金は最強なのかもしれないですけど、仮想通貨や IoT を利用した決済手段が主流になれば、現金の利点はどんどん減っていくのでしょう。 10 年以上インデックス投資を続けているとなると、リーマンショックや東日本大震災、ギリシャショック、チャイナショックなどをもろに食らっているわけですが、結局は2〜3 年程度で回復するため、収支は数十パーセントのプラスになっているようです。大ダメージを受けても撤退せず、10 年以上たんたんと積み立てを続けている人の話には説得力があります。 ちなみに、インデックス投資では、積み立て時に定額で購入し続けるドルコスト平均法が有名ですが、売りの出口戦略としては、定額ではなくて定率で少しずつ売っていくようにすれば価格変動の影響を減らすことができるとのこと。 例えば、老後に株資産の 5％ ずつを少しずつ売っていくようにすれば、株価が高い時にはたくさんの現金になり、株価が低い時には少量の現金になります（割安なときに株をたくさん売ってしまうのを防ぐことができる）。"
},
{
url: "/p/e94pu2w/",
title: "2017-07-18 ゼロから生み出す力",
date: "2017-07-18T00:00:00Z",
body: "2017-07-18 ゼロから生み出す力 幸せに生きていくために必要なことってなんだろう？ 幸せの定義は人それぞれなのだから、必要なものも人それぞれで、ひとことで定義するのは難しいのかもしれません。でもあえて言えば、それはきっと自分の価値観を持って、それに従って生きるということ。自分にとっての幸せが何なのかをちゃんと考えて、そこを目指して進んでいくこと。 最近よく考えるのは、逆説的だけど、不安はどうすれば減らせるのかということです。不安を取り除いていけば、幸せな状態が残るはず。そんな考え方でもいいのかもしれません。 ちきりんさんが、著書『未来の働き方を考えよう』の中で、**「ストック型よりもフロー型が重要」**といっています。例えば、いくら貯金（ストック）を持っていても不安は尽きないけれど、稼ぐ力（フローを得る力）があれば、安楽に構えていることができる。 もっともですよね。今お金をたくさん持っていたとしても、元になったのが親から受け継いだ遺産や、宝くじで当たった大金だったとしたら、何らかの突発的な事故で失ってしまう可能性を考えると不安は消えません。でも、ゼロから稼ぐ力があれば、何が起きても大丈夫だという自身が持て、不安からは解消されるでしょう。 あるお金持ちがこう言っています。**「本当のお金持ちというのは、一億円持っている人ではなくて、一億円を稼ぐ力を持っている人のこと」**だと。みんな考えていることは同じですね。 企業の財務諸表であれば、バランスシート（現在の資産）ではなく、キャッシュフロー（稼ぐ力）の方が未来の成長のためには重要だと言うこと。 だから、幸せに生きるためには、「今何かを得ること」というよりは、「何かを得る力をつける」ということを考えて生きていくのがいいんだと思います。「稼ぐことではなくて、稼ぐ力をつけること」、**「人との繋がりをつくるのではなくて、人との繋がりをつくる力をつけること」**を考えよう。"
},
{
url: "/p/in9us4k/",
title: "2017-07-07 多くの人に動いてもらうにはインセンティブを与える",
date: "2017-07-07T00:00:00Z",
body: "2017-07-07 多くの人に動いてもらうにはインセンティブを与える 大きな組織で働いていると、ときには何百人もの人を対象に指示・お願いをしなければいけないことがあります。 そういったときに、皆に確実に動いてもらうためには、何らかのインセンティブを与えるのが効果的です。例えば、ある作業をお願いする場合、 ７月７日までに必ず完了するようにしてください と指示するだけでは多くの人に動いてもらうことはできません（３割くらいは動いてくれるかもしれません）。その後、進捗が思わしくないときには、次のような催促のメールを送りたくなるかもしれません。 期日までに終わらない場合は、定例ミーティングでその理由を報告してください このような指示は、動いてくれなかった人に罰則を与えているだけで、もともと達成したかった「期日までに終わらせる」という本質的な目的からずれてしまっています。 もちろん、罰則やルールで縛ることによって、人はある程度動いてくれるようになります。 しかし、同じ組織の仲間たちに罰則を与え、作業を強制させるというやり方はあまり気持ちのよいものではありません。 こんなときは、作業を進めることによって、何らかのメリットを得られるというインセンティブを与えられないかを考慮するとよいです。 例えば、 先に作業を完了したメンバから優先的に ～ を利用して構いません とか、 ７月７日までに到着したデータは、こちらでまとめて登録します など、作業を早く終わらせることによって得られるメリットをいっしょに提示してあげると、皆のモチベーションは確実に上がります。 いっしょに提示するメリットが思いつかないという場合は、私がいつも使っている裏技があります。それは、「罰則を反対向きに提示してインセンティブとする」という方法です。例えば、 登録が７月７日に間に合わなかった場合は、登録後に全メンバに内容を報告してください という罰則がある場合、最初から次のようにお願いするのです。 登録後は全メンバに内容を報告してください。ただし、７月７日までに登録していただいた分に関しては、報告を免除します この２つ、実はお願いしていることはまったく同じです。 でも、ちょっと視点を変えてお願いするだけで、人を動かせるかどうかが変わってきます。"
},
{
url: "/p/uy6nsvq/",
title: "2017-07-03 図書館を利用して読書のペースを上げる",
date: "2017-07-03T00:00:00Z",
body: "2017-07-03 図書館を利用して読書のペースを上げる 読書量を増やそうとして本をたくさん本は買ったものはいいものの、積ん読ばかりが増えてしまう、という人は、図書館を活用してみるのがいいかもしれません。 自分で買った本は、自分の手元にずっと置いておけるため、いずれ読めばいいやと積ん読になりがちです。でも、図書館で借りた本は二週間で返さなければいけないので、例えば４冊借りてくれば、二週間で４冊読む、というペースが作れます。 図書館には新刊は少ないかもしれませんが、まずは読書のペースを掴むことが大切。今ではネットで蔵書を検索できるところも多いので、興味のありそうな本はたくさん見つけられるはずです。 一般的な書店での本の並べ方に慣れていると、50音順に整列されている図書館では、目的の本を見つけにくいかもしれません。図書館を活用するコツは検索システムを使って本を探すことです（館内の端末や、インターネットで）。 図書館は本を返却するのが面倒という人もいますが、区内の図書館であればどこの図書館でも返却できたり、夜間の返却ポストもあったりして、意外と気軽に利用できます。 今度のお休みは近くの図書館にでも行って、普段は読まないような本でも借りてみたらどうでしょうか。"
},
{
url: "/p/7girbw9/",
title: "2017-06-30 企業の成長には A/B テストの考え方が必要",
date: "2017-06-30T00:00:00Z",
body: "2017-06-30 企業の成長には A/B テストの考え方が必要 ソフトウェア開発の世界では、A/B テストという改善手法が主流になってきています。 複数のデザインのアプリケーションをランダムに配信することで、どちらの方が効果が高いかを実際の顧客行動から導き出すというもの。 オバマさんの選挙キャンペーンでは、寄付金サイトの改善を A/B テストで繰り返すことによって、最終的に寄付金のコンバージョンレートを 49 ％向上させたらしいです（ようするに、失敗しない方法で、どんどん寄付する人してくれる人を増やし、最大限に寄付金を集めることができたということ）。 これって、考え方自体は普通のビジネスで昔からやっていることと同じですよね。どの改善案がお客様にとって受け入れられるのか、より利益を出すことができるのかを考えて実行していく。事業を大きくしていくというのは、このように改善方法を考えて、繰り返し適用していくことなので。 ソフトウェアの世界では、このような改善がよりシステマチックにできるようになってきたというだけのこと。顧客がどういった経路で商品の購入に至ったのか、どのあたりの情報を時間をかけて読んでいるのか、といった生の顧客データをリアルタイムに取得することができるので、本当に効果的な改善かどうかを確認したうえで大規模に展開していける。 一か八かでサービスをリニューアルする、という手法では企業は生き残れなくなってきています。顧客の購買行動などをダイレクトに改善につなげる A/B テストの考え方が必要。こういった効果的な改善を続けて行っている企業は強いです。A/B テストで明確な指標を設定して事業展開している企業は、戦略的撤退も迅速かつ的確です。 野口竜司さんの「A/B テストの教科書」は、A/B テストの考え方や進め方が体系的にまとまっていてわかりやすいですね。 パッと見では、主に Web サイトの改善にフォーカスしているように見えますが、A/B テストの思想的な部分もわかりやすく説明されているので、何らかの「改善活動」を行おうと思っている人には参考になると思います。 軽くポイントをメモしておきます。 A/B テストによる改善は、大体こんな流れで進めていきます。 (1) 課題の発見と管理 まずは、改善すべき個所（課題）を見つけるための調査を行います。アクセス解析データや、ユーザビリティテスト、アンケートなどで調査します。ここで、「大きな課題」を見つけられば、A/B テストによる改善のポテンシャル（リターン）も大きくなります。 「課題・仮説シート」の作成: 調査データとそこから導き出される課題を記入していきます。A/B テストによる改善は、継続的に行っていくものなので、課題はリスト化して管理しておきます。 「KPI マップ」の作成: 実際のアクセス解析データから KPI マップを作ると、テストのゴール設定（改善したい指標）や、改善効果の確認がやりやすくなります。ユーザがどの場所で離脱しているのか、ある経路の購入率はいくつかなどを一目で分かるようにフローチャートなどで図示します。KPI マップは月単位くらいで更新するのが理想です。KPI マップを利用して、重要視する指標（改善したい指標）を絞り込み、テストのターゲット（ゴール）とします。 (2) テスト計画と具体案の作成（改善仮説の設定） テスト計画では、今回改善対象とする箇所を決めていきます。 テストする場所の決定: 課題リストや KPI マップをもとに、どこをテストするのかを決定します。 テスト KPI の設定: KPI マップなどをもとにして、テストによって改善すべき「テスト KPI」を設定します。１つの最重要指標（購入完了率など）といくつかのサブ指標を設定し、効果を定量的に測れるようにします。 テスト仮説（案）の作成: どうすれば改善できるのかを「テスト仮説（案）」として洗い出していきます。テスト仮説がたくさんある場合は、最重要指標をルートとする「仮説ツリー」を作り、グルーピングします。 テスト様式の決定: どんな種類のテストを行うのか決めます。テストにかかる工数や期間に影響します。 テストロードマップの決定: どの時期に、どれくらいテストを行うのか決めます。 大枠のテスト計画が決まったら、具体的なテスト案（異なる表示パターンなど）を作成します。テストを繰り返すことを前提にし、「次のラウンドのテスト案」も作成しておくのが改善をスムーズに進めるコツです。 ワイヤーフレームの作成: テスト案と、どのような構成にするかのワイヤフレームを作成します。 クリエイティブの作成: A/B テスト用の、具体的なデザイン、コピーなどを作成します。ここで作成するものをクリエイティブと呼び、A/B テストではこのクリエイティブを切り替えてテストを行います。どの変更がどのような影響を与えるかを明確にするため、「１つのバリエーションで１つの仮説」だけを対象とするように注意して作成します。用意するクリエイティブのバリエーション数は、テストごとに３～５種類くらいが平均的です（A と B の２種類じゃないよ）。 スクリプトの作成: テストパターンにおいて JavaScript などで動的な制御が必要な場合は、クリエイティブの作成と同様にここで作成します。 (3) A/B テストツールの組み込みと実行 タグの設定: Web サイトであれば、A/B テストツールが発行するタグをページ内に組み込んで、アクセスを追跡できるようにします。独自形式のアプリケーションであれば、アクセスを追跡するための独自の仕組みが必要になるかもしれません。 テストパターン組み込み: テスト用に複数用意したクリエイティブを組み込み、A/B テストツールを利用して、ランダムにアクセスが発生するように設定します。独自形式のアプリケーションであれば、クリエイティブの切り替え処理のための独自の仕組みが必要になるかもしれません。 計測設定: A/B テストツールでは、ゴール設定を行うことで、成果を自動計測できます（例えば、購入完了のページをゴールとする）。 配信設定: 配信対象のユーザや端末を設定します。 動作検証: 本番環境でのテストの前に、正しく動作するかの検証を行います。 テスト開始: 本番環境でテストを開始し、モニタリングを行います。 (4) 結果分析と本番環境への反映 テスト結果の分析: テスト結果のデータを取得し、その原因を分析します。セグメント別の解析や、Google Analytics などによる解析結果を利用し、分析結果のサマリー文書を作成します。 本番環境への反映: テストで改善効果の高かったパターンを、本番サイトに適用します。 次のテスト立案: 分析結果のサマリーをもとに、次ラウンドのテスト計画へ進みます。"
},
{
url: "/p/xcvvkie/",
title: "2017-06-29 情報収集の前に意思決定プロセスを決める",
date: "2017-06-29T00:00:00Z",
body: "2017-06-29 情報収集の前に意思決定プロセスを決める ちきりんさんの「自分のアタマで考えよう」より。 意思決定プロセスが明確になる前に、やみくもに情報収集を始めても、時間ばかりがすぎて何も決まらないという指摘。ふわっとしたプロジェクトではありがちな話でドキッとしました。 意思決定の判断基準が明確になっていれば、そのために必要な情報だけを集中して集めればよいので、無駄に情報収集に時間をかけてしまうのを防ぐことができます。情報の探しやすさも上がるでしょう。 情報収集という作業自体は、何のために情報を集めているのかが何となく分かっていれば始められてしまいます。でもそれだと、どれだけ情報を集めればよいか明確ではなくて、延々と情報収集に嵌ってしまう。そうではなく、意思決定プロセスがこうなっているから、その決定のために必要なこんな情報を集める、とちゃんと意識するようにすれば仕事の効率は上がりそうです。"
},
{
url: "/p/poesfyd/",
title: "2017-06-23 IPO 銘柄に値段がつかない",
date: "2017-06-23T00:00:00Z",
body: "2017-06-23 IPO 銘柄に値段がつかない 当選すれば必ず儲かるという伝説の IPO 銘柄（新規上場銘柄の株）についに当選しました！ 同僚が。 いろんな証券会社で２年くらい申し込み続けてやっとゲットしたらしいです。 ディーエムソリューションズ (6549) というダイレクトメール事業などを行っている会社で、上場日は値段がつきませんでした。 あれ？ 成行の売りが入っているのにどうして少しも売買成立しないの？ たしかに。 普通は少しでも成行売りが入っていたら、引け後（15:00）には必ず売買成立するのになんでだろうと思って調べてみたら、新規上場後の初値だけは、売り数と買い数が完全に一致するまで値段がつかないみたいですね。 だから、買いたい人がたくさんいれば、値段がつかず、次の日に持ち越されると。 初値で確実に売りたければ、成行売りを入れておけば OK ってことですね。 （結局、２日目に初値がついて、公募価格の約３倍になったみたいです。うらやましー）"
},
{
url: "/p/7pd9985/",
title: "2017-06-19 ゆるく考えよう",
date: "2017-06-19T00:00:00Z",
body: "2017-06-19 ゆるく考えよう ちきりんさんの『「自分メディア」はこう作る！』という本がおもしろかったので、最初の著書である『ゆるく考えよう』も読んでみました。 外資系企業で働いてきた彼女が達した境地は、 自由に生きる、楽観的に生きる ということ。バリバリ働いてきた彼女だから、資産などに余裕があるっていう面もあると思うけど、幸せな人生を過ごすにはこういう考えをベースにして生きていくって大切ですよね。 自由に生きるといっても、何も考えずに過ごすのではなくて、ちきりんさんは**「インプットとアウトプット」のバランス**を重視してます。英語を勉強するときも、自分にどんなアウトプットが必要なのかを考えて、インプットの量を考えているから、無駄に勉強する必要がないし、その分だけ自由に生きることができる。アウトプットに必要なインプットがあればいい。 人生って結局、有限な時間をどのように使うかですよね。だから、その時間をどう過ごすのかを考えることは本当に大切なことだと思います。趣味のために時間を使うのか、仕事に没頭するのか、家族といっしょに過ごすのか。それをちゃんと考えた上で、有意義なものだと思えば、のんびり過ごすのは全然問題ない。ちきりんさんは逆に、「いつも予定が入っていることがいいこと」と考える人は下品だと切り捨ててます。さすがです。 これを読んで、ユダヤ人は休日は徹底して働かないという話を思い出しました。安息日である土曜日（シャバット）は、料理もせず、遠出もせず、とにかく休んで家族と過ごす。よりよく生きるということを追求すると、働かないで過ごす時間をいかに確保するかってとこに行き着くのかもしれないですね。 ちなみに、わたしたちは１週間が７日というのを常識だと思って暮らしていますが、もともとこの週７日という概念を作り上げたのもユダヤ人です。この週という概念がなければ、わたしたちは毎日毎日働きづめだったかもしれません。時間をどのように使うかの指針を与えてくれるこの発明は、自動車の発明よりも、インターネットの発明よりもすごいと思いませんか？ 「働かない生活」を選んだちきりんさんですけど、別にバリバリ働く生活を否定しているわけではないんですよね。もし、今の仕事が本当に楽しくて楽しくてしょうがない、とても価値のあることだ、というのであれば、仕事に人生のほとんどの時間を割いてしまってもよいんじゃないかな、と思います。でもまくは、やっぱりある程度は余裕を持って生きていきたいなぁ。 というわけで、まくのブログも、ゆるゆるな感じにしていこうと思います。"
},
{
url: "/p/z5xn5b5/",
title: "2017-06-18 ブログで日記を書くときに気をつけること",
date: "2017-06-18T00:00:00Z",
body: "2017-06-18 ブログで日記を書くときに気をつけること ちきりんさんの書籍を読んで、日記を書くときに気をつけること、ブログの価値を上げるために大切なことをまとめてみました。 日付は目立つようにレイアウトすること。 URL にも日付を含んでいると後々わかりやすい。 独自ドメインにこだわらない。内容で信用度を上げることの方が大切。 サイトの第一印象を上げたいのであれば、トップの部分（スクロールせずに表示される部分）には広告を入れない方がいい。 いきなり読者を集めようとしない。ブログが未熟なうちに読者を集めようとするより、おもしろい記事がたくさん集まったあとで、ブログを見つけてもらった方がいい。 特定の人を傷つけるようなこと、批判するようなことを書かない。そんなブログは質が高いとはいえない。実際にその人たちに会うことになったときのことを考える。 新しいコンテンツは必ず自分のサイトに載せる。ビジネスサイトからの依頼で記事をそちらに書くということをしていると、自分のメディアの価値が下がってしまう。転載を許可するような場合は、掲載期間をつけるのがよい。 ディスる、オワコン、ステマといったネットの中の人だけが使う言葉を使わない。 ネットの世界で話題になっていることを、世間一般で話題になっていると勘違いしない。 コメント欄があることでサイトの質が下がってしまうのであればコメント欄は外す（スパムとか広告とか投稿されるような場合）。 言われてみればもっともな感じですけど、小手先のテクニックで読者を集めようとしたり、収益を得ようとしたりしてしまいがちですよね。アクセスを稼ぐために、派手なタイトル（「○○するために必要な 10 のコト」みたいな）を付けるのも、本質的なブログの価値（記事の質）を上げているわけではないです。肝に命じておきたいです。 あと、ちきりんさんは、実名や外見を晒さないようにしていますが、これは次のようなリスクを考慮してのこと。 家族にまで影響が及ぶかもしれない 会社勤めの人は、その会社にまで影響が及ぶかもしれない 周りの目を気にした行動をとってしまうかもしれない（見栄を貼って高いものを買うとか） 自分を売り込むために、自分の写真を載せて、実名でブログを書く、ということが流行っていますが、こういったリスクはちゃんと考えておきたいですね。信頼度を上げるために自分の写真を載せるとよい、といったアドバイスがあったりしますが、信頼度は質の高い記事を書き続けることで上げていくべきもの。本当にブログが有名になってしまったら、芸能人と同じようにプライベートがなくなってしまうかもしれません。まくはそんな生活は嫌だ。"
},
{
url: "/p/kad9cep/",
title: "2017-06-17 読んでもらおうと意識しすぎない",
date: "2017-06-17T00:00:00Z",
body: "2017-06-17 読んでもらおうと意識しすぎない 近くの図書館に行って、「Chikirin の日記」のちきりんさんの本を読みました。 アフィリエイトでお金を稼ごう的な書籍がたくさん刊行されている中で、ちきりんさんのブログに対する考え方はグッとくるものがありますね。 「Chikirin の日記」は 2005 年から始まっていますが、彼女はブログを始める前から 25 年間も紙の日記をつけていて、日記は基本的に自分のためのものでした。なので、そもそもブログを始めるときに「はじめまして」みたいに読者のことを意識した書き方はしていないし、ブログで集客しようなどとも考えていませんでした。日記を書くためにネタを探すということはなく、自然な日常の行為として日記を続けています。 ブログが続かないという人は、ちきりんさんみたいに、「自分が考えたこと」を記録として残すだけ、くらいに考えれば簡単に続けられるかもしれません。 まくが見習うべきと思ったところは、自分のやりたいこと、ブログの目的やゴールをちゃんと意識して、その通りに行動しているところ。ちきりんさんのゴールは、 自分のブログを価値あるメディアに育てる ということ。彼女の定義では、「価値あるメディア」とは読者が似通っていて、絞り込まれているメディアのこと。例えば、読売新聞より日経新聞、地上波放送よりCS放送、というイメージです。自分の記事に共感してくれる「想定読者」を増やすことで、自分の意見を発信する場であるブログというメディアの価値を上げることを目標としています。たしかに月間 200 万 PV もあれば、発信力、影響力は大きなものになりますね。 そんな風にちゃんとゴールを設定して生活しているから、仕事を引き受けるべきか迷ったときに、「手間をかけずにブログの想定読者を増やすことができるか」、「ブログの価値を上げられるか」、という基準で判断することができます。 人生は 30000 日しかありません。自分のやりたいことやゴールを設定して、そこに一歩ずつ近づけるように毎日の行動を決めていきたいですね。 そんじゃーね。"
},
{
url: "/p/2vu66jo/",
title: "2017-06-13 NURO 光がやっと開通、遅すぎて速すぎ！",
date: "2017-06-13T00:00:00Z",
body: "2017-06-13 NURO 光がやっと開通、遅すぎて速すぎ！ まくの家（賃貸）にも NURO 光がやってきました。４月下旬に申し込んでいたけどやっと開通です。やっとテザリング生活から解放された〜よ。噂通り、開通まではものすごく待たされて、1.5ヶ月近くもかかったけど、インターネットの通信速度は爆速でした。 なんということでしょう。545.11Mbps 出てます。これで作業が100倍はかどる・・・といいなぁ。 しかもこれ計測している裏で Netflix 再生してますからね。Netflix の再生もめちゃ速いです。Netflix はフレッツ光のときからサクサクでしたけど、NURO 光にしてからはもっとサクサクです。ロード時間なし。 NURO 光は、申し込みは早めにしないと待ち時間が大変ですけど、キャンペーン適用して料金もお得ですし、この爆速感はすばらしぃです。"
},
{
url: "/p/y2kvx5f/",
title: "配色サンプル (Color Combination)",
date: "2017-06-12T00:00:00Z",
body: "配色サンプル (Color Combination) table { margin-left: auto; margin-right: auto; max-width: 90%; left-margin: auto; right-margin: auto; } http://www.honda.co.jp/kids/ より #8bc7ed (R139 G199 B237) #f8aaca (R248 G170 B202) #c1d93b (R193 G217 B59) #f2f0e9 (R242 G240 B233) #906c3a (R144 G108 B58) #ffc823 (R255 G200 B35) http://blend-design.jp/ より #7fc67f (R127 G198 B127) #82d8d8 (R130 G216 B216) #d1a5db (R209 G165 B219) #f78d7f (R247 G141 B127) #dbb583 (R219 G181 B131) #f4c551 (R244 G197 B81)"
},
{
url: "/p/akojpbr/",
title: "2017-06-04 お名前.com で独自ドメインとって WordPress を共用サーバー SD ではじめてみた",
date: "2017-06-04T00:00:00Z",
body: "2017-06-04 お名前.com で独自ドメインとって WordPress を共用サーバー SD ではじめてみた お名前.com でドメイン をとって、ついでに お名前.com のレンタルサーバー （共用サーバーSD）も借りました。 同じところでドメイン＆サーバー設定してしまえば、いろんなサイトの説明にまどわされることもないし楽ですよね。 お名前.com のレンタルサーバーであれば、稼働率99％以上保証という安定性があり、独自SSLが月額100円から使えるというところも決め手でした。SSL 対応すれば、Google の検索ランクにもプラス評価されるため、アクセスを集めるにはもはや SSL 対応は必須という状況になってきました。 早速、お名前.com 共用サーバーで WordPress を簡単インストールしようと思い、WordPress インストールボタンをポチッとしたら、 事前にインストールするドメインのネームサーバーを、弊社指定のネームサーバーに変更をお願いします。 というエラーが発生。。。 これは、独自ドメインを運用する DNS サーバーが、「お名前.com 共用サーバで提供されている DNS サーバ (dns01.gmoserver.jp)」に設定されておらず、「お名前.com（ドメインサービス）で提供されている DNS サーバ (dns1.onamae.com)」に設定されているということです。 共用サーバーと同時にドメイン取得したんだから、デフォルトで共用サーバー側の DNS へ結びつけてくれてもいいのに、このあたりの設定は結局自分でやらなきゃなんですね ^^; あれ？？ドメインもレンタルサーバーもお名前.com で頼んだのに、 全然楽になってない！ まぁ、そんなもんだと思ってあきらめます。でも、お名前.com（GMO）もっとがんばれ！ 固定 IP アドレスを提供しているレンタルサーバーであれば、お名前.com の DNS サーバを使い続けたまま、A レコード設定によって「独自ドメイン → 固定 IP アドレス」という結びつけができます。 でも、お名前.com 共用サーバーSDは、 メンテナンス等の影響で変動する場合もございますので、非公開とさせていただいております。共用サーバーSDプラン/ホームページエディタープランではお客様個別の固定IPアドレスのご用意はございません。 サーバーのIPアドレスを教えてください - お名前.comヘルプセンター と言っているので、独自ドメインを管理する DNS サーバ自体を、お名前.com の DNS サーバーから、お名前.com 共用サーバーの DNS サーバーに変更しなければいけません。 【レンタルサーバー】ネームサーバー（DNS）を教えてください 独自ドメインを管理する DNS サーバを変更するには、お名前.com のドメイン Navi から設定を行います。 「ドメインNavi」ログインページ｜お名前.com ネームサーバーの変更｜ドメイン取るならお名前.com DNS サーバーの変更設定は 24〜72 時間ほどかかるというので、気長に待ちます。 独自ドメインが現在どの DNS サーバで設定されているかは、nslookup コマンドで確認できます。 $ nslookup \u0026gt; set type=NS \u0026gt; maku.blog ... Non-authoritative answer: maku.blog nameserver = dns1.onamae.com. maku.blog nameserver = dns2.onamae.com. 上記で、dns1.onamae.com と表示されるということは、お名前.com のデフォルトの DNS からまだ変更できていないということ。ここが、dns01.gmoserver.jp という表示に変わるまでまちましょう (-.-)Zzz しばらくすると（1日くらい？）、WordPress の簡単インストールが実行できるようになります。 で、無事にインストールが完了して、独自ドメインにアクセスすると、再びこの画面へ。。。 図: このドメインは、お名前.com で取得されています。 しょうがないのでもう1日程度待ちます (-.-)Zzzzzz 独自ドメイン取得はこちらから → レンタルサーバーはこちらから →"
},
{
url: "/p/s7d2r2f/",
title: "読書メモ『シンプルに生きれば、すべてがうまくいく！』西村豪庸",
date: "2017-05-27T00:00:00Z",
body: "読書メモ『シンプルに生きれば、すべてがうまくいく！』西村豪庸 感想 ★★★★☆ 4/5点。 事業の失敗や、離婚などを経てどん底に落ちた著者が、シンプルに考え、生きていくことの大切さを説いてくれます。モノや情報に溢れているこの世の中で、幸せになるためのカギは、「シンプル」のひとことに尽きるのかもしれません。 シンプルに生きれば、すべてがうまくいく！ 西村豪庸 KADOKAWA / 中経出版 読書メモ 第一章「身の回りを片付け、潜在意識を汚さない」 モノはすべて引き出しなどに収納して、外に出さない。 何がどこに入っているのか、すべて言えるくらいがちょうどいい。 モノを残す基準は、火事が起きたときに持ち出すもの。 迷ったら「とりあえずボックス」に入れて、置くべき場所を検討する（著者の場合はワインの木箱）。定位置と、この場所だけ探せばすべてが見つかるようになる。 荷物が少なければ身軽です。フットワークが軽くなります。─ 「ほぼ手ぶら」くらいのノリで旅に出てみませんか。 第二章「お金と仕事から自由になる考え方」 お金が増える ＝ 選択肢が増える ≠ 幸せになる 幸せなお金持ちというのは、人を大切にする人。 「目の前の人」を大切にして働いていく。 お金持ちはたくさんの水路（収入源）を作ることに努力する。 村全体のことを考えて、みんなと水路を作る。この考え方がコツ。 時給分だけ働くつもりでいると、結果的に損をする。求められたよりも、大きなものを先に与えていくこと。 稼げることより、好きなことの方がうまくいく。ただし、市場があることが条件。 何でもいいので、一番になっておいた方がいい。 ２つ以上の技能を持つことで価値が生まれる（マーケティングと会計を両方知っている、Windows と Mac 両方に詳しい、など）。ひとは何人ものひとに尋ねるよりも、一人のひとから聞く方を選ぶ。 「これだけは譲れない代わりに、ここは我慢する」というセットでアピールした方が、他の人も協力しやすい。 デイトレで成功できた理由は、「上がれ！」とか「下がれ！」とか祈らなくなったこと。 ビジネス体力をつける。１日に10冊くらいの本に目を通す。 第三章「人間関係の問題はわけて単純化する」 自分がコントロールできないことは、悩まない。 最初はとにかく、性善説にのっとって人を信用して付き合う。その結果、協力してくれたら関係を続ける。意地悪されたら付き合わない。 第四章「数字に置き換えてみると明確になる」 どのくらいの資産を持ちたいか、数値化して明確にした方が実現しやすい。 年収3000万円以下の人は、１秒あたり１円も稼いでいない。だから、１円を１秒かけて拾う価値がある。年収３億円以下なら、10円は拾うべき。 上司の評価、職場の評価に応えられなければ、何も始まらない。 第五章「とにかく場数を踏むことが成功につながる」 無能から有能になるためのプロセスは、失敗し続けること。でも絶対に失敗したくないことも決めておく（友達を失うような失敗など）。それ以外はどんな失敗も恐れず、前に進む。 人の成長は二次曲線。最初の伸びない時期にあきらめない。"
},
{
url: "/p/9yzpr65/",
title: "読書メモ『手離す技術』桜井章一",
date: "2017-02-13T00:00:00Z",
body: "読書メモ『手離す技術』桜井章一 手離す技術 桜井章一 講談社 人が本来成すべきなのは、人脈づくりではなく、いい人間関係を築いていくことなのだ。成功のために人間関係があるのではない。いい人間関係の先に成功があるということを忘れてはいけない。 幸せというものはそもそも、求めるものではなく、与えるものなのだ。「まわりの人を楽しませたい」「あの人の笑顔が見たい」、そんな純粋な気持ちで動ける人が、真の意味で「幸福な人」なのである。 結局、欲というのは、シンプルな形態のものであればあるほど、満たされるのである。だからなおのこと、いかにシンプルにできるかが問われてくる。 金とのつき合い方は、「気づいたら金がそこにあった」という程度がちょうどいい。握っているけれどいつでも手離せる感覚。 野菜は八百屋で、魚は魚屋で買うようにする。そのほうが商店街も元気になるし、地域のコミュニティも活性化される。 終わりが終わりなのは「生命の終わり」だけであって、そのほかの終わりはすべて始まりだという感覚を私は抱いている。だから、**たとえなにかを失ったとしても、「今度得ることの始まりだ」**と思えるのだ。 人間は、手に入れた知識や情報といったものをなかなか排出しようとしない。利益や利権、権力といったものにも、いつまでもしがみついていたりする。本来であれば、そういったすべてのものも、便や尿のように排出すべきものなのである。 上の立場の人間は、「いいことはすべて人のおかげ」にするのがいい。そうしていると、不思議と生きていく中で「文句」や「不平不満」というものがなくなっていく。 人は往々にして金、権力、情報など、「掴めるもの」にばかり価値を見出してしまう。しかし私は、「掴めないもの」こそ、大切であるといつも思っている。自分のまわりにある、掴めないものの存在を知り、感じることで、人間の本能や感覚といったものは研ぎ澄まされていく。"
},
{
url: "/p/pk9h87c/",
title: "読書メモ『僕らが毎日やっている最強の読み方』佐藤優／池上彰",
date: "2017-01-01T00:00:00Z",
body: "読書メモ『僕らが毎日やっている最強の読み方』佐藤優／池上彰 僕らが毎日やっている最強の読み方 佐藤優／池上彰 東洋経済新報社 池上さんおすすめの海外紙は、イギリスの経済紙の『フィナンシャル・タイムズ』。１紙630円と値は張るが、文章が平易で英語の勉強にもなる。一方で、『ニューヨーク・タイムズ』や『タイム』は気取った表現が多い。 『ウォールストリート・ジャーナル』もおすすめ。 佐藤優「dマガジン、ビューンなどの雑誌定額サービスは通勤時の空き時間に読むのがオススメ。無料のネット情報よりも質が高いので、こういったのを利用して時間を有効に使うべき」 まとまった時間には「書籍」を読んで深い知識を付ける。隙間時間には「雑誌」を読んで視野を広げる。 国際情勢を知るには『フォーリン・アフェアーズ・リポート』がオススメ。 ネットの記事は「編集」「校閲」の機能が欠如しているので、時間ばかりを浪費する効率の悪いメディア。やはり「新聞」や「雑誌」がよい。ネット上にも新聞社のサイトはあるが、時系列に記事が並んでしまうため、記事の重要度が分かりにくく時間の無駄になる（新聞を広げたように記事が配置されていればOK）。 ネット上には自分の好きな記事ばかり表示されるようになるので、知識が偏ってしまう危険もある。 調べものはネット記事や Wikipedia のような正しいかどうかわからないものを使うのではなく、まずは百科事典や辞書を使用すること。 東大生は歩きスマホをしている人が少ない。時間の使い方をわかっている。 佐藤優「リアルタイムでテレビを見る回数は、映画館に行く回数より少ない」 池上彰「テレビはまったく見ない」 池上優「どんなジャンルでもベースになる本は３冊以内。そういった本は時間をかけてしっかりと読み込む」 佐藤優「読んでいることで優位に立てるのが古典」"
},
{
url: "/p/ttpeeux/",
title: "読書メモ『ゼロ ─ なにもない自分に小さなイチを足していく』堀江貴文",
date: "2016-09-18T00:00:00Z",
body: "読書メモ『ゼロ ─ なにもない自分に小さなイチを足していく』堀江貴文 ゼロ ─ なにもない自分に小さなイチを足していく 堀江貴文 ダイヤモンド社 感想 ★★★★ 4/5点。 ホリエモンの生い立ちなどが書かれていて親近感が湧くようになります。 起業をすることはみんなが思っているより普通にできることなんだよ、と説いてくれます。 会社員として働き続けることに疑問を持っている人にはオススメです。 メモ **やりたいことは「できっこない」という心のフタを外せば湯水のように溢れ出てくる。**やりたいことがないという人は最初から「できっこない」とあきらめている。 **わずかな期間でも会社経営を経験しておくと、ビジネススキルは飛躍的に向上する。**会社員を何年続けても身につかない仕事の本質だ。起業は誰でもできると考えるのが普通。この国で働く人のうち20人に1人くらいは経営者。 **お金よりも信用が価値を持つ。**1億円を持っている人が100万人のフォロワーを集めるのは難しいが、100万人のフォロワーを持つ人が1億円を集めるのは簡単。人生の崖っぷちに追い込まれたときに、あなたを救ってくれるのは信用だ。 **信用を得るにはまず自信を付けること。**背伸びしてでもできると言って引き受け、ハードルを越えていく。 **理性の声に従った決断には迷いも後悔もない。**感情に流された決断は後悔に襲われる可能性がある。ひとつの熟考よりも三つの即決。悩むことと考えることは違う。 自ら生み出した仕事に臨んでいるとき、あなたは「自分の時間」を生きている。 与えられた仕事をやらされているとき、あなたは「他人の時間」を生きている。 **やりがいというのは自ら「仕事をつくる」ことによって生まれる。**やりがいというのは仕事の内容ではなくて、「取り組み方」の問題だ。能動的に取り組むというプロセス自体が「仕事をつくる」ということ。 **没頭することで何かを好きになる。**没頭さえすればいつの間にか好きになる。仕事を嫌いだと思っている人はただの経験不足で、仕事に没頭したことがない人のこと。 自分の都合のいい情報だけでなく、たとえばツイッターでも、自分と意見の合わない有識者を一定数フォローすること。 情報弱者にならないためにも、かたっぱしから情報を取りまくろう。 ゼロ [ 堀江貴文 ] 価格：1512円（税込、送料無料) (2016/9/20時点)"
},
{
url: "/p/edpxk5d/",
title: "読書メモ『99％の会社はいらない』堀江貴文",
date: "2016-09-17T00:00:00Z",
body: "読書メモ『99％の会社はいらない』堀江貴文 99％の会社はいらない 堀江貴文 ベストセラーズ 飽きるのは決して悪いことではない。飽きてしまうということは、その物事にハマった結果だ。形になる前に止めてしまうのはよくないが、形になっているのであれば、それは次の仕事につながっている。 最優先していること以外は基本的にやらなくていい。自分に何ができて何ができないかなんて、自分が一番わかっているはず。だから不得意なところは人に任せてもいい。 ファーストペンギンよりも、セカンドペンギンの方が大事なのである。 「飛び込めば大きなものが得られるかもしれない」と思っているのだが、何かその確証や保険が欲しくなるのかもしれない。 ─ やらない言い訳をしていたら、いつまで経っても変わらない。だから、あまり考えすぎない方がいい。 新しいことをはじめるのは、決して苦しいものではない。なぜなら、面白いことや興味のあることをするからだ。だから、動いてみると、結果として面白いことの方が多いのだ。 大事なのは、ギブ・アンド・テイクではなく、ギブ・アンド・ギブの精神だ。 誰かに一緒に仕事をしたいと思ってもらおうなどとは、これっぽっちも考えていない。 ─ 認めてもらうかどうかは関係なく、お互いにとって何かの面で「Win-Win」の関係になればいい。 レベニューシェアにすることで頑張って事業を大きくしようという気持ちにもなれるし、夢を見ることもできる。その方がお互いにとっていいことだ。 他人に頼ることができなければすべてを自分でやらなければならなくなる。 \u0026ndash; もちろんときには裏切られることだってある。 ─ 裏切られたことはすぐに忘れる。そういうものだと思って行動するのが一番だ。 人が惹かれるスキルこそが、実はコミュニケーションスキルの本質だ。 ─ 資格なんてものは、スキルとしての差別化はまったくない。 「飼い犬」だっていつ飼い主がいなくなるかもわからないし、もしかしたら捨てられてしまうかもしれない。 ─ 自分がいる環境を見つめて欲しい。広い世界を見て欲しい。 行動するのは実は簡単である。バカになればいいのだ。"
},
{
url: "/p/t6nqgcj/",
title: "読書メモ『わたしの外国語学習法』ロンブ・カトー",
date: "2016-09-01T00:00:00Z",
body: "読書メモ『わたしの外国語学習法』ロンブ・カトー わたしの外国語学習法 ロンブ・カトー 筑摩書房 外国語を学習するのは、それ自体が面白いからでもある。 外国語学習に必要な最低限の時間は週10〜12時間。まず何よりも、時間の割り振りのバランスをとること。不可能ならば始める前によく考える。 外国語学習を始めた初日から学習計画に読書を盛り込むこと。能動的に読むこと。 言語から文法を学ぶのであって、文法から言語を学ぶのではない。 最も信頼のおける外国語の担い手は本であり、最も頼りになる教科書である。 パターンを反復する最良の手段が本。どんどん読もう。本は書き込みで真っ黒にしても、バラバラに分解してもよい。単語の無限の反復を保障し得るのは本だけ。 本はわたしたちの誠実な道連れとなってくれる。わたしたちがその本よりも成長するまで。 自分が興味を魅かれるものを読めばよい。映画俳優の本、推理小説、歌、精神医学の本、雑誌類、インテリアや衣類のデザインの本など。 英語は「書き言葉」と「話し言葉」がかなり異なるので、両方（二種類の言葉）を学ぶ必要がある。 心からお勧めしたいのは、学習用に改作され、注釈などを施した本。 外国語で独り言を言うのがオススメ。物を相手に対話するのもよい。 外国に移り住んでも、自発的に学習をしない人は、結局正しく話せるようにはならない。 その国を訪れることが、外国語を習得するための条件ではない。外国にいても、自国にいても、同じ時間をかけて覚え込める量は同じ。 母国語にない発音はウンザリするほどたくさんある。だから、まずは発音の違いが意味の違いを生んでしまうものから取り組む。 ラテン語以外の文字を使用する言語には難しいというレッテルが貼られているが、学んだことのあるものはそれが過大評価だということを知っている。 You may, but you can\u0026rsquo;t. （いいですよ、でもお出来になれんでしょう ー バーナード・ショー） 単語や名前を、真空管にぶら下がった格好で覚えようとするのはダメ。すでに知っている表現や概念と組み合わせることで何らかの情報を付加すると忘れない。語呂合わせでもよい。 自分の個性の反映された単語帳を自作する。類義語が反義語を書き込む。ただし、凝りすぎないこと。本当にその時に必要なものだけを書き込む。 単語の意味をコンテキストから言い当てることができた場合、快い感情を呼び起こしてくれる。何も考えずに辞書を引いたりするより、その成果は強固である。 会話をつなげる役割を持つフレーズに初期から取り組むこと。「かなり」「きっと」「非常に」「もちろん」「つまり」「たしかに」「また」「主に」「おそらく」「むしろ」「ずっと」「やはり」。この種の語句の一覧表を作成し、自動的に口をついて出てくるまで覚え込む。 参考書は日本人向けに書かれたものを使うこと。日本語と異なる概念にページ数を多く割いているから効率が良い。 外国語で語るということは、常に妥協するということだ。 毎日勉強すること。時間がなくても最低 10 分。意欲が減退するようなら、別の形を考える。教科書から離れてラジオを聞くとか、辞書をパラパラめくってみるとか。 独学する場合は、正しいとわかっている表現だけを覚え込むこと。自分で組み立てた表現は間違っている可能性がある。 成句や熟語的表現は、一〜三人称、単数で書き出して覚えること。be 〜 と書き出すのではなく、I am 〜 という実際に使う形で書き出す。 四方八方から攻める。「新聞を読む」「ラジオを聴く」「吹き替えなしの映画を見る」「外国語の講義を聞く」「教科書を使う」「文通する」「出会って会話する」 誤りを犯すことを恐れず、それを直してくれるよう頼む。 自分は目標を達成できるのだと固く確信すること。 土台の構築にこそ最大限のエネルギーが消耗されるのだということを忘れない。スタートを切る前にあきらめないこと。 外国語学習の結果は、次の式で表すことができる。（消費時間 ＋ 関心および意欲）／羞恥心。 誰にでもわかるような簡単な部分に分解し、解釈を組み立てていくようにすればよい。 演説の通訳は参考になる。使っていけない言い回しはしないし、言葉をつなぐ手法に長けている。 わたしの外国語学習法 [ カトー・ロンブ ] 価格：1026円（税込、送料無料) (2016/9/5時点)"
},
{
url: "/p/kgc9pxa/",
title: "読書メモ『ピーター流外国語習得術』ピーター・フランクル",
date: "2016-08-20T00:00:00Z",
body: "読書メモ『ピーター流外国語習得術』ピーター・フランクル ピーター流外国語習得術 ピーター・フランクル 岩波書店 たくさんの外国語を効率に学ぶにはどうしたらいいかというお話。 数学とジャグリングが得意なピーター・フランクル氏が書いてます。 最初の段階では対訳の本を読むのが効率がよい。探偵小説なら先が気になって最後まで読み通すことができる。 単語の丸暗記ではなく、詩を覚えるのがよい。詩は韻をふんでいるし、意味もある。 その言語で独り言を言うのがオススメ。 教科書は一冊だけでなく、何冊か買って勉強すること。いろんな教科書で何度も同じ単語や言い回しに触れることで覚えられる。 達成しやすい目標を立てること。短くて可愛らしい「星の王子さま」であれば、誰でも1ヶ月がんばれば読める。目標は低めに設定することで、ステップを踏んでいけばよい。高すぎる目標を立てると、道のりが遠すぎて、途中であきらめてしまいやすい。 わからない単語は必ずすぐに調べること。何度か出てきてから調べるという方法では、復習のチャンスを失ってしまう。調べた単語は自分用の単語帳に書いておく。次に出てきたときは、市販の辞書ではなく、まずは自分用の単語帳を見ることで復習の効果がある。違う意味で使われていたら、その都度意味を書き加えておく。 作文などの宿題は遊び感覚でやるとよい。例えば、複数の単語を使った作文の宿題なら、強引にひとつの文章に入れてしまうなど。 自分の生まれた国からちょっと離れて、ひろひろな人と交流して戻ってくると、自分のことをもっとよく理解できる。 外国語を勉強するときは、速く読むよりも集中してじっくり味わった方が、単語や言い回しを覚えられる。 同じグループの単語は同じ状況で使うことが多いので、一緒に覚えるのがよい。新しい色を覚えるときは、前に覚えた色をいっしょに思い出すことで復習できる。 他の日本人といっしょに毎日のように食べたり飲んだりする数を減らすべき。特に悪いのはお酒を飲んで酔っ払うこと。酔ってしまうと集中できなくなり、時間を無駄にしてしまう。 日本人の大きな問題は、いつも複雑なことを言おうとすること。努力してでも簡単に言うことが大切。自分のレベルをわきまえて簡単なことしか言わない方がよい。基本の基本を何度も繰り返すことで身に付いていき、長い時間会話することができるようになる。 その人の言語のレベルは「分」という単位で示すことができる。新しく会った人と何分間会話を続けられるかということ。 いつも大きな声で話すこと。自信がなくて間違っているかもしれないと思っても、大きな声でしゃべらないと、相手の反応が分からず、間違った使い方をしていることにも気付けない。間違っているときは、間違ったまま相手にちゃんと聞き取ってもらうことが大切。"
},
{
url: "/p/bsnij2z/",
title: "読書メモ『レバレッジ・シンキング 無限大の成果を生み出す4つの自己投資術』本田直之",
date: "2016-08-03T00:00:00Z",
body: "読書メモ『レバレッジ・シンキング 無限大の成果を生み出す4つの自己投資術』本田直之 レバレッジ・シンキング 無限大の成果を生み出す4つの自己投資術 本田直之 東洋経済新報社 感想 ★★★★☆ 4/5点。 本の中で難度も「レバレッジ」といういかにも新しい考え方っぽい言葉を使ってますが、簡単に言えば「効率化」ということですね。 隙間時間を使うとか、通勤時には読書するとかそういったちょっとした効率化のコツがたくさん書いてあります。 毎日ダラダラと過ごしてしまっているなぁと思っている人には参考になりそうです。 メモ ゴールを明確に描いていると、余計なことをやらないで済むようになる。ゴールを明確に描いていると、普段の生活の中で気付きや出会いが多くなる。チャンスを逃さなくて済む。 仕事がうまくいったときは、なぜうまくいったかを考えて仕組み化しておく。少ない労力で成果を上げることができるようになり、誰かに任せることもできる。 マニュアルが悪いのではなく、マニュアルの使い方が悪い。個々がマニュアルを超えた対応をすればよい。 良い習慣はすばらしい資産。資産を作るつもりで良い行動を習慣化していく。習慣にすれば、その行動に対してのストレスはなくなり、良いスパイラルになっていく。小さな習慣から作っていけばいい。帰宅後部屋が散らかっているのが嫌なのであれば、まずは**「帰宅後に靴を揃える」「今日出したものは今日中にしまう」**といった小さな習慣から作っていく。 読んだビジネス書の冊数を記録していく。記録に残すことで、もっとやろうというマインドが生まれる。 KSF (Key Success Factor) を探すことによって、短時間で大きな成果を上げられるようになる。重要なのは、それ以外のことをやらないということ。受験勉強で過去問をやるのは、勉強しなくてもよいところを探すため。合格ラインとのギャップがわかり、勉強の意欲が湧いてくる。 効率化を考えるときは、同時に何かできないかを考える。「風呂に入るときに読書する」、「通勤中にビジネス書を読む」、「ジョギング中に音声教材を聞く」、「会議に出るときは別の仕事の資料を持ち込んで隙間時間を利用する」など何でもやる。 同時にやって稼ぎに繋げている人もいる。「ガーデニングが趣味な人が緑化事業を立ち上げた」、「マンション購入が考えている人が賢いマンション選びの本を書いた」。 疲れたときこそゴロゴロ過ごすのではなく、普段通り体を動かすとよい。トレーニングすると疲れが取れることに気がついた。 人間が変わる方法は３つしかない。「時間配分を変える」「住む場所を変える」「つきあう人を変える」。 by 大前研一 時間をかけることでよい成果が出るわけではない。短時間で成果を上げることこそ重要。素早く動くということではなく、何をやるかを見極めることが重要。隙間時間を活用することも重要。 スケジュールを逆算して考えるには俯瞰できる月間のカレンダーがよい。 主催者の役割は、会ったその場で皆がお互いのことを知っているという状況にすること。あらかじめメールなどで全員のプロフィールやウェブサイト、著書などを共有しておく。"
},
{
url: "/p/3q8uzoo/",
title: "Nginx の設定: Nginx の設定ファイルの書き方が正しいか確認する (configtest)",
date: "2015-09-21T00:00:00Z",
body: "Nginx の設定: Nginx の設定ファイルの書き方が正しいか確認する (configtest) nginx の configtest コマンドを使用すると、nginx のコンフィグファイルの記述方法が正しいかを確認することができます。 このコマンドは管理者権限で実行する必要があります。 $ sudo /etc/init.d/nginx configtest nginx: the configuration file /etc/nginx/nginx.conf syntax is ok nginx: configuration file /etc/nginx/nginx.conf test is successful"
},
{
url: "/p/6aazmy3/",
title: "Nginx の設定: Nginx の設定ファイルの変更を反映する（再読み込み）",
date: "2015-09-20T00:00:00Z",
body: "Nginx の設定: Nginx の設定ファイルの変更を反映する（再読み込み） nginx の設定ファイル (/etc/nginx/nginx.conf や /etc/nginx/conf.d/*.conf) の内容を変更した場合は、下記のようにして反映することができます。 $ sudo service nginx reload $ sudo /etc/init.d/nginx reload nginx の起動はとても速いので、単純な Web コンテンツだけを提供しているの Web サーバであれば、nginx サービス自体を再起動してしまってもよいでしょう。 $ sudo service nginx restart $ sudo /etc/init.d/nginx restart"
},
{
url: "/p/x2b2gw3/",
title: "ソフトウェアアーキテクトが考えること",
date: "2015-07-21T00:00:00Z",
body: "ソフトウェアアーキテクトが考えること ソフトウェアアーキテクチャとは アーキテクチャとは「要求と設計の橋渡し」である ─『オブジェクト開発の神髄』より 外部から見える特性 構成要素 構成要素間の関係 アーキテクトが考えること 何をもとにシステムを設計するか 部品をどのように組み立てるか システムをどのように動作保証するか パフォーマンス アーキテクチャドライバとは アーキテクチャを決定する要件のことを「アーキテクチャドライバ」といいます。 つまり、アーキテクチャドライバはアーキテクチャ設計のためのインプットとなります。 アーキテクチャドライバには以下の３つの要素があります。 制約（最重要。変更できないものだから） ビジネス制約 技術制約 品質特性 Performance 性能 Modifiability 変更容易性 Usability ユーザビリティ Availability 可用性 Security セキュリティ Testability テスト容易性 主な機能要件（重要性としては一番低い。ほとんどの場合、制約にかかわらず実現できるので） アーキテクチャドライバはステークホルダーとのコミュニケーションの道具であり、このアーキテクチャドライバの作成（文章作成）を行うのがアーキテクトの最初の仕事です。 アーキテクチャ設計のステップ アーキテクチャ要件抽出 アーキテクチャドライバの作成（要求を要件として分類する。上の３つの要素） ステークホルダーと仕様優先度レビュー アーキテクチャドライバに基づくシステムの分割 ソフトウェアアーキテクチャレビュー アーキテクチャドキュメント ソフトウェアは様々な視点で捉えられ、これをビュー (View) と呼びます。 アーキテクチャドキュメントはビューの集合と相互作用の説明で構成されます。 アーキテクトが作成すべき図の例 パッケージ図 パッケージ間の依存関係 それぞれのパッケージに何が配置されるか ソースコードやライブラリの物理構造 コンポーネント図 配置図 物理的なハードウェアやソフトウェアの配置 実行環境を表すノードとの接続関係など アーキテクチャパターン アーキテクチャパターンとは、「アーキテクチャの要素と要素間の関係を使い方の制約と共に特定したもの」です。 ─出展『Principles of software architecture』。 様々なアーキテクチャパターンが提唱されており、GOF のデザインパターンとは違い統一された解釈は存在しません。 Shaw and Garlan \u0026ldquo;Software Architecture\u0026rdquo; ― Shaw と Garlan のリスト Buschmann et al. \u0026ldquo;Pattern-oriented Software\u0026rdquo; ― Buschmann らのパターンシステム Clements et al. \u0026ldquo;Documenting Software Architecture\u0026rdquo; ― CMU SEI のパターンカタログ パターンの説明を覚えるより、「ルール」や「どの品質特性に影響するのか」を理解することが重要です。 例えば、Layered Pattern に関しては、 ルール \u0026ndash; 各レイヤはすぐ下のレイヤのサービスのみ呼び出せる。 特性 \u0026ndash; Modifiability は上がり、Performance は下がる。 といった点を抑えておくことが重要です。 パフォーマンス解析／チューニング Profiling (computer programming)（日本語: 性能解析） Performance analysis - Wikipedia 性能解析 - Wikipedia ページの最後にプロファイラのリストがあります。 Performance tuning - Wikipedia Performance counter Hardware performance counter - Wikipedia Working with Performance Counters - Microsoft TechNet Archive 並列処理に関する制御モデル 並列性を利用するコードは、一般的に 3 種類のモデルに基いて構築されます。 ワーククルーモデル: 類似した一連のタスクを並列的に実行。 ボス、ワーカーモデル: ボスがワーカーに作業を配分。 パイプラインモデル: データを中心に一連のタスクを実行し、データを次のタスクへ渡す。 出展:『Code Reading』"
},
{
url: "/p/phdp2do/",
title: "Linuxコマンド: curl コマンドの使い方メモ",
date: "2015-04-03T00:00:00Z",
body: "Linuxコマンド: curl コマンドの使い方メモ 昔は curl コマンドは Linux 用のコマンドという認識でしたが、Windows 10 には標準搭載されるようになりました。 curl コマンドでファイルをダウンロードする curl コマンドはデフォルトではダウンロードしたファイルを標準出力に出力します。 -o（小文字のオー）オプションや、-O（大文字のオー）オプションを指定することで、ファイルに保存することができます。 指定したファイル名で保存 (-o) $ curl -L http://example.com/sample.zip -o sample.zip （相対パスで指定）（この場合は -O のが早い） $ curl -L http://example.com/sample.zip -o /tmp/sample.zip （絶対パスで指定） ダウンロード元と同じファイル名で保存 (-O) $ curl -L -O http://example.com/sample.zip curl コマンドで POST リクエストを送信する curl コマンドは、ファイルのダウンロードだけではなく、POST コマンドの送信にも使用できます。 REST API を提供する Web アプリのテストなどに利用できます。 $ curl http://localhost:3000/books -d {} ちなみに、wget コマンドの場合は次のように POST リクエストを送信できます。。 $ wget http://localhost:3000/books --post-data=\u0026#39;{}\u0026#39; -O -"
},
{
url: "/p/nao2coz/",
title: "文字コード、フォント関連用語まとめ",
date: "2015-02-10T00:00:00Z",
body: "文字コード、フォント関連用語まとめ 用語まとめ character map / charmap 特定のエンコーディングの文字コードを、glyph index にマッピングするための情報。１つの Font face は複数の charmap を含んでいることが多い。Mac 用の charmap、Unicode（Windows）の charmap など。 charset / 文字セット 「文字集合」と「エンコーディング」をセットにした概念。IANA が定義した。 font collection 複数の font face を 1 つのファイルに含んだもの。 font face font family に、Italic とか Bold とかの区別を加えたもの（ノーマルなものは Regular）。 font family Arial とか Courier とか。 glyph 文字を描画したときの形。フォントファイルは、ビットマップで glyph を持つこともあるし、ベクターデータで glyph を持つこともある。 ligature 合字。２文字以上をくっつくて１文字を表現したもの。 エンコーディング形式 / 文字符号化方式 / CES: Character Encoding Scheme 文字集合内の文字に割り当てられた数値を、コンピュータが実際に使用するバイト列に対応付ける方法。例: Shift_JIS、EUC-JP、ISO-2022-JP スクリプト スクリプト（書体）は言語の文字情報を表す記号の集まりです。スクリプトの例には、ラテン文字、アラビア文字、漢字、ギリシャ文字があります（参考: http://unicode.org/reports/tr24/ ）。 文字コード 文字に割り当てられた数値（バイト表現）のこと。まれに、エンコーディング形式のことを文字コードといったりする。例: 0x0102 文字集合 / 符号化文字集合 文字コードの集合。文字の見た目が同じであったとしても、文字集合ごとに、割り当てられる文字コードは異なる。例: JIS X 0208（JIS拡張漢字） 「文字集合」と、それに適用できる「エンコーディング形式」には関連があります。 例えば、文字集合 JIS X 0208 で使われるエンコーディング形式は ISO-2022-JP、EUC-JP、Shift_JIS などです。 Unicode について Unicode の登場以前は、日本語は JIS X 0208 という文字集合、中国語繁体字は Big5 という文字集合、のように、文字の種類ごとに文字集合を使い分けることが普通でしたが、Unicode ではすべての文字を 1 つの文字集合で表現します。 JIS X 0208 文字集合に含まれていた文字は、すべて Unicode に含まれています。"
},
{
url: "/p/bpvo8h7/",
title: "TV 関連技術",
date: "2014-11-20T00:00:00Z",
body: "TV 関連技術"
},
{
url: "/p/bq86dfz/",
title: "Windows で ARIB 外字を表示できるフォント（Windows TV フォント）",
date: "2014-11-20T00:00:00Z",
body: "Windows で ARIB 外字を表示できるフォント（Windows TV フォント） Windows 7 には、ARIB 外字を表示するフォントファイルがデフォルトで用意されています。 下記のファイルをダブルクリックすれば、インストールすることができます。 ファイル名 含まれているフォント C:\\Windows\\ehome\\WTVGOTHIC-R.ttc Windows TV P丸ゴシック、Windows TV 丸ゴシック C:\\Windows\\ehome\\WTVGOTHIC-RB.ttc Windows TV P太丸ゴシック、Windows TV 太丸ゴシック C:\\Windows\\ehome\\WTVGOTHIC-S.ttc Windows TV Pゴシック、Windows TV ゴシック"
},
{
url: "/p/a3jyhwd/",
title: "文字列の類似度を計算する（LCS: 最長共通部分列）",
date: "2014-11-20T00:00:00Z",
body: "文字列の類似度を計算する（LCS: 最長共通部分列） LCS とは LCS: Longest Common Subsequence（最長共通部分列） 問題とは、2 つのシーケンスから最長の共通部分列を探す問題です。 参考: Wikipedia - Longest common subsequence problem 参考: Wikipedia - 最長共通部分列問題 部分列は飛び飛びの要素で構成されていても構いませんが、順番はキープして作成する必要があります。下記の例は、2 つの文字列とその最長共通部分列 (LCS) を示したものです。 文字列1: \u0026ldquo;ABCDCE\u0026rdquo; 文字列2: \u0026ldquo;ACCDEX\u0026rdquo; LCS: \u0026ldquo;ACCE\u0026rdquo; or \u0026ldquo;ACDE\u0026rdquo; LCS の計算方法 LCS は、動的計画法（DP: Dynamic Programming）の例題としてよく示される問題で、DP を使うことで効率的に答えを求めることができます。 考え方としては、下記のような文字列の入ったスタックから、任意の順番で文字を取り出していく問題だとみなすと分かりやすいです。 どちらか一方から要素を取り出すときは、文字をマッチさせないと考えます。 両方の要素を同時に取り出すときは、そのタイミングで文字をマッチさせる（LCS を構成する要素）と考えます。 このように、任意の順番で取り出してマッチングしていったときに、最大の一致数になったものが LCS ということになります。 ここでは、DP（動的計画法）を使って、文字列 1 と文字列 2 の LCS の長さを求めるコードを考えてみます。 文字列 1 の長さを Len1、文字列 2 の長さを Len2 とします。 dp[i][j] には、文字列 1 の j 文字目までの部分文字列と、文字列 2 の i 文字目までの部分文字列を一致させた場合 LCS の長さを格納します。 まず、0 文字の部分文字列同士の LCS は当然 0 文字なので、 dp[0][0] = 0 となります。 dp[0][i] は、文字列 1 の i 文字目までの部分文字列と、空文字列（文字列 2 の 0 文字目まで）の LCS の長さを示しています。 一方が空文字なので、結局 LCS の長さは 0 です。 同様に、dp[i][0] もすべて 0 です。 dp 配列をテーブルで示すと下記のようになります。 右方向に移動していくのは文字列 1 (\u0026ldquo;ABCDCE\u0026rdquo;) から一文字を取り出して捨てること、下方向に移動していくのは文字列 2 (\u0026ldquo;ACCDEX\u0026rdquo;) から一文字を取り出して捨てることを示しています。 その文字を LCS の候補とみなさずに捨てるだけなので、最大長は変化しません。 取り出そうとしている文字が一致する場合は、LCS の候補としてマッチさせることができます。 このテーブル上では、斜め方向に移動することで表現します。 この斜め移動は、それぞれの文字列から同じ文字を取り出して LCS の文字として採用することを表すので、最大長 +1 ということになります。 dp[1][1] = dp[0][0] + 1 2 つの文字列から 1 文字ずつ取り出す方法は、このように LCS の候補としてマッチさせる方法と、それぞれの文字を LCS の候補とみなさずに捨てる方法（下図）があります。 文字を捨てるだけの場合は、LCS 最大長は変化しないので dp[1][1] = 0 のままです。 dp[i][j] には、i 文字、j 文字を消費するパターンのうち、LCS 長が最大になる値を格納すればよいので、結果として dp[1][1] は 1 と求まります。 ここまでの処理は下記のような漸化式として表現できます。 dp[i][j] は下記の最大値: * dp[i][j-1] ＃左から進んでくるケース（文字列 1 から一文字削除） * dp[i-1][j] ＃上から進んでくるケース（文字列 2 から一文字削除） * dp[i-1][j-1] + 1 ＃LCS の候補とみなした場合（同じ文字の場合のみ） i, j の小さい順に求めていくと、dp 配列全体の値が求まり、最終的に以下のようになります。 右下の値 (4) が LCS 最大長を表しています。 斜めに進んでいる部分が、文字をマッチさせたタイミングを表していて、LCS の候補として \u0026ldquo;ACCE\u0026rdquo; と \u0026ldquo;ACDE\u0026rdquo; の二通りがあることが分かります。 Java による LCS の実装例 下記は Java で LCS を求めるサンプルコードです。 LcsSample.java public class LcsSample { /** * Calculate the length of the LCS (Longest Common Sequence). * * @param s1 the first string to be compared, not null * @param s2 the second string to be compared, not null * @return the length of the LCS * @see http://en.wikipedia.org/wiki/Longest_common_subsequence_problem */ public static int lcs(String s1, String s2) { int len1 = s1.length(); int len2 = s2.length(); // 配列初期値は 0 なので dp 配列の初期化は不要 int dp[][] = new int[len2 + 1][len1 + 1]; for (int i = 1; i \u0026lt;= len2; ++i) { for (int j = 1; j \u0026lt;= len1; ++j) { dp[i][j] = Math.max(dp[i - 1][j], dp[i][j - 1]); if (s1.charAt(j - 1) == s2.charAt(i - 1)) { dp[i][j] = Math.max(dp[i][j], dp[i - 1][j - 1] + 1); } } } return dp[len2][len1]; } public static void main(String[] args) { System.out.println(lcs(\u0026#34;\u0026#34;, \u0026#34;A\u0026#34;)); // 0 System.out.println(lcs(\u0026#34;AC\u0026#34;, \u0026#34;AB\u0026#34;)); // 1 \u0026#34;A\u0026#34; System.out.println(lcs(\u0026#34;ABC\u0026#34;, \u0026#34;ACB\u0026#34;)); // 2 \u0026#34;AB or \u0026#34;AC\u0026#34; System.out.println(lcs(\u0026#34;AGCAT\u0026#34;, \u0026#34;GAC\u0026#34;)); // 2 System.out.println(lcs(\u0026#34;ABCDCE\u0026#34;, \u0026#34;ACCDEX\u0026#34;)); // 4 \u0026#34;ACCE\u0026#34; or \u0026#34;ACDE\u0026#34; } } 実は、dp[i][j] を更新する部分は、次のように最適化することができます。 if (s1.charAt(j - 1) == s2.charAt(i - 1)) { dp[i][j] = dp[i - 1][j - 1] + 1; } else { dp[i][j] = Math.max(dp[i - 1][j], dp[i][j - 1]); } 斜めに移動できるケースの場合は、必ず斜めに移動させた方が LCS の最大長を +1 できて有利だからです。 さらに、一行ずつ dp 配列を求めていることを考えると、実は二次元配列ではなく、一次元配列を使って計算することもできます。 private static int lcs(String s1, String s2) { int len1 = s1.length(); int len2 = s2.length(); int[] dp1 = new int[len1 + 1]; int[] dp2 = new int[len1 + 1]; for (int i = 1; i \u0026lt;= len2; ++i) { for (int j = 1; j \u0026lt;= len1; ++j) { if (s1.charAt(j - 1) == s2.charAt(i - 1)) { dp2[j] = dp1[j - 1] + 1; } else { dp2[j] = Math.max(dp2[j - 1], dp1[j]); } } // Swap buffers int[] temp = dp1; dp1 = dp2; dp2 = temp; } return dp1[len1]; }"
},
{
url: "/p/xjw9ju7/",
title: "文字列の類似度を計算する（レーベンシュタイン距離）",
date: "2014-11-18T00:00:00Z",
body: "文字列の類似度を計算する（レーベンシュタイン距離） レーベンシュタイン距離とは レーベンシュタイン距離 (Levenshtein Distance) は、ある文字列に対して、何回の変更処理（削除、挿入、置換）を行えば対象の文字列に変換できるかを示します。 参考: Wikipedia - Levenshtein distance 参考: Wikipedia - レーベンシュタイン距離 レーベンシュタイン距離を効率的に計算するために、一般的に DP マッチング（動的計画法による距離計算）が使用されます（ここでは文字列間の距離を求めていますが、DP マッチングは単純に二つの波形を伸縮させながらマッチングするためにも使用されます）。 下記に詳細なマッチングの過程を示します。 2 つの文字列のレーベンシュタイン距離を求める 次のような文字列 A と文字列 B のレーベンシュタイン距離を求めるとします。 文字列 A = \u0026ldquo;CARROT\u0026rdquo; 文字列 B = \u0026ldquo;CAT\u0026rdquo; 文字列 A の文字数が i 文字、文字列 B の文字数が j 文字だとした場合の距離（最短変換数）を格納するための dp 配列を用意します。 dp[LenA + 1, LenB + 1] 下記の図は、この配列を表にしたものです。 セル内の数値は文字列を一致させるのに費やした変換手順数を表しており、dp[0, 0] は文字列 A も文字列 B も空文字だった場合の距離なので 0 です（空文字から空文字に変換するまでの手順数です）。 この表に左下から順番に手順数を埋めていき、最終的に右上の G が示している dp[7, 4] に文字列 A と文字列 B の距離が格納されます（\u0026ldquo;CAT\u0026rdquo; を \u0026ldquo;CARROT\u0026rdquo; に変換する手順数）。 ここでは、 文字列 B (\u0026ldquo;CAT\u0026rdquo;) を文字列 A (\u0026ldquo;CARROT\u0026rdquo;) に変換するためにかかる手順数 を求めていきます。 文字列 A を文字列 B に変換するためには逆の変換手順を行えばよいので、その手順数も同じになります。 dp[1, 0] は文字列 A の文字数が 1 文字（つまり \u0026ldquo;C\u0026rdquo; という文字列）、文字列 B の文字数が 0 文字（つまり空文字）だった場合に、文字列 B を文字列 A に変換するのにかかる手順数を示します。 この場合は、 空文字列 B に \u0026#34;C\u0026#34; という文字を追加して文字列 A に一致させる という手順で一致させることができるので dp[1, 0] = 1 です。 dp[1, 0] の時点で構成される文字列は \u0026ldquo;C\u0026rdquo; です。 dp[2, 0] は空文字列 B を、文字列 A (\u0026ldquo;CA\u0026rdquo;) に一致させるための手順数を表します。 ここでのポイントは、dp[2, 0] を求めるときに、すでに計算済みの dp[1, 0] の値を利用して計算できるということです（動的計画法の考え方）。 dp[1, 0] には 1 文字目 (\u0026ldquo;C\u0026rdquo;) までを一致させるための手順数が格納されているので、あと 1 文字追加して 2 文字目まで (\u0026ldquo;CA\u0026rdquo;) を一致させるための手順数は次のような計算で求められます。 dp[2, 0] = dp[1, 0] + 1 = 2 同様に繰り返していくと、dp[6, 0] の時点で構成される変換後の文字列は、\u0026ldquo;CARROT\u0026rdquo; となり、変換手順数は 6 になります。 この過程で文字列 B（空文字列）が \u0026ldquo;CARROT\u0026rdquo; に変換されていく様子を示すと以下のようになります。 簡単にいうと、文字を 1 文字ずつ追加する操作を 6 回行っているだけです。 ようするに、右方向への移動は、文字列 B への文字の追加を表しています。 上方向への移動は、逆に文字列 B から文字を削除して文字列 A に合わせていく操作を表します（もう一度繰り返しますが、ここでは、文字列 B (\u0026ldquo;CAT\u0026rdquo;) を文字列 A (\u0026ldquo;CARROT\u0026rdquo;) に変換する手順数を計算しています）。 下記は、文字列 B（\u0026ldquo;CAT\u0026rdquo;) から 3 文字の削除を行い、文字列 A（空文字）に一致させる操作を表現しています。 3 回の削除なので、dp[0, 3] = 3 となります。 変換後の文字列は空文字 \u0026quot;\u0026quot; です。 次に dp[1, 1] を見てみます。 dp[0, 1] の \u0026quot;\u0026quot; の状態からの変化を考えると、\u0026ldquo;C\u0026rdquo; という文字を追加すれば文字列 A (\u0026ldquo;C\u0026rdquo;) に一致させることができます。 dp[1, 1] = dp[0, 1] + 1 = 2 上、右、と進む動きは、文字列 B から \u0026ldquo;C\u0026rdquo; を削除して、\u0026ldquo;C\u0026rdquo; を追加するという操作を示しています。 よく考えると同じ文字を削除して追加することは無駄な操作なのですが、あくまで、上方向への動きは文字列 B からの文字削除、右方向への動きは文字列 B への文字追加、というステップで変換していくことを表すので、この場合の合計手順数は 2 となります (dp[1,1] = 2)。 dp[0, 1] の状態から進んでくる場合も同様に、dp[1, 1] = dp[0, 1] + 1 = 2 です。 この場合は、右、上と進んでくるので、文字列 B に対して \u0026ldquo;C\u0026rdquo; を追加してから、\u0026ldquo;C\u0026rdquo; を削除するという操作をしていることになります。 つまり、文字列 B に対して、以下のような変換操作をしています。 \u0026#34;C\u0026#34; =\u0026gt; \u0026#34;CC\u0026#34; =\u0026gt; \u0026#34;C\u0026#34; 無駄ですね。 そこで次に考慮するのが 斜め方向の移動 です。 斜め方向の移動は、 変換を行わずに文字を一致させる（手順数＋0） 文字列 B 側の文字を置換して文字列 A 側の文字に一致させる（手順数＋1） のいずれかを表現します。 今回のケースでは、文字列 A と B の 1 文字目はともに \u0026ldquo;C\u0026rdquo; という同じ文字なので、追加や削除の手順を踏まず（変換せず）に一文字目を一致させることができます。 なので、dp[1, 1] = dp[0, 0] + 0 = 0 という手順数で文字列を一致させることができます。 dp 配列にはそこに至るまでの最少手順数を格納するので、dp[1, 1] = 0 で確定です。 最初に計算した経路の手順数 2 は冗長なので採用しません。 手順数 0 でも同じ結果 \u0026ldquo;C\u0026rdquo; が得られるので、最少手順数である 0 を採用します。 文字列 A が \u0026ldquo;CARROT\u0026rdquo; ではなく \u0026ldquo;PARROT\u0026rdquo; であったらどうでしょう？ 下の図では、一致させようとしている文字が \u0026ldquo;C\u0026rdquo; と \u0026ldquo;P\u0026rdquo; で異なっているケースを示しています。 レーベンシュタイン距離では、文字の置換も許可しているので、仮に、現在一致させようとしている文字（ここでは 1 文字目と 1 文字目）が異なっている場合、1 回の手順で変換して一致させることができます。 この例では、文字列 B の \u0026ldquo;C\u0026rdquo; という文字を、文字列 A の \u0026ldquo;P\u0026rdquo; という文字に合わせるように置換すればよいので、手順数は 1 となります (dp[1, 1] = dp[0, 0] + 1 = 1)。 重要な点は、dp[1, 1] という状態に至るまでにどのような変換経路をたどってきた場合でも、最終的に得られる結果（文字列 B から文字列 A への変換）は同じであるということです。 つまり、三種類の経路のうち、最小の手順数になるものを dp 配列に記憶していけばよいことになります。 以上のことを踏まえると、下記のような漸化式が導き出せます。 dp[i, j] = min( dp[i-1, j] + 1, dp[i, j-1] + 1, dp[i-1, j-1] + 0 or dp[i-1, j-1] + 1) 最後の or のところは、文字列 A の i 文字目、文字列 B の j 文字目が一致する場合に +0 となります。 異なる場合は、1 文字の置換操作を表すので +1 となります。 これを全セルに対して繰り返していくと、最終的に dp[LenA, LenB] に求める距離が格納されることになります。 右上の値は 3 になったので、最少手順で変換された場合の手順数は 3 回で、レーベンシュタイン距離は 3 ということになります。 変換の手順を示す経路は以下のようになります。 具体的な変換手順はこうなります。 \u0026ldquo;C\u0026rdquo; キープ（手順数 +0） \u0026ldquo;A\u0026rdquo; キープ（手順数 +0） \u0026ldquo;R\u0026rdquo; を挿入（手順数 +1） \u0026ldquo;R\u0026rdquo; を挿入（手順数 +1） \u0026ldquo;O\u0026rdquo; を挿入（手順数 +1） \u0026ldquo;T\u0026rdquo; キープ（手順数 +0） この例では、最小の変換手順は 1 パターンしかありませんが、複数の変換パターンが存在することもあります。 Java による実装例 下記は二次元配列を使用した Java での実装例です。 Levenshtein.java public class Levenshtein { /** * Calculate the Levenshtein distance between two strings. * * @param s1 the first string to be compared, not null * @param s2 the second string to be compared, not null * @return the distance between two strings * @see http://en.wikipedia.org/wiki/Levenshtein_distance */ public static int getDistance(CharSequence s1, CharSequence s2) { int len1 = s1.length(); int len2 = s2.length(); int[][] dp = new int[len2 + 1][len1 + 1]; // dp[0][0] = 0; for (int i = 1; i \u0026lt;= len1; ++i) { dp[0][i] = i; } for (int i = 1; i \u0026lt;= len2; ++i) { dp[i][0] = i; } for (int i = 1; i \u0026lt;= len2; ++i) { for (int j = 1; j \u0026lt;= len1; ++j) { if (s1.charAt(j - 1) == s2.charAt(i - 1)) { dp[i][j] = dp[i - 1][j - 1]; } else { dp[i][j] = Math.min(dp[i - 1][j - 1] + 1, Math.min(dp[i - 1][j] + 1, dp[i][j - 1] + 1)); } } } return dp[len2][len1]; } public static void main(String[] args) { System.out.println(getDistance(\u0026#34;\u0026#34;, \u0026#34;\u0026#34;)); // =\u0026gt; 0 System.out.println(getDistance(\u0026#34;\u0026#34;, \u0026#34;ABC\u0026#34;)); // =\u0026gt; 3 System.out.println(getDistance(\u0026#34;ABC\u0026#34;, \u0026#34;\u0026#34;)); // =\u0026gt; 3 System.out.println(getDistance(\u0026#34;A\u0026#34;, \u0026#34;ABC\u0026#34;)); // =\u0026gt; 2 System.out.println(getDistance(\u0026#34;ABC\u0026#34;, \u0026#34;ABC\u0026#34;)); // =\u0026gt; 0 System.out.println(getDistance(\u0026#34;ABC\u0026#34;, \u0026#34;XXXX\u0026#34;)); // =\u0026gt; 4 System.out.println(getDistance(\u0026#34;CXX\u0026#34;, \u0026#34;XCCX\u0026#34;)); // =\u0026gt; 2 } } 二次元配列の更新は、1 行ずつしか行わないので、実は 2 つの一次元配列を使うだけで実装することができます。 下記は、一次元配列を使った実装例です。 public class Levenshtein { public static int getDistance(CharSequence s1, CharSequence s2) { int len1 = s1.length(); int len2 = s2.length(); int[] dp1 = new int[len1 + 1]; int[] dp2 = new int[len1 + 1]; for (int i = 0; i \u0026lt;= len1; ++i) { dp1[i] = i; } for (int i = 1; i \u0026lt;= len2; ++i) { dp2[0] = i; for (int j = 1; j \u0026lt;= len1; ++j) { if (s1.charAt(j - 1) == s2.charAt(i - 1)) { dp2[j] = dp1[j - 1]; } else { dp2[j] = Math.min(dp1[j - 1] + 1, Math.min(dp1[j] + 1, dp2[j - 1] + 1)); } } // Swap buffers int[] temp = dp1; dp1 = dp2; dp2 = temp; } return dp1[len1]; } } TypeScript による実装例 lib.ts export class StringUtil { /** * 2つの文字列間のレーベンシュタイン距離を求めます。 * 全く同じ文字列であれば、距離は 0 になります。 */ static calcLevenshtein(s1: string, s2: string): number { const len1 = s1.length; const len2 = s2.length; let dp1: number[] = [] let dp2: number[] = [] for (let i = 0; i \u0026lt;= len1; ++i) { dp1[i] = i; } for (let i = 1; i \u0026lt;= len2; ++i) { dp2[0] = i; for (let j = 1; j \u0026lt;= len1; ++j) { if (s1.charAt(j - 1) == s2.charAt(i - 1)) { dp2[j] = dp1[j - 1]; } else { dp2[j] = Math.min(dp1[j - 1] + 1, Math.min(dp1[j] + 1, dp2[j - 1] + 1)); } } // Swap buffers [dp1, dp2] = [dp2, dp1]; } return dp1[len1]; } } 使用例 (main.ts) import { StringUtil } from \u0026#39;./util\u0026#39;; console.log(StringUtil.calcLevenshtein(\u0026#34;\u0026#34;, \u0026#34;\u0026#34;)); // =\u0026gt; 0 console.log(StringUtil.calcLevenshtein(\u0026#34;\u0026#34;, \u0026#34;ABC\u0026#34;)); // =\u0026gt; 3 console.log(StringUtil.calcLevenshtein(\u0026#34;ABC\u0026#34;, \u0026#34;\u0026#34;)); // =\u0026gt; 3 console.log(StringUtil.calcLevenshtein(\u0026#34;A\u0026#34;, \u0026#34;ABC\u0026#34;)); // =\u0026gt; 2 console.log(StringUtil.calcLevenshtein(\u0026#34;ABC\u0026#34;, \u0026#34;ABC\u0026#34;)); // =\u0026gt; 0 console.log(StringUtil.calcLevenshtein(\u0026#34;ABC\u0026#34;, \u0026#34;XXXX\u0026#34;)); // =\u0026gt; 4 console.log(StringUtil.calcLevenshtein(\u0026#34;CXX\u0026#34;, \u0026#34;XCCX\u0026#34;)); // =\u0026gt; 2"
},
{
url: "/p/nvetfsf/",
title: "private メソッドのユニットテストが書きたくなったら",
date: "2014-10-16T00:00:00Z",
body: "private メソッドのユニットテストが書きたくなったら private メソッドをテストすべきかどうかは色々意見がありますが、あるクラスの private メソッドの割合が、public メソッドに比べて非常に多くなった場合は、private メソッドのテストも書きたくなるかもしれません。 そのような場合は、クラス抽出のリファクタリングを考えるとよいです。 特定の処理がクラスとして抽出されれば、そのクラスを利用するインタフェースは public メソッドになるので、自然にテストを記述できるようになります。 もとのクラスの見通しもよくなり、一石二鳥です。 計算処理を担うようなメソッドはテストを記述するよい対象になりますが、private メソッドのままではテストが記述できません。 そのような場合は、public static なユーティリティメソッドに変更することで、テストを記述できるようにするとよいです。 そのメソッド内でフィールドにアクセスしないユーティリティメソッドになっていれば（ステートレス）、オブジェクトに副作用を与えることはないので、public メソッドにしても悪影響は出ません（カプセル化は崩れない）。 JxUnit のように private メソッドをテスト可能なフレームワークを使用するのもひとつの手です。 JxUnit は内部でリフレクションを利用して private メソッドのテストを可能にしています。"
},
{
url: "/p/qj8p3eq/",
title: "Android開発: ShapeDrawable で基本図形を描く",
date: "2014-08-03T00:00:00Z",
body: "Android開発: ShapeDrawable で基本図形を描く 矩形の描画 private ShapeDrawable mDrawable = new ShapeDrawable(); private void draw(Canvas canvas) { mDrawable.setBounds(100, 100, 200, 200); mDrawable.getPaint().setColor(Color.YELLOW); mDrawable.draw(canvas); } 円、楕円の描画 private ShapeDrawable mDrawable = new ShapeDrawable(new OvalShape()); private void draw(Canvas canvas) { mDrawable.setBounds(100, 100, 200, 200); mDrawable.getPaint().setColor(Color.YELLOW); mDrawable.draw(canvas); }"
},
{
url: "/p/2udtaq5/",
title: "Android開発: TextureView に関するメモ",
date: "2014-07-24T00:00:00Z",
body: "Android開発: TextureView に関するメモ 少ない数の Canvas#drawRect() や Canvas#drawText() をするなら、SurfaceView よりも描画が速い。ある程度たくさん描画すると、SurfaceView に負ける。さらにたくさん描画すると同じくらいになる。 ベンチマークを Xperia Tablet Z で取ると次のような感じ。 Rect(x100),Text(x100): SurfaceView 60fps, TextureView 80fps Rect(x500),Text(x500): SurfaceView 32fps, TextureView 27fps Rect(x1000),Text(x1000); SurfaceView 15fps, TextureView 15fps lockCanvas() ～ unlockCanvasAndPost() の中では毎回全体を描き直す必要がある。前回の描画情報が保持されることが保証されないため（TextureView#lockCanvas() の Javadoc を参照）。 SurfaceTextureListener#onSurfaceTextureDestroyed() は通常 return true するように実装する。 画面回転すると強制終了したりする（SurfaceView のときは大丈夫だった）。"
},
{
url: "/p/7jkgzd4/",
title: "macOS で JAVA_HOME に設定すべきパスを調べる（java_home コマンド）",
date: "2014-07-19T00:00:00Z",
body: "macOS で JAVA_HOME に設定すべきパスを調べる（java_home コマンド） 複数の JDK がインストールされている場合にバージョンを切り替えて java (javac) コマンドを使用するには、JAVA_HOME 環境変数を設定します。 JAVA_HOME に設定すべきパスは、java_home コマンドで調べることができます。 下記は、Apple の JDK1.6、Oracle の JDK1.8 がインストールされている場合の出力例です。 $ /usr/libexec/java_home -v 1.6 /System/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Home $ /usr/libexec/java_home -v 1.8 /Library/Java/JavaVirtualMachines/jdk1.8.0_11.jdk/Contents/Home 普段使用する JDK バージョンは、下記のように .bash_profile で設定しておけばよいでしょう。 ~/.bash_profile # JDK 1.6 を使用する場合 export JAVA_HOME=$(/usr/libexec/java_home -v 1.6) # JDK 1.8 を使用する場合（デフォルト） export JAVA_HOME=$(/usr/libexec/java_home -v 1.8)"
},
{
url: "/p/vtfddwb/",
title: "Groovy をインストールする",
date: "2014-05-30T00:00:00Z",
body: "Groovy をインストールする MacOSX に Groovy をインストールする GVM: Groovy enVironment Manager を使うと複数バージョンの Groovy を管理することができます。 ここでは、GVM を使って Groovy の環境をインストールする手順を示します。 1. GVM のインストール $ curl -s get.gvmtool.net | bash これで、.bash_profile に以下のように追加されて gvm コマンドにパスが通ります。 #THIS MUST BE AT THE END OF THE FILE FOR GVM TO WORK!!! [[ -s \u0026quot;/Users/maku/.gvm/bin/gvm-init.sh\u0026quot; ]] \u0026amp;\u0026amp; source \u0026quot;/Users/maku/.gvm/bin/gvm-init.sh\u0026quot; 2. GVM で groovy のインストール $ gvm list groovy # インストール可能なバージョン確認 $ gvm install groovy # 最新版のインストール $ gvm install groovy 2.3.2 # バージョンを指定してインストール これで、groovy や groovysh コマンドが使用できるようになります。 使用中の groovy のバージョンの確認、切り替えは以下のように行います。 $ gvm current # GVM で管理しているコマンドとそのバージョンを確認 $ gvm use groovy 2.3.1 # 使用する groovy コマンドのバージョンを切り替え Windows に Groovy をインストールする Windows では Groovy のインストーラを使用するのが簡単です。 Groovy を http://groovy.codehaus.org/Download のインストーラでインストール（環境変数 GROOVY_JAVA はインストーラから設定できます）。 JDK を http://www.oracle.com/technetwork/java/javase/downloads/ のインストーラでインストール。 環境変数 JAVA_HOME を C:\\Program Files\\Java\\jdk1.8.0_05 などに設定（bin ディレクトリまで指定しないことに注意）。 これで、以下のように Groovy の処理系を使用できるようになります。 C:\\\u0026gt; groovy （ファイルを実行） C:\\\u0026gt; groovysh （対話型の実行） ☝️ dynamic library (jvm.dll) 関連のエラーが出る場合 Windows 用には、groovy.exe と groovy.bat が入っていますが、groovy.bat の方を実行するとうまく起動できます。 拡張子を省略して groovy と実行すると、groovy.exe の方が優先的に実行されてしまうので、groovy.exe を __groovy.exe などにリネームしておくとよいです。"
},
{
url: "/p/jpke2wk/",
title: "数学メモ",
date: "2014-05-06T00:00:00Z",
body: "数学メモ"
},
{
url: "/p/psotadn/",
title: "数学メモ: 平均二乗誤差など",
date: "2014-05-06T00:00:00Z",
body: "数学メモ: 平均二乗誤差など 二乗平均平方根 (RMS: Root Mean Square) $$\\operatorname{RMS}[x] = \\sqrt{\\frac{1}{n}\\sum_{i=1}^n \\left( x_i \\right)^2}$$ 各データの二乗をすべて足して平均をとり、さらに平方根をとったもの。 平均二乗平方根じゃなくて二乗平均平方根って言うんだね。 平均二乗誤差 (MSE: Mean Squared Error) $$\\operatorname{MSE}=\\frac{1}{n}\\sum_{i=1}^n(y_i-\\hat{y_i})^2$$ $y_i$ : 実際の値 $\\hat{y_i}$ : 予測値 予測値とのずれの二乗をすべて足して平均をとったもの。 平均二乗誤差平方根 (RMSE: Root Mean Squared Error) $$\\operatorname{RMSE}=\\sqrt{\\operatorname{MSE}}=\\sqrt{\\frac{1}{n}\\sum_{i=1}^n(y_i-\\hat{y_i})^2}$$ $y_i$ : 実際の値 $\\hat{y_i}$ : 予測値 平均二乗誤差 (MSE: Mean Squared Error) の平方根。 実測値と予測値がどれほど異なっているかを表す。 標準偏差 標準偏差も基本的には RMSE と同じで、予測値の代わりに平均値を使っているだけ。 RMSE: 実測値と予測値のずれ 標準偏差: 実測値と（実測値の）平均値のずれ $$\\operatorname{標準偏差(\\sigma)}=\\sqrt{\\frac{1}{n} \\sum_{i=1}^{n}(x_i - \\bar{x})^2}=\\sqrt{\\frac{1}{n} \\sum_{i=1}^{n}x_i^2 - \\bar{x}^2}$$ $x_i$ : 実測値 $\\bar{x}$ : 実測値の平均値"
},
{
url: "/p/uvusqb7/",
title: "mongo シェルで find() の結果をインデントして見やすく表示する",
date: "2014-03-31T00:00:00Z",
body: "mongo シェルで find() の結果をインデントして見やすく表示する mongo シェルで find() を実行した結果を見やすいように整形するには、実行結果に対して pretty() を適用します。 \u0026gt; db.books.find().pretty() { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;533973de50b35840de2dda25\u0026#34;), \u0026#34;title\u0026#34; : \u0026#34;Title 1\u0026#34;, \u0026#34;tags\u0026#34; : [ \u0026#34;AAA\u0026#34;, \u0026#34;BBB\u0026#34; ] } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;533973de50b35840de2dda26\u0026#34;), \u0026#34;title\u0026#34; : \u0026#34;Title 2\u0026#34;, \u0026#34;tags\u0026#34; : [ \u0026#34;BBB\u0026#34;, \u0026#34;CCC\u0026#34; ] } { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;533973de50b35840de2dda27\u0026#34;), \u0026#34;title\u0026#34; : \u0026#34;Title 3\u0026#34;, \u0026#34;tags\u0026#34; : [ \u0026#34;CCC\u0026#34;, \u0026#34;AAA\u0026#34; ] }"
},
{
url: "/p/qvkkcuj/",
title: "mongo シェルで MapReduce を実行する",
date: "2014-03-31T00:00:00Z",
body: "mongo シェルで MapReduce を実行する mongo シェルを使って、下記のような books コレクションに対して MapReduce をかけて、タグ情報のリスト（tags コレクション）を生成する方法を示します。 { title: \u0026#39;Title 1\u0026#39;, tags: [\u0026#39;AAA\u0026#39;, \u0026#39;BBB\u0026#39;] } { title: \u0026#39;Title 2\u0026#39;, tags: [\u0026#39;BBB\u0026#39;, \u0026#39;CCC\u0026#39;] } { title: \u0026#39;Title 3\u0026#39;, tags: [\u0026#39;CCC\u0026#39;, \u0026#39;AAA\u0026#39;] } 作成される tags コレクションは、以下のようになることを想定しています。 { \u0026#34;_id\u0026#34; : \u0026#34;AAA\u0026#34;, \u0026#34;value\u0026#34; : 2 } { \u0026#34;_id\u0026#34; : \u0026#34;BBB\u0026#34;, \u0026#34;value\u0026#34; : 2 } { \u0026#34;_id\u0026#34; : \u0026#34;CCC\u0026#34;, \u0026#34;value\u0026#34; : 2 } まずは、サンプルデータとなる books コレクションを作成します。 books.js use testdb; // books コレクションの初期化 db.books.drop(); db.books.save({title: \u0026#39;Title 1\u0026#39;, tags: [\u0026#39;AAA\u0026#39;, \u0026#39;BBB\u0026#39;]}); db.books.save({title: \u0026#39;Title 2\u0026#39;, tags: [\u0026#39;BBB\u0026#39;, \u0026#39;CCC\u0026#39;]}); db.books.save({title: \u0026#39;Title 3\u0026#39;, tags: [\u0026#39;CCC\u0026#39;, \u0026#39;AAA\u0026#39;]}); // 確認 print(\u0026#39;books collection has been created\u0026#39;); db.books.find(); $ mongo \u0026lt; books.js 次に、books コレクションに MapReduce をかけて、tags コレクションを生成します。 mapreduce.js use testdb; var map = function() { if (!this.tags) { return; } this.tags.forEach(function(tag) { emit(tag, 1); }); }; var reduce = function(key, values) { var sum = 0; values.forEach(function(val) { sum += val; }); return sum; }; db.runCommand({ mapReduce: \u0026#39;books\u0026#39;, // MapReduce をかけるコレクション map: map, // Map 関数 reduce: reduce, // Reduce 関数 out: \u0026#39;tags\u0026#39; // MapReduce の結果を格納するコレクション }); $ mongo \u0026lt; mapreduce.js 実際に tags コレクションが生成されているか確認してみます。 $ mongo testdb \u0026gt; db.tags.find() { \u0026#34;_id\u0026#34; : \u0026#34;AAA\u0026#34;, \u0026#34;value\u0026#34; : 2 } { \u0026#34;_id\u0026#34; : \u0026#34;BBB\u0026#34;, \u0026#34;value\u0026#34; : 2 } { \u0026#34;_id\u0026#34; : \u0026#34;CCC\u0026#34;, \u0026#34;value\u0026#34; : 2 } できてますね！ 参考: mapReduce — MongoDB Manual"
},
{
url: "/p/4vcr8ji/",
title: "Jade テンプレートエンジンのメモ",
date: "2013-12-30T00:00:00Z",
body: "Jade テンプレートエンジンのメモ"
},
{
url: "/p/q8tw6c4/",
title: "Nginx の設定: Nginx でバーチャルホストを設定する（リバースプロキシ）",
date: "2013-12-03T00:00:00Z",
body: "Nginx の設定: Nginx でバーチャルホストを設定する（リバースプロキシ） アクセス時のドメイン名により別の Web サーバに処理をフォワードする 例えば、http://test.example.com/ というアドレス（80番ポート）で nginx サーバにアクセスしてきたときに、localhost:7000 で動作している Web サーバに処理を委譲するには、下記のように設定します。 /etc/nginx/conf.d/example.com.conf server { listen 80; server_name test.example.com; location / { proxy_pass http://localhost:7000/; } } この機能を利用することで、一つの PC 内に複数の Web サーバを（異なるポート）で立ち上げておき、アクセスしてきた URL（のドメイン名）によって処理を振り分けることができます。 例えば、次のように Web サーバへのアクセスをフォワードできます。 http://aaa.example.com/ でアクセスされた場合 → localhost:7000 で処理 http://bbb.example.com/ でアクセスされた場合 → localhost:7100 で処理 http://ccc.example.com/ でアクセスされた場合 → localhost:7200 で処理 それぞれのドメインは同じ IP アドレスにマッピングされており、物理的には 1 つのマシンに対してアクセスが発生するのですが、クライアント（Web ブラウザのユーザ）から見ると、あたかも異なるホストにアクセスしているかのように見えます（ドメイン名が異なるので）。 バーチャルなホストが存在しているような動作をするということで、このような Web サーバの機能をバーチャルホストと呼びます。 また、このように、サーバ環境側（ここでは 80 ポートのサーバ）でいったんアクセスを受けておいて、アドレス等を見て別の内部サーバ（ここでは 7000 ポートで待ち受けているサーバなど）に処理をフォーワードする仕組みのことを、リバースプロキシと呼びます。 リバースプロキシというのは Web サーバのためだけの仕組みではなく、より一般的なサーバの仕組みを指す名前です。 nginx や Apache などの Web サーバのバーチャルホスト機能は、リバースプロキシの仕組み（概念）を利用して実現されているということです。 アクセス時のドメイン名によりドキュメントルートを切り替える 上記の例では、クライアントからのアクセスを、別々の Web サーバ（例えば同じ PC 内の別のポートで待ち受けている Web サーバ）に振り分ける例でしたが、Web サーバは 1 つだけで、使用するコンテンツファイルのルートだけを切り替えるという方法もあります。 下記の設定例では、aaa.example.com でアクセスされた場合と、bbb.example.com でアクセスされた場合に使用するドキュメント（html ファイル）のルートディレクトリを切り替えています。 /etc/nginx/conf.d/my.conf server { listen 80; server_name aaa.example.com; location / { root /home/maku/website/aaa/public; index index.html index.htm; } } server { listen 80; server_name bbb.example.com; location / { root /home/maku/website/bbb/public; index index.html index.htm; } } この設定により、クライアントからのアクセス時に指定された　URL によって、下記のように参照するファイルが切り替わります。 http://aaa.example.com/ でアクセスされた場合 → /home/maku/website/aaa/public/index.html http://bbb.example.com/ でアクセスされた場合 → /home/maku/website/bbb/public/index.html"
},
{
url: "/p/pms426x/",
title: "Nginx の設定: Nginx の設定ファイル (nginx.conf) の場所",
date: "2013-12-02T00:00:00Z",
body: "Nginx の設定: Nginx の設定ファイル (nginx.conf) の場所 nginx の設定ファイルは、/etc/nginx/nginx.conf です。 ソースからビルドする場合は、./configure の実行時にパスを指定できます。 この設定ファイルの中で、以下のように include ディレクティブが指定されているため、/etc/nginx/conf.d/ ディレクトリ内にある個別の設定ファイル (*.conf) も読み込まれるようになっています。 http { ... include /etc/nginx/conf.d/*.conf; } バーチャルホスト機能を利用して複数ドメインのサーバを運用するようなケースでは、ドメインごとに設定ファイルを分けておくと管理しやすいでしょう。 例えば、example.com ドメインのサーバ用には /etc/nginx/conf.d/example.com.conf を作成します。"
},
{
url: "/p/c3s7wyx/",
title: "Linuxコマンド: rsync コマンドで2つのディレクトリを同期する",
date: "2013-12-01T00:00:00Z",
body: "Linuxコマンド: rsync コマンドで2つのディレクトリを同期する （Windows の場合は、WinSCP をコマンドラインで利用すると同じようなことを実現できます）。 rsync でディレクトリごとコピーする rsync コマンドを使って、src ディレクトリの内容を dst ディレクトリにコピーするには下記のように実行します。 例: src ディレクトリを dst ディレクトリにコピー $ rsync -av src/ dst # src ディレクトリの「中身」を dst ディレクトリ内へコピー $ rsync -av src dst # src ディレクトリを dst ディレクトリ内へコピー -a オプションは、パーミッションやタイムスタンプなどの情報を維持しつつ、ディレクトリを再帰的にコピーする指定をまとめて行うための archive オプションです。 -v オプションは転送情報などを出力する verbose オプションです。 上記例のように、ソースディレクトリの 最後にスラッシュをつけるかつけないかで意味が変わってくる ので注意してください。 2番目のように実行すると、結果として ./dst/src というディレクトリが作成されることになります。 コピー元にないファイルを削除する (\u0026ndash;delete) rsync コマンドはデフォルトでは、コピー先ディレクトリのファイルを削除することはありません。 コピー元 (src) に存在しないファイルを、コピー先 (dst) から削除したいときは、明示的に --delete オプションを付けて実行します。 つまり、2つのディレクトリを同じ内容にしたい（同期したい）のであれば、--delete オプションを付けて実行する必要があります。 例: src の内容を dst に同期させる（src に存在しないファイルは dst から削除する） $ rsync -av --delete src/ dst 指定した拡張子のファイルだけコピーする (\u0026ndash;include) 特定の種類のファイル（png ファイルなど）だけをコピーしたいときは、--include オプションと --exclude を組み合わせて以下のような感じで指定します。 例: src 内の *.png を dst 以下にコピー $ rsync -av --include=\u0026#39;*.png\u0026#39; --include=\u0026#39;*/\u0026#39; --exclude=\u0026#39;*\u0026#39; src/ dst この指定方法は少しわかりにくいので、実際にファイルコピーする前に、-n (--dry-run) オプションを付けて実行して、どのようなファイルがコピーされるのかを確認するとよいです。 rsync でリモートホストへディレクトリをコピーする rsync コマンドは、リモートホストへのファイルコピーにも対応しています（デフォルトで SSH によるファイルコピーが行われます）。 リモートへのファイルコピーを指示したいときは、ターゲットディレクトリの部分を user@hostname:directory というフォーマットで指定します。 ディレクトリ名の部分を省略すると、指定したユーザ (user) のホームディレクトリがコピー先ディレクトリとして使用されます（この場合も、コロン : は省略できません）。 例: リモートホストのホームディレクトリにコピーする $ rsync -rv --delete src user@example.com: 上記のようにすると、ローカルディレクトリ (src) の中のファイルが、リモートホスト (example.com) のユーザ (user) のホームディレクトリにコピーされます。 末尾のコロン (:) を忘れないように注意してください。 これを忘れると、ローカルに user@example.com という名前のディレクトリができてしまいます。 例: リモートホストのコピー先ディレクトリを指定してコピーする $ rsync -rv --delete src/ user@example.com:dst 上記のようにすると、ローカルの src ディレクトリの中身が、リモートの dst ディレクトリにコピーされます。 src の後ろにバックスラッシュ (/) を忘れないように注意してください。 これを忘れると、リモートの dst ディレクトリの下に src ディレクトリができてしまいます。 例: 複数のディレクトリをまとめてコピーする $ rsync -rv --delete src1 src2 src3 user@example.com:dst 上記のようにすると、ローカルの src1、src2、src3 ディレクトリを、リモートの ~/dst ディレクトリへコピーします。 コピー元のディレクトリ名の末尾にスラッシュ (/) を付けずに実行しているので、リモートの ~/dst ディレクトリ内に src1、src2、src3 ディレクトリがそれぞれ作成されます（ディレクトリ内のファイルがコピーされるのではなく、ディレクトリごとコピーされる）。 rsync で SSH 鍵を使ってリモートホストに接続する リモートホスト側の ~/.ssh/authorized_keys に、ローカルホストの SSH 公開鍵を登録しておけば、rsync コマンドでも SSH 鍵による公開鍵認証方式で接続できるようになります。 参考: ssh-id-copy で SSH の公開鍵をリモートホストに登録する rsync コマンドの実行方法は、パスワード認証の場合と変わりませんが、代わりに SSH 秘密鍵のパスワード入力プロンプトが表示されます。 秘密鍵にパスワードを設定していない場合は、パスワードの入力なしで rsync が実行されます。 $ rsync -rv --delete src/ user@example.com:dst Enter passphrase for key \u0026#39;/Users/maku/.ssh/id_rsa\u0026#39;: ******** 使用する SSH 鍵（秘密鍵）を指定したいときは、次のように -e オプションを使います。 $ rsync -e \u0026#39;ssh -i ~/.ssh/id_rsa_xxx\u0026#39; -rv --delete src/ user@example.com:dst シンボリックリンク先の実体をコピーする（-L オプション） 例えば、次のように他のディレクトリへのシンボリックリンクを含む ~/src 以下のファイル群を ~/dst 以下に同期させたいとします。 ~/src +-- sample.txt +-- data/ （~/real-data ディレクトリへのシンボリックリンク） ~/src/data というシンボリックリンクは、例えば ln -s ~/real-data ~/src/data のように作成したもので、実体となる ~/real-data ディレクトリの内容は次のような内容になっています。 ~/real-data +-- images/ +-- a.png +-- b.png +-- c.png このような構成で ~/src ディレクトリ以下の内容を ~/dst ディレクトリ以下にシンクしてみます（src 自身をコピーしないために src/ のように末尾にスラッシュを忘れずに）。 $ rsync -a ~/src/ ~/dst すると、デフォルトでは、~/dst の下にシンボリックリンクファイル (data) がそのままコピーされます。 $ ls -Fl ~/src ...省略... data@ -\u0026gt; /Users/maku/real-data ...省略... sample.txt そうではなくて、リンク先のファイル群の実体をコピーしたいときは、rsync の -L (--copy-links) オプション (transform symlink into referent file/dir) を指定します。 $ rsync -aL ~/src/ ~/dst これで、~/dst/data はシンボリックリンクではなく、~/real-data 以下の内容がすべてコピーされたディレクトリになります。 $ ls -Fl ~/dst ...省略... data/ （通常のディレクトリで、a.png などが含まれている） ...省略... sample.txt"
},
{
url: "/p/wyeboxi/",
title: "Nginx の基本: Nginx をインストールする",
date: "2013-12-01T00:00:00Z",
body: "Nginx の基本: Nginx をインストールする yum で nginx をインストールする ここでは、CentOS などの Linux 環境を想定し、nginx を yum でインストールします。 下記のような yum の設定ファイルを作成しておくことで、最新に近い nginx をインストールできるようになります。 /etc/yum.repos.d/nginx.repo [nginx] name=nginx repo baseurl=http://nginx.org/packages/centos/$releasever/$basearch/ gpgcheck=0 enabled=1 下記のコマンドで nginx をインストールします（バージョンアップも同じコマンドで実行できます）。 $ sudo yum install nginx インストールできたか確認するために、バージョンを表示してみましょう。 $ nginx -v nginx version: nginx/1.4.4 nginx の起動 下記のようにして nginx サーバを起動できます。 $ sudo service nginx start 動作しているかを確認。 $ sudo service nginx status nginx (pid 19996) is running... PC 起動時に nginx が自動起動するようにする nginx が無事に起動するようになったら、chkconfig でマシンの立ち上げ時に nginx が自動起動するようにしておきましょう。 nginx を自動起動するように設定 $ sudo chkconfig nginx on 設定内容の確認 $ chkconfig --list nginx nginx 0:off 1:off 2:on 3:on 4:on 5:on 6:off"
},
{
url: "/p/ti537g4/",
title: "Node.js で Evernote API を使用する（evernote モジュールインストールする）",
date: "2013-11-11T00:00:00Z",
body: "Node.js で Evernote API を使用する（evernote モジュールインストールする） Evernote API を使用するには、API キーの取得と、Sandbox 用アカウントの作成を行っておく必要があります。 API キーの取得: http://dev.evernote.com/#apikey Sandbox 用アカウントの作成: https://sandbox.evernote.com Node.js から Evernote API を使用するために、evernote モジュールをインストールします。 $ npm install evernote 下記のようにして、evernote モジュールをロードできれば準備完了です。 var Evernote = require(\u0026#39;evernote\u0026#39;).Evernote; console.log(Evernote.EDAM_VERSION_MAJOR); console.log(Evernote.EDAM_VERSION_MINOR);"
},
{
url: "/p/buvv4fz/",
title: "Linuxコマンド: scp コマンドでファイルやディレクトリを転送する",
date: "2013-11-09T00:00:00Z",
body: "Linuxコマンド: scp コマンドでファイルやディレクトリを転送する ここでは、scp を使ったファイル転送の方法を示していますが、ディレクトリ単位のファイルコピーやバックアップを行いたい場合は、rsync コマンドを使用したほうが効率的です。 ファイル送信 $ scp \u0026lt;localFile\u0026gt; \u0026lt;user\u0026gt;@\u0026lt;host\u0026gt;:\u0026lt;remoteFile\u0026gt; ファイル受信 $ scp \u0026lt;user\u0026gt;@\u0026lt;host\u0026gt;:\u0026lt;remoteFile\u0026gt; \u0026lt;localFile\u0026gt; 例: リモートのホームディレクトリ内のファイルを取得 $ scp maku@maku.example.com:hello.txt hello.txt remoteFile の指定は、ホームディレクトリからの相対パスで OK です。 ディレクトリ送信 $ scp -r \u0026lt;localDir\u0026gt; \u0026lt;user\u0026gt;@\u0026lt;host\u0026gt;:\u0026lt;remoteDir\u0026gt; ディレクトリ受信 $ scp -r \u0026lt;user\u0026gt;@\u0026lt;host\u0026gt;:\u0026lt;remoteDir\u0026gt; \u0026lt;localDir\u0026gt; 例: ホームディレクトリの sample ディレクトリを丸ごとダウンロード $ scp -r maku@maku.example.com:sample ."
},
{
url: "/p/yejmu4v/",
title: "mongo シェルで各フィールドの型を調べる",
date: "2013-10-22T00:00:00Z",
body: "mongo シェルで各フィールドの型を調べる mongo シェルで、各フィールドの型（タイプ）を調べたいときは、typeof や instanceof を使用します。 フィールドの型を調べる typeof mydoc._id 指定した型のフィールドかどうか調べる mydoc._id instanceof ObjectId 参考リンク Data Types in the mongo Shell — MongoDB Manual"
},
{
url: "/p/wdbr8dx/",
title: "MongoDB の ObjectId について（Document の生成時間を調べる）",
date: "2013-10-22T00:00:00Z",
body: "MongoDB の ObjectId について（Document の生成時間を調べる） MongoDB の各 Document（RDB でいうレコード）は、それぞれ _id というプライマリキーとなるフィールドを持っています。 この値は、何も指定しないと、自動的に ObjectId オブジェクトが生成されて設定されます。 \u0026gt; db.mycollection.insert({value:100}) \u0026gt; db.mycollection.findOne() { \u0026#34;_id\u0026#34; : ObjectId(\u0026#34;5265e358c76d2a2f8b870057\u0026#34;), \u0026#34;value\u0026#34; : 100 } この ObjectId オブジェクトは BSON 形式 のオブジェクトで、内部的に以下のような値を保持しています。 フィールド サイズ 内容 Timestamp 4 bytes 生成時間（秒） Machine ID 3 bytes マシン固有値 PID 2 bytes プロセス ID Counter 3 bytes ランダム値から始まってインクリメントされる ObjectId オブジェクト内に含まれているタイムスタンプは、getTimestamp() メソッドによって取得できます。 これを利用すると、Document の _id フィールドから、その Document が生成された時間を調べることができます。 \u0026gt; db.mycollection.findOne()._id.getTimestamp() ISODate(\u0026#34;2013-10-22T02:30:48Z\u0026#34;) 参考リンク ObjectId — MongoDB Manual"
},
{
url: "/p/pwpgu5h/",
title: "プロダクトバックログとスプリントバックログの概念図",
date: "2013-10-22T00:00:00Z",
body: "プロダクトバックログとスプリントバックログの概念図 図: プロダクトバックログ"
},
{
url: "/p/29awadj/",
title: "数学メモ: 任意の桁のレプ・ユニット (repeated units) を求める方法",
date: "2013-05-26T00:00:00Z",
body: "数学メモ: 任意の桁のレプ・ユニット (repeated units) を求める方法 レプ・ユニット (repeated units) というのは、1 の連続した数字を表します（例: 1, 11, 111, 1111）。 n 桁のレプ・ユニットは、以下のような計算で求められます。 $$R_{n} = \\frac{10^n - 1}{9}$$ 下記は Python でこの計算をテストする例です。 repeated_units.py def repeated_units(n): return (10 ** n - 1) // 9 for i in range(1, 10): print(repeated_units(i)) 実行結果 1 11 111 1111 11111 111111 1111111 11111111 111111111 もちろん、Python のプログラムとしては、単純に繰り返し文字列を作成してから、それを数値に変換することもできます。 def repeated_units(n): return int(\u0026#39;1\u0026#39; * n)"
},
{
url: "/p/qyohkjh/",
title: "数学メモ: 書籍『はじめての数論（原著第3版）』の練習問題メモ",
date: "2013-05-22T00:00:00Z",
body: "数学メモ: 書籍『はじめての数論（原著第3版）』の練習問題メモ 練習問題 1.1 問題 平方数でも三角数でもある最初の 2 つの数は 1 と 36 である。次に小さな例を見つけよう。できれば、その次の例も見つけよう。三角数でありかつ平方数でもある数を見つける有効な方法を見つけることはできるだろうか？こうした性質をもつ数は無数にあると考えられるか？ 解答 Python で三角数 (triangle number) ＝ 平方数 (square number) となる数値を見つけてみる。 #!/usr/bin/env python def triangle(k): return k * (k + 1) // 2 def square(k): return k ** 2 a = 1 b = 1 while True: tri = triangle(a) squ = square(b) if tri == squ: print(\u0026#39;triangle({}) = square({}) = {}\u0026#39;.format(a, b, tri)) a += 1 b += 1 elif tri \u0026lt; squ: a += 1 else: b += 1 if a \u0026gt; 10000000: break 実行結果 triangle(1) = square(1) = 1 triangle(8) = square(6) = 36 triangle(49) = square(35) = 1225 triangle(288) = square(204) = 41616 triangle(1681) = square(1189) = 1413721 triangle(9800) = square(6930) = 48024900 triangle(57121) = square(40391) = 1631432881 triangle(332928) = square(235416) = 55420693056 triangle(1940449) = square(1372105) = 1882672131025 数を大きくすれば、無数に見つかりそうな予感はします。 練習問題 1.2 問題 最初の何個かの奇数を足し合わせてみよう。このとき、その和に何かパターンを見出せるだろうか？パターンを見つけたならば、それを式にしてみよう。その公式が正しいことを幾何的に証明してみよ。 解答 奇数の和は、以下のように $n^2$、つまり平方数になっているように見えます。 1 = 1 1 + 3 = 4 1 + 3 + 5 = 9 1 + 3 + 5 + 7 = 16 1 + 3 + 5 + 7 + 9 = 25 幾何学的には、n が増えるごとに、以下のように逆 L 字型を追加していくことを表しているので、結果的に n x n の正方形になることが分かります。 □■□■□ ■■□■□ □□□■□ ■■■■□ □□□□□ 理論的には、第k項の奇数を 2k - 1 として、 $$\\sum_{k=1}^{n}2k-1 = 2 \\frac{n(n+1)}{2} - n = n^2$$ となり、確かに平方数になっていることが分かります。 練習問題 1.3 問題 引き続く 3 つの奇数 3, 5, 7 はすべて素数である。無数に多くの「素数の 3 つ組」すなわち「三つ子素数」は存在するだろうか？言い直せば、素数 p について、p+2 および、p+4 も素数であるものは無数に存在するだろうか？ 解答 p が偶数の場合は、p は素数でないので、奇数の p についてだけ考えます。 5 から始まる三つ子を列挙してみると、以下のようになります。 5, 7, [9] 7, [9], 11 [9], 11, 13 11, 13, [15] 13, [15], 17 [15], 17, 19 17, 19, [21] 括弧で囲んだ部分が示すように、3 行ごとに必ず右端に 3 の倍数が出てきます。なので、3, 5, 7 以外には三つ子素数は存在しないことが分かります。 数学っぽく説明するなら、p=2k+3（奇数）とおいて、 p = 2(k+1) p+2 = 2(k+2) p+4 = 2(k+3) と書けるので、k がどんな自然数だとしても、3 つの数字のうちいずれかが必ず 3 の倍数になることが説明できます。 練習問題 1.4 問題 $N^2 + 1$ の形をした素数は無数に存在すると信じられているが、それが確かなことであるかまだ誰も知らない。 $N^2 - 1$ の形をした素数は無数に多くあると考えられるか？ $N^2 - 2$ の形をした素数は無数に多くあると考えられるか？ $N^2 - 3$ や $N^2 - 4$ についてはどうだろうか？ $N^2 - a$ の形をした素数が無数に多くあるような $a$ の値はどのような性質を持つだろうか？ 解答 またこんど 練習問題 1.5 続きはボチボチやっていこう。。。"
},
{
url: "/p/ts5mhjj/",
title: "数学メモ: 累乗 (2^x) と階乗 (x!) の増え方を比べる",
date: "2013-05-02T00:00:00Z",
body: "数学メモ: 累乗 (2^x) と階乗 (x!) の増え方を比べる $2^x$ の値は、$x$ が増えるごとに 2倍、2倍、2倍、で増えていきます。 一方、$x!$ の値は、$x$ が増えるごとに 2倍、3倍、4倍、と増えていくので激しい増え方をします。 どちらも指数関数ですが、圧倒的に $x!$ の増え方の方が大きいです。 だからびっくりマークが付いているんですね。 値が、8 桁に到達するのは、それぞれ、 $2^{24}$ = 16777216 11! = 39916800 です。 組み合わせ問題を PC を使って総当たりで解く場合、これくらいのサイズで限界に達します（短い時間で解く場合）。 実際には、$2^{23}$ と 10! までの総当たりが限度と覚えておけばよいでしょう。 $2^x$ の増え方 $2^x$ は以下のような感じで増えます。 2**1 = 2 2**2 = 4 2**3 = 8 2**4 = 16 2**5 = 32 2**6 = 64 2**7 = 128 2**8 = 256 2**9 = 512 2**10 = 1024 2**11 = 2048 2**12 = 4096 2**13 = 8192 2**14 = 16384 2**15 = 32768 2**16 = 65536 2**17 = 131072 2**18 = 262144 2**19 = 524288 2**20 = 1048576 2**21 = 2097152 2**22 = 4194304 2**23 = 8388608 2**24 = 16777216 2**25 = 33554432 2**26 = 67108864 2**27 = 134217728 2**28 = 268435456 2**29 = 536870912 2**30 = 1073741824 2**31 = 2147483648 2**32 = 4294967296 2**33 = 8589934592 2**34 = 17179869184 2**35 = 34359738368 2**36 = 68719476736 2**37 = 137438953472 2**38 = 274877906944 2**39 = 549755813888 2**40 = 1099511627776 2**41 = 2199023255552 2**42 = 4398046511104 2**43 = 8796093022208 2**44 = 17592186044416 2**45 = 35184372088832 2**46 = 70368744177664 2**47 = 140737488355328 2**48 = 281474976710656 2**49 = 562949953421312 2**50 = 1125899906842624 x! の増え方 x! つまり、階乗 (factorial) は以下のような感じで爆発的に増えます。 1! = 1 2! = 2 3! = 6 4! = 24 5! = 120 6! = 720 7! = 5040 8! = 40320 9! = 362880 10! = 3628800 11! = 39916800 12! = 479001600 13! = 6227020800 14! = 87178291200 15! = 1307674368000 16! = 20922789888000 17! = 355687428096000 18! = 6402373705728000 19! = 121645100408832000 20! = 2432902008176640000 21! = 51090942171709440000 22! = 1124000727777607680000 23! = 25852016738884976640000 24! = 620448401733239439360000 25! = 15511210043330985984000000 26! = 403291461126605635584000000 27! = 10888869450418352160768000000 28! = 304888344611713860501504000000 29! = 8841761993739701954543616000000 30! = 265252859812191058636308480000000 31! = 8222838654177922817725562880000000 32! = 263130836933693530167218012160000000 33! = 8683317618811886495518194401280000000 34! = 295232799039604140847618609643520000000 35! = 10333147966386144929666651337523200000000 36! = 371993326789901217467999448150835200000000 37! = 13763753091226345046315979581580902400000000 38! = 523022617466601111760007224100074291200000000 39! = 20397882081197443358640281739902897356800000000 40! = 815915283247897734345611269596115894272000000000 41! = 33452526613163807108170062053440751665152000000000 42! = 1405006117752879898543142606244511569936384000000000 43! = 60415263063373835637355132068513997507264512000000000 44! = 2658271574788448768043625811014615890319638528000000000 45! = 119622220865480194561963161495657715064383733760000000000 46! = 5502622159812088949850305428800254892961651752960000000000 47! = 258623241511168180642964355153611979969197632389120000000000 48! = 12413915592536072670862289047373375038521486354677760000000000 49! = 608281864034267560872252163321295376887552831379210240000000000 50! = 30414093201713378043612608166064768844377641568960512000000000000"
},
{
url: "/p/qxskyjh/",
title: "gnuplot",
date: "2013-05-01T00:00:00Z",
body: "gnuplot http://gnuplot.sourceforge.net/ ここの Demos を見たら、昔と比べて随分いろいろな表示ができるようになっててびっくりしました。 もはやどんなグラフでも描けそうな勢い。"
},
{
url: "/p/oau2e7h/",
title: "数学メモ: TeX の記法のメモ",
date: "2013-04-29T00:00:00Z",
body: "数学メモ: TeX の記法のメモ 演算子、等号（不等号） 演算子 $a+b$ a+b (plus) $a-b$ a-b (minus) $a \\times b$ a \\times b (multiplied by, times) $a \\pm b$ a \\pm b (plus or minus) 等号・不等号 $x+y = z$ x+y = z (equal to) $x+y \\equiv z$ x+y \\equiv z (identical to) （定義・合同） $x+y \\neq z$ x+y \\neq z (not equal to) $x+y \\lt z$ x+y \\lt z (less than)（そのまま \u0026lt; でも OK） $x+y \\gt z$ x+y \\gt z (greater than)（そのまま \u0026gt; でも OK） $x+y \\leq z$ x+y \\leq z (less than or equal to) $x+y \\geq z$ x+y \\geq z (greater than or equal to) $x+y \\ll z$ x+y \\ll z (much less than) $x+y \\gg z$ x+y \\gg z (much greater than) 近似 $x+y \\sim z$ x+y \\sim z (similar) $x+y \\simeq z$ x+y \\simeq z (similar equal) $x+y \\approx z$ x+y \\approx z (approximately equal) 対数 (logarithm) $\\log x$ \\log x $\\log_2 x$ \\log_2 x 対数の底が 2 場合 $\\log_{10} x$ \\log_{10} x 常用対数 (common logarithm) $\\ln x$ \\ln x 自然対数 (natural logarithm) 10 を底とする対数を常用対数 (common logarithm) と呼びます。 また、ネイピア数 $\\mathrm{e}$ を底とする対数を、自然対数 (natural logarithm) と呼びます。 自然対数はラテン語で logarithmus naturalis なので、ln と略します。 分数、連分数 $y = \\frac{a}{b}$ y = \\frac{a}{b} 分数 (fraction) $y = \\frac{a-1}{\\frac{b+1}{c+2}}$ y = \\frac{a-1}{\\frac{b+1}{c+2}} 連分数 (continued fraction) 論理演算（論理積∩、論理和∪、含意⇒） $\\cup$ \\cup 論理和 (logical add, logical sum, OR) $\\cap$ \\cap 論理積 (logical AND, logical multiply) $\\oplus$ \\oplus 排他的論理和 (exclusive OR) $A \u0026amp;\u0026amp; B$ A \u0026amp;\u0026amp; B 条件付き論理積 (conditional AND, short-circuit logical AND) $A || B$ A || B 条件付き論理和 (conditional OR, short-circuit logical OR) $\\Rightarrow$ \\Rightarrow 含意 (conditional implication) 順列、組み合わせ ${}_n \\mathrm{P} _r$ {}_n \\mathrm{P} _r 順列 (permutation) ${}_n \\Pi _r$ {}_n \\Pi _r 重複順列 (repeated permutation) ${}_n \\mathrm{C} _r$ {}_n \\mathrm{C} _r 組み合わせ1 (combination) ${n}\\choose{r}$ {n}\\choose{r} 組み合わせ2 (combination) ※海外ではこう書くことがあります ${}_n \\mathrm{H} _r$ {}_n \\mathrm{H} _r 重複組み合わせ (repeated combination) Sum 型記号 $\\sum$ \\sum $\\sum_{k=1}^{n}k$ \\sum_{k=1}^{n}k 等号 align $$ \\begin{align} (a + b)^2 \u0026amp;= (a + b)(a + b) \\\\ \u0026amp;= a^2 + 2ab + b^2 \\end{align} $$ \\begin{align} (a + b)^2 \u0026amp;= (a + b)(a + b) \\\\\\\\ \u0026amp;= a^2 + 2ab + b^2 \\end{align}"
},
{
url: "/p/x3d286c/",
title: "数学メモ: 公式 - 二次方程式の解",
date: "2013-04-29T00:00:00Z",
body: "数学メモ: 公式 - 二次方程式の解 $ax^2 + bx + c = 0$ の解は、$x = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}$ になります。 元の式を平方完成して、$$a(x + \\frac{b}{2a})^2 - \\frac{b^2}{4a} + c$$ の形にして計算すると上の式を導くことができます。"
},
{
url: "/p/47ogzwo/",
title: "業務プロセスの表記法 (BPMN)",
date: "2013-04-22T00:00:00Z",
body: "業務プロセスの表記法 (BPMN) BPMN (Business Process Modeling Notation) の概要 BPMN.org - http://www.bpmn.org/ アメリカの非営利団体である BPMI (Business Process Management Initiative) が策定。 BPM (Business Process Management) を進める際の標準記述言語。 BPMN は、業務フローを図にするときの表記法を定義しています。業務フローの図って、誰が描いても大体同じような感じになるものだけど、表記法の標準があるのであれば、それを使うのがよいですね。 大まかには、以下のような記号を使って描いていきます。 丸 \u0026ndash; イベントの発生、終了 四角 \u0026ndash; タスク 菱形 \u0026ndash; 分岐 矢印（実線） \u0026ndash; シーケンスのフロー 矢印（点線） \u0026ndash; データのフロー それぞれのタスクを担当する組織などを表現したい場合は、全体のフローを短冊状に区切って表現すれば OK。これも一応、Swimlane という記法として定義されてます。 参考サイト: 情報システム用語事典：BPMN（びーぴーえむえぬ） - ITmedia エンタープライズ"
},
{
url: "/p/6f8k3ns/",
title: "ソフトウェアテストに関するリンク",
date: "2013-03-25T00:00:00Z",
body: "ソフトウェアテストに関するリンク ソフトウェアテスト標準用語集 2012-04-01 時点で Version 2.1"
},
{
url: "/p/3kkchub/",
title: "HTTP ヘッダに関するメモ",
date: "2012-12-15T00:00:00Z",
body: "HTTP ヘッダに関するメモ プロキシ経由時の「リクエスト行」の URI について プロキシサーバを介する場合は、リクエスト行に絶対アドレス指定で URI を指定する必要があります。 これは、リクエストを受け取ったプロキシサーバが、リクエストの転送先サーバを判断するためです。 Client ｜ ｜ GET http://target.example.com/index.html HTTP/1.1 ▽ Proxy server ｜ ｜ GET /index.html HTTP/1.1 ▽ target.example.com HTTP1.1 の Host 指定 HTTP1.1 では、メッセージヘッダに Host: の指定が必須です。これはバーチャルホストの機能を実現するためです。 HTTP1.0 を使う場合は、Host: の指定は必要ありません。 HTTP のメッセージヘッダの種類 HTTP のメッセージヘッダには、大きく分けて、 End-to-End Hop-by-Hop の 2 種類があります。"
},
{
url: "/p/draiajt/",
title: "数学メモ: 公式 - 二項定理",
date: "2012-11-10T00:00:00Z",
body: "数学メモ: 公式 - 二項定理 二項定理の公式 $$(a+b)^n=\\sum_{r=0}^{n} {}_n \\mathrm{C}_r a^{n-r}b^{n}$$ 例: 2乗の場合 $$ \\begin{aligned} (a+b)^2 \u0026amp;= \\sum_{r=0}^{2} {}_2 \\mathrm {C}_r a^{2-r}b^r \\\\ \u0026amp;= {}_2 \\mathrm{C}_0 a^2b^0 + {}_2 \\mathrm{C}_1 a^1b^1 + {}_2 \\mathrm{C}_2 a^0b^2 \\\\ \u0026amp;= a^2 + 2ab + b^2 \\end{aligned} $$ 例: 3乗の場合 $$ \\begin{aligned} (a+b)^3 \u0026amp;= \\sum_{r=0}^{3} {}_3 \\mathrm{C}_r a^{3-r}b^r \\\\ \u0026amp;= {}_3 \\mathrm{C}_0 a^3b^0 + {}_3 \\mathrm{C}_1 a^2b^1 + {}_3 \\mathrm{C}_2 a^1b^2 + {}_3 \\mathrm{C}_3 a^0b^3 \\\\ \u0026amp;= a^3 + 3a^2b + 3ab^2 + b^3 \\end{aligned} $$"
},
{
url: "/p/herfwex/",
title: "ソフトウェア開発手法のまとめ",
date: "2012-11-04T00:00:00Z",
body: "ソフトウェア開発手法のまとめ XP (eXtream Programming) Kent Beck が指揮。 12 のプラクティスがあり、それぞれが連携している。 顧客との連携を重視する。「オンサイト顧客」というプラクティスでは、開発チームに顧客を含めてしまう。 SCRUM マイクロソフトで発祥。 マネジメントに焦点を当てたプロセス。 それぞれの役割に、強い権力付けがされているのが特徴。 1ヶ月のスプリントの間、スクラムマスターはスクラムチームを外の雑音から守る。 約10分で終わるスタンドアップミーティングで一日を始める。 クリスタル Alistair Cockburn が提唱するプロジェクトのテンプレート群。 メンバー数などから、クリスタルクリア、イエロー、オレンジ、レッドと分類される。 規模が大きくなると、ドキュメントを多く作るような規則になっていく。 ASD (Adaptive Software Development) Jim Highsmith と Sam Bayer が作成。 RAD (Rapid Application Development) の考えから作成されたアジャイル開発プロセス。 複雑性の理論により、「Speculate（推測） ➡ Collaborate（強調） ➡ Learn（学習）」の繰り返しでプロジェクトを順応させていく。 大規模開発は、メンバー数を増やすことで可能にする。 リーン開発 Poppendieck 夫妻が提唱。 無駄を省きながらプロジェクトを進める開発手法。 プロジェクト開発中の待ち時間になっている部分を少なくすることでプロジェクトを短期間に終わらせようとする考え。 FDD (Feature Driven Development) ボーランドが提唱。 開発の単位を「機能」とする。 機能のリリースは2週間単位。 機能の完成度は「赤：未着手」「黄：作業中」「緑：完成」の3段階のみで表現。 機能単位で担当を割り当てる。クラス単位で担当を決めることで、人同士のやり取りが、クラス間のやり取りに等しくなるという利点がある。 TDD (Test Driven Development) XP と同じ Kent Beck が提唱。 XP のテストファーストの考え方を、プロセス全体に適用したもの。 GUI の開発であっても、クラスを疎結合にすることで、テストの自動化を考える。"
},
{
url: "/p/fzwyf7z/",
title: "電子署名と電子証明書の基礎",
date: "2012-09-28T00:00:00Z",
body: "電子署名と電子証明書の基礎 電子署名（デジタル署名）(digital signature) 「電子署名」とは、データに付加され、そのデータが本当に作成者が作ったのかを確認するためのものです。 別の言い方をすると、受け取ったデータが第三者によって作られた偽物でないことを確認するための印です。 以下のような手順で、データが偽物でないか確認します。 データ送信側の「電子署名の作成」手順 送信するデータのメッセージダイジェストを求める。 メッセージダイジェストを非公開鍵 (private key) で暗号化し、「電子署名」とする。 データ受信側の「電子署名の確認」手順 受信した「データ」のメッセージダイジェストを求める。 受信した「電子署名」を「送信者の公開鍵」で復号化し、メッセージダイジェストに戻す。 1 と 2 のメッセージダイジェストが等しければ、本人が作成したデータだと分かる。 上記の手順からも分かるように、一般的に「電子署名」の仕組みには、公開鍵暗号方式が用いられます。 問題は、公開鍵 (public key) が偽物である場合に、なりすましができてしまうことです。 そこで、公開鍵が本物であるかを証明するための、「電子証明書」が必要になってきます。 電子証明書（デジタル証明書) (digital certificate) 電子証明書とは？ 公開鍵が偽物であると、公開鍵暗号方式は意味をなさなくなるため、公開鍵の正当性を証明することが重要になってきます。 電子証明書は、ある公開鍵が本物であることを証明するためのものです。 電子証明書は、一般的には、ITU-T X.509 の標準フォーマット（拡張子 .cer）で作成されます。 X.509 で作成された電子証明書ファイル (.cer) には、公開鍵そのものに加え、公開鍵の作成者（証明書の申請者）の情報、有効期限などが含まれています。 電子証明書の発行 電子証明書は、公開鍵が本物であることを示すためのものですが、その電子証明書自体が本物であることを示すために、末尾に電子署名が付加されます。 その署名は、公開鍵を作成したユーザが行うこともあるし、信頼のおける第三者が行うこともあります。 通常は、信頼のおける第三者機関である認証局 (CA: Certificate Authority) が電子証明書への署名を行い、電子証明書の発行を行います。 電子証明書 (X.509) の構成 電子証明書は、下記のようなデータで構成されています。 +------------------------------------+---------------------------------+ | 公開鍵 + 作成者情報 + 有効期限など | ← これが本物だと示す CA の署名 | +------------------------------------+---------------------------------+ 認証局による電子証明書の発行の流れ 公開鍵の作成者が、身元情報と公開鍵を CA（認証局）へ提出する。 CA は 1 の情報を厳密に審査し、電子証明書（X.509形式）を発行する。 このとき、電子証明書は、CA の非公開鍵で電子署名される。ここでは、認証局が電子証明書（X.509 の .cer ファイル）だけを発行する例を示していますが、秘密鍵と電子証明書の両方を認証局が作成、発行することもあります。 SSL 通信を行うときに相手の Web サーバの公開鍵を取得するまでの流れ SSL 通信を行うときは、通信相手の Web サーバの公開鍵を取得する必要があります。 Web サーバの公開鍵は、CA から発行された電子証明書の形で Web サーバ自身が持っています。 Web サーバは、クライアントから SSL 通信の要求を受けると、自分の電子証明書を返します。 クライアントは、その電子証明書を見て、それを発行した CA を調べます。 クライアントは、その CA から CA 自身の公開鍵を取得します。 電子証明書には、CA の署名がついているので、CA の公開鍵を取得すれば、電子証明書が本物だと分かります。 電子証明書に入っている公開鍵を取り出せば、それが Web サーバの公開鍵です。 上記の流れでは、3 で CA に公開鍵を取得しに行っていますが、有名な CA の公開鍵は、あらかじめブラウザに「信頼されたルート証明機関(CA)の公開鍵」としてインストールされているので、CA へのアクセスは省略されます。 上記のようにして、クライアントが、Web サーバの公開鍵を取得できたら、クライアント側で共通鍵を作成し、それを Web サーバに暗号化して送ることで、その後のデータ通信が共通鍵暗号化方式で暗号化して行えるようになります。"
},
{
url: "/p/ce8c2q5/",
title: "Doxygen",
date: "2012-07-10T00:00:00Z",
body: "Doxygen"
},
{
url: "/p/n83ryrp/",
title: "Doxygen のコメントの書き方: メンバ変数の行末コメント",
date: "2012-07-10T00:00:00Z",
body: "Doxygen のコメントの書き方: メンバ変数の行末コメント メンバ変数の後ろにドキュメント・ブロックを置くことができます。 class Hoge { ... int var1; ///\u0026lt; ドキュメント int var2; //!\u0026lt; ドキュメント int var3; /*!\u0026lt; ドキュメント */ int var4; /**\u0026lt; ドキュメント */ }; enum の各エントリに対しても同様にドキュメントを記述することができます。 このように、行末に1行で記述したドキュメントは、Brief description として扱われます。"
},
{
url: "/p/6h47cno/",
title: "XAMPP/Apache の DocumentRoot を設定する",
date: "2012-04-29T00:00:00Z",
body: "XAMPP/Apache の DocumentRoot を設定する httpd.conf を編集 例えば、Mac OSX にインストールした XAMPP の Apache の場合は、/Applications/XAMPP/xamppfiles/etc/httpd.conf を編集します。 (1) DocumentRoot の変更 DocumentRoot \u0026#34;/Applications/XAMPP/xamppfiles/htdocs\u0026#34; ↓ DocumentRoot \u0026#34;/Users/maku/website/public_html\u0026#34; (2) 対応する Directory ディレクトリの変更 \u0026lt;Directory \u0026#34;/Applications/XAMPP/xamppfiles/htdocs\u0026#34;\u0026gt; ↓ \u0026lt;Directory \u0026#34;/Users/maku/website/public_html\u0026#34;\u0026gt; トラブルシューティング http://localhost/ にアクセスしたときに以下のようなエラーが出た場合は、DocumentRoot に設定したディレクトリのパーミッションを確認します。 Access forbidden! You don't have permission to access the requested directory. There is either no index document or the directory is read-protected. 例えば、DocumentRoot として、/aaa/bbb/ccc を設定した場合、/aaa、/aaa/bbb、/aaa/bbb/ccc 全てに read パーミッションがついている必要があります。 $ chmod 0755 /aaa $ chmod 0755 /aaa/bbb $ chmod 0755 /aaa/bbb/ccc"
},
{
url: "/p/dn3okad/",
title: "Unicode 関連リンク",
date: "2012-04-27T00:00:00Z",
body: "Unicode 関連リンク Omniglot \u0026ndash; Language index http://www.omniglot.com/writing/languages.htm 言語ごとに Glyph の一覧を確認できます Unicode Codepoint Chart http://inamidst.com/stuff/unidata/ Unicode のブロックごとに Glyph を確認できます。 Unicode.org \u0026ndash; Languages and Scripts http://unicode.org/repos/cldr-tmp/trunk/diff/supplemental/languages_and_scripts.html 言語と、Unicode Script のマッピングを確認できます。 Unicode.org \u0026ndash; Scripts.txt http://unicode.org/Public/UNIDATA/Scripts.txt Unicode Script に対する Code point を確認できます。 Unicode.org \u0026ndash; CodeChart http://www.unicode.org/Public/6.1.0/charts/CodeCharts.pdf Unicode すべての文字一覧（80MB 以上） ISO15924 http://www.unicode.org/iso15924/ http://www.unicode.org/iso15924/iso15924-codes.html 4 文字のスクリプトコードを定義しています。"
},
{
url: "/p/axg4xms/",
title: "Insertion Sort（挿入ソート）の実装練習",
date: "2012-04-10T00:00:00Z",
body: "Insertion Sort（挿入ソート）の実装練習 Insertion Sort 実装の練習！ void insertion_sort(int vals[], int size) { for (int i = 1; i \u0026lt; size; ++i) { // Insert vals[i] into the sorted sequence vals[0..i-1]. int key = vals[i]; int j = i - 1; while (j \u0026gt;= 0 \u0026amp;\u0026amp; vals[j] \u0026gt; key) { vals[j + 1] = vals[j]; --j; } vals[j + 1] = key; } } 降順ソート (descending order) にするには、vals[j] \u0026gt; key というところを、vals[j] \u0026lt; key にするだけで OK。 テスト #include \u0026lt;iostream\u0026gt;using namespace std; int main() { int vals[] = {5, 2, 4, 6, 1, 3}; const int N = sizeof(vals) / sizeof(int); insertion_sort(vals, N); for (int i = 0; i \u0026lt; N; ++i) { cout \u0026lt;\u0026lt; vals[i] \u0026lt;\u0026lt; endl; } } 参考: Introduction to Algorithms"
},
{
url: "/p/p3z9bup/",
title: "アルゴリズム",
date: "2012-04-10T00:00:00Z",
body: "アルゴリズム"
},
{
url: "/p/iju5ion/",
title: "数学メモ: 駒大数学科の問題",
date: "2012-03-20T00:00:00Z",
body: "数学メモ: 駒大数学科の問題 ビートたけしの『駒大数学科』で出てきた問題で、中村先生の解答がかっこよかったのでメモメモ。 問題 「3で割ると2余る」「5で割ると3余る」「11で割ると9余る」整数のうち、1000以下の最大のものを求めよ。 解答 以下のように、それぞれを「○の倍数＋□」という表現に変えて、□ のところを強引に合わせる。 「3で割ると2余る」→「3の倍数+1」−2 と考える 「5で割ると3余る」→「5の倍数」−2 と考える 「11で割ると9余る」→「11の倍数」−2 と考える すると、答えとなる数は次のように表現できる。 $$(3m+1) \\times 5 \\times 11 - 2$$ これが、1000 より小さい数になればよいので、m=5 のときの 878 という値が正解となる。"
},
{
url: "/p/rdq2cnx/",
title: "Linuxメモ: apt (apt-get) コマンドの使い方メモ",
date: "2012-02-21T00:00:00Z",
body: "Linuxメモ: apt (apt-get) コマンドの使い方メモ apt と dpkg の違い Debian/Ubuntu 系 Linux のパッケージ管理には apt (apt-get) コマンドを使いますが、 Low-Level なパッケージ管理コマンドとして dpkg コマンドも備えています。 参考: DebianPackageManagement - Debian Wiki 参考: AptCLI - Debian Wiki dpkg コマンドは純粋にシステムにパッケージをインストールする部分のみを担うため、インターネットからパッケージをダウンロードしたり、依存関係を自動解決したりする仕組みは備えていません。 そこで、apt は dpkg をラップする形でこれらの機能を提供します。 dpkg \u0026hellip; Debian/Ubuntu にパッケージをインストールする仕組み apt \u0026hellip; パッケージの依存関係を解決してダウンロードし、パッケージをインストールする仕組み（ただし、インストールには内部的に dpkg が使われる） apt と apt-get の違い 2016 年にリリースされた Ubuntu 16.04 の頃から、apt-get コマンドの代わりに apt コマンドが使われるようになりました。 2020 年にリリースされた Ubuntu 20.04 でも apt-get、apt-cache コマンドは使用可能ですが、今後は主に apt コマンドを使っていくことになりそうです。 apt はもともと Linux Mint ユーザーによって作られたコマンドで、これまで apt-get や apt-cache などに散らばっていたコマンド群を整理して使いやすくしています。 apt-get install → apt install apt-get remove → apt remove apt-cache search → apt search apt-cache show → apt show apt によるパッケージのインストール中にはプログレスバーが表示されるなど、表示上の見やすさも考慮されています。 apt が進化している段階では、apt-get が廃止されてしまうことはないでしょうが、まずはパッケージ管理は apt でできるだけ済ませ、どうしても apt-get、apt-cache が必要な場合にはそちらを使う、という考え方でよいと思います。 アップデート可能なパッケージの一覧を表示する (apt list \u0026ndash;upgradable) 更新可能なパッケージの一覧を確認できます。 $ apt list --upgradable Listing... Done libsystemd0/focal-updates,focal-security 245.4-4ubuntu3.15 amd64 [upgradable from: 245.4-4ubuntu3.14] libudev1/focal-updates,focal-security 245.4-4ubuntu3.15 amd64 [upgradable from: 245.4-4ubuntu3.14] インストールされているパッケージの一覧を調べる (apt list \u0026ndash;installed) $ apt list --installed エラー以外の出力を抑制する (\u0026ndash;qq) apt update などで APT のパッケージキャッシュを更新する場合、デフォルトでは大量のメッセージが出力されてしまいます。 スクリプトなどで apt コマンドの実行を自動化する場合は、このようなメッセージは邪魔なことがあります。 apt コマンドの実行時に、エラーメッセージ以外の表示を抑制するには、下記のように -qq オプションを指定します。 $ sudo apt -qq update パッケージの詳細情報を表示する (apt show / apt-cache show) $ apt show \u0026lt;パッケージ名\u0026gt; 上記のコマンドを使うと、指定したパッケージの詳細情報を表示することができます。 インストールされていないパッケージの情報も見ることができます。 例: gnuplot パッケージの詳細情報を表示する $ apt show gnuplot Package: gnuplot Architecture: all Version: 5.2.8+dfsg1-2 Priority: optional Section: universe/math ... パッケージを検索する (apt search / apt-cache search) $ apt search \u0026lt;キーワード\u0026gt; $ apt-cache search \u0026lt;キーワード\u0026gt; 上記のコマンドを使うと、パッケージ情報の中に指定したキーワードが含まれているパッケージを検索することができます（apt と apt-cache で出力形式が異なります）。 あるソフトウェアをビルド中に何らかのライブラリが足りないというエラーが出た場合、このコマンドを使って、インストールしなければいけないパッケージを見つけることができます。 例えば、configure コマンドを実行して、No package 'pthread-stubs' found というエラーが出たら、以下のように pthread-stubs というキーワードで検索してみます。 $ apt-cache search pthread-stubs libpthread-stubs0 - pthread stubs not provided by native libc libpthread-stubs0-dev - pthread stubs not provided by native libc, development files これで、libpthread-stubs0-dev をインストールする必要があることがわかります。 $ sudo apt install libpthread-stubs0-dev 一行説明だけでなく、パッケージの詳細情報も表示したい場合は、--full オプションを付けて検索します。 $ apt-cache --full search pthread-stubs パッケージ名からパッケージを検索する (apt-cache pkgnames) $ apt-cache pkgnames \u0026lt;キーワード\u0026gt; 上記のコマンドを使うと、指定したキーワードで始まるパッケージ名を列挙することができます。 apt-cache コマンドは、APT のパッケージキャッシュから検索を行うため、まだインストールされていないパッケージを探すために使用することができます。 ただし、apt-cache pkgnames は、前方一致でしかキーワードを検索しない ことに注意してください。 例: gnuplot でパッケージ名が始まるものを検索（前方一致） $ apt-cache pkgnames gnuplot gnuplot gnuplot-doc gnuplot-x11 gnuplot-nox gnuplot-mode キーワードを省略すると、APT が現在のパッケージキャッシュから認識できるすべてのパッケージ名を表示します（インストールしていないものも含めて）。 以下のように grep と組み合わせて使用すれば、キーワードの部分一致でパッケージ名を検索することができます。 例: gnuplot をパッケージ名に含むものを検索（部分一致） $ apt-cache pkgnames | grep gnuplot gnuplot python-gnuplot gnuplot-doc libgnuplot-ruby gnuplot-x11 gnuplot-nox libgnuplot-ruby1.8 gnuplot-mode libchart-gnuplot-perl libgraphics-gnuplotif-perl パッケージに含まれているファイルを検索する (apt-file) apt-file コマンドを使うと、パッケージに含まれているファイルを検索することができます。 apt-file は以下のようにして導入します。 $ sudo apt-get install apt-file $ sudo apt-file update 例: libGL.so がどのパッケージに含まれているか検索 $ apt-file search libGL.so パッケージがどんなファイルで構成されているか調べる (dpkg -L) （Ubuntu 12.04 〜 20.04 で動作確認済み） Debian/Ubuntu 系の Linux では、deb パッケージ用の管理コマンド dpkg を使うことができます（APT は内部で dpkg を使用しています）。 あるパッケージが所有しているファイル・ディレクトリの一覧を表示するには次のコマンドを使用します。 $ dpkg -L ＜パッケージ名＞ 例えば、libdbus-glib-1-doc が apt-get install されているとして、実際にこのパッケージがどのようなファイルで構成されているかは次のように調べることができます。 $ dpkg -L libdbus-glib-1-doc /. /usr /usr/share /usr/share/gtk-doc /usr/share/gtk-doc/html /usr/share/gtk-doc/html/dbus-glib /usr/share/gtk-doc/html/dbus-glib/ch01.html /usr/share/gtk-doc/html/dbus-glib/ch02.html /usr/share/gtk-doc/html/dbus-glib/ch03.html ..."
},
{
url: "/p/tm4iwbq/",
title: "Linuxメモ: デバイスドライバ作成の雑多メモ",
date: "2012-02-08T00:00:00Z",
body: "Linuxメモ: デバイスドライバ作成の雑多メモ デバイスドライバは kernel 空間で動作するプログラムで、kernel の機能を使って実装することができる。一方、通常のプログラムはユーザランドで動作する。 デバイスドライバは kernel 自体に組み込んでしまう方法と、ローダブルモジュールとして動的にロード (insmod)、アンロード (rmmod) できるようにする方法がある。 ユーザランドで動作する普通のプログラムが、デバイスドライバの機能を使うには、デバイスファイルを介してアクセスする。 デバイスファイルの操作は、open、close、read、write のような基本的なファイル操作関数を使用する。"
},
{
url: "/p/ym2pdnb/",
title: "読書メモ『ファミコンの驚くべき発想力 －限界を突破する技術に学べ－』松浦健一郎",
date: "2012-01-15T00:00:00Z",
body: "読書メモ『ファミコンの驚くべき発想力 －限界を突破する技術に学べ－』松浦健一郎 ファミコンの驚くべき発想力 －限界を突破する技術に学べ－ 松浦 健一郎、司 ゆき 技術評論社 前半はファミコンの CPU 6502 についての仕様の話が続いてちょっと退屈だけど、後半はドルアーガの迷路生成のアルゴリズムなどが書いてあって面白いです。 実は迷路生成はランダムだけど、乱数生成のシードを工夫したりして、ユーザには規則性があると思わせているところはなるほどと思いました。 基本的には読み物形式で進んでいくのですが、技術的な話題として、加算、減算だけで実現する乗算、除算のアルゴリズムや、ファミコンのスプライトやラスタースクロールの仕組み、垂直帰線期間、水平帰線期間の話など、現在のプログラマでも知っておいたほうがよい知識を幅広く扱ってます。 個人的に面白いと思ったのは、初期のドラクエのゲーム内で使われるカタカナが イ・カ・キ・コ・シ・ス・タ・ト・ヘ・ホ マ・ミ・ム・メ・ラ・リ・ル・レ・ロ・ン の 20 文字に制限されていて（ROM の容量制約）、呪文もこれらの組み合わせだけで作られているというところでした。 ホイミ、メラ、ギラ、マホカンタ、、、確かに！"
},
{
url: "/p/v2y4dwt/",
title: "数学メモ: 頂点の重心と面の重心",
date: "2011-12-16T00:00:00Z",
body: "数学メモ: 頂点の重心と面の重心 頂点の重心 数学的な求め方: 各頂点のx座標、y座標を平均する 物理的な意味: 各頂点におもりを付けて、各頂点から張った糸をまとめて吊り上げて平行になる点が、頂点の重心。 面の重心 数学的な求め方: 面を三角形に分割し、それぞれの三角形の重心を求め、各三角形の面積を重みとして重み付き平均を求める 物理的な意味: 図形の一点に穴を開けて壁などに吊るし、垂直な線を引く。これをもう一カ所の点で同じことをして、線が交わる場所が面の重心。 性質 三角形、長方形、平行四辺形において、頂点の重心と面の重心は一致する。 三角形の重心は、中線（頂点と向かい合う辺の中点を結ぶ線）が交わるところ。 四角形の重心は、向かい合う頂点を結んだ線が交わるところ。"
},
{
url: "/p/j6jv8iu/",
title: "JavaFX2 で CheckBox を ScrollPane に並べる",
date: "2011-10-10T00:00:00Z",
body: "JavaFX2 で CheckBox を ScrollPane に並べる Main.java import javafx.application.Application; import javafx.scene.Group; import javafx.scene.Scene; import javafx.scene.control.CheckBox; import javafx.scene.layout.VBox; import javafx.scene.paint.Color; import javafx.stage.Stage; public class Main extends Application { public static void main(String[] args) { launch(args); } private Group createRootGroup() { CheckBox cb1 = new CheckBox(\u0026#34;First\u0026#34;); CheckBox cb2 = new CheckBox(\u0026#34;Second\u0026#34;); CheckBox cb3 = new CheckBox(\u0026#34;Third\u0026#34;); // Align vertically VBox vbox = new VBox(); vbox.setSpacing(10); vbox.getChildren().add(cb1); vbox.getChildren().add(cb2); vbox.getChildren().add(cb3); // Add to the root Group root = new Group(); root.getChildren().add(vbox); return root; } @Override public void start(Stage primaryStage) { Group root = createRootGroup(); Scene scene = new Scene(root, 200, 150, Color.IVORY); primaryStage.setScene(scene); primaryStage.show(); } }"
},
{
url: "/p/haq7myf/",
title: "JavaFX2 で HelloWorld（ウィンドウの表示）",
date: "2011-10-10T00:00:00Z",
body: "JavaFX2 で HelloWorld（ウィンドウの表示） Main.java import javafx.application.Application; import javafx.scene.Group; import javafx.scene.Scene; import javafx.scene.paint.Color; import javafx.stage.Stage; public class Main extends Application { public static void main(String[] args) { launch(args); } @Override public void start(Stage primaryStage) { Group root = new Group(); Scene scene = new Scene(root, 400, 300, Color.GRAY); primaryStage.setScene(scene); primaryStage.show(); } }"
},
{
url: "/p/9ne93oc/",
title: "Android開発: Handler.post した Runnable タスクがメインスレッドで実行される仕組み",
date: "2011-08-08T00:00:00Z",
body: "Android開発: Handler.post した Runnable タスクがメインスレッドで実行される仕組み Android プログラムで UI 操作を行う場合は、その処理はアプリのメインスレッドから行わなければいけません（Android に限らずほとんどの OS で同じような感じです）。 Activity の onCreate メソッドなどを呼び出しているのがそのアプリのメインスレッドであり、Android ではイコール UI スレッドです。 タイマー処理などで、UI を更新する場合はこのメインスレッドから行う必要があり、新しく立ち上げた別のスレッドから UI を更新することはできません。 このようなケースで利用できるのが android.os.Handler クラスです。 Handler#post メソッドに Runnable オブジェクトを渡すと、最終的にその Handler オブジェクトを生成したスレッドで Runnable オブジェクトの run メソッドが実行されるようになっています。 つまり、Handler オブジェクトを Application のメインスレッドから（例えば Activity のフィールドとして）生成しておけば、そこに post した Runnable タスクは、メインスレッドで実行されることが保証されます。 Handler#post メソッドは、内部的にはスレッドローカルな Looper に結び付けられた MessageQueue オブジェクトに処理をキューイングしています。 Handler オブジェクトをメインスレッドから生成すれば、メインスレッド上の MessageQueue と結び付けられ、その MessageQueue が Looper によってメインスレッド上で処理されるという流れになっています。 別の言い方をすれば、メインスレッドの MessageQueue に対して、Runnable タスクを投入するためのインタフェースとなるのが Handler オブジェクトというわけです。"
},
{
url: "/p/2bqp8i3/",
title: "秀丸: カラーマーカーを設定してジャンプする",
date: "2011-07-14T00:00:00Z",
body: "秀丸: カラーマーカーを設定してジャンプする 秀丸のメニューから、その他 → キー割り当て で以下のような感じでショートカットキーを設定しておくと、任意の行にさくっとブックマークできるので便利です。 現在行をマーク/マーク解除 \u0026ndash; Alt+Ctrl+Right マーク一覧 \u0026ndash; Alt+Ctrl+Left マーク行の下検索 \u0026ndash; Alt+Ctrl+Down マーク行の上検索 \u0026ndash; Alt+Ctrl+Up あとは、以下のようにマークした行全体を強調するようにすると見やすくなります。 その他 → ファイルタイプ別の設定 → デザイン/表示 と辿る マークした行全体をカラー表示 にチェック"
},
{
url: "/p/ht3uidd/",
title: "秀丸エディタ",
date: "2011-07-14T00:00:00Z",
body: "秀丸エディタ"
},
{
url: "/p/oo32y2x/",
title: "Linuxコマンド: テンポラリディレクトリを作成する (mktemp)",
date: "2011-06-30T00:00:00Z",
body: "Linuxコマンド: テンポラリディレクトリを作成する (mktemp) mktemp コマンドを使用して、一時ディレクトリを作成することができます。 $ mktemp -d /tmp/tmp.LE04SMiEzq mktemp コマンドは、作成したファイルやディレクトリのパスを表示するので、シェルスクリプト内で以下のようにすれば、そのパスを変数に格納することができます。 tempdir=`mktemp -d`"
},
{
url: "/p/95pkhzc/",
title: "Linuxコマンド: ディレクトリのサイズを調べる (du)",
date: "2011-06-29T00:00:00Z",
body: "Linuxコマンド: ディレクトリのサイズを調べる (du) du コマンドを使って、ディレクトリ内のファイルの合計サイズを調べることができます。 $ du -hs mydir 685M mydir 各オプションは次のような効果があります。 -h (--human-readable) \u0026hellip; 人に読みやすい単位でサイズ表示します（例: 1K、234M、2G） -s (--summarize) \u0026hellip; 合計サイズのみを表示します サイズ部分だけを表示したい場合は、cut コマンドで 1 番目のフィールドを切り出してしまうのが手っ取り早いです。 $ du -hs mydir | cut -f1 685M"
},
{
url: "/p/bv6dksy/",
title: "Linux プログラミングメモ",
date: "2011-06-22T00:00:00Z",
body: "Linux プログラミングメモ"
},
{
url: "/p/neegpac/",
title: "Linux の system 関数で任意のプログラムを実行する",
date: "2011-06-22T00:00:00Z",
body: "Linux の system 関数で任意のプログラムを実行する Linux の system 関数は、プログラムの起動に失敗すると -1 を返します。 また、戻り値を WEXITSTATUS マクロにかけると、呼び出したプログラム自体の終了コード（正常時は 0）を取得することができます。 #include \u0026lt;stdio.h\u0026gt;#include \u0026lt;stdlib.h\u0026gt; // system(), WEXITSTATUS bool doSystem(const char* command) { int ret = system(command); if (ret == -1) { fprintf(stderr, \u0026#34;ERROR: Cannot execute [%s]\\n\u0026#34;, command); return false; } int exitStatus = WEXITSTATUS(ret); if (exitStatus != 0) { fprintf(stderr, \u0026#34;ERROR: [%s] returns error %d\\n\u0026#34;, command, exitStatus); return false; } return true; }"
},
{
url: "/p/6i7dvxj/",
title: "Linuxコマンド: ファイルの MIME メディアタイプを調べる (file)",
date: "2011-06-20T00:00:00Z",
body: "Linuxコマンド: ファイルの MIME メディアタイプを調べる (file) file コマンドに -i オプションを付けて実行すると、そのファイルの MIME タイプを調べることができます。 $ file -i sample.txt sample.txt: text/plain; charset=us-ascii"
},
{
url: "/p/cw7ekxc/",
title: "Linuxコマンド: ファイルの内容を8進数や16進数でダンプする (od)",
date: "2011-06-20T00:00:00Z",
body: "Linuxコマンド: ファイルの内容を8進数や16進数でダンプする (od) od コマンドの基本（8 進数でダンプする） od (octal dump) コマンドを使用すると、ファイルの内容を 8 進数や 16 進数でダンプすることができます。 ファイル内容を 8 進数でダンプする $ od sample.jar | head -5 0000000 045520 002003 000024 000010 000010 122216 037257 000000 0000020 000000 000000 000000 000000 000000 000024 000000 042515 0000040 040524 044455 043116 046457 047101 043111 051505 027124 0000060 043115 106505 005313 030302 042420 001767 103771 040374 0000100 072502 121341 133273 020473 145340 106255 044315 007207 先頭のカラムはアドレスを示しています。 アドレスの後ろからは、6 文字ずつに区切って 8 進数のデータが並びます。 8 進数では 1 文字が 3 ビットなので、6 文字で最大 18 ビットを示すことができますが、od コマンドの出力では、その内の 16 ビット（= 2 バイト）を使用しています。 頭の 2 ビットは必ず 0 でパディングされているので、各カラムの先頭の数字は 0 か 1 になります（アスキーコードのテキストなら必ず 0 でしょう）。 上記の例では、1 行ごとに、16 バイト（2 バイト x 8）ずつ出力しています。 ファイルの内容を 16 進数でダンプする od コマンドはデフォルトでは 8 進数でダンプしますが、-x オプションを付けると 16 進数でダンプすることができます。 $ od -x sample.jar | head -5 0000000 4b50 0403 0014 0008 0008 a48e 3eaf 0000 0000020 0000 0000 0000 0000 0000 0014 0000 454d 0000040 4154 492d 464e 4d2f 4e41 4649 5345 2e54 0000060 464d 8d45 0acb 30c2 4510 03f7 87f9 40fc 0000100 7542 a2e1 b6bb 213b cae0 8cad 48cd 0e87 od の出力フォーマットを変更する 下記の例では、od コマンドの出力フォーマットをオプションで変更しています。 $ od -t x1 -Ax sample.jar | head -5 000000 50 4b 03 04 14 00 08 00 08 00 8e a4 af 3e 00 00 000010 00 00 00 00 00 00 00 00 00 00 14 00 00 00 4d 45 000020 54 41 2d 49 4e 46 2f 4d 41 4e 49 46 45 53 54 2e 000030 4d 46 45 8d cb 0a c2 30 10 45 f7 03 f9 87 fc 40 000040 42 75 e1 a2 bb b6 3b 21 e0 ca ad 8c cd 48 87 0e 各オプションは次のような意味を持っています。 -t x1 \u0026hellip; 16 進数で 1 バイトごとに -Ax \u0026hellip; アドレス表示を 16 進数で"
},
{
url: "/p/v7bxgmn/",
title: "CPU のアーキテクチャ名と CPU 名の対応表",
date: "2011-06-19T00:00:00Z",
body: "CPU のアーキテクチャ名と CPU 名の対応表 Intel 系 CPU アーキテクチャ名 CPU名 i386 80386 i486 80486 i586 Pentium, MMX Pentium i686 Pentium Pro, Pentium II, Pentium III, Pentium 4 athlon Athlon, Athlon MP, Athlon XP x86_64 Opteron, Athlon64, Xeon (EM64T), Core, Core2Duo メモ x86 (IA-32) Intel 社の 8086 系のプロセッサの略称。（binary hacks より） x86_64 (AMD64) AMD が設計した x86 上位互換の 64 ビットプロセッサのアーキテクチャ。（binary hacks より）"
},
{
url: "/p/89tt5ie/",
title: "Linuxメモ: デバイスドライバのライセンスについて",
date: "2011-06-19T00:00:00Z",
body: "Linuxメモ: デバイスドライバのライセンスについて デバイスドライバを Linux カーネルに直接取り込む（静的リンクする）場合は GPL になります。 Linux カーネル自体が GPL なので、ドライバも GPL になるということです。 このようなドライバはランレベル 1 でロードされます。 カーネルモジュール（ローダブルモジュール）としてドライバを動的にロードする場合は、ライセンスは開発者が決めることができます。 通常はランレベル 3 になった時点で、insmod や modprobe コマンドでロードします。 カーネルモジュールとして作成するドライバのライセンスは、 コードの中で以下のように MODULE_LICENSE マクロを使用して指定します。 MODULE_LICENSE(\u0026#34;Dual BSD/GPL\u0026#34;); ライセンスは以下のものから選択することができます。 GPL GPL v2 GPL and additional rights Dual BSD/GPL Dual MIT/GPL Dual MPL/GPL Proprietary # default"
},
{
url: "/p/crfin42/",
title: "読書メモ『外国語上達法』千野栄一",
date: "2011-05-27T00:00:00Z",
body: "読書メモ『外国語上達法』千野栄一 外国語上達法 千野栄一 岩波書店 ポイントメモ はじめに 決して忘れていはいけない忠告「忘れることを恐れるな」。 目的と目標 「なんでこの外国語を習うのか」ということを明確にする。 必要とする量だけ学習する。 どの言語を三拍子揃った言語にし、どの言語を受け身な読めるだけの言語にするかをよく考える。 本を読んで理解が出来ればいい言語を、書いたり話したりできるようにするのは、無駄な努力である。 必要なもの 外国人に日本語を教え、かわりにその外国語を学ぶというのはよく聞くが、そうやっても上達しないのはお金を使っていないから。 1日に6時間ずつ4日やるより、2時間ずつ12日した方がいい。 覚えなければいけないのはたったの2つ「語彙と文法」。 まずは単語を知らなくては駄目。 次の3つが揃っているのが望ましい「いい教科書」「いい教師」「いい辞書」。 語彙 まず何はともあれ、やみくもに千の単語を覚えることが必要。 千の単語を覚えるのに辞書を引くのは無駄。辞書を使うのはもっと後のことで、この段階ではすでに訳のついている単語を覚える。 千語習得の時間は短くなければならず、そこで十分に時間をとれるときに新しい言語を学び始めるように計画する。 確実な500語は、不確実な2000語より、その言語を習得するのに有効である。 頻度数の高いものから覚えるべき。 大体どの言語のテキストでも、3000語覚えれば、テキストの90％は理解できる。 頻度数の高い語は原則として短い。短い語はなるべく覚えた方がいい。 文法 母語と外国語ではどこが違うかに細かく気を配れる人にとっては、文法はとても面白い分野である。 文法は補助手段であり学習の目的ではない。 多くの人が必要とするのは文法の基礎的知識である。 黒枠に入っている変化表は全部覚えなければならない。 1冊の学習書の中の変化表を全部切り抜いてビッシリ張り直すと、大体10ページくらいになる。 最初の1、2ヶ月のうちに、この10ページを徹底的に覚える。そして何度も繰り返す。 不規則変化するものは、基本語彙であり、頻度数が高く、この表も重要である。 教科書 語学書は薄くなければならない。とりわけ、初歩の学習書はそうである。 新しく出て来た単語が、次の課で再び登場するようなテキストがいいテキストである。 関係のない文を集めているテキストより、1つのテーマで貫かれているテキストがよい。 例文はそのまま実際に使ってもいい文からのみできているべきである。 辞書 辞書を上手に使うには、編集主幹のはしがき、編集の方針、使い方の指示を必ず読む。少しのスペースの中に編集者の血の滲むような思いが込められている。 自分の程度にあった学習辞典を見つけるのは、語学攻略の大事なポイント。 学習辞典に出ていない単語に出会ったら、その単語は当分覚えなくていいと思うべき。 発音 後になってよくない発音を矯正するのは、困難というより不可能に近い。 発音に関しては初めが肝心である。 レアリア チェコ語に「レアーリエ」(reálie) という語があり、「ある時期の生活や文芸作品などに特徴的な細かい事実や具体的なデータ」という説明がついている。 「レアリア」の知識が、外国語の上達にとってはとても大切。 英語を母語として話す人なら当然知っていることを、外国語として英語を使う人は知らないことがある。レアリアはこの差を補っていこうとするもの。 人名にせよ地名にせよ、固有名詞はその最たるもので、それらを知っているか知らないかは、全体の理解に大きな影響を持っている。 その外国語を支えている文化、歴史、社会……という様々な分野の知識を身につけておけば、それは外国語の理解の際に、まるで隠し味のように後から効いてくる。 まとめ 短時間ものすごく集中することより、学習を規則的に持続していくこと。 繰り返しは忘却の特効薬。 たとえ短い時間でも毎日することが大切で、減食やジョギングと同じように少しずつでも毎日する方がいい。 2つの原語より3つの言語、3つの言語より4つの言語と進むにつれて、その人の視野は複眼的になり、物事の違った面が見えてくる。ただ、その言語が使い物になることがその条件。"
},
{
url: "/p/7s4vnax/",
title: "Android開発: LowMemoryKiller の動きのメモ",
date: "2011-05-11T00:00:00Z",
body: "Android開発: LowMemoryKiller の動きのメモ Android の lowmemorykiller では、最もメモリを使っていて、oom_adj の値が大きいものが殺されます。 oom_adj の値は、/proc/\u0026lt;Process ID\u0026gt;/oom_adj に書かれた値です。 本来は Linux の oom (Out of memory) killer が使うファイルですが、Android の lowmemorykiller もこのファイルを使っています。 oom_adj の値は -16～15 をとり、小さいほど殺されにくくなります。デフォルトは 0 です。 ただし、oom_adj に OOM_DISABLE (-17) を設定すると、lowmemorykiller の対象外になるようです。 oom_adj の値を確認したり、強引に変更したい場合はこんな感じ。 # cat /proc/1234/oom_adj 0 # echo -16 \u0026gt; /proc/1234/oom_adj"
},
{
url: "/p/ticmqdo/",
title: "辞書アプリのアイデア",
date: "2011-04-23T00:00:00Z",
body: "辞書アプリのアイデア 辞書ソフト (MemDic) アイデア、コンセプト Web 上にある辞書のデータはそのまま活かしたいので、基本は Web 上の辞書をマッシュアップ（プラグイン形式）で検索。Web 上に存在しない語句は独自で追加できるようにする。Web 上に存在する語句についても、コメントなどを追加できるようにする。 タグ（カテゴリ分け）をできるようにし、自分仕様にカスタマイズされた単語帳のように使えるようにする。 コメントをユーザ間で共有できるとなお Good。 複数の辞書はプラグイン形式で追加できる（ワンタッチで ON/OFF）。"
},
{
url: "/p/kx7myd9/",
title: "TeraTerm マクロのメモ",
date: "2011-04-19T00:00:00Z",
body: "TeraTerm マクロのメモ マクロの起動の仕方 TeraTerm が起動している場合 メニューから Control → Macro でマクロファイル (.ttl) を選択 TeraTerm を起動してマクロを実行する場合 C:\\\u0026gt; ttermpro.exe /M=sample.ttl TeraTerm を起動せずにマクロを実行する場合 C:\\\u0026gt; ttpmacro.exe sample.ttl マクロの実行中止ダイアログを表示しないようにするには、/V オプションをつけます。 ttpmacro.exe でマクロを実行した場合、マクロ中で connect コマンドを実行したときに TeraTerm が表示されます。 例1: COM1 ポートでシリアル接続する場合 connect \u0026#39;/C=1\u0026#39; 例2: TCP/IP (Telnet) 接続する場合 connect \u0026#39;host.example.com\u0026#39; 例3: TCP/IP (any port) 接続する場合 connect \u0026#39;host.example.com:8080\u0026#39; 文字列を表示する (dispstr) dispstr を使えば、TeraTerm アプリケーションの機能として文字列を表示できます。 マクロの実行経過などを表示したい場合などは dispstr を使うのがよいでしょう。 dispstr 'Hello World'#$0A 末尾の #$0A は改行コード (LF) を表しています。 間違えやすいものに sendln がありますが、これは接続先の端末に対してコマンドを送るものです。 以下のように echo コマンドを送信した場合は、リモートの端末上で echo コマンドが実行されることになります。 sendln 'echo Hello World' メッセージボックスを表示する (messagebox) messagebox \u0026quot;Hello TTL!\u0026quot; \u0026quot;It's cool\u0026quot; ビープ音を出す (beep) ビープ音を出すコマンドの書式は以下の通りです。 beep [\u0026lt;sound type\u0026gt;] 以下のマクロでは、sound type を変えて 1 秒おきにビープ音を鳴らします。 Windows 7 の標準設定では、sound type = 4 の音は鳴りませんでした。 dispstr 'A simple beep'#$0A beep 0 pause 1 dispstr 'Windows Asterisk sound'#$0A beep 1 pause 1 dispstr 'Windows Exclamation sound'#$0A beep 2 pause 1 dispstr 'Windows Critical Stop sound'#$0A beep 3 pause 1 dispstr 'Windows Question sound'#$0A beep 4 pause 1 dispstr 'Windows Default Beep sound'#$0A beep 5 pause 1 実行結果 A simple beep Windows Asterisk sound Windows Exclamation sound Windows Critical Stop sound Windows Question sound Windows Default Beep sound 特定の文字列が出現するまで待機する (waitln) waitln を使用すると、ターミナル上に特定の文字列が表示されるまで、マクロの実行がそこで待機されます。 waitln 'Hoge' 複数の文字列を指定することもできます。 例えば、以下のようにすると、いずれかの文字列が出現するまで待機します。 waitln 'Hoge1', 'Hoge2', 'Hoge3' timeout 変数に秒数を代入すると、waitln のタイムアウト時間（最大待ち時間）を設定することができます。 0 秒以下を指定すると、waitln は指定された文字列が登場するまで永遠に待ち続けます。 ; Timeout never occurs timeout = 0 waitln 'Hoge' 応用例: ある文字列を含むラインを受信したらメッセージボックスに表示するマクロ :LOOP waitln \u0026#34;Your Keyword\u0026#34; gettime timestr messagebox inputstr timestr goto LOOP 指定した秒数だけ待機する (pause) ; Pause for 3 seconds. pause 3 サブルーチンの定義＆呼び出し call SubRoutineName end :SubRoutineName messagebox 'Yah Yah Yah!' '' return マクロサンプル: telnet でリモートホストに自動ログインする login_sample.ttl ``` ;;;----------------------------------------------------------------- ;;; TeraTerm マクロのサンプル ;;; telnet でリモートホストに自動ログインする ;;; ;;; Usage: ;;; ttpmacro.exe login_sample.ttl ;;;----------------------------------------------------------------- ;;; 接続先のホスト名（または IP アドレス）を指定 ;;; （TeraTerm 起動してなかったら起動する） connect \u0026#39;host.example.com\u0026#39; ;;; \u0026#34;login:\u0026#34; という文字列を受信するまで待機し、 ;;; ユーザ名を送信する。 wait \u0026#39;login:\u0026#39; sendln \u0026#39;MyName\u0026#39; ;;; \u0026#34;password:\u0026#34; という文字列を受信するまで待機し、 ;;; パスワードを送信する。 wait \u0026#39;password:\u0026#39; sendln \u0026#39;MyPassword\u0026#39;"
},
{
url: "/p/q5w35me/",
title: "秀丸: 秀丸で OR 検索する (grep)",
date: "2011-04-18T00:00:00Z",
body: "秀丸: 秀丸で OR 検索する (grep) 秀丸の検索 (grep) 機能で OR 検索をしたいときは、正規表現にチェックを入れて、以下のように検索する文字列を | で区切れば OK です。 Pattern A | Pattern B"
},
{
url: "/p/8yhxet9/",
title: "Kent Beck の CollectingParameter パターン",
date: "2011-04-10T00:00:00Z",
body: "Kent Beck の CollectingParameter パターン Collecting Parameter の特徴 巡回するオブジェクトの戻り値をベースに目的のデータを構築するのではなく、パラメータに渡したオブジェクトを使ってデータを構築する。 戻り値となるオブジェクトのインスタンス化を防ぐことができるので、コードの実行速度が上がる。 戻り値をベースにしたデータ構築よりも、より柔軟なタイミングでデータの構築が行える（例えば、メソッドの実行途中で結果を append できる）ようになり、コードを分割しやすくなる。 参考文献: 『パターン思考リファクタリング入門』 第10章 累積処理 Collecting Parameter を使わない場合の実装例 public String extractText() { StringBuilder results = new StringBuilder(); Node node = null; while ((node = nodeList.next()) != null) { results.append(node.toString()); // 戻り値をベースにしたデータ構築 } return results.toString(); } Collecting Parameter を使う場合の実装例 public String extractText() { StringBuilder results = new StringBuilder(); Node node = null; while ((node = nodeList.next()) != null) { node.getText(results); // パラメータをベースにデータ構築 } return results.toString(); } 巡回される要素の方で、Collecting Parameter を使ってデータを構築します。 public StringNode implements Node { ... public void getText(StringBuilder results) { results.append(\u0026#34;\u0026lt;P\u0026gt;\u0026#34;); results.append(text); results.append(\u0026#34;\u0026lt;/P\u0026gt;\u0026#34;); } } 巡回される要素側にデータ構築のためのコードが含まれてしまうのを防ぎたい場合は、 Visitor パターン を使用し、呼び出し側に処理を委譲するようにします。"
},
{
url: "/p/xmc9kvq/",
title: "読書メモ『こんな小さなことで愛される77のマナー』大原敬子",
date: "2011-03-08T00:00:00Z",
body: "読書メモ『こんな小さなことで愛される77のマナー』大原敬子 こんな小さなことで愛される77のマナー 大原敬子 PHP研究所 ポイントメモ 嫌いな人に会うときは、その目的さえわかれば会うときの態度は自ずから変わってくる。嫌だと言っているのは、自分の感情。 大事なのは、相手に清潔感を与えることを心がけること。 視線を反らさない。 小声で話さない。 ばか遠慮はしない。 背筋を伸ばして座る。 自分の意志を曖昧に答えない。 意味不明な笑い顔を作らない。 自分を立派に見せなければ、緊張しないで人に会うことができる。 自分を誇示しない。 自分を素直に出す。 自分を信じる。 部下に馬鹿にされたとき、 距離をおく。軽く見られる人は、けじめをつけることに無頓着。 視線をそらさない。「うかつな嘘は言えないな」と思わせること。 体を動かさない。本当に自信があると、しっかりと相手を見て話します。あることに集中すると、体は静止するもの。 どんなに安いアクセサリーでも、肌の手入れの行き届いた人が身につけているのを見ると、思わず見とれてしまいます。 湿度の低いヨーロッパは足の蒸れは少ないと言います。しかし、長い時間履いているときは、香水で中底を拭くのです。 お金では絶対に買えない自分の文化教養を身につけることが、本当のブランド的生き方です。行動の積み重ねがその人の品行を作ります。心の積み重ねがその人の品性を築きます。 言葉の順番に気をつける。 ○はい、そうです。 ×そうですね、はい。 ○それは違います。 ×違います、それは。 ○今日も頑張ったね。 ×今日はがんばったね。 励まし、やる気を起こさせるには「も」を使う。 ○今日も料理おいしいね。 ×今日は料理おいしいね。 最初に相手の名前で話しかけること。 Jさん、これはできません。Sくん、今日はだめです。 許せない人がいる人には生きるエネルギーがあります。それを生産性を高めることに使うことです。 「お母さんできたよ」「まあすばらしい」視線は違う方に向いているのです。子供はその母親の視線から、嘘を感じ取るのです。言葉はなくても目が「すごい」という表情をしたとき、子供は信じます。 思いやりは相手のことを考えて行動すること。その思いやりは相手に聞くこと。 「お茶を入れてください」 → 「濃いめのお茶がよろしいですか？」 「急いで企画書を書いてくれないか」 → 「いつまでに作ればよろしいでしょうか？」 「この書類をとじておいてください」 → 「各分野ごとですか、それともひとまとめですか？」 几帳面な人は人間関係がギクシャクすることがあります。ていねいな人はギクシャクはありません。人の行動を見て苛々したときは、ていねいな心ではなく、自分の義務感からの几帳面さだと思うことです。"
},
{
url: "/p/rm78k9i/",
title: "Linuxメモ: syslog のログの保存先の設定",
date: "2011-02-20T00:00:00Z",
body: "Linuxメモ: syslog のログの保存先の設定 /etc/syslog.conf に以下のように記述されていれば、debug レベルのログは /var/log/debug に、info, notice, warn レベルのログは /var/log/messages に記録されます。 *.=debug; \\ auth,authpriv.none;\\ news.none;mail.none -/var/log/debug *.=info;*.=notice;*.=warn;\\ auth,authpriv.none;\\ cron,daemon.none;\\ mail,news.none -/var/log/messages"
},
{
url: "/p/zff2scf/",
title: "SQL",
date: "2011-02-20T00:00:00Z",
body: "SQL"
},
{
url: "/p/6ebo58o/",
title: "SQL の検索結果をソートする (ORDER BY)",
date: "2011-02-20T00:00:00Z",
body: "SQL の検索結果をソートする (ORDER BY) SELECT によるレコードの検索結果の並び順は不定なので、特定のカラムでソートしたい場合は、明示的に ORDER BY 指定を行う必要があります。 書式 SELECT*FROMtblORDERBYcol 複数のカラムでソートしたい場合は、カンマでチェック順にカラム名を並べます。 SELECT*FROMtblORDERBYa,b,c 昇順 (ASC)、降順 (DESC) を指定するには以下のように末尾に追加するだけです。 SELECT*FROMtblORDERBYcolASC-- 昇順 (default) SELECT*FROMtblORDERBYcolDESC-- 降順 NULL がどのように扱われるかはデータベースによって異なります。"
},
{
url: "/p/ey8rn5z/",
title: "日本語入力時に数字を必ず半角で入力する",
date: "2011-02-20T00:00:00Z",
body: "日本語入力時に数字を必ず半角で入力する Mac OSX の場合 ことえりで「ひらがな」入力状態にする。 「あ」のアイコンを右クリックして「環境設定を表示」を選択。 「入力文字」の項目で、「数字を全角で入力」のチェックを外す。 Windows Vista (MS IME) の場合 言語バーを右クリックして「設定」を選択。 Microsoft Office IME2007 を選択して「プロパティ」を開く。 「オートコレクト」タブの英字、数字を「常に半角に変換」に設定。 MS IME の場合、英数字を入力してから一回はスペースを押す必要があります。"
},
{
url: "/p/64zojt6/",
title: "Android開発: レイアウトの種類まとめ",
date: "2011-01-10T00:00:00Z",
body: "Android開発: レイアウトの種類まとめ FrameLayout ウィジェットを左上に１つだけ配置する。 FrameLayout の中で複数の View を配置した場合は、最後に表示したものが上に重ねて表示される。 LinearLayout 水平か、垂直に一直線にウィジェットを並べる。 水平: android:orientation=\u0026quot;horizontal\u0026quot; 垂直: android:orientation=\u0026quot;vertical\u0026quot; ConstraintLayout フラットなビュー階層を持つ大きくて複雑なレイアウトを作成する。 RelativeLayout より柔軟。 LinearLayout を組み合わせてレイアウトを入れ子構造にするとパフォーマンスが悪くなるが、ConstraintLayout ひとつでフラットにビューを配置すると効率的な描画が可能。 TableLayout HTML の TABLE 要素のようにウィジェットを並べる。 RelativeLayout 他のウィジェットとの相対的な位置関係で配置する。 参照されるウィジェットは、参照するウィジェットよりも先に定義されていなければならない。 AbsoluteLayout（非推奨） 絶対座標でウィジェットを配置する。 それぞれの Layout を入れ子にして、その中にウィジェットを配置していくことで複雑なレイアウトを作成することができます。 \u0026lt;LinearLayout ...\u0026gt; \u0026lt;LinearLayout ...\u0026gt; ... \u0026lt;/LinearLayout\u0026gt; \u0026lt;LinearLayout ...\u0026gt; ... \u0026lt;/LinearLayout\u0026gt; \u0026lt;/LinearLayout\u0026gt;"
},
{
url: "/p/3u8vrba/",
title: "読書メモ『The Secret Book』石井裕之、苫米地英人ほか",
date: "2011-01-04T00:00:00Z",
body: "読書メモ『The Secret Book』石井裕之、苫米地英人ほか フォレスト出版が無料で配布していた「THE SECRET BOOK」のメモ、抜粋。 悶々としている気分から一歩踏み出そう！ by 石井裕之 \u0026ndash; 1963年生まれ。有限会社オープーアソシエイツ代表取締役。 セミナーに参加して一度だけ話を聞くよりも、セミナーを収録したテープを何度も何度も聴くことのほうがプラスになります。 オーディオにはあって本にはないもの。それはリズムの効用です。その意味でも、繰り返し聴くことは重要なのです。 音で聴かないと入ってこないというところがありました。 だから、昔テレビでやっていたドラマ「大草原の小さな家」の二カ国語放送の英語部分だけを録音して何度も聴いて英語を勉強してたりしていました。 英語でも、次から次へと新しい文章を覚えるよりも、むしろ同じ文章を繰り返し聴くことでリズムを浸透させるのです。そうすると、音の響きでこれは正しいか間違っているかどうかわかるようになってくるのです。 世間のセミナーは、単に情報を伝えているだけのものがほとんどです。しかし、本来セミナーはそういうものではなく、参加者の潜在意識を巻き込んで、参加者と一体になってリアルタイムで作り上げていくものだと思っています。そのレベルになると、もはやテープではカバーできない。ライブのセミナーでなければ実現できないものになります。 脳科学でわかった！もっとも効率的な勉強法 by 苫米地英人 \u0026ndash; 1959年生まれ。ドクター苫米地ワークス代表。 理想の教材は「オリジナルの人」が語っているもの。その点から考えると、本当に教授が顔を出しているので、放送大学は役に立ちます。 新しいファイナンス理論を学びたかったら、アメリカのファイナスプログラムを作った人たちのところに直接行って学ぶのが理想。それが不可能な場合は、動画。動画もダメな場合は、音声。本人がしゃべっているという音声の言語の中にたくさんの情報を集めていく。それがDVD・CDを使いなさいという理由。 グレゴリー・チャイティンが数学全般にわたって不完全性の定理を証明したレクチャーはユーチューブでガンガン見ることができます。ゲーテルの不完全性の定理が完成させられた瞬間です。 慣れてきたら、仕事をしながらとか、雑誌を読みながらとか、「〜しながら」CDやDVDを聴いたり、観たりしてもいい。人間の脳は、同時に何でもできます。 同時通訳者は、通訳しながら会議中に編み物をしている人もいるくらいです。国連のおばちゃんとかそうやってます。慣れの問題だし、脳はいくらでも調節できます。それは、私が『頭の回転が50倍速くなる脳の作り方』（フォレスト出版）の中でやり方を書いたように、ボトルネック外しが必要になります。 推論するときも常に並列で考えた方がいい。たくさんのことを同時にやるということは、シリアルボトルネックを外す訓練です。 親は子供に、抽象化する訓練をさせなきゃいけない。それは「説明」させればいい。親は子供に常に「なんでそうするの？」と聞かなきゃいけない。何をやっても全部説明させること。親も教えるときには「赤信号で止まるのは、赤信号は止まらなければいけないと学校で教わったと思うけど、なんでそう思う？」と説明させなきゃいけない。 経営者としての深い悩みを解決する方法 by 中山和義 \u0026ndash; 1966年生まれ。メンタルヘルス協会公認心理カウンセラー。 本で「こういうことを社員にさせるのがいい」とあると、すぐやらせます。そういうときに本がすごく便利です。それを読ませれば社員と共有できるからです。 今日はこれからの人生のバースデー by 箱田忠昭 \u0026ndash; インサイトラーニング（株）代表取締役。 「箱田さんどうしたの？遅れちゃダメじゃないですか」と怒られると思っていたのに、「大変でしたね？大丈夫ですか？」と心配されたんです。・・・デールカーネギーコースでは「相手の立場に立て」と教えられていました。 ずっと若い頃から勉強していれば必ず勝つ、ということではないでしょうか。 「コマ切れ時間」にすぐやる仕事なり、勉強のリストを作っておき、15分時間ができたらすぐ取りかかれるようにしておきます。 一流の人から教えてもらう！ by 本田健 \u0026ndash; 経営コンサルティング会社などを経営。 多くの成功者が「成功の秘訣」として必ず挙げる事柄がありました。「成功するためには本を読みなさい」ということと、「CD教材を聴きなさい」ということです。 学歴なんかあっても、「従業員」として働かざるを得ない。自分のビジネスをやるために本当に必要なのは、専門知識だ。それはセミナーやCD教材で学べる。 一流の人たちが何十年もかけて学んだこと・・・たった2、3時間でマスターできるのです。 スピーチの技術だとか、マーケティング、セールス、コミュニケーション術・・・そういう「人間関係」に関するものについては、人の言葉、すなわち音声のほうが、深く理解できるのです。 本や人との出会いと同じように、そこにCDもある。 海外のミステリー小説はオーディオブックをよく利用しています（これが英語のリスニングのいい勉強になるのです）。 ひとつの考え方が人生のすべてを変える可能性もあります。だから、そういう考え方に出会うチャンスは、できるだけ多く持ってもらいたいです。"
},
{
url: "/p/kojyx2x/",
title: "読書メモ『Javaの鉄則』ピーター・ハガー",
date: "2010-11-22T00:00:00Z",
body: "読書メモ『Javaの鉄則』ピーター・ハガー Javaの鉄則 ピーター・ハガー ピアソンエデュケーション 鉄則1 パラメータは参照渡しではなく値で渡される パラメータを参照渡しするという誤解がある。Java ではパラメータはすべて値渡しされる。オブジェクトをパラメータで渡す場合は、オブジェクトへの参照が値渡しされる。つまり、以下のようにしても呼び出し元のオブジェクトは変更されない。 public void doSomething(MyClass obj) { obj = new MyClass(); } 鉄則2 定数データおよび定数オブジェクトへの参照に final を使う final で定数を定義すると、別の場所での 代入 がエラーになる。 public class MyClass { private static final int mInt = 100; private static final Circle mCircle = new Circle(3.0); ... 例えば上記のように宣言されている場合、以下のような代入処理がエラーになる。 mInt = 200; // Error! mCircle = new Circle(5.0); // Error! オブジェクトの参照先の値は変更できることに注意。 mCircle.setRadius(6.0); // OK 鉄則3 非 static メソッドはデフォルトでオーバーライドできることを理解する メソッドを final で宣言すると、そのメソッドはサブクラスでオーバーライドできなくなる。 クラスを final で宣言すると、そのクラスはサブクラス化できなくなる。すべてのメソッドを暗黙のうちに final で宣言するのと同じ。 ▽メモ \u0026ndash; ユニットテストの書きやすさを考慮すると、final 宣言は実はあまり使うべきではない。参考：『レガシーコード改善ガイド』。 鉄則4 配列と Vector の選択に注意 配列の個々のエントリーはその型に基づくデフォルト値に設定される。数値は 0、boolean 値は false、オブジェクト型は null がデフォルト値。 Vector はオブジェクトへの参照しか含められないが、配列はオブジェクトへの参照とプリミティブ型のどちらでも含めることができる。プリミティブ型の場合は配列を使った方が遥かに効率的。 鉄則5 instanceof よりも多態を 多態を用いることでほとんどの instanceof の誤用を避けることができる。instanceof を使用しているコードを見たら、必ずそれを除去できないか考えるべき。 instanceof は効率的でないし、簡素でなく、拡張性がない。instanceof のような処理は本来 Java のランタイムシステムがやるべきこと。 鉄則6 絶対必要なときにしか instanceof を使わない Effective C++ で Scott Meyer は、「オブジェクトが T1 型だったらこうして、T2 型だったら他の処理をする、そのような形態のコードを書いていることに気が付いたら、自分の頬を叩きなさい」と述べている。これはまったく正しい。 クラスライブラリの設計が不適切なために instanceof を使わざるを得ない状況はある。例えば、Vector のようなコレクションの集合体を自分で操作できない場合は、instanceof を使う必要がある。 鉄則7 必要がなくなったらオブジェクト参照に null を設定する ある参照が必要なくなったときに null をセットすれば、ガーベジコレクションがメモリを開放する手出すけをすることができる。 多くのガーベジコレクションでは、他のスレッドをすべて保留してからガーベジコレクションを実行する。 鉄則8 参照型とプリミティブ型の違いを理解する オブジェクトのスタックエントリは、オブジェクト自身ではなくオブジェクトへの参照である。オブジェクトへの参照は、ヒープのある領域を指すポインタである。 MyClass obj2 = obj1; で、obj1、obj2 は同じオブジェクトを参照することになる。 鉄則9 == と equals を区別する オブジェクト同士の == での比較は、2つの参照が同じオブジェクトを指しているかを調べるだけ。つまり、obj1、obj2 が保持しているオブジェクトの実体へのアドレスが等しいかを見ているだけ。 意味的に2つのオブジェクトの内容が等しいことを調べるには、equals() メソッドを使用する。== が真なら equals も必ず真になるが、equals が真のときに == が真になるとを限らない。 Integer obj1 = new Integer(1); Integer obj2 = new Integer(1); System.out.println(obj1 == obj2); // false !! System.out.println(obj1.equals(obj2); // true 通常は異なるクラスのオブジェクトを equals で比較しても true になることはない。 Integer iVal = new Integer(100); Float fVal = new Float(100.0f); System.out.println(iVal == fVal); // false 鉄則10 equals のデフォルト実装をあてにしない equals を実装していないクラスでは、デフォルトでは以下のような java.lang.Object の equals 実装が使用される。 public boolean equals(Object obj) { return (this == obj); } つまり、equals を実装していないクラスでは、以下の2つは同じ意味になる。 if (obj1 == obj2) { ... } if (obj1.equals(obj2) { ... } equals は大体次のように実装する。メンバフィールドの比較も、オブジェクト同士の比較の場合は == ではなくて equals を使用すること。 @Override public boolean equals(Object obj) { if (this == obj) { return true; } if (obj == null || getClass() != obj.getClass() || !super.equals(obj)) { return false; } Person p = (Person) obj; return mName.equals(p.getName()) \u0026amp;\u0026amp; mAddress.equals(p.getAddress()) \u0026amp;\u0026amp; mAge == p.getAge(); } ※メモ float は Float.floatToIntBits で int に変換してから == で比較する double は Double.doubleToLongBits で long に変換して == で比較する 鉄則11 よく考えてから equals メソッドを実装する 2つのオブジェクトがメモリ上で同じ空間を占めていなくても、意味的に同じだと判断できることがある場合は equals メソッドを実装する。 鉄則12 equals メソッドの実装には getClass を使うのがよい getClass() を使って、2つのオブジェクトの型が同じでないときは false を返すようにするのが一番安全な方法。 鉄則13 基底クラスの super.equals を呼び出す サブクラスで equals メソッドを実装する場合は、親クラスのフィールドの同一性を super.equals を使ってチェックする。 鉄則14 equals メソッド実装での instanceof 使用はよく考える 派生クラスのオブジェクトと、基底クラスのオブジェクトが等しいと判断する equals を実装するには、getClass の代わりに instanceof を使用する必要がある。 public boolean equals(Object obj) { if (this == obj) { return true; } if (obj == null || !(obj instanceof Base) || !super.equals(obj)) { return false; } ... } このような、基底オブジェクトと派生オブジェクトの比較は受け入れがたい問題を引き起こすことがあるので、できれば equals メソッドの実装では、instanceof ではなく getClass でのクラス同一性を調べるようにした方がよい。 例えば、instanceof を使用して equals メソッドを実装してしまうと、対称性の問題が出ててくる。つまり、以下のような比較が同一の結果を返さなくなる。 if (base.equals(derived)) { ... } if (derived.equals(base)) { ... } 基底クラスで instanceof を使用した equals メソッドが実装されている場合でも、その派生クラスを作成する場合は、equals の実装で getClass() を使用するのが最良の方法。ただし、この場合も対称性の問題は避けられない。 Java ライブラリでは、equals メソッドの実装で getClass を使用したり、instanceof を使用したり一貫性がない。 鉄則15 equals メソッドを実装する際はこのルールに従うこと this との比較を行う。 Object 以外の基底クラスが equals を提供する場合は、super.equals を呼び出す。 基本的に getClass を使用する。 instanceof で基底クラスのオブジェクトとの一致を許す場合は、instanceof の問題を理解してから実装すること。 鉄則16 例外制御フローのメカニズムを理解する 例外が発生すると、制御は即座に以下の３つのうちの１つに移る。 catch ブロック finally ブロック それを呼び出したメソッド 鉄則17 例外を無視しない Java では、例外が発生して捕えられないと、例外が起きたスレッドが終了する。 鉄則18 例外を隠さない 例外を処理している間に、catch あるいは finally ブロックから別の例外がスローされると、もとの例外の情報が見えなくなってしまう。ひとつの解決策としては、発生したすべての例外をリストに保存する方法がある。 鉄則19 throws 文節の欠点を知る あるメソッドの throws 文節に例外を追加すると、それを間接的に呼び出す全てのメソッドに影響する。エラー処理に関しては開発の初期の段階から計画的に構築し、後から例外処理を追加するのはなるべく避けるようにする。"
},
{
url: "/p/sfvqxtr/",
title: "Android開発: 3種類のタイムスタンプの使い分け",
date: "2010-11-09T00:00:00Z",
body: "Android開発: 3種類のタイムスタンプの使い分け Android において long 型のタイムスタンプを取得する方法には、以下の 3 種類があり、それぞれ意味が異なるため、用途に応じて使い分ける必要があります。 System. currentTimeMillis() Epoch (1970-01-01) を基準にしたシステムタイムまでの経過ミリ秒。 ユーザがシステムの現在時刻を変更すると、過去にジャンプしたりするので、タイムスタンプベースのタイマーなどに使用するべきではない。時計の UI を表示するときに使用する。 android.os.SystemClock. elapsedRealtime() Android 端末をブートしてからの経過ミリ秒。uptimeMillis() とは異なり、スリープ中にもカウントされる。 AlarmManager はスリープ中の時間もカウントして発火するので、内部で elapsedRealtime() ベースのタイマを使用する。これは、AlarmManager のタイプで ELAPSED_REALTIME (ELAPSED_REALTIME_WAKEUP) を指定した場合の振る舞いで、RTC (RTC_WAKEUP) を指定すれば、System.currentTimeMillis() ベースのタイマで発火するように指定することもできる。 android.os.SystemClock. uptimeMillis() Android 端末をブートしてからの経過ミリ秒。スリープ中にはカウントされない。 タイムスタンプベースのタイマーに使用できる。例えば Handler クラスは、uptimeMillis() ベースのタイマを使用して非同期コールバックを発火している。 AlarmManager Handler. postAtTime Handler. sendMessageAtTime System.currentTimeMillis UTC（システム時刻設定で変化） ○ RTC(_WAKEUP) × × SystemClock.elapsedRealtime ブートからの経過時間（スリープ時間含む） ○ ELAPSED_REALTIME(_WAKEUP) × × SystemClock.uptimeMillis ブートからの経過時間（スリープ時間含まず） × （スリープ時カウントできないため） ○ ○"
},
{
url: "/p/p6awy3z/",
title: "読書メモ『レガシーコード改善ガイド』マイケル・C・フェザーズ",
date: "2010-10-30T00:00:00Z",
body: "読書メモ『レガシーコード改善ガイド』マイケル・C・フェザーズ レガシーコード改善ガイド マイケル・C・フェザーズ 翔泳社 はじめに テストのないコードは悪いコード（レガシーコード）である。 これがマイケル・C・フェザーズの強いメッセージです。 どれだけうまく書かれているかは関係ない。テストが書かれていない＝悪であるとまで言い切っています。 どれだけ美しいか、オブジェクト指向か、きちんとカプセル化されているかは関係ない。テストがなきゃだめだ！ 第1部 変更のメカニズム 第1章 ソフトウェアの変更 リファクタリングでは、 小さな変更を繰り返し行う。 変更を容易に行うためテストでサポートする。 機能を変更すべきではない。 コードの変更時に問題になるのは、影響範囲を把握できないこと。変更を安全に行うために最も重要なことは、影響範囲を理解すること。 変更を避けると腕がなまってしまう。大きなクラスを分割する作業は週に２，３回くらい行っていないと、困難な仕事になってしまう。頻繁に変更を行っていれば、何が分割できるかの検討をつけやすくなり、変更作業が容易になる。 第2章 フィードバックを得ながらの作業 テストを用意することには、「正しいことを確認するため」だけでなく、「変更を検出するため」という目的もある。 特定のコードにエラーがあると思ったときにテストハーネスを利用できれば、手早くテストコードを書いて、本当にそこにエラーがあるのか確認することができる。 優れた単体テストの条件 実行が速い: 速く走らないとしたら、それは単体テストではない。0.1 秒もかかっていたら遅い単体テストである。「DBアクセス」、「ネットワーク通信」、「ファイルシステムアクセス」、「実行するための環境設定」が必要なものは単体テストとは言えない。 問題個所の特定がしやすい 他のクラスと依存関係があるクラスはテストハーネスに入れられない。例えば、DbConnection に依存しているクラスをテストしたい場合は、まずはインタフェース IDbConnection を導入して依存を切る必要がある。 価値をもたらす機能的な変更を行いながら、システムのより多くの部分をテストで保護していくべき。 扱いやすくなるように大きなクラスを分割するといった些細なことによって、アプリケーションに大きな違いが出てくる。 第3章 検出と分離 テストを整備する際に依存関係を排除するのには2つの理由がある。 検出: コードの計算した値にアクセスできないときに、それを検出するために依存関係を排除する。 分離: コードをテストハーネスに入れて実行することすらできないとき、分離するために依存関係を排除する。 ソフトウェアを分離するには様々な方法があるが、検出のための主な手段は「強調クラスの擬装」のひとつしかない。 あるクラスの依存をインタフェースの導入によってなくした場合、そのクラスに FakeObject を渡してテストすることになる。FakeObject ではテスト対象のクラスから渡されたデータを記録することで、テスト対象のクラスが正しくデータを渡しているかを検証できる。依存部分を切り離すことにより、依存していたインタフェースでやりとりしているデータが正しいかどうかをテストすることができる。 public void testPrintItem() { FakePrinter printer = new FakePrinter(); Item item = new Item(printer); // テスト対象のクラス item.doSomething(100); // テスト対象のメソッド assertEquals(\u0026#34;This is a result\u0026#34;, item.getLastLine()); } オブジェクト指向以外の言語では、代替関数を定義して、その中でテストからアクセスできるグローバルなデータに値を記録する。 擬装オブジェクトに、結果が正しいかを確認する機能を追加したものが「モックオブジェクト」。モックオブジェクトは協力なツールだが、すべての言語に対応するモックオブジェクトフレームが提供されているわけではない。しかし、大抵の場合は、単純な擬装オブジェクトで十分である。 第4章 接合モデル テストが可能になるようにクラスを取り出す作業を行っていると、どのような設計が優れているかという基準が変わってくる。 ソフトウェアを接合部 (Seam) という観点から見ることで、コードにすでに含まれている依存関係を排除するための手掛かりを見出すことが可能になる。Seam とは直接その場所を変更しなくても、プログラムの振る舞いを変えられることのできる場所。 Java では同じ名前のクラスを別のディレクトリに置き、CLASSPATH を変更することで別のクラスにリンクすることができる。（リンク接合部: link seam） 第5章 ツール 自動リファクタリングツール: リファクタリングツールを使って自動リファクタリングを行う場合、振る舞いが変わっていないか注意する必要がある。例えば、リファクタリング後に、あるメソッドの呼び出し回数が変わっている場合、そのメソッドに副作用があると振る舞いが変化する。 モックオブジェクト (mock object): 他のコードを取り除いて、テスト時に自分のコードを完全に実行させるには、代わりに正しい値を返してくれるものが必要になる。オブジェクト指向のコードでは、これをモックオブジェクトと呼ぶ。 単体テストハーネス: xUnit テスティングフレームワークは、ほとんどの言語に移植されている。JUnit, CppUnit, NUnit\u0026hellip; 一般的なテストハーネス: FIT (Framework for Integrated Test) は統合テスト用のテスティングフレームワーク。システムに関する文書を書き、その中にシステムの入力と出力について記述した表を含めることができれば、FIT フレームワークがテストを実行してくれる。FitNesse は wiki 上に構築された FIT で、FIT テストを定義するときに階層構造の Web ページを使うことができる。 第2部 ソフトウェアの変更 第6章 時間がないのに変更しなければなりません 一般的に変更箇所は集中する。今日ソフトウェアを変更しているのであれば、近い将来、そのすぐ近くを変更することになる。 今すぐクラスを変更しなければならないのなら、テストハーネス内でそのクラスのインスタンス化を試みてみる。 システムに新しい要件を加えるときの方法。 スプラウトメソッド (sprout method): 新しい機能を新しいメソッドとして記述する方法。既存のコードに直接手を加えるよりも望ましい結果をもたらす。 長所: 古いコードと新しいコードを明確に区別できる。 短所: 元のコードはテストするわけでもなく、改善するわけでもない。 スプラウトクラス (sprout class): 変更部分を新しいクラスで実現する方法。変更対象の既存のクラスをテストハーネス内でインスタンス化できない場合は、テストを書けないのでスプラウトメソッドは使えない。既存クラスの依存を排除するのに時間がかかりすぎる場合、新しいクラスを導入して、そこだけテスト可能にするという方法がある。 長所: コードを直接書き換える方法よりも、確信を持って変更を進められる。 短所: 仕組みが複雑になること。 第7章 いつまで経っても変更作業が終わりません あまりに多くの依存関係を持つクラスは、大きなコードの塊を切り離し、テストで保護できるかどうかを調べるとよい。 第8章 どうやって機能を追加すればよいのでしょうか? この章には、TDD の基本的な進め方が述べられています。 強力なリファクタリングは数多くあるが、最も強力なのはクラス名の変更である。開発者のコードの見方を変え、考えもしなかった可能性に気づかせてくれる。 第9章 このクラスをテストハーネスに入れることができません コンストラクタで渡しているオブジェクトが外部リソースなどを利用している場合、そのクラスのインタフェースを抽出し、擬装オブジェクトを渡してテストするようにする。例えば、コンストラクタでデータベースへの接続を行うオブジェクトを渡している場合は、その FakeConnection などの擬装オブジェクトを渡すようにする。リファクタリングをサポートしたツールがあれば、インタフェースの抽出は簡単にできる。 テストコードはきれいであるべき。それは簡単に理解でき、変更できるものでなければならない。 テストしたいクラスが、生成しづらいパラメータを必要としていたら、Null を渡すことを考えてみる。実際にそのパラメータがテスト中で参照されたら例外を投げるので分かるはず。実際にそのパラメータが必要になった時点で、必要なオブジェクトを生成するように変更すればよい。ただし、C++ のように Null ポインタエラーを検知できない言語ではこの方法は使用できない。 通常は Null を本番コードで使用すべきではない。Null オブジェクトパターンなどを適用できないか考えてみる。 あるクラスをテストする際に、依存するクラスのインスタンスを作らなければならない時、そのクラスの振る舞いがテストに影響することがある。例えば、その依存クラスのコンストラクタで DB へのコネクションを張っていたりすると単体テストが書けない。このような場合は、依存クラスのサブクラスを作って connect() などをオーバーライドしてしまえばよい。これを可能にするためにも、コンストラクタでのハードコードは避けてメンバメソッドを呼び出すような実装を心がけるべき。 依存クラスのコンストラクタ内で、外部リソースやライブラリに依存するクラスのオブジェクトを生成している場合もテストができなくなる。その場合は、コンストラクタのパラメータでオブジェクトを渡すようにする（コンストラクタのパラメータ化）。元々のシグネチャを持つコンストラクタは残しておいて、新しくパラメータをとるコンストラクタを追加すればよい。コンストラクタ内でオブジェクトが生成されていて、生成の依存関係がない場合には、コンストラクタのパラメータ化が非常に簡単に適用できる。 テストハーネスの中で Singleton を含むコードを実行するには、Singleton の制約を緩和する必要がある。 Singleton クラスに、Singleton インスタンスの setter メソッドを用意する。 Singleton クラスのコンストラクタを private から protected に変更する。 Singleton クラスのインタフェースを抽出し、テストコードから擬装オブジェクトを生成して Singleton クラスにセットする。あるいは、Singleton クラスをサブクラス化して、各メソッドをオーバーライドする方法もある。 第10章 このメソッドをテストハーネスで動かすことができません オリジナルのコードは複雑すぎるので、ここでは簡素化したコードに置き換えてざっと説明してみます。 テストしたいメソッドが private である private メソッドをテストしたい場合、そのメソッドは public にすべきである。 public メソッドにすべきかどうかで悩んでしまう場合、大抵は、そのクラスが多くのことを行いすぎであり、修正すべきことを意味している（1つのクラスが複数の責務を持ってしまっている）。 よい設計はテスト可能であり、テスト可能でない設計は悪い設計である。 ▲まく注記: 例えば、複雑なアルゴリズムや演算処理を担う private メソッドがあるのであれば、それはおそらく専用クラスの public メソッドとして作成し、テストを記述すべきということでしょう。 private メソッドを別クラスに括りだして、public 化する余裕がない場合は、以下のようにテスト用のラッパークラスを作成して解決する方法がある。 // テスト対象のクラス class Sample { protected: // ← private だったものを protected にする void needToTest(); }; // テスト用に作成するラッパークラス class TestingSample : public Sample { public: // ← テスト用にサブクラス化して public にする void needToTest() { // 親クラスのメソッドを呼び出す Sample::needToTest(); } }; // C++ では下記のように using を使って委譲処理を簡潔に記述できる class TestingSample : public Sample { public: using Sample::needToTest(); } この方法は、メソッドを単純に public 化するのと本質的には変わらないので微妙な対応方法だが、リファクタリングすべき箇所の目印となる。 Java などの言語ではリフレクションによって private メソッドのテストを記述することはできるが、根本的な依存関係の問題を先延ばしにしているだけである。その種のごまかしをすると、コードがどの程度悪くなっているのかに気付きにくくなってしまう。 標準ライブラリの継承できないクラス、インスタンス化できないクラス依存している Java の final クラス、.NET の sealed クラスのような、継承できないクラスに依存したコードがあると、うまくテストがかけないことがある（インスタンス化できなかったり）。 このような制御不可能なライブラリのクラスに直接依存したコードがあったら、将来の変更に対応できるようにインタフェースを抽出し、ラッパーで隔離するのがよい。 例えば、.NET の sealed なクラス HttpPostedFile に直接依存したコードがあったら、IHttpPostedFile インタフェースとして抽出し、HttpPostedFileWrapper というラッパクラスを作成する。 public class HttpPostedFileWrapper : IHttpPostedFile { public HttpPostedFileWrapper(HttpPostedFile file) { this.file = file; } public string FileName { get { return file.FileName; } } public int ContentLength { get { return file.ContentLength; } } } 元の HttpPostedFile クラスに依存したコードを、IHttpPostedFile インタフェースを使用したコードに置き換え、HttpPostedFileWrapper 経由で HttpPostedFile クラスを使用するようにする。テストコードでは、IHttpPostedFile を実装したスタブクラスを用意すればよい。 GUI に強く結びついたコードになっていて結果を検出できない 例えば、下記の UI 系クラスは、イベントハンドラ内で表示内容の構築から UI 表示までの処理を一括で行っている。 このイベントハンドラを実行した結果は、実際の UI 上の表示が更新されるという形で表れるので、テストコードから直接呼び出しても結果の妥当性を判断することができない。 また、表示内容を構築するロジックが UI 系のクラスに依存していると、その部分を別クラスに抽出することもできなかったりする。 public MyFrame extends Frame { public void actionPerformed(Event event) { if (\u0026#34;activity\u0026#34;.equals(event.getCommand())) { // ... display.setDescription(...); display.show(); } } } このようなケースでは、UI 系クラスをサブクラス化し、取得したい結果だけをフックして参照できるようにしつつ、実行されてはいけない UI 処理をオーバーライドにより削除してしまうという方法がある。 一言で言えば、「サブクラス化してテストしたい部分だけを生かす」ということ。 public MyFrame extends Frame { // イベントハンドラはテストコードからは直接呼び出さないので、 // 処理を public メソッドに委譲するだけにする。 public void actionPerformed(Event event) { performCommand(event.getCommand()); } // テストコードから直接呼び出す部分を public メソッドに抽出する。 // ここにはテストしたいビジネスロジックが含まれており、 // かつ、テストでは動作させたくない UI 更新処理も含まれている。 public void performCommand(String command) { if (command.equals(\u0026#34;project activity\u0026#34;)) { ... updateView(...); ... setResult(...); } } // UIを実際に更新する部分も分離する。 public void updateView(String desc) { display = new Display(); display.setDescription(desc) display.show(); } } そして、テストコードでは、この UI 系のクラスをサブクラス化し、処理結果だけを機械的に取得できるようにする。 UI 制御を行っている部分は updateView メソッドとして分離してあるので、オーバーライドして空っぽにしてしまえば、テストコードを実行したときに UI が表示されてしまうのを防ぐことができる。 public TestingMyFrame extends MyFrame { String result = \u0026#34;\u0026#34;; public void updateView(String desc) { // 何もしない } public void setResult(String result) { this.result = result; } } // テストコードのイメージ public void testPerformCommand() { TestingMyFrame frame = new TestingMyFrame(); frame.performCommand(\u0026#34;activity\u0026#34;); assertEquals(\u0026#34;Correct result\u0026#34;, frame.result); } ▲まく注記: もちろん Frame クラスが単独でインスタンス化できないと、このようなテストは不可能ですね。 ここでは、どうしても部分的にしかテストできないクラスがあるときに、何とかしてその部分だけでもテストできるようにする方法の一例があげられているのだと捉えればよいでしょう。 コラム: コマンドとクエリーの分離 コマンドとクエリーの分離 (Command/Query Separation) は、Bertrand Meyer（Eiffel の開発者）が設計の原則で、メソッドはコマンドあるいはクエリーのいずれかであり、両方にすべきではないというもの。 コマンド: オブジェクトの状態を変更できるが値は返さないメソッド。 クエリー: 値は返すがオブジェクトの状態を変更しないメソッド。 この原則に従うことでわかりやすい設計になる。 例えば、メソッドがクエリーであれば、副作用を起こさずに何度も続けて呼び出せることがすぐにわかる（C++ ではメソッドに const キーワードが付いていれば、クエリーであることがすぐにわかる）。 第11章 変更する必要がありますが、どのメソッドをテストすればよいのでしょうか? テストすべき場所はどこか この章には、変更の影響範囲を調べ、テストする部分を決めるまでの流れに関して記述されています。 基本的な手順は次の通り。 変更の影響範囲を調べて、どこで変更を検出することができるかを明らかにする。影響スケッチ (effect sketch) を描くとよい。 どこで影響を検出できるかを明らかにしたら、その中から選んでテストを記述する（影響が伝搬していった先の方でテストを書くと効果が大きい）。 影響は基本的に以下の３種類の方法で伝搬する。 戻り値が呼び出し側で使われる パラメータとして渡されたオブジェクトが変更される 静的データや、グローバルなデータが変更される （書籍には明記されてませんが、メンバ変数などの変更もこれに含むと考えればよい） メソッドの利用者になり得るスーパークラスとサブクラスも忘れずに確認する必要がある。 あと、使用している言語についてよく知っていることは重要。 例えば、C++ では、変数宣言に mutable キーワードを指定した場合、const メソッドからその変数を更新することができてしまう。 const メソッドだから、意味的に const（変更されない）と捉えていると危険なことになります。 影響を単純化する 小さな重複部分を削除することが、影響の広がりを小さくすることに繋がる。 例えば、下記の影響スケッチは、declarations というフィールドの変更が、getInstance メソッドと getDeclaration メソッドに影響することを示している（言い換えると、2つのメソッドが declarations フィールドを参照している）。 getInterface の実装の中で直接 declarations フィールドを参照せず、getDeclaration メソッドを呼び出すように変更すれば、影響スケッチは下記のようにシンプルになる。 こうすることで、getInterface のテストをすれば、getDeclaration のテストもできたことになる。 影響スケッチが末広がりな形になっていたら、このような小さな変更で改善できないかを考えてみるとよい。 著者の意見 著者の意見として、「影響を調査できる統合開発環境があるといいなぁ。コードの一部を選択してホットキーを押すと、選択したコードの変更によって影響を受ける、すべての変数とメソッドを示してくれるようなもの」というものがあります。 ▲まく注記: 確かにこのようなものが一般的になれば、ユニットテストや、リファクタリングもずいぶん作りやすくなりそうです。 ただ、フレームワークによっては影響範囲というものは動的にしか決まらない部分（Android の Intent のように、レシーバーが動的に決まるものなど）も多々あるので、なかなか難しいのかもしれません。 マイケル・C・フェザーズは、カプセル化とテストが対立した場合（どちらかを諦めないといけない場合）、テストによる保護を優先する立場を取っています。 カプセル化自体は目的ではなく、理解するための手段であるということ、テストはコード調査を簡単にし、将来カプセル化を強めるために役立つということなどを理由に挙げています。 第12章 1カ所にたくさんの変更が必要ですが、関係するすべてのクラスの依存関係を排除すべきでしょうか? 割り込み点 割り込み点 (interception point) とは、特定の変更による影響を検出できるプログラム上の場所のこと。 例えば、private フィールドに影響が及ぶとしても、そこでは影響を検出できないので、割り込み点ではない。 多くの場合、変更のための最善の割り込み点は、変更しようとしているクラスの public メソッドになる。 変更点のすぐそばにある割り込み点を選択するのが良い考えである。 絞り込み点 絞り込み点 (pinch point) とは、影響スケッチの集約された場所であり、少数のメソッドに対するテストで、多くのメソッドの変更を検出できる場所である。 つまり、割り込み点の中で、テストを書くべき第一候補となる場所である。 例えば、ある変更に関して下記のような影響スケッチが描けた場合、絞り込み点は BillingStatement.makeStatement となる。 ここにテストがあれば、そこより上の影響をすべて把握することができる。 ただし、多くの場合、絞り込み点を見つけるのはほとんど不可能である。 直接的に影響を及ぼすものがたくさんあると、影響スケッチは大きな絡み合った木のようになってしまう。 そのような場合は、一度にあまりにたくさんの変更をしようとしているのかもしれないので、1つや2つの変更だけを取り上げて絞り込み点を探すのがよい。 最終的に絞り込み点が2つだけ見つかったときに、そのどちらか片方だけにテストを書くだけで十分かどうかを判断するには、「そのメソッドを壊したら、この場所で変更を検出できるか？」と問いかけてみればよい。 既存のコードに変更を加えるとき、絞り込み点を見つけて、そこにテストを書くのがファーストステップになる。 絞り込み点のテストは、森の中に歩いて立ち入り、線を引いて、「この区域すべては私のものだ」と言うようなものだ。 その後、その区域内のリファクタリングを行い、より細かい粒度でテストを書いていけばよい。 最終的には絞り込み点のテストは削除し、それぞれのクラス用の単体テストを使って開発を進めることができるようになる。 絞り込み点を見つけることは、コード改善のためのヒントにもなる。 絞り込み点は、自然なカプセル化の境界を示している。 大きすぎるクラスがある場合、影響スケッチを描いて絞り込み点を見つけることで、どの境界でクラス分離するのがよいかが分かる。 第13章 変更する必要がありますが、どんなテストを書けばよいのかわかりません ほとんどのレガシーコードでは、すべてのバグを見つけて修正することを目標にすると作業は決して終わらなくなってしまう。 レガシーコードを修正する必要があるときは、ソフトウェアの仕様書やプロジェクトのメモを掘り起こしてテストコードを書く方法の他に、仕様化テスト (characterization test) を書いてコードの振る舞いを明らかにする方法がある。 仕様化テスト (characterization test) 仕様化テスト（マイケル・C・フェザーズの造語）は、コードの実際の振る舞いを明らかにするテスト。 「システムはこれをすべきだ」とか「こうしていると思う」ということを確認するテストではない。 仕様化テストは、システムの現在の振る舞いをそのまま文書化する。 下記が仕様化テストを書くときの手順である。 テストハーネスの中で対象のコードを呼び出す 失敗するとわかっている表明 (assert) を書く 失敗した結果から実際の振る舞いを確認する コードが実現する振る舞いを期待するように、テストを変更する 以上の手順を繰り返す ▲まく注記: ようするに、現在の振る舞いを正しいものとしてユニットテストを書くだけですね。 仕様化テストはどこまで書けばよいか？ 仕様化テストは無限に書けてしまうが、いつやめればよいのか？ 重要なことは、ブラックボックステストを書いているわけではないということ。 仕様化テストを書くときは、対象となるコードを読むことができる。 コードに加えたい変更について考え、変更に起因するあらゆる問題を、今持っているテストで検出できるかを考えてみるとよい。 できない場合、検出できると確信を持てるまでテストを追加する。 それでも確信できない場合は、別の方法でソフトウェアを変更すること（つまり、仕様書などの文書を調べてテストを記述すること）を考えた方が安全。 仕様化テストでバグを発見した場合 a) リリース前なら … 修正する。 b) リリース後なら … 関係者に周知して相談。もちろん修正するのが望ましいが、影響度合いによる。 ▲まく注記: 仕様化テストを書いたときは、それが望ましい振る舞いを調べるためのテストではなく、あくまで現在の振る舞いを調べる仕様化テストとして書いたことが分かるようにしておいた方がよいですね。 第14章 ライブラリへの依存で身動きが取れません 特定のライブラリに強く依存したコード → ベンダーがライブラリを値上げする → 利益出ないので乗り換えたい → 無理。死亡。 ライブラリの直接呼出しをコード内に分散させてはならない。使用するライブラリの変更は絶対ないと考えるかもしれないが、勝手な予想にすぎない。 言語の機能を利用して、設計上の制約に従わせようとするライブラリの設計者は、過ちを犯していることが多い。優れたコードはテスト環境でも問題なく動くものである。本番環境に特化した制約は、テスト環境で行いたい作業を不可能にしてしまうことがある。 ▲まく注記: 要するに、ライブラリとの結合部はゆる～く置き換えられるような設計になっていないとテストできなくなっちゃうよ。本番環境で完璧に動けばOKという考え方は間違っているよ。ということ。 第15章 私のアプリケーションは API 呼び出しだらけです ライブラリの API 呼び出しをあちこちで行っているシステムは、自分たちの手作りのシステムに比べて扱いが難しくなる。 理由1: 表面的な API 呼び出ししかないので、構造を改善する方法を調べるのが難しい。 理由2: その API が自分たちの所有物でないので、インタフェースを改善しにくい。 こういったシステムにアプローチする方法は2つある。 API をラップする 責務をもとに抽出する API をラップする方法 以下のような状況では API をラップしてしまうのが有効。 API が比較的小さい。 サードパーティライブラリへの依存を完全に分離したい。 API を通じたテストが不可能なため、テストを書くことできない。 責務をもとに抽出する 以下のような状況では、コード内の処理を責務をもとに抽出し、より上位のメソッドとしてまとめてしまうのが有効。 API が複雑である。 安全なメソッド抽出をサポートするツールがあるか、手動での抽出を安全に行う自信がある。 API をラップする方法の方がシンプルに感じるが、実際にはうまくいかないケースがある。 例えば、下記のようなコードで Trasport のラップすることを考えてみる（テスト用のスタブとしてサブクラスを作る）。 Session smtpSession = Session.getDefaultInstance(props, null); Transport transport = smtpSession.getTransport(\u0026#34;smtp\u0026#34;); transport.connect(host.smtpHost, host.smtpUser, host.smtpPw); よく見ると、Transport は Session から作成されているので、Session の方をラップしなければいけないことがわかる。 でも、Session クラスはライブラリ内で final 定義されていてサブクラス化できない。 こうなると、ラッパ用のサブクラスを作成することは不可能なので、2つ目の、責務をもとに抽出するという方法を取らざるを得なくなる。 API をラップする方法の方が作業量は多くなるが、サードパーティライブラリから自分たちのコードを切り離したいときには便利である。 責務をもとに抽出する方法では、コードをより上位のインタフェースに依存させることが可能となるが、抽出したコードはテストで保護できないかもしれない。 第16章 変更できるほど十分に私はコードを理解していません コードを印刷することで、印をつけることができるようになる。 長いコードを色分けすることで、責務の分担や、構造の理解に役立てる。 テストを書かずにリファクタリングすること (試行リファクタリング: scratch refactoring) は、そのコードを理解するために非常に役に立つ。ただし、そのコードはチェックインせずに破棄すること。 第17章 私のアプリケーションには構造がありません 大規模なシステムの全体像を理解する方法のカタログが『Object-Oriented Reengineering Patterns』 に載っている。 他には下記のような方法もある。 システムのストーリーを話す 2人以上でシステムの振る舞いをストーリー仕立てで話すことで、他のメンバに説明する方法。 「このシステムのアーキテクチャはどうなっていますか？」という質問から始め、「他には何かありますか？」と繋げていく。 シンプルな会話ベースで説明することにより、システム自体をシンプルにするのを促す効果がある。 ストーリーは指針を提供する。 白紙のCRC CRC は、クラス (Class)、責務 (Responsibility)、協調 (Collaboration) の略。 それぞれのカードにクラス名、クラスの責務、強調するクラス（やりとりする他のクラス）の一覧を記述する。 ここで提案する方法は、白紙の CRC カード、つまり、単なる白いカードを使ってアーキテクチャを説明する方法で、カードを何らかのインスタンスに見立ててシステムの動きを表現する。 例えば、あるインスタンスが入力と出力の接続を持つのであれば、1つのカードの上に二枚のカードを重ねる。 コレクションを表現する場合も、カードの上にカードを重ねる。 そして、それぞれのカードを動かしながら、システム全体の動きを説明する。 第18章 自分のテストコードが邪魔になっています 第19章 私のオブジェクトはオブジェクト指向ではありませんが、どうすれば安全に変更できるでしょうか? 第20章 このクラスは大きすぎて、もうこれ以上大きくしたくありません 第21章 同じコードをいたるところで変更しています 第22章 モンスターメソッドを変更する必要がありますが、テストを書くことができません 第23章 どうすれば何も壊していないことを確認できるでしょうか? 第24章 もうウンザリです。何も改善できません) 第3部 依存関係を排除する手法 第25章 依存関係を排除する手法"
},
{
url: "/p/eecgkww/",
title: "ネットワークトラブルの調査手順",
date: "2010-10-10T00:00:00Z",
body: "ネットワークトラブルの調査手順 ネットワークトラブルはホストに近いところからチェックしていくのがセオリーです。 ソフトウェア的要因よりも、ハードウェア的要因の方を先に調べるのがよいです。 ハードウェア的要因 ケーブルの断線 NIC の故障 電源の故障 ポートの接触不良 機器の熱暴走 ソフトウェア的要因 IP アドレスの設定ミス デフォルトゲートウェイの設定ミス VLAN の設定ミス ルーティングテーブルの不具合 サーバアプリケーションの設定ミス／不具合 参考: NETWORKWORLD - May 2007 ping による調査 あるホストに ping が通らないときは、以下の順番で ping を通す確認をしていきます。 テスト結果は正常時の結果と比べなければ意味がないので、正常時の tracert 結果などを定期的にとっておくことが重要です。 ループバックアドレスに対して ping TCP/IP モジュールの異常の可能性 ホストの IP アドレスへ ping OS が NIC を認識していない可能性 同じスイッチに接続された別の PC へ ping スイッチのポート、ケーブルの故障 VLAN の設定ミス、接続ミス スイッチ自体には IP アドレスは設定されないので、別の PC に ping することで、スイッチまでの接続を確認する。 ルータに ping ルータのダウン、アドレス設定ミス ルータの別のポートへ ping ルーティングプロセスの異常 インタフェースの設定ミス ルータは複数のネットワークにつながっているので、別のネットワーク用のポートにも ping する必要がある。 異なるネットワークの PC へ ping tracert で、通信不能ネットワークを切り分け ターゲットホストに ping ターゲットホストのダウン アプリケーソンレベルの確認 参考: NETWORKWORLD - May 2007"
},
{
url: "/p/2iccv8a/",
title: "SQLite のテーブル作成に関するメモ",
date: "2010-08-01T00:00:00Z",
body: "SQLite のテーブル作成に関するメモ SQLite 3 のフィールド型 テーブル作成時 (CREATE TABLE) に指定したフィールド定義に含まれているテキストにより、以下のようにフィールド型が決定されます。 INTEGER 型: INT という文字列を含む場合。 TEXT 型: CHAR、CLOB、TEXT を含む場合。 NONE 型: BLOB を含む型、あるいはデータ型が特定されない場合。 NUMERIC 型: それ以外の場合。 テーブルが存在しない場合だけテーブルを作成する (IF NOT EXISTS) CREATETABLEIFNOTEXISTStbl(idINTEGERPRIMARYKEY,nameTEXT,binBLOB); 逆に、テーブルが存在する場合だけテーブルを削除するということもできます。 この場合は、IF NOT EXISTS の代わりに、IF EXISTS を使用します。 DROPTABLEIFEXISTStbl; NULL の追加を禁止する (NOT NULL) フィールドの定義時に、NOT NULL というフィールド制約を加えておくと、データ追加時にそのフィールドの値を省略できないようになります。 CREATETABLEtbl(f1NOTNULL,f2,f3); 動作確認 sqlite\u0026gt; INSERT INTO tbl(f1, f2) VALUES(100, 200); sqlite\u0026gt; INSERT INTO tbl(f2, f3) VALUES(200, 300); SQL error: tbl.f1 may not be NULL 同じ値の入力を禁止する (UNIQUE) フィールドの定義時に、UNIQUE というフィールド制約を加えることで、別のレコードに入っている値と同じ値を追加できないようになります。 CREATETABLEtbl(nameUNIQUE); 動作確認 sqlite\u0026gt; INSERT INTO tbl(name) VALUES(\u0026#39;Jack\u0026#39;); sqlite\u0026gt; INSERT INTO tbl(name) VALUES(\u0026#39;Jack\u0026#39;); SQL error: column name is not unique 自動的に連番を振る (INTEGER PRIMARY KEY) フィールドの定義で、INTEGER PRIMARY KEY を指定しておくと、データ追加時にそのフィールドの値を指定しなかった場合に、自動的に連番を振ってくれます。 CREATETABLEtbl(idINTEGERPRIMARYKEY); 動作確認 sqlite\u0026gt; INSERT INTO tbl(id) VALUES(NULL); sqlite\u0026gt; INSERT INTO tbl(id) VALUES(NULL); sqlite\u0026gt; INSERT INTO tbl(id) VALUES(NULL); sqlite\u0026gt; SELECT * FROM tbl; 1 2 3 自動的に日付・時刻を格納する (DEFAULT CURRENT_TIMESTAMP) フィールドの定義に日時関連の DEFAULT 制約を設定しておくと、データの追加時にそのフィールドに何も指定しない場合に現在の日時をセットしてくれます。 DEFAULT CURRENT_DATE: 現在の日付 (2010-08-21) DEFAULT CURRENT_TIME: 現在の時刻 (14:30:56) DEFAULT CURRENT_TIMESTAMP: 現在の日時 (2010-08-21 14:30:56) 上記の日時は、UTC で格納されるので、実際にこの値を取得してローカルタイムで表示する場合は、時差などを考慮して時刻を表示する必要があります。 テーブルの作成例 CREATETABLEtbl(idINTEGERPRIMARYKEY,dateDEFAULTCURRENT_TIMESTAMP); 動作確認 sqlite\u0026gt; INSERT INTO tbl(id) VALUES(1); sqlite\u0026gt; INSERT INTO tbl(id) VALUES(2); sqlite\u0026gt; INSERT INTO tbl(id) VALUES(3); sqlite\u0026gt; SELECT * FROM tbl; 1||2010-07-31 19:15:27 2||2010-07-31 19:15:40 3||2010-07-31 19:15:44"
},
{
url: "/p/h45duja/",
title: "Excel でよく使うショートカット",
date: "2010-05-31T00:00:00Z",
body: "Excel でよく使うショートカット ウィンドウ制御 ショートカット 説明 Ctrl + F1 リボンを最小化する／元に戻す Ctrl + PageDown 次のシートへ Ctrl + PageUp 前のシートへ Ctrl + Tab 次のブックへ Ctrl + Shift + Tab 前のブックへ Alt リボンをアクティブにする（左右キーでタブ切り替え） カーソル移動 ショートカット 説明 Enter 入力確定してカーソルを下へ Shift + Enter 入力確定してカーソルを上へ Tab 入力確定してカーソルを右へ Shift + Tab 入力確定してカーソルを左へ Home 先頭の列にジャンプ Ctrl + カーソル 値のあるセル範囲で境界位置へジャンプ（End → カーソルでも同様） Ctrl + Home 一番左上 (A1) にジャンプ Ctrl + End データのある矩形範囲の一番右下にジャンプ 編集 行と列の挿入、削除 ショートカット 説明 Shift + Space 行を選択 Ctrl + Space 列を選択 Ctrl + A 全体の選択 Ctrl + - 選択したセルの削除 Ctrl + + 新しくセルを挿入 上記の組み合わせで、行や列の削除、挿入がキーボードだけで素早く行えます。 例えば、行を削除したければ、Shift + Space で行を選択し、Ctrl + - で削除できます。 値の挿入 ショートカット 説明 Ctrl + R 左のセルをコピー Ctrl + D 上のセルをコピー Alt + ↓ オートコンプリートの一覧を表示（上方向にあるセルが候補になるっぽい） Ctrl + ; 日付の挿入 Ctrl + : 時刻の挿入 Shift + F2 コメントの挿入 Shift + F3 関数の挿入 書式の変更 ショートカット 説明 Ctrl + 1 書式設定のダイアログを開く Ctrl + 2 太字の On/Off Ctrl + 3 斜体の On/Off Ctrl + 4 下線の On/Off Ctrl + 5 取り消し線の On/Off 機能実行 ショートカット 説明 F7 スペルチェックを実行 Alt + F8 マクロを実行"
},
{
url: "/p/5oc7g4c/",
title: "読書メモ『ピープルウェア』トム・デマルコ、ティモシー・リスター",
date: "2010-01-31T00:00:00Z",
body: "読書メモ『ピープルウェア』トム・デマルコ、ティモシー・リスター ピープルウェア トム・デマルコ、ティモシー・リスター 日経BP社 感想 マネージャー、リーダーの立場にある人にはぜひ読んで欲しい本です。 ずいぶん前に書かれた本ですが、ソフトウェア開発の本質は「人」であるということを訴えているバイブル的な書籍であり、その内容は色褪せることがありません。 多くの企業が生産性について誤解している部分を「人」を中心に解き明かしていきます。 **オープンすぎるオフィスレイアウト**、**リーダーとの進捗確認になってしまっているチームミーティング**、**競争心をあおいでしまう管理者**など、誰しも心当たりのありそうなことをはっきりダメなものと指摘しています。 21世紀に入り、「オープンなオフィスはよいものだ」というおかしな風潮が広がってしまったように感じます。 世の中の「できる」ソフトウェア開発者はそのような盲目的な考え方が間違いであることを認識しているはずですが、オフィスのレイアウトをオープンなものに変えようとする人ってプロのプログラマーじゃないことが多いんですよね。。。 この本がもう一度見直される日が来ることを願ってやみません。 抜粋＆メモ 担当者が自分で作り込んだ問題を摘出した場合でも、「よくやった」と誉める。 管理者は、むしろ働き過ぎないように、時折、気を配らなければならない。こうすると、すばらしい仕事がどんどん出来上がる。 本当に人を知る管理者は、ユニークな個性こそが、プロジェクト内の不思議な作用を活発にし効果的にすることをよく認識している。 プロジェクトチームを結束させる能力のある人は、普通に仕事をする人の二人分の価値がある。 生産性を論じるときは、退職問題に触れないと全く意味がない。生産性を上げると退職率も上がる危険がある。 コストは全体のコスト、つまり、退職者の補充に費やした余計な費用を含むべきである。 早くヤレとせかせれば、雑な仕事をするだけで、質の高い仕事はしない。 チームワークのよいチームの管理者は、チーム内のお荷物的な作業者に対してどなりたい気持ちをぐっと我慢している。 目標値の設定者は以下の順で生産性が高い。 目標なし システムアナリスト プログラマー 管理者 生産性向上の問題は、安易な解決法では手に負えない。そんなものは、すべてとうの昔に考えられ適用されてしまった。よい実績は、効果的な人の扱い方、作業場所は社風の改善などの手段を講じることで得られる。 開発者の主な仕事は、ユーザー流の表現で表したユーザー要求を、厳密な処理手順に変換するための、人と人とのコミュニケーションである。これは絶対に必要な仕事であり、自動化できるはずがない。 管理者の役割は、人を働かせることにあるのではなくて、人を働く気にさせることである。 企業におけるプログラマーの能力差は10倍あるといわれている。しかし、企業自体の生産性にも10倍の開きがある。 作業環境と生産性の相関関係は極めて顕著である。以下のオフィス環境を考慮すべき。 一人当たりのスペース 十分に静かか？ プライバシーは十分か？ 電話の呼出音を消せるか？ 電話を他へ転送できるか？ 無意味な割り込みが多くないか？ 現在のオフィスを今はやりの「開放型オフィス」に変える場合、その前にプログラマーの生産性への影響を十分に調査する必要がある。 プログラミングコンテストの結果を総合すると、参加者の58％が現在のオフィスは騒々しいと考えており、また、61％が個人の場所がなく、プライバシーが脅かされていることに不満を感じている。さらに、54％が自宅には会社よりもずっとよい作業場所がある、と回答している。 「オフィスは騒々しい」と回答したプログラマーは、「自分は不良を作り込む可能性が高い」と公言しているのに等しい。 特定の作業に対して投入された時間の総合計を集計しているところはあるが、これだけでは投入時間の質は不明である。 どんなものでも、計測しようと思えば必ずできるし、測定しないでいるよりもずっとよい。── ギルブの法則 困ったことに電話の弊害にはみんな慣れてしまい、誰も気にしなくなってしまった。 精神集中して仕事に没頭したいときには、かかってきた電話を無視できるような、現実的で効果的な方法を考えなければならない。 前面8フィート（2.4ｍ）以内にめくら壁を設けてはならない。8フィート以内にめくら壁があると、目の休まることがない。 窓から外の景色を見えないような部屋は、凶悪犯をぶちこんでおく刑務所と変わりない。 もし、彼が最初からその仕事に適していなければ、変化は決して起こりえない。 力のある管理者は、チームのメンバーが頭を丸坊主にしようがネクタイをしめないでいようが一向に気にしない。チームの誇りの対象は、チームメンバーが成し遂げた成果だけである。 成功する管理者の多くは、局所的なエントロピーを大幅に下げる。── 組織は死後硬直を起こしているかもしれないが、その一部であるプロジェクトは生き生きとして活動することができる。 応募者に過去の仕事について聞くのはよいが、見せてほしいというのはよくない、といった不文律があるようだ。だが、要求すれば、応募者はほとんど例外なく喜んでサンプルを持参する。──求人側が応募者に成果一覧表を持参するよう支持することはあまりないが、なぜそうしないのだろう。 能力テストは、従業員の「自己」評価には素晴らしい道具だ。 失敗の最もたるものは移転だ。退職がどんなに高くついたか信じられないだろう。 最良の組織は、意識的にベストになろうとして奮闘する。これは、全員に共通した目標であり、これによって、共通の方向づけ、共に分かち合う充足感、および強力な結束効果が生まれる。 退職率が最も低い会社に共通した特徴は、生涯教育プログラムの充実である。 書類の山は災いをもたらすだけで、問題の解決にはならない。 作業規定が示す全くその通りに仕事を行えば、仕事はほとんど止まってしまう。 ソフトウェア業界全体では、新しいアプローチを探し求め、それを自社内でやってみたこともないのに、規格として強制するようなことが広く行われている。 人は、他と違った扱いを受けることに魅力を感じ、注目されることを好み、珍しいものに好奇心をよせる。これはその後、ホーソン効果と呼ばれるようになった。つまりホーソン効果は、人は何か新しいことをやろうとしたとき、それをよりよくやろうとする、ことを示している。 挑戦はチームのメンバーに一緒になって努力する目標を与えることからこそ重要なのだ。──人は最良の仕事仲間を持ったとき、愉快な気分になるし、力の限りを尽くす。 結束したチームは、生意気で、自己満足的で、神経を苛立たせ、排他的かもしれないが、管理者の真の目標に対しては、交換可能な部品の集まりのようなグループが果たすよりも、はるかに、大きな役割を果たすことは間違いない。 陰険なイメージをふくらませるために、チームのメンバーは黒い服を着用しはじめた（ここから黒集団の名がついた）。プログラムがテストに引っかかると恐ろしい声でケタケタ笑った。 与えられたグループでやっていこうといったん決めたならば、最良んの戦術は部下を信頼することである。 少しはミスをさせたらよい。 自己防衛的な管理手段の中で最も明白なものは、作業規定マニュアルと、管理者による技術的な干渉である。この2つが揃えば、プロジェクトは長期的に見て失敗する運命にある。 隣にいる他のグループの作業者は、騒音と分裂の源である。作業者が同じチームにいるときは、同じ時間帯では静かにすることとが多いから、精神集中を妨げられることも少ない。 複数の結束したチームに同時に身を置くことはできない。時間を分断されたらチームは結束しない。 まやかしの製品を開発している開発者同士は、互いに視線を避けるようになる。自分たちがやっていることをやめられるなら、救われた気持ちになると、みんなが感じている。 部下に自分の評価の一部を委ねていることは、少々乱暴で恐ろしいことと思うかもしれないが、それがみんなに最善を尽くさせる道なのだ。 どの地位の人も、どんな不服従が許されるかよく知っている。──判断を誤っても、部下は自分たちのことを考えてくれるその管理者を支持するだろう。 自分が働きたいと思っている人と仕事ができる方が重要だったのだ。 品質至上主義は、世間一般からチームを際立った存在にするので、チームを一つに結束させる役割を果たす。 「不器用な作用」を醸し出すがうまい管理者は、仕事をいくつかに分割し、その一つひとつが、それなりに完成感を味わえるようにする。そんな管理者は、上級管理者やユーザーには、せいぜい2つに分ければ十分な仕事を、20ものバージョンに分けるように工夫する。──分割した新バージョンは、要するに打ち上げ用である。 成功する管理の本質は、みんなを同じ方向に向かわせ、管理者でさえ前進を止められないところまで燃え上がらせることにあるのだ。 プロジェクトが完了した際には、少なくとも他のプロジェクトを選択する余地を与えるべきである。 恒久的なリーダーは、やがて仲間として扱われなくなり、チームメンバーとの相互作用は崩壊しはじめる。 プロジェクトを、新しい技術を用いた試行プロジェクトとして実施した方が、費用が少なくて済む可能性が高い（生産性が上がる可能性が高い）。 試行プロジェクトの賢明なやり方は、一部分だけを新しい方法でやってみることである。 人は、期限通りに仕事をするために多くの残業をするのではなく、仕事が期限通りできそうもないことがわかったときに、非難から身を守るためにそれをやるのだ。 チーム内の競争は、コーチングを困難にし、または不可能にするという直接の影響がある。──管理者が、何かチーム内の競争心をあおるようなことをしたら、チーム殺し的と見なければならない。 真の利益をもたらすプロジェクトのすべては、それと共に真のリスクを伴うものだ。 組織が「成熟」するにつれて、次第にリスクを避けるようになる。CMM のレベルが上がったことを証拠で示せ、との厳しい監視の下にいる組織に、真の挑戦は期待できそうもない。 最もやる価値のあるプロジェクトとは、それはあなたのところの（CMM の）レベルを一つ完全に下げざるをえないプロジェクトだ。 サタイア・モデルがきわめて重要な理由は、「混乱」が変化には絶対必要な部分であることを、我々に認識させたことである。素朴な第二ステージだけのモデルでは、混乱を予期しない。それが起こると、それを「新しい状況」になったものと誤解してしまう。 逆説的に、変化は、もし失敗──少なくともちょっとした失敗──が、成功と同じように許される場合のみ、成功の可能性がある。 中間管理層の強力なリーダーシップがあって、はじめて学習センターは成功する。 管理における究極の罪は、人の時間を浪費することだ。 現状を把握するためにはミーティングは必要ない。現状把握だけの問題なら、他人の時間の浪費をもっと少なくする方法がいくらでもある。 本当に有効な会議は、出席者全員が一つの問題を一緒に討議する必要がある場合に開く。ミーティングの目的はコンセンサスにたどり着くことだ。そんな会議は、定義からも明らかなように、臨機応変に開く。臨機応変ということは、定期的ではない。 設計作業は、集中しなければならないし、作業場所が静かで、少人数での密度の高い会話が必要。"
},
{
url: "/p/8npfate/",
title: "読書メモ『仕事は楽しいかね２』デイル・ドーテン",
date: "2009-12-27T00:00:00Z",
body: "読書メモ『仕事は楽しいかね２』デイル・ドーテン 仕事は楽しいかね2 デイル・ドーテン きこ書房 『仕事は楽しいかね』デイル・ドーテン の続きです。 感想 ★★★★★ 5/5点。 本作では優れた上司になるための話が物語り風に進んでいきます。 前作と根本的な考え方は同じで、部下に変化のための自由、チャンスを与えることで魅力的な職場にするといったことが書かれています。 部下を持つような立場になったら、定期的に読み返して元気をもらいたい本です。 抜粋＆メモ きみの求める答えは「仕事をしない」ということではないと思う。必要なのは、人と人との「結びつき」を仕事に取り入れることなんだ。 「ほんもの」の部下とは、管理される必要がなく、上司にいい仕事をさせ、部署全体をより高いレベルに引き上げるような部下だ。 きみに必要なのは「最強の逸材」、つまり独創的な考え方をする人、独立独歩のできる人だ。同僚はもちろん上司のことも向上させる人。新たな行動規範を打ち立てる人。 「ほんもの」の上司と「ほんもの」の部下は、同じものを職場に求めている。自由（管理がない、平凡でない、愚か者がいない）、変化、チャンス。 「ほんもの」の上司と部下は、互いを管理の苦痛から解放している。 優れた上司の仕事は、魅力的な職場環境をつくることだ。 事務用品で有名な 3M（スリーエム）社の「15パーセント・ルール」。社員は好きなプロジェクトを自分で選び、勤務時間の15％をそれに充てるんだ。このプログラムなら「我が社は並みの職場とは違います」と言っていることになる。 「カジュアル・フライデー」ではなく「フォーマル・マンデー」という日を設けた。週に1日だけ、社員はカジュアルな服装ではなく、昔ながらの背広にネクタイという格好をするんだ。 優れた上司のもとで働き始めた人間ははっきりと知る。給料よりももっと大切なもの、つまりチャンスと変化が得られることをね。 優れた上司は規則ではなく高い規準を決める。些細なことには寛大に、重要なことには細心に。 ウェルカーはすぐに隊員たちのところへ行き、砲撃の準備を八分以内に完了する方法を考え出せ、と命令した。彼はその方法を教えなかった。ただ規準を定め、どうすればいいのかは部下たち自身に考えさせた。 優れた上司はお役所的な体制の外でどう仕事をすべきかを知っている。 優れた上司は答えを教えず、質問を投げかける。部下に答えを見つけさせることのほうが、答えそのものより大切である。 変化は冒険だ。しかし試みならやり直しがきくし、ちょっと無謀なことだってできる。私は、新しいプロジェクトは試みと位置づけて、試験的なことを少し含めるようにしていった。 部署の管理をうまくやるには、一日中、二つの質問をするだけでいい。もっといい方法はないか？これがきみにできる最善のことか？ ロータスを扱っているかどうかを尋ねた。何軒のかの店は「はい、やっています」としか答えなかったが、ある店はこう答えた。「もちろんですとも。私どもは輸入車を専門に扱っています。」「はい」のひとことですませるより、ずっといい答えが必ずある。 上司が間違いを認めることがわかれば、上司に対して意見を述べるのはそうするだけの価値のあることだと思うはずです。そして上司が変わることがわかれば、彼らも変わります。 優れた部下は、問題が起きたり混乱しているときにこそ、素晴らしい力を発揮する。彼らのおかげでみんな落ち着きを取り戻す。彼らの自身が伝わるのだ。 仕事選びの大切な基準は「いまより幸せになれること」なんだ！ 彼は「うちに来て手伝ってくれ」とは言わず、「あなたが、ほしいものを手に入れるお手伝いをしよう」と言った。 私は優秀なアシスタントが辞めるのを許すのは間違いではないかと思ったが、代わりとなる人材のリストがあれば、部下の転職にもずいぶん手を貸しやすいだろうと考え直した。 スカウトのプロセスは、単に大勢の人と知り合いになることじゃない。優秀な人たちの仕事をよく知ることなんだ。 上司が部下に与える時間や気配りは、上司自身に返ってくるんだ。クビにする人たちを敵にまわすのではなく、彼らと同盟を結ぶわけだから。 単なる友だち関係なら一時的ということもあるだろうけど、同盟関係は何があっても壊れることはない。 優れた上司を選べば確実に才能を伸ばしていける。そして、自分が仕事をしていく上で、大切な役割を引き受けてくれる生涯の同志を得られるんだ。 会社を去った人も、あとに残っている人たちのことなんか思い出すこともない。だけど、本当に優れた上司は本当に優れた部下のことを決して忘れないし、連絡も絶やさないものなんだ。 いくつかの試みを1、2週間以内に実行できそうだと思った。また、こうした試みに積極的に取り組んでくれそうな部下としぶる部下を、見きわめることもできた。 彼らがどういう人間かを知るだけではだめで、自分がどういう人間かを彼らに知らせる必要があるってことだからね。 私の部署で何か話をしてもらえないか頼んでみようと思います。部下のためにいろんな人を招いて「弁当を食べながらの勉強会」をやっている人ですし、きっと来てくれると思うんです。そうすれば、私たちの試みのことを詳しく知ってもらえます。"
},
{
url: "/p/cbvx4d5/",
title: "読書メモ『不機嫌な職場 - なぜ社員同士で協力できないのか』",
date: "2009-12-26T00:00:00Z",
body: "読書メモ『不機嫌な職場 - なぜ社員同士で協力できないのか』 不機嫌な職場 - なぜ社員同士で協力できないのか 河合太介、高橋克徳、永田稔、渡部幹 講談社 感想 ★★★☆☆ 3/5点。 タイトル通り、なぜ社員同士で協力できないかという「原因」を把握するためによい本。 ただ、それをどう解決していくかについてはあまり述べられていないので、そのあたりは自分で考えなきゃですね。 メモ 中間管理職に責任を押し付けても、何も解決しない。 実際は組織マネジメントの問題、あるいは組織全体でつくりだしている風土、価値観や行動原理の問題。 こうした問題の原因を特定することなく、壊れた人たちをその都度、医者に診てもらうだけでは、何も解決しない。 声をあげれば、自分が矢面に立たなければならなくなる。それが、苦痛であり、自分自身がさらに仕事を抱え込むことになりかねない。おかしいと思っていても黙っていよう。そんな心理が働いてはいないか。 大事なのは、自分で迷うことがあれば、おかしいと思うことがあれば、それを周囲に伝え、一緒に解決していくプロセスを共有すること。 協力をしないという行動の連鎖が、結局は自分を苦しめることになる。このことをすべての人が理解しなければならない。 個人の業務や役割分担も同様である。この括りで働きましょうね、という役割構造を持っている。▼悪い点 仕事をしているようだが、実のところ何をしているのかわからない人。まったく中身が分からない仕事。あの人が辞めると、仕事自体が止まるといわれている状態。 日本の会社は仕事が属人的になっており、誰が何をしているのか、誰に何を聞いたらいいのかすら、外国人の自分には分からない。 従来、組織としては必要だからと社員がお互いに手を差し伸べて行っていた業務は、個人の成果にはあまり関係がないということで、次々となくなった。 深さを追求しなければならないことに加え、個々人を束ねることが仕事を進める上で必要になっている。 以前だったら、誰かが対応して問題は起きなかったようなトラブルが頻発するようになった。 インフォーマルネットワークの弱体化により、知り合う機会が減少した。 会社組織自体がシステム化されていなかったため、人間関係などに依存する部分が多かったので、中途ではいると、ゼロから人間関係の構築をしなければならず、仕事上も不利だった。 会社はあてにならないものだと学習していった。そうなると頼りになるのは結局、自分の腕＝スキルだけということになる。 このとき、もっとも重要となるのは「不振の連鎖」を防ぐことである。多くの場合、この連鎖はコミュニケーションの不全による誤解に端を発する。 部下には最大限協力する意図があったとしても、失敗した際に上司が、「お前がわざと手抜きしているからだ」というふうに考えてしまったら、部下は協力する意図さえなくし、新たな不信の連鎖を招いてしまう。 重要なのは、自分が協力する意図と自分に協力してもらうニーズを、周りのみんなにわかってもらうための方策を皆で実践すること。 グーグルの構造 … その時々のテーマで立ち上がり、終わると消えてゆく──このように流動的な組織のため、役割が固定化してしまうことによる「タコツボ化」は構造的には発生しにくい。 グーグルの採用基準 … 他のグーグルの人と一緒に働けるか？自分で動ける人か？ 働きやすい環境、世界でもトップ水準の仲間、お互いが認知される風土、これらがエンジニアにとっての価値のある報酬となっている。この報酬は、グーグルという場そのものが提供するものである。この報酬を永続的に受け取るためには、グーグルという会社を永続的に存続させることである。 みんなに注目されたり、ほめられる。一緒に喜びを分かち合える。その方がずっと自分という存在に自身が持てるようになり、前向きな気持ちが持てるようになる。 ──最初はまったく意見がでなかったという。そこで考えられたのが、「ワクワク楽しいミーティング」に変えようということだった。 寄田院長は、「ありがとうは伝染する」と言っている。まず自分からありがとう。その気持ちがスタッフに伝わり、スタッフ間に伝わり、患者に伝わる。 1つの方法論ではなく、多様な取り組みで、社員を協力というベクトルに向けて囲い込んでいる。──この種の取り組みはすぐに効果があらわれる類のものではない。──社内の関係性が明らかに変わりはじめたと感じるまでに、「3年くらいかかった」と口を揃えて言う。 全員が、個人の利益を超えた共通目標・価値観を「共有化」するための工夫に取り組むことが大切。──人材の流動化、多様化が著しい現在、こうした流動化、多様化に対応するような、「共有化」作業を徹底して行っているだろうか。 立派な冊子、モノはつくったが、配布して終わっている。こうした施策で終わっていないだろうか。 「壁をつくらないから、何でも意見を言いなさい」というところまでは、多くの組織で行われている。しかし、そこで出てくる意見を1つひとつまじめみ取り上げないならば、社員は、そのうち馬鹿らしくなる。 その人が病気等で休んだ場合は、お手上げになる。責任感が強い人だと、そのことがわかっているから休めなくなる。失格マネージャーにいたっては、「休まれると困るから」と言って、その人の休暇申請をなかなか認めない。 仕事に余裕があるときに、自分の仕事の手順書マニュアルを作成するという習慣。──引継ぎ後、何か相談したいことがあったときも、そのマニュアルをもとに相談できる。──引き継いだ人は、そのマニュアルをバージョンアップするのが習慣。 自分の仕事で最高の仕事をしたかったら、周辺分野の知見をあわせて持つこと。 武田薬品工業の取り組み … 異動者に対して、「ローテーションポイント」という加算評価ポイントを付加している。これは異動損にならないように、未経験職務、習熟に時間を要する職務に異動をする場合、最長で三年（二年が通常）にわたって、評価でポイントを加算する仕組み。 「いまどきの若者は、社員同士の飲み会等に出たがらない」。しかし、それは若い人が、「あなたとの飲み会が嫌」なのであり、「あなたとの旅行が嫌」なのかもしれないと、自分を疑ってみる必要がある。 「人の顔をお互いに知ろう」と呼びかけたところで、そんな場所に行きたいという動機は働かない。──そこに人が集まるためには、その旅行自体が魅力的なものでなければならない。 ブログやイントラネットが良いと聞いて、それを導入して失敗している会社は、ただ、それをシステムとして導入するところで終わっている──固い、つまらないもにしていては、ダメ。 自分がいい仕事をする上で、欠かせない協力をしてくれた裏方の社名を三名選出し、その社員も次の週に、同じように表彰されるという工夫。"
},
{
url: "/p/8sinbv4/",
title: "読書メモ『仕事は楽しいかね』デイル・ドーテン",
date: "2009-12-23T00:00:00Z",
body: "読書メモ『仕事は楽しいかね』デイル・ドーテン 仕事は楽しいかね デイル・ドーテン きこ書房 感想 ★★★★★ 5/5点。 毎日何か新しいことにチャレンジすることの素晴らしさに気付かせてくれます。 「明日は今日と違う自分になる」「試すことに失敗はないから、とにかくいろんなことを試してみよう」がキーワード。 この書籍は、続きの 『仕事は楽しいかね２』デイル・ドーテン も出ています。 抜粋メモ 試してみることに失敗はない。 頭のいい人がする一番愚かな質問は、『あなたは五年後、どんな地位についていたいですか』というものだ。 僕は人生の中で何をすべきかなんて、問いかけなくなった──どうせ、人生なんて思いどおりにはならないからね。 今日の目標は明日のマンネリ。 明日は今日と違う自分になる。 人は違うものになって初めてより良くなれるんだから。 人生は進化だ。そして進化の素晴らしいところは、最終的にどこに行き着くか、まったくわからないところなんだ。 彼（ビル・ゲイツ）は、目標はつねにコンピューターに違ったやり方で処理させる方法を見つけることだとも明言していた。 遊び感覚でいろいろやって、成り行きを見守る。 チャンスの数が十分にあれば、チャンスはきみの友人になるのだ。 まぐれ当たり専門家になるべきかもしれないよ。 注意さえ払い始めたら、目にできるありとあらゆるところに偶然が転がっているのがわかると思うよ。 昔はよく人にこう聞いたものだ、「どんなことを考えているのかね？」今じゃこう聞く、「何を試してきたのかね？」。 望みうる最良のものは、手に入れたものを好きになることなんだよ。 十六の企業は、持つべき姿勢をしっかり育てて、それから画期的な成功を収めたんじゃない。画期的な成功を収めて、それから持つべき姿勢について、もっともらしい話をしたんだ。 目標や夢がないからという理由で失敗した事業を、僕は知らない。 いざその夢なり目標なりを実行に移して市場に入り込むと、十人中九人が失敗する。ろくでもない秘訣だね、そんな目標や夢なんて。 もし、ビジネスに対するきみの唯一の目標が、僕が仕事のために打ち立てている目標──つまり、日々違ったものになるというものだったら、どうなっていただろう。 小説を研究しても小説家になれないように、成功を研究しても成功は手に入らない。 成功の宝くじでは、勝つチャンスは何百と手に入るし、そのほとんどは大損するようなものじゃない。 人は、変化は大嫌いだが、試してみることは大好きなんだ。 チャレンジの中で一番大切なのは、心を開くことだ。だけど一度開いてしまえば、あとはそこにいろんなアイデアが流れ込んでくる。 きみはたぶん何十もの素晴らしいアイデアに、目の前を通り過ぎさせてきてしまっていると思うよ。 あらゆることをしろ。素晴らしいアイデアは、どこからやってくるかわからないのだから。 できることはどんどん変えてごらん。みんなが、きみが変えていることに気がつくくらいに何でも変えるんだ。好奇心を旺盛にすること。実験好きな人だと評判になったら、みんなのほうからアイデアを持ってきてくれるようになるよ。 リストを三つ作るんだ。── 仕事上でやったミスを全部書き出すこと。── 問題点を書き出すこと。── 仕事に関してやっているすべてのことをリストアップすること。── 一度書いたら、二度と書かないこと。同じものは決して書いてはいけない。つねにリストを変化させること。 まずはとにかく始めること。どのアイデアが最終的に実を結んで、どのアイデアが実を結ばないか、確かめる方法なんてないんだから。できるかぎりいろんなことをとにかくやってみること。そうすれば、そのアイデアがまた別のアイデアを引き寄せる。 問題というのは、自分がどんなにうまくその問題に対処できるかを示すチャンスだってことだ。 試すことは簡単だが、変えるのは難しい。 活用しようと思うことはどんなものでも活用すること、そして拝借できそうなアイデアをあちこち探すこと。 報告書に書くデータについてはどうだろう。いまとは違う方法を採れないだろうか。 仕事としてしているあらゆることを書き出し、私が出くわした、あるいは同僚が出くわしたあらゆる問題をリストに連ねてみると、試すためのアイデアを生み出すのは簡単なことだった。"
},
{
url: "/p/ejm5wd2/",
title: "読書メモ『ソフトウェアアーキテクトが知るべき97のこと』鈴木雄介 監修",
date: "2009-12-18T00:00:00Z",
body: "読書メモ『ソフトウェアアーキテクトが知るべき97のこと』鈴木雄介 監修 ソフトウェアアーキテクトが知るべき97のこと 鈴木 雄介 (監修) オライリージャパン 共感した部分をメモ。 新しくてクールなソリューションを使ってみたいという誘惑は大きい。でも、正しいものを選んだ方が、チームも顧客も幸せになれますし、いろんなストレスも減ります。すると、時間に余裕ができてきます。 相手の言うことをよい方にとらえ、考え方を聞くチャンスと思って話し合いに臨みましょう。そうすれば、相手からより多くのことを学べますし、相手が防衛的になって空に閉じこもってしまう危険性も減るでしょう。 ソフトウェア・アーキテクトは、自分がリーダーでもあることを忘れがちです。しかし、健全な職場で能力を発揮するためには、リーダーとして同僚から一目置かれるようにならなければなりません。 アーキテクチャーの策定プロセスにデベロッパーたちを参加させていれば、彼らから自発的、積極的な姿勢を引き出すことができます。 アプリケーションのパフォーマンスとスケーラビリティを左右する最大の要因は、アプリケーションのアーキテクチャだ。 ユーザが必要だという機能や特徴に、実は何を求めているかをたずねれば、アーキテクトは本当の問題を考えることができます。 アーキテクトという地位に就いてからは、コミュニケーションの相手は人間になります。 複数の相手に自分の考えを説明するときは、いつでも立って話をしなさい。── 立ち上がると、自動的に威厳と自身が伝わるようになります。 システムがさまざまな形でエラーを起こすことを受け入れること。 ソフトウェア・アーキテクトはエラーを鳩首し、正常な部分を保護するセーフモードを作ることができます。 交渉では、絶対に最初の要求を取り下げてはいけません。 「速い」は、要件にはなりません。── 要件を満たすかどうかを判断するための客観的な指標がないからです。── 要件として認められるのは、このような形のものです。「1500ミリ秒以内にユーザーの入力に反応しなければならない」 実装するチーム・メンバーを尊重し、彼らの言葉に耳を傾けましょう。彼らが設計書に手こずっているなら、彼らが正しくて設計が間違っているか、そうでないにしても曖昧だということです。 すべての設計書は、実装しながら書き直していく必要があるのです。 パフォーマンステストはできる限り早い段階で開始したほうがいい。──最大の理由は、どのような変更を加えたときにパフォーマンスか急降下したかがわかること。 ソフトウェア・アーキテクトの仕事は、単に技術的な問題をクリアすることだけではなく、それら技術要件と、プロジェクトに関わる利害関係者のビジネス要件との間でバランスを取ることが求められる。 時間を割いて、仕事が早くできるようにシステムを作りましょう。そうすれば、流れが良くなり、独りよがりな仕事をする理由がなくなるので、最終的には開発のペースを上げることができます。モックを使い、シミュレーターを作り、依存関係を減らし、システムを小さなモジュールに分割し、その他何でもできることをしましょう。コミットエンドランを決めてやろうなどと思う理由さえなくしてしまうのです。 アーキテクトは、企業の目的と経営の現実に基づいて技術的な決定を導いていかなければなりません。 汎用性に至るルートとしてもっともよいのは、個別の具体例を理解し、そのエッセンスを煮詰めていくうちに、共通の解にたどり着くというものです。推測による汎用性よりも、経験を通じた単純性の方が役に立つのです。よく似た設計案から1つを選択するときは、汎用性よりも単純性という価値基準が決め手になります。──気まぐれに柔軟性を追求すると、意図的であれ偶然であれ、単純な設計が持っている優れた性質をみすみす失うことが多いのです。 すぐれたアーキテクトは、模範となってチームをリードしなければなりません。──チームメンバーがすることなら何でもできる必要があります。──アーキテクトがテクノロジーを理解していないようなら、チームメンバーは自分たちのアーキテクトにどうやって信頼を置いたらよいでしょうか。 ビジネスの役に立つという目標に向かってチームを動かしていくために、アーキテクトはビジネスのことも理解していなければなりません。 プロジェクトマネージャーは、日常的な管理を行う人です。ありふれた仕事や人員の管理のためにアーキテクトが忙殺されないように、アーキテクトを助けます。 アーキテクチャーを設計するときに、トレードオフがどのようなものになるかを把握するためのツールがいくつかあります。ポピュラーなのは、ATAM と CBAM です。 選択肢 A と B のどちらを選ぶかではなく、A、B のどちらを選んでも、それほど重大な意味を持たないようにするために、どう設計するかを考えるのです。 どれを選ぶべきかがはっきりしない場合には、判断をしないという判断をしましょう。実際的な知識に基づいて、今よりも責任を持って判断を下せるようになるまで、実質的な判断を先延ばしにするのです。 信頼できる人で、必要なときに苦い現実を言ってくれるような人は、とても貴重な存在になります。 あると思わないものを探す人はいません。再利用可能なものについての情報を「プッシュ」していけば、再利用に成功する確率が上がります。──わずかな研修を施すだけで、再利用ということでは全員が同じレベルを維持しているという状態に大きく近づけることができます。 チームを大切にしなさい。チームメンバーは、単なるリソースではありません。あなたとともに設計を進めるコラボレーターであり、あなたのセーフティネットにもなってくれる人たちです。大切にされていないと感じている人たちは、セーフティネットにはなってくれません。 上空300ｍからの目は、適切なレベルでの情報を与えてくれます。──クラス、メソッドレベルの指標群である CheckStyle からの出力をスプレッドシートに取り込みし、グラフ化するようなことです。InfoViz ツールキットを使えば、同じ指標をツリーマップで表示できます。また、GraphViz は、複雑な依存グラフを図示できる優れたツールです。──図表が美しければ、おそらくシステムもよいものになっている。 判断の時期が迫ったことに気づいたアーキテクトは、数人のデベロッパーに問題のソリューションをそれぞれ考えさせ、しばらくそれぞれその方向で作業をするように頼みます。そして、最後の瞬間が近づいたときにミーティングを実施し、それらのソリューションの長所と短所を評価します。──アーキテクトは意思決定する必要すらありません。ただ、意思決定プロセスをリードすればよいのです。──結局、もっとも安くて済むのは、複数のソリューションを試してみる方法なのです。 ソフトウェア・アーキテクトの仕事は、ビジネスの問題、目標、要件を理解し、それらを満足させることのできる技術アーキテクチャーを作ることです。──彼らは、最高幹部やビジネスユーザーが使っているドメイン言語でコミュニケーションをとることができます。すると、このソフトウェア・アーキテクトは仕事がわかっているという強い信頼が生まれます。 チームメートに自己裁量を与えてそれぞれの創造力とコーディング能力を発揮させることがとても大切。 正しい課題を選ばなければ、危険な目に遭います。 複雑なアーキテクチャーは、単純なアーキテクチャーよりもかなり高い確率で失敗します。プロジェクトのスコープを縮小すれば、多くの場合、アーキテクチャーも小規模になります。スコープ縮小は、アーキテクトが成功の確率を上げるためにできるもっとも効果的な戦略の1つなのです。 自分の判断がそれらの人々に与える影響をかならず意識するようにしてください。自分の負担が重くなっても、彼らのためになる仕事をしようと思うようになるはずです。 優れたシステム仕様は、応答時間そのものだけでなく、作業時間も規定します。 アーキテクチャー／デザインパターンは、基本的に、エンタープライズ・アーキテクチャーパターン、アプリケーション・アーキテクチャーパターン、インテグレーションパターン、デザインパターンの4種類に分類できます。 アンチパターンについても学んでおくことも大切です。http://en.wikipedia.org/wiki/Anti-pattern まず何よりも状況について考え、そこからもっともシンプルなソリューションにたどり着くようにすべき。 それぞれのタイプの中でもっとも優秀な人々だけを集めたとしても、そのチームには、問題へのアプローチのしかたが1種類しかありませんので、できることは大きく制約されます。 むしろ、アーキテクトの役割は、さまざまな利害関係を持つ人々の間の対立を調停すること。 誰かが何かをしなければ重複は消えません。その誰かとはあなたなのです。 優れたアーキテクトは、プロジェクト、チーム、キャリアを進歩させるような新しいアイデア、ツール、デザインに対して開かれた心を持っています。時間の大半を管理会議に費やしたり、逆にコーディングばかりしていてはいけません。優れたアイデアは認め、アイデアが育つ雰囲気を作るのです。 開発関係者は、別のソリューションではなくそのソリューションが選ばれた理由や、どのようなトレードオフが含まれているかを明確に理解していなければなりません。──ドキュメントは、「決定の内容は何か」、「なぜそのような決定をしたか」という基本的な問いに答えるものでなければなりません。 自分のアイデアや信念が議論に耐えられないようなものなら、そんなものを基礎としてシステムを作るより、今それは誤りだと気付くほうがよほどよい。 早い段階で保守リーダーの参加を求める。保守リーダーを開発チームの中心メンバーに据える。アプリケーションのサポート計画に保守リーダーを加える。 抽象的に見ると、すべてのアルゴリズムは、データのあるバージョンを別のバージョンに変換する作業です。プログラム全体は、データをさまざまなリビジョンに変化させていく変換処理を集めたものにすぎません。──データ指向の見方を取れば、複雑なシステムでも、相手にできる程度の細部をまとめたものに圧縮できます。 解決策が1つしか見つからないことはまれです。おそらく、アーキテクトがそのドメインでは経験不足なのでしょう。自分を抑えて経験のある他の人に助けを求めたほうがよいです。 設計や実装を完璧なものにしたいという誘惑に負けてはなりません。「十分よい」レベルを狙い、そこまで達したら立ち止まるのです。──アーキテクチャーと設計にずれがなく、実装は正しく動作してパフォーマンス要件を満たし、コードが簡潔明快でドキュメント化されていれば十分よいと言えます。 意見の不一致を受け入れて仕事を進めることを覚えましょう。 失敗したプロジェクトを振り返ってみると、失敗したのは、能力がないからではなく、勤勉さと危機意識が欠けていたからだと分かります。 アジャイルであろがなかろうが、自分の判断プロセスが完全に把握できていなければなりません。次の2つの条件が満たされるまで、アーキテクチャー上の決定を下したといってはなりません。──決定事項をきちんと文書化する。──影響を受ける人に決定事項を伝える。 未来のないテクノロジーのために、プロジェクトを危険にさらさないように注意すべきです。 システムは設計した通りにはならない、と理解しなければなりません。 複数のフレームワークを導入する場合は、互いに重複がなく、何かに特化したフレームワークを選ぶこと。 最後に参加したプロジェクトを最初からやり直すことができるとすれば、何を変えたいのかを聞けば、教訓を応用する能力があるかどうかが推測できます。 今のニーズにもっとも合うソリューションを選びましょう。それ以外のものは、未来の選択として誤っているだけでなく、今の選択としても誤っているのです。 最初から大規模なシステムを設計することにはほとんどメリットはありません。──大きな設計ではなく、大きなビジョンを持つのです。 計算機を扱うにあたって、もっと本質的な知識とは？アルゴリズムとデータ構造、情報理論、計算機の動作原理、情報検索、情報圧縮…などなど。これらの知識は、ウェブでは手に入りにくい。──情報源は書籍（特に大学の教科書）や学術論文にあります。 開発中のドキュメントと保守ドキュメントを明確に区別することが重要となります。"
},
{
url: "/p/ba6kwjd/",
title: "VIM のフォントを設定する (gvimrc)",
date: "2009-09-09T00:00:00Z",
body: "VIM のフォントを設定する (gvimrc) Gvim のフォントは、guifont にフォント名と、pt 数を指定することで変更できます。 :set guifont Courier:14 \u0026#34;Windows の場合:set guifont Courier\\ 14 \u0026#34;Linux の場合 フォントの候補をカンマで区切って複数指定することができます。 :set guifont=Courier\\ New:12, Arial:10 フォントの高さと幅を別々に指定することもできます。 :set guifont=FixedSys:w10:h8 フォントをダイアログから選んで設定する場合は、次のコマンドを実行します。 :set guifont=* 詳しくは、 :help \u0026#39;guifont\u0026#39; (gvimrc) ファイルタイプ別にフォントを設定する 例: *.txt ファイルを開いた場合のフォントを設定する autocmd BufEnter *.txt set guifont=Arial\\ 12"
},
{
url: "/p/oi9yak2/",
title: "TeraTerm でログを自動保存する",
date: "2009-07-17T00:00:00Z",
body: "TeraTerm でログを自動保存する TeraTerm 起動時にログを自動でファイルに保存するようにする （Version: TeraTerm 4.62 で確認） メニューから、Setup → Additional settings\u0026hellip; Log のタブを開き、例えば以下のように設定 Default Log File Name (strftime format): %Y%m%dT%H%M%S-log.txt Default Log Save Folder: D:\\y\\log\\teraterm Auto start loggin: Check 最後に Setup → Save setup で設定を保存 これで、TeraTerm 起動時に自動で 20090717T201506-log.txt のような名前で、ログファイルを作成してくれるようになります。 ログファイルの各行に Windows システム時刻を付加する 以下のように設定しておくと、 メニューから File → Log\u0026hellip; （ログ取得中の場合はいったんログ取得を停止してから） Option から Timestamp にチェックを入れて Save 最後に Setup → Save setup で設定を保存 ログファイルの各行に以下のような、時刻のプレフィックスが付くようになります。 [Tue Jun 28 13:37:27.890 2011] ... [Tue Jun 28 13:37:30.590 2011] ... [Tue Jun 28 13:37:30.590 2011] ... ログ取得のダイアログを非表示する ログ取得中のダイアログが邪魔な場合は、以下のように消すことができます。 メニューから File → Log\u0026hellip; （ログ取得中の場合はいったんログ取得を停止してから） Option から Hide dialog にチェックを入れて Save 最後に Setup → Save setup で設定を保存 一時的に表示させたい場合は、以下のようにします。 メニューから File → Show Log dialog\u0026hellip;"
},
{
url: "/p/8nnbyho/",
title: "Doxygen のコメントの書き方: TODO コメント",
date: "2009-06-09T00:00:00Z",
body: "Doxygen のコメントの書き方: TODO コメント 関数のコメントとして、以下のように @todo タグを入れておくと、 ドキュメント内の Member Function Documentation の節で、TODO リストとして表示されるようになります。 ヘッダファイルではなく、CPP ファイル内にインラインコメントとして @todo を含めることもできます。 この場合は、ヘッダファイル内の関数コメントとして有効な Doxygen コメントを記述しておく必要があります。 /** * @brief Brief description. * @todo Modify macros. */ void Hoge(); void MyClass::Hoge() { /// @todo Modify macro name. TEMPORARY_MACRO(); }"
},
{
url: "/p/t3xmq3m/",
title: "Doxygen のコメントの書き方: 関数のコメント",
date: "2009-06-09T00:00:00Z",
body: "Doxygen のコメントの書き方: 関数のコメント 関数のコメントの書き方 ここでは、Javadoc スタイルのコメント記法を使っています。 /** * @brief Brief description 1. * Brief description 2. * * Detailed description 1. * Detailed description 2. * @param[in] param1 Param1's explanation. * @param[out] param2 Param2's explanation. * @param[in,out] param3 Param3's explanation. * @return The number of channels in the list. * @see RelatedFunction() */ int MyFunc(int param1, const Foo\u0026amp; param2, Bar\u0026amp; param3); Brief description と Detailed description の間には空行を入れるようにします。 できれば Brief description は一行で書くようにしてください。 Detailed description を記述しない場合は、以下のように空行を省略しても大丈夫です（コマンドが切れ目になるので）。 /** * @brief Brief description. * @param[in] param1 Param1's explanation. * @param[in] param2 Param2's explanation. */ void MyFunc(int param1, int param2); 戻り値は、１つの @return で説明的に記述してもよいし、複数の @retval を記述してすべての戻り値を列挙してもよいです。 /** * ... * @retval true Time is valid. * @retval false Time is invalid. */ パラメーターなどの説明が必要なく、メソッドのコメントが Brief description 一行だけですむ場合は、C# スタイルのコメントを使うと便利です。 /// Brief description. void MyFunc(); 箇条書きを使用したいときは、インデントを揃えてハイフンを記述すれば OK です。 このあたりは Javadoc よりも便利ですね。 /** * @brief Brief description. * * Detailed description. * - Item 1 * - Item 2 * - Item 3 */ 関数コメントのいろいろな書き方 メンバ関数のコメントで、いろんな書き方をした場合に、Brief description と Detailed description のどちらとみなされるのかをテストしてみます。 JAVADOC_AUTOBRIEF の設定が YES、NO の場合でルールが大きく変わるので、それぞれの設定でテストします。 JAVADOC_AUTOBRIEF = NO の場合 (default) デフォルト設定では、Brief description を入れるには、明示的に @brief タグを記述する必要があります。 空行が来るまでは Brief description とみなされます。 /** * @brief Brief description 1. * Brief description 2. * * Detailed description 1. * Detailed description 2. */ void MyFunc(); C# スタイルのコメントを使って @brief の代わりにすることも可能です。 /// Brief description 1. /** * Detailed description 1. * Detailed description 2. */ void MyFunc(); コメントとしてタグなしで普通に文章を記述すると、Detailed description になります。 ドキュメント化された時点で改行はなくなります。 /** * Detailed description 1. * Detailed description 2. * Detailed description 3. */ void MyFunc(); 空行を入れると、パラグラフの区切りとみなされて改行が入ります。 ただし、すべて Detailed description であることに変わりはありません。 /** * Detailed description 1. * * Detailed description 2. * Detailed description 3. */ void MyFunc(); JAVADOC_AUTOBRIEF = YES の場合 設定ファイル (Doxyfile) で JAVADOC_AUTOBRIEF = YES と設定しておくと、普通にコメントを書けば、最初のピリオド (.) までが自動的に Brief description とみなされます。 /** * Brief description 1. * Detailed description 1. * Detailed description 2. */ void MyFunc(); 改行を含んでいても、ピリオドが出てくるまでは Brief description とみなされます。 /** * Brief description 1 * Brief description 2 * Brief description 3. * Detailed description 1. */ void MyFunc(); ピリオドがなくても、空行が現れた時点で、Brief description は終了します。 この場合、出力されるドキュメントには勝手にピリオドが付加されるっぽいです。 /** * Brief description 1 * Brief description 2 * * Detailed description 1. * Detailed description 2. */ void MyFunc(); ピリオドで強制的に区切られるので、基本的には 2 文以上の Brief description は記述できません。 /** * Brief description 1. Detailed description 1. * Detailed description 2. * Detailed description 3. */ void MyFunc(); Brief description にピリオドを含めたい場合は、ピリオドの後ろにバックスラッシュ (\\) を入れる必要があります（気持ち悪っ^^;）。 /** * Brief description 1.\\ Detailed description 1. * Detailed description 2. * Detailed description 3. */ void MyFunc(); オススメの書き方（どのように記述するのがよいか？） 設定ファイルやコメントの記述方法によって、上記のように、どの部分が Brief description としてみなされるかが変わってくることが分かりました。 つまり、正しくドキュメントを出力するためには、プロジェクト内で共通の Doxyfile を使い、決められたフォーマットでドキュメンテーションコメントを記述するのが基本的なやり方になってくるでしょう。 ただし、少なくとも以下のようなルールでドキュメンテーションコメントを記述しておけば、JAVADOC_AUTOBRIEF の設定に左右されずに、想定通りのドキュメントが出力されるようになります。 Brief description は @brief で始める。 Brief description は1行で書く。 Detailed description の前には空行を入れる。"
},
{
url: "/p/ne3ocwx/",
title: "Doxygen の基本的な使い方と初期設定",
date: "2009-06-09T00:00:00Z",
body: "Doxygen の基本的な使い方と初期設定 コマンド 設定ファイル Doxyfile を作成する $ doxygen -g 次のように -s オプションを付けて生成すれば、最小限のコメントを含んだ Doxyfile を生成できます。 $ doxygen -s -g ドキュメントを生成する $ doxygen [configName] ※設定ファイル名を省略した場合は、Doxyfile が使用されます。 Doxyfile で最低限設定しておいた方がよさそうなタグ プロジェクト名を指定 PROJECT_NAME = MyProject HTML 形式のドキュメントだけを作成するように設定 GENERATE_HTML = YES GENERATE_CHI = NO GENERATE_LATEX = NO ※これがデフォルトで YES になってる GENERATE_RTF = NO GENERATE_MAN = NO HTML 出力形式の設定 SOURCE_BROWSER = YES # Files tab includes *.cpp files. GENERATE_TREEVIEW = YES # A side panel will be generated. doxygen コマンド実行時に warning 以外の出力を抑制する QUIET = NO WARNINGS = YES 下位ディレクトリも処理 RECURSIVE = YES"
},
{
url: "/p/x79fc82/",
title: "Doxygen の設定いろいろ (Doxyfile)",
date: "2009-06-09T00:00:00Z",
body: "Doxygen の設定いろいろ (Doxyfile) 基本的な設定 プロジェクト名を指定 PROJECT_NAME = MyProject HTML 形式のドキュメントだけを作成するように設定 GENERATE_HTML = YES GENERATE_CHI = NO GENERATE_LATEX = NO ※これがデフォルトで YES になってる GENERATE_RTF = NO GENERATE_MAN = NO HTML 出力形式の設定 SOURCE_BROWSER = YES # Files tab includes *.cpp files. GENERATE_TREEVIEW = YES # A side panel will be generated. doxygen コマンド実行時に warning 以外の出力を抑制する QUIET = NO WARNINGS = YES 指定したディレクトリ内のファイルを対象にする 例: カレントディレクトリ以下を対象にする（デフォルト） INPUT = RECURSIVE = YES 例: 指定したディレクトリ以下を対象にする INPUT = /home/john/src RECURSIVE = YES 特定のディレクトリを対象外にする パターンに一致する名前のディレクトリをドキュメント化の対象から外すことができます。 例: test という名前のディレクトリを対象から外す EXCLUDE_PATTERNS = */test/* パターンではなく、ディレクトリパスを明示する場合は、EXCLUDE タグを使用できます。 指定した拡張子のファイルを対象にする 例: .cpp と .h ファイルのみをドキュメント化の対象にする FILE_PATTERNS = *.cpp *.h ドキュメントの出力先ディレクトリの設定 ドキュメントの出力先ディレクトリは、ドキュメントのファイル形式ごとに設定できます。 さらに OUTPUT_DIRECTORY を設定しておくと、ディレクトリのプレフィックスとして使用されます。 例えば、以下のようにすると、HTML ドキュメントは doc/html 以下に生成されるようになります。 HTML_OUTPUT = html RTF_OUTPUT = rtf LATEX_OUTPUT = latex XML_OUTPUT = xml MAN_OUTPUT = man OUTPUT_DIRECTORY = doc HTML_OUTPUT = html Doxygen コメントの付いていないメンバメソッドなども対象にする EXTRACT_ALL = YES # default:NO ドキュメントにソースコードを含める INLINE_SOURCES = YES"
},
{
url: "/p/b2zio3x/",
title: "読書メモ『情報整理術クマガイ式』熊谷正寿",
date: "2009-02-07T00:00:00Z",
body: "読書メモ『情報整理術クマガイ式』熊谷正寿 情報整理術クマガイ式 熊谷正寿 かんき出版 夢を実現するには時間が必要 → 情報を探すのには時間がかかる → 情報を整理して時間を確保しよう。 というコンセプトの本。 専門家や経営者のブログを定期的に巡回すると勉強になる。 情報整理は手間がかかるくらいでよい。情報整理の際に情報に触れることで、頭の中が整理され、記憶に残りやすくなる。 お気に入りでファイルを管理するようにすると、マウスを動かしていくだけでフォルダをどんどん開いていける。 予定に関連するファイルは次のように分けた時系列フォルダに入れておくとよい。例えば、毎週水曜日にチェックしなければならない Web サイトのショートカットを「毎週／水」のディレクトリに入れておけば、水曜日にそのディレクトリをチェックするだけでよい。定例会議で使う資料もここから辿ることができる。 「毎月」フォルダ \u0026ndash; 1日～31日 のサブフォルダを作る。 「毎週」フィルダ \u0026ndash; 月～日 のサブフォルダを作る。 「毎日」フォルダ 1つの用件に対しては1枚のリフィルを使う。1枚のリフィルにたくさんの用件を記述してしまうと、インデックスをつけて検索できなくなるし、並び替えて情報を整理することもできなくなる。リフィルに限らず、ポストイットやA4用紙に関しても同様。 今すぐディープな情報が欲しいと思ったら、とにかく情報をたくさん集めるとよい。ただし、夢や目標を明確にしてから情報収集に望むこと。たくさんの情報に接しているうちに、情報を選別する目が養われる。 「メディア情報」と「人情報」はバランスよく集めないとダメ。 「一日一改善」を目標にする。 会議を行う時は、遅くても前日の午後5時までにアジェンダ、必要な資料を参加者全員にメールする。会議内で数字の説明をすることなく、すぐに意見をぶつけ合うことができる。 訪問の要請があったら失礼のないように用件をメールで送ってもらうとよい。わざわざ会わなくても済む案件が多い。 「事前に資料を揃えておきたい」 「案件に詳しい担当者を同席させたい」 「お力になれるかどうか検討したい」 「誠実に対応したい」 電話は机の左側に置いて左手で受話器を取るようにすると、右手でメモを取りながら話すことができる。 GMOインターネットでは「挨拶抜きの社内電話応対ルール」決めている。1日に10回電話するとしたら、1回につき20秒節約できるとして、1ヵ月で1時間もの時間を節約できる。 ある金融機関のストラテジストの話。「成功する秘訣は？」「絶対に風邪をひかないこと」 ビタミン剤を眠る前に飲むと眠っている間に疲れを取ってくれる。 集中力が落ちてきたと思ったら、ブドウ糖のサプリメントをとると頭がスッキリしてくる。講演会や会議の前に取ると集中できる。"
},
{
url: "/p/ckahx6k/",
title: "ライフハック: GTD 風の E-mail 分類手法 (Email Inbox Zero)",
date: "2009-02-03T00:00:00Z",
body: "ライフハック: GTD 風の E-mail 分類手法 (Email Inbox Zero) メールの処理方法に関するハック The inbox makeover｜Macworld Google Video - Inbox Zero Email: Empty Your Inbox with the Trusted Trio こんな感じでやってみるのがよいかも メールを受信したら以下のフォルダに一気にガーっと振り分け、Inboxの中は0件にする（InboxZero 方式）。振り分け終わったら、上から処理する。 Respond: すぐに返信できるもの（5分以内に返信できるもの）。 Action: なんらかの作業が必要なもの（資料をまとめたり、調査が必要なものなど） 。 Waiting: 誰かの返事待ち。 Archive: 今後参照する可能性のあるもの。 NotImportant: 今後参照する可能性のないもの。読む時間がなかったらスルーしても困らないもの。 Spam: スパムメール。 NotImportant、Spam に入れるべきメールは Subject から判断できるものも多いので、フィルタ機能で自動で Inbox から移動するようにしておく。直接ゴミ箱に入れずにいったん Span に入れるのは、スパムじゃないものまで捨ててしまうのを念のため防ぐため。 Archive フォルダ内のメールは検索で探すことを基本とする。場合によってはサブフォルダを作って分類したり、タグを付けて管理してもよい。"
},
{
url: "/p/z9r3xt9/",
title: "メモアプリ/Wikiのアイデア",
date: "2009-01-30T00:00:00Z",
body: "メモアプリ/Wikiのアイデア ファイル名に ID とタイトルを両方いれる ＜ID＞_＜Wikiページのタイトル＞.wiki のようなファイル名にすれば、ファイル名から ID と Title の両方が取得できる。 ファイル名が長くなるのが欠点か。 子ノードの管理 ページ内にリンクを張っておくと、 そのページが自動的にツリー表示で子ノードとして表示される。 通常ファイルの付加情報を別ファイルで管理する sample.zip に付加情報を追加する場合は、同じディレクトリに sample.zip.additionalinfo のようなファイルを生成し、そのファイル内に \u0026ldquo;Title: サンプル\u0026rdquo; のように書いておく。 ファイルの一覧を表示するときなどは、上記のメタデータを利用して表示するとわかりやすい。 バックアップはビューアごと CD-R/DVD-R へ メモをバックアップするときは、そのとき使っていたビューアもいっしょに焼いて、 焼いた CD-R から直接メモを参照できるようにしたい。 ビューアもいっしょに焼くのは、メモのフォーマットが変わったりしても、その CD-R 内のメモは確実に読めるようにするため。 プラグイン機能でページごと拡張 プラグインは文字の装飾などに使うだけではなく、そのページの属性を拡張してしまう用途にも使える。 例えば、Wikidpad のケースでは、ページの中に [color: blue] と書いておくと、そのページのツリー項目が青色で表示される。 WikidPad の Attributes という考え方 WikidPad には Attributes という機能があって、ページの中に [Attribute: Value] というテキストを含んでおくと、左のツリービューの Views というノードからその位置に簡単にジャンプできるようになる。 Attribute 名は次のように階層化して管理することもできる。 [Foo.Bar.Hoge: Value] どうやって、ジャンプ先のインデックスを作ってるんだろ？ 本文とヘッダの編集は別のエディタで メモの本文と、付加情報を示すヘッダ部分は別々の画面（エディタ）で編集できるようにしてもよいかも。 その場合、編集画面は Perforce のクライアント設定のようにテンポラリ・ファイルを Vim などで開いて情報入力することができるといい感じ。 ローカルファイルを簡単に扱えるメモ管理ソフトだと導入しやすい 既存のテキストファイル (.txt) があるディレクトリを操作して、自動的にデータベースを作成し、いろいろ付加情報を追加できるようなソフトになっていると導入しやすいかも。 ただ、ファイル名を変更したときなどに整合性を保つのが大変か。"
},
{
url: "/p/w5x4797/",
title: "SQLite 雑多メモ",
date: "2008-11-16T00:00:00Z",
body: "SQLite 雑多メモ SQLite にできないこと SQL Features That SQLite Does Not Implement より。 ユーザごとにアクセス制限ができない。 GRANT によるアクセス権限の制御はできない。 SQLite にはデータベースサーバが存在せず、クライアントが直接 DB ファイルにアクセスする形式のため、サーバでの GRANT によるアクセス権限の制御ができない。 そのユーザーがファイルにアクセスできるということは、そのデータベースに対して何でもできるということを示す。 VIEW は使えるがリードオンリーである。 SQLite 2 と SQLite 3 の違い バージョン 3 では BLOB (Binary Large OBject) がサポートされた。 バージョン 3 のほうがデータベースファイルのサイズがコンパクトになる。 整数の連番を生成する ROWID がバージョン 2 では 32bit、バージョン 3 では 64bit。 SQLite 2 のデータベースファイルを SQLite 3 のデーターベース形式に変換する $ sqlite db2 .dump | sqlite3 db3 各言語用の SQLite ライブラリ SQLite Wrappers Python で SQLite を操作する PEP 249 \u0026ndash; Python Database API Specification v2.0"
},
{
url: "/p/fn9ris5/",
title: "『アジャイルソフトウェア開発の奥義』ロバート・C・マーチン（輪講メモ）",
date: "2008-10-27T00:00:00Z",
body: "『アジャイルソフトウェア開発の奥義』ロバート・C・マーチン（輪講メモ） 今回読み進める本は、『アジャイルソフトウェア開発の奥義』です。 第2版までは日本語版が出てます。内容的にはどの版のものを読んでも大丈夫。 第1版 アジャイルソフトウェア開発の奥義 ロバート・C・マーチン ソフトバンククリエイティブ 第2版 アジャイルソフトウェア開発の奥義 第2版 オブジェクト指向開発の神髄と匠の技 ロバート・C・マーチン ソフトバンククリエイティブ 第3版 Agile Principles, Patterns, and Practices in C# Robert C. Martin Prentice Hall ちなみに版が進むごとにサンプルコードの言語がより高水準な言語に変わっています。 第1版: C/C++ 第2版: Java 第3版: C# 第1版と第2版の内容はほとんど一緒だけど、第3版には各種ダイアグラムに関する説明の Chapter.14～20 が追加で挿入されています。 C/C++ のコードで読みたい場合は、書店からなくなる前に第1版を買っておいた方がよいです。 以下、各章ごとのポイントや議論のメモです。 Preface（序文） 単なるパターン集ではなく、そのパターンが「なぜ」生き残ったのかという過程を知ることが大切。 著者 Robert C. Martin（Object Mentor 社の創設者。社長）は、11個のオブジェクト指向の原則をまとめている。それに従って設計することで、デザインパターンですら導き出される。 Section I: Agile Development（アジャイル開発） ▼議論 Q. アジャイルを大規模な開発に適用できるか？ 当初は大規模開発に適さないのでは？という懸念があったが、結果として大規模開発においてもアジャイル開発が主流になりつつある。ただ、いつものことだが日本では普及が遅れている。 大規模プロジェクトにおけるアジャイル開発に関しては、下記の記事や書籍が参考になる。 IBM Rational アジャイル開発 (そのうち3分の1は従業員数10,000人以上) の88%がアジャイル・プロセスを使用中または評価中である 書籍: 『The Object Primer（邦題: オブジェクト開発の神髄）』 アジャイルソフトウェア開発の長所の一つ: 規模の大小を問わずうまくいく。 The Rational Edge (72) アジャイル開発の広範な普及を目指して The Rational Edge (28) 大規模プロジェクトにアジャイルを適用する方法 「この大規模プロジェクトがアジャイル手法で管理できるのか？ 」という疑問が出てくる。その答えはイエスだ。 アジャイルソフトウェアプロセスを使ってオフショア開発（English） アジャイルソフトウェアプロセスを使ってオフショア開発（日本語） 分析と設計はオンショアで行い、構築をオフショアで行い、そして受入試験をオンショアで行うというやり方よりも、オフショアのチームにできるだけ多くの工程をやらせると問題が改善される。作業工程に沿って分けるのではなく、機能面に沿った分割を行う。 バグフィクスからやらせると、開発者は変更するよりも多くのコードを読むことになるので、コードベースに精通することができた。 オフショア開発においては、ドキュメントを作成するための時間を確保する必要がある。 最低限、IM と Wiki、良質の電話回線を用意すること。 Chapter 1. Agile Practices（アジャイルプラクティス） プロジェクトをうまくまわすためにルールやプロセスをどんどん導入してしまうと、逆に重くなってうまくいかない。 重いプロセスのせいで開発ペースが落ちる ⇒ まだプロセスが足りないと思い込む ⇒ ルールやプロセスを追加する ⇒ 悪循環… マネージャーは開発環境を構築する前にチームを構築するべき。環境はチームメンバーに最適化させるのがよい。 高価なツールを導入する前に小さなところから始める。 まずはフリーのツールを実際に使ってみて、本当に使えるのか試してみる。 CASE (Computer-Aided Software Engineering) ツールの前にホワイトボードやグラフ用紙を使ってみる。 大きなデータベースを使う前にプレーンテキストファイルを使ってみる。 ドキュメントに関して Martin のドキュメントに関する第一法則 … 重要で差し迫った必要のあるドキュメント以外は作成しない。 読みやすいドキュメントを用意する必要はあるが、多すぎるドキュメントは、少なすぎるドキュメントよりもたちが悪い。ドキュメントが多すぎると、ソースコードを変更したときにドキュメントを修正して整合性を保つのに時間がかかる。メンテナンスされていないドキュメントが存在していると、そこには嘘が書かれていることになり、逆に混乱を招く。ソースコードは嘘をつかない。 ドキュメントは手短に、洗練されたものだけ用意するのがよい。ドキュメントは長くても12ページ～24ページ（1、2ダース）に保ち、抽象度の高い設計構造を示したドキュメントを用意するとよい。新メンバーが参入した場合に、より詳細な設計構造を教えたい場合は、隣に座ってコミュニケーションを取るのが効率がよい。 プロジェクト成功の鍵 顧客との密接な協調関係を築くこと。 「コスト」や「納期」などの条件を決める契約ではなく、「相互の協調関係」について取り決めた契約書を用意する。「近くで一緒に働こう」といったものがよい。 うまくいった一例としては、「顧客側の受け入れテストに合格した機能ブロックの分だけ対価を支払う」という契約がある。どのように受け入れテストを行うかなどの詳細は契約では決めていない。 計画は日程がずれるだけでなく、形そのものが変わっていくもの。 詳細な予定 … 2週間先まで決める。 大まかな計画 … 3ヶ月先まで決める。 それ以外は柔軟にしておく。システムがどんな形になるのかを把握するくらいでよい。 Chapter 2. Overview of Extreme Programming この章には XP の概要が書かれている。 Chapter 3. Planning ブレイクダウンの順番 Features (by customer) Stories (by customer \u0026amp; developer) Development Tasks (by developer) プロジェクト開始時 developer と customer は話し合って feature を洗い出し、それぞれの feature を複数の story に分割してインデックスカードに記入する。それぞれの story には相対的な実装コストを示す story point を記入する。より正確な見積もりのため、大きすぎる story は分割し、小さすぎる story は結合する。 developer と customer で話し合い、iteration ごとの期間を決める。一般的には1週間か2週間。実装の進捗度合いによって iteration の期間が変わることはない。 iteration 開始時 customer は次の iteration で、どの story を実装してもらいたいかを決める。story の選択は、iteration あたりにこなせる story point 数である velocity の範囲内で決めないといけない。それ以上の story は選択してはいけない。iteration の途中で実装してもらう story を変更してはいけない。 velocity は通常、前回の iteration でこなせた story point と同じ値にする。 iteration の中で story をどのような順で実装していくかは、developer が自由に決めてよい。 developer は story を development task に分割し、story point と同じように task point を付け、メンバーへのタスク分担の目安とする。 メンバーは自分の得意不得意にかかわらず、好きな task を選んでよい。 iteration 中間点 iteration の中間点でミーティングを行い、story の半分をこなせているかを調べる。もし遅れているようであれば、task の分担をやり直す。それでも間に合いそうになかったら、customer と話し合い、story （あるいは task）を減らしたり優先度を付けるといった決断をする。 iteration 終了時 story の実装が終了したかどうかは、acceptance test をパスしたかどうかで決める。各 story の acceptance test は iteration の開始時に作成される。 task の進捗が 90% であっても、story の進捗が 0% では意味がない。 developer は iteration ごとに動作するソフトウェアを customer に触ってもらい、見た目はどうか、パフォーマンスはどうかといったフィードバックを得る。このフィードバックは新しい story 作成のために使われる。 iteration 開始時に計画した story の実装が終了しなかったら、次の iteration の velocity を調整する。 技術が向上したり、設備が整えば、velocity は上がる。 プロジェクトの開始時は velocity が分かりにくく、見積もりしにくいかもしれないが、そこであまり時間をかけてはいけない。3, 4週間すれば平均 velocity が分かる。平均 velocity が分かれば、最初のリリース（多くの場合24ヵ月後）までにどういった feature が実現できるか明らかになる。 メンバー全員のよく見える場所に少なくとも次の2つの表を貼っておく。 Velocity chart … 横軸に iteration、縦軸に velocity（その iteration でこなした story point）を示した棒グラフ。 Burn-down chart … velocity chart とは少し違い、縦軸に次のマイルストーン（またはリリース）までの残り story point を示した棒グラフ。story が追加されれば残り story point は増加するし、story の再見積もりによっても変化する。 Chapter 4. Testing（テスティング） ユニットテストを書くという行為は、機能検証というより設計に近い行為である。 テストを最初に書くことは、ソフトウェアを次のようにする効果があり、設計の質が高まる。 テスト可能な形式。 分離された形式。 テストはコンパイルも実行できるドキュメントである。テストは「常に最新の用例集」としての役割を果たす。 ユニットテストと受け入れテスト ユニットテスト … ホワイトボックステスト。プログラマが読めるようにプログラム言語で記述される。 受け入れテスト … ブラックボックステスト。究極の仕様書。顧客が読めるように顧客自身が設計した言語で記述される。 1回分のイテレーションの仕様をとり上げて、受け入れテストのフレームワークを作るのはそれほど困難ではない。作っただけの見返りは得られる。 Chapter 5. Refactoring（リファクタリング） 書き上げるモジュールも、保守するモジュールもすべてリファクタリングするべきである。 Chapter 6. A Programming Episode（プログラミングエピソード） UML ダイアグラムを使うことが適切でない時もある。それは、ダイアグラムを検証するコードを作らず、それに従ってプログラムを作ろうとする場合。 アイデアの模索に UML ダイアグラムを使うことは問題はないが、できたダイアグラムが最適なものであると思い込んでしまうことに問題がある。 最良の設計は、まずテストを用意し、小さなステップの積み重ねで生まれていくもの。 Section II: Agile Design（アジャイル設計） 以下は、貧弱な設計の兆候である。 硬さ もろさ 移植性のなさ 扱いにくさ 不必要な複雑さ 不必要な繰り返し 不透明さ これらの兆候が現れるということは、1 つ以上の原則に違反している可能性が高い。 下記は、オブジェクト指向設計の原則である。 SRP: Single Responsibility Principle （単一責任の原則 → 8章） OCP: Open-Closed Principle（オープン・クローズドの原則 → 9章） LSP: Liskov Substitution Principle（リスコフの置換原則 → 10章） DIP: Dependency Inversion Principle（依存関係逆転の原則 → 11章） ISP: Interface Segregation Principle（インタフェース分離の原則 → 12章） Chapter 7. What Is Agile Design?（アジャイル設計とは？） アジャイル設計とは、ソフトウェアの構造や可読性を向上させるために、原則、パターン、プラクティスを継続的に適用する行為である。 ⇒ 仕様変更にも素早く対応できる。 仕様が最も変わりやすいものだということはみんなが知っている。仕様変更が原因で設計が劣化していくなら、それは自分たちの設計やプラクティスが間違っている。 仕様は変化するものであり、設計もその変わっていくものなので、アジャイルなチームは初期の設計に時間をかけるようなことはしない。そこに時間をかけるのではなく、ユニットテストや受け入れテストをできるだけ頻繁に行うようにして、変更しやすいように保つべき。 新しい要求、仕様変更が来た時点で、今後の変更にも対応できるように設計を改善するのがよい。先を見越して設計をするのは工数の無駄に終わることが多いし、逆に不要なコードが含まれて理解が難しいコードになってしまう。 アジャイルでいう「柔軟」とは、どちらかというと設計のシンプルさに重点を置いている。 汎用性を揚げようとすると、ほとんどの場合、永遠に使われないモジュールであふれかえって複雑なものができあがる。 ⇒ YAGNI: You Aren\u0026rsquo;t Going to Need It! （あなたはそれを必要としないだろう） ▼議論 Q. クリーンなコードってなんや？シンプルなコードとは違うのか？ 無駄なコードがない。バグっぽいコードがないってことではないか。少しでも汚いコードがあると、そこからどんどんコードが腐敗していくということは 『達人プログラマー』 でも言及されている 。 Q. 後からたぶん仕様変更があると分かっていて、その対応をあらかじめいれておかないと、変更するときに二度手間にならない？ 確実に仕様変更があると分かっているのならあらかじめ対応をいれておけばよいし、その判断は期待値によるのでは？ただ、あらかじめ対応コードを入れておく方法は、逆に仕様変更がなかった場合に意味のない無駄なコードを残すことになるリスクや、結局あとからコードを消さないといけなくなるリスクが常にある。 Q. アジャイル設計はプロセスではないのか？ 翻訳ミスですね。翻訳本では「アジャイル設計はプロセスでもイベントでもない」となっているが、原書では \u0026ldquo;Agile design is a process, not an event.\u0026rdquo; となっている。アジャイルプロセスって言葉もあるしね。 Chapter 8. Single Responsibility Principle (SRP) 単一責任の原則 単一のクラスは単一の責務だけを持つべきである クラスが複数の責任を持っていることの弊害 そのクラスを使うモジュールが必要のない部分まで含んでしまう。 そのクラスを変更すると、そのクラスを使用しているモジュールをリビルド、再テスト、再ロードしないといけない。 永続性のあるシステム（データベースなど）と、ビジネスルールは、単一クラスに絶対に混ぜてはいけない。 永続性のあるシステムはあまり変化しないけど、ビジネスルールは頻繁に変化する。 永続性のあるシステムとビジネスルールはまったく違う理由で変化する。 クラスの役割の分離は、Chapter 7 で言っているように、必要になってから行えばよい。 ▼議論 Q. 「永続性のあるシステム」と「ビジネスルール」を分離する必要性がいまいち分からない。 ホットスポットとなる部分を別クラスに分離するのは Agile でなくてもごく基本的な考え。分離していないと、あまり変更のない部分だけを利用したいクラスでも無駄なリビルドやテストが頻繁に発生してしまう。 また、永続化部分とビジネスロジックが分かれていないと、ビジネスロジックのユニットテストを記述することが困難になる。 Chapter 9. Open-Closed Principle (OCP) オープン・クローズドの原則 変更の起こる部分は抽象化して、機能を拡張できるようにしつつ (Open)、既存の部分は変更しないでも済むように (Closed) すべし クラス図の中で A → B という矢印があったら、「B を変更したら A も変更しなければならない」 と考える。 変更に対して Closed にするには、依存の矢印があると無理なので「抽象」を使用する。どの部分をどのように抽象化すべきかは、求められているシステムによって異なる。 抽象クラスを使用する方法 … Strategy パターン 抽象メソッドを使用する方法 … Template Method パターン OCP をむやみに適用すべきではない。つまり、抽象をむやみに使用すべきではない。 抽象を使いすぎるとコードは複雑になる。 抽象化にはある程度の時間がかかる。 抽象化は、変化が起こる部分（変化しやすい部分）が明らかになってから行えばよい。 前世紀の考え方では、あらかじめ抽象を仕込むこと＝柔軟と考えられていたがこれは間違いである。 なぜなら、 抽象化には、将来の仕様変更をある程度予測する洞察力が必要だ。 そして、その予測はほとんどの場合外れる。 抽象化されたクラスは邪魔でしかなくなる。 変化が起こってから抽象化を行うのであれば、変化の可能性はプロジェクトの早めに知ることができたほうがよい。そのためには、 テストファーストで開発をする。 短いサイクルで開発し、顧客へのリリース頻繁に行う。 最も重要な機能から優先的に開発を進める。 ▼議論 Q. テストファーストでどうして変化の可能性を早く知ることができるのか？ 変化の可能性を知るというよりは、あらかじめテストで想定されうる入力を洗い出すことで、早い時点で抽象化するべき部分を見極めることができるということではないか。 Chapter 10. The Liskov Substitution Principle (LSP) リスコフの置換原則 派生型はその基本型と置換可能でなければならない ── Barbara Liskov 1988 基本クラスの使えるところでは必ず派生クラスのオブジェクトが使えなければならないという意味。派生型の本当の定義は、基本型と置き換えられるということ。例えば、MyFunc(Base *pObj) という関数には、Base クラスのサブクラスのオブジェクトを渡しても適切に振舞わなければならない。だからといって、if 文でオブジェクトの型を判断して処理を振り分けるようなコードは記述してはならない。これは OCP (Open-Closed Principle) に違反し、修正に対して「閉じ」なくなってしまう。 派生クラスが基本クラスの機能を制限してしている場合は LSP に違反している。なぜなら、基本クラス以下のことしかできないものは基本クラスの代わりにはなり得ないから。あるメソッドをオーバーライドして、実装を空っぽにしてしまうのは典型的な違反例。 派生クラスで基本クラスにない例外を投げてしまうと、LSP に違反する。基本クラスを使っているメソッドは、派生クラスが投げる例外をキャッチするようには設計されていないため。 LSP に準拠させるためには、「振る舞い」の等しさに注目して継承関係を持たせないといけない。 ソフトウェアは「振る舞い」そのものであり、ソフトウェアの世界で「IS-A 関係」を持つということは、つまり、「振る舞い」が等しいということである。例えば、Rectangle::SetWidth() と Square::SetWidth() の「振る舞い」は異なるので、Rectangle クラスと Square クラスは継承関係 (IS-A) を持たせてはいけない。 モデルの正当性は立場によって異なり、その使い方によって正しかったり正しくなかったりするので、普遍的に正しいモデルは存在しない。以下のテクニックを使えば、そのクラスが合理的だと仮定している「振る舞い」を明確にできる。 契約による設計 (Design by Contract) Bertrand Meyer 1997 によって提唱。メソッドの事前条件と事後条件を明確にすることでユーザに対して「振る舞い」を明示する。派生クラスの事前条件は、基本クラスで許可されているものは全て許可しなければならない（派生クラスで事前条件を厳しくしてはいけない）。派生クラスの事後条件は、基本クラスで課せられている条件を全て満たさなければならない。これにより、基本クラスのオブジェクトの代わりに派生クラスのオブジェクトを使用できることが保証される。 ユニットテスト ユニットテストによって契約内容を記述することもできる。ユーザはユニットテストを見れば、そのクラスについて何が仮定されているか知ることができる。 2つのクラスに単純な継承関係を持たせることによって LSP に違反してしまう場合は、共通部分だけを親クラスにくくり出すことによって解決できることがある。 ▼議論 Q. 共通部分を親クラスにくくり出すというが、実装の多重継承ができない言語を使用していて、既にあるクラスを継承している場合はどうするのか？ そーゆー場合は、インタフェースだけくくり出すしかないのでは。 Q. 純粋仮想関数として親クラスにくくり出した場合、ここで言っている「振る舞い」が IS-A 関係にあることが保証されるのか？ インタフェースはそもそも何も「振る舞い」を定義しないので、IS-A 関係は必ず成立する。そのインタフェースを使うメソッドは何らかの「振る舞い」を期待したコーディングをしてはいけない。 Chapter 11. The Dependency-Inversion Principle (DIP) 依存関係逆転の原則 上位のモジュールは下位のモジュールに依存してはならない。どちらのモジュールも抽象に依存すべきである。 抽象は実装の詳細に依存してはならない。実装の詳細が抽象に依存すべき。 下位レイヤのモジュールがサブルーチンライブラリという形で再利用できるのは当たり前。そういうことを言っているのではなく、ここでは、上位のモジュールを再利用できるようにするために、下位のモジュールに依存しないように設計しようと言っている。特に C → C++ という学習過程を辿ってきた人には重要な原則。 ここで「上位のモジュール」といっているのは、アプリケーションの全体的な動きなどの方針を決める部分で、実装の詳細（下位のモジュール）が変更されても影響を受けない本質的な部分。 下位のモジュールが提供するインタフェースを利用するのではなく、上位のモジュールが要求しているインタフェースを下位のモジュールが実装するという考え。分かりやすいのは Observer パターンとか。 下記は DIP に違反している例。 [上位モジュール] ─利用→ [下位モジュール] 下記は DIP に従っている例。 [上位モジュール] ─利用→ [抽象インタフェース] ←実装─ [下位モジュール] DIP に違反していれば「手続き型」の設計をしており、DIP に従っていれば「オブジェクト指向」の設計をしている。 下位のモジュールの再利用は、サブルーチンライブラリという形で確保されている。我々が本当に確保したいのは上位のモジュールの再利用性である。実装の詳細（下位のモジュール）を変更しても、上位のモジュールに影響がないようにしないといけない。 再利用可能なフレームワークの構築には DIP の適切な適用が欠かせない。例えば、あるメニュー項目をクリックしたときに、具体的な処理が行われるとか。メニューのフレームワークが特定の処理に依存しているわけではない。 あるクラスがほかのクラスにメッセージを送るようなケースでは、この依存関係の逆転は常に適用できる。 ▼議論 Q. 上位モジュールと下位モジュールの依存関係を逆転するために最初から上位モジュールが利用するインタフェースを用意するという実装方法（図11-2）は、常にコードをシンプルに保つという思想と矛盾していないか？DIP はシンプルさうんぬんの前に最低限守るべきということ？ レイヤーの違うモジュールに関してはこの原則を適用すべきということ。 Chapter 12. The Interface Segregation Principle (ISP) インタフェース分離の原則 関連性のないインタフェースをまとめない すべてのインタフェースを1つのクラスにまとめてしまわず、関連性のあるインタフェースごとにグループ分けして分離する。 インタフェースが太りすぎると、そのインタフェースを変更したとき、多くのサブクラスを再コンパイルしなければいけない。 インタフェースを追加するときは、既存のインタフェースを弄るのではなく、新しいインタフェースを追加する方法もある。この方法で追加した新しいインタフェースをクライアントが利用するには、次のように新しいインタフェースを取得することができる。 void Invoke(Service *service) { if (NewService *ns = dynamic_cast\u0026lt;NewService *\u0026gt;(service)) { // ns を利用する } ... } Chapter 13. Overview of UML for C# Programmers Chapter 14. Working with Diagrams Chapter 15. State Diagrams Chapter 16. Object Diagrams Chapter 17. Use Cases Chapter 18. Sequence Diagrams Chapter 19. Class Diagrams Chapter 20. Heuristics and Coffee Section III: The Payroll Case Study Chapter 21. COMMAND and ACTIVE OBJECT: Versatility and Multitasking Command パターンはシンプルだが万能で、様々な目的に利用できる。 データベースのトランザクションの生成と処理 デバイスの制御 マルチスレッドのコア GUI の do/undo の管理 例えばデバイスの制御に適用すれば、システムの論理的な内部構造とシステムに接続するデバイスの詳細を切り離すことができる。Sensor はイベントを検出したら結び付けられた Command インタフェースの do メソッドを呼び出すだけでよい（初期化時の関連付けは必要だが、実行の際に Sensor が出力先のハードウェアの詳細を意識する必要はない）。 命令の一時的な保存場所として Command オブジェクトを使用することもできる。例えば、Transaction インタフェースに validate() メソッドを加えれば、Transaction オブジェクト生成時にその有効性だけをチェックしておき、後からまとめてバッチ処理を行うことができる。 Command インタフェースに do() メソッドだけでなく、undo() メソッドを用意すれば、Undo 処理をサポートできる。各 Command オブジェクトは do() 実行時に以前の状態を覚えてスタックに積まれる（当然、操作対象となるオブジェクトの参照も覚えておく）。Undo するときは、スタックから pop して、undo() メソッドにより以前の状態に戻される。 Command パターンを有効活用しているパターンの 1 つに ActiveObject パターンがある。 ActiveObject パターンでは、メソッドの実行は 1 つのスレッドでシーケンシャルに行われるため、スタック領域を節約しなければならないようなメモリの限られたシステムでメリットが大きい。 参考: ActiveObject パターンの論文 Active Object: An Object Behavioral Pattern for Concurrent Programming 下記は P.1 ～ P.4 までのまとめ。 Active Object パターンとは、複数のスレッドからオブジェクトにアクセスする際の \u0026ldquo;method execution\u0026rdquo; と \u0026ldquo;method invocation\u0026rdquo; のスレッドを分離するパターン。 別名 (Also Known As) は \u0026ldquo;Concurrent Object and Actor\u0026rdquo; Active Object が解決しようとしているのは、複数スレッドからの共有オブジェクトへのアクセスが引き起こす下記のような課題。 共有オブジェクトにおけるメソッド呼び出しが実行されるときに、全体のスレッドがブロックされてしまうのを防ぎたい。 複数スレッドからの共有オブジェクトへのアクセスはできるだけシンプルにしたい。例えば、アクセスごとに mutex lock をかけなければならないのは複雑だ。 アプリケーションは透過的に並列性を利用するように設計されるべきだ。←▼これの意図がよくわからない。 Active Object パターンを使う場合、メソッドの呼び出しは、自動的に Method Requrest オブジェクトに変換されるので、普通のメソッド呼び出しと同じようになる。 全体のフローの概要は以下の通り。 クライアントのスレッドは Proxy 経由で共有オブジェクトのメソッドを呼び出す。 Proxy が各メソッドに対応する MethodRequest オブジェクトを生成し、別スレッドの Scheduler に enqueue() する。 Scheduler 側のスレッドは常にシーケンシャルに MethodRequest を処理していく。Proxy で呼びだされるメソッドの実装は Servant と呼ばれているもので実装される。 クライアント側では Proxy 経由のメソッド呼び出しの戻り値として Future オブジェクトを取得し、Future オブジェクトから各メソッドの戻り値を取得できる。 Chapter 22. TEMPLATE METHOD and STRATEGY: Inheritance versus Delegation （継承と委譲） 1990年代初期は、継承によって差分プログラミングできると信じられていた。1995年には、継承の乱用の欠点が明らかになった。GoF は「クラスの継承よりオブジェクトのコンポジションを使え」というまでになった。 Template Method パターンは継承を使って問題を解決し、Strategy パターンは委譲を使って問題を解決する。もっと詳しくいうと、Template Method パターンでは汎用的なアルゴリズムを抽象クラスで実装し、具体的な処理の内容を派生クラスで実装する。Strategy パターンでは汎用的なアルゴリズムを具象クラスで実装し、具体的な処理の内容はインタフェースに委譲する。 // Template Method パターン void func() { ... abstractMethod1(); // 派生クラスで実装 ... abstractMethod2(); } // Strategy パターン void func(Strategy *strategy) { ... strategy-\u0026gt;method1(); // インタフェースに委譲 ... strategy-\u0026gt;method2(); } Template Method パターンも Strategy パターンも上位レベルのアルゴリズムを再利用するパターン。Strategy パターンは、Template Method パターンより複雑さ、メモリ効率、実行時間の点で若干不利だが、Strategy パターンには下位レベルの実装の詳細を再利用できるという利点がある。 Template Method パターン 欠点: 上位クラス（アルゴリズム部分）が下位クラス（実装の詳細）が継承という強い関係で結ばれてしまう。つまり、下位クラスはその上位クラスとは切り離して使用することができないので、別のアルゴリズムに再利用することができなくなってしまう（DIP に違反）。たとえ下位クラスの実装から上位クラスのメソッドを利用していないとしても、継承関係にある限り切り離せない。 欠点: ▼そもそも多重継承の許されない言語を使っている場合は採用しにくいでしょ？ Strategy パターン 利点: 実装の詳細が、アルゴリズムを表現しているクラスの実装に依存しないため、いろんなアルゴリズムで利用できる（DIP に完全に準拠している）。 欠点: Template Method パターンに比べ、クラスの数が多く、間接参照が多い（メモリ、実行時間のコストがかかる）。ただし、多くの場合、これはほとんど問題にならない。 結論としては、実装の詳細を再利用できる可能性が少しでもあり、微々たる実行コストが問題にならないなら、常に Strategy パターンを採用すべし。 Chapter 23. Facade and Mediator Facade パターンも Mediator パターンもある種の方針をオブジェクトに強制する。 Facade パターンは上から方針を制約する。その方針は視覚的に捉えられる。 Mediator パターンは下から方針を制約する。その方針は視覚的には捉えられない。 Facade パターンを採用する場合は、全員が Facade を利用することに同意しなければならないことを暗に意味する。上から使い方の制約を課すことができるのであれば、Facade パターンを利用できる。Facade のクライアントは、Facade の下に隠されたライブラリに直接アクセスしないように約束する必要がある。 // Facade パターンでは、クライアントコードに見える形で方針が課される。 // つまり、Facade 経由でメソッドを呼び出さないといけないというルールが必須。 facade.DoSomething1(); facade.DoSomething2(); Mediator パターンは、Mediator オブジェクトを作成した時点でオブジェクト間の方針が課される。Mediator パターンの場合、オブジェクト同士にどのような制約が課されるか（どのように連携されるか）は、Mediator の実装によって隠蔽される。 // Mediator パターンでは、クライアントコードは Mediator オブジェクトを作成するだけ。 // あとは、クライアントコードには見えない形で方針が課される。 HogeMediator m = new HogeMediator(obj1, obj2); Chapter 24. Singleton and Monostate Singleton はインスタンスが複数生成されないような「構造」である。 Monostate はすべてのオブジェクトが同じ「振る舞い」をする。 Singleton パターンの特徴 Singleton でない既存のクラスを派生して Singleton にすることができる。 Singleton であるクラスを継承すると、そのままでは Singleton ではなくなってしまう。 Monostate パターンの特徴 Monostate を継承したクラスは Monostate になる（派生による多態性を利用できる）。 Monostate でないクラスを継承して Monostate にすることはできない。 Monostate のメソッドは static でないので多態性を持たせられる。 Singleton に比べて Monostate は振る舞い的に気持ち悪い。 あるクラスを Monostate にするには、メンバ変数をすべて static にすればよい（メンバメソッドは static にしない）。 Monostate パターンによる実装例 (MyMonostate.cs) public class MyMonostate { private static int itsX = 0; // すべてのインスタンスが同じ値を共有 public int X { get { return itsX; } set { itsX = value; } } } ▼議論 Q. Singleton は削除するいい方法がないといっているが、参照カウンタで生存期間を管理すればよいのでは？ 参照カウンタが 0 になった時点でオブジェクトが消えてしまうのであれば、次に生成されるオブジェクトは別のオブジェクトになってメンバ変数も初期化されるので、それはもはや Singleton とは言えない。つまり、メモリ使用量が気になるようなオブジェクトは、Singleton にしてはいけない。 Q. Singleton のメンバメソッドも static ではないので Monostate と同様に多態性を持たせられるのでは？ そもそも Singleton を継承するのは難しい。なぜなら、親クラスの GetInstance() は static なので継承ができないし、親クラスと子クラス両方に GetInstance() 系のメソッドを用意すると、クライアントは親クラスと子クラスのオブジェクトを別々に生成できることになり、結果として親クラスの性質を持つオブジェクトが 2 つ存在することになる。要するに分かりにくい。 Chapter 25. Null Object Null Object パターンは、オブジェクトを返すメソッドが null や 0 を返さないことを保証し、メソッド呼び出し側での null チェックの必要をなくす。 Color color = GetColor(\u0026#34;0xFF4080FF\u0026#34;); color.Paint(); // NullObject の場合は何もしない Null Object が唯一のインスタンスであることが保証されているのであれば、従来の null チェックのような分岐処理を記述することもできる。 Color color = GetColor(\u0026#34;0xFF4080FF\u0026#34;); if (color == Color.NULL) { // ... } ▼議論 Q. null チェックしなくてよくなったとしても、バグが表面化しないだけで、潜在的なバグを Null Object によって包み込んでしまうだけでは？ そうかもしれない。結局のところ、Null Object が提供する振る舞い（一般的に何も実行しないという振る舞い）が正しい振る舞いでないのであれば、分岐処理は必要である。 Q. では、Null Object パターンの主な価値は何？だって、Null Object で何もしないでスルーしてもよいケースなんてそんなないでしょ？ プレースホルダ的な機能を用意しておくケースはいろいろある。あるピアへの接続が完了するまではイベント発生しても何もしないとか、イベントに対して何らかの振る舞いを後付けで割り当てるケースなど。 「null チェック忘れによってクラッシュすることを防ぐ」ために Null Object を導入するというのは、本質的な使い方ではない。 元のコードで、null 時に特別なシーケンスを実行していたのであれば、Null Object を導入したところでそのシーケンスが必要なくなるわけではない。 Chapter 26. The Payroll Case Study: Iteration 1 （給与システムのケーススタディ：最初のイテレーション） データベースは実装の詳細にすぎないので、データベースについて考えるのはできるだけ後回しにすべき。 Jacobson が提唱したユースケースは、XP のユーザーストーリーの概念にそっくり。ユースケースはユーザーストーリーをもう少し詳細にしたものだと考えればよい。 ユースケースを使った落とし込みは、現在のイテレーションで実装する必要のあるユーザーストーリーについてだけ行うべき。 各イテレーションの最初で、チーム全員がホワイトボードの前で、選択されたユースケースの簡単な設計議論を行うのは「考えるプロセスを始める」ためであり、設計の詳細を詰めるためではない。 Chapter 27. The Payroll Case Study: Implementation （給与システムのケーススタディ：実装） コードの検証を怠って、UML にのめり込んでしまうのは危険である。コードは UML が教えてくれなかった設計の問題点を教えてくれる。UML ダイアグラムは役立つツールだが、コードからのフィードバックなしに依存しきってしまうのは危険だ。 フィードバックなしに設計を進めると必ずエラーが発生する。エラーを防ぐには、テストケースやコードを走らせることでフィードバックを得ること。 データベースを設計や実装の主要部分とみなすべきではない。データベースに対する考察は最後まで残し、詳細設計として扱うべきである。そうすることで、データの保存方法や、テストのメカニズムをどう作るかに関して色々な選択肢を残しておける。 Section IV: Packaging the Payroll System Chapter 28. Principles of Package and Component Design （パッケージ設計の原則） 大きなアプリケーションを体系化するにはクラスだけでなく、もっと大きな単位のパッケージが必要になる。UML ではクラスをとりまとめるコンテナとしてパッケージを扱える。 パッケージ内部の凝集度 (cohesion) に関する原則 (1) 再利用・リリース等価の原則 (REP: Reuse-Release Equivalency Principle) 再利用の単位とリリースの単位は等価になる。 再利用されるものはリリースされて、そのパッケージにリリース番号を与えてトラッキング可能でなければならない。 パッケージ内のクラスはすべて再利用可能なものか、すべて再利用できないものかのどちらかにすべき。 (2) 全再利用の原則 (CRP: Common Reuse Principle) パッケージに含まれるクラスはすべて一緒に再利用される。 一緒に使われる傾向のあるクラスは同じパッケージに属す。コンテナとイテレータなど。 逆に、一緒に使われる傾向のないクラスは同じパッケージに入れるべきではない。 ある新しいクラスを使おうとしてパッケージを新しいものに置き換えると、そのパッケージ内のクラスを利用しているコードをすべて再評価しなければならない。 (3) 閉鎖性共通の原則 (CCP: Common Closure Principle) パッケージに含まれるクラスは、みな同じ種類の変更に対して閉じているべきである。 単一責任の原則 (SRP) のパッケージ版。 こうすれば、仕様変更があってもその影響を受けるパッケージを最小限にできる。 パッケージ同士の結合度に関する原則 (4) 非循環依存関係の原則 (ADP: Acyclic Dependencies Principle) パッケージ依存グラフに循環を持ち込んではいけない。 パッケージの依存グラフの矢印を辿っていったときに、最初のパッケージに戻ってきてはいけない。 矢印を下向きに書くと、上向きの矢印が出てきたときに依存関係が循環してしまっていることがすぐに分かる。 非循環性の有効グラフ (DAG: Directed Acyclic Graph) になっていれば、新しいパッケージのリリースによる影響範囲を絞り込みやすい。矢印をただ逆に辿ればよいだけ。 依存グラフが循環すると、ほとんどのパッケージを同時にビルド、リリースしないといけなくなる。 パッケージ依存構造は、アプリケーションの作成の過程で変化していくものなので、常に依存構造に循環が起きていないか見張っておかなければならない。 パッケージ依存ダイアグラムはビルド方法を示すマップであり、アプリケーションの機能の概要を示すことはほとんどない。 クラスを作る前にパッケージダイアグラムを作ろうとするのは間違い。確実に依存関係が循環することになる。 (5) 安定依存の原則 (SDP: Stable Dependencies Principle) 安定する方向に依存せよ。パッケージの不安程度は、それが依存するパッケージの不安程度より大きくあるべきだ。 不安定なパッケージを常に上に描くようにするとよい。こうしておけば、上向きの矢印が見つかったらすぐに SDP に違反していることが分かる。 (6) 安定度・抽象度等価の原則 (SAP: Stable Abstractions Principle) パッケージの抽象度と安定度は同程度でなければならない。 パッケージの安定度が高いということは、それ相応の抽象クラスで構成されているべきということ。 このバランスが崩れると、無意味なパッケージ、苦痛を伴うパッケージが生まれることになる。 Chapter 29. Factory いくらインタフェースを使用して具象クラスのオブジェクトにアクセスしても、具象クラスを new する部分がコードが含まれていれば、そのクラスに依存してしまう。Factory パターンは、抽象インタフェースのみで具象クラスを作成することを可能にする。 Factory パターンのメリットのひとつとして、Factory の実装を自由に入れ替えられることがあげられる。Factory を抽象化しておけば、オブジェクトのインスタンス化方法を簡単に変更できる。 Factory パターンを、テスト用のモックオブジェクトを作成するために使うこともできる。 Factory の抽象インタフェースをグローバルに保持するようにしておけば、テストコードの中でこのグローバル変数に、テスト用の Factory の参照をセットできるようになる。つまり、本物のコードに一切手をつけずにテスト用の振る舞いをさせることができる。 依存関係逆転の法則 (DIP) に完全に準拠しようとすると、多くの場所で Factory パターンを適用しなければならなくなる。ただし、これはやりすぎで、例えば、下記のような場合に Factory パターンを適用するとよい。 Proxy パターンを使う場合。Factory を使って永続性のあるオブジェクトを作るために必要になる。 ユニットテストのために、オブジェクトを生成するオブジェクトをだまさないといけない場合。 Chapter 30. The Payroll Case Study: Package Analysis （給与システムのケーススタディ：ふたたび） ダメなパッケージ分割 … 詳細部分が下の方に配置されている。 よいパッケージ分割 … 抽象化された部分がより下に配置されている。 再利用の単位はパッケージ単位になる。なぜならば、パッケージ内のクラスには凝集性 (cohesive) があるからで、互いに強く依存しているから。これはパッケージ分割のひとつの指標になる。 パッケージ分割はシンプルなところから始めて、徐々に複雑にしていくのがよい。 再利用されないものや、変更の少ないものまでパッケージ分割するのはやりすぎ。 パッケージ間の依存度は、Factory パターンによって下げることができる。パッケージごとに、Factory を 1 つ用意し、そのパッケージ内に含まれる public なオブジェクトをその Factory を通してインスタンス化するようにすればよい。 機能面を軸にパッケージ分割するよりも、トランザクションを軸にパッケージ分割する方がずっと意味がある。 Chapter 31. Composite Command パターンに Composite パターンを付加すれば、ある Command を使用しているクラスに変更をいれずに複数の Command を扱えるようになる。 → OCP をうまく適用した例。 複数のオブジェクトを同様に扱うためのリストや配列などをメンバ変数として持っているクラスは、Composite パターンを導入することで、「1対多」の関係から「1対1」の関係に落とし込める。こうすることで、コードはシンプルになり、コーディングも保守も楽になる。各クライアントにリストを繰り返し処理するためのコードを埋め込むのではなく、Composite の中に一度だけ繰り返し処理を記述するだけで済むようになる。 Chapter 32. Observer: Evolving into a Pattern （デザインパターンへの回帰） テストファーストを実践することで、必然的に設計の分離性が促進される。テストの方法を考えるだけで、インタフェースを設計に追加することになる。 Observer パターンを使用すると直接的な依存関係をなくすことができるので、多くの場所で使用したくなるが、Observer パターンを乱用すると、理解しにくく、流れを追いにくくなってしまう。 Chapter 33. Abstract Server, Adapter, and Bridge 依存関係逆転の法則 (DIP) は抽象クラスに依存することが望ましいと主張している。 通常、継承階層構造は同じパッケージにまとめるべきものではない。クライアントは、それがコントロールするインタフェースとともにパッケージ化されるべき。 システムの一部をその場しのぎで解決しても、あとからそれが原因で厄介な依存関係が生じ、まったく関係ない別のシステムで問題を引き起こす。 Adapter パターンを使用するときに Factory パターンも一緒に使用すれば、Adapter の存在を隠蔽することができ、Adapter への依存関係をなくすことができる。 Bridge パターンを利用することで、複数の階層構造を 1 つに併合せず、分離したまま結合することができる。 Adapter パターンを使った方法は、シンプルで依存関係も正しい方向になる。一方、Bridge パターンは 2 つの階層構造を完全に分離することができるが、かなり複雑になるので、その必要がある局面でない限りおすすめできない。 責任の所在をたやすく「不十分な設計」のせいにするべきではない。この世に十分な設計などありえない。存在するのは、コストと利益のバランスがとれるように設計された構造だけ。設計の変化をうまく管理するには、システムを極力シンプルかつ柔軟に保つこと。 Chapter 34. PROXY and GATEWAY: Managing Third-Party APIs （第1版タイトル: Proxy, Stairway to Heaven） Proxy パターンを導入すると、ビジネスルールを他のあらゆる実装（データベース、COM、CORBA、EJB）から切り離すことができる。 Proxy パターンの取り扱いはそれほど簡単ではなく、ほとんどのアプリケーションでは導入すべきではない。ただし、アプリケーションと API を徹底的に分離することが望ましいケースもある。その代表的なケースは、システムが大きく、データベーススキーマや API が頻繁に変更されるような場合、あるいは複数の MW、データベースエンジン上に構築されているシステム。 パフォーマンスの改善方法の検討は、実際にパフォーマンスが問題になっていることを検証して、それが実証された場合に限って行うべき。 Stairway to Heaven パターンを使うと、Proxy パターンと同様に依存関係の逆転を実現できる。ビジネスルールの継承構造を、他の実装（永続メカニズムなど）の継承構造と分離できる。ただし、C++ のような多重継承をサポートした言語でしか採用できない。 Proxy パターンや Stairway to Heaven パターンは本当に必要になるまでは導入すべきではない（特に Proxy パターン）。それまでは Facade パターンなどを使えばよい。 ▼議論 Q. Stairway to Heaven ってインタフェース導入すれば多重継承しなくてもよいんじゃない？ その通り。そうするとまさに Proxy っぽくなる。だから Stairway to Heaven は Proxy の退化版（インタフェース使わない版）とも言えるかもしれない。第3版から削除されたのはそれが理由かも。 Q. Facade のダイアグラムの依存の方向逆じゃない？ データクラスが Facade のクライアントということを示していると思われる。でも、この Facade の使い方は気持ち悪い。この図だけではデータの永続化のタイミングはどうやって指定しているのか分からない。 Chapter 35. Visitor Visitor パターンは大きなデータ構造を渡り歩き、そのレポートを作成するような場合によく使われる。1 つのデータ構造をいろいろな形で利用しなければならないアプリケーションで使用される。 Visitor パターンがうまくいくのは、visit される側のクラスをあまり変更することがない場合。visit される側に派生クラスが追加されるたびに Visitor 側も再コンパイルしなければならない。 visit される側のクラスの階層構造が頻繁に変わるような場合は、Acyclic Visitor パターン（非循環 Visitor パターン）を採用するとよい。ただし、Acyclic Visitor パターンは若干複雑で、キャストを必要とする。 Visitor パターンは魅惑的だが、通常はもっとシンプルな方法で解決できることが多い。 Decorator パターン、Extension Object パターンも、既存のクラス構造に影響を与えずに機能を追加するパターン。 Extension Object は他のパターンより複雑だが、パワフルで柔軟性がある。 ▼議論 Q. Extension オブジェクトは、getExtension() した時点で作成した方が効率てきではないか？Hash を使った方がシンプルで分かりやすいというのは確かだが、CSV や XML の両方の Extension オブジェクトをいつも使うわけではないので、Extension オブジェクト生成のコストが無駄になるのでは？ その通り。 Chapter 36. State 有限状態マシン (FSM: Finite State Machine)、状態遷移図 (STD: State Transition Diagram) は、ほとんどどんな場合でも使用できる万能な設計ツール。もっと活用すべき。 状態遷移図における遷移は、状態遷移テーブル (STT: State Transition Table) でも表現できる。 状態遷移図、状態遷移テーブルを使うことで、設計者が見落としてしまいがちなマイナーな状態を発見できる。 Java の弱点のひとつは、C++ の friend と同等の機能が存在しないこと。この機能がないので、private な state 変数をチェックするテストコードが書けない。 有限状態マシンを実装する 3 つの方法 switch 文を使う方法 ○ 単純な有限状態マシンならエレガントに効率的に実装できる × 状態が多くなると保守できなくなる × 状態マシンの論理部分とアクション部分を分離できない 遷移テーブルを使う方法 ○ 状態遷移テーブルの構成を理解しやすい ○ プログラム実行時にテーブルを変更できる ○ 複数の遷移テーブルを作れる × 遷移テーブルをサーチするため効率が悪い × 遷移テーブルをサポートするためにサポート関数が多数必要 State パターンを使う方法 ○ switch を使う方法の効率性、遷移テーブルを使う方法の柔軟性の両方を備えている。 × State クラスのサブクラスを作成する作業が飽き飽きする。 × 論理が記述している部分が複数の State 派生クラスに分離してしまい、保守が困難になる。 State パターンと Strategy パターンの違いは、State パターンでは State クラスが Context クラスへの参照を保持していること。 State クラスのメソッドのデフォルト実装として、例外を投げるコードを記述しておくと、ある State で発生してはいけないイベントが発生したときにすぐ分かるようになる。 ▼議論 Q. テーブルをサーチするのは switch 文より効率が悪いって本当？ currentState * event の組み合わせでリニアサーチするから switch より平均的に遅くなる。さらに switch 分岐はインデクシングにより最適化される可能性が高い。 Q. n回イベントが発生したときに状態を遷移させるようなステートチャートは記述可能か？ ガード条件を付加すれば可能。ただ、単純な表からコードを自動生成するようなことができなくなりそう。 Chapter 37. The Payroll Case Study: The Database Chapter 38. The Payroll User Interface: MODEL VIEW PRESENTER"
},
{
url: "/p/ot2a7rx/",
title: "読書メモ『手帳フル活用術 仕事の達人、27人の手のうち！』",
date: "2008-10-12T00:00:00Z",
body: "読書メモ『手帳フル活用術 仕事の達人、27人の手のうち！』 文庫本サイズなので、最初に読む手帳本としてはよいかも。 「会いたい人」を手帳に書いておくとよい。それを何度も見ることで意識することができ、それを回りに吹聴することで自然にコネクションができたりする。 心理学に「ザイアンスの単純接触の原理」がある。何度も何度も手帳をチェックすれば、その内容を好きになってくる。 「このテーマについてもっと情報を集めたい」と思ったら、手帳のよく見える場所にそのテーマのキーワードを書き込んでおく。普段何気なく見過ごしてしまう情報も、意識していることで脳に飛び込んでくるようになる。このように潜在意識が欲求を理解することを大脳生理学で「オートマトン」という。 「部下指導日記」をつける。部下ごとに毎日、どんな教育をしたか、どんなアドバイスをしたかを書き込んでいく。 言われたことをその場で手帳に書き込まないと、相手が心配する。 手帳に記された予定に沿って、どんな準備をするかが大切。 「やりたいこと」を書き下すとよい。下記はその例。 コンサルタント業 人のプロデュース 単行本の執筆 小説家 翻訳家 ルポライター 経済評論家 経営評論家 雑誌の連載 テレビ出演 講演 各種セミナーの企画・運営 教育（大学、ビジネススクール） 漫才・落語作家 番組の企画（テレビ、ラジオ） 映画のプロデュース（企画、脚本など） 出版社の経営 飲食店の経営 飲食店のプロデュース 芸能プロダクション経営 イベントの企画・運営 テレビキャスター ラジオパーソナリティ 旅行企画・主催 手帳に書く5つの「夢リスト」 To Do List（何をやりたいのか、何をやるべきか） To Be List（どんな人になりたいのか、どんな状況にしたいのか） To Have List（何が欲しいのか、何があれば便利か） To Meet List（誰に会いたいのか、どういう人と会うべきか） To Study List（一番勉強したいことは何か、自分の生涯学習は何か） すべての仕事でもっとも大切なことは「ゴールの設定」。仕事ができる人はゴールを決めてからいつスタートするかを考える。 自分自身が気づいていない「コンピタンシー」を発見するために、周囲の人に、自分にはどんな能力があるのか意見をもらうといい。"
},
{
url: "/p/bymt9rp/",
title: "読書メモ『人生は手帳で変わる 第4世代手帳フランクリン・プランナーを使いこなす』",
date: "2008-10-08T00:00:00Z",
body: "読書メモ『人生は手帳で変わる 第4世代手帳フランクリン・プランナーを使いこなす』 フランクリン・プランナーでは、自分の中で最も大切なこと (Value, Role, Mission) をはっきりさせて、その価値観にそった行動をすることに着眼しています。 この本の付録にある、「演習：最も大切なことを発見するためのヒント」は使えそうです。 ある男性の価値観の例 常に誠実であること 何事にもチャレンジすること 物事に柔軟に対応すること 正直であること 経済的に自立すること 前向きに考えること 言ったことは実行すること 謙虚であること 今やっている仕事が不本意なものであっても、自分の目的を実現するための一歩なのだと決めて取り組めば、モチベーションはまったく違ってくる。 会議を成功させるためには、その目的をはっきりさせることがもっとも大切となる。どんなミーティングでも、その目的は 3 つしか存在しない。 決定するためのミーティング 各人のアイデアを自由に出し合うブレーンストーミングのためのミーティング 告知、情報提供のためのミーティング タスクをこなす上で最も重要なのは、タスクを「いつ始めるか」。今日やることをリストにするだけでなく、何時から何時の間にやると明記することが必要。"
},
{
url: "/p/r55ad8w/",
title: "読書メモ『人生は手帳で変わる』の付録『最も大切なことを発見するためのヒント』",
date: "2008-10-08T00:00:00Z",
body: "読書メモ『人生は手帳で変わる』の付録『最も大切なことを発見するためのヒント』 「価値観 (Value)」を考える 10年後にはどのような人になりたいですか？ 例：周りから尊敬される人 人と接する上で何が一番大切ですか？ 例：どんなときでも誠実に対応すること 失うと生きる気力がなくなるものはなんですか？ 例：家族と一緒に過ごす時間 今後の人生において最も身に付けたい才能や能力はなんですか？ 例：周りの人の能力を最大限に引き出せるような教える能力 あなたが最も得意だったことはなんですか？ 例：周りの人たちとコミュニケーションをとること。 あなたがこれまでに最もわくわくしたことはどのようなことでしたか？ 例：自分の子供の成長が実感できたこと あなたが心の底から「リラックス」できる時間はどのような時ですか？ 例：家族だけでゆっくりとした時間を過ごしているとき あなたの理想とする人は、何を最も大事にしているのでしょうか？ 例：友情 あなたが出会った人の中で、最も愛する人は誰ですか？ 例：妻 人生の中で、学ぶことの多かった失敗、挫折体験はなんですか？ 例：大学受験で失敗したこと。⇒地道に努力する必要性を知った。 仕事とプライベートで共通して言える指針はなんですか？ 例：できるだけ嘘をつかないで事にあたる。 20年後の自分に質問して価値観を考える（あらゆる面で満足している自分をイメージして） あなたがそのような成功をおさめたのはどうしてですか？ 例：地道な努力を続けた そのようになるには何が必要でしたか？ 例：周りの人に恵まれた そのように運にも恵まれるには、あなたが何をしてきたからですか？ 例：誠意をつくして正直でありつづけた 「役割 (Role)」を考える 「役割」と、その中で「実現したいこと」を考える。 例：父親、友人、夫、上司（部下）、子供、兄弟、社会の一員、テニスクラブのメンバー 「ミッション (Mission)」を考える（自分自身の憲法） あなたの人生のなかで、充実感の高かった成功体験は何でしたか？ 例：全国スピーチ大会で優勝したこと ⇒ 自分を素直にアピールすることに長けていた。 今後仕事面で実現したいことは何ですか？ 例：独立してレストランを開く プライベートで、すばらしい結果をもたらすとおもわれることは何ですか？ 例：子供と野球チームを作り、親子の対話を欠かさない 毎日の生活で気をつけていることは何ですか？ 例：元気に挨拶をし、周りの人を気持ちよくさせる 私生活で最も価値があると考える活動は何ですか？ 例：地球環境にやさしいリサイクル活動を行う 今後の人生でやりたいことは何ですか？ 例：つりに打ち込み、名人になる 今、十分な時間があれば誰と何をしたいですか？ 例：妻と一緒に全大陸を旅行する これからの人生で一番実現したいことは何ですか？ 例：事業を成功させる あなたの理想とする人生はどのようなことを成し遂げた人ですか？ 例：周りの人に常に元気を与え続けた父のようになる あなたの人生のなかで大きな影響を受けた人はどんな点が最も優れていましたか？ 例：どんな人とも分け隔てなく付き合おうとした点 あなたの得意なものは何でしたか？また今後どう活かしますか？ 例：みなの前でしゃべること。 ⇒ 「話す」ことに充実感を感じ、リーダーシップをとることに誇りを感じる 弔辞（ちょうじ）を考えてミッションを明らかにする 私生活での友人の弔辞の例 例：誠実で信頼できる友に先立たれ、大きな喪失感を味わっています 職場の同僚の弔辞の例 例：皆を率いたリーダーを喪い、明日から路頭に迷いかねません 地域社会の知人の弔辞の例 例：誰からも愛されたあなたですから、天国でも楽しく過ごされることでしょう 家族からの弔辞の例 例：子供たちの良き手本となり家族を正しい方向へ導いてくれました 職場の部下（上司）からの弔辞の例 例：先輩がいらしたからこそ横道にそれずに歩んでこられました 最も大切なこと（Value, Role, Mission）が明らかになったら 「価値観」に説明文をつける 「役割」に説明文をつける 長期目標とそのためのステップを設定する"
},
{
url: "/p/h52ih57/",
title: "TV規格: ISDB(ARIB)メモ",
date: "2008-07-14T00:00:00Z",
body: "TV規格: ISDB(ARIB)メモ 自動表示メッセージ (Auto Message) 左下に表示される B-CAS 関連のメッセージ枠などに関する仕様です。 詳しくは「ARIB TR-B14 5.10 自動表示メッセージ表示」を参照 EMM共通メッセージセクションの自動表示消去種別というもので表示の ON/OFF を行う 0x00 消去可: ユーザ操作で表示 OFF してもよい 0x01 消去不可: 出しっぱにしなきゃダメ 0x02 表示消去: 今消すべし 映像といっしょに EPG（番組表）などが表示されている場合に、自動表示メッセージを表示するかどうかは商品仕様による（表示 OFF にしているものがほとんど）。 表示枠は視聴を邪魔しないように半透明などにするのが望ましい（とは言っても、視聴の邪魔をして有料契約させる意図がある）。 文字色は商品仕様によるが、無彩色にして必要以上に目立たせないのが望ましい。 録画された番組を再生する場合にも、TS データに基づいて表示する。契約情報などは、その時装着されている IC カードに基づいて判断すること。 デコードに関するメッセージ、例えば IC カード抜け（デスクランブルできない）などのメッセージは優先して表示してよい。IC カードを装着してデコードできる状態になってから（映像が見えてから）自動表示メッセージを改めて表示すれば OK。 Network ID、TS ID、Service ID などのユニーク性に関して 『ＢＳ/広帯域ＣＳデジタル放送運用規定 ARIB TR-B15　6.5版（第二分冊） 5.3 識別子の運用』より。 network_id: BS デジタル放送に対して1 個割り当て。日本国内でユニーク。 transport_stream_id: 各TS に対し割り当て。ネットワーク内でユニーク。 service_id(=program_number): 各編成チャンネルに対し割り当て。ネットワーク内でユニーク。 event_id: 各イベントに対し割り当て。service 内でユニーク。 broadcaster_idブロードキャスタに対して割り当て。オリジナルネットワーク内でユニーク。 series_id: 番組のシリーズに対して割り当て。ブロードキャスタ内の同一メディ アタイプに属するサービス群内でユニーク。 8.2.1 event_id の再使用について（時間方向の一意性）より 終了時刻を過ぎれば、そのイベントに付与された event_id の値は、EIT から消え、一定時間後、別のイベントに対し同じ値を付与することが可能となる。 しかし、終了時刻から 24 時間以内は別のイベントに対し同じ値を付与し EIT に記述してはならない。 枝番表示について http://www.arib.or.jp/english/html/overview/doc/4-TR-B14v4_1-1p3-1.pdf#page=213 枝番 他地域（他県）の放送を受信する場合、その地域の放送局のチャンネル 番号と自地域の放送局のチャンネル番号が重複する場合があり、この時 は、３桁チャンネル番号も同じになる。受信機では、これらの放送局を 区別するために、3 桁に加えてもう 1 桁、番号を付ける。この番号を「枝番」と呼び、自地域の放送局には、末尾に「0」が、他地域の放送局に は「1」以降の番号が付けられる（例: 自地域 0210、他地域 0211 など）。 ジャンル情報に関する情報 ARIB TR-B14 3.5版（第二分冊）4-341 第4部付録 [付録A] 放送開始当初のジャンルコード表（content_nibble） TR-B15: BS/広帯域CSデジタル放送運用規定（第2分冊） [付録A] 放送開始当初のジャンルコード表 地デジ/BS/CS 共通のジャンル TR-B15: BS/広帯域CSデジタル放送運用規定（第4分冊） [付録A] 放送開始当初のジャンルコード表 CS では、content_nibble_level_1=\u0026ldquo;0xE\u0026rdquo;, content_nibble_level_2=\u0026ldquo;0x1\u0026rdquo; に、user_nibble フィールドにて拡張ジャンルを表現いている。 EIT[p/f/sch] に関する情報 ARIB TR-B14 第4分冊: B.8 EIT (p.4-396) 番組セルの表示方法 ARIB TR-B14 第4分冊: 19 イベント編成変更 ARIB TR-B14 第4分冊: 19.6.5 番組割り込み(2) EPG の表示仕様については以下を参照 ARIB TR-B14 6.6 EPG EPG のチャンネルの並び順（07DTG の UI 仕様より） BS/CS デジタルの場合には service_id 昇順。 地上デジタルの場合には「ARIB TR-B14 第二編 6.6.3 番組表および番組リスト」 「JEITA 地上デジタルテレビジョン放送受信機 受信機動作ガイドライン 4 EPG への放送局提示順に関するガイドライン」に準拠する。並び変えたチャンネルは、左から右に配置する。 デジタル放送に関するアクセス制御方式 ARIB STD-B25 CAS-R \u0026ndash; 受信時の制御方式である限定受信方式。暗号化（スクランブル）されたコンテンツを受信時に復号し、リアルタイムでコンテンツを視聴することを可能とするもの。 CAS-P \u0026ndash; 再生時の制御方式である限定再生方式。サーバー型放送受信機の蓄積装置に暗号化されたままの状態で蓄積したコンテンツを、再生時に復号し、サービス事業者より許諾された利用条件に従って視聴、利用することを可能とするもの。 チャンネルロゴに関して チャンネルロゴのサイズ HD ラージ 36x64 ｽｸｴｱﾋﾟｸｾﾙ 9 : 16 0x05 1152 HD スモール 27x48 ｽｸｴｱﾋﾟｸｾﾙ 9 : 16 0x02 972 SD4:3 ラージ 36x72 1.118 : 1 9 : 16 0x03 1296 SD4:3 スモール 24x48 1.118 : 1 9 : 16 0x00 864 SD16:9 ラージ 36x54 1.118 : 1.333 9 : 16 0x04 972 SD16:9 スモール 24x36 1.118 : 1.333 9 : 16 0x01 648 参考: 『地上デジタルテレビジョン放送運用規定』ARIB TR-B14 3.5版（第一分冊）(1/2) のページ 1-6 表4-1 送出するロゴマークのサイズパターン（ロゴタイプ） ロゴデータのダウンロード チャンネルロゴのダウンロードに関して運用規定を抜粋。 ARIB TR-B14_3.5版（第一分冊）(1/2) 4 ダウンロードの用途と前提 (3) ロゴデータの更新 受信機の設置場所にて受信できる放送局のロゴデータ更新を行う。受信機は出荷時の初期状態においてロゴデータを持っていないと想定される。各放送局は表示させたいサービスのロゴデータを自らの放送波によって受信機へダウンロードする。 5 ダウンロード伝送ガイドライン \u0026ndash; 5.1.1 ダウンロードコンテンツ ロゴのうち、PNGデータとして送出されるロゴデータはCDT（Common Data Table）を用いて配信される。また簡易ロゴに用いる文字（最大英数記号5文字）はSDT内に配置するロゴ伝送記述子に記載する。 5 ダウンロード伝送ガイドライン \u0026ndash; 5.1.2 告知情報 CDTを用いてロゴが配信されている間は、SDTサービスループ内のそのロゴを参照するサービスにロゴ伝送記述子が配置され、ロゴ配信が検知可能であるとともに、CDTへのポインティングがなされる。 6.2 CDT方式の受信機ガイドライン \u0026ndash; 6.2.1 メモリ規定 (1) ロゴデータ用のメモリ領域として必要となるメモリ量を確保すること。送られてくる 6 種類のロゴデータのうち、どれを取得するかは商品企画とする。 6.2.2 動作規定 \u0026ndash; 6.2.2.1 受信機能 以下の手順で新しいロゴデータの受信／蓄積／表示を行う。 (1) SDT 内サービスループにCDT 伝送方式1 のロゴ伝送記述子が配置されているのを検出する。 (2) logo_id とlogo_version 値が現在受信機内に保存されているものと異なる場合、ロゴ伝送記述子に記載のdownload_data_id をサブテーブルとし、かつ、受信機で使用する logo_type のセクションのCDT を受信する。 (3) \u0026hellip; ⇒ つまり、SDT 内に「ロゴ配信しますよ」フラグが立っているタイミングでロゴデータが受信されます。 ARIB STD-B21_4.8版 デジタル放送用受信装置（望ましい仕様） 12.2.2.2 ダウンロードコンテンツ・セクション伝送方式 ダウンロードコンテンツをセクション形式で伝送する場合はCDT（Common Data Table）を用いる。 (1) 全受信機共通データテーブル（CDT）（Common Data Table） CDT は、そのテーブルを受信する全ての受信機を対象として、不揮発性メモリに格納すべき共通データをセクション形式で伝送するために用いる。地上デジタルテレビジョン放送では、事業者のサービスロゴデータはCDT 内のdata_module_byte にロゴデータを配置して伝送する。ロゴデータフォーマットは「付属(ダウンロード機能)」のAppendix.A を参照のこと。 3 用語 [#tb268b1d] CDT: Common Data Table：全受信機共通データテーブル。事業者ロゴマークなど、受信機で共通に必要なデータを伝送する。 番組の最短時間長、最大時間長について ARIB TR-B14_3.5版（第二分冊） C.5 番組表 C.5.6 番組表で扱う情報種 より抜粋 番組開始予定時刻と終了予定時刻 EITのstart_time , durationフィールドを利用する。イベント時間長の最大値は48時間である。よってイベント終了時刻は最大二日後の日付になる可能性もある。情報提示を行う際には注意が必要である。また最小時間は1分であるがやむを得ぬ場合には1分未満のイベントが定義されることがあること、開始時刻が毎正分に設定されるとは限らないことにも注意が必要である。サマータイム導入時にはTOTで提供されるローカルタイムオフセット記述子を利用しオフセット時刻を足した時刻で提示すると良い。 １分未満を正式に許可しているのか、どっちなのかはっきりして欲しい。。。 規格資料リンク 放送分野の標準規格 (STD) http://www.arib.or.jp/tyosakenkyu/kikaku_hoso/hoso_kikaku_number.html STD-B10: デジタル放送に使用する番組配列情報 概要: http://www.arib.or.jp/tyosakenkyu/kikaku_hoso/hoso_std-b010.html PDF: http://www.arib.or.jp/english/html/overview/doc/2-STD-B10v5_3.pdf 放送分野の技術資料 (TR) http://www.arib.or.jp/tyosakenkyu/kikaku_hoso/hoso_gijutsu_number.html TR-B14: 地上デジタルテレビジョン放送運用規定（全5分冊） 概要: http://www.arib.or.jp/tyosakenkyu/kikaku_hoso/hoso_tr-b014.html 第1分冊: http://www.arib.or.jp/english/html/overview/doc/4-TR-B14v5_6-1p5.pdf 第2分冊: http://www.arib.or.jp/english/html/overview/doc/4-TR-B14v5_6-2p5.pdf 第3分冊: http://www.arib.or.jp/english/html/overview/doc/4-TR-B14v5_6-3p5.pdf 第4分冊: http://www.arib.or.jp/english/html/overview/doc/4-TR-B14v5_6-4p5.pdf 第5分冊: http://www.arib.or.jp/english/html/overview/doc/4-TR-B14v5_6-5p5.pdf TR-B15: BS/広帯域CSデジタル放送運用規定（全4分冊） 第1分冊: http://www.arib.or.jp/english/html/overview/doc/4-TR-B15v6_5-1p4.pdf 第2分冊: http://www.arib.or.jp/english/html/overview/doc/4-TR-B15v6_5-2p4.pdf 第3分冊: http://www.arib.or.jp/english/html/overview/doc/4-TR-B15v6_5-3p4.pdf 第4分冊: http://www.arib.or.jp/english/html/overview/doc/4-TR-B15v6_5-4p4.pdf"
},
{
url: "/p/pd4aqk6/",
title: "将棋、チェスなどの対人ゲームで待ち時間を減らすアイデア",
date: "2008-07-14T00:00:00Z",
body: "将棋、チェスなどの対人ゲームで待ち時間を減らすアイデア 将棋やチェスって、相手が長考する人だと待っている時間がヒマだったりしますよね（その時間も考えろよという話ですが）。 あと、今はもうないかもしれませんが、手紙を使って手を進めていくゲームなどでも待ち時間はすごく長いです。 こんなときは、2枚の盤を使って同時に先手・後手になって交互に指す、というのが面白いです。 つまり、同じ相手とやる多面指しです。 うまくタイミングが合うと、常に自分の手番になります（笑）。 別に将棋ｘ２でやらなくても、オセロと碁、将棋とチェスみたいに別のゲームを同時にやっても面白いです。 慣れるまでは頭の体操みたいになっちゃいますけど。"
},
{
url: "/p/m4x8mcw/",
title: "クワイン・マクラスキー法 (Quine-McCluskey algorithm)",
date: "2008-06-20T00:00:00Z",
body: "クワイン・マクラスキー法 (Quine-McCluskey algorithm) カルノー・マップを用いた Bool 演算の簡易化のような処理を、単純な処理の繰り返しで行えるようにしたもの。コンピュータでの処理に向いている。 クワイン・マクラスキー法 - Wikipedia Petrick\u0026rsquo;s method - Wikipedia"
},
{
url: "/p/r58xbyk/",
title: "無名サブルーチンとクロージャ",
date: "2008-04-30T00:00:00Z",
body: "無名サブルーチンとクロージャ 『初めての Perl 第3版』より クロージャ (closure) は非常に強力な概念で、Lisp の世界から持ってきたものです。クロージャとは、（荒っぽい言い方をすれば）自分自身のプライベートなデータを持っている無名サブルーチンです。 『続・初めての Perl』より その時点で存在するすべてのレキシカル変数に、宣言された時点からアクセスできるサブルーチンをクロージャ (closure) と呼びます（クロージャは、もともとは数学用語です）。 例えば、以下の callback サーブルーチンは、レキシカル変数 $count を参照するクロージャといえます。 my $count = 0; sub callback { ++$count; }"
},
{
url: "/p/j26fuew/",
title: "ライフハック／未分類メモ",
date: "2007-09-16T00:00:00Z",
body: "ライフハック／未分類メモ ストレスフリーに過ごすコツ 自分の心配ではなく、他人のことを気遣うようにする。他人のことを考えていれば、自分のことで悩む暇はなくなる。 何かに夢中になること。読書、ゲーム、運動、DIY などなんでもよい。 プレゼンテーションの上達方法 ロールモデルを持つ 例えば、レーガン大統領のプレゼンをイメージし、彼とどこが違うのかを分析する。 他人のアドバイスは反論せずに真摯に受け止める 自分のプレゼンを客観的に分析する 参考: 先見経済 2005-11-07「プレゼン力を鍛える（西野浩輝）」 三日坊主の防止法 目標は現実的なものを設定する。 目標を達成したら何が得られるかを明確にする。 目標を細分化して達成感を得られやすいようにする。 参考: BIG tomorrow May 2006「三日坊主を直すための方法・大研究」 2 つの作業の期間を合わせてリズムを作る 例: ブリタ（浄水器）のカートリッジを変える時に台所で使うスポンジを新しいものに交換する。"
},
{
url: "/p/b34f2vu/",
title: "大規模なコードを読み解くコツ（コードリーディング）",
date: "2007-05-12T00:00:00Z",
body: "大規模なコードを読み解くコツ（コードリーディング） 階層構造の意味をメモする 大規模なプロジェクトのソースコードを読む場合は、まずはディレクトリがどのようなポリシーで分けられているのか、各ディレクトリ内のコードの役割などのメモを作成していくことをオススメします。 役割のわからないディレクトリについては、そのままにしておいて、わかった時点で詳細を追加していけば OK です。 project +-- tools（ほげほげ用のツール） +-- src +-- hogeui（ほげほげインタフェースに関するクラス） +-- foobar（？）"
},
{
url: "/p/nyehhfd/",
title: "Linuxコマンド: パッチファイルを作成・適用する (diff, patch)",
date: "2007-05-11T00:00:00Z",
body: "Linuxコマンド: パッチファイルを作成・適用する (diff, patch) パッチの基本 (diff/patch) パッチファイルの作成 sample.cpp #include \u0026lt;iostraem\u0026gt; int main() { std::cout \u0026lt;\u0026lt; \u0026#34;AAA\u0026#34; \u0026lt;\u0026lt; std::endl; return 0; } ew/sample.cpp #include \u0026lt;iostraem\u0026gt; int main() { std::cout \u0026lt;\u0026lt; \u0026#34;BBB\u0026#34; \u0026lt;\u0026lt; std::endl; return 0; } 例えば、上記のような sample.cpp の内容を new/sample.cpp に変更するためのパッチファイルを作成するには、次のように diff コマンドを実行します。 $ diff -u sample.cpp new/sample.cpp \u0026gt; sample.patch -u オプションは unified diff 形式で差分を出力することを示しています（他の形式でも出力可能ですが、patch 用のパッチファイルを作成するときは、ほとんどの場合 unified diff 形式が使用されるようです）。 これで、次のようなパッチファイルが生成されます。 sample.patch --- sample.cpp 2007-05-11 20:36:13.265625000 +0900 +++ new/sample.cpp 2007-05-11 20:26:31.875000000 +0900 @@ -1,6 +1,6 @@ #include \u0026lt;iostraem\u0026gt; int main() { - std::cout \u0026lt;\u0026lt; \u0026#34;AAA\u0026#34; \u0026lt;\u0026lt; std::endl; + std::cout \u0026lt;\u0026lt; \u0026#34;BBB\u0026#34; \u0026lt;\u0026lt; std::endl; return 0; } 差分を表示している各行の 1 文字目は次のような意味を持っています。 + \u0026hellip; 追加される行 - \u0026hellip; 削除される行 space \u0026hellip; 変化しない行 変化しない行の情報を含めることにより、パッチを当てるときに、前後関係を考慮しながら処理できるようになります。 FreeBSD の diff の man ページにも、パッチ作業をうまく働かせるために、この変化しない行が必要であることが明記されています。 パッチファイルの適用 作成したパッチファイルを適用するには、対象のファイルがあるディレクトリへ移動し、以下のように実行します。 $ patch \u0026lt; sample.patch patching file sample.cpp パッチを適用する前のファイルをバックアップしておきたい場合は、-b オプションをつけて patch コマンドを実行します。 $ patch -b \u0026lt; sample.patch patching file sample.cpp sample.cpp が修正されると同時に、バックアップファイルとして sample.cpp.orig が生成されます。 ディレクトリ単位での diff/patch ディレクトリ内のファイルをまとめての diff を取る $ diff -urN old_dir new_dir \u0026gt; hoge.patch -r オプションでディレクトリを再帰的に検索、-N オプションで削除、追加されたファイルについても diff を取るようになります。 ディレクトリ内のファイルにまとめて patch を当てる 変更対象のファイルのあるディレクトリに hoge.patch を置いて、そこで次のように実行します。 $ patch \u0026lt; hoge.patch"
},
{
url: "/p/4kntagu/",
title: "ライフハック: ライフハックのライフハック",
date: "2007-05-11T00:00:00Z",
body: "ライフハック: ライフハックのライフハック 実行したい LifeHacks や、心構えのリストは常に持ち歩いて定期的に見直せるようにしておくとよいです。 実行すべき LifeHacks の内容を忘れてしまっては意味がないので。"
},
{
url: "/p/9658789/",
title: "ライフハック: 遠出したときの写真の撮り方",
date: "2007-05-10T00:00:00Z",
body: "ライフハック: 遠出したときの写真の撮り方 旅行にいったときや、遠くへ散歩に出かけたときなどは、ルールを決めて写真を撮っておくようにすると、その行動を後日思い出しやすくなります。 場所を移動したときは、場所が分かる写真を撮る 電車に乗る場合は、ホームなどで必ず駅名や地名の入ったものを写真に撮っておくようにします。 車や飛行機、船などで移動する場合も同様。 最近の携帯電話のカメラは GPS 情報が付加されるけど、写真内に地名が分かるものを写しておいたほうが手っ取り早いです。 一時間おきくらいに何でもいいから周辺の写真を撮る どんな場所にどれくらい時間をかけたかを思い出せます。 理想的には一時間おきに自分が見ている風景を自動的に撮影してくれる装置みたいなのがあればいいんですけどね。"
},
{
url: "/p/87vzas6/",
title: "ビリヤード",
date: "2007-05-09T00:00:00Z",
body: "ビリヤード"
},
{
url: "/p/d88pph6/",
title: "ビリヤード: 最近の練習メニュー",
date: "2007-05-09T00:00:00Z",
body: "ビリヤード: 最近の練習メニュー 左手で 15 球入れる センターショット 10 球 押し引きを交互に 5 球ずつ（スクラッチさせる） フットショット　左右交互に 5 球ずつ への字　左右交互に 5 球ずつ 土手撞き　左右交互に 5 球ずつ 力加減の調整　左右 5 球ずつ バンクショット 練習方法模索中。。。 ボーラード 3 フレームとミスした配置の練習（3 連続ストライクを目指す） 出しや入れに失敗したら、その配置をできるだけ正確にメモして、その配置を納得するまで練習。 リカバリに失敗した場合は、リカバリする配置にしてしまった原因の配置と、リカバリショットの両方を練習すること。 メモが溜まれば、自分の苦手な配置のパターンが分かってくる。 Artistic Pool の課題球の練習 http://www.artisticpoolplayers.com/ 特殊な撞き方やキュー切れをアップさせることでプレーの幅を広げる。 自分のショットのスキルがどれだけ未熟かを認識できます。。。 その他の練習配置など"
},
{
url: "/p/8rjkpe3/",
title: "河口湖かちかち山へ",
date: "2007-05-02T00:00:00Z",
body: "河口湖かちかち山へ 自然に癒されたくなったので河口湖へ。 河口湖駅から歩いて 15 分くらいで行けます。 湖の前のお店でほうとうを食べて、ロープウェイでかちかち山に登りました。 かちかち山からは河口湖の他に、富士山とか富士急ハイランドとか見渡せます。 う～～～ん、空気がうまーい。 と深呼吸したら、流れてきたタバコの煙をおもいっきり吸い込んでげほほっ。"
},
{
url: "/p/tamw4a7/",
title: "富士急ハイランド、ええじゃないか",
date: "2007-05-01T00:00:00Z",
body: "富士急ハイランド、ええじゃないか 突然「ええじゃないか」に乗りたくなったので富士急ハイランドへ。 8 時開園だったので、4 時に起きて電車で 5 時発くらいの電車に乗って行きました。 ねむー。 前日は暑かったので薄着でいったら、曇っていてめちゃんこ寒かったので、中で上着を購入。 とりあえず 3 大ジェットコースター？のフジヤマ、ドドンパ、ええじゃないかに乗りました。 ドドンパは急発進していきなり 170 km くらい出すので、顔が風圧でぐにゃぐにゃです。 フジヤマは地上 80 メートルくらいまで上るし、さらに寒くてガクブル。 ええじゃないかは座席がぐるんぐるん回ったけど、ホールド感がすごいあったので、3 つの中では一番平和な乗り物でした。 近くにふじやま温泉ってのがあったので、そこで疲れをとってご飯たべて、歩いて 15 分くらいのビジネスホテルでねんねこ（富士急フリーパス込みで 8500 円でした）。 ふじやま温泉は風呂出た後にくつろげるスペースがたくさんあって結構よかったです。 ただ、富士急ハイランドを挟んで駅の反対側にあるから帰り道がかなり困ります。 ぐるーっと回って駅側に出るのは歩きだと結構遠いので、タクシー乗るのがおすすめかな。"
},
{
url: "/p/d4huh4e/",
title: "シルク・ドゥ・ソレイユの「ドラリオン」見てきた",
date: "2007-04-28T00:00:00Z",
body: "シルク・ドゥ・ソレイユの「ドラリオン」見てきた 原宿駅近くの国立代々木競技場の横辺りに、シルク・ドゥ・ソレイユのドラリオンを見に行きました。12:30 から 15:00 まで。 シルク・ドゥ・ソレイユは、２年おきくらいに日本でミュージカル風のサーカスやってるグループです。サルティンバンコとかアレグリアとかが有名かな（見たことないけど）。 DVD でも出ているみたいなので今度見てみよっと。 簡単に言えば、サーカスの豪華版のようなものだけど、普通のサーカスに比べると、質が全然違います。技、音楽、衣装、パフォーマンスなど、見せ方がうまい。 とはいっても、高度な技がすべて成功することはなくて、何度かミスすることがありました。シルク・ドゥ・ソレイユがすごいのはここからで、ミスをすると同時にみんなが踊りだして、そのダンスの中でセットの修復などを済ませてしまう。普通のサーカスだったら、もう一回チャレンジしますよ的なパフォーマンスになってしまうんだけど、流れを乱さずにミスのフォローをするってところに感動しました。そのフォローの仕方を見たくて、途中からミスして欲しくなってしまいました。 SS席 11000 円はちょっと高めかなと思ったけど、それだけの価値はありました。"
},
{
url: "/p/3vej2ej/",
title: "ビリヤードのアイデア: 詰めビリヤードという遊び方",
date: "2007-04-19T00:00:00Z",
body: "ビリヤードのアイデア: 詰めビリヤードという遊び方 昔、ビリヤードの雑誌の『球\u0026rsquo;s』か何かに、エフレン・レイズは球を取り出すのが面倒なので、練習ではポケットに入れないことがあるって書いてありました。 これは球が穴にプールされるタイプのテーブルの場合の話だと思うけど、ポケットさせないで練習するっていうのが結構新鮮でした。 ビリヤード場でそんな練習してる人ってほとんど見たことないから。 これを読んで思ったんですけど、ポケットビリヤードの台でも、先球をポケットさせない遊び方はもっとたくさんあっていいと思います。 カイルンなんかはその代表例だけど、キャロム系のゲームに捉われずにもっといろいろ楽しみ方はあるはず（アーティスティックは初心者には難しすぎ）。 例えば、ある条件を満たせたら得点ゲットとか、手球を課題通り動かせたらＯＫ、みたいな。 言うなれば、詰め将棋ならぬ、詰めビリヤードみたいな遊び方があってもいいと思う。 簡単な問題例として、以下の配置。 クリア条件: 手球フリーで、先球を 3 クッション以上させて、手球と先球をキスさせる 解答例はこちら: 20070419-002.png いろんな遊び方、独特な練習方法を試して、個性的なスキルを身に付けていきたいですね。"
},
{
url: "/p/pnzzne6/",
title: "ビリヤードのコツ: 左右を捻るときの顔のラインに注意",
date: "2007-04-12T00:00:00Z",
body: "ビリヤードのコツ: 左右を捻るときの顔のラインに注意 左右の撞点を撞くときは、キューのラインだけ平行移動させるのではなく、顔のラインをキューのライン上に乗せること。こうしないと、キューを真っ直ぐ出せないので、払うような撞き方になってしまう。カーブの出にくいショットをするためにも重要。 特に、こんな感じのレール沿いで強めに突く場合、払うような撞き方になってしまうと押しがかかりにくくなったり、方向がずれてガコりやすい。"
},
{
url: "/p/asgh5yd/",
title: "ビリヤードのコツ: 素振りとラストストロークの調子を変えない",
date: "2007-04-10T00:00:00Z",
body: "ビリヤードのコツ: 素振りとラストストロークの調子を変えない 素振りに意味を持たせるためにも、素振りとラストストロークで、ストロークの調子を変えてはいけません。 相対的なスピード自体は若干変わるのはしょうがないけど、全体のリズムを保つ感じ。 例えば、 上体の位置を変えない 握り方を変えない 力の入れ具合を変えない 前腕の軌道、キュー方向（ベクトル）の変化具合を変えない プロのラストストロークは、B級くらいの人と比べて、素振りとラストストロークのギャップが小さいのがよく分かります。 とくにハードショットのとき。 ラストストロークで急に力が入ってしまう癖のある人は、バックスイングの頂点まで脱力を保ちつつ、同じ軌道でキューを引くことに気をつけるとよいです。"
},
{
url: "/p/cxx9oa2/",
title: "ビリヤードのコツ: すべての動作を滑らかに",
date: "2007-04-02T00:00:00Z",
body: "ビリヤードのコツ: すべての動作を滑らかに 緊張していてもキューをまっすぐ振るコツは、すべての動作を滑らかにすること。 動作を滑らかにするには、スピードを一定にすることに気をつける。 ひとつはキューの振りのスピード（バックスイングからフォロースルーまで）。 ストロークのスピードが安定しないと、手球の動きも安定しない。 カクカクしたストロークはダメ。 もうひとつは自分なりのルーチンの動作のスピード（移動→狙う→構える→素振り→ラストストローク）。 各動作を滑らかに繋げられれば、乱れが減って落ち着けるし、見た目もきっとエレガント。 ストロークで意識するのは、肘から下の前腕が滑らかに真っ直ぐ出せるかどうか。 あくまで頭、ブリッジは動かさず、手首は使わずに柔らかく。"
},
{
url: "/p/t9urz45/",
title: "ビリヤードのアイデア: 練習配置用スポットシール",
date: "2007-03-15T00:00:00Z",
body: "ビリヤードのアイデア: 練習配置用スポットシール 新しいビリヤード練習アイテム開発しましたっ。 同じ配置を繰り返し練習するためのスポットシールです。 ポスト○ットに穴あけただけ。。 市販されてるパンチ穴シールでもよいけど、練習用に使う場合は粘着力がもっと弱い方がよいので。"
},
{
url: "/p/445q6w9/",
title: "ビリヤードのコツ: コンビネーションからの出し",
date: "2007-03-14T00:00:00Z",
body: "ビリヤードのコツ: コンビネーションからの出し やや右側に当て、手球より長く走らせてネクストを作る。 ネクストは右上コーナー狙いか、上サイドになる。 ネクストを左上のコーナーに取ろうとしても、先球は手球よりも右側に出るので失敗する。"
},
{
url: "/p/qwtoj94/",
title: "SQLite の日時関連の処理",
date: "2007-02-17T00:00:00Z",
body: "SQLite の日時関連の処理 現在の日時を取得する（テキスト形式） 日付＋時刻 sqlite\u0026gt; select datetime(\u0026#39;now\u0026#39;) 2007-02-17 07:53:30 日付のみ sqlite\u0026gt; select date(\u0026#39;now\u0026#39;) 2007-02-17 時刻のみ sqlite\u0026gt; select time(\u0026#39;now\u0026#39;) 07:53:30 これらのデータ型は TEXT 型です。 sqlite\u0026gt; select typeof(datetime(\u0026#39;now\u0026#39;)); text 現在の日時を現地時間で取得する（テキスト形式） sqlite\u0026gt; select datetime(\u0026#39;now\u0026#39;, \u0026#39;localtime\u0026#39;) 2007-02-17 16:53:30 sqlite\u0026gt; select date(\u0026#39;now\u0026#39;, \u0026#39;localtime\u0026#39;) 2007-02-17 sqlite\u0026gt; select time(\u0026#39;now\u0026#39;, \u0026#39;localtime\u0026#39;) 16:53:30 ある標準時を現地時刻へ変換する sqlite\u0026gt; select datetime(\u0026#39;2007-02-17 21:30:00\u0026#39;, \u0026#39;localtime\u0026#39;); 2007-02-18 06:30:00 sqlite\u0026gt; select time(\u0026#39;21:30:00\u0026#39;, \u0026#39;localtime\u0026#39;); 06:30:00"
},
{
url: "/p/qnnukuj/",
title: "Doxygen でどのコメントスタイルを使うべきかの考察",
date: "2006-08-08T00:00:00Z",
body: "Doxygen でどのコメントスタイルを使うべきかの考察 方法(1) Javadoc スタイル これが一番よく使われている記法だと思います。 特にこだわりがないのであれば、この記法を使っておくのが無難です。 /** * @brief Brief description. * * Detail description. * @param a hogehoge * @param b hogehoge */ void Hoge(int a, int b); 特徴 brief コマンドの後ろに空行が必要なため、行数が増えてしまうし、少しアンバランスな感じになる。 ひとつのコメントブロックとして判別しやすい。 簡易説明は 2 行以上に渡って記述できる（その代わり、brief の下に空行が必要という制約がある）。 簡易説明だけでよい場合にすっきり書くのが難しい（その場合は /// で一行で済ませる手がある）。 一行の Brief description だけ記述したい場合でも、以下のように @brief が必要です。 /** * @brief Brief description. */ void Hoge(); あるいは、 /** @brief Brief description. */ void Hoge(); 通常は Javadoc スタイルで書いておいて、一行の Brief description だけを記述したい場合だけ、C# スタイルのコメントを使うのがすっきりするかもしれません。 /// Brief description. void Hoge(); Javadoc スタイルのコメントは、以下のような file スペシャルコマンドの書き方と統一しやすいのも利点です。 /** * @file $File$ * @brief Brief description. * * Detail description. */ 方法(2) C# スタイル /// @brief Brief description. /// /// Detail description. /// @param a hogehoge /// @param b hogehoge void Hoge(int a, int b); 特徴: 記号は 2 種類だけでよい。 brief コマンドの後ろに空行が必要なため、行数が増えてしまうし、少しアンバランスな感じになる。 簡易説明は 2 行以上に渡って記述できる。 方法(3) Qt スタイル 一行要約に //! を使うことができます。 //! Brief description. /*! * Detail description. * \\param a hogehoge * \\param b hogehoge */ void Hoge(int a, int b); 特徴 見にくい！ 4種類の記号を使うので煩雑。 簡易説明は一行しか書けない。 番外編(1) Qt スタイルと C# スタイルのハイブリッド Brief description にだけ Qt 風の記法を使う方法です。 //! Brief description. /// Detail description. /// @param a hogehoge /// @param b hogehoge void Hoge(int a, int b); 特徴 brief コマンドのあとに、空行を入れなくてもよい。 行数は最も少ないが、詰め込みすぎな感じもする。 C++ のコメントスタイルを使っているので、C 言語のコメントでまとめてコメントアウトできる（/* と */ で囲める）。 コンパクトに書けますが、ちょっとやりすぎかな。。パッと見、抵抗を感じます。 番外編(2) C# スタイルと Javadoc スタイルのハイブリッド /// Brief description. /** * Detail description. * @param a hogehoge * @param b hogehoge */ void Hoge(int a, int b); 特徴 brief コマンドのあとに、空行を入れなくてもよい。 簡易説明は一行しか書けない。 簡易説明だけでよい場合に、以下のように C# スタイルで一行で記述するのであれば、このハイブリッド記法はまぁまぁイケてるかもしれません。 /// Brief description. void Hoge(); まとめ Javadoc スタイルを使うのがオススメ メソッドのコメントが1行の要約だけでいい場合は、例外的に C# スタイルの /// を使うとすっきりする。"
},
{
url: "/p/96rfove/",
title: "読書メモ『アイデアのつくり方』ジェームス・ウェブ・ヤング",
date: "2006-06-24T00:00:00Z",
body: "読書メモ『アイデアのつくり方』ジェームス・ウェブ・ヤング アイデアのつくり方 ジェームス・ウェブ・ヤング CCCメディアハウス いろんなブログで絶賛されているほど目から鱗という感じではないですが、アイデアが生まれる過程がどのようなものかが分かりやすく記述されています。 あまりに古い文献（原著 1940 年）なので、コンピュータやネットの活用方法については何も触れられていません。 アイデア作成に大切な２つのこと アイデアとは既存の要素の新しい組み合わせである。 組み合わせる才能は事物の関連性を見つける才能に依存する。 言葉はそれ自身がアイデアである 言葉をマスターするとアイデアは息を吹き返す。 言葉はアイデアのシンボルであり、言葉を集めることでアイデアを集められる。 アイデアを生み出す手順 下記に示したものがアイデア作成までの 5 ステップであり、ひとつでも順番を飛ばしてはいけない。 1, 2, 5 は意識的活動の時期に行われるもので、3, 4 は無意識的活動の時期に行われるものである。 第1段階 … 資料を集める アイデアの種がなければアイデアは生まれないためこのステップを飛ばさないこと。 実際は資料集めをほとんどせずにアイデアが浮かぶことを待ってる人が多い。 資料集めは大変な作業であり、積極的な収集活動が必要。 カード索引法を学ぶとよい。3 インチ x 5 インチのカードにアイデアの断片を書き込んで分類していく方法。 一般的資料を集めるためにスクラップ・ブックのようなファイルを作成するのも有益。 第2段階 … データの咀嚼 心の中で資料に手を加える。 事実をあまり直視せず、意味の声に耳を傾けるのがコツ（一種の放心状態に近い）。 この段階で思い浮かんだアイデアは、どんなに突飛で不完全なものでも書き留めておくこと。 この段階でもカード索引法が利用できる。 ふたつの事実を並べてどうすればその二つが噛み合うかなどを考えてみる。 パズルを組み合わせる努力を実際にやりとげ、考えに考え抜いた結果、頭の中がごっちゃになって絶望状態に陥った時点でやっと第三段階へ移行してよい。 第3段階 … 孵化段階 意識の外で、データの組み合わせが勝手に行われることを待つ段階。 問題をできるだけ意識の外に追いやり、努力することを完全に放棄する。 ただし、想像力や感情を刺激する環境に身を置いておくこと（劇場や映画へ出かけたり、小説を読んだりする）。 第4段階 … アイデア誕生の瞬間 もっとも期待していないときにアイデアは訪れる（寝起きや、風呂に入っているときなど）。 第5段階 … アイデアのチェック アイデアを具体化させ、現実の世界へと展開させる。 これをやらないために、ほとんどのアイデアは世に出ることなく消えていく。 アイデアを胸の底にしまいこんでしまわず、理解ある人の批判を仰ぐこと。 良いアイデアはそれ自身が成長する性質を持っている。 良いアイデアは人々を刺激し、人々の意見を集める。"
},
{
url: "/p/dk63fzr/",
title: "読書メモ『ヤル気が格段に高まる科学的習慣』BIG tomorrow August 2005",
date: "2006-05-24T00:00:00Z",
body: "読書メモ『ヤル気が格段に高まる科学的習慣』BIG tomorrow August 2005 昼食後に10分昼寝する。カフェインの含まれたコーヒーがお茶を飲んで目を閉じると、10分くらいで自然に目が覚める。 脳を刺激するなら大腿筋を使って歩く。 デスクワークに疲れた時は、首や肩を揉むよりも、太ももを30回叩いた方がよい。 気持ちよく目覚めるには、音より光。キッチンタイマーとライトを使って、30分前くらいに ON になるようにしておくと自然に目が覚める。 朝起き上がる前に、20秒くらい手と足の指を開いたり閉じたりするとよい。目覚めモードになる。 低い枕を使った方が血流がよくなり、ストレス解消できる。 光と音は厚手のカーテンで完全にシャットアウトするのが快眠のポイント。 起きる時間よりも寝る時間を一定にする。 毎日腹筋を200回すると頭がスッキリする、という人もいる。 就寝前のゲーム、食事、カフェインは快眠の妨げになる。 食事後に入浴する時は、1時間30分の間をおいてからがよい。消化吸収に悪いから。 アイデアは歩いているときにひらめく。"
},
{
url: "/p/q7abhn6/",
title: "特許の読み方（請求項に関して）",
date: "2006-05-02T00:00:00Z",
body: "特許の読み方（請求項に関して） 特許として有効な範囲は「請求項」に挙げられているもの。 「請求項」は1個のこともあれば、200個のこともある。 請求項が複数ある場合は、請求項1が一番抽象的（全体を包含したもの）になっており、他の請求項はそれを掘り下げるものになっている。 言い換えると、それぞれの請求項はツリー構造のような関係になっている。 親の請求項を掘り下げているものは、文末に「〜請求3に記載の〜」のように記述されることが多い。 請求項の階層の上位のものが特許として認められれば、その有効範囲は広くなる。 逆に部分的に認められれば、有効範囲は狭くなる。 請求項は重要だが、その後ろにある「説明」の章を読んだ方が全体の内容、要点（課題、手段）は分かりやすい。 まずは説明の最初の方を読んで、この特許が何を解決しようとしているかの目星をつけるとよい。"
},
{
url: "/p/6rn67mc/",
title: "暗号技術まとめ",
date: "2005-12-20T00:00:00Z",
body: "暗号技術まとめ 昔の暗号 シーザー暗号 - 文字をずらすだけの最も古い暗号。ジュリアス・シーザー（ユリウス・カエサル）が作った。 共通鍵暗号 ブロック暗号 ブロック暗号というのは、共通鍵暗号の一種。 データを一定のブロックごとに暗号化する方式。 高速な暗号化処理を行える。 Triple DES - 1990年代。64 bit のブロック暗号 DES を 3 回繰り返す暗号化アルゴリズム。かつては米国政府標準暗号だった。 MISTY1 - 1990年代。三菱電機が開発した 128 bit 暗号鍵を持つ 64 bit ブロック暗号アルゴリズム。 CAST-128 - 64 bit ブロック暗号。 Camellia - 2000年代。128 bit ブロック暗号。NTT・三菱電機。 AES: Advanced Encryption Standard - 2000年代。128 bit ブロック暗号。 SEED - 128 bit ブロック暗号。 国際標準のブロック暗号 (ISO/IEC18033-3) は、Camellia、AES、SEED、CAST-128、MISTY1、Triple DES。 ストリーム暗号 MUGI MULTI-S01 SNOW 国際標準のストリーム暗号 (ISO/IEC18033-4) は、MUGI、MULTI-S01、SNOW。 公開鍵暗号 RSA RSA: Rivest - Shamir - Adleman - 大きな素数の素因数分解が難しいという根拠に基づいた暗号方式。 楕円曲線暗号 楕円曲線状での離散対数問題に基づいた公開鍵暗号方式。 PSEC-KEM: Provably Secure Elliptic Curve encryption - Key Encapsulation Mechanisms - NTT。 ECDSA: Elliptic Curve Digital Signature Algorithm 国際標準の公開鍵暗号 (ISO/IEC18033-2) は、ACE-KEM, ECIES-KEM, PSEC-KEM, RSA-KEM, RSA-OAEP, HIME(R)。 参考: NTT 技術ジャーナル 2005.12 暗号アルゴリズムの使用期限 図: NISTが提示する暗号アルゴリズムの使用期限 『日経ビジネス』2018.07.23より 米国の国立標準技術研究所 (NIST) が提示する鍵の長さとその使用期限は、世界最高レベルのスーパーコンピューターを使っても解読に何十年もかかるかどうかが基準になっている。"
},
{
url: "/p/a9u6j7f/",
title: "秀丸: 日時挿入マクロ",
date: "2005-01-31T00:00:00Z",
body: "秀丸: 日時挿入マクロ カーソル位置に、2005-01-31 14:07:33 といった現在の日時を挿入するマクロです。 my_insert_datetime.mac //disableinvert; //disabledraw; call DayOfWeekStr; // 挿入用文字列を作成 #i = -1; #i = #i + 1; $str[#i] = year + \u0026#34;-\u0026#34; + month + \u0026#34;-\u0026#34; + day; #i = #i + 1; $str[#i] = year + \u0026#34;-\u0026#34; + month + \u0026#34;-\u0026#34; + day + \u0026#34; \u0026#34; + hour + \u0026#34;:\u0026#34; + minute; #i = #i + 1; $str[#i] = year + \u0026#34;-\u0026#34; + month + \u0026#34;-\u0026#34; + day + \u0026#34; \u0026#34; + hour + \u0026#34;:\u0026#34; + minute + \u0026#34;:\u0026#34; + second; #i = #i + 1; $str[#i] = year + \u0026#34;-\u0026#34; + month + \u0026#34;-\u0026#34; + day + \u0026#34; (\u0026#34; + $$return + \u0026#34;)\u0026#34;; #i = #i + 1; $str[#i] = year + \u0026#34;-\u0026#34; + month + \u0026#34;-\u0026#34; + day + \u0026#34; (\u0026#34; + $$return + \u0026#34;)\u0026#34; + \u0026#34; \u0026#34; + hour + \u0026#34;:\u0026#34; + minute; #i = #i + 1; $str[#i] = year + \u0026#34;-\u0026#34; + month + \u0026#34;-\u0026#34; + day + \u0026#34; (\u0026#34; + $$return + \u0026#34;)\u0026#34; + \u0026#34; \u0026#34; + hour + \u0026#34;:\u0026#34; + minute + \u0026#34;:\u0026#34; + second; // 表示用文字列を作成 #j = 0; while (#j \u0026lt;= #i) { $showstr[#j] = \u0026#34;\u0026amp;\u0026#34; + str(#j + 1) + \u0026#34; \u0026#34; + $str[#j]; #j = #j + 1; } menuarray $showstr, #i+1; #n = result; // result は 1 回しか参照できないので保存 (Ver 4.15 -- 2005/07/08) if (#n != 0) { insert $str[#n - 1]; } //enabledraw; //enableinvert; endmacro; // 曜日の文字列作成 DayOfWeekStr: ##n = dayofweeknum; if (##n == 0) { return \u0026#34;Sun\u0026#34;; } else if (##n == 1) { return \u0026#34;Mon\u0026#34;; } else if (##n == 2) { return \u0026#34;Tue\u0026#34;; } else if (##n == 3) { return \u0026#34;Wed\u0026#34;; } else if (##n == 4) { return \u0026#34;Thu\u0026#34;; } else if (##n == 5) { return \u0026#34;Fri\u0026#34;; } else if (##n == 6) { return \u0026#34;Sat\u0026#34;; } return \u0026#34;\u0026#34;;"
},
{
url: "/p/4r6ht6g/",
title: "ビリヤードのルール: 2 Ball Pool Carom",
date: "2005-01-08T00:00:00Z",
body: "ビリヤードのルール: 2 Ball Pool Carom ポケットビリヤードの台で遊ぶキャロムです。 配置・ブレイク 手玉はヘッドスポット、1 番をセンタースポット、2 番をフットスポットに配置。 ブレイクでセーフティは禁止。 勝敗 先に 20 点、40 点などの得点に達したほうが勝ち。 あるいは 10 回ずつ撞いて得点の多いほうが勝ち。 得点 2 つの的球に手玉を当てられれば 1 点。 1 つの的球をポケットしつつもう 1 つの的球に当てたら 2 点。 2 つの的球を同時にポケットしたら 3 点。 ファールした場合は 0 点。 ポケットされた的球の処理 残っている的球から距離が遠くなるように、ヘッドスポットかフットスポットのどちらかに置く。 テーブル上に残っている的球がヘッドスポットよりフットスポットに近い場合 → ヘッドスポットへ テーブル上に残っている的球がフットスポットよりヘッドスポットに近い場合 → フットスポットへ 2 つとも的球がポケットされた場合 → ヘッドスポットとフットスポットへ ただし、戻した的球が手玉と重なってしまう場合は、センタースポットを候補に入れて再選択。 ファール 手玉がどちらの的球にも当たらない場合はファール。 ノークッションファールはなし。 ファールした場合は 1 点マイナス。 ファールした場合は手球フリー。引球で当てられる位置におけば、もう一点は確実。 連続 3 ファールしても負けにはならない。"
},
{
url: "/p/i6iu7iu/",
title: "ビリヤードのルール: Bank Pool",
date: "2005-01-08T00:00:00Z",
body: "ビリヤードのルール: Bank Pool かならずバンクショットで的球をポケットするゲーム。 配置・ブレイク 15 個の的球を順番に関係なくラックする。 ブレイクで入った的球はバンクでなくても全部得点になる。 ブレイクでセーフティは禁止。 勝敗 8 つの的球を先に落としたほうが勝ち。 得点 コールショット（狙う球の番号とポケットを指定）でポケットしたら 1 点。 ファール 通常のファールは、ペナルティとして 1 点減点で、手玉フリー。 指定したポケット以外に的球が入ったらファールで、ペナルティとして 1 点減点。フットスポットへ的球を戻す。 的球が場外した場合はファールだがペナルティによる減点なし。 3 連続ファールしたらそのゲームは負けとなる。"
},
{
url: "/p/3939qxt/",
title: "かんたん料理シリーズ",
date: "2004-01-21T00:00:00Z",
body: "かんたん料理シリーズ 鶏肉の照り焼き 『会社の星』で簡単な照り焼きの作り方やってたのでφ(･ｪ･o)~メモメモ たれの材料（甘辛しょうゆ） しょうゆ 1カップ 酒 1/2カップ 砂糖 100g 作り方 鶏肉を茹でて、ひと口大にに切る。 フライパンで焼き目をつける感じで焼く。 焼いているときにたれをかける。 もやしとほうれん草と挽肉のピリ辛ミソあえ（一人分） （おおきめのお皿が必要） 材料 ほうれん草 － １束 もやし － ５０ｇ Ａ 挽肉 － ５０ｇ サラダ油 － 小さじ１ みそ － 小さじ１ 豆板醤 － 小さじ１ さとう － 小さじ１ 作り方 ほうれん草を５ｃｍくらいに切って皿に入れる もやしを洗って皿に入れる Ａを混ぜて皿に入れる レンジで４分加熱 混ぜてできあがり！ 簡単たまご野菜丼 材料 A 卵 １個 しょうゆ 小さじ１ 酒 小さじ１ 豚挽き肉 80g 野菜少し （ニンジン1/2の薄切りとか） 作り方 豚と野菜を炒める A を入れて半熟でご飯にかける さばとねぎの味噌煮 材料 さば １切れ 長ねぎ １本 煮汁 水 １カップ みそ 大さじ１ みりん 1／4カップ 作り方 ねぎを５ｃｍに切って軽く焦げるまでやく なべに煮汁を入れて 1 と さばをいれて15分くらい煮込む（途中で煮汁をかけながら） 煮汁が減ってきてとろとろになったら火を止めて完成 ※さばがないのでブリで作ったらあんましおいしくなかった(-_- 電子レンジで肉詰めピーマン 材料 たまねぎ 1/2 卵 1個 ひき肉 100g ピーマン 4個 牛乳 大さじ2 ケチャップ 作り方 たまねぎをみじん切りにしてバターで炒める パン粉に牛乳をかける ひき肉と卵と 1) と 2) を混ぜる ピーマンをたて半分に切ってたねを詰める ラップをかけてレンジで3分～4分加熱 ケチャップをかけていただきま～す！ にんたまスープ（４人分） 材料 にんじん ･･･ １本 たまねぎ ･･･ 1/2 個 キャベツ ･･･ 1/8 個 コンソメスープの素 ･･･ 1.5個 作り方 野菜を切る にんじんはチロルチョコサイズ。 たまねぎは幅 5mm の千切り。 水４カップとコンソメスープの素を入れて野菜を煮る。中火で20分。 ロールキャベツ（2人分） 材料 キャベツの葉 ･･･ ４枚 固形スープのもと ･･･ 1/2 個 ひき肉だね 合い挽き肉 ･･･ 100g キャベツの芯のみじん切り たまねぎ ･･･ 小 1/2 個 パン粉 ･･･ 1/8 カップ 塩 ･･･ 少々 トマトソース トマトピューレ ･･･ １カップ （ケチャップでも） 砂糖、塩、こしょう ･･･ 少々 作り方 キャベツを茹でる、芯はみじん切りにする ひき肉だねを混ぜて、ゆでたキャベツの葉で包む なべに水１カップとスープの元をほぐして入れる 強火にして蓋をする → 煮立ったら中火にして 20 分ゆでる。 トマトソースをかけ、再び５分茹でる。 「小さなフライパンでできるミニフレンチトースト」 材料 食パン ･･･ １枚 卵 ･･･ １個 牛乳 ･･･ 1/2 カップ 砂糖 ･･･ 大さじ１ バター ･･･ 少し 作り方 食パンを４隅から対角線上に４等分に切る。 ボールで卵、牛乳、砂糖を混ぜる。 フライパンにバターを溶かす。 食パンを２切れボールに浸して軽く焦げ目がつくまで焼く。 ブロッコリーとエビのたまご炒め 材料 ブロッコリー ･･･ １束 エビ ･･･ 適量 卵 ･･･ ３個 しょうゆ ･･･ 小さじ１ 砂糖 ･･･ 大さじ１ 作り方 ブロッコリーの茎の部分は下から包丁で切り込みを入れてむく ブロッコリーとエビを塩をいれて茹でる 卵としょうゆと砂糖を混ぜて、そこにブロッコリーとエビを入れる。 全部いっしょに炒める（卵があんましぼろぼろにならないように）。 かんたんホワイトシチュー 材料 にんじん、たまねぎ、じゃがいも（野菜は少なめでOK） 固形スープの元 ･･･ １／２個 ホワイトソース バター ･･･ 大さじ３ 小麦粉 ･･･ 大さじ４ 牛乳 ･･･ １カップ 塩コショウ ･･･ 少々 作り方 たまねぎをみじん切りにして炒める （中途半端な大きさで切るとアクがすくいにくくなる） にんじん、じゃがいもの順でいためる （肉じゃがよりは小さめに切る） 水をひたひたに入れて固形スープの元を入れて蓋をして沸騰させる。 沸騰したら１回アクをすくい20分くらい煮込む ホワイトソースを入れてやさしく混ぜる。 焦げないようにちょっとだけ煮て完成！ ホワイトソースは、ステップ 4 で煮込んでいる間に作る。 鍋にバターを入れて小麦粉を炒める（きつね色にならないように） とろみを保ちながら牛乳を少しずつ混ぜながら入れる 塩コショウを振る 泡が細かくなったら火を止める チンゲンサイのピリカラ丼（1,2人分） 材料 チンゲンサイ ･･･ １束 豚挽き肉 ･･･ 100g 卵 ･･･ １個（２人分なら２個） 調味料 トウバンジャン ･･･ 小さじ１ しょうゆ ･･･ 大さじ１ 酒 ･･･ 大さじ１ 砂糖 … 小さじ１ 作り方 チンゲンサイは一枚ずつはがし、茎と葉の部分に切り分ける。 根元の砂をちゃんと洗い流す。 葉は２等分、茎は３等分くらいに切る。 茎の部分をレンジで１分加熱するとやわらかくなる。 サラダ油大さじ１／２、中火でひき肉を炒める。 チンゲンサイの茎の部分を入れて１分くらい炒めて、葉っぱも入れる。 しんなりしてきたら調味料を加える。 卵をいれて蓋をして弱火で好みの硬さになるまで蒸し煮する。 かんたん肉じゃが（3人分） 材料 じゃがいもｘ中3個（メイクイーン） たまねぎｘ１個 にんじんｘ１本（にんじんはなくても可） 細切れ豚肉100～200ｇくらい 調味料 砂糖 ･･･ 大さじ１ みりん ･･･ 大さじ１ しょうゆ ･･･ 大さじ２（濃い口なら３） 日本酒 ･･･ 大さじ２ 作り方 たまねぎを串形に切る。 じゃがいもはマッチ箱くらいの大きさに切る（半分に切って3等分くらい）。 切ったじゃがいもは水に浸しておく。 にんじんは小さ目のかまぼこ型に切る。 調味料と細切れ肉を鍋に入れてさっと煮る（アクが出たら取る）。 野菜を全部入れ、水をひたひたになるくらいまで入れる。 水が減ってくるまで３０分くらい煮込む。 厚焼き卵（2人分） 材料 卵 ･･･ ３個 砂糖 ･･･ 大さじ２ 塩 ･･･ ほんの少し みりん ･･･ 大さじ２ しょうゆ ･･･ 小さじ１ 作り方 材料を全部混ぜる。 卵焼きフライパンに油を薄く塗る。 １／３入れて向こうから巻く。 向こうにずらして、空いたとこに油を塗って残り半分を入れる。 卵の下に流しいれてまた向こうから巻く。 ４を繰り返す。 にんじんともやしのケチャップソース炒め（1人前） 材料 にんじん ･･･ １／２本 もやし ･･･ １／３袋 ソース ケチャップ ･･･ 大さじ１ ソース ･･･ 大さじ１ 塩こしょう ･･･ 少々 作り方 にんじんを幅１cm、厚さ１ミリくらいの短冊切りにする。 材料を油大さじ１で３分炒める。 ソースを入れてさらに５分炒める。 塩こしょう振ってできあがり。 ぶりの照り焼き 材料 ぶり ･･･ １～２切れ 下味 酒 しょうゆ たれ 砂糖 ･･･ 小さじ１ みりん ･･･ 大さじ１ しょうゆ ･･･ 大さじ１ 作り方 ぶりを下味につける 表から焼き、すこし焼けたら裏返す。 酒を入れてふたをしめて弱火で２～３分蒸し焼きにする。 たれを入れてちょっと火を強めてたれがなくなってくるまで焼く。 味噌ダレの野菜炒め 材料 味噌ダレ 味噌 ･･･ 大さじ３ 砂糖 ･･･ 大さじ１ 酒 ･･･ 大さじ２ 作り方 普通に野菜を炒める。 味噌ダレを加えて味噌が焦げるちょっと前に火を止める。 酢豚風やさいだけ 材料 野菜 にんじん 1/2本 干ししいたけ ３個 ピーマン １個 たまねぎ １個 合わせ調味料 水 カップ１ ケチャップ 大さじ１ 醤油 大さじ２ 酢 大さじ３ 砂糖 大さじ５ 塩 小さじ 1/2 水溶き片栗粉 片栗粉 大さじ１ 水 大さじ２ 作り方 にんじんを切って下ゆでしておく。 その間に玉ねぎを 2cm 角に切る。ピーマンも切る。合わせ調味料を作る。 にんじん、たまねぎ、ピーマンの順に炒める。 調味料を入れて強火で煮立たせる。 片栗粉を回しいれてとろみをつける。 すぐに皿に盛る。"
},
{
url: "/p/44o4a9p/",
title: "IETF によるプロトコル標準化の流れ",
date: "2003-10-01T00:00:00Z",
body: "IETF によるプロトコル標準化の流れ プロトタイプが普及する 独自バージョンが作られるようになる IETF (Internet Engineering Task Force) の援助で Working group が作られる Working group は「インターネットドラフト」としてプロトコルを文書化する IETF の IESG (Internet Engineering Steering Group) に提出する 実験期間を経て、IESG によって RFC 番号が割り当てられ、修正などをして「実験 RFC」として公表される 実際の運用によるテストを経て、IESG が「提案標準」として認定する IESG が「ドラフト標準」に推薦する プロトコルに STD 番号が割り当てられ、RFC に加えて STD となる 上記の流れで最低でも 10 ヵ月以上はかかる。"
},
{
url: "/p/m3p8hh6/",
title: "数値計算系のプログラムメモ",
date: "2001-10-20T00:00:00Z",
body: "数値計算系のプログラムメモ n が 2 のべき乗か判定する long powerof2(long n) { return (n \u0026gt; 0) \u0026amp;\u0026amp; ((n \u0026amp; (n - 1)) == 0); }"
},
{
url: "/p/uyp4geh/",
title: "画像処理メモ: 画像の 2 値化の閾値を求める方法いろいろ",
date: "2001-05-25T00:00:00Z",
body: "画像処理メモ: 画像の 2 値化の閾値を求める方法いろいろ 平均法（平均を取るだけ）← 使えない Pタイル法（物体・背景の面積が分かっている場合）← 自動ではない モード法（極小を求める）← グラフを滑らかにする必要がある 判別分析法（クラス間分散が最大となるところで２値化する）← Good"
},
{
url: "/p/8zhwcq6/",
title: "C/C++ のメモ",
date: "2001-05-11T00:00:00Z",
body: "C/C++ のメモ"
},
{
url: "/p/tgt7it6/",
title: "C/C++サンプル: TCP クライアント／サーバー",
date: "2001-05-11T00:00:00Z",
body: "C/C++サンプル: TCP クライアント／サーバー むかーし書いたやつ。 だっさーいコードが残ってるかも (^^; CTcpClient / CTcpServer ライブラリ CTcpClient.h / CTcpClient.cpp CTcpServer.h / CTcpServer.cpp socket.h Makefile 使用例 SimpleTcpServer.cpp SimpleTcpClient.cpp Makefile"
},
{
url: "/p/xwfr3cm/",
title: "C/C++サンプル: TCP ポートスキャナー",
date: "2001-05-11T00:00:00Z",
body: "C/C++サンプル: TCP ポートスキャナー むかーし書いたコードです。 だっさーいコードが残ってるかも (^^; portscan.cpp"
},
{
url: "/p/g9q6kyf/",
title: "C/C++サンプル: エンディアンの判定",
date: "2001-05-11T00:00:00Z",
body: "C/C++サンプル: エンディアンの判定 使用している PC のホストバイトオーダーが、ビッグエンディアンかリトルエンディアンかを調べるプログラムです。 endian.cpp #include \u0026lt;iostream\u0026gt;using namespace std; int main() { union { char c[2]; short s; } u; u.s = 0x0102; if (u.c[0] == 0x01 \u0026amp;\u0026amp; u.c[1] == 0x02) cout \u0026lt;\u0026lt; \u0026#34;Big-endian\u0026#34; \u0026lt;\u0026lt; endl; else if (u.c[0] == 0x02 \u0026amp;\u0026amp; u.c[1] == 0x01) cout \u0026lt;\u0026lt; \u0026#34;Little-endian\u0026#34; \u0026lt;\u0026lt; endl; else cout \u0026lt;\u0026lt; \u0026#34;Unknown\u0026#34; \u0026lt;\u0026lt; endl; return 0; }"
},
{
url: "/search/data.js",
title: "",
date: "0001-01-01T00:00:00Z",
body: ""
},
{
url: "/p/oi66eim/",
title: "TV規格: DVBメモ",
date: "0001-01-01T00:00:00Z",
body: "TV規格: DVBメモ DVB について DVB (Digital Video Broadcasting) はヨーロッパのデジタル放送規格。標準化団体名でもある。DVB には以下のような種類がある。 DVB-T (Terrestrial) \u0026ndash; 地上デジタル放送の規格 DVB-S (Satellite) \u0026ndash; 衛星放送の規格 DVB-C (Cable) \u0026ndash; CATV の規格 ISDB (Integrated Services Digital Broadcasting) は日本、ブラジル向けのデジタル放送規格。ちなみに ARIB (Association of Radio Industries and Broadcast): 社団法人電波産業会というのは通信・放送分野の研究、標準化などを行う団体名であって規格の名前ではない。ISDB には以下のような種類がある。 ISDB-T (Terrestrial) \u0026ndash; 地上デジタル放送の規格 ISDB-S (Satellite) \u0026ndash; 衛星放送の規格 ISDB-TSB (Terrestrial for Sound Broadcasting) \u0026ndash; 地上デジタルラジオ放送の規格 DVB の資料 EPG に関することを知りたかったら、DVB SI 系の資料を読むと良い。まずは、DVB の Web サイトにある、DVB SI の 2 冊の Bluebook (PDF) から読み始めると楽（150ページくらい）。Bluebook はメアド登録しなくてもダウンロードできる。 DVB - Digital Video Broadcasting [Standards \u0026amp; Technology] → [Standards \u0026amp; BlueBooks] → DVB SI 日本、ブラジル向けのデジタル放送規格 ISDB も DVB をもとに考えられているので、DVB の資料を先に読んでおくと理解しやすい。 service, programme, event の違い service \u0026ndash; DVB で定義 event, programme \u0026ndash; MPEG2 で定義 broadcaster （放送局）が 1 つの TV チャンネルとして垂れ流している一連の放送を service という。つまり TV チャンネルと考えてよい。service は映像、音声、字幕などの Components (ES: Elementary Stream) をまとめたものとして構成されている。 programme は、MPEG-2 のストリームを分けるための概念で、TV のチャンネルの考え方に近い。ただし、MPEG-2 では TV に特化したものは定義していないので、DVB で TV のチャンネルに相当する service というものを定義している。service には TV のチャンネル名などが含まれる。 service 自体には時間の概念はなく、延々と続く映像や音声の ES を垂れ流しているだけ。ここに、時間の概念を入れて、1 つの番組として、開始時刻や長さを定義したものが event。複数の event を集めたものを service と考えるよりは、1 つの service を event という概念で区切ったものが番組であると考える方が正しい。 1 つの transponder（あるいは channel）で複数の service が multiplex （多重化）されて、同時に配信されている。※ここでいう channel は TV のチャンネルではなく、チャネル。ケーブル TV や地上波での 1 つの配信システムを表している。 Network ID について DVB Services - identifiers http://www.dvbservices.com/identifiers/network_id http://www.dvbservices.com/identifiers/original_network_id ここが分かりやすい http://www.interactivetvweb.org/tutorials/dtv_intro/dtv_intro 階層構造はこんなイメージ。 Network（Cable とか Satellite とかのシステムを表す。1つ以上の Transport stream を流せる） Transport stream (MPEG-2 のストリーム。複数の Service を含む） Service (TV channel) Event (TV show) Elementary stream TS パケット MPEG-2 の TS (Transport Stream) は、TS パケットという単位でいろんなデータが多重化されて配信されている（複数のチャンネルの映像や音声、字幕、番組情報、時刻データなど）。TS パケットは 188byte 固定長。 TS パケット (188byte) = TS ヘッダ (4byte) + ペイロード (184byte) TS パケットは、Audio/Video/Teletext などのデータを構成する PES (Packetized Elementary Stream) の一部であったり、SI (Service Information) や BML データを構成する section data の一部であったりする。 ある TS パケットが、これらのどのデータの一部であるかを判別するために、TS ヘッダの中に 13bit の PID (PacketID) が入っている。デコーダはこの PID を見て、TS ストリームを多重分離 (demultiplex) することができる。例えば、SI の PAT 情報を構成する TS パケットの場合、PID は 0x0000 が入っている。 SI (Service Information) tables DVB の SI (Service Information) は、ISO/IEC 13818-1 (MPEG-2) で定義されている PSI のテーブルに加え、service （チャンネル）情報や event （番組）情報を示す各種テーブルで構成されている。 PSI (Program Specific Information) のテーブル PSI は、受信機が多重化された multiplex データ（MPEG-2 TS ストリーム）を demultiplex するための情報で、MPEG-2 にて定義されている。 ※複数の service を 1 つの channel、transponder で多重送信することを multiplex という。 PSI には下記の 4 つのテーブルがある。 PAT: Program Association Table MPEG-2 の TS ストリームで伝送されるプログラムを管理する情報。各 service（チャンネル）における PMT の PID (PacketID) を示す（正確に言えば、PMT の一部のデータである TS パケットの PID）。 その TS で流している service の数だけ PID (PacketID) を含んでいる（つまり PMT もチャンネルの数だけある）。 デコーダは、この PAT の情報を起点として各 service（チャンネル）ごとの PMT パケットの PID を知るので、PAT の PID (PacketID) は 0x0000 になっている。 NIT: Network Information Table MPEG-2 の TS ストリームを配信するのに使用されている physical network の情報を示す。 MPEG-2 の PSI では NIT の構造は定義していないので、各放送方式などで独自に定義する必要がある。 PMT: Program Map Table 各 service を構成する ES: Elementary Stream（映像、音声ストリームなど）の位置を示す。チャンネルの数だけ PMT が存在する。 その service（チャンネル）が Video、Audio、Teletext の 3 つの ES で構成されているなら、PMT の中に PID (PacketID) が 3 つ含まれる。 PMT データ自体の TS パケットの PID は、PAT 内で指定されるので、PAT や CAT パケットの PID とは違って固定値ではない。 CAT: Conditional Access Table CA システムに関する情報。EMM stream (Entitlement Management Message) の位置を示す。EMM はそれぞれの CA システムに特化した情報であり、例えば日本のデジタル T V では、B-CAS カードの契約情報や暗号解除するための鍵情報などが含まれている。EMM は B-CAS カードごとに個別に送信され、情報はカード内に保存される。 PAT と同じく、TS パケットにおいて最初の段階で取得しないといけない情報なので、CAT には固定の PID (PacketID) 0x0001 が割り当てられている。 DVB 独自のテーブル DVB の SI データには、MPEG-2 で定義されている PSI の 4 つのテーブルの他に、以下の 9 種類のテーブルが含まれている。これらのテーブルは、チャンネル情報、番組情報、時刻情報などを示している。 BAT: Bouquet Association Table bouquet （ブーケ）情報を示す。bouquet を構成する service のリストなど。異なるネットワークで送信された service も 1 つの bouquet にまとめられ得る。 SDT: Service Description Table チャンネル情報（service 情報）。チャンネル名、放送局の識別子など。 EIT: Event Information Table 番組情報（event 情報）。番組名、番組の開始時刻、番組長など。SI のテーブルのうち、この EIT だけはスクランブルがかかることがある。 RST: Running Status Table 番組の現在の進行状況。 TDT: Time and Date Table 現在時刻の情報。 TOT: Time Offset Table ローカルタイム（現地時間）に関する情報。 ST: Stuffing Table 現在のセクションを無効にする。データ境界を合わせるために使用。 SIT: Selection Information Table DIT: Discontinuity Information Table SED と EED 参考資料（規格） https://www.dvb.org/standards DVB SI [DVB BlueBook A038] Specification for Service Information (SI) in DVB system https://www.dvb.org/resources/public/standards/a038_dvb-si_spec.pdf DVB SI [DVB BlueBook A005] Guidelines on implementation and usage of Service Information (SI) https://www.dvb.org/resources/public/standards/a005_dvb-si_impl_guide.pdf SED と EED の定義 SED (Short Event Descript) と EED (Extended Event Descriptor) は、SI データの EIT-section で流される (EIT: Event Information Table) の一種です。 SED には「番組名とその短い説明」が入り、EED はそれを補足する形で、「出演者: ○○○」「あらすじ: ○○○」みたいな、いわゆる Key and Value のような形で詳細説明が入ってます。 以下、DVB BlueBook A005 より 4.2.4.10 Short event descriptor This descriptor is used to transmit the name and a short text description for an event. A language code is transmitted in order to indicate in which language the title and the text are written. Transmission of this descriptor is mandatory, unless there is a time_shifted_event_descriptor, in which case the descriptor is not allowed. This descriptor is allowed more than once in the EIT event loop for different languages. Thus it is not allowed to have more than one short_event_descriptor with the same language code. 4.2.4.5 Extended event descriptor This descriptor is used to transmit a bigger amount of textual information for an event than is possible with the short_event_descriptor. The information in extended event descriptors supplements that given in a short event descriptor. A language code is transmitted in order to indicate in which language the text is written. More than one extended_event_descriptor is allowed in the EIT event loop, for transmitting more data than one descriptor can contain (255 bytes excluding header), and for different languages. The last_descriptor field specifies the number of the last extended_event_descriptor for a specific language. If there is a time_shifted_event_descriptor, this descriptor is not allowed. Transmission of this descriptor is optional. SED と EED のテーブルのフォーマット 以下、DVB BlueBook A038 より。 6.2.37 Short event descriptor short_event_descriptor(){ descriptor_tag descriptor_length ISO_639_language_code event_name_length for (i=0;i\u0026lt;event_name_length;i++){ event_name_char } text_length for (i=0;i\u0026lt;text_length;i++){ text_char } } 6.2.15 Extended event descripto extended_event_descriptor(){ descriptor_tag descriptor_length descriptor_number last_descriptor_number ISO_639_language_code length_of_items for ( i=0;i\u0026lt;N;i++){ item_description_length for (j=0;j\u0026lt;N;j++){ item_description_char } item_length for (j=0;j\u0026lt;N;j++){ item_char } } text_length for (i=0;i\u0026lt;N;i++){ text_char } } MPEG-2 TS を多重分離する流れの概要 ES（映像、音声など）を多重分離する流れ PAT (PID=0x0000) の TS パケットを受信 （TS パケットを結合して PAT を復元） PAT の内容を見て、PMT の PID を取得（チャンネル数だけある） PMT の内容を見て、各 ES の PID を取得（ES の数だけある） ES の TS パケットを結合して再生 EIT（番組情報テーブル）を多重分離する流れ EIT (PID=0x0012) の TS パケットを受信。 （TS パケットを結合して EIT を復元） EIT の内容がそのチャンネルの番組情報。 他の SI のテーブル、例えば SDT (PID=0x0011)、RST (PID=0x0013)、TDT/TOT (PID=0x0014) なども同様に多重分離される。 DVB 標準一覧 図: 出典: 映像情報メディア学会誌 Vol.60, No. 5 (2006) ディジタル地上波マルチプレックスの例 図: 出典: 映像情報メディア学会誌 Vol.60, No. 5 (2006) 各サービスをどのような比率で送信するかは、欧州各国政府が決める。"
},
{
url: "/p/uqhbb5p/",
title: "HMAC-SHA256 コードを生成する",
date: "0001-01-01T00:00:00Z",
body: "HMAC-SHA256 コードを生成する Python で HMAC-SHA256 を生成する 下記の siggen.py スクリプトは、コマンドライン引数で渡された「秘密鍵テキスト」と「メッセージ」をもとに HMAC (Hash-based Message Authentication Code) 署名を生成します。 siggen.py import sys import hashlib import hmac def usage(): print(\u0026#39;python \u0026#39; + sys.argv[0] + \u0026#39; \u0026lt;key\u0026gt; \u0026lt;message\u0026gt;\u0026#39;) sys.exit(-1) if __name__ == \u0026#39;__main__\u0026#39;: if len(sys.argv) \u0026lt; 3: usage() key = sys.argv[1] msg = sys.argv[2] sig = hmac.new(key.encode(\u0026#39;ascii\u0026#39;), msg.encode(\u0026#39;ascii\u0026#39;), hashlib.sha256) print(sig.hexdigest()) 使用例 $ python siggen.py \u0026#39;SecretKey\u0026#39; \u0026#39;YourMessage\u0026#39; 8aff2951003c218bd26ee43c99e30527a0c30e06042008a60935ef1ab28891ec ここでは、SHA256 ハッシュ関数を使用していますが (HMAC-SHA256)、hashlib.sha256 の部分を変更すれば、他のハッシュ関数を適用することができます。 openssl コマンドで HMAC-SHA256 を生成する Linux や macOS などの、openssl コマンドを使用できる環境では、下記のようにして簡単に HMAC-SHA256 を求めることができます。 $ echo -n \u0026#39;YourMessage\u0026#39; | openssl dgst -sha256 -hmac \u0026#39;SecretKey\u0026#39; 8aff2951003c218bd26ee43c99e30527a0c30e06042008a60935ef1ab28891ec おまけ（ランダムで秘密鍵テキストを生成するスクリプト） 下記の random-password.py スクリプトは、HMAC 計算に使用可能な 20 桁のランダムな文字列（秘密鍵）を生成します。 上記の siggen.py スクリプトに入力する秘密鍵として使用することができます。 ramdom-password.py from random import randint CHARS = \u0026#39;0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ#$-=?@[]_\u0026#39; password = \u0026#39;\u0026#39; for i in range(20): password += CHARS[randint(0, len(CHARS)-1)] print(password) 使用例 $ python random-password.py GAFJ[XHrAClx_#ZPfE$O"
},
{
url: "/p/qm9cfjn/",
title: "パワーポイントのおすすめ設定",
date: "0001-01-01T00:00:00Z",
body: "パワーポイントのおすすめ設定 PowerPoint のおすすめのフォント PowerPoint のフォントは、Windows Vista 以降であれば、 和文: メイリオ 欧文: Segoe UI で統一すると、そこそこ見た目が整います。 スライドマスタでフォントを設定する手順は下記の通りです。 メニューの [表示] =\u0026gt; [スライドマスター] を選択。 スライドマスタータブの [フォント] =\u0026gt; [新しいテーマのフォントパターンの作成] を選択。 英数字用のフォントで「Segoe UI」、日本語文字用のフォントで「メイリオ」を選択。 ちなみに、メイリオの代わりに Meiryo UI を使用すると、文字幅が若干縮まります。 Meiryo UI は Windows 7 で標準搭載されたフォントで、Windows のリボン UI 上のテキストを狭いスペースで表示できるように最適化されたものらしいです。 通常は「メイリオ」の方を使用しておけばよいでしょう。 もし、テキストをたくさん含めなければいけない資料を作らないといけなくなった場合は、「Meiryo UI」の方を使ってみるとよいかもしれません。 参考: Windows デベロッパーセンター ─ フォント スライドの縦横比率は 16:9 スライドの縦横比率は 16:9 が主流です。 PowerPoint 2013 からはデフォルトで 16:9 になってます。 メニューの [表示] =\u0026gt; [スライドマスター] を選択。 スライドマスタータブの [ページ設定] を選択。 スライドのサイズ指定で 16:9 を選択。 PowerPoint ファイルを共有するときはフォントを埋め込む 異なる環境で PowerPoint ファイル開いたときに、設定したフォントで正しく描画されるようにするには、PowerPoint ファイルにフォントを埋め込んでおく必要があります。 メニューから [ファイル] =\u0026gt; [オプション] を選択。 [保存] タブの「ファイルにフォントを埋め込む」にチェックを入れる。サブ項目で「すべての文字を埋め込む」にチェックを入れる。"
},
{
url: "/p/8rhjqk4/",
title: "ビリヤードの雑多メモ",
date: "0001-01-01T00:00:00Z",
body: "ビリヤードの雑多メモ センターショットばかりやるのはなぜダメか？ 実はまっすぐ見えていないのに、たまたま視線のズレとストロークのズレが打ち消しあってまっすぐ付けているかのように勘違いしてしまうことがある。フリのある球も適度に練習するべき。 手球をストップさせるための力加減の許容範囲が広いため、力加減を調整する撞き方を身につけにくい。フリがある球は手球のスピードや回転によって狙いが変わるが、センターショットだけやっているとこの感覚を覚えられない。 ダブルイマジナリーボールで狙う方法 通常イマジナリーボールは、ポケットから見て的球の後ろ側に作りますが、その反対側（ポケット側）にも作るようにすると、的球の転がりイメージしやすくなります。"
},
{
url: "/p/o7mkmjt/",
title: "ライフハック: 掃除テクニック",
date: "0001-01-01T00:00:00Z",
body: "ライフハック: 掃除テクニック 台所のシンクは大根の切れ端 or レモンでこするときれいになる。 ガスコンロまわりの油汚れ 塩を振りまいてレモンでこするときれいになる。 軽く湿らせたメラミンスポンジでこすると、油のベトベトはすっきり取れる（ただし、メラミンスポンジは減りは早い^^;）"
},
{
url: "/p/pjsq9sp/",
title: "心に響く言葉とか",
date: "0001-01-01T00:00:00Z",
body: "心に響く言葉とか 実装しなくなったら、エンジニアとしての人生はそこで終了ですよ ── マイクロソフト元社長 他社製品を見たら改善を考えるより、別のアプローチを考えろ ── 映画『スティーブ・ジョブズ』 ミスタードリラーの主人公ホリ・ススムの父親は、ディグダグの主人公ヒロ・タイゾウ ── 『レトロゲーム忍法帖』忍者増田 プログラマーが「できない」と言った瞬間にそのアイディアは死ぬんです。だから「できない」と言うんだったら、「ここまでならできるけど」と言えよ ── 任天堂 岩田聡 aibo の開発では議論が白熱しても、そこに aibo がいると、なぜだかみんな笑顔になれた ── aibo 開発者"
},
{
url: "/p/zwgs69e/",
title: "見たドラマの記録",
date: "0001-01-01T00:00:00Z",
body: "見たドラマの記録 白い春 （全11回） ★★★★★ 5/5点。 内容というより阿部さんがいい味だしてるなぁ。 亡くなった妻や子供のために必死になるところとか、 お金あんましないのにポーンとあげちゃうところとか、 自分より人のことを大切にして生きてるのが素敵です。 24 TWENTY FOUR シーズンⅥ （全24話） ★★★★☆ 4/5点。 テロの核攻撃を阻止するために悪戦苦闘する話かと思ってたら、 いつのまにか中国との基板争奪戦になってたという話。 CTU の作戦よりも、モリスとクロエの微妙な関係のほうが気になりました。 しかし、ジャックの撃った弾が確実に敵に当たるわ当たるわ。 無敵かいな。 銭ゲバ ★★★★★ 5/5点。 やっぱり貧乏ものドラマは面白い。 主人公の松山ケンイチさんよりも、椎名桔平さんの方がいい味出してるなぁ。 「お～こわいこわい」っていう、人をおちょくるような感じとか大好き。 最後まで何を考えてるのか分かんないのもいい雰囲気出してます。 ドラマ最終回の終わり方もまさに銭ゲバって感じですね。 プリズンブレイク シーズン3 ★★★★★ 5/5点。 刑務所ソーナのどろどろした雰囲気が生々しくて面白い。 それぞれのキャラクタがみんな魅力的で、どのキャラクタのシーンになっても見ていて飽きないです。 中でもティーバッグが好きだなぁ。 ブラッディ・マンデイ ★★★★☆ 4/5点。 天才ハッカーがテロリストのテロをハッキングで阻止するドラマ。 Microsoft がサポートしているということで、 コマンドラインでの入力も本物っぽく見せてるところがすごい。 技術指導者が Python 好きなのか、Python ばっかり使ってたｗ Bluetooth を数秒で乗っ取って、敵のボスの声を音声合成で作成して 偽の指示を出すシーンはバビった。どんだけ天才やねんｗ スクラップ・ティーチャー ★★★★★ 5/5点。 毎回各教師が問題を起こしていくのだけれど、 みんないい方向に解決していく。 そして最終回はすべてがうまくいってハッピーエンドするところは 見ていて気持ちがよいです。 生徒を大切にする気持ちをまっすぐぶつける杉先生の姿は 全国の先生に見てもらいたいくらいです。 結婚できない男 ★★★★★ 5/5点。 トリックと同じ感じで阿部寛さんがいい味だしてます。 素直でないと思ったらたまに素直で、 自分のポリシーだけは曲げない。 そんなキャラクターは何回見ても飽きないです。 ライアー・ゲーム ★★★★☆ 4/5点。 嘘ついて騙し合ってお金を稼ぐドラマ。 演出はちょっとちゃっちいけど、 人を信じることが正しいんだとみんなが最後に団結するところがよかったな。 ヨコヤが泣き崩れるシーンも好き。 僕と彼女と彼女の生きる道（全12話） ★★★★★ 5/5点。 いきなり離婚から始まるところが面白い。 いきなり子供に八つ当たりするところが面白い。 自分の周りの環境の変化とともに、 そんな生き方が少しずつ代わっていくところが面白い。"
},
{
url: "/p/okpz4jx/",
title: "見た映画の記録",
date: "0001-01-01T00:00:00Z",
body: "見た映画の記録 E.T. 20 周年アニバーサリー特別版 （2002年 アメリカ） ★★★☆☆ 3/5点。 今見るとなんだか平凡な宇宙人映画。 警察に囲まれたときに、自転車で飛んで行ってしまうシーンは、 当時の子供たちに夢を与えたんだろうなぁ。 パイレーツオブカリビアン デッドマンズ・チェスト （2006年 アメリカ） ★★★★★ 5/5点。 パイレーツオブカリビアンの2作目（の前編）。 呪いで死ねなくなって、顔にフジツボが付いてしまってたり、 顔がタコだったり気持ち悪いのがいっぱい出てくるところが面白い。 エリザベスは男装してたほうが凛々しくてかわいいです。 20世紀少年 ＜最終章＞ ぼくらの旗 ★★★★★ 5/5点。 最終章が一番面白かった。 映画の終わりに歌をもってくると、 いい感じになっちゃうからちょっとずるい。 ケンジは体がボロボロのくせに、 ロボットのはしごはものすごくしっかり登るのが不思議でした。 あんなの絶対振り落とされるよ。 パイレーツ・オブ・カリビアン 呪われた海賊たち （2003年 アメリカ） ★★★★☆ 4/5点。 おちゃめなジョニー・デップがかわいい。 この映画に出てくる他の海賊たちも極悪非道という感じはしないですね。 のろわれたメダルを全部集めたらしいけど、あれだけ大量のメダルを どうやって探したんだろ？ マチルダ （1996年 アメリカ） ★★☆☆☆ 2/5点。 ひどい家族、ひどい校長先生に囲まれた環境で 幼いマチルダがなぜか超能力を身につけ、校長先生をこらしめる話。 子供向けっぽいストーリーでした。 マチルダの天才ぶりや、超能力がいまいち活かしきれていない感じ。 リロ＆スティッチ （2002年 アメリカ） ★★☆☆☆ 2/5点。 物を破壊しまくるロボットをペットとして飼う話。 もともとかわいくないスティッチが、 家族がほしくなってくところがかわいい。 努力しないで出世する方法 （1967年 アメリカ） ★★☆☆☆ 2/5点。 本に書いてある通りに行動して大成功する話。 あれだけ口が達者でどんどんアプローチしていけば、 普通に仕事していても成功しそうな気がします。。 どう見ても努力してます。 この映画はミュージカル風になっていて、まじめなストーリーではないです。 雀魔アカギ （1997年 日本） ★★★★☆ 4/5点。 闘牌伝アカギの続編。 第一作ほどマージャンシーンは多くないですが、 浦部のキャラとか楽しめます。 偽アカギの素人っぽさが面白いです。 あの素人っぽさをわざとやっているとしたら大したもんです。 ボーン・アイデンティティ （2002年 アメリカ） ★★★★☆ 4/5点。 ボーンシリーズ全3作中の1作目。 ボーンが素早く敵を倒してゆくシーンはプロっぽくてかっこいいです。 あらためて見て見ると、明らかに次回作があることを匂わせてますね。 ターミネーター4 ★★★★★ 5/5点。 3はひどかったけど、今回の4は素晴らしかったです。 カメラが揺れすぎでちょっと目が疲れたけど、迫力満点の映像ばっかりでした。 いろんなタイプのマシンは出てくるし、CGも本物っぽいし、前作までとはスケールが違います。 モトターミネーターがかっこよかったです。 シュワちゃんは今回は完全におまけキャラでした。 それにしてもジョンコナー渋くなりすぎ！毎回濃くなってくよ。顔が。 七人の侍 （1954年 日本） ★★★☆☆ 3/5点。 日本映画の代表作と言われている黒澤明作品。 農民たちが野武士たちと戦うという単純明快なストーリーですが、 昔の生活が非常にリアルに描画されてます。昔の映画だからってのもあるけど。 最後の大雨の中の合戦シーンなども CG などろくに使えない時代なのに迫力があります。 ジョンウー監督のレッドクリフも影響を受けてそうです。同じだ。 ラストシーンの音楽に合わせて田植えをするシーンは 北野監督の座頭一を思い出します。同じだ。 アイランド （2005年 アメリカ） ★★★★☆ 4/5点。 自分がよく分からない施設で生活しているなぁと思ったら、 実は自分は臓器を取り出すために作られたクローン人間だったという話。 極秘でクローン人間を育てている施設にしては随分セキュリティがあまい気がしました。 マイノリティリポートほど発展した未来は描かれていなくて現実味があるんですが、 西暦2019年という設定はいくらなんでも無理があるんじゃないかと。。あと10年です。 エネミー・オブ・アメリカ （1998年 アメリカ） ★★★☆☆ 3/5点。 ある弁護士が、あるきっかけで国家安全保障局 NSA の機密情報を手に入れてしまい、 あらゆる監視システムによって追い詰められていくという話。 前半は、NSA に情報をあらゆる操作をされて人生をぼろぼろにされていきます。 なんか見ているこっちが疲れました。 ほとんどの監視システムは衛星を基にしたものになっていますが、 技術の背景をちゃんと説明していて、なかなかリアルでよいです。 最後は、冒頭の事件を利用するのですが、ちょっとこじつけっぽかったなぁ。 縛り首の木 （1959年 アメリカ） ★☆☆☆☆ 1/5点。 丘の上に診療所を開いた医者のフレイルが、崖から落ちそうになっていたルーンを救い召使にする話。 ヤマもオチもなかった。 あ、ヤマは金を発見した場面か。 ファイナルファンタジー （2001年 アメリカ、日本） ★★☆☆☆ 2/5点。 よく見えない敵と戦って、地球の精神（ガイア）を守る？みたいなよく分かんない全編 CG 映画。 CG は綺麗で、人も常に動かしててリアルです。 戦ってる意味がよく分かんないし、エンディングも何を救ったのかよく分かんないし、 しかも全部 CG なので、なんだか全然感情移入できないまま終わりました。。 2001年宇宙の旅 （1968年 イギリス、アメリカ） ★★★☆☆ 3/5点。 宇宙船の人工知能に殺されそうになりながらモノリスの謎を探る話。 リアルさを追求した結果なのかもしれないけど、無音のシーンが多くて眠くなる。。 最後の長旅の映像はあまりにも長い。。 1968年に作られたことを考えると、当時としては結構衝撃的な映像が多かったのかもしれないけど、 今見ると退屈なシーンが多いです。 最後のシーン、もうちょっとわかりやすくして欲しかった。 WALL・E ウォーリー （2008年 アメリカ） ★★☆☆☆ 2/5点。 お掃除ロボットが地球の植物を取り戻す話。 絵は綺麗なんだけど、いまいち面白くなかった。 ただ、未来の人はほとんど運動しなくてよくなって、みんな太ってるのが面白かった。 むしろそっちの話をつっこんでくれるとよかったなぁ。 ミラクル7号 ★★★☆☆ 2/5点。 チャウンシンチー作品。 UFO から出てきたへんな生き物がいろいろなことをする話。 意味がよく分かりません。 ところどころにカンフーハッスルのパロディが出てきます。 チャウシンチーはまた貧乏役でした。似合うからよいんだけどね。 ブルー・イン・ザ・フェイス （1995年 アメリカ） ★★★☆☆ 3/5点。 ブルックリンのあるタバコ屋に集まる人々の日常を描いた作品。 ほとんどのシーンは店の中だけですが、みんな活気にあふれてて見てて元気がでます。 みんな喋りまくりでほのぼのとした感じではないんだけど、こんな映画もたまにはいいかな。 レイン・フォール 雨の牙 （2009年 日本） ★★☆☆☆ 2/5点。 ジョン・レイン役が椎名桔平じゃなかったら1点かな。 10年くらい前のストーリーを見ているようでした。 警察、ヤクザ、CIA が USB メモリーを追いかけるだけの話だけど、 データのコピー元が残ってる限り根本的に解決してない気がする。 途中からレインが普通の優しいおじさんになってた。ガックリ。 桔平さんは、銭ゲバのお父さんのように謎を秘めてそうな役がいいです。 透明人間 （1992年 アメリカ） ★★☆☆☆ 2/5点。 爆発事故に巻き込まれて透明人間になってしまう話。 警察につかまらないようにずっと逃げまわります。 題材はいいのに何だか平凡なストーリーでした。 透明人間になったからこそいろんなことをやってほしかったなぁ。 終わり方も何の解決にもなってなくてガックリ。 PLANET OF THE APES／猿の惑星 （2001年 アメリカ） ★★★☆☆ 3/5点。 猿が人間を支配する惑星に不時着する話。ティムバートンによるリメイク版らしい。 人間の脇役がまったく意味を成してないのがおしいです。 エンディングはよく意味が理解できませんでした。 ただ時空間を飛び回っていただけというオチ？ ラストの数分だけは考えさせられるので面白いです。 リメイク前の猿の惑星をちょっと見たくなりました。 少林少女 （2008年 日本、香港） ★★☆☆☆ 2/5点。 中国で9年間修行した凛という少女？が日本で少林寺拳法を広めようとしてラクロスする話。 てゆーかなぜにラクロスなのか意味が分かんなかった。 戦う理由も、ただ戦いたいというだけだし、 少林サッカーと比べるとかなり見劣りします。 中村トオルがいい体してたのだけが印象に残ってます。 さすがビーバップハイスクール。 レッドクリフ PartⅡ ★★★☆☆ 3/5点。 戦略とかを楽しんだ PartⅠに比べて、PartⅡはどろどろの殺し合い。 戦いの中でいろんな友情が芽生えていくけれど、結局は殺し合い。 これがジョンウー監督っぽいのかな。 ナルニア国物語 第1章：ライオンと魔女 （2005年 アメリカ） ★★☆☆☆ 2/5点。 かくれんぼで洋服ダンスの中に入ったら、そこにナルニア国があったという話。 ナルニア国で魔女とライオンが戦っている理由がよく分からなかった。 まぁファンタジーだからしょうがないか。 ライオンが蘇った理由もよく分からなかった。 まぁファンタジーだからしょうがないか。 イエス・マン ★★★★★ 5/5点。 ジムキャリー主演。 何でもイエスと答える誓いをして、人生を変えようという話。 何か行動をするときや、頼みごとをされたときに すぐに面倒だなぁと思ってしまう人はこの映画を見ると 少しは前向きに考えられるようになるかもしれない。 現実にはこんなうまくいくことはないかもしれないけど、 NOと答えるよりはYESと答えたほうが物事はよい方向へ向かいそうだなぁ と思わせてくれます。 幸せの力 （2006年 アメリカ） ★★★★★ 5/5点。 貧乏のどん底に落とされたところから這い上がる話。 映画館で見たけど面白かったのでもう一回見てみた。やっぱおもしろい。 明かりがないから高い窓から差し込むかすかな光で勉強するシーンとか、 車にはねられても研修に遅刻しないように飛ばされた靴を必死に探すシーンとか泣けてきます。 デンジャラスビューティ （2001年 アメリカ） ★☆☆☆☆ 1/5点。 ちょっと下品な FBI の捜査官がミス・アメリカ・コンテストに出る話。 女性にはウケるのかな。 シリコン・バレーを駆け抜けろ！ （2002年 アメリカ） ★★★☆☆ 3/5点。 大手企業を自ら辞めて、ベンチャーで 99 ドルの PC を開発するプロジェクトに加わる話。 チームメンバー 4 人で、たった 3 週間で新しい PC を作るところはさすがにできすぎだけど、 最後の最後で開発者たちの努力が報われてよかったー。 装置を極限までにシンプルにしてコスト削減した未来の PC ということだけど、 あれが 99 ドルでできるとは思えませんｗ 探偵物語 （1983年） ★★★★☆ 4/5点。 赤川次郎の小説の映画化。 私立探偵の辻山秀一が女子大生の直美のボーディーガードをする話 この映画の松田優作はすごくまじめな人という設定だけど、 あいかわらずしぶさ爆発なので、優作ファンは楽しめると思います。 さらに、こどもっぽくてかわいい薬師丸ひろ子が競演ときたら、 大ヒットするのもうなずけます。 20世紀少年 第二章 （2009年 日本） ★★★★☆ 4/5点。 ケンヂがいなくなって15年後のともだちが仕切る世界の話。 第二章はケンヂが出てこないのでちょっと残念。 第一章と同じくどうも全体的に盛り上がりにかけるんだけど、 ともだちが起き上がるシーンはしびれたー。 ばかげてるなぁって思っちゃうシーンだけど、 集団心理ってあんなもんなのかなぁ。 ユースケサンタマリアの顔はウケ狙いとしか思えなかったｗ フェノミナン （1996年 アメリカ） ★★★☆☆ 3/5点。 ある日まぶしい光を見て天才になってしまったジョージとの まわりの人々とのかかわりあいを描いた映画。 すごい力を手に入れることによって周りの人に怖がられ、ジョージは孤独になっていく。 そして最後には力の悲しい招待を知ることになります。 でもジョージは街のみんなを大切にしていたからこそ分かってもらえた。 やさしい愛が感じられる話です。 銀河鉄道999 GALAXY EXPRESS （日本 1979年） ★★★★☆ 4/5点。 鉄郎がメーテルに出会って、別れるまでの話をギュッと凝縮した感じのストーリー。 人間を惑星の部品にしてしまうなど、考えただけでゾッとします。 鉄郎はどうして機械の体を手に入れてから機械伯爵と戦わなかったのかなぁ。 そっちのが安全そうなのに。 メーテルの体は人間の体らしいのだけど、それってほとんど人間な気がする。 007 ユア・アイズ・オンリー （1981年 イギリス・アメリカ） ★★★☆☆ 3/5点。 007シリーズ第12作。 落とされそうになりながら崖を登っていくシーンはハラハラおもしろいです。 この映画をアニメにするとルパン三世みたいになっちゃうのかなって思った。 007 ゴールデンアイ （1995年 イギリス・アメリカ） ★★★☆☆ 3/5点。 戦車で街を壊しながら走るのはよくないと思いました。 X-MEN ファイナルディシジョン （2006年 アメリカ） ★★☆☆☆ 2/5点。 X-MEN の第3弾。 主役があっけなく死にすぎ。 映像はよくてストーリーはいまいち。 そもそもジーンをあんなに簡単に刺すとは思わなかった。 マグニートが最後に金属のチェスの駒をピクッと動かして終わるシーンはしゃれてて好き。 椿三十郎 （2007年 日本） ★★☆☆☆ 2/5点。 いたって平凡なヒーロー物時代劇。 織田雄二好きなら見てもよいかも。 マトリックス ★★★★☆ 4/5点。 現実であると思っている世界が実はコンピュータの作り上げた世界であるという 設定はおもしろいんだけど、戦っている目的がよく分からなかった。 プレデター2 （1991年 アメリカ） ★☆☆☆☆ 1/5点。 2は主演がシュワちゃんじゃない。 なぜかプレデターの動きがとろすぎる。 1のときもそうだったけどストーリーがまったくない。 RED CLIFF レッドクリフ （2008年 中国 香港 日本 韓国 台湾） ★★★★☆ 4/5点。 三国志は全然知らないけど見てみました。 中国だからしょうがないけど、、人使いすぎ。 戦いのシーンを見た瞬間、あ、300（スリーハンドレッド）っぽいと思いました。 亀の陣形を使った戦いのシーンは迫力があって眼が離せません。 将軍がひとりだけで雑魚たちをばっさばっさと倒していくところは 現実味はないけど、映画としては見せ方がうまいです。 ただ、初めて 300 を見たときほどの衝撃はなかったかなぁ。 カメラワークが下手なのかわざとなのか、やけに揺れるシーンがあって ちょっと酔いそうな感じがしました。あと、馬の出産シーンは少し眠くなりました。 金城武の孔明が主人公？というくらい出番多すぎ。いい役もらったなぁ。 プレデター （1987年 アメリカ） ★★★★☆ 4/5点。 テレビでやってたのでまた見てしまった。 シュワちゃんの野生的な力強さが楽しめる映画です。 それにしても、プレデターって小学校の頃みんな知ってたから こういう映画って子供受けするのかなぁ。 プレデターというよりシュワちゃん全盛期だったのかな。 映画もほとんどシュワちゃんの一人舞台。みんな死にすぎ。 スニーカーズ （1992年 アメリカ） ★★★☆☆ 3/5点。 ハッカーもの映画。 元犯罪者たちが集まって運営しているセキュリティ会社が、 どんなコンピュータにもアクセスできる「箱」を盗み出す話。 ハッカーものにしては、そんなバカなってシーンは少なくて、 銀行に侵入してお金を送金するだけという無難なことしかしてないのがちょっと残念。 逆に言えば穴は少なくて安心して見れます。 オーシャンズ11もこの映画に影響されてるのかな。 スイング・ガールズ （2004年 日本） ★★★★☆ 4/5点。 補修をさぼるために始めた吹奏楽にはまって、 最後は演奏会で大成功する話。 吹奏楽を練習したいという気持ちに素直になって みんなの気持ちがひとつになっていくところ、 演奏が段々うまくなっていくところは見ていて気持ちいいです。 イーオン・フラックス （2005年 アメリカ） ★★☆☆☆ 2/5点。 クローンとしてしか子供の生まれない世界を変えるためイーオンが戦う話。 原作のアニメを知っていたら楽しめるのかもしれないけど、 映画だけ見ただけでは世界観とかイマイチよく分からない。 クローンとして生まれてきた人は昔の自分の記憶も少し持っている という設定らしい。 To live only once but with hope. （人生は一度きり、だけど希望がある） といったメッセージが出るということは監督はクローン技術に反対なのかな。 ユニバーサル・ソルジャー ザ・リターン （1999年 アメリカ） ★★☆☆☆ 2/5点。 改造人間のユニバーサル・ソルジャーたちが自らの意思で動き出してしまったのを 元ユニバーサル・ソルジャーのリュック（ジャン・クロード・バンダム）が止める話。 それ以上でもそれ以下でもない。 ジャッキー・チェンの映画風に終わるのはどうかと思った。 僕のニューヨークライフ （2003年 アメリカ フランス オランダ イギリス） ★☆☆☆☆ 1/5点。 コメディ作家と一緒に暮らすアマンダが浮気しまくるだけの話。 ヤマなしオチなしなので微妙でした。 ただ、アマンダの開き直り方のすごさは圧倒されます。というか口がポカーン。 DOA デッドオアアライブ （2006年 イギリス・ドイツ・アメリカ） ★★★☆☆ 3/5点。 セガ・サターンのゲーム、DOAの映画化。 最初から最後まで戦いをするだけのストーリー。 かすみ役をデヴォン青木が演じているのを批判している人が多いけど、アクションが冴えててよかったと思う。 かすぅみって発音はいただけないけど。 幸せのポートレート （2005年 アメリカ） ★☆☆☆☆ 1/5点。 婚約者がクリスマスパーティに来て、変な四角関係ができてしまう話。 最初はみんな自分の気持ちを押し殺してぎこちない関係にだったけど、最終的には正直な気持ちで振る舞い、自然体になることで丸く収まります。 自分をさらけ出すことは誤解されたりしてリスクはあるけど、本当に幸せになるには大切なことですね。 プロジェクトBB （2006年 香港） ★★☆☆☆ 2/5点。 警察役が好きなジャッキーとしてはめずらしく、泥棒しまくる話。 と思ったら途中から赤ん坊の世話の話に。 2 週間くらい人の赤ちゃんを預かっただけで、あんなに入れ込んでしまうのかな。 親バカってそんなものなのかな。 ショコラ （2000年 アメリカ） ★★☆☆☆ 2/5点。 ある日フランスの小さな村に来た母娘がチョコレート屋さんを始める話。 チョコを散々否定してきた神父さんが、 チョコを食べまくるシーンが滑稽でおもしろいです。 ヴィアンヌはひどいことをされても怒らないで、逆に暖かく接します。 こういう人が、閉ざされた心を開くんだと思いました。 最後にアンリ神父が、 「人間の価値は何を禁ずるか、何を拒むかでは決まらない。 何を受け入れるかで決まる」 と言ってました。いい言葉だ。 デッドリー・フレンド （1986年 アメリカ） ★★★☆☆ 3/5点。 天才少年のポールが、自分の作ったロボット BB の CPU を 死んだ恋人のサムの脳に埋め込んでよみがえらせる話。 脳に CPU を直接つないでいるシーンなど、いくらなんでも適当すぎです。 そこをしっかり見せればいい感じだったんだけど。。 オープニングの10分くらいは、人工知能ロボットのほんわかした話になるのかと思ったら、 途中でいきなりグロい場面が。。。ばびった このシーンはかなりやばい。。 たかがボールぶつけただけで、んなアホなっ！て思います。 ある意味、この映画はこのシーンを見るためにあるといっても過言ではない。 ポールは最後までサムをあきらめないで生き返らせようとします。 天才少年の考えることは凡人には分からないということですね。 チェーン・リアクション （1996年 アメリカ） ★★★☆☆ 3/5点。 水素によるクリーンエネルギーを開発してしまったばかりに、謎の組織に誘拐されてしまう話。 マトリックスのキアヌ・リーヴス主演。 最初の爆発はすごかったけど、最後はなんかあっけなかった。 無限のエネルギーができたら世界は混乱するとか、そんなことはないとか、途中でそういったやり取りがでてきたけど、 その辺をもうすこし掘り下げて欲しかった。 蛇拳 （香港 1976年） ★★★★☆ 4/5点。 これって私が生まれる前の映画なんですね。びっくり。 ジャッキーの映画にしては敵がみんな優しいし、クンフーものなんだけど、なんだかほんわかして見れます。 酔拳にも同じじぃさんが出てきたけど、このじぃさん蛇拳も使えるし、酔拳も使えるし達人だなぁ。 ジャッキーが特訓している姿をみると、なぜだか元気が出てきます。 20世紀少年 第一章（2008年 日本） ★★★☆☆ 3/5点。 期待してたほどではなかった。とりあえず長すぎ。せめて2時間にしてほしかった。 ケンヂのコンビニが燃やされて、「あぁ」っていってるシーンはわびしくて好きです。 人間ってああいう不条理なことされるとなんか力が出ますよね。 ともだちライブのボーカルが I Rock You. じゃなくて絶対に I Lock You. って発音してるのが非常に気になった。わざとだろうけども（・ω・） 第二章は 2015 年からの話っぽいけど、2001年から2014年までの空白が気になります。 第一章は刑事ドラマみたいな感じであまりお金かけてないように見えたけど、どこに60億円も使ったんだろう。。二章と三章がすごいのかな。 崖の上のポニョ（2008年 日本） ★★☆☆☆ 2/5点。 大人でも楽しめるけど、ジブリ映画の中でも子供向けな感じがしました。 ポニョはしゃべってないときのさかなのときの方がかわいいです。 アース Earth （2007年 ドイツ、イギリス） ★☆☆☆☆ 1/5点。 北極から南極までの広大な自然や、動物たちの映像をドキュメンタリー風に流し続ける映画。 なんだか２時間かけて NHK の教育番組を見ているような感じ。 自然の映像美を見せたいのか、温暖化の危機を訴えたいのかはっきりしませんでした。 温暖化についての映画ならアル・ゴア氏の不都合な真実の方が説得力があるし、 スタッフロールへのメッセージ挿入も秀逸でした。 シロクマの生活が脅かされているというだけではちょっと弱いかな。 映像としてはかなり綺麗で、どうやって撮ったのか分からないものもありました。 タイガにある森林だけで、地球の 1/3 を占めていることとか知ってちょっとビックリ。 コン・エアー ★★★☆☆ 3/5点。 家族を守るために人を殺してしまって囚人になり、 待ちに待った仮釈放の日に乗った護送機コン・エアーの中で、 凶悪犯のハイジャックに巻き込まれてしまう悲惨な話。 主人公キャメロンは逃げるチャンスはいくらでもあるのに 最後まで友人の身を守るために凶悪犯たちの作戦に付き合います。 ほんまかいな～っ思ってしまうおいらは心がないのかな。。 でもここまで友を大切にする姿を子供はしっかりと見ていて、 元囚人だったとしても、きっと子供から尊敬されるいいお父さんになるんだろうなぁ。 ハンコック ★★★★☆ 4/5 点。 メディアージュの先行上映。 ハンコックにもある程度弱いところがあるところがあると思ってたのに、 開始早々いきなり空飛んでて逆に拍子抜けした感じです。 もっとスパイダーマンみたいに主人公の変化とかが分かる展開の方が好きかな。 ウィルスミスは、ハンコックみたいな不器用なキャラがハマってます。 囚人がハンコックの力を奪うんだといってる場面など、 なんだか分かりにくいところがいくつかあったのがマイナス点かな。 人が飛んでくシーンは爽快です。 醜聞 スキャンダル （1950年 日本） ★★☆☆☆ 2/5点。 黒澤明監督作品。 恋愛記事を捏造した出版社を告訴する話。 蛭田弁護士はお金に目がくらんで裏切ろうとするけど、 娘がきっかけとなって心を開いていく。 50年以上たったいま見ても通じるほど完成度は高いです。 でも、蛭田弁護士が酔っ払ってしゃべるシーンが多くて 聞き取りにくい。。 ナンバー23 (THE NUMBER 23) （2007年 アメリカ） ★★☆☆☆ 2/5点。 23 という数字に取り捕り憑かれて狂っていく人の話。 23 にどんな不思議が隠されているのか期待して観たのですが、 92 という数字を 4 で割ったら 23 になるとか、 どうでもよいこじつけばかりで、何も不思議な要素はありませんでした。 どちらかというと、数字ノイローゼになった人の話と割り切って観たほうがよいです。 落ちは夢オチよりはましでした。 ジム・キャリーもおじさんになったなぁ。 シャンハイナイト （2003年 アメリカ） ★★★★☆ 4/5点。 ジャッキー映画の中でもテンポがよくていい感じ。 セットを利用したアクションもキレがあって見てて飽きないです。 チョン・ウェンの友人のロイ・オバノンはちょっといい加減な性格だけれど、 友人にひどいことを言われても切れたりしないで すぐに元気なるところが微笑ましいです。 ボビー・フィッシャーを探して （1993 アメリカ） ★★★★☆ 4/5点。 自分の子供をチェスのチャンピオンに育てようとする話。 チェスで完敗したときに息子の才能に気が付き、 チェスの英才教育が始まります。 でも、ある時やりすぎたとういことに気付く。 そういった子供の教育の難しさとか、チェスのダイナミックさとか楽しめる映画です。 時空の旅人 （1986年 日本） ★★☆☆☆ 2/5点。 未来からやってきたアギノ・ジロが現代人を巻き込んでタイムスリップしまくる迷惑な話。 障壁の事実を知ってしまったアギノが2つの選択肢しか残っていないと 判断するのはちょっと極端すぎだと感じました。 クタジマがアギノを泳がせた工作部分とか、障壁の設定などがもっと詳しく 説明されてるともっと面白そうです。 そいえばファミコンのゲームもあったなぁ。 忍 SHINOBI （2005年 日本） ★★☆☆☆ 2/5点。 2つの忍の里の5人衆が戦う話。 強引に戦わされてる理由もよく分からないし、 里が襲われている理由もよく分からない。 ただ、弦之介の技は、ディオのザ・ワールドっぽくてかっこよかった。 プリティ・プリンセス 2 （2004年 アメリカ） ★☆☆☆☆ 1/5点。 ミアが女王になるために結婚することを迷い続ける話。 ヤマなし、落ちなし。 女王のような生活にあこがれる女性には受けるのかもしれません。 猫の恩返し （2002年 日本） ★★★★☆ 4/5点。 猫王の息子を助けたことがきっかけで猫の世界に連れ去られてしまう話。 全体的にのんびりした話ではあるんだけど、不思議と最後まで楽しめました。 のんびりしていてちょっぴり夢のある話って結構好きなのかも。 ユキはハルを必死に人間の世界に戻そうとするけど、 その理由って、もしかして、王子様をハルに取られたくないからだったりして。。 ダークだ。 カジノ （1995年 アメリカ） ★★★☆☆ 3/5点。 カジノの支配人になった男のカジノ経営と結婚生活の話。 カジノの裏の怖い世界を楽しめます。 カジノの支配人であるエースの視点（セリフ）と、 友人のニッキーの視点（セリフ）でストーリーが進んでいくので、 これを理解してないと最初は少し分かりにくいです。 これまでうまくカジノを経営してきたエースも、 浮気性のジンジャーと結婚していろいろ歯車が狂い始めます。 普通の女性と結婚すれば幸せになれそうなんですが、 惚れてしまった時点でエースの負けだったんでしょう。 ニッキーとジンジャーがお金にこだわる中、エースだけは 堅気にカジノの経営に力を注ぎ、完全な破滅は免れるのですが、 最後にエースが得たものは本当に望んでいたものなのか。 ラストシーンはなんともいえない哀愁が漂います。 それにしても、3時間は長すぎる。。 サウンド・オブ・サンダー （2004年 アメリカ） ★★☆☆☆ 2/5点。 タイムマシン TAMI を使って過去の世界へ戻り、恐竜ハンティングを楽しむ話。 あるとき、過去のものを少し持ち帰ってしまい、現在の世界が大きく変わってしまう。 衝撃波のように進化の波が押し寄せることで現在の世界が変わっていくところは、 あまりに強引すぎな気がします。 人間の作ったものはそのままで、生物だけが進化しているという世界は 不気味さが出ていてよいです。でも、もっと気持ち悪さがあってもよいかな。 インディ・ジョーンズ レイダース 失われたアーク《聖櫃》 （1981年 アメリカ） ★★★☆☆ 3/5点。 インディ・ジョーンズシリーズの第一作。 最初の洞窟のシーンは仕掛け物の原点なんだなと感じさせます。 トレジャー・ハンターとして命の危険にさらされながらも、 考古学者としてのポリシーを曲げないインディがかっこいいです。 ラスベガスをぶっつぶせ ★★★★☆ 4/5点。 MIT の数学が得意な学生が、ラスベガスのブラックジャックで学費を稼ぐという話。 勝ち方が単純なカウンティングだけというところが平凡だけど、 ビジネスとしての人間関係と、友達としての人間関係の違いに 主人公が少しずつ気づいていくところが面白いです。 黒幕が誰なのかというヒントがところどころにあるので、 主要人物の意味深な言葉に注意してみると楽しめると思います。 結局は、裏で操作しているやつが一番得をするってことだけど、 最後はお金ではなく、人間的に成長したんだという終わり方は好き。 DEATH GAME デスゲーム （2006年） ★☆☆☆☆ 1/5点。 ゲームの中で死ぬと現実の世界でも同じように死ぬというありがちな話。 ホラー映画にストーリーを求めては行けないのかもしれないけど、 ストーリーがなさすぎ。 一番最初に首を吊るシーンが一番気持ち悪いです。 そのあとは、後ろを振り向いたら・・・っていう感じのシーンばかりでした。 サウンド・オブ・サンダー （2004年 アメリカ） ★★☆☆☆ 2/5点。 タイムマシン TAMI を使って過去の世界へ戻り、恐竜ハンティングを楽しむ話。 あるとき、過去のものを少し持ち帰ってしまい、現在の世界が大きく変わってしまう。 衝撃波のように進化の波が押し寄せることで現在の世界が変わっていくのですが、 これは好みが分かれるところ。 ブリジットジョーンズの日記 (2001) ★★★☆☆ 3/5点。 カロリー取りすぎの32歳独身のブリジットが上司のダニエルに振り回される話。 不器用だけど自分らしく振舞い続けるブリジットが微笑ましい。 何度失敗しても行動力だけは失わないところは見習わないとなぁって思った。 でもちょっと下品すぎ。。 ウルトラヴァイオレット （2006 米） ★☆☆☆☆ 1/5点。 ストーリーが薄すぎ。CGも手抜き。 殺し屋になったヴァイオレットにも母性本能が残ってたという話。 ヴァイオレットが何をしたいのかいまいち分かりにくいし、 クローン人間のシックスが何を考えているのかも分かりにくい。 終わり方はターミネーターのまねっこ。 ターミネーター3 ★★★☆☆ 3/5点。 どう見ても 2 の焼き増しにしか見えない。 元が面白いから結構楽しめるけど、 1, 2 ほど新鮮味がないです。 ちょっぴりバッドエンドなのは自虐的で素敵。 ソフィーの選択 ★★☆☆☆ 2/5点。 主人公スティンゴが、ネイサンとソフィーの住むアパートに いっしょに住むようになるところから物語が始まる。 ネイサンとソフィーは周りから見ると変わった人たちだけど、 スティンゴはそんな2人の不思議な魅力にはまっていく。 実はネイサンとソフィーには秘密や嘘があるんだけど、 スティンゴだけがそれを知ることになる。 秘密って知った方がいいのか、知らないままがいいのか そんなことを考えさせられます。 とりあえず話が長すぎなのと、 見終わってもいい気分になれないとこがイマイチ。 スパイダーウィックの謎 ★★★☆☆ 3/5点。 見えない妖精たちと戦って、スパイダーウィックの書いた本を守る話。 ドキドキハラハラするシーンがないし、 テンポがスローすぎてちょっと退屈です。 そもそも兄弟を3人にする必要性が感じられないので、 2人に絞った方がもっとテンポよくなると思いました。 とりあえず人数多ければ話の繋ぎが楽なのかもしれないけど、 ハリーポッターを意識しすぎ！ アーサーとミニモイの方が好きです。 カンフーハッスル ★★★★★ 5/5点。 テレビでやってたので見た（前にも一回見たけど）。 アイスクリームを食い逃げするシーンとか わびしさがあって好きだなー。 あとは最初に斧頭会（ふとうかい）のボスが踊りながら登場するシーンもお気に入り。 戦いのシーンは相手が軽く吹っ飛びすぎって 感じるところもあるけど、全体的に非常によく考えて作ってあると思った。 これ見るとチャウシンチーの他の映画も見たくなります。 イン・ザ・カット ★☆☆☆☆ 1/5点。 バラバラ殺人の刑事との恋愛話。 落ちもないし、つまらない。 ルパン三世 ハリマオの財宝を追え (2000年) ★★☆☆☆ 2/5点。 ハリマオの財宝を手に入れるために3体の像を探す話。 キャラの良さがあまり出てなかったけど、 ラーメンさえあればどこでも元気な銭形のとっつぁんが好き。 スティックメン (2002年) ★☆☆☆☆ 1/5点。 ビリヤードものの B 級映画。 ストーリーは微妙。 タキシード (2003年) ★★☆☆☆ 2/5点。 ジャッキーチェン主演。 身に付けると身体能力がものすごく上がる ハイテクなタキシードの話。 はっきりいってジャッキーのよさが活かせていないので、 ジャッキーものとして見ると裏切られるかも。 L change the WorLd ★★★★☆ 4/5点。 デスノート劇場版で夜神月との勝負に勝利した L が、 残された 23 日の命をどのように過ごしたかを描いたストーリー。 デスノートの原作や映画本編を見てからじゃないと面白さ半減です。 デスノートがここまでヒットすると分かっていたら、 本編で月を殺さなかっただろうなぁ。。 L というキャラが好きなら見る価値ありかと。 デスノート本編ほど捻った展開はなかったけど、 ワタリがいない状態の L だけのストーリーにしてはうまくまとめられていてよかった。 タイの少年が L の出したお菓子を食べない場面など、 少しだけですが謎解き要素も含まれてました。 FBI 捜査官役のナンちゃんは思いっきりギャグキャラだったなぁ。 ヤマカシ ★★☆☆☆ 2/5点。 ピョコピョコ走り回るヤマカシというグループが、 ひとりの子供の手術費用を稼ぐために泥棒するお話。 メンバーひとりひとりの個性がもう少し出ているとよかったかな。 これ見てると医者が信用できなくなってきます。 電車男 ★★☆☆☆ 2/5点。 某掲示板からの映画化。 おどおどしたオタク主人公が電車で会ったエルメスとの恋に目覚める話。 ドキドキする展開もないし、かなり平凡な恋愛映画。 スウィーニー・トッド ★★★☆☆ 3/5点。 理髪屋さんがミュージカル風に歌を歌いながら復習劇をくり広げる話。 血が派手に飛び散ります。生々しいです。殺しまくりです。 死体をまさかあんな風に利用するとは思わなかった。 最後のシーンは観客全員が静かになること必死です。 カップルで見たりするのはあまりお勧めできません。 貧しい女性が最後まで正体を明かさなかったのがなぜなのかが謎でした。 ショーシャンクの空へ ★★★☆☆ 3/5点。 冤罪でつかまった主人公が囚人として長い年月を過ごす物語。 主人公が刑務所を出たときに、 長い年月をかけて刑務所の中で行ってきたことの意味がはっきりします。 囚人ものの映画にしては結構まったりとした感じ。 ドラゴン・ヘッド ★☆☆☆☆ 1/5点。 コミックの映画化。 うわさに違わなずつまらなかった。 演技もストーリーもいまいち。 映画はもっと違う話にしたほうがよかったんでないかな。 コミック版の結末と同じくらい力が抜けた。。 I AM LEGEND ★★★★☆ 4/5点。 映画の完成度はかなり高くて、演出もうまくて最後まで飽きさせない。 終わったときは、もうちょっと続いてもいいかなって思ってしまった。 ただ、よく考えてみるとストーリー的にはありがちなもの。 この映画のコメントで「そっち系の映画か」ってのがあったけど、 見て納得。 まさか、○○○○○ー○系の映画だとは。。 クリスマスイブに見ちゃった。おもしろかったからよいけど。 ウィル・スミスって「幸せの力」のときもそうだったけど、 座り込んで涙を流すシーンが似合うなぁ。 ウィル・スミスは座って泣く人っていうイメージができつつあります。 スイミング・プール ★★★☆☆ 3/5点。 どこが現実で、どこが小説（妄想）の中の話なのかを 見る側の判断にまかせるという趣旨の映画。 こういう映画が好きな人は、オゾン監督の別の映画も好きなみたい。 「解釈は人それぞれです」という監督は、ある意味責任放棄というか、 ただ単にストーリーがぐちゃぐちゃになっちゃっただけなんじゃないの？ って気がするので個人的にはあまり好きではないけれど、 もう一度見てみようかなって思わせる作り方はさすがです。 てぃーろーりーろー♪てぃーろーりーろー♪ っていうミステリアスな BGM は気味が悪くて怖くなるので苦手です。 笑拳 ★★★☆☆ 3/5点。 父親を殺した仇をとる話。 ジャッキーが3人を同時に相手にするシーンがすごすぎる。 ボーン・アルティメイタム ★★★★☆ 4/5点。 台場メディアージュで鑑賞。 ボーンの過去が明らかになるボーンシリーズ完結編。 アイデンティティ、スプレマシーを見てなくても楽しめました。 携帯電話で指示を出すシーンのテンポがちょっと速すぎて分かりにくかったな。 あのスピード感がいいのかもしれないけど。 すっきりした終わり方は嫌いじゃないけど、 ボーンがなぜ、ジェイソン・ボーンになったのかという 背景をもう少し詳しく描いた方がよかったと思う。 それにしてもマットデイモンはかこいいー。 無駄にしゃべらず、必要なときには正確な指示を出す。 そんなところがクールに感じるのかもね。 アーサーとミニモイの不思議な国 ★★★☆☆ 3/5点。 アーサーが小さくなって、地下のミニモイの国に入り、 おじいちゃんが庭に埋めたという宝物を探すお話。 空とぶ乗り物に乗っているのに、ストローが貴重だと言ったり、 気にしだすとおかしなところはたくさんあるけど、 ファンタジーものが好きなら気にせずに楽しめます。 アーサーはミニモイのセレニアと結婚しちゃったけど、 将来はミニモイの国で暮らすのかな。。 ハリーポッターと不死鳥の騎士団 Harry Potter and the Order of the Phoenix ★★★★☆ 4/5点。 長い映画ですけど、さすが、全体的にクオリティが高いので 途中で眠くならずに見続けられますｗ 最初ハリーが（子供役として）ブランコに乗ってるシーンで始まるわけだけど、 身長がもうすっかり大人になっていて、 ものすごい不自然な感覚を味わえますｗ 途中でハリーが魔法の先生になって、ハリー軍団を作っていたので、 最後にどれだけ活躍するのかワクワクして見てたのに、 結局ハリーの一人舞台。 最後の戦いがイマイチでした。 ラッシュアワー3 ★★★☆☆ 3/5点。 ちょっと下品なジャッキーチェンが見れるラッシュアワー。 ジャッキーはもちろん刑事役です。 工藤夕貴との格闘シーンが明らかに早送りになっていたのがものすごく気になりました。。。 ストーリー的にはありきたりでもうひとつかな。 レミーのおいしいレストラン ★★★☆☆ 3/5点。 心のほんわかする安心して見れる映画です。 ねずみのレミーはすごいがんばってたけど、 主人公の男の子は結局何もやってないような。。。 レミーがいなくなっても、一人で料理できるようになる っていうエンディングの方がよかったな。 オーシャンズ13 ★★★☆☆ 3/5点。 カジノの経営者への復習として、みんなでカジノ潰しする話です。 2 よりは面白いけど 1 の方が面白いです。 1 は結構スリリングだったけど、今回の話はスリルが足りないし、ストーリーもいまいちでした。 役者の演技力でもってる感じがしました。 ブラッドピットは座ってるだけでかっこいいです。 カジノものとしては、007 カジノロワイヤルの方が全然おもしろかったです。 A.I. ★★★☆☆ 3/5点。 スピルバーグが長年かけて作った人工知能を持つ少年ディビッドの話。 前半でディビッドは家族の一員として認められつつあったが、ちょっとしたミスで捨てられてしまう。 後半では家族からの愛を取り戻すために、ディビッドは本当の人間になろうとする。 決して叶うことのない、人間になるという望みを叶えてもらうためにひたすら待ち続けるシーンは、すごい孤独で、さびしい気持ちになりました。 あとで気づいたんだけど、A.I. ってタイトルは、この映画のテーマでもある「愛」とも読めるんだね。しゅご。 愛というものが、人間の五感で伝わるものだとすれば、ロボットから愛を感じられるような時代が来るのかもしれません。 SWORDFISH ★★☆☆☆ 2/5点。 ハッキングして 60 秒で 50 億ドル盗み出す話。 どうやってやったのかはまったくもって謎です。というか映画最後まで見ても、多くの謎が解決されないので結構わだかまりが残ります。 スタンリーが、コンピュータの前でワームを作っているときにノリノリになって踊っているシーンがありました。 プログラマやってると、結構その気持ち分かります。自分の思ったとおりに動くプログラムができていく快感というか興奮というか。さすがに仕事中に踊り出したりしませんが。 DVD にはおまけとして、別のエンディングが 2 種類はいってました。 不都合な真実 ★★☆☆☆ 2/5点。 温暖化による危機を訴える映画。 映画としては面白くないかもしれないけど、見ておくべき映画でしょう。 ゴアさんの必死さが伝わってくる映画でした。 環境に関する論文をすべて調べて、確たる証拠のもとに 起こるであろうことを述べているところに説得力があります。 温暖化の誤解をバッサバッさと切り捨てていきます。 温暖化で海水面は上昇しないとか、温暖化は過去にもあったから今度も大丈夫だとか。 最後のスタッフロールと同時に、みんながこれから 気をつけていくべきことに関するメッセージが流れます。 こういった映画は国が補助したりして多くの人に見てもらうべきだと思います。 300（スリーハンドレッド） ★★★★★ 4/5点。 300人のスパルタ兵たちが数百万人の軍隊と戦う話。 どうやってその兵力の差を埋めるのかが気になって見てしまいました。 圧倒的な兵力を武器に攻めてくる敵に対し、スパルタ兵は子供のころから仕込まれてきた戦いの技術で対抗します。 大きい盾で隣の味方を守りながら戦うというスタイルなど、戦いのプロフェッショナルであることがうまく描写されてました。 兵と兵がぶつかり合うシーンをまったくごまかさずに描写しているのは見事でした。 肉弾戦をここまでリアルに見せる映画ってこれまでなかった気がします。 あと、みんな揃ってウォーウォーっていうのがカッコよかったです。 少しだけ気になったのは、長い戦いの中で、食料とかどう確保したのかなってこと。 ものすごい手ぶらだったしｗ プレステージ（2007年） ★★★★★ 4/5点。 トリックのタネはちょっとゾッとするものでした。 登場人物が多いので最初はちょっと混乱しますが、結末を見るとなるへそという感じです。 でもやっぱり２回見ないと分かりにくい映画であることは確かで、Mr. マリックがもう一回見るって言ってたのが分かった気がします。 DVD 出たらもう一回見よっと。 ペイ・フォワード ★★★☆☆ 3/5点。 「世界を変える」という課題を出された少年が、助け合いの連鎖を作りだす pay it forward というアイデアを考える話。自分が助けられたら、別の人を助けるという単純なアイデア。少年はまずホームレスを助けます。 それにしてもやけにカッコいいホームレスだｗ 県庁の星 ★★★☆☆ 3/5点。 県庁で人生かけてめちゃんこがんばってたのに、コネのなさだけでプロジェクトを外されてしまって途方に暮れる話。現実にも普通にありそうな話でちょっと怖いです。 ウィル・スミスの「幸せの力」もそうだったけど、一旦どん底に叩き落されてから這い上がってくる系の話は、見ていて元気が出るので好きです。仕事がんばらなきゃなって気持ちになれる。 県庁さんがプロジェクトを外され、民間企業で働いて学んだことは何かと聞かれて、「素直に謝ること、素直に教わること、何かを成し遂げるには仲間が必要だということ」と言っていた。プライドを持つことは大切だけど、素直な気持ちを持つことも同じくらい大切なんだって気付かせてくれる映画でした。 バベル ★★☆☆☆ 2/5点。 映画の「バベル」見ました。 4 つの場所での話が並行して進んでいくんですけど、さっぱり意味が分かりませんでした。世界の人々の繋がりとか、愛の大切さとか、銃の怖さとかを伝えたかったのかな？最後も、「え？終わり？」って感じでした。 見た人なりに何かを感じ取ってください、みたいな映画がたまにあるけど、単にストーリーが適当なだけな気がします。 クラブの照明が点滅を繰り返すシーンで、吐き気を催したという人が出てニュースになっていますが、実際かなりヤバイ感じでした。ポケモンで問題になったピカチュウの点滅は数秒間でしょうけど、この映画は１分近く点滅し続けます。しかも暗い映画館の中でｗこれが問題になりそうなことくらい公開前に分かりそうなんですけど、小さい子は見なさそうな映画だからスルーしたんでしょうか。。"
},
{
url: "/p/oappodj/",
title: "読んだマンガの記録",
date: "0001-01-01T00:00:00Z",
body: "読んだマンガの記録 RiNGO （全3巻） 高校生の考えたゲームがゲーム会社に採用されて、 その中のバーチャルアイドル RiNGO を育てていく話。 ゲームショーで RiNGO を紹介しただけで あそこまで人気が出てしまうのがちょっと不自然だったけど、 それがおたくパワーなのかな。 幼なじみは結構いい味だしてたから、もっと活躍させて欲しかった。 主人公は最後に独立してゲーム会社を立ち上げるわけだけど、 そこで最初に作ったゲームがカクカクポリゴン○○○ゲー。。 力が抜けました。"
},
];